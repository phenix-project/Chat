

 *******************************************************************************
xfel/euxfel/__init__.py


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/agipd_cxigeom2nexus.py
from __future__ import absolute_import, division, print_function
from six.moves import range
import os
import h5py
import numpy as np
import subprocess
from read_geom import read_geom
from libtbx.phil import parse
from libtbx.utils import Sorry
import six

phil_scope = parse(
    """
  cxi_file = None
    .type = str
    .help = cheetah file used to read in image data(.cxi).
  geom_file = None
    .type = str
    .help = geometry file to be read in for AGIPD detector (.geom).
  detector_distance = None
    .type = float
    .help = AGIPD Detector distance
  wavelength = None
    .type = float
    .help = AGIPD wavelength override
  mode = vds cxi
    .type = choice
    .optional = False
    .help = Input data file format. VDS: virtual data set. CXI: \
            Cheetah file format.
"""
)


"""

This script creates a master nexus file by taking in as input a) a .cxi file and b) a .geom file
The cxi file is generated by cheetah after processing the raw images and doing appropriate gain corrections
The assumed parameters for the detector can be seen in the __init__ function and should be changed
if they are modified at EU XFEL in the future

"""


def get_git_revision_hash():
    definitions_path = os.path.join(os.path.dirname(sys.argv[0]), "definitions")
    current_dir = os.getcwd()
    os.chdir(definitions_path)
    definitions_hash = subprocess.check_output(["git", "rev-parse", "HEAD"]).strip()
    os.chdir(current_dir)
    return definitions_hash.decode()


class agipd_cxigeom2nexus(object):
    def __init__(self, args):
        self.params_from_phil(args)
        if self.params.detector_distance == None:
            self.params.detector_distance = (
                177.0  # Set detector distance arbitrarily if nothing is provided
            )
        self.hierarchy = read_geom(self.params.geom_file)
        self.n_quads = 4
        self.n_modules = 4
        self.n_asics = 8

    def params_from_phil(self, args):
        user_phil = []
        for arg in args:
            if os.path.isfile(arg):
                user_phil.append(parse(file_name=arg))
            else:
                try:
                    user_phil.append(parse(arg))
                except Exception as e:
                    raise Sorry("Unrecognized argument: %s" % arg)
        self.params = phil_scope.fetch(sources=user_phil).extract()

    def _create_scalar(self, handle, path, dtype, value):
        dataset = handle.create_dataset(path, (), dtype=dtype)
        dataset[()] = value

    def create_vector(self, handle, name, value, **attributes):
        handle.create_dataset(name, (1,), data=[value], dtype="f")
        for key, attribute in six.iteritems(attributes):
            handle[name].attrs[key] = attribute

    def create_nexus_master_file(self):

        """
    Hierarchical structure of master nexus file. Format information available here
    http://download.nexusformat.org/sphinx/classes/base_classes/NXdetector_module.html#nxdetector-module
    --> entry
      --> data
      --> definition (leaf)
      --> instrument
      --> sample
    """
        output_file_name = os.path.splitext(self.params.cxi_file)[0] + "_master.h5"
        f = h5py.File(output_file_name, "w")
        entry = f.create_group("entry")
        entry.attrs["NX_class"] = "NXentry"
        # --> definition
        definition_string = f"NXmx"
        self._create_scalar(
            entry,
            "definition",
            f"S{len(definition_string)}",
            np.string_(definition_string),
        )
        # --> data
        data = entry.create_group("data")
        data.attrs["NX_class"] = "NXdata"
        data_key = "data"
        data[data_key] = h5py.ExternalLink(self.params.cxi_file, "entry_1/data_1/data")
        # --> sample
        sample = entry.create_group("sample")
        sample.attrs["NX_class"] = "NXsample"
        beam = sample.create_group("beam")
        beam.attrs["NX_class"] = "NXbeam"
        if self.params.wavelength is None:
            wavelengths = h5py.File(self.params.cxi_file, "r")[
                "instrument/photon_wavelength_A"
            ]
            beam.create_dataset(
                "incident_wavelength", (1,), data=np.mean(wavelengths), dtype="f8"
            )
        else:
            beam.create_dataset(
                "incident_wavelength", (1,), data=self.params.wavelength, dtype="f8"
            )  # 9150
        beam["incident_wavelength"].attrs["units"] = "angstrom"
        # --> instrument
        instrument = entry.create_group("instrument")
        instrument.attrs["NX_class"] = "NXinstrument"
        agipd = instrument.create_group("AGIPD")
        agipd.attrs["NX_class"] = "NXdetector_group"
        agipd.create_dataset("group_index", data=list(range(1, 3)), dtype="i")
        data = [np.string_("AGIPD"), np.string_("ELE_D0")]
        agipd.create_dataset("group_names", (2,), data=data, dtype="S12")
        agipd.create_dataset("group_parent", (2,), data=[-1, 1], dtype="i")
        agipd.create_dataset("group_type", (2,), data=[1, 2], dtype="i")
        transformations = agipd.create_group("transformations")
        transformations.attrs["NX_class"] = "NXtransformations"
        # Create AXIS leaves for RAIL, D0 and different hierarchical levels of detector
        self.create_vector(
            transformations,
            "AXIS_RAIL",
            self.params.detector_distance,
            depends_on=".",
            equipment="detector",
            equipment_component="detector_arm",
            transformation_type="translation",
            units="mm",
            vector=(0.0, 0.0, 1.0),
        )
        self.create_vector(
            transformations,
            "AXIS_D0",
            0.0,
            depends_on="AXIS_RAIL",
            equipment="detector",
            equipment_component="detector_arm",
            transformation_type="rotation",
            units="degrees",
            vector=(0.0, 0.0, -1.0),
            offset=self.hierarchy.local_origin,
            offset_units="mm",
        )
        # Add 4 quadrants
        # Nexus coordiate system, into the board         AGIPD detector
        #      o --------> (+x)                             Q3=(12,13,14,15) Q0=(0,1,2,3)
        #      |                                                        o
        #      |                                            Q2=(8,9,10,11)   Q1=(4,5,6,7)
        #      v
        #     (+y)

        panels = []
        for q, quad in six.iteritems(self.hierarchy):
            for m, module in six.iteritems(quad):
                panels.extend([module[key] for key in module])
        fast = max([int(panel["max_fs"]) for panel in panels]) + 1
        slow = max([int(panel["max_ss"]) for panel in panels]) + 1
        pixel_size = panels[0]["pixel_size"]
        assert [
            pixel_size == panels[i + 1]["pixel_size"] for i in range(len(panels) - 1)
        ].count(False) == 0

        if self.params.mode == "vds":
            quad_fast = fast
            quad_slow = slow * self.n_quads
            module_fast = quad_fast
            module_slow = quad_slow // self.n_quads
            asic_fast = module_fast
            asic_slow = module_slow // self.n_asics
        elif self.params.mode == "cxi":
            quad_fast = fast
            quad_slow = slow // self.n_quads
            module_fast = quad_fast
            module_slow = quad_slow // self.n_modules
            asic_fast = module_fast
            asic_slow = module_slow // self.n_asics

        detector = instrument.create_group("ELE_D0")
        detector.attrs["NX_class"] = "NXdetector"
        if "mask" in h5py.File(self.params.cxi_file, "r")["entry_1/data_1"]:
            detector.create_dataset(
                "pixel_mask_applied", (1,), data=[True], dtype="uint32"
            )
            detector["pixel_mask"] = h5py.ExternalLink(
                self.params.cxi_file, "entry_1/data_1/mask"
            )
        array_name = "ARRAY_D0"

        alias = "data"
        data_name = "data"
        detector[alias] = h5py.SoftLink("/entry/data/%s" % data_name)

        for quad in range(self.n_quads):
            q_key = "q%d" % quad
            q_name = "AXIS_D0Q%d" % quad
            quad_vector = self.hierarchy[q_key].local_origin.elems
            self.create_vector(
                transformations,
                q_name,
                0.0,
                depends_on="AXIS_D0",
                equipment="detector",
                equipment_component="detector_quad",
                transformation_type="rotation",
                units="degrees",
                vector=(0.0, 0.0, -1.0),
                offset=quad_vector,
                offset_units="mm",
            )
            for module_num in range(self.n_modules):
                m_key = "p%d" % ((quad * self.n_modules) + module_num)
                m_name = "AXIS_D0Q%dM%d" % (quad, module_num)
                module_vector = self.hierarchy[q_key][m_key].local_origin.elems
                self.create_vector(
                    transformations,
                    m_name,
                    0.0,
                    depends_on=q_name,
                    equipment="detector",
                    equipment_component="detector_module",
                    transformation_type="rotation",
                    units="degrees",
                    vector=(0.0, 0.0, -1.0),
                    offset=module_vector,
                    offset_units="mm",
                )

                for asic_num in range(self.n_asics):
                    a_key = "p%da%d" % ((quad * self.n_modules) + module_num, asic_num)
                    a_name = "AXIS_D0Q%dM%dA%d" % (quad, module_num, asic_num)
                    asic_vector = self.hierarchy[q_key][m_key][a_key][
                        "local_origin"
                    ].elems
                    self.create_vector(
                        transformations,
                        a_name,
                        0.0,
                        depends_on=m_name,
                        equipment="detector",
                        equipment_component="detector_asic",
                        transformation_type="rotation",
                        units="degrees",
                        vector=(0.0, 0.0, -1.0),
                        offset=asic_vector,
                        offset_units="mm",
                    )

                    asicmodule = detector.create_group(
                        array_name + "Q%dM%dA%d" % (quad, module_num, asic_num)
                    )
                    asicmodule.attrs["NX_class"] = "NXdetector_module"
                    if self.params.mode == "vds":
                        asicmodule.create_dataset(
                            "data_origin",
                            (3,),
                            data=[
                                (quad * self.n_modules) + module_num,
                                asic_slow * asic_num,
                                0,
                            ],
                            dtype="i",
                        )
                        asicmodule.create_dataset(
                            "data_size", (3,), data=[1, asic_slow, asic_fast], dtype="i"
                        )
                    elif self.params.mode == "cxi":
                        asicmodule.create_dataset(
                            "data_origin",
                            (2,),
                            data=[
                                asic_slow
                                * (
                                    (quad * self.n_modules * self.n_asics)
                                    + (module_num * self.n_asics)
                                    + asic_num
                                ),
                                0,
                            ],
                            dtype="i",
                        )
                        asicmodule.create_dataset(
                            "data_size", (2,), data=[asic_slow, asic_fast], dtype="i"
                        )

                    fast = self.hierarchy[q_key][m_key][a_key]["local_fast"].elems
                    slow = self.hierarchy[q_key][m_key][a_key]["local_slow"].elems
                    self.create_vector(
                        asicmodule,
                        "fast_pixel_direction",
                        pixel_size,
                        depends_on=transformations.name
                        + "/AXIS_D0Q%dM%dA%d" % (quad, module_num, asic_num),
                        transformation_type="translation",
                        units="mm",
                        vector=fast,
                        offset=(0.0, 0.0, 0.0),
                    )
                    self.create_vector(
                        asicmodule,
                        "slow_pixel_direction",
                        pixel_size,
                        depends_on=transformations.name
                        + "/AXIS_D0Q%dM%dA%d" % (quad, module_num, asic_num),
                        transformation_type="translation",
                        units="mm",
                        vector=slow,
                        offset=(0.0, 0.0, 0.0),
                    )

        f.close()


if __name__ == "__main__":
    import sys

    nexus_helper = agipd_cxigeom2nexus(sys.argv[1:])
    nexus_helper.create_nexus_master_file()


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/agipd_from_defs.py
from __future__ import division
from read_geom import read_geom
from extra_data import RunDirectory

from libtbx.phil import parse
from libtbx.utils import Sorry

import h5py
from h5py import string_dtype as h5py_str
import os
import subprocess
import sys
from pathlib import Path
from lxml import etree, objectify
import logging
import numpy as np
from datetime import datetime as dt
from typing import Union, Any, List
from enum import Enum, auto
from collections import Counter
from itertools import product

LOGGING_FORMAT = "%(levelname)s: %(message)s"
logging.basicConfig(level=logging.INFO, format=LOGGING_FORMAT)
logger = logging.getLogger()

p = Path(__file__)
path_to_defs = p.parent / "definitions/applications/NXmx.nxdl.xml"
path_to_phil = p.parent / "AGIPD.phil"

try:
    root = objectify.parse(str(path_to_defs))
except OSError:
    # clone the submodule with definitions:
    os.system(
        f"cd {p.parent.parent.parent} && git submodule update --init --remote && cd -"
    )
    root = objectify.parse(str(path_to_defs))

for elem in root.getiterator():
    try:
        elem.tag = etree.QName(elem).localname
    except ValueError:
        logger.warning(f"Error with {elem.tag}")

with open(path_to_phil) as phil:
    phil_scope = parse(phil.read())


class NxType(Enum):
    """ Enumeration for elements withing NeXus schema """

    group = auto()
    field = auto()
    attribute = auto()


class LazyFunc:
    """ Very primitive version of lazy executor """

    def __init__(self, *args):
        self.func, self.loc_src, self.loc_dest = args

    def push(self, h5file: h5py.File):
        self.func(self.loc_src, h5file[self.loc_dest])
        # close the source file after usage:
        self.func.__self__.close()


class NexusElement:
    def __init__(
        self,
        full_path: str,
        value: Any,
        nxtype: NxType,
        dtype: str,
        parent: str = "",
        attrs: dict = None,
    ) -> None:
        self.value = value
        self.dtype = dtype
        self.type = nxtype
        self.parent = parent
        self.full_path = full_path
        self.attrs = attrs

    def push(self, h5file):
        """ Write an element to the file """
        if self.full_path:
            h5file.create_dataset(self.full_path, data=self.value, dtype=self.dtype)
            if self.attrs:
                for k, v in self.attrs.items():
                    h5file[self.full_path].attrs[k] = v
        else:
            logger.error(f"Cannot push {self.name}")

    def __str__(self):
        return f"{self.value} [type:{type(self.value)}, dtype:{self.dtype}]"


def get_git_revision_hash() -> str:
    definitions_path = os.path.join(os.path.dirname(sys.argv[0]), "definitions")
    current_dir = os.getcwd()
    os.chdir(definitions_path)
    definitions_hash = subprocess.check_output(["git", "rev-parse", "HEAD"]).strip()
    os.chdir(current_dir)
    return definitions_hash.decode()


class Agipd2nexus:
    def __init__(self, args):
        self.group_rules = {}
        self.field_rules = {}
        self.additional_elements = {}
        self.params_from_phil(args)
        self.output_file_name = (
            os.path.splitext(self.params.cxi_file)[0] + "_master_from_defs.h5"
        )
        self.stat = Counter()

    def params_from_phil(self, args):
        """`args` are command line arguments"""
        user_phil = []
        for arg in args:
            if os.path.isfile(arg):
                user_phil.append(parse(file_name=arg))
            else:
                try:
                    user_phil.append(parse(arg))
                except Exception as e:
                    raise Sorry("Unrecognized argument: %s" % arg)
        self.params = phil_scope.fetch(sources=user_phil).extract()

    def translate_groups(self, h5_path: str):
        local_path = h5_path[:]
        for NXname, local_name in self.group_rules.items():
            local_path = local_path.replace(NXname, local_name["names"])
        return local_path

    def get_root_path(self, tree_elem: etree) -> List[str]:
        """ return a NeXus path (e.g. `entry/instrument/detector_group`) from an lxml tree element

        The trickery is that we compare the path's elements with the group names which we want to rename
        and substitute those path's elements accordingly.
        And if for a certain element we need to create several groups, then paths get duplicated with those names:

        Example:
            we have `entry/instrument/detector_group` in the schema, and
            `detector_group` are [`DET_1`, `DET_2`]. Then we've got two paths as the result:
            [`entry/instrument/DET_1`, `entry/instrument/DET_2`]

        """
        ancestor_list = list(x.attrib["type"] for x in tree_elem.iterancestors())
        for j, elem in enumerate(ancestor_list):
            # an `elem` might occur in the `group_rules` no more than once!
            if elem in self.group_rules:
                # for NXname, local_names in self.group_rules.items():
                # check if we use our own names
                if "names" not in self.group_rules[elem]:
                    continue
                local_names = self.group_rules[elem]["names"]
                if len(local_names) == 1:
                    ancestor_list[j] = [local_names[0]]
                else:
                    ancestor_list[j] = []
                    for local_name in local_names:
                        # iterate through many identical groups
                        ancestor_list[j] += [local_name]
            else:
                ancestor_list[j] = [elem]

        ancestor_list = ancestor_list[:-1][
            ::-1
        ]  # drop the last element and reverse the order
        root_path = [
            "/" + "/".join(path).replace("NX", "") for path in product(*ancestor_list)
        ]  # concatenate the values
        return root_path

    @staticmethod
    def get_nxdlPath(h5_path: h5py.Group) -> str:
        par = h5_path.parent.attrs.get("NX_class")
        if par == b"NXentry":
            return par.decode()
        return f"{Agipd2nexus.get_nxdlPath(h5_path.parent)}/{par.decode()}"

    def create_group(
        self, h5file: h5py.File, lx_elem: objectify.ObjectifiedElement, lx_parent: str
    ) -> None:
        """
        Create a new h5.Group attached to the `parent_elem`

        The group name might be provided in the `group_rules`, otherwise it is created on the fly
        either by reducing `NXblah` to `blah` or from the `name` attribute

        Group rules might contain additional actions like creation specific content
        """
        NXname = lx_elem.attrib[
            "type"
        ]  # TODO: the name might be contained in the `name` attribute
        if NXname.startswith("NX"):
            name = NXname.replace("NX", "")
        else:
            logger.warning(f"name {NXname} is not a correct NX-name")
            return
        logger.debug(f"GROUP: {lx_parent} --> {NXname}")
        root_paths = self.get_root_path(lx_elem)
        for root_path in root_paths:
            parent = h5file[root_path]
            if NXname in self.group_rules and "names" in self.group_rules[NXname]:
                for n in self.group_rules[NXname]["names"]:
                    new_group = parent.create_group(n)
                    new_group.attrs["NX_class"] = NXname
                    logger.debug(f"group {n} was created from a rule")
                    self.stat["groups from rules"] += 1
            else:
                new_group = parent.create_group(name)
                new_group.attrs["NX_class"] = NXname
                logger.debug(f"group {name} was created")
                self.stat["groups from defs"] += 1

    def create_field(
        self,
        h5file: h5py.File,
        lx_elem: Union[objectify.ObjectifiedElement, dict],
        recommended: bool = False,
    ) -> None:
        """
        The function tries to add a field to the HDF5 hierarchy.

        If there is a `recommended` marker but the element is not in the `field_rules` then it will be skipped.
        If `recommended == False` then it means the element is mandatory, and even if it is not in the `field_rules`
        it will be filled with a dummy value `7.7777777`
        """
        NXname = lx_elem.attrib["name"]
        name = NXname.replace("NX", "")
        if isinstance(lx_elem, objectify.ObjectifiedElement):
            root_paths = self.get_root_path(lx_elem)
            full_paths = ["/".join([path, name]) for path in root_paths]

        for full_path in full_paths:
            if full_path in self.field_rules:
                logger.debug(
                    f"Add {full_path} from a rule: {self.field_rules[full_path]}"
                )
                if isinstance(self.field_rules[full_path], dict):
                    vector = self.field_rules[full_path]
                    h5file[full_path] = np.array(vector.pop("value"), dtype="f")
                    for key, attribute in vector.items():
                        h5file[full_path].attrs[key] = attribute
                elif isinstance(self.field_rules[full_path], (NexusElement, LazyFunc)):
                    self.field_rules[full_path].push(h5file)
                else:
                    h5file[full_path] = self.field_rules[full_path]
                logger.debug(f"field {full_path} was added")
                self.stat["fields from rules"] += 1

            else:
                if recommended:
                    logger.info(
                        f"Recommended element {full_path} is not in the field rules. Skipped"
                    )
                    continue
                logger.warning(f"Add {full_path} from definition as `7.7777777`")
                field = NexusElement(
                    full_path=full_path, value=7.7777777, nxtype=NxType.field, dtype="f"
                )
                field.push(h5file)
                self.stat["fields from defs"] += 1

    def create_attribute(self, h5file: h5py.File, elem):
        NXname = elem.attrib["name"]
        name = NXname.replace("NX", "")
        if isinstance(elem, objectify.ObjectifiedElement):
            root_path = self.get_root_path(elem)
            full_path = "/".join([root_path, name])

        h5file[full_path] = elem.attrib["value"]
        self.stat["attr"] += 1

    def create_nexus_master_file(self):
        self.out_file = h5py.File(self.output_file_name, "w")
        logger.info(f"file {self.output_file_name} was created")

        for k, v in self.global_attrs.items():
            self.out_file.attrs[k] = v

        for elem in root.getiterator(("group", "field", "attribute")):
            try:
                parent = elem.getparent().attrib["type"]
            except KeyError:
                # that's an attribute
                parent = elem.getparent().attrib["name"]

            if parent == "group":
                # create root element of the file
                entry = self.out_file.create_group("entry")
                entry.attrs["NX_class"] = "NXentry"
                continue

            if elem.tag == "group":
                if (
                    "minOccurs" in elem.keys()
                    and elem.attrib["minOccurs"] == "0"
                    and elem.attrib["type"] not in self.group_rules
                ):
                    continue
                self.create_group(self.out_file, elem, parent)
            elif elem.tag == "field":
                if ("minOccurs" in elem.keys() and elem.attrib["minOccurs"] == "0") or (
                    "optional" in elem.keys() and elem.attrib["optional"] == "true"
                ):
                    logger.debug(f">>> FIELD {elem.attrib['name']} is optional")
                    # an optional field, skip
                    continue
                elif (
                    "recommended" in elem.keys()
                    and elem.attrib["recommended"] == "true"
                ):
                    self.create_field(self.out_file, elem, recommended=True)
                else:
                    self.create_field(self.out_file, elem)
            elif elem.tag == "attribute":
                if "optional" in elem.keys() and elem.attrib["optional"] == "true":
                    continue
                logger.debug(f"Adding attr {elem.attrib['name']}")
        for path, elem in self.additional_elements.items():
            if elem.type == NxType.field:
                field = elem
                setattr(field, "full_path", path)
                field.push(self.out_file)
                logger.debug(f"Additional elem was added to {path}")
                self.stat["fields from add"] += 1
        self.out_file.close()


class Ruleset(Agipd2nexus):
    def __init__(self, args):
        # constructor of the parent class first
        Agipd2nexus.__init__(self, args)

        self.hierarchy = read_geom(self.params.geom_file)

        if self.params.cxi_file and Path(self.params.cxi_file).exists():
            cxi = h5py.File(self.params.cxi_file, "r")
        else:
            cxi = None

        if self.params.detector_distance is None:
            # try to take from the geometry file:
            if self.hierarchy.detector_distance:
                self.params.detector_distance = self.hierarchy.detector_distance
            else:
                raise Sorry(
                    "Detector distance is undefined! You should set it either in `.phil` or in `.geom` files, "
                    "or pass as a command line argument: `detector_distance=123.45` (in mm)"
                )
        if self.params.wavelength is None:
            # try to take from the geometry file:
            if self.hierarchy.incident_wavelength:
                self.params.wavelength = self.hierarchy.incident_wavelength
            else:
                raise Sorry(
                    "Incident wavelength is undefined! You should set it either in `.phil` or in `.geom` files, "
                    "or pass as a command line argument: `wavelength=1.2345` (in angstrom)"
                )
        self.n_quads = 4
        self.n_modules = 4
        self.n_asics = 8

        # ==== CREATE DETECTOR MODULES ====
        """
        Add 4 quadrants
        Nexus coordiate system, into the board            AGIPD detector
             o --------> (+x)                             Q3=(12,13,14,15) Q0=(0,1,2,3)
             |                                                        o
             |                                            Q2=(8,9,10,11)   Q1=(4,5,6,7)
             v
            (+y)
        """
        panels = []
        for q, quad in self.hierarchy.items():
            for m, module in quad.items():
                panels.extend([module[key] for key in module])
        fast = max([int(panel["max_fs"]) for panel in panels]) + 1
        slow = max([int(panel["max_ss"]) for panel in panels]) + 1
        pixel_size = panels[0]["pixel_size"]
        assert [
            pixel_size == panels[i + 1]["pixel_size"] for i in range(len(panels) - 1)
        ].count(False) == 0

        quad_fast = fast
        quad_slow = slow * self.n_quads
        module_fast = quad_fast
        module_slow = quad_slow // self.n_quads
        asic_fast = module_fast
        asic_slow = module_slow // self.n_asics

        self.group_rules = {
            "NXdetector": {"names": ["ELE_D0"]},
            "NXdetector_group": {"names": ["AGIPD"]},
            "NXtransformations": {},
            "NXdetector_module": {"names": []},  # 'names' will be populated below
        }
        array_name = "ARRAY_D0"
        det_path = "/entry/instrument/ELE_D0/"
        t_path = det_path + "transformations/"

        class Transform(NexusElement):
            def __init__(
                self, name: str, value: Any = [0.0], attrs: dict = None
            ) -> None:
                default_attrs = {
                    "equipment": "detector",
                    "transformation_type": "rotation",
                    "units": "degrees",
                    "offset_units": "mm",
                    "vector": (0.0, 0.0, -1.0),
                }
                NexusElement.__init__(
                    self,
                    full_path=t_path + name,
                    value=value,
                    nxtype=NxType.field,
                    dtype="f",
                    attrs={**default_attrs, **attrs},
                )

        det_field_rules = {}  # extends mandatory field rules
        det_additional_rules = (
            {}
        )  # additional transformation elements (fields) for the detector

        for quad in range(self.n_quads):  # iterate quadrants
            q_key = f"q{quad}"
            q_name = f"AXIS_D0Q{quad}"
            quad_vector = self.hierarchy[q_key].local_origin.elems

            q_elem = Transform(
                q_name,
                attrs={
                    "depends_on": t_path + "AXIS_D0",
                    "offset": quad_vector,
                    "equipment_component": "detector_quad",
                },
            )
            det_additional_rules[t_path + q_name] = q_elem
            for module_num in range(
                self.n_modules
            ):  # iterate modules within a quadrant
                m_key = f"p{(quad * self.n_modules) + module_num}"
                m_name = f"AXIS_D0Q{quad}M{module_num}"
                module_vector = self.hierarchy[q_key][m_key].local_origin.elems
                m_elem = Transform(
                    m_name,
                    attrs={
                        "depends_on": t_path + q_name,
                        "equipment_component": "detector_module",
                        "offset": module_vector,
                    },
                )
                det_additional_rules[t_path + m_name] = m_elem
                for asic_num in range(self.n_asics):  # iterate asics within a module
                    a_key = f"p{(quad * self.n_modules) + module_num}a{asic_num}"
                    a_name = f"AXIS_D0Q{quad}M{module_num}A{asic_num}"
                    asic_vector = self.hierarchy[q_key][m_key][a_key][
                        "local_origin"
                    ].elems

                    a_elem = Transform(
                        a_name,
                        attrs={
                            "depends_on": t_path + m_name,
                            "equipment_component": "detector_asic",
                            "offset": asic_vector,
                        },
                    )
                    det_additional_rules[t_path + a_name] = a_elem
                    det_module_name = array_name + f"Q{quad}M{module_num}A{asic_num}"
                    # populate ``group_rules`` with detector modules:
                    self.group_rules["NXdetector_module"]["names"] += [det_module_name]

                    def full_m_name(name: str) -> str:
                        return det_path + det_module_name + "/" + name

                    det_field_rules[full_m_name("data_origin")] = np.array(
                        [(quad * self.n_modules) + module_num, asic_slow * asic_num, 0],
                        dtype="i",
                    )
                    det_field_rules[full_m_name("data_size")] = np.array(
                        [1, asic_slow, asic_fast], dtype="i"
                    )

                    fast = self.hierarchy[q_key][m_key][a_key]["local_fast"].elems
                    slow = self.hierarchy[q_key][m_key][a_key]["local_slow"].elems

                    det_field_rules[full_m_name("fast_pixel_direction")] = NexusElement(
                        full_path=full_m_name("fast_pixel_direction"),
                        value=[pixel_size],
                        dtype="f",
                        nxtype=NxType.field,
                        attrs={
                            "depends_on": t_path
                            + f"AXIS_D0Q{quad}M{module_num}A{asic_num}",
                            "transformation_type": "translation",
                            "units": "mm",
                            "vector": fast,
                            "offset": (0.0, 0.0, 0.0),
                        },
                    )
                    det_field_rules[full_m_name("slow_pixel_direction")] = NexusElement(
                        full_path=full_m_name("slow_pixel_direction"),
                        value=[pixel_size],
                        dtype="f",
                        nxtype=NxType.field,
                        attrs={
                            "depends_on": t_path
                            + f"AXIS_D0Q{quad}M{module_num}A{asic_num}",
                            "transformation_type": "translation",
                            "units": "mm",
                            "vector": slow,
                            "offset": (0.0, 0.0, 0.0),
                        },
                    )
        self.field_rules = {
            # '/entry/definition': np.string_(f"NXmx:{get_git_revision_hash()}"),      # TODO: _create_scalar?
            "/entry/definition": np.string_(
                "NXmx"
            ),  # XXX: whoa! this is THE criteria of being a "nexus format"    !
            "/entry/file_name": np.string_(self.output_file_name),
            # '/entry/start_time': np.string_(self.params.nexus_details.start_time),
            "/entry/start_time": np.string_(
                "2000-10-10T00:00:00.000Z"
            ),  # FIXME: what is the real data?
            # '/entry/end_time': np.string_(self.params.nexus_details.end_time),
            "/entry/end_time": np.string_("2000-10-10T01:00:00.000Z"),
            # '/entry/end_time_estimated': np.string_(self.params.nexus_details.end_time_estimated),
            "/entry/end_time_estimated": np.string_("2000-10-10T01:00:00.000Z"),
            "/entry/data/data": LazyFunc(cxi.copy, "entry_1/data_1/data", "entry/data"),
            "/entry/instrument/name": NexusElement(
                full_path="/entry/instrument/name",
                value=self.params.nexus_details.instrument_name,
                nxtype=NxType.field,
                dtype=h5py_str(),
                attrs={"short_name": self.params.nexus_details.instrument_short_name},
            ),
            "/entry/instrument/AGIPD/group_index": np.array(
                list(range(1, 3)), dtype="i"
            ),  # XXX: why 16, not 2?
            "/entry/instrument/AGIPD/group_names": np.array(
                [np.string_("AGIPD"), np.string_("ELE_D0")], dtype="S12"
            ),
            "/entry/instrument/AGIPD/group_parent": np.array([-1, 1], dtype="i"),
            "/entry/instrument/beam/incident_wavelength": NexusElement(
                full_path="/entry/instrument/beam/incident_wavelength",
                value=self.params.wavelength,
                nxtype=NxType.field,
                dtype="f",
                attrs={"units": "angstrom"},
            ),
            "/entry/instrument/beam/total_flux": NexusElement(
                full_path="/entry/instrument/beam/total_flux",
                value=self.get_xgm_data(cxi),
                nxtype=NxType.field,
                dtype="f",
                attrs={"units": "Hz"},
            ),
            "/entry/instrument/ELE_D0/data": h5py.SoftLink("/entry/data/data"),
            "/entry/instrument/ELE_D0/sensor_material": "Si",  # FIXME: move to the `phil`-file
            "/entry/instrument/ELE_D0/sensor_thickness": NexusElement(
                full_path="/entry/instrument/ELE_D0/sensor_thickness",
                value=300.0,  # FIXME: move to the `phil`-file
                nxtype=NxType.field,
                dtype="f",
                attrs={"units": "microns"},
            ),
            "/entry/sample/depends_on": np.str("."),  # XXX: Why not `np.string_`??
            "/entry/sample/name": NexusElement(
                full_path="/entry/sample/name",
                value=self.params.sample_name,
                nxtype=NxType.field,
                dtype=h5py_str(),
            ),
            "/entry/source/name": NexusElement(
                full_path="/entry/source/name",
                value=self.params.nexus_details.source_name,
                nxtype=NxType.field,
                dtype=h5py_str(),
                attrs={"short_name": self.params.nexus_details.source_short_name},
            ),
        }

        self.field_rules = {**self.field_rules, **det_field_rules}
        self.additional_elements = {
            "/entry/instrument/AGIPD/group_type": NexusElement(
                full_path="/entry/instrument/AGIPD/group_type",
                value=[1, 2],
                nxtype=NxType.field,
                dtype="i",
            ),
            f"{t_path}/AXIS_D0": Transform(
                "AXIS_D0",
                attrs={
                    "depends_on": t_path + "AXIS_RAIL",
                    "equipment_component": "detector_arm",
                    "offset": self.hierarchy.local_origin,
                },
            ),
            f"{t_path}/AXIS_RAIL": NexusElement(
                full_path=t_path + "AXIS_RAIL",
                dtype="f",
                nxtype=NxType.field,
                value=[self.params.detector_distance],
                attrs={
                    "depends_on": np.string_("."),
                    "equipment": "detector",
                    "equipment_component": "detector_arm",
                    "transformation_type": "translation",
                    "units": "mm",
                    "vector": (0.0, 0.0, 1.0),
                },
            ),
        }
        self.additional_elements = {**self.additional_elements, **det_additional_rules}
        self.global_attrs = {
            "NX_class": "NXroot",
            "file_name": self.output_file_name,
            "file_time": str(dt.now()),
            "HDF5_Version": h5py.version.hdf5_version,
        }

    def get_xgm_data(self, cxi):
        run_raw = RunDirectory(self.params.xgm_dir)
        # Photon energy: E = hc/λ
        hc = 1.9864458571489e-25  # [joule * meter]
        # wavelength is in ångström, it gives the 1E10 factor
        pe = hc * 1e10 / self.params.wavelength  # photon energy in joules
        tids = cxi["entry_1/trainId"]
        intensity = run_raw.get_array(
            self.params.xgm_addr, "data.intensityTD", extra_dims=["pulseID"]
        )
        xgm_data = intensity[
            (intensity["trainId"] >= tids[0]) & (intensity["trainId"] <= tids[-1])
        ][:, : self.params.xgm_pulse_num]
        # XGM data is in μJ, it gives the 1E-6 factor
        # Finally, we normalize this per 220 nanoseconds (2.2E-7)
        return xgm_data * 1e-6 / pe / 2.2e-7


if __name__ == "__main__":
    nexus_helper = Ruleset(sys.argv[1:])
    nexus_helper.create_nexus_master_file()
    logger.info(
        "Stats:\n\t" + "\n\t".join(f"{k}: {v}" for k, v in nexus_helper.stat.items())
    )


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/impatient-guide/conf.py
# -*- coding: utf-8 -*-
#
# NeXus for the Impatient documentation build configuration file, created by
# sphinx-quickstart on Tue Nov 22 12:47:54 2011.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = []

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'NeXus for the Impatient'
copyright = u'2014-2016, http://nexusformat.org'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '2016'
# The full version, including alpha/beta/rc tags.
release = '2016'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'agogo'
html_theme = 'sphinxdoc'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
html_title = 'NeXus for the Impatient'

# A shorter title for the navigation bar.  Default is the same as html_title.
html_short_title = project

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
html_logo = "nexuslogo.png"

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
html_favicon = 'favicon.ico'

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
html_use_index = False

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'NXImpatient'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
# FIXME: roman page numbers in TOC, and no page numbers later
#  http://osdir.com/ml/sphinx-dev/2011-03/msg00036.html
#  BUT, latex does not recognize these two lines when in the preamble
'preamble': '''%
 \pagestyle{plain}
 \pagenumbering{arabic}
''',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'NXImpatient.tex', project,
   u'nexusformat.org', 'howto'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
latex_logo = 'nexuslogo.png'

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
latex_domain_indices = False


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'nximpatient', project,
     [u'nexusformat.org'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'NXImpatient', project,
   u'nexusformat.org', 'NXImpatient', 
   'Brief overview of the NeXus data format.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'


# -- Options for Epub output ---------------------------------------------------

# Bibliographic Dublin Core info.
epub_title = project
epub_author = u'nexusformat.org'
epub_publisher = u'http://nexusformat.org'
epub_copyright = copyright

# The language of the text. It defaults to the language option
# or en if the language is not set.
#epub_language = ''

# The scheme of the identifier. Typical schemes are ISBN or URL.
#epub_scheme = ''

# The unique identifier of the text. This can be a ISBN number
# or the project homepage.
#epub_identifier = ''

# A unique identification for the text.
#epub_uid = ''

# A tuple containing the cover image and cover page html template filenames.
#epub_cover = ()

# HTML files that should be inserted before the pages created by sphinx.
# The format is a list of tuples containing the path and title.
#epub_pre_files = []

# HTML files shat should be inserted after the pages created by sphinx.
# The format is a list of tuples containing the path and title.
#epub_post_files = []

# A list of files that should not be packed into the epub file.
#epub_exclude_files = []

# The depth of the table of contents in toc.ncx.
#epub_tocdepth = 3

# Allow duplicate toc entries.
#epub_tocdup = True


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/manual/source/conf.py
# Configuration file for the Sphinx documentation builder.
#
# This file only contains a selection of the most common options. For a full
# list see the documentation:
# https://www.sphinx-doc.org/en/master/usage/configuration.html

# -- Path setup --------------------------------------------------------------

import sys, os, datetime

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#
# import os
# import sys
# sys.path.insert(0, os.path.abspath('.'))


# -- Project information -----------------------------------------------------

project = 'nexus'
author = 'NIAC, https://www.nexusformat.org'
copyright = u'1996-{}, {}'.format(datetime.datetime.now().year, author)
description = u'NeXus: A Common Data Format for Neutron, X-ray, and Muon Science'

# The full version, including alpha/beta/rc tags
version = u'unknown NXDL version'
release = u'unknown NXDL release'
nxdl_version = open('../../NXDL_VERSION').read().strip()
if nxdl_version is not None:
    version = nxdl_version.split('.')[0]
    release = nxdl_version


# -- General configuration ---------------------------------------------------

# https://github.com/nexusformat/definitions/issues/659#issuecomment-577438319
needs_sphinx = '2.3'

# Add any Sphinx extension module names here, as strings. They can be
# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom
# ones.
extensions = [
    'sphinx.ext.mathjax',
    'sphinx.ext.ifconfig',
    'sphinx.ext.viewcode',
    'sphinx.ext.githubpages',
]

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
# This pattern also affects html_static_path and html_extra_path.
exclude_patterns = []


# -- Options for HTML output -------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
#
# html_theme = 'alabaster'
html_theme = 'sphinxdoc'

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

html_sidebars = {
    '**': [
        'localtoc.html', 
        'relations.html', 
        'sourcelink.html', 
        'searchbox.html', 
        'google_search.html'
    ],
}

# Output file base name for HTML help builder.
htmlhelp_basename = 'NeXusManualdoc'


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/manual/source/examples/epics/write_nexus_file.py
import numpy as np
import h5py
import datetime

def write_nexus_file(fname, image, md={}):
	"""
	write the image to a NeXus HDF5 data file

	Parameters
	----------
	fname : str
		name of the file (relative or absolute) to be written
	image : numpy array
		the image data
	md : dictionary
		key: value where value is something that can be written by h5py
			 (such as str, int, float, numpy array, ...)
	"""
	nexus = h5py.File(fname, "w")
	nexus.attrs["filename"] = fname
	nexus.attrs["file_time"] = str(datetime.datetime.now())
	nexus.attrs["creator"] = "write_nexus_file()"
	nexus.attrs["H5PY_VERSION"] = h5py.__version__

	# /entry
	nxentry = nexus.create_group("entry")
	nxentry.attrs["NX_class"] = "NXentry"
	nexus.attrs["default"] = nxentry.name

	# /entry/instrument
	nxinstrument = nxentry.create_group("instrument")
	nxinstrument.attrs["NX_class"] = "NXinstrument"

	# /entry/instrument/detector
	nxdetector = nxinstrument.create_group("detector")
	nxdetector.attrs["NX_class"] = "NXdetector"

	# /entry/instrument/detector/image
	ds = nxdetector.create_dataset("image", data=image, compression="gzip")
	ds.attrs["units"] = "counts"
	ds.attrs["target"] = "/entry/instrument/detector/image"

	# /entry/data
	nxdata = nxentry.create_group("data")
	nxdata.attrs["NX_class"] = "NXdata"
	nxentry.attrs["default"] = nxdata.name

	# /entry/data/data --> /entry/instrument/detector/image
	nxdata["data"] = nexus["/entry/instrument/detector/image"]
	nxdata.attrs["signal"] = "data"

	if len(md) > 0:
		# /entry/instrument/metadata (optional, for metadata)
		metadata = nxinstrument.create_group("metadata")
		metadata.attrs["NX_class"] = "NXcollection"
		for k, v in md.items():
			try:
				metadata.create_dataset(k, data=v)
			except Exception:
				metadata.create_dataset(k, data=str(v))

	nexus.close()

	
if __name__ == "__main__":
	"""demonstrate how to use this code"""
	import epics
	prefix = "13SIM1:"
	img = epics.caget(prefix+"image1:ArrayData")
	size_x = epics.caget(prefix+"cam1:ArraySizeX_RBV")
	size_y = epics.caget(prefix+"cam1:ArraySizeY_RBV")
	# edit the full image for just the binned data
	img = img[:size_x*size_y].reshape((size_x, size_y))

	extra_information = dict(
		unique_id = epics.caget(prefix+"image1:UniqueId_RBV"),
		size_x = size_x,
		size_y = size_y,
		detector_state = epics.caget(prefix+"cam1:DetectorState_RBV"),
		bitcoin_value="15000",
	)
	write_nexus_file("example.h5", img, md=extra_information)


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/manual/source/examples/epics/write_nexus_file2.py
import numpy as np
import nexusformat


def write_nexus_file(fname, image, md={}):
    """
    write the image to a NeXus HDF5 data file

    Parameters
    ----------
    fname : str
        name of the file (relative or absolute) to be written
    image : numpy array
        the image data
    md : dictionary
        key: value where value is something that can be written by h5py
             (such as str, int, float, numpy array, ...)
    """
    nx = NXroot()
    nx['/entry'] = NXentry(NXinstrument(NXdetector()))
    nx['entry/instrument/detector/image'] = NXfield(image, units='counts',
                                                    compression='gzip')
    nx['entry/data'] = NXdata()
    nx['entry/data'].makelink(nx['entry/instrument/detector/image'])
    nx['entry/data'].nxsignal = nx['entry/data/image']

    if len(md) > 0:
        # /entry/instrument/metadata (optional, for metadata)
        metadata = nx['/entry/instrument/metadata'] = NXcollection()
        for k, v in md.items():
            metadata[k] = v

    nx.save(fname, 'w')

	
if __name__ == "__main__":
	"""demonstrate how to use this code"""
	import epics
	prefix = "13SIM1:"
	img = epics.caget(prefix+"image1:ArrayData")
	size_x = epics.caget(prefix+"cam1:ArraySizeX_RBV")
	size_y = epics.caget(prefix+"cam1:ArraySizeY_RBV")
	# edit the full image for just the binned data
	img = img[:size_x*size_y].reshape((size_x, size_y))

	extra_information = dict(
		unique_id = epics.caget(prefix+"image1:UniqueId_RBV"),
		size_x = size_x,
		size_y = size_y,
		detector_state = epics.caget(prefix+"cam1:DetectorState_RBV"),
		bitcoin_value="15000",
	)
	write_nexus_file("example.h5", img, md=extra_information)


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/manual/source/examples/h5py/BasicReader.py
#!/usr/bin/env python
'''Reads NeXus HDF5 files using h5py and prints the contents'''

import h5py    # HDF5 support

fileName = "prj_test.nexus.hdf5"
f = h5py.File(fileName,  "r")
for item in f.attrs.keys():
    print(item + ":", f.attrs[item])
mr = f['/entry/mr_scan/mr']
i00 = f['/entry/mr_scan/I00']
print("%s\t%s\t%s" % ("#", "mr", "I00"))
for i in range(len(mr)):
    print("%d\t%g\t%d" % (i, mr[i], i00[i]))
f.close()


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/manual/source/examples/h5py/BasicWriter.py
#!/usr/bin/env python
'''Writes a NeXus HDF5 file using h5py and numpy'''

import h5py    # HDF5 support
import numpy
import six

print("Write a NeXus HDF5 file")
fileName = u"prj_test.nexus.hdf5"
timestamp = u"2010-10-18T17:17:04-0500"

# load data from two column format
data = numpy.loadtxt(u"input.dat").T
mr_arr = data[0]
i00_arr = numpy.asarray(data[1],'int32')

# create the HDF5 NeXus file
f = h5py.File(fileName, "w")
# point to the default data to be plotted
f.attrs[u'default']          = u'entry'
# give the HDF5 root some more attributes
f.attrs[u'file_name']        = fileName
f.attrs[u'file_time']        = timestamp
f.attrs[u'instrument']       = u'APS USAXS at 32ID-B'
f.attrs[u'creator']          = u'BasicWriter.py'
f.attrs[u'NeXus_version']    = u'4.3.0'
f.attrs[u'HDF5_Version']     = six.u(h5py.version.hdf5_version)
f.attrs[u'h5py_version']     = six.u(h5py.version.version)

# create the NXentry group
nxentry = f.create_group(u'entry')
nxentry.attrs[u'NX_class'] = u'NXentry'
nxentry.attrs[u'default'] = u'mr_scan'
nxentry.create_dataset(u'title', data=u'1-D scan of I00 v. mr')

# create the NXentry group
nxdata = nxentry.create_group(u'mr_scan')
nxdata.attrs[u'NX_class'] = u'NXdata'
nxdata.attrs[u'signal'] = u'I00'      # Y axis of default plot
nxdata.attrs[u'axes'] = u'mr'         # X axis of default plot
nxdata.attrs[u'mr_indices'] = [0,]   # use "mr" as the first dimension of I00

# X axis data
ds = nxdata.create_dataset(u'mr', data=mr_arr)
ds.attrs[u'units'] = u'degrees'
ds.attrs[u'long_name'] = u'USAXS mr (degrees)'    # suggested X axis plot label

# Y axis data
ds = nxdata.create_dataset(u'I00', data=i00_arr)
ds.attrs[u'units'] = u'counts'
ds.attrs[u'long_name'] = u'USAXS I00 (counts)'    # suggested Y axis plot label

f.close()	# be CERTAIN to close the file

print("wrote file:", fileName)


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/manual/source/examples/h5py/TestReader.py

'''Reads NeXus HDF5 files using h5py and prints the contents'''

import h5py    # HDF5 support


testFiles = ("prj_test.nexus.hdf5",)

GROUP_TYPE_MATCH = "<class 'h5py.highlevel.Group'>"
DATASET_TYPE_MATCH = "<class 'h5py.highlevel.Dataset'>"


def print_attr(parent, label):
    for k, v in parent.attrs.iteritems():
        print("%s.attrs[%s]=%s" % (label, k, v))


def print_child(item, label):
    print("#" + "-"*40)
    print("%s  %s" % (label, type(item)))
    print_attr(item, label)
    if (repr(type(item)) == GROUP_TYPE_MATCH):
        base = label
        if "NX_class" in item.attrs:
            base += ":" + item.attrs["NX_class"]
        for k in item.keys():
            key = "%s/%s" % (base, k)
            print_child(item[k], key)
    if (repr(type(item)) == DATASET_TYPE_MATCH):
        #print label, item.value
        print(label)
        print("shape:", item.shape)
        print("size:", len(item.shape))
        print("NumPy dtype:", item.dtype)


def process(fileName):
    try:
        f = h5py.File(fileName, "r")
    except:
        return False
    print(f.filename)
    print("keys: ", f.keys())
    print_attr(f, "f")
    for k in f.keys():
        print_child(f[k], "%s://%s" % (fileName, k))
    f.close()
    return True


if __name__ == '__main__':
    for fileName in testFiles:
        print("#" + "="*60)
        if not process( fileName ):
            print("Could not open:", fileName)


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/manual/source/examples/h5py/TestWriter.py
'''Writes a NeXus HDF5 file using h5py'''

import h5py    # HDF5 support
import six
import time


RAW_MR_SCAN = """
17.92608    1037
17.92591    1318
17.92575    1704
17.92558    2857
17.92541    4516
17.92525    9998
17.92508    23819
17.92491    31662
17.92475    40458
17.92458    49087
17.92441    56514
17.92425    63499
17.92408    66802
17.92391    66863
17.92375    66599
17.92358    66206
17.92341    65747
17.92325    65250
17.92308    64129
17.92291    63044
17.92275    60796
17.92258    56795
17.92241    51550
17.92225    43710
17.92208    29315
17.92191    19782
17.92175    12992
17.92158    6622
17.92141    4198
17.92125    2248
17.92108    1321
"""


if __name__ == '__main__':
    print("Write a NeXus HDF5 file")
    fileName = "prj_test.nexus.hdf5"
    tzsecs = abs(time.timezone)
    if time.timezone < 0:
        tzhhmm = "+"    # reverse logic, it seems
    else:
        tzhhmm = "-"
    if time.daylight:
        tzsecs -= 3600
    tzhhmm += "%02d%02d" % (tzsecs / 3600, (tzsecs % 3600)/60)
    timestamp = time.strftime("%Y-%m-%dT%H:%M:%S") + tzhhmm

    # prepare the data
    data = {u"mr": [], u"I00": []}
    buffer = RAW_MR_SCAN.strip().split("\n")
    for row in buffer:
        (x, y) = row.split()
        data[u"mr"].append(float(x))
        data[u"I00"].append(float(y))

    # create the HDF5 NeXus file
    f = h5py.File(fileName, "w")
    f.attrs[u"file_name"] = fileName
    f.attrs[u"creator"] = "Pete R. Jemian <jemian@anl.gov> using h5py"
    f.attrs[u"HDF5_Version"] = six.u()h5py.version.hdf5_version
    f.attrs[u"NeXus_version"] = u"4.2.1"
    f.attrs[u"h5py_version"] = six.u(h5py.version.version)
    f.attrs[u"file_time"] = six.u(timestamp)
    f.attrs[u"file_update_time"] = six.u(timestamp)
    f.attrs[u"default"] = u"entry"    # identify default NXentry group

    nxentry = f.create_group(u"entry")
    nxentry.attrs[u"NX_class"] = u"NXentry"   # identify NeXus base class
    nxentry.attrs[u"default"] = u"mr_scan"    # identify default NXdata group

    # store the scan data
    nxdata = nxentry.create_group(u"mr_scan")
    nxdata.attrs[u"NX_class"] = u"NXdata"   # identify NeXus base class
    nxdata.attrs[u"signal"] = u"I00"        # identify default data to plot
    nxdata.attrs[u"axes"] = u"mr"           # identify default dimension scale to plot

    mr = nxdata.create_dataset(u"mr", data=data[u"mr"])
    mr.attrs[u"units"] = u"degrees"

    i00 = nxdata.create_dataset(u"I00", data=data[u"I00"])
    i00.attrs[u"units"] = u"counts"

    # fill in some optional metadata
    nxentry.create_dataset(u"title", 
    	data=u"APS USAXS instrument MR (alignment) scan")
    nxentry.create_dataset(u"start_time", data=u"2010-04-25T10:20:56-0500")
    nxentry.create_dataset(u"end_time", data=u"2010-04-25T10:21:16-0500")
    nxentry.create_dataset(u"experiment_identifier", 
       data=u"spec file 04_25.dat, scan #8")
    nxentry.create_dataset(u"experiment_description", 
       data=u"alignment scan of the USAXS collimating optics")

    # be CERTAIN to close the file
    f.close()


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/manual/source/examples/h5py/externalExample.py
#!/usr/bin/env python
'''
Writes a NeXus HDF5 file using h5py with links to data in other HDF5 files.

This example is based on ``writer_2_1``.
'''

import h5py
import numpy

FILE_HDF5_MASTER = u"external_master.hdf5"
FILE_HDF5_ANGLES = u"external_angles.hdf5"
FILE_HDF5_COUNTS = u"external_counts.hdf5"

#---------------------------

# get some data
buffer = numpy.loadtxt("input.dat").T
tthData = buffer[0]                             # float[]
countsData = numpy.asarray(buffer[1],'int32')   # int[]

# put the angle data in an external (non-NeXus) HDF5 data file
f = h5py.File(FILE_HDF5_ANGLES, "w")
ds = f.create_dataset(u"angles", data=tthData)
ds.attrs[u"units"] = u"degrees"
f.close()    # be CERTAIN to close the file


# put the detector counts in an external HDF5 data file 
# with *incomplete* NeXus structure (no NXdata group)
f = h5py.File(FILE_HDF5_COUNTS, "w")
nxentry = f.create_group(u"entry")
nxentry.attrs[u"NX_class"] = u"NXentry"
nxinstrument = nxentry.create_group(u"instrument")
nxinstrument.attrs[u"NX_class"] = u"NXinstrument"
nxdetector = nxinstrument.create_group(u"detector")
nxdetector.attrs[u"NX_class"] = u"NXdetector"
ds = nxdetector.create_dataset(u"counts", data=countsData)
ds.attrs[u"units"] = u"counts"
# link the "two_theta" data stored in separate file
local_addr = nxdetector.name + u"/two_theta"
f[local_addr] = h5py.ExternalLink(FILE_HDF5_ANGLES, u"/angles")
f.close()

# create a master NeXus HDF5 file
f = h5py.File(FILE_HDF5_MASTER, "w")
f.attrs[u"default"] = u"entry"
nxentry = f.create_group(u"entry")
nxentry.attrs[u"NX_class"] =u"NXentry"
nxentry.attrs[u"default"] = u"data"
nxdata = nxentry.create_group(u"data")
nxdata.attrs[u"NX_class"] = u"NXdata"

# link in the signal data
local_addr = '/entry/data/counts'
external_addr = u"/entry/instrument/detector/counts"
f[local_addr] = h5py.ExternalLink(FILE_HDF5_COUNTS, external_addr)
nxdata.attrs[u"signal"] = u"counts"

# link in the axes data
local_addr = u"/entry/data/two_theta"
f[local_addr] = h5py.ExternalLink(FILE_HDF5_ANGLES, u"/angles")
nxdata.attrs[u"axes"] = u"two_theta"
nxdata.attrs[u"two_theta_indices"] = [0,]

local_addr = u"/entry/instrument"
f[local_addr] = h5py.ExternalLink(FILE_HDF5_COUNTS, u"/entry/instrument")

f.close()


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/manual/source/examples/h5py/writer_1_3.py
#!/usr/bin/env python
'''
Writes the simplest NeXus HDF5 file using h5py 

Uses method accepted at 2014NIAC
according to the example from Figure 1.3 
in the Introduction chapter
'''

import h5py
import numpy

buffer = numpy.loadtxt("input.dat").T
tthData = buffer[0]                             # float[]
countsData = numpy.asarray(buffer[1],'int32')   # int[]

f = h5py.File("writer_1_3.hdf5", "w")  # create the HDF5 NeXus file
# since this is a simple example, no attributes are used at this point

nxentry = f.create_group(u"Scan")
nxentry.attrs[u"NX_class"] = u"NXentry"

nxdata = nxentry.create_group(u"data")
nxdata.attrs["NX_class"] = u"NXdata"
nxdata.attrs[u"signal"] = u"counts"
nxdata.attrs[u"axes"] = u"two_theta"
nxdata.attrs[u"two_theta_indices"] = [0,]

tth = nxdata.create_dataset(u"two_theta", data=tthData)
tth.attrs[u"units"] = u"degrees"

counts = nxdata.create_dataset(u"counts", data=countsData)
counts.attrs[u"units"] = u"counts"

f.close()	# be CERTAIN to close the file


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/manual/source/examples/h5py/writer_2_1.py
#!/usr/bin/env python
'''
Writes a simple NeXus HDF5 file using h5py with links
according to the example from Figure 2.1 in the Design chapter
'''

import h5py
import numpy

buffer = numpy.loadtxt("input.dat").T
tthData = buffer[0]                             # float[]
countsData = numpy.asarray(buffer[1],'int32')   # int[]

f = h5py.File("writer_2_1.hdf5", "w")  # create the HDF5 NeXus file
f.attrs[u"default"] = u"entry"

nxentry = f.create_group(u"entry")
nxentry.attrs[u"NX_class"] = u"NXentry"
nxentry.attrs[u"default"] = u"data"

nxinstrument = nxentry.create_group(u"instrument")
nxinstrument.attrs[u"NX_class"] = u"NXinstrument"

nxdetector = nxinstrument.create_group(u"detector")
nxdetector.attrs[u"NX_class"] = u"NXdetector"

# store the data in the NXdetector group
ds_tth = nxdetector.create_dataset(u"two_theta", data=tthData)
ds_tth.attrs[u"units"] = u"degrees"
ds_counts = nxdetector.create_dataset(u"counts", data=countsData)
ds_counts.attrs[u"units"] = u"counts"

# create the NXdata group to define the default plot
nxdata = nxentry.create_group(u"data")
nxdata.attrs[u"NX_class"] = u"NXdata"
nxdata.attrs[u"signal"] = u"counts"
nxdata.attrs[u"axes"] = u"two_theta"
nxdata.attrs[u"two_theta_indices"] = [0,]

source_addr = u"/entry/instrument/detector/two_theta"   # existing data
target_addr = u"two_theta"                              # new location
ds_tth.attrs[u"target"] = source_addr                   # a NeXus API convention for links
nxdata[target_addr] = f[source_addr]                    # hard link
# nxdata._id.link(source_addr, target_addr, h5py.h5g.LINK_HARD)

source_addr = u"/entry/instrument/detector/counts"      # existing data
target_addr = u"counts"                                 # new location
ds_counts.attrs[u"target"] = source_addr                # a NeXus API convention for links
nxdata[target_addr] = f[source_addr]                    # hard link
# nxdata._id.link(source_addr, target_addr, h5py.h5g.LINK_HARD)

f.close()	# be CERTAIN to close the file


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/manual/source/examples/simple3D.py
#!/usr/bin/python

import sys
import nxs
import numpy

a = numpy.zeros((2,3,4),dtype=numpy.int)
val = 0
for i in range(2):
    for j in range(3):
        for k in range(4):
            a[i,j,k] = val
            val = val + 1

nf = nxs.open("simple3D.h5", "w5")

nf.makegroup("entry","NXentry")
nf.opengroup("entry","NXentry")

nf.makegroup("data","NXdata")
nf.opengroup("data","NXdata")
nf.putattr("signal","test")

nf.makedata("test",'int32',[2,3,4])
nf.opendata("test")
nf.putdata(a)
nf.closedata()

nf.closegroup()	# NXdata
nf.closegroup() # NXentry

nf.close()

exit


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/manual/source/examples/verysimple.py
#!/usr/bin/env python
'''uses h5py to build the verysimple.nx5 data file'''

import h5py

angle = [18.9094, 18.9096, 18.9098, 18.91,  18.9102, 
         18.9104, 18.9106, 18.9108, 18.911, 18.9112, 
         18.9114, 18.9116, 18.9118, 18.912, 18.9122]
diode = [1193, 4474, 53220, 274310, 515430, 827880, 
         1227100, 1434640, 1330280, 1037070, 598720, 
         316460, 56677, 1000, 1000]

f = h5py.File('verysimple.nx5', 'w')
f.attrs['default'] = 'entry'

nxentry = f.create_group('entry')
nxentry.attrs["NX_class"] = 'NXentry'
nxentry.attrs['default'] = 'data'

nxdata = nxentry.create_group('data')
nxdata.attrs["NX_class"] = 'NXdata'
nxdata.attrs['signal'] = 'counts'
nxdata.attrs['axes'] = 'two_theta'
nxdata.attrs['two_theta_indices'] = [0,]

tth = nxdata.create_dataset('two_theta', data=angle)
tth.attrs['units'] = 'degrees'
tth.attrs['long_name'] = 'two_theta (degrees)'

counts = nxdata.create_dataset('counts', data=diode)
counts.attrs['units'] = 'counts'
counts.attrs['long_name'] = 'photodiode counts'

f.close()


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/utils/build_preparation.py
#!/usr/bin/env python

# Coded for both python2 and python3.

'''
Copy all resources for out-of-source documentation build

Since we provide a build for Linux, MacOSX, and Windows,
this tool must be multiplatform.  If only for Linux
(and possibly MacOSX), it might be possible to use a form of::

  cp -a ../base_classes ./
  cp -a ../applications ./
  cp -a ../contributed_definitions ./
  cp -a ../manual ./
  ...

Here, we identify and copy all resources to build.
The target directory is assumed to be the current directory.

'''

# Re-run this code to bring in any changed files (for incremental build)
# Be sure to properly specify the source and target directories.

from __future__ import print_function
import os, sys
import local_utilities


MTIME_TOLERANCE = 0.001   # ignore mtime differences <= 1 ms
ROOT_DIR_EXPECTED_RESOURCES = {
    'files': '''COPYING LGPL.txt Makefile NXDL_VERSION
                nxdl.xsd nxdlTypes.xsd README.md
             '''.split(),
    'subdirs': '''applications base_classes contributed_definitions manual
                 package utils www impatient-guide
               '''.split(),
}
REPLICATED_RESOURCES = '''
    LGPL.txt  Makefile  nxdl.xsd  nxdlTypes.xsd  NXDL_VERSION
    base_classes  applications  contributed_definitions 
    manual  utils impatient-guide
'''.split()


def mtime_size(filename):
    '''get the modification time and size of the given item'''
    file_status = os.stat(filename)
    return file_status.st_mtime, file_status.st_size


def standardize_name(path, resource_name):
    '''always use the absolute path to the filesystem resource'''
    return os.path.abspath(os.path.join(path, resource_name))


def identical(source, target):
    '''compare if the resource is the same on both paths'''
    if not os.path.exists(target):
        return False
    s_mtime, s_size = mtime_size(source)
    t_mtime, t_size = mtime_size(target)
    return abs(s_mtime - t_mtime) <= MTIME_TOLERANCE and s_size == t_size


def get_source_items(resources, source_path):
    '''walk the source_path directories accumulating files to be checked'''
    file_list = []
    path_list = []
    for path in sorted(resources):
        source = standardize_name(source_path, path)
        if os.path.isfile(source):
            file_list.append(source)
        else:
            for root, dirs, files in os.walk(source):
                path_list.append(root)
                file_list = file_list + [os.path.join(root, _) for _ in files]
    return path_list, file_list


def is_definitions_directory(basedir):
    '''test if ``basedir`` is a NeXus definitions directory'''
    # look for the expected files and subdirectories in the root directory
    for item_list in ROOT_DIR_EXPECTED_RESOURCES.values():
        for item in item_list:
            if not os.path.exists(os.path.join(basedir, item)):
                return False
    return True


def qualify_inputs(source_dir, target_path):
    '''raise error if this program cannot continue, based on the inputs'''
    if not os.path.exists(source_dir):
        raise RuntimeError('Cannot find ' + source_dir)

    if not os.path.isdir(source_dir):
        raise RuntimeError('Not a directory: ' + source_dir)

    if not is_definitions_directory(source_dir):
        msg = 'Not a NeXus definitions root directory ' + source_dir
        raise RuntimeError(msg)
    
    if source_dir == target_path:
        msg = 'Source and target directories cannot be the same'
        raise RuntimeError(msg)


def command_args():
    '''get the command-line arguments, handle syntax errors'''
    import argparse
    doc = __doc__.strip().splitlines()[0]
    parser = argparse.ArgumentParser(prog=sys.argv[0], description=doc)
    parser.add_argument('defs_dir',
                        action='store', 
                        help="path to NeXus definitions root directory")
    parser.add_argument('build_dir',
                        action='store', 
                        default=None,
                        nargs='?',
                        help="path to target directory (default: current directory)")
    return parser.parse_args()


def update(source_path, target_path):
    '''
    duplicate directory from source_path to target_path
    
    :param source_path str: source directory (NeXus definitions dir)
    :param target_path str: target directory is specified for build product
    '''
    # TODO: what about file items in target_path that are not in source_path?
    source_path = os.path.abspath(source_path)
    target_path = os.path.abspath(target_path)
    qualify_inputs(source_path, target_path)
    
    paths, files = get_source_items(REPLICATED_RESOURCES, source_path)
    local_utilities.printf('source has  %d directories   and   %d files\n', len(paths), len(files))
    
    # create all the directories / subdirectories
    for source in sorted(paths):
        relative_name = source[len(source_path):].lstrip(os.sep)
        target = standardize_name(target_path, relative_name)
        if not os.path.exists(target):
            local_utilities.printf('create directory %s\n', target)
            os.mkdir(target, os.stat(source_path).st_mode)
    # check if the files need to be updated
    for source in sorted(files):
        relative_name = source[len(source_path):].lstrip(os.sep)
        target = standardize_name(target_path, relative_name)
        if not identical(source, target):
            local_utilities.printf('update file %s\n', target)
            local_utilities.replicate(source, target)


def main():
    '''
    standard command-line processing
    
    source directory (NeXus definitions dir) named as command line argument
    target directory is specified (or defaults to present working directory)
    '''
    cli = command_args()
    source_path = os.path.abspath(cli.defs_dir)
    target_path = cli.build_dir or os.path.abspath(os.getcwd())
    update(source_path, target_path)


def __developer_build_setup__():
    '''for use with source-code debugger ONLY'''
    import shutil
    # sys.argv.append('-h')
    os.chdir('../')
    os.chdir('build')
    sys.argv.append('..')


if __name__ == '__main__':
    # __developer_build_setup__()
    main()


# NeXus - Neutron and X-ray Common Data Format
# 
# Copyright (C) 2008-2015 NeXus International Advisory Committee (NIAC)
# 
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 3 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
#
# For further information, see http://www.nexusformat.org


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/utils/create_release_notes.py
#!/usr/bin/env python

"""
Create release notes for a new release of this GitHub repository.
"""

# Requires: 
#
# * assumes current directory is within a repository clone
# * pyGithub (conda or pip install) - https://pygithub.readthedocs.io/
# * Github personal access token (https://github.com/settings/tokens)
#
# Github token access is needed or the GitHub API limit 
# will likely interfere with making a complete report 
# of the release.

import argparse
import datetime
import github
import logging
import os


logging.basicConfig(level=logging.WARNING)
logger = logging.getLogger('create_release_notes')


def findGitConfigFile():
    """
    return full path to .git/config file
    
    must be in current working directory or some parent directory
    
    This is a simplistic search that could be improved by using 
    an open source package.
    
    Needs testing for when things are wrong.
    """
    path = os.getcwd()
    for i in range(99):
        config_file = os.path.join(path, ".git", "config")
        if os.path.exists(config_file):
            return config_file      # found it!
        
        # next, look in the parent directory
        path = os.path.abspath(os.path.join(path, ".."))

    msg = "Could not find .git/config file in any parent directory."
    logger.error(msg)
    raise ValueError(msg)

def parse_git_url(url):
    """
    return (organization, repository) tuple from url line of .git/config file
    """
    if url.startswith("git@"): # deal with git@github.com:org/repo.git
        url = url.split(":")[1]
    org, repo = url.rstrip(".git").split("/")[-2:]
    return org, repo

def getRepositoryInfo():
    """
    return (organization, repository) tuple from .git/config file
    
    This is a simplistic search that could be improved by using 
    an open source package.
    
    Needs testing for when things are wrong.
    """
    config_file = findGitConfigFile()
        
    with open(config_file, "r") as f:
        for line in f.readlines():
            line = line.strip()
            if line.startswith("url"):
                url = line.split("=")[-1].strip()
                if url.find("github.com") < 0:
                    msg = "Not a GitHub repo: " + url
                    logger.error(msg)
                    raise ValueError(msg)
                return parse_git_url(url)

def get_release_info(token, base_tag_name, head_branch_name, milestone_name):
    """mine the Github API for information about this release"""
    organization_name, repository_name = getRepositoryInfo()
    gh = github.Github(token)   # GitHub Personal Access Token

    user = gh.get_user(organization_name)
    logger.debug(f"user: {user}")

    repo = user.get_repo(repository_name)
    logger.debug(f"repo: {repo}")

    milestones = [
        m
        for m in repo.get_milestones(state="all")
        if m.title == milestone_name
    ]
    if len(milestones) == 0:
        msg = f"Could not find milestone: {milestone_name}"
        logger.error(msg)
        raise ValueError(msg)
    milestone = milestones[0]
    logger.debug(f"milestone: {milestone}")

    compare = repo.compare(base_tag_name, head_branch_name)
    logger.debug(f"compare: {compare}")

    commits = {c.sha: c for c in compare.commits}
    logger.debug(f"# commits: {len(commits)}")

    tags = {}
    earliest = None
    for t in repo.get_tags():
        if t.commit.sha in commits:
            tags[t.name] = t
        elif t.name == base_tag_name:
            # PyGitHub oddity:
            #   t.commit == commit
            #   t.commit.last_modified != commit.last_modified
            commit = repo.get_commit(t.commit.sha)
            dt = str2time(commit.last_modified)
            earliest = min(dt, earliest or dt)
    logger.debug(f"# tags: {len(tags)}")

    pulls = {
        p.number: p
        for p in repo.get_pulls(state="closed")
        if p.closed_at > earliest
    }
    logger.debug(f"# pulls: {len(pulls)}")

    issues = {
        i.number: i
        for i in repo.get_issues(milestone=milestone, state="closed")
        if (
            (milestone is not None or i.closed_at > earliest)
            and
            i.number not in pulls
        )
    }
    logger.debug(f"# issues: {len(issues)}")

    return repo, milestone, tags, pulls, issues, commits


def parse_command_line():
    """command line argument parser"""
    doc = __doc__.strip()
    parser = argparse.ArgumentParser(description=doc)

    help_text = "name of tag to start the range"
    parser.add_argument('base', action='store', help=help_text)

    help_text = "name of milestone"
    parser.add_argument('milestone', action='store', help=help_text)

    parser.add_argument(
        'token', 
        action='store', 
        help=(
            "personal access token "
            "(see: https://github.com/settings/tokens)"))

    help_text = "name of tag, branch, SHA to end the range"
    help_text += ' (default="master")'
    parser.add_argument(
        "--head", 
        action='store', 
        dest='head',
        nargs='?', 
        help = help_text, 
        default="master")

    return parser.parse_args()


def str2time(time_string):
    """convert date/time string to datetime object
    
    input string example: ``Tue, 20 Dec 2016 17:35:40 GMT``
    """
    if time_string is None:
        msg = f"need valid date/time string, not: {time_string}"
        logger.error(msg)
        raise ValueError(msg)
    return datetime.datetime.strptime(
        time_string, 
        "%a, %d %b %Y %H:%M:%S %Z")


def report(title, repo, milestone, tags, pulls, issues, commits):
    print(f"## {title}")
    print("")
    print(f"* **date/time**: {datetime.datetime.now()}")
    print("* **release**: ")
    print("* **documentation**: [PDF]()")
    if milestone is not None:
        print(f"* **milestone**: [{milestone.title}]({milestone.url})")
        print("")
    print("section | quantity")
    print("-"*5, " | ", "-"*5)
    print(f"[New Tags](#tags) | {len(tags)}")
    print(f"[Pull Requests](#pull-requests) | {len(pulls)}")
    print(f"[Issues](#issues) | {len(issues)}")
    print(f"[Commits](#commits) | {len(commits)}")
    print("")
    print("### Tags")
    print("")
    if len(tags) == 0:
        print("-- none --")
    else:
        print("tag | date | name")
        print("-"*5, " | ", "-"*5, " | ", "-"*5)
        for k, tag in sorted(tags.items()):
            commit = repo.get_commit(tag.commit.sha)
            when = str2time(commit.last_modified).strftime("%Y-%m-%d")
            print(f"[{tag.commit.sha[:7]}]({tag.commit.html_url}) | {when} | {k}")
    print("")
    print("### Pull Requests")
    print("")
    if len(pulls) == 0:
        print("-- none --")
    else:
        print("pull request | date | state | title")
        print("-"*5, " | ", "-"*5, " | ", "-"*5, " | ", "-"*5)
        for k, pull in sorted(pulls.items()):
            state = {True: "merged", False: "closed"}[pull.merged]
            when = str2time(pull.last_modified).strftime("%Y-%m-%d")
            print(f"[#{pull.number}]({pull.html_url}) | {when} | {state} | {pull.title}")
    print("")
    print("### Issues")
    print("")
    if len(issues) == 0:
        print("-- none --")
    else:
        print("issue | date | title")
        print("-"*5, " | ", "-"*5, " | ", "-"*5)
        for k, issue in sorted(issues.items()):
            if k not in pulls:
                when = issue.closed_at.strftime("%Y-%m-%d")
                print(f"[#{issue.number}]({issue.html_url}) | {when} | {issue.title}")
    print("")
    print("### Commits")
    print("")
    if len(commits) == 0:
        print("-- none --")
    else:
        print("commit | date | message")
        print("-"*5, " | ", "-"*5, " | ", "-"*5)
        for k, commit in commits.items():
            message = commit.commit.message.splitlines()[0]
            when = commit.raw_data['commit']['committer']['date'].split("T")[0]
            print(f"[{k[:7]}]({commit.html_url}) | {when} | {message}")


def main(base=None, head=None, milestone=None, token=None, debug=False):
    if debug:
        base_tag_name = base
        head_branch_name = head
        milestone_name = milestone
        logger.setLevel(logging.DEBUG)
    else:
        cmd = parse_command_line()
        base_tag_name = cmd.base
        head_branch_name = cmd.head
        milestone_name = cmd.milestone
        token = cmd.token
        logger.setLevel(logging.WARNING)

    info = get_release_info(
        token, base_tag_name, head_branch_name, milestone_name)
    # milestone, repo, tags, pulls, issues, commits = info
    report(milestone_name, *info)


if __name__ == '__main__':
    main()


# NeXus - Neutron and X-ray Common Data Format
# 
# Copyright (C) 2008-2020 NeXus International Advisory Committee (NIAC)
# 
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 3 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
#
# For further information, see http://www.nexusformat.org


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/utils/dev_create_release_notes.py
#!/usr/bin/env python

'''
Developers: use this code to develop and test create_release_notes.py
'''
import os

CREDS_FILE = os.path.join(
    os.environ["HOME"],
    ".config",
    "github_token",
)

with open(CREDS_FILE, "r") as cf:
    token = cf.read().strip()

from create_release_notes import main
main(
    base="v2018.5", 
    head="master", 
    milestone="NXDL 2020.1", 
    token=token,
    debug=True)


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/utils/dev_nxdl2rst.py
#!/usr/bin/env python

'''
Developers: use this code to develop and test nxdl2rst.py
'''

# testing:
# cd /tmp
# mkdir out
# /G/nx-def/utils/nxdl2rst.py /G/nx-def/applications/NXsas.nxdl.xml > nxsas.rst && sphinx-build . out
# then point browser to file:///tmp/out/nxsas.html


import nxdl2rst
import os
import sys


# find the directory of this python file
BASEDIR = os.path.dirname(__file__)


# nxdl = os.path.join(BASEDIR, '..', 'applications', 'NXarchive.nxdl.xml')
# nxdl = os.path.join(BASEDIR, '..', 'applications', 'NXsas.nxdl.xml')
# nxdl = os.path.join(BASEDIR, '..', 'base_classes', 'NXcrystal.nxdl.xml')
nxdl = os.path.join(BASEDIR, '..', 'base_classes', 'NXentry.nxdl.xml')
# nxdl = os.path.join(BASEDIR, '..', 'base_classes', 'NXobject.nxdl.xml')
# nxdl = os.path.join(BASEDIR, '..', 'base_classes', 'NXuser.nxdl.xml')
# nxdl = os.path.join(BASEDIR, '..', 'contributed_definitions', 'NXarpes.nxdl.xml')
# nxdl = os.path.join(BASEDIR, '..', 'contributed_definitions', 'NXmagnetic_kicker.nxdl.xml')
# nxdl = os.path.join(BASEDIR, '..', 'applications', 'NXcanSAS.nxdl.xml')

if len(sys.argv) == 1:
    sys.argv.append(nxdl)
elif len(sys.argv) > 1:
    sys.argv[1] = nxdl

nxdl2rst.main()


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/utils/dev_units2rst.py
#!/usr/bin/env python

'''
Developers: use this code to develop and test nxdl2rst.py
'''

import sys
from units2rst import worker


sys.argv.append("../nxdlTypes.xsd")
worker('anyUnitsAttr')


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/utils/local_utilities.py
#!/usr/bin/env python

# Coded for both python2 and python3.

'''
Common code for NeXus definitions Python tools

======================  ==================================
tool                    description
======================  ==================================
:meth:`printf`          wrapper for Python 2.x and 3.x
:meth:`mtime`           return file modification time
:meth:`replicate_tree`  copy directory stack or file
======================  ==================================

'''

from __future__ import print_function
import os, sys, re
import shutil



def printf(str, *args):
    '''wrapper for Python 2.x and 3.x'''
    print(str % args, end='')


def mtime(file_name):
    '''return file modification time'''
    return os.stat(file_name)[stat.ST_MTIME]


def replicate(source, target):
    '''
    for directories or files: copy ``source`` to ``target``, replaces ``target``
    
    :param str source: path to source resource
    :param str target: path to target location
    '''
    if os.path.isfile(source):
        shutil.copy2(source, target)
    elif os.path.isdir(source):
        replicate_tree(source, target)
    else:
        msg = 'Do not know how to copy (skipped): ' + source
        raise RuntimeWarning(msg)


def replicate_tree(source, target):
    '''
    for directories: copy ``source`` to ``target``, replaces ``target``
    
    :param str source: path to source resource (a directory)
    :param str target: path to target location (a directory)
    '''
    if os.path.exists(source):
        if os.path.exists(target):
            shutil.rmtree(target, ignore_errors=True)
        shutil.copytree(source, target)
    else:
        raise RuntimeError('Directory not found: ' + source)


# NeXus - Neutron and X-ray Common Data Format
# 
# Copyright (C) 2008-2020 NeXus International Advisory Committee (NIAC)
# 
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 3 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
#
# For further information, see http://www.nexusformat.org


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/utils/nxdl2rst.py
#!/usr/bin/env python

# Tested under both python2 and python3.

'''
Read the NeXus NXDL class specification and describe it.
Write a restructured text (.rst) document for use in the NeXus manual in
the NeXus NXDL Classes chapter.
'''

# testing:  see file dev_nxdl2rst.py

from __future__ import print_function
import os, sys, re
from collections import OrderedDict
import lxml.etree
from six.moves import html_parser as HTMLParser
from local_utilities import printf, replicate


INDENTATION_UNIT = '  '
listing_category = None


def fmtTyp( node ):
    typ = node.get('type', ':ref:`NX_CHAR <NX_CHAR>`') # per default
    if typ.startswith('NX_'):
        typ = ':ref:`%s <%s>`' % (typ, typ)
    return typ


def fmtUnits( node ):
    units = node.get('units', '')
    if not units:
        return ''
    if units.startswith('NX_'):
        units = '\ :ref:`%s <%s>`' % (units, units)
    return ' {units=%s}' % units


def getDocBlocks( ns, node ):
    docnodes = node.xpath('nx:doc', namespaces=ns)
    if docnodes is None or len(docnodes)==0:
        return ''
    if len(docnodes) > 1:
        raise Exception( 'Too many doc elements: line %d, %s' %
                         (node.sourceline, os.path.split(node.base)[1]) )
    docnode = docnodes[0]

    # be sure to grab _all_ content in the documentation
    # it might look like XML
    s = lxml.etree.tostring(docnode, pretty_print=True,
                            method='c14n', with_comments=False).decode('utf-8')
    m = re.search(r'^<doc[^>]*>\n?(.*)\n?</doc>$', s, re.DOTALL )
    if not m:
        raise Exception( 'unexpected docstring [%s] ' % s )
    text = m.group(1)

    # substitute HTML entities in markup: "<" for "&lt;"
    # thanks: http://stackoverflow.com/questions/2087370/decode-html-entities-in-python-string
    htmlparser = HTMLParser.HTMLParser()
    try:		# see #661
        import html
        text = html.unescape(text)
    except (ImportError, AttributeError):
        text = htmlparser.unescape(text)

    # Blocks are separated by whitelines
    blocks = re.split( '\n\s*\n', text )
    if len(blocks)==1 and len(blocks[0].splitlines())==1:
        return [ blocks[0].rstrip().lstrip() ]

    # Indentation must be given by first line
    m = re.match(r'(\s*)(\S+)', blocks[0])
    if not m:
        return [ '' ]
    indent = m.group(1)

    # Remove common indentation as determined from first line
    if indent=="":
        raise Exception( 'Missing initial indentation in <doc> of %s [%s]' %
                         ( node.get('name'), blocks[0] ) )

    out_blocks = []
    for block in blocks:
        lines = block.rstrip().splitlines()
        out_lines = []
        for line in lines:
            if line[:len(indent)]!=indent:
                raise Exception( 'Bad indentation in <doc> of %s [%s]: expected "%s" found "%s".' %
                                 ( node.get('name'), block,
                                   re.sub(r'\t',"\\\\t", indent ),
                                   re.sub(r'\t',"\\\\t", line ),
                            ) )
            out_lines.append( line[len(indent):] )
        out_blocks.append( "\n".join(out_lines) )
    return out_blocks


def getDocLine( ns, node ):
    blocks = getDocBlocks( ns, node )
    if len(blocks)==0:
        return ''
    if len(blocks)>1:
        raise Exception( 'Unexpected multi-paragraph doc [%s]' %
                         '|'.join(blocks) )
    return re.sub(r'\n', " ", blocks[0])


def get_minOccurs(node, use_application_defaults):
    '''
    get the value for the ``minOccurs`` attribute
    
    :param obj node: instance of lxml.etree._Element
    :param bool use_application_defaults: use special case value
    :returns str: value of the attribute (or its default)
    '''
    # TODO: can we improve on the default by exmaining nxdl.xsd?
    minOccurs_default = {True: '1', False: '0'}[use_application_defaults]
    minOccurs = node.get('minOccurs', minOccurs_default)
    return minOccurs


def get_required_or_optional_text(node, use_application_defaults):
    '''
    make clear if a reported item is required or optional
    
    :param obj node: instance of lxml.etree._Element
    :param bool use_application_defaults: use special case value
    :returns: formatted text
    '''
    tag = node.tag.split('}')[-1]
    nm = node.get('name')
    if tag in ('field', 'group'):
        optional_default = not use_application_defaults
        optional = node.get('optional', optional_default) in (True, 'true', '1', 1)
        recommended = node.get('recommended', None) in (True, 'true', '1', 1)
        minOccurs = get_minOccurs(node, use_application_defaults)
        if minOccurs in ('0', 0) or optional:
            optional_text = '(optional) '
        elif recommended:
            optional_text = '(recommended) '
        elif minOccurs in ('1', 1):
            optional_text = '(required) '
        else:
            # this is unexpected and remarkable
            # TODO: add a remark to the log
            optional_text = '(``minOccurs=%s``) ' % str(minOccurs)
    elif tag in ('attribute',):
        optional_default = not use_application_defaults
        optional = node.get('optional', optional_default) in (True, 'true', '1', 1)
        recommended = node.get('recommended', None) in (True, 'true', '1', 1)
        optional_text = {True: '(optional) ', False: '(required) '}[optional]
        if recommended:
            optional_text = '(recommended) '
    else:
        optional_text = '(unknown tag: ' + str(tag) + ') '
    return optional_text


def analyzeDimensions( ns, parent ):
    node_list = parent.xpath('nx:dimensions', namespaces=ns)
    if len(node_list) != 1:
        return ''
    node = node_list[0]
    # rank = node.get('rank') # ignore this
    node_list = node.xpath('nx:dim', namespaces=ns)
    dims = []
    for subnode in node_list:
        value = subnode.get('value')
        if not value:
            value = 'ref(%s)' % subnode.get('ref')
        dims.append( value )
    return '[%s]' % ( ', '.join(dims) )


def printEnumeration( indent, ns, parent ):
    node_list = parent.xpath('nx:item', namespaces=ns)
    if len(node_list) == 0:
        return ''

    if len(node_list) == 1:
        printf( '%sObligatory value: ' % ( indent ) )
    else:
        printf( '%sAny of these values:' % ( indent ) )

    docs = OrderedDict()
    for item in node_list:
        name = item.get('value')
        docs[name] = getDocLine(ns, item)

    ENUMERATION_INLINE_LENGTH = 60
    def show_as_typed_text(msg):
        return '``%s``' % msg
    oneliner = ' | '.join( map(show_as_typed_text, docs.keys()) )
    if ( any( doc for doc in docs.values() ) or
         len( oneliner ) > ENUMERATION_INLINE_LENGTH ):
        # print one item per line
        print('\n')
        for name, doc in docs.items():
            printf( '%s  * %s' % ( indent, show_as_typed_text(name) ) )
            if doc:
                printf( ': %s' % ( doc ) )
            print('\n')
    else:
        # print all items in one line
        print(' %s' % ( oneliner ) )
    print('')


def printDoc( indent, ns, node, required=False):
    blocks = getDocBlocks(ns, node)
    if len(blocks)==0:
        if required:
            raise Exception( 'No documentation for: ' + node.get('name') )
        print('')
    else:
        for block in blocks:
            for line in block.splitlines():
                print( '%s%s' % ( indent, line ) )
            print()


def printAttribute( ns, kind, node, optional, indent ):
    name = node.get('name')
    index_name = name
    print( '%s.. index:: %s (%s attribute)\n' %
           ( indent, index_name, kind ) )
    print( '%s**@%s**: %s%s%s\n' % (
        indent, name, optional, fmtTyp(node), fmtUnits(node) ) )
    printDoc(indent+INDENTATION_UNIT, ns, node)
    node_list = node.xpath('nx:enumeration', namespaces=ns)
    if len(node_list) == 1:
        printEnumeration( indent+INDENTATION_UNIT, ns, node_list[0] )


def printIfDeprecated( ns, node, indent ):
    deprecated = node.get('deprecated', None)
    if deprecated is not None:
        print( '\n%s.. index:: deprecated\n' % indent)
        fmt = '\n%s**DEPRECATED**: %s\n'
        print( fmt % (indent, deprecated ) )


def printFullTree(ns, parent, name, indent):
    '''
    recursively print the full tree structure

    :param dict ns: dictionary of namespaces for use in XPath expressions
    :param lxml_element_node parent: parent node to be documented
    :param str name: name of elements, such as NXentry/NXuser
    :param indent: to keep track of indentation level
    '''
    global listing_category

    use_application_defaults = listing_category in (
        'application definition', 
        'contributed definition')

    for node in parent.xpath('nx:field', namespaces=ns):
        name = node.get('name')
        index_name = name
        dims = analyzeDimensions(ns, node)

        optional_text = get_required_or_optional_text(node, use_application_defaults)
        print( '%s.. index:: %s (field)\n' %
               ( indent, index_name ) )
        print(
            '%s**%s%s**: %s%s%s\n' % (
                indent, name, dims, optional_text, fmtTyp(node), fmtUnits(node)
                ))

        printIfDeprecated( ns, node, indent+INDENTATION_UNIT )
        printDoc(indent+INDENTATION_UNIT, ns, node)

        node_list = node.xpath('nx:enumeration', namespaces=ns)
        if len(node_list) == 1:
            printEnumeration( indent+INDENTATION_UNIT, ns, node_list[0] )

        for subnode in node.xpath('nx:attribute', namespaces=ns):
            optional = get_required_or_optional_text(subnode, use_application_defaults)
            printAttribute( ns, 'field', subnode, optional, indent+INDENTATION_UNIT )

    for node in parent.xpath('nx:group', namespaces=ns):
        name = node.get('name', '')
        typ = node.get('type', 'untyped (this is an error; please report)')

        optional_text = get_required_or_optional_text(node, use_application_defaults)
        if typ.startswith('NX'):
            if name == '':
                name = typ.lstrip('NX').upper()
            typ = ':ref:`%s`' % typ
        print( '%s**%s**: %s%s\n' % (indent, name, optional_text, typ ) )

        printIfDeprecated(ns, node, indent+INDENTATION_UNIT)
        printDoc(indent+INDENTATION_UNIT, ns, node)

        for subnode in node.xpath('nx:attribute', namespaces=ns):
            optional = get_required_or_optional_text(subnode, use_application_defaults)
            printAttribute( ns, 'group', subnode, optional, indent+INDENTATION_UNIT )

        nodename = '%s/%s' % (name, node.get('type'))
        printFullTree(ns, node, nodename, indent+INDENTATION_UNIT)

    for node in parent.xpath('nx:link', namespaces=ns):
        print( '%s**%s** --> %s\n' % (
            indent, node.get('name'), node.get('target') ) )
        printDoc(indent+INDENTATION_UNIT, ns, node)


def print_rst_from_nxdl(nxdl_file):
    '''
    print restructured text from the named .nxdl.xml file
    '''
    global listing_category
    # parse input file into tree
    tree = lxml.etree.parse(nxdl_file)

    # The following URL is outdated, but that doesn't matter;
    # it won't be accessed; it's just an arbitrary namespace name.
    # It only needs to match the xmlns attribute in the NXDL files.
    NAMESPACE = 'http://definition.nexusformat.org/nxdl/3.1'
    ns = {'nx': NAMESPACE}

    root = tree.getroot()
    name = root.get('name')
    title = name
    if len(name)<2 or name[0:2]!='NX':
        raise Exception( 'Unexpected class name "%s"; does not start with NX' %
                         ( name ) )
    lexical_name = name[2:] # without padding 'NX', for indexing

    # retrieve category from directory
    #subdir = os.path.split(os.path.split(tree.docinfo.URL)[0])[1]
    subdir = root.attrib["category"]
    # TODO: check for consistency with root.get('category')
    listing_category = {
                 'base': 'base class',
                 'application': 'application definition',
                 'contributed': 'contributed definition',
                 }[subdir]

    use_application_defaults = listing_category in (
        'application definition', 
        'contributed definition')

    # print ReST comments and section header
    print( '.. auto-generated by script %s from the NXDL source %s' %
           (sys.argv[0], sys.argv[1]) )
    print('')
    print( '.. index::' )
    print( '    ! %s (%s)' % (name,listing_category) )
    print( '    ! %s (%s)' % (lexical_name,listing_category) )
    print( '    see: %s (%s); %s' %
           (lexical_name,listing_category, name) )
    print('')
    print( '.. _%s:\n' % name )
    print( '='*len(title) )
    print( title )
    print( '='*len(title) )

    # print category & parent class
    extends = root.get('extends')
    if extends is None:
        extends = 'none'
    else:
        extends = ':ref:`%s`' % extends

    print('')
    print( '**Status**:\n' )
    print( '  %s, extends %s' %
           ( listing_category.strip(),
             extends ) )

    printIfDeprecated(ns, root, '')

    # print official description of this class
    print('')
    print( '**Description**:\n' )
    printDoc(INDENTATION_UNIT, ns, root, required=True)


    # print symbol list
    node_list = root.xpath('nx:symbols', namespaces=ns)
    print( '**Symbols**:\n' )
    if len(node_list) == 0:
        print( '  No symbol table\n' )
    elif len(node_list) > 1:
        raise Exception( 'Invalid symbol table in ' % root.get('name') )
    else:
        printDoc( INDENTATION_UNIT, ns, node_list[0] )
        for node in node_list[0].xpath('nx:symbol', namespaces=ns):
            doc = getDocLine(ns, node)
            printf( '  **%s**' % node.get('name') )
            if doc:
                printf( ': %s' % doc )
            print('\n')

    # print group references
    print( '**Groups cited**:' )
    node_list = root.xpath('//nx:group', namespaces=ns)
    groups = []
    for node in node_list:
        g = node.get('type')
        if g.startswith('NX') and g not in groups:
            groups.append(g)
    if len(groups) == 0:
        print( '  none\n' )
    else:
        out = [ (':ref:`%s`' % g) for g in groups ]
        txt = ', '.join(sorted(out))
        print( '  %s\n' % ( txt ) )
        out = [ ('%s (base class); used in %s' % (g, listing_category)) for g in groups ]
        txt = ', '.join(out)
        print( '.. index:: %s\n' % ( txt ) )


    # TODO: change instances of \t to proper indentation
    html_root = 'https://github.com/nexusformat/definitions/blob/master'

    # print full tree
    print( '**Structure**:\n' )
    for subnode in root.xpath('nx:attribute', namespaces=ns):
        optional = get_required_or_optional_text(subnode, use_application_defaults)
        printAttribute( ns, 'file', subnode, optional, INDENTATION_UNIT )
    printFullTree(ns, root, name, INDENTATION_UNIT)

    # print NXDL source location
    subdir_map = {
                  'base': 'base_classes',
                  'application': 'applications',
                  'contributed': 'contributed_definitions',
                  }
    print( '**NXDL Source**:' )
    print( '  %s/%s/%s.nxdl.xml' % (
        html_root, subdir_map[subdir], name) )


def main():
    '''
    standard command-line processing
    '''
    import argparse
    parser = argparse.ArgumentParser(description='test nxdl2rst code')
    parser.add_argument('nxdl_file', help='name of NXDL file')
    results = parser.parse_args()
    nxdl_file = results.nxdl_file

    if not os.path.exists(nxdl_file):
        print( 'Cannot find %s' % nxdl_file )
        exit()

    print_rst_from_nxdl(nxdl_file)

    # if the NXDL has a subdirectory,
    # copy that subdirectory (quietly) to the pwd, such as:
    #  contributed/NXcanSAS.nxdl.xml: cp -a contributed/canSAS ./
    category = os.path.basename(os.getcwd())
    path = os.path.join('../../../../', category)
    basename = os.path.basename(nxdl_file)
    corename = basename[2:].split('.')[0]
    source = os.path.join(path, corename)
    if os.path.exists(source):
        target = os.path.join('.', corename)
        replicate(source, target)


if __name__ == '__main__':
    main()


# NeXus - Neutron and X-ray Common Data Format
# 
# Copyright (C) 2008-2020 NeXus International Advisory Committee (NIAC)
# 
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 3 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
#
# For further information, see http://www.nexusformat.org


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/utils/nxdl_desc2rst.py
#!/usr/bin/env python

'''
Read the NXDL field types specification and find
all the valid data types.  Write a restructured
text (.rst) document for use in the NeXus manual in 
the NXDL chapter.
'''


import os, sys
import lxml.etree


TITLE_MARKERS = '- + ~ ^ * @'.split()  # used for underscoring section titles
INDENTATION = ' '*4


ELEMENT_DICT = {
                'attribute': '''
An ``attribute`` element can *only* be a child of a 
``field`` or ``group`` element.
It is used to define *attribute* elements to be used and their data types
and possibly an enumeration of allowed values.

For more details, see: 
:ref:`NXDL.data.type.attributeType`
                ''',
                
                'definition': '''
A ``definition`` element can *only* be used
at the root level of an NXDL specification.
Note:  Due to the large number of attributes of the ``definition`` element,
they have been omitted from the figure below.

For more details, see: 
:ref:`NXDL.data.type.definition`,
:ref:`NXDL.data.type.definitionType`, and
:ref:`NXDL.data.type.definitionTypeAttr`
                ''',
                
                'dimensions': '''
The ``dimensions`` element describes the *shape* of an array.
It is used *only* as a child of a ``field`` element.

For more details, see: 
:ref:`NXDL.data.type.dimensionsType`
                ''',
                
                'doc': '''
A ``doc`` element can be a child of most NXDL elements.  In most cases, the
content of the ``doc`` element will also become part of the NeXus manual.

:element: {any}:

In documentation, it may be useful to
use an element that is not directly specified by the NXDL language. 
The *any* element here says that one can use any element
at all in a ``doc`` element and NXDL will not process it but pass it through.

For more details, see: 
:ref:`NXDL.data.type.docType`
                ''',
                
                'enumeration': '''
An ``enumeration`` element can *only* be a child of a 
``field`` or ``attribute`` element.
It is used to restrict the available choices to a predefined list,
such as to control varieties in spelling of a controversial word (such as
*metre* vs. *meter*).

For more details, see: 
:ref:`NXDL.data.type.enumerationType`
                ''',
                
                'field': '''
The ``field`` element provides the value of a named item.  Many different attributes
are available to further define the ``field``.  Some of the attributes are not
allowed to be used together (such as ``axes`` and ``axis``); see the documentation
of each for details.
It is used *only* as a child of a ``group`` element.

For more details, see: 
:ref:`NXDL.data.type.fieldType`
                ''',
                
                'choice': '''
A ``choice`` element is used when a named group might take one
of several possible NeXus base classes.  Logically, it must
have at least two group children.

For more details, see: 
:ref:`NXDL.data.type.choiceType`
                ''',
                
                'group': '''
A ``group`` element can *only* be a child of a 
``definition`` or ``group`` element.
It describes a common level of organization in a NeXus data file, similar
to a subdirectory in a file directory tree.

For more details, see: 
:ref:`NXDL.data.type.groupType`
                ''',
                
                'link': '''
.. index:: 
    single: link target

A ``link`` element can *only* be a child of a 
``definition``,
``field``, or ``group`` element.
It describes the path to the original source of the parent
``definition``,
``field``, or ``group``.

For more details, see: 
:ref:`NXDL.data.type.linkType`
                ''',
                
                'symbols': '''
A ``symbols`` element can *only* be a child of a ``definition`` element.
It defines the array index symbols to be used when defining arrays as
``field`` elements with common dimensions and lengths.

For more details, see: 
:ref:`NXDL.data.type.symbolsType`
                ''',
                }

DATATYPE_DICT = {
                 'basicComponent': '''/xs:schema//xs:complexType[@name='basicComponent']''',
                 'validItemName': '''/xs:schema//xs:simpleType[@name='validItemName']''',
                 'validNXClassName': '''/xs:schema//xs:simpleType[@name='validNXClassName']''',
                 'validTargetName': '''/xs:schema//xs:simpleType[@name='validTargetName']''',
                 'nonNegativeUnbounded': '''/xs:schema//xs:simpleType[@name='nonNegativeUnbounded']''',
                 }

ELEMENT_PREAMBLE = '''
=============================
NXDL Elements and Field Types
=============================

The documentation in this section has been obtained directly 
from the NXDL Schema file:  *nxdl.xsd*.
First, the basic elements are defined in alphabetical order.  
Attributes to an element are indicated immediately following the element
and are preceded with an "@" symbol, such as
**@attribute**.
Then, the common data types used within the NXDL specification are defined.
Pay particular attention to the rules for *validItemName*
and  *validNXClassName*.

..
    2010-11-29,PRJ:
    This contains a lot of special case code to lay out the NXDL chapter.
    It could be cleaner but that would also involve some cooperation on 
    anyone who edits nxdl.xsd which is sure to break.  The special case ensures
    the parts come out in the chosen order.  BUT, it is possible that new
    items in nxdl.xsd will not automatically go in the manual.
    Can this be streamlined with some common methods?
    Also, there is probably too much documentation in nxdl.xsd.  Obscures the function.

.. index::
    see: attribute; NXDL attribute
    ! single: NXDL elements

.. _NXDL.elements:

NXDL Elements
=============

    '''

DATATYPE_PREAMBLE = '''

.. _NXDL.data.types.internal:

NXDL Field Types (internal)
===========================

Field types that define the NXDL language are described here.
These data types are defined in the XSD Schema (``nxdl.xsd``)
and are used in various parts of the Schema to define common structures
or to simplify a complicated entry.  While the data types are not intended for
use in NXDL specifications, they define structures that may be used in NXDL specifications. 

'''

DATATYPE_POSTAMBLE = '''
**The** ``xs:string`` **data type**
    The ``xs:string`` data type can contain characters, 
    line feeds, carriage returns, and tab characters.
    See https://www.w3schools.com/xml/schema_dtypes_string.asp 
    for more details.

**The** ``xs:token`` **data type**
    The ``xs:string`` data type is derived from the 
    ``xs:string`` data type.

    The ``xs:token`` data type also contains characters, 
    but the XML processor will remove line feeds, carriage returns, tabs, 
    leading and trailing spaces, and multiple spaces.
    See https://www.w3schools.com/xml/schema_dtypes_string.asp 
    for more details.
'''


def _tagMatch(ns, parent, match_list):
    '''match this tag to a list'''
    if parent is None:
        raise "Must supply a valid parent node"
    parent_tag = parent.tag
    tag_found = False
    for item in match_list:
        # this routine only handles certain XML Schema components
        tag_found = parent_tag == '{%s}%s' % (ns['xs'], item)
        if tag_found:
            break
    return tag_found


def _indent(indentLevel):
    return INDENTATION*indentLevel


def printTitle(title, indentLevel):
    print(title)
    print(TITLE_MARKERS[indentLevel]*len(title) + '\n')


def generalHandler(ns, parent=None, indentLevel=0):
    '''Handle XML nodes like the former XSLT template'''
    # ignore things we don't know how to handle
    known_tags = ('complexType', 'simpleType', 'group', 'element', 'attribute')
    if not _tagMatch(ns, parent, known_tags):
        return
    
    parent_name = parent.get('name')
    if parent_name is None:
        return
    
    simple_tag = parent.tag[parent.tag.find('}')+1:]    # cut off the namespace identifier
    
    # <varlistentry> ...
    name = parent_name  # + ' data type'
    if simple_tag == 'attribute':
        name = '@' + name
    
    if indentLevel == 0 and not simple_tag in ('attribute'):
        print('.. index:: ! %s (NXDL data type)\n' % name)
        print('\n.. _%s:\n' % ('NXDL.data.type.'+name))

    printTitle(name, indentLevel)
    
    printDocs(ns, parent, indentLevel)
    
    if len(parent.xpath('xs:attribute', namespaces=ns)) > 0:
        printTitle("Attributes of "+name, indentLevel+1)
        applyTemplates(ns, parent, 'xs:attribute', indentLevel+1)

    node_list = parent.xpath('xs:restriction', namespaces=ns)
    if len(node_list) > 0:
        #printTitle("Restrictions of "+name, indentLevel+1)
        restrictionHandler(ns, node_list[0], indentLevel+1)
    node_list = parent.xpath('xs:simpleType/xs:restriction/xs:enumeration', namespaces=ns)
    if len(node_list) > 0:
#        printTitle("Enumerations of "+name, indentLevel+1)
        applyTemplates(ns, parent, 'xs:simpleType/xs:restriction', 
                       indentLevel+1, handler=restrictionHandler)
    
    if len(parent.xpath('xs:sequence/xs:element', namespaces=ns)) > 0:
        printTitle("Elements of "+name, indentLevel+1)
        applyTemplates(ns, parent, 'xs:sequence/xs:element', indentLevel+1)
    
    node_list = parent.xpath('xs:sequence/xs:group', namespaces=ns)
    if len(node_list) > 0:
        printTitle("Groups under "+name, indentLevel+1)
        printDocs(ns, node_list[0], indentLevel+1)

    applyTemplates(ns, parent, 'xs:simpleType', indentLevel+1)
    applyTemplates(ns, parent, 'xs:complexType', indentLevel+1)
    applyTemplates(ns, parent, 'xs:complexType/xs:attribute', indentLevel+1)
    applyTemplates(ns, parent, 'xs:complexContent/xs:extension/xs:attribute', indentLevel+1)
    applyTemplates(ns, parent, 'xs:complexType/xs:sequence/xs:attribute', indentLevel+1)
    applyTemplates(ns, parent, 'xs:complexType/xs:sequence/xs:element', indentLevel+1)
    applyTemplates(ns, parent, 'xs:complexContent/xs:extension/xs:sequence/xs:element', indentLevel+1)


def restrictionHandler(ns, parent=None, indentLevel=0):
    '''Handle XSD restriction nodes like the former XSLT template'''
    if not _tagMatch(ns, parent, ('restriction',)):
        return
    printDocs(ns, parent, indentLevel)
    print('\n')
    print(_indent(indentLevel) + 'The value may be any')
    base = parent.get('base')
    pattern_nodes = parent.xpath('xs:pattern', namespaces=ns)
    enumeration_nodes = parent.xpath('xs:enumeration', namespaces=ns)
    if len(pattern_nodes) > 0:
        print(_indent(indentLevel) + '``%s``' % base + ' that *also* matches the regular expression::\n')
        print(_indent(indentLevel) + ' '*4 + pattern_nodes[0].get('value'))
    elif len(pattern_nodes) > 0:
        # how will this be reached?  Perhaps a deprecated procedure
        print(_indent(indentLevel) + '``%s``' % base + ' from this list:')
        for node in enumeration_nodes:
            enumerationHandler(ns, node, indentLevel)
            printDocs(ns, node, indentLevel)
        print(_indent(indentLevel))
    elif len(enumeration_nodes) > 0:
        print(_indent(indentLevel) + 'one from this list only:\n')
        for node in enumeration_nodes:
            enumerationHandler(ns, node, indentLevel)
            printDocs(ns, parent, indentLevel)
        print(_indent(indentLevel))
    else:
        print('@' + base)
    print('\n')


def enumerationHandler(ns, parent=None, indentLevel=0):
    '''Handle XSD enumeration nodes like the former XSLT template'''
    if not _tagMatch(ns, parent, ['enumeration']):
        return
    print(_indent(indentLevel) + '* ``%s``' % parent.get('value'))
    printDocs(ns, parent, indentLevel)


def applyTemplates(ns, parent, path, indentLevel, handler=generalHandler):
    '''iterate the nodes found on the supplied XPath expression'''
    db = {}
    for node in parent.xpath(path, namespaces=ns):
        name = node.get('name') or node.get('ref') or node.get('value')
        if name is not None:
            if name in ('nx:groupGroup',):
                print(">"*45, name)
            if name in db:
                raise "Duplicate name found: " + name
            db[name] = node
    for name in sorted(db):
        node = db[name]
        handler(ns, node, indentLevel)
        #printDocs(ns, node, indentLevel)


def printDocs(ns, parent, indentLevel=0):
    docs = getDocFromNode(ns, parent)
    if docs is not None:
        print(_indent(indentLevel) + '\n')
        for line in docs.splitlines():
            print(_indent(indentLevel) + line)
        print(_indent(indentLevel) + '\n')


def getDocFromNode(ns, node, retval=None):
    docnodes = node.xpath('xs:annotation/xs:documentation', namespaces=ns)
    if docnodes == None:
        return retval
    if not len(docnodes) == 1:
        return retval
    
    # be sure to grab _all_ content in the documentation
    # it might look like XML
    s = lxml.etree.tostring(docnodes[0], pretty_print=True)
    p1 = s.decode().find('>')+1
    p2 = s.decode().rfind('</')
    text = s[p1:p2].decode().lstrip('\n')    # cut off the enclosing tag
    
    lines = text.splitlines()
    if len(lines) > 1:
        indent0 = len(lines[0]) - len(lines[0].lstrip())
        indent1 = len(lines[1]) - len(lines[1].lstrip())
        if len(lines) > 2:
            indent2 = len(lines[2]) - len(lines[2].lstrip())
        else:
            indent2 = 0
        if indent0 == 0:
            indent = max(indent1, indent2)
            text = lines[0]
        else:
            indent = indent0
            text = lines[0][indent:]
        for line in lines[1:]:
            if not len(line[:indent].strip()) == 0:
                raise "Something wrong with indentation on this line:\n" + line
            text += '\n' + line[indent:]

    # substitute HTML entities in markup: "<" for "&lt;"
    # thanks: http://stackoverflow.com/questions/2087370/decode-html-entities-in-python-string
    try:		# see #661
        import html
        text = html.unescape(text)
    except (ImportError, AttributeError):
        from six.moves import html_parser as HTMLParser
        htmlparser = HTMLParser.HTMLParser()
        text = htmlparser.unescape(text)

    return text.lstrip()


def addFigure(name, indentLevel=0):
    fmt = '''
.. compound::

    .. _%s:

    .. figure:: %s
        :alt: fig.nxdl/nxdl_%s
        :width: %s

        Graphical representation of the NXDL ``%s`` element

    .. Images of NXDL structure are generated from nxdl.xsd source
        using the oXygen XML Editor.  Open the nxdl.xsd file and choose the
        "Design" tab.  Identify the structure to be documented and expand
        as needed to show the detail.  Right click and select "Save as Image ..."
        Set the name: "nxdl_%s.jpg" and move the file into the correct location using
        your operating system's commands.  Commit the revision to version control.
    '''
    imageFile = 'img/nxdl/nxdl_%s.jpg' % name
    figure_id = 'fig.nxdl_%s' % name
    if not os.path.exists(os.path.abspath(imageFile)):
        return
    text = fmt % (figure_id, imageFile, name, '80%', name, name, )
    indent = _indent(indentLevel)
    for line in text.splitlines():
        print(indent + line)
    print('\n')


def pickNodesFromXpath(ns, parent, path):
    return parent.xpath(path, namespaces=ns)


def main(tree, ns):
    print(".. auto-generated by script: " + sys.argv[0])
    print(ELEMENT_PREAMBLE)

    for name in sorted(ELEMENT_DICT):
        print("")
        print('.. index:: ! %s (NXDL element)\n' % name)
        print('.. _%s:\n' % name)
        printTitle(name, indentLevel=0)
        print('\n')
        print(ELEMENT_DICT[name])
        print('\n')
        addFigure(name, indentLevel=0)
        

    print(DATATYPE_PREAMBLE)

    path_list = (
                 "/xs:schema/xs:complexType[@name='attributeType']",
                 "/xs:schema/xs:element[@name='definition']",
                 "/xs:schema/xs:complexType[@name='definitionType']",
                 "/xs:schema/xs:simpleType[@name='definitionTypeAttr']",
                 "/xs:schema/xs:complexType[@name='dimensionsType']",
                 "/xs:schema/xs:complexType[@name='docType']",
                 "/xs:schema/xs:complexType[@name='enumerationType']",
                 "/xs:schema/xs:complexType[@name='fieldType']",
                 "/xs:schema/xs:complexType[@name='choiceType']",
                 "/xs:schema/xs:complexType[@name='groupType']",
                 "/xs:schema/xs:complexType[@name='linkType']",
                 "/xs:schema/xs:complexType[@name='symbolsType']",
                 "/xs:schema/xs:complexType[@name='basicComponent']",
                 "/xs:schema/xs:simpleType[@name='validItemName']",
                 "/xs:schema/xs:simpleType[@name='validNXClassName']",
                 "/xs:schema/xs:simpleType[@name='validTargetName']",
                 "/xs:schema/xs:simpleType[@name='nonNegativeUnbounded']",
                 )
    for path in path_list:
        nodes = pickNodesFromXpath(ns, tree, path)
        print("\n.. Xpath = %s\n" % path)
        generalHandler(ns, parent=nodes[0])

    print(DATATYPE_POSTAMBLE)


if __name__ == '__main__':
    developermode = True
    developermode = False
    if developermode and len(sys.argv) != 2:
        NXDL_SCHEMA_FILE = os.path.join('..', 'nxdl.xsd')
    else:
        if len(sys.argv) != 2:
            print("usage: %s nxdl.xsd" % sys.argv[0])
            exit()
        NXDL_SCHEMA_FILE = sys.argv[1]
    if not os.path.exists(NXDL_SCHEMA_FILE):
        print("Cannot find %s" % NXDL_SCHEMA_FILE)
        exit()
        
    tree = lxml.etree.parse(NXDL_SCHEMA_FILE)
    NAMESPACE = 'http://www.w3.org/2001/XMLSchema'
    ns = {'xs': NAMESPACE}
    
    main(tree, ns)


# NeXus - Neutron and X-ray Common Data Format
# 
# Copyright (C) 2008-2020 NeXus International Advisory Committee (NIAC)
# 
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 3 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
#
# For further information, see http://www.nexusformat.org


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/utils/nxdl_summary.py
#!/usr/bin/env python

'''
Summarize the NXDL classes definitions for the given NXDL section.

Re-write the index.rst file with a list of: class  summary (and a hidden toctree)
'''


import os, sys
import lxml.etree


TITLE_MARKERS = '- + ~ ^ * @'.split()  # used for underscoring section titles
INDENTATION = ' '*4


NAMESPACE = 'http://definition.nexusformat.org/nxdl/3.1'
NS = {'nx': NAMESPACE}


PREAMBLES = {
    'base_classes': '''
.. index::
     ! see: class definitions; base class
     ! base class

.. _base.class.definitions:

Base Class Definitions
######################

A description of each NeXus base class definition is given.
NeXus base class definitions define the set of terms that
*might* be used in an instance of that class.
Consider the base classes as a set of *components*
that are used to construct a data file.
    ''',

    # - - - - - - - - - - - - - - - - - - - - - - - - - - - -

    'applications': '''
.. index::
     ! see: class definitions; application definition
     ! application definition

.. _application.definitions:

Application Definitions
#########################

A description of each NeXus application definition is given.
NeXus application definitions define the *minimum*
set of terms that
*must* be used in an instance of that class.
Application definitions also may define terms that
are optional in the NeXus data file.  The definition, in this case,
reserves the exact term by declaring its spelling and description.
Consider an application definition as a *contract*
between a data provider (such as the beam line control system) and a 
data consumer (such as a data analysis program for a scientific technique)
that describes the information is certain to be available in a data file.

Use NeXus links liberally in data files to reduce duplication of data.
In application definitions involving raw data,
write the raw data in the :ref:`NXinstrument` tree and then link to it
from the location(s) defined in the relevant application definition.
    ''',

    # - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    
    'contributed_definitions': '''
.. index::
     ! see: class definitions; contributed definition
     ! contributed definition

.. _contributed.definitions:

Contributed Definitions
#########################

A description of each NeXus contributed definition is given.
NXDL files in the NeXus contributed definitions include propositions from
the community for NeXus base classes or application definitions, as well
as other NXDL files for long-term archival by NeXus.  Consider the contributed
definitions as either in *incubation* or a special
case not for general use.  The :ref:`NIAC` is charged to review any new contributed 
definitions and provide feedback to the authors before ratification
and acceptance as either a base class or application definition.
    ''',
}


def getSummary(nxdl_file):
    '''
    get the summary line from each NXDL definition doc
    
    That's the first physical line of the doc string.
    '''
    tree = lxml.etree.parse(nxdl_file)
    root = tree.getroot()
    nodes = root.xpath('nx:doc', namespaces=NS)
    if len(nodes) != 1:
        raise RuntimeError('wrong number of <doc> nodes in NXDL: ' + nxdl_file)
    text = nodes[0].text
    return text.strip().splitlines()[0]


def command_args():
    '''get the command-line arguments, handle syntax errors'''
    import argparse
    doc = __doc__.strip().splitlines()[0]
    parser = argparse.ArgumentParser(prog=sys.argv[0], description=doc)
    parser.add_argument('section',
                        action='store', 
                        help="NXDL section (such as *base_classes*)")
    return parser.parse_args()


def main(section):
    if section not in PREAMBLES.keys():
        raise KeyError('unknown NXDL section: ' + section)
    base_path = os.path.abspath(os.path.dirname(__file__))
    nxdl_path = os.path.abspath(os.path.join(base_path, '..', section))
    if not os.path.exists(nxdl_path):
        raise IOError('not found: ' + nxdl_path)

    rst_path = os.path.abspath(os.path.join(base_path, '..', 'manual', 'source', 'classes', section))
    if not os.path.exists(rst_path):
        raise IOError('not found: ' + rst_path)

    index_file = os.path.join(rst_path, 'index.rst')

    classes = []
    text = []
    text.append('''
.. do NOT edit this file
   automatically generated by script ''' + __file__)
    text.append('')
    text.append(PREAMBLES[section])
    for fname in sorted(os.listdir(nxdl_path)):
        if fname.endswith('.nxdl.xml'):
            class_name = fname.split('.')[0]
            classes.append(class_name)
            summary = getSummary(os.path.join(nxdl_path, fname))
            text.append('')
            text.append(':ref:`' + class_name + '`')
            text.append(INDENTATION + summary)
    text.append('')
    text.append('.. toctree::')
    text.append(INDENTATION + ':hidden:')
    text.append('')
    for cname in sorted(classes):
        text.append(INDENTATION + cname)
    text.append('')
    open(index_file, 'w').writelines('\n'.join(text))


if __name__ == '__main__':
    cli = command_args()
    main(cli.section)


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/utils/test_nxdl.py
#!/bin/env python

'''
unit testing of NeXus definitions NXDL files and XML Schema
'''

import os
import sys
import unittest
import lxml.etree
from six import with_metaclass

# xmllint --noout --schema nxdl.xsd base_classes/NXentry.nxdl.xml 
# base_classes/NXentry.nxdl.xml validates


BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
NXDL_XSD_SCHEMA = 'nxdl.xsd'
NXDL_SCHEMA = lxml.etree.XMLSchema(
    lxml.etree.parse(
        os.path.join(BASE_DIR, NXDL_XSD_SCHEMA)))

NXDL_CATEGORY_NAMES = 'base_classes applications contributed_definitions'.split()


class NXDL_Invalid(Exception): pass
class NXDL_Valid(Exception): pass


def isNXDL(fname):
    return fname.endswith('.nxdl.xml')


def get_NXDL_file_list():
    os.chdir(BASE_DIR)
    file_list = []
    for category in NXDL_CATEGORY_NAMES:
        raw_list = os.listdir(category)
        nxdl_files = [os.path.join(category, fn) for fn in raw_list if isNXDL(fn)]
        file_list += sorted(nxdl_files)
    return file_list


def validate_xml(xml_file_name):
    '''
    validate an NXDL XML file against an XML Schema file

    :param str xml_file_name: name of XML file
    '''
    try:
        xml_tree = lxml.etree.parse(xml_file_name)
    except lxml.etree.XMLSyntaxError as exc:
        msg = xml_file_name + ' : ' + str(exc)
        raise NXDL_Invalid(msg)
    try:
        result = NXDL_SCHEMA.assertValid(xml_tree)
        # there is no assertNotRaises so raise this when successful
        raise NXDL_Valid
    except lxml.etree.DocumentInvalid as exc:
        msg = xml_file_name + ' : ' + str(exc)
        raise NXDL_Invalid(msg)


class TestMaker(type):
    
    def __new__(cls, clsname, bases, dct):
        # Add a method to the class' __dict__ for every 
        # file name in the NXDL file list.
        cat_number_dict = {c: str(i+1) for i, c in enumerate(NXDL_CATEGORY_NAMES)}
        for fname in get_NXDL_file_list():
            category, nxdl_name = os.path.split(fname)
            category_number = cat_number_dict[category]
            point = nxdl_name.find(".")
            nxdl_name = nxdl_name[:point]
            test_name = 'test'
            # since these will be sorted, get the categories in the desired order
            test_name += '__' + str(category_number)
            test_name += '__' + category
            test_name += '__' + nxdl_name
            dct[test_name] = cls.make_test(fname)

        return super(TestMaker, cls).__new__(cls, clsname, bases, dct)

    @staticmethod
    def make_test(nxdl_file_name):
        
        def test_wrap(self):
            # test body for each NXDL file test
            with self.assertRaises(NXDL_Valid):
                validate_xml(nxdl_file_name)
            self.assertRaises(NXDL_Valid, validate_xml, nxdl_file_name)
        return test_wrap


class Individual_NXDL_Tests(with_metaclass(TestMaker, unittest.TestCase)):
    '''
    run all tests created in TestMaker() class, called by suite()
    '''


def suite(*args, **kw):
    '''gather all the tests together in a suite, called by run()'''
    test_suite = unittest.TestSuite()
    test_suite.addTests(unittest.makeSuite(Individual_NXDL_Tests))
    return test_suite


def run():
    '''run all the unit tests'''
    runner=unittest.TextTestRunner(verbosity=2)
    runner.run(suite())


if __name__ == '__main__':
    run()


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/utils/test_nxdl2rst.py
#!/bin/env python

'''
unit testing: NXDL to RST for documentation
'''

import os
import sys
import unittest
import lxml.etree
from six import with_metaclass
from six import StringIO

import nxdl2rst


class Capture_stdout(list):
    '''
    capture all printed output (to stdout) into list
    
    # http://stackoverflow.com/questions/16571150/how-to-capture-stdout-output-from-a-python-function-call
    '''
    def __enter__(self):
        self._stdout = sys.stdout
        sys.stdout = self._stringio = StringIO()
        return self
    def __exit__(self, *args):
        self.extend(self._stringio.getvalue().splitlines())
        del self._stringio    # free up some memory
        sys.stdout = self._stdout


class Issue_524_Clarify_Optional_or_Required(unittest.TestCase):
    '''
    make it obvious what is required and what is optional
    
    **field**: (optional or required) NX_TYPE
    '''
        
    def test_base_class_NXentry(self):
        expected_lines = '''
        **definition**: (optional) :ref:`NX_CHAR <NX_CHAR>`
        **DATA**: (optional) :ref:`NXdata`
        **notes**: (optional) :ref:`NXnote`
        **@default**: (optional) :ref:`NX_CHAR <NX_CHAR>`
        '''.strip().splitlines()
        
        self.apply_tests('base_classes', 'NXentry', expected_lines)
        
    def test_base_class_NXuser(self):
        expected_lines = '''
        **name**: (optional) :ref:`NX_CHAR <NX_CHAR>`
        '''.strip().splitlines()
        
        self.apply_tests('base_classes', 'NXuser', expected_lines)
        
    def test_application_definition_NXcanSAS(self):
        expected_lines = '''
        **definition**: (required) :ref:`NX_CHAR <NX_CHAR>`
        **title**: (required) :ref:`NX_CHAR <NX_CHAR>`
        **run**: (required) :ref:`NX_CHAR <NX_CHAR>`
        **I**: (required) :ref:`NX_NUMBER <NX_NUMBER>`
        **Q**: (required) :ref:`NX_NUMBER <NX_NUMBER>` {units=\ :ref:`NX_PER_LENGTH <NX_PER_LENGTH>`}
        **Idev**: (optional) :ref:`NX_NUMBER <NX_NUMBER>`
        **dQw**: (optional) :ref:`NX_NUMBER <NX_NUMBER>` {units=\ :ref:`NX_PER_LENGTH <NX_PER_LENGTH>`}
        **dQl**: (optional) :ref:`NX_NUMBER <NX_NUMBER>` {units=\ :ref:`NX_PER_LENGTH <NX_PER_LENGTH>`}
        **ENTRY**: (required) :ref:`NXentry`
        **DATA**: (required) :ref:`NXdata`
        **DATA**: (optional) :ref:`NXdata`
        **SAMPLE**: (optional) :ref:`NXsample`
        **INSTRUMENT**: (optional) :ref:`NXinstrument`
        **NOTE**: (optional) :ref:`NXnote`
        **PROCESS**: (optional) :ref:`NXprocess`
        **SOURCE**: (optional) :ref:`NXsource`
        **@default**: (optional) :ref:`NX_CHAR <NX_CHAR>`
        **@timestamp**: (optional) :ref:`NX_DATE_TIME <NX_DATE_TIME>`
        **@canSAS_class**: (required) :ref:`NX_CHAR <NX_CHAR>`
        **@signal**: (required) :ref:`NX_CHAR <NX_CHAR>`
        **@I_axes**: (required) :ref:`NX_CHAR <NX_CHAR>`
        '''.strip().splitlines()
        
        self.apply_tests('applications', 'NXcanSAS', expected_lines)

    def apply_tests(self, category, class_name, expected_lines):
        nxdl_file = os.path.join(os.path.dirname(__file__),'..', category, class_name+'.nxdl.xml')
        self.assertTrue(os.path.exists(nxdl_file), nxdl_file)
        
        sys.argv.insert(0, 'python')
        with Capture_stdout() as printed_lines:
            nxdl2rst.print_rst_from_nxdl(nxdl_file)
        
        printed_lines = [_.strip() for _ in printed_lines]
        for line in expected_lines:
            expected = line.strip()
            self.assertTrue(expected in printed_lines, line.strip())


def suite(*args, **kw):
    '''gather all the tests together in a suite, called by run()'''
    test_suite = unittest.TestSuite()
    test_suite_list = [
        Issue_524_Clarify_Optional_or_Required,
    ]
    for item in test_suite_list:
        test_suite.addTests(unittest.makeSuite(item))
    return test_suite


def run():
    '''run all the unit tests'''
    runner=unittest.TextTestRunner(verbosity=2)
    runner.run(suite())


if __name__ == '__main__':
    run()


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/utils/test_suite.py
#!/usr/bin/env python

'''
unit testing of the NeXus definitions
'''

import os
import unittest
import sys


def suite(*args, **kw):
    import test_nxdl
    import test_nxdl2rst
    test_suite = unittest.TestSuite()
    test_list = [
        test_nxdl,
        test_nxdl2rst,
        ]

    for test in test_list:
        test_suite.addTest(test.suite())
    return test_suite


if __name__ == '__main__':
    owd = os.getcwd()
    runner=unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite())
    os.chdir(owd)
    sys.exit(len(result.errors))


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/utils/types2rst.py
#!/usr/bin/env python

'''
Read the the NeXus NXDL types specification and find
all the valid data types.  Write a restructured
text (.rst) document for use in the NeXus manual in 
the NXDL chapter.
'''


import units2rst


if __name__ == '__main__':
    units2rst.worker('primitiveType', section = 'data')


# NeXus - Neutron and X-ray Common Data Format
# 
# Copyright (C) 2008-2020 NeXus International Advisory Committee (NIAC)
# 
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 3 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
#
# For further information, see http://www.nexusformat.org


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/utils/units2rst.py
#!/usr/bin/env python

'''
Read the the NeXus NXDL types specification and find
all the valid types of units.  Write a restructured
text (.rst) document for use in the NeXus manual in 
the NXDL chapter.
'''


import os, sys
import lxml.etree


def worker(nodeMatchString, section = 'units'):
    if len(sys.argv) != 2:
        print("usage: %s nxdlTypes.xsd" % sys.argv[0])
        exit()
    NXDL_TYPES_FILE = sys.argv[1]
    if not os.path.exists(NXDL_TYPES_FILE):
        print("Cannot find %s" % NXDL_TYPES_FILE)
        exit()
        
    tree = lxml.etree.parse(NXDL_TYPES_FILE)
    
    output = ['.. auto-generated by %s -- DO NOT EDIT' % sys.argv[0]]
    output.append('')
    
    labels = ('term', 'description')
    output.append('.. nodeMatchString : %s' % nodeMatchString)
    output.append('')
    db = {}
    
    NAMESPACE = 'http://www.w3.org/2001/XMLSchema'
    ns = {'xs': NAMESPACE}
    root = tree.xpath('//xs:schema', namespaces=ns)[0]
    s = '//xs:simpleType'
    node_list = tree.xpath("//xs:simpleType", namespaces=ns)
    
    # get the names of all the types of units
    members = []
    for node in node_list:
        if node.get('name') == nodeMatchString:
            union = node.xpath('xs:union', namespaces=ns)
            members = union[0].get('memberTypes', '').split()
    
    # get the definition of each type of units
    for node in node_list:
        node_name = node.get('name')
        if 'nxdl:' + node_name in members:
            words = node.xpath('xs:annotation/xs:documentation', namespaces=ns)[0]
            examples = []
            for example in words.iterchildren():
                nm = example.attrib.get("name")
                if nm is not None and nm == "example":
                    examples.append("``"+example.text+"``")
            a = words.text
            if len(examples) > 0:
                a = a.strip() + ", example(s): " + " | ".join(examples)
            db[node_name] = a

#             for item in node.xpath('xs:restriction//xs:enumeration', namespaces=ns):
#                 key = '%s' % item.get('value')
#                 words = item.xpath('xs:annotation/xs:documentation', namespaces=ns)[0]
#                 db[key] = words.text
    
    print('\n'.join(output))
    
    # this list is too long to make this a table in latex
    # for two columns, a Sphinx fieldlist will do just as well
    for key in sorted(db):
        print('.. index:: ! %s (%s type)\n' % (key, section))       # index entry
        print('.. _%s:\n' % key)       # cross-reference point
        print(':%s:' % key)
        for line in db[key].splitlines():
            print('    %s' % line)
        print('')


if __name__ == '__main__':
    #sys.argv.append('../nxdlTypes.xsd')  # FIXME: developer only -- remove for production!!!
    worker('anyUnitsAttr')


# NeXus - Neutron and X-ray Common Data Format
# 
# Copyright (C) 2008-2020 NeXus International Advisory Committee (NIAC)
# 
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 3 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
#
# For further information, see http://www.nexusformat.org


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/definitions/utils/update_copyright_date.py
#!/usr/bin/env python

# Coded for both python2 and python3.

'''
update the copyright date in all NeXus text files

This is the bash command to find all matching lines::

  grep -iR copyright | grep -i "(c)" | grep -i nexus

See copyright text at bottom of this file for example.
'''

from __future__ import print_function
import os, sys
import mimetypes
import local_utilities
from build_preparation import ROOT_DIR_EXPECTED_RESOURCES
import datetime

YEAR = datetime.datetime.now().year
LEFT_SIDE_TEXT_MATCH = 'Copyright (C) '
RIGHT_SIDE_TEXT_MATCH = ' NeXus International Advisory Committee (NIAC)'


def update(filename):
    '''update the copyright year in the file'''
    def position(line, key):
        pos = line.find(key)
        if pos >= 0:
            if line.find('NIAC') >= 0:
                return pos
        return None
        
    if not os.path.exists(filename):
        return
    changes = []
    buf = open(filename).readlines()
    for number, line in enumerate(buf):
        pos = position(line, LEFT_SIDE_TEXT_MATCH)
        if pos is None:
            continue    # no match

        pos += len(LEFT_SIDE_TEXT_MATCH)
        text_l = line[:pos]

        text = line[pos:]
        pos = text.find(RIGHT_SIDE_TEXT_MATCH)
        text_r = text[pos:]

        try:
            years = list(map(int, text[:pos].split('-')))
            if len(years) in (1, 2):
                if len(years) == 1:
                    years.append(YEAR)
                elif len(years) == 2:
                    years[1] = YEAR
                line_new = text_l + '-'.join(map(str, years)) + text_r
                changes.append(list((number, line_new)))
        except Exception as _exc:
            print(number, filename, str(_exc))
    for number, line in changes:
        buf[number] = line
    if len(changes) > 0:
        print('Update: ', filename)
        fp = open(filename, 'w')
        fp.writelines(buf)
        fp.close()


def find_source_files(path):
    '''walk the source_path directories accumulating files to be checked'''
    file_list = []
    for root, dirs, files in os.walk(path):
        if root.find('/.git') < 0 or root.find('/kits') < 0:
            file_list = file_list + [os.path.join(root, _) for _ in files]
    return file_list


def sift_file_list(file_list):
    '''remove known non-text files and paths'''
    new_list = []
    acceptable_mime_types = '''
        application/xml
        application/x-msdos-program
        application/xslt+xml
    '''.strip().split()
    ignore_extensions = '''
    .dia .vsdx .h5 .nx .hdf5 .hdf .nx5 .pyc
    '''.strip().split()
    for fn in file_list:
        _fn = os.path.split(fn)[-1]
        mime = mimetypes.guess_type(fn)[0]
        if fn.find('/.git') >= 0:
            continue
        if fn.find('/.settings') >= 0:
            continue
        if fn.find('/kits') >= 0:
            continue
        if fn.find('/build') >= 0:
            continue
        if os.path.splitext(fn)[-1] in ignore_extensions:
            continue
        if mime is None or mime.startswith('text/') or mime in acceptable_mime_types:
            new_list.append(fn)
    return new_list


def is_definitions_directory(basedir):
    '''test if ``basedir`` is a NeXus definitions directory'''
    # look for the expected files and subdirectories in the root directory
    for item_list in ROOT_DIR_EXPECTED_RESOURCES.values():
        for item in item_list:
            if not os.path.exists(os.path.join(basedir, item)):
                return False
    return True


def qualify_inputs(root_dir):
    '''raise error if this program cannot continue, based on the inputs'''
    if not os.path.exists(root_dir):
        raise RuntimeError('Cannot find ' + root_dir)

    if not os.path.isdir(root_dir):
        raise RuntimeError('Not a directory: ' + root_dir)

    if not is_definitions_directory(root_dir):
        msg = 'Not a NeXus definitions root directory ' + root_dir
        raise RuntimeError(msg)


def command_args():
    '''get the command-line arguments, handle syntax errors'''
    import argparse
    doc = __doc__.strip().splitlines()[0]
    parser = argparse.ArgumentParser(prog=sys.argv[0], description=doc)
    parser.add_argument('defs_dir',
                        action='store', 
                        help="NeXus definitions root directory")
    return parser.parse_args()


def main():
    '''
    standard command-line processing
    
    source directory (NeXus definitions dir) named as command line argument
    target directory is specified (or defaults to present working directory)
    '''
    cli = command_args()
    root_dir = os.path.abspath(cli.defs_dir)
    qualify_inputs(root_dir)
    
    file_list = sift_file_list(find_source_files(root_dir))
    for fn in file_list:
        update(fn)


def __developer_build_setup__():
    '''for use with source-code debugger ONLY'''
    import shutil
    # sys.argv.append('-h')
    sys.argv.append('..')


if __name__ == '__main__':
    #__developer_build_setup__()
    main()


# NeXus - Neutron and X-ray Common Data Format
# 
# Copyright (C) 2008-2020 NeXus International Advisory Committee (NIAC)
# 
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 3 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
#
# For further information, see http://www.nexusformat.org


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/read_geom.py
from __future__ import division
import sys, os
from scitbx.matrix import col
from libtbx.phil import parse
from libtbx.utils import Sorry

help_str = """Converts a CrystFEL file to DIALS json format."""

phil_scope = parse(
    """
  geom_file = None
    .type = str
    .help = CrystFEL geometry file to convert
  show_plot = False
    .type = bool
    .help = plot of detector geometry
"""
)


class PanelGroup(dict):
    def __init__(self):
        self.center = None
        self.detector_distance = None  # in mm
        self.incident_wavelength = None  # in angstrom
        self.local_origin = None
        self.local_fast = col((1, 0, 0))
        self.local_slow = col((0, 1, 0))

    def setup_centers(self) -> None:
        if self.center is not None:  # the center is already defined
            return
        center = col((0.0, 0.0, 0.0))
        for key, child in self.items():
            if isinstance(child, PanelGroup):
                if child.center is None:
                    child.setup_centers()
                center += child.center
            else:
                center += child["center"]
        center /= len(self)
        self.center = center

    def setup_local_frames(self) -> None:
        for key, child in self.items():
            if isinstance(child, PanelGroup):
                child.local_origin = child.center - self.center
                child.setup_local_frames()
            else:
                child["local_origin"] = child["origin"] - self.center


def read_geom(geom_file: str) -> PanelGroup:
    """Function to read in the CrystFEL .geom file."""
    panels = {}
    rigid_groups = {}
    collections = {}

    def known_panels() -> set:
        all_keys = []
        for value in rigid_groups.values():
            all_keys.extend(value)
        for value in collections.values():
            all_keys.extend(value)
        return set(all_keys)

    pixel_size = None

    with open(geom_file) as geom:
        lines = geom.readlines()

    lines = (line.split(";")[0] for line in lines)  # cut out comments
    lines = (line for line in lines if len(line.split("=")) == 2)
    geometry = dict(map(lambda x: x.strip(), line.split("=")) for line in lines)  # noqa

    if "res" in geometry:
        pixel_size = 1000 / float(geometry.pop("res"))  # mm
    else:
        raise KeyError("Pixel size is not defined!")

    for key, value in geometry.items():
        if "rigid_group" in key:
            if "collection" in key:
                collections[key.split("rigid_group_collection_")[1]] = value.split(",")
            else:
                rigid_groups[key.split("rigid_group_")[1]] = value.split(",")
        else:
            if "/" not in key:
                continue
            panel = key.split("/")[0].strip()
            key = key.split("/")[1].strip()
            if panel not in known_panels():
                continue
            if panel not in panels:
                panels[panel] = {}
            panels[panel][key] = value

    mapping = {}
    for panel in panels:
        mapping[panel] = {}
        for group in rigid_groups:
            if panel not in rigid_groups[group]:
                continue
            for collection in collections:
                if group in collections[collection]:
                    mapping[panel][collection] = group, len(rigid_groups[group])
    # example of mapping entry: mapping['p0a0'] = {'asics': ('p0', 8), 'quadrants': ('q0', 32)}
    parents = {}
    for panel in panels:
        parents[panel] = [
            mapping[panel][k][0]
            for k in sorted(mapping[panel], key=lambda x: x[1], reverse=True)
        ]
    # example of parents entry:  parents['p0a0'] = ['q0', 'p0']
    # IE parents are listed in reverse order of immediacy (p0 is the parent of p0a0 and q0 is the parent of p0)

    hierarchy = PanelGroup()

    if "clen" in geometry:
        hierarchy.detector_distance = float(geometry.pop("clen")) * 1000
    if (
        "photon_energy" in geometry
    ):  # h * c / e = 1.23984198E-6 [SI] -- eV to angstrom which itself is [1E-10 SI]
        hierarchy.incident_wavelength = 1.23984198e4 / float(
            geometry.pop("photon_energy")
        )

    def add_node(panel, parent, parents, depth):
        if depth == len(parents):
            parent[panel] = panels[panel]
        else:
            if parents[depth] not in parent:
                parent[parents[depth]] = PanelGroup()
            add_node(panel, parent[parents[depth]], parents, depth + 1)

    for panel in panels:
        add_node(panel, hierarchy, parents[panel], 0)

    # example of a hierarchy entry:
    # hierarchy['q0']['p0']['p0a0'] = full panel dictionary

    def parse_vector(vector):
        try:
            x, y, z = vector.split(" ")
        except ValueError:
            x, y = vector.split(" ")
            return col((float(x.rstrip("x")), float(y.rstrip("y")), 0.0))
        else:
            return col(
                (float(x.rstrip("x")), float(y.rstrip("y")), float(z.rstrip("z")))
            )

    # set up panel vectors in lab space
    for panel in panels:
        panels[panel]["origin"] = col(
            (
                float(panels[panel]["corner_x"]) * pixel_size,
                float(panels[panel]["corner_y"]) * pixel_size,
                0.0,
            )
        )
        if "coffset" in panels[panel]:
            panels[panel]["origin"] += col(
                (0, 0, 1000 * float(panels[panel]["coffset"]))
            )
        panels[panel]["fast"] = panels[panel]["local_fast"] = parse_vector(
            panels[panel]["fs"]
        ).normalize()
        panels[panel]["slow"] = panels[panel]["local_slow"] = parse_vector(
            panels[panel]["ss"]
        ).normalize()
        center_fast = (
            panels[panel]["fast"]
            * pixel_size
            * (int(panels[panel]["max_fs"]) - int(panels[panel]["min_fs"]) + 1)
            / 2.0
        )
        center_slow = (
            panels[panel]["slow"]
            * pixel_size
            * (int(panels[panel]["max_ss"]) - int(panels[panel]["min_ss"]) + 1)
            / 2.0
        )
        panels[panel]["center"] = panels[panel]["origin"] + center_fast + center_slow
        panels[panel]["pixel_size"] = pixel_size

    assert "pixel_size" not in panels

    hierarchy.setup_centers()
    hierarchy.local_origin = hierarchy.center
    hierarchy.setup_local_frames()
    return hierarchy


def run(args):
    if "-h" in args or "--help" in args or "-c" in args:
        print(help_str)
        phil_scope.show(attributes_level=2)
        return

    user_phil = []
    for arg in args:
        if os.path.isfile(arg):
            user_phil.append(parse(file_name=arg))
        else:
            try:
                user_phil.append(parse(arg))
            except Exception as e:
                raise Sorry("Unrecognized argument: %s" % arg)
    params = phil_scope.fetch(sources=user_phil).extract()

    hierarchy = read_geom(params.geom_file)

    # Plot the detector model highlighting the hierarchical structure of the detector
    def plot_node(cummulative, node, name):
        if isinstance(node, PanelGroup):
            plt.arrow(
                cummulative[0],
                cummulative[1],
                node.local_origin[0],
                node.local_origin[1],
            )
            for childname, child in node.items():
                plot_node(cummulative + node.local_origin, child, childname)
        else:
            plt.arrow(
                cummulative[0],
                cummulative[1],
                node["local_origin"][0],
                node["local_origin"][1],
            )

            ori = node["origin"]
            fast_at_zero = (
                node["fast"]
                * node["pixel_size"]
                * (int(node["max_fs"]) - int(node["min_fs"]) + 1)
            )
            slow_at_zero = (
                node["slow"]
                * node["pixel_size"]
                * (int(node["max_ss"]) - int(node["min_ss"]) + 1)
            )
            plt.arrow(ori[0], ori[1], fast_at_zero[0], fast_at_zero[1], color="blue")
            plt.arrow(ori[0], ori[1], slow_at_zero[0], slow_at_zero[1], color="red")

            plt.text(ori[0], ori[1], name)

    if params.show_plot:
        from matplotlib import pyplot as plt

        plot_node(col((0, 0, 0)), hierarchy, "root")
        plt.xlim(-200, 200)
        plt.ylim(200, -200)

        plt.show()


if __name__ == "__main__":
    run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
xfel/euxfel/write_composite_image.py
from __future__ import absolute_import, division, print_function
from six.moves import range
import h5py, os, sys
import numpy as np
from libtbx.phil import parse
from xfel.euxfel.agipd_cxigeom2nexus import agipd_cxigeom2nexus

message = '''Program to calculate the maximum, mean and/or stdev image from an EU-XFEL run. Applicable only for the AGIPD detector. Needs a) cxi file b) what mode to use c) geometry file for generation of the master file d) detector distance (optional)'''

phil_scope = parse("""
  cxi_file = None
    .type = str
    .help = cheetah file used to read in image data (.cxi format)
  composite_mode = *max mean stdev
    .type = str
    .multiple = True
    .help = specify what statistical metric(s) should be used for output image
  geom_file = None
    .type = str
    .help = geometry file to be read in for AGIPD detector (.geom).
  detector_distance = None
    .type = float
    .help = AGIPD Detector distance
""")




class composite_image_writer(object):
  ''' class to write composite image'''
  def __init__(self, args):
    self.params_from_phil(args)
    n_frames = None

  def params_from_phil(self,args):
    user_phil = []
    for arg in args:
      if os.path.isfile(arg):
        user_phil.append(parse(file_name=arg))
      else:
        try:
          user_phil.append(parse(arg))
        except Exception as e:
          raise Sorry("Unrecognized argument: %s"%arg)
    self.params = phil_scope.fetch(sources=user_phil).extract()

  def copy_attributes(self,src, dest):
    for attr in src.attrs:
      dest.attrs[attr] = src.attrs[attr]

  def recursive_copy(self,src, dest, mode='max', n_frames=None):
    print(src, type(src))
    self.copy_attributes(src, dest)

    assert n_frames is not None, 'Need to provide n_frames'
    assert type(src) in [h5py._hl.group.Group, h5py._hl.files.File]
    for key in src:
      if type(src[key]) in [h5py._hl.group.Group, h5py._hl.files.File]:
        dest_child = dest.create_group(key)
        self.recursive_copy(src[key], dest_child,mode=mode,n_frames=n_frames)
      elif type(src[key]) is h5py._hl.dataset.Dataset:
        dataset = src[key]
        print(key, dataset.shape)
        if dataset.shape == (n_frames, 8192, 128):
          if dataset.name != "/entry_1/data_1/data":
            print("Skipping data block", dataset.name)
            continue
          print('=====================================')
          if mode == 'max':
            dmax = np.zeros((8192, 128))
            dmax[:] = -np.inf
            for i in range(n_frames):
              frame = dataset[i]
              dmax = np.maximum(dmax, frame)
            result = dmax.reshape(1 ,8192, 128)
          elif mode == 'mean':
            dsum = np.zeros((8192, 128))
            for i in range(n_frames):
              frame = dataset[i]
              dsum += frame
            result = (dsum/n_frames).reshape(1 ,8192, 128)
          elif mode == 'stdev':
            dsum = np.zeros((8192, 128))
            dsumsq = np.zeros((8192, 128))
            for i in range(n_frames):
              frame = dataset[i]
              dsum += frame
              dsumsq += frame*frame
            result = dsumsq - dsum*dsum
            result = np.sqrt(result)/n_frames

          new_dataset = dest.create_dataset(os.path.basename(dataset.name), data = result)
        else:
          new_dataset = dest.create_dataset(os.path.basename(dataset.name), data = dataset)
        self.copy_attributes(dataset, new_dataset)
      else:
        assert False, type(src)

if __name__ == '__main__':

  image_writer = composite_image_writer(sys.argv[1:])
  handle = h5py.File(image_writer.params.cxi_file, 'r')
  n_frames = len(handle['entry_1/instrument_1/detector_1/distance'])
  for mode in image_writer.params.composite_mode:
    outfile = os.path.splitext(image_writer.params.cxi_file)[0]+"_"+mode+".h5"
    output_handle = h5py.File(outfile, 'w')
    image_writer.recursive_copy(handle, output_handle,mode=mode,n_frames=n_frames)
    nexus_helper_str = ['cxi_file='+outfile] \
                     + ['geom_file='+image_writer.params.geom_file]
    if image_writer.params.detector_distance is not None:
      nexus_helper_str += ['detector_distance='+str(image_writer.params.detector_distance)]
    nexus_helper = agipd_cxigeom2nexus(nexus_helper_str)
    nexus_helper.create_nexus_master_file()


 *******************************************************************************
