

 *******************************************************************************
libtbx/auto_build/install_distribution.py
#!/usr/bin/python

"""
Template for building Unix/Linux installers for CCTBX-based packages, e.g.
Phenix or LABELIT.  This is derived from the Phenix installer, with options
specific to Phenix removed.

The installer makes several assumptions about the distribution bundle, and
will break if it does not encounter the expected files and directories.  The
recommended way to create an installer package is to start with the script
setup_installer.py in the same directory.  The expected directory structure is:

INSTALLER_DIR/bin/
INSTALLER_DIR/bin/install   # main executable, subclasses 'installer' class
INSTALLER_DIR/lib
INSTALLER_DIR/lib/libtbx/   # complete libtbx distribution
INSTALLER_DIR/bundles/      # compressed binary distribution
INSTALLER_DIR/source/       # source tarballs
INSTALLER_DIR/dependencies  # third-party software

The last four directories contain the actual distribution; depending on whether
the installer is source or binary, they may not all be present.  The 'bundles'
directory will have one or more tar.gz files containing all compiled files
(and many Python modules).  The 'sources' directory will contain a set of
tar.gz files for the distributed modules, one of which will be a CCTBX source
bundle (plus various add-ons like ccp4io, cbflib, etc.).  'dependencies' is for
third-party packages such as Python that need to be compiled for source
installation.

In addition to the required contents, the installer may also contain files
named README, LICENSE, etc.; these will automatically be propagated to the
installed package.  Information describing the version may also be provided
but the implementation of this is left up to each product.  Installers may also
have additional directories for non-compiled packages such as geometry
restraints or documentation.

To implement an installer for distribution, an install script should be written
along these lines:

  from libtbx.auto_build import install_distribution
  import os.path
  import sys

  class installer(install_distribution.installer):
    product_name = "PHENIX"
    dest_dir_prefix = "phenix"
    make_apps = ["phenix"]
    installer_dir = os.path.dirname(os.path.dirname(__file__))

  if (__name__ == "__main__"):
    installer(sys.argv[1:])

Note that the location of the install script is not mandatory, but it must be
able to correctly detect the base installer directory.
"""

from __future__ import absolute_import, division, print_function
from optparse import OptionParser
import os.path as op
import os
import sys
# set nproc automatically if possible
try :
  import multiprocessing
  NPROC_DEFAULT = min(24, multiprocessing.cpu_count())
except Exception :
  NPROC_DEFAULT = 1
# local imports
# XXX HACK
libtbx_path = op.abspath(op.dirname(op.dirname(__file__)))
if (not libtbx_path in sys.path):
  sys.path.append(libtbx_path)
from libtbx.auto_build import write_gui_dispatcher_include
from libtbx.auto_build import regenerate_module_files
from libtbx.auto_build import install_base_packages
from libtbx.auto_build import create_mac_app
from libtbx.auto_build.installer_utils import *

class InstallerError(Exception):
  __orig_module__ = __module__
  # trick to get just "Sorry" instead of "libtbx.utils.Sorry"
  __module__ = Exception.__module__

  def reset_module(self):
    """
    Reset the class module on an instance to libtbx.utils.
    """
    self.__class__.__module__ = self.__class__.__orig_module__

class installer(object):
  """
  Base class for installers. Some methods and class attributes must be
  re-implemented in subclasses!
  """
  # Basic configuration variables - override in subclasses
  organization = "gov.lbl.cci"
  product_name = "CCTBX"
  destination = "/usr/local"
  dest_dir_prefix = "cctbx"
  installer_dir = os.environ.get(product_name + "_INSTALLER", None)
  include_gui_packages = True
  # Options passed to install_base_packages.py
  base_package_options = []
  base_modules = []
  modules = [
    "cctbx_project",
  ]
  # Modules that need to be configured for use in the final installation.
  #   this will automatically include dependencies.
  configure_modules = ["mmtbx", "smtbx"]
  # Programs to make graphical .app launchers for (Mac only)
  make_apps = []
  # Architectures supported for a particular distribution. Those listed here
  #   will be detected automatically.
  supported_mtypes = [
    "intel-linux-2.6",
    "intel-linux-2.6-x86_64",
    "mac-intel-osx",
    "mac-intel-osx-x86_64",
    "intel-windows",
    "intel-windows-x86_64",
  ]
  # Boolean flags to control installer behaviour in a fine-grained manner
  flags = [
    'create_versioned_dispatchers'
  ]

  def __init__(self, args=None, out=sys.stdout):
    self.args = args or []
    self.out = out
    self.parse_options()

  def parse_options(self):
    """
    Process command-line options.  These may be supplemented by subclasses that
    override the method add_product_specific_options.
    """
    parser = OptionParser(
      description=("Command-line installer for %s crystallography "+
        "software on Mac and Linux systems.  Please note that Mac users "+
        "may also use the graphical installer, but this is limited to single "+
        "workstations.") % self.product_name)
    parser.add_option("--prefix", dest="prefix", action="store",
      help="Directory where %s is to be installed" % self.product_name,
      default=self.destination)
    parser.add_option("--nproc", dest="nproc", action="store", type="int",
      help="Number of processors for source install", default=NPROC_DEFAULT)
    parser.add_option("--no-app", dest="no_app", action="store_true",
      help="Disable generation of Mac app launcher(s)", default=False)
    parser.add_option("--compact", dest="compact", action="store_true",
      help="Remove unnecessary files such as compiled sources to save space")
    parser.add_option("--try-unsupported", dest="try_unsupported",
      action="store_true", default=False,
      help="Attempt source install on unsupported platform")
    parser.add_option("--verbose", "-v", dest="verbose", action="store_true",
      help="Provide more detailed output during installation", default=False)
    # Source only options
    parser.add_option("--no-gui", dest="no_gui", action="store_true",
      help="Disable building of GUI dependencies (source install only)",
      default=False)
    parser.add_option("--base-only", dest="base_only", action="store_true",
      help="Only install base libraries and files", default=False)
    parser.add_option("--source", dest="source", action="store_true",
      help="Force source installation", default=None)
    parser.add_option("--openmp", dest="openmp", action="store_true",
      help="Enable OpenMP compilation if possible", default=False)
    parser.add_option("--no-opt", dest="no_opt", action="store_true",
      help="Disable optimization during compilation", default=False)
    parser.add_option("--debug", dest="debug", action="store_true",
      help="Turn on debugging during compilation", default=False)
    parser.add_option("--python_static", default=False, action="store_true",
      help="Compile Python as static executable and library (Linux only)")
    parser.add_option("--use-conda", default=False, action="store_true",
      help="Install conda dependencies (source install only)")
    # Deprecated
    parser.add_option("--makedirs", default=False, action="store_true",
      help="Create installation path prefix if not already present")
    parser.add_option("--binary", dest="binary", action="store_true",
      help="Use pre-compiled binary install", default=None)
    parser.add_option("--nopycompile", dest="nopycompile", action="store_true",
      help="Do not precompile python files", default=False)
    self.add_product_specific_options(parser)
    self.options, args = parser.parse_args(self.args)

  def install(self):
    check_python_version()
    self.parse_options()
    self.basic_setup()
    self.product_specific_preinstallation_hook()
    self.check_directories()
    if sys.platform != "win32":
      self.print_banner()
      if not os.path.exists('build'):
        print("No build directory exists; trying source installation.", file=self.out)
        self.options.source = True
      if self.options.source:
        print("Source installation specified.", file=self.out)
        self.install_from_source()
      else:
        self.install_from_binary()
    self.install_finalize()
    self.print_header('Installation complete!')

  def basic_setup(self):
    # Check version
    self.version = self.get_version()
    assert (self.version is not None)
    # GUI Flag
    self.flag_build_gui = False
    if (self.include_gui_packages):
      self.flag_build_gui = not self.options.no_gui

    # Check this is a supported architecture.
    self.mtype = self.machine_type()
    if (self.mtype is None):
      raise InstallerError("Machine type not recognized")
    elif ((not self.mtype in self.supported_mtypes) and
          (not self.options.try_unsupported)):
      raise InstallerError("""
  %(mtype)s is not a supported platform, installation aborted
    use the --try-unsupported option to attempt installation on this platform
    use the --no-gui option for a core %(product)s installation
  """%{ "mtype" : self.mtype, "product" : self.product_name})

  def check_directories(self):
    if sys.platform == "win32":
      self.dest_dir = os.getcwd()
      self.tmp_dir = self.dest_dir
      self.build_dir = op.join(self.dest_dir, "build")
      self.base_dir = op.join(self.dest_dir, "base")
      self.modules_dir = op.join(self.dest_dir, "modules")
      # check for conda
      if os.path.isdir(op.join(self.installer_dir, "conda_base")) or \
         os.path.exists(op.join(self.installer_dir, "conda_base.tar")):
        self.base_dir = op.join(self.dest_dir, "conda_base")
      return
    # The default behavior for nearly all program's --prefix options
    # is to create the directory, so I don't think the --makedirs option
    # is necessary.

    if not os.access(self.options.prefix, os.W_OK):
      if not os.path.exists(self.options.prefix):
        os.makedirs(self.options.prefix)
      else:
        raise InstallerError("""
  Installation directory not writeable:
    %s
  Please specify an alternative directory using the --prefix option."""
      %self.options.prefix)

    # Do not overwrite an existing installation.
    self.dest_dir = op.abspath(op.join(
      self.options.prefix, "%s-%s"%(self.dest_dir_prefix, self.version)))
    if os.path.exists(self.dest_dir):
      raise InstallerError("""
  Installation directory already exists:
    %s
  Please remove this directory and try again.
    """%self.dest_dir)

    # Other useful directories.
    self.tmp_dir = op.join(self.installer_dir, "base_tmp")
    self.build_dir = op.join(self.dest_dir, "build")
    self.base_dir = op.join(self.dest_dir, "base")
    self.modules_dir = op.join(self.dest_dir, "modules")
    for i in [self.dest_dir, self.tmp_dir]:
      if not os.path.exists(i):
        os.makedirs(i)

    # check for conda
    if os.path.isdir(op.join(self.installer_dir, "conda_base")) or \
       os.path.exists(op.join(self.installer_dir, "conda_base.tar")):
      self.base_dir = op.join(self.dest_dir, "conda_base")

    # Environment variables required by other scripts
    os.environ["%s_MTYPE" % self.product_name] = self.mtype
    os.environ["%s_INSTALLER" % self.product_name] = self.installer_dir
    os.environ["%s_LOC" % self.product_name] = self.dest_dir
    os.environ["%s_BUILD" % self.product_name] = self.build_dir

  def print_banner(self):
    print("""
    ==========================================================================
                          %(product)s Installation

                          version: %(version)s
                     machine type: %(mtype)s
                       OS version: %(os)s
                      destination: %(dest)s
                  # of processors: %(nproc)s
    =========================================================================
    """ % { "product" : self.product_name,
            "version" : self.version,
            "mtype"   : self.mtype,
            "os"      : get_os_version(),
            "dest"    : self.dest_dir,
            "nproc"   : self.options.nproc,
      }, file=self.out)

  def machine_type(self):
    """
    Determine the mtype string.  The four pre-defined mtypes will be detected
    automatically (with Linux kernel 3.x treated as 2.6), but additional mtypes
    can be used if this method is re-implemented.
    """
    return machine_type()

  #---------------------------------------------------------------------
  # BINARY INSTALL
  #
  def install_from_binary(self):
    """
    Unpackage the binary bundle in the destination directory.
    """
    # Copy base, build, and modules
    for i in ['base', 'conda_base', 'build', 'modules', 'doc']:
      if os.path.exists(os.path.join(self.installer_dir, i)):
        copy_tree(os.path.join(self.installer_dir, i), os.path.join(self.dest_dir, i))

    # Copy conda_base packaged with conda-pack if available
    # only this file or the conda_base directory will exist in the installer
    conda_base_tarfile = os.path.join(self.installer_dir, 'conda_base.tar')
    if os.path.exists(conda_base_tarfile):
      import subprocess
      import tarfile
      tarball = tarfile.open(conda_base_tarfile)
      dest_dir = os.path.join(self.dest_dir, 'conda_base')
      tarball.extractall(path=dest_dir)
      tarball.close()
      cwd = os.getcwd()
      os.chdir(dest_dir)
      unpack_cmd = [sys.executable, os.path.join('.', 'bin', 'conda-unpack')]
      if sys.platform == 'win32':
        unpack_cmd = [os.path.join('.', 'Scripts', 'conda-unpack.exe')]
      subprocess.check_call(unpack_cmd)
      os.chdir(cwd)

    # Reconfigure
    log = open(os.path.join(self.tmp_dir, "binary.log"), "w")
    if not os.path.exists(self.tmp_dir):
      os.makedirs(self.tmp_dir)
    if (sys.platform != "darwin"):
      os.environ["LD_LIBRARY_PATH"] = "lib:%s:%s" % \
        (op.join(self.base_dir, "lib"), op.join(self.base_dir, "lib64"))
    self.product_specific_binary_install(log=log)

    os.chdir(self.build_dir)
    print("Configuring %s components..."%(self.product_name), file=self.out)
    self.reconfigure(log=log)

  #---------------------------------------------------------------------
  # SOURCE INSTALL
  #
  def install_from_source(self):
    log = self.out # open(os.path.join(self.tmp_dir, "source.log"), "w")
    cmd = [
      sys.executable,
      os.path.join('modules', 'cctbx_project', 'libtbx', 'auto_build', 'bootstrap.py'),
      'base',
      'build',
      '--builder', self.dest_dir_prefix,
      '--nproc', str(self.options.nproc),
    ]
    if self.options.use_conda:
      cmd.append('--use-conda')
      self.base_dir = op.join(self.dest_dir, "conda_base")
    call(cmd, log=log)
    self.product_specific_source_install(log=log)
    self.install_from_binary()

  def show_installation_paths(self):
    print("""
%(product)s installation target directory <%(product)s_LOC> set to:
   %(dest_dir)s
%(product)s installation source directory set to:
   %(inst_dir)s
%(product)s installation build directory set to:
   %(build_dir)s
%(product)s temporary build directory set to:
   %(tmp_dir)s
""" % { "product" : self.product_name,
        "dest_dir" : self.dest_dir,
        "build_dir" : self.build_dir,
        "inst_dir" : self.installer_dir,
        "tmp_dir" : self.tmp_dir, }, file=self.out)

  #---------------------------------------------------------------------
  # NON-COMPILED COMPONENTS AND FINAL SETUP
  #
  def reconfigure(self, log):
    """
    Run libtbx/configure.py to configure the build in the new location.
    """
    os.chdir(self.build_dir)

    base_python = os.path.join(self.base_dir, 'bin', 'python')
    if 'win32' in sys.platform:
      base_python = os.path.join(self.base_dir, 'bin', 'python', 'python.exe')

    # check for conda
    if self.base_dir.endswith('conda_base'):
      if 'darwin' in sys.platform:
        base_python = os.path.join(self.base_dir, 'python.app', 'Contents',
                                   'MacOS', 'python')
      elif 'win32' in sys.platform:
        base_python = os.path.join(self.base_dir, 'python.exe')

    args = [
      base_python,
      os.path.join(self.modules_dir, 'cctbx_project', 'libtbx', 'configure.py'),
      "--current_working_directory", self.build_dir
    ]
    if 'win32'==sys.platform:
      args = [
        base_python,
        os.path.join(self.modules_dir, 'cctbx_project', 'libtbx', 'configure.py'),
      ]
    if 'create_versioned_dispatchers' in self.flags:
      args += [ "--command_version_suffix", self.version ]
    args += self.configure_modules

    # check for conda
    if self.base_dir.endswith('conda_base'):
      args += ['--use_conda']

    if self.options.verbose:
      print(self.build_dir)
      print(args)

    if 1: #try :
      call(args=args, log=log, verbose=self.options.verbose)
    else: #except RuntimeError :
      raise InstallerError("Configuration step incomplete!  See the log file for detailed error messages.")

  def install_finalize(self):
    """
    Set up dispatchers and assorted shell scripts, create app bundles, etc.
    """
    self.print_header('Finalizing %s installation'%self.product_name)
    log_path = op.join(self.tmp_dir, "install_finalize.log")
    print("Log file: %s"%log_path, file=self.out)
    log = open(log_path, "w")

    # Write environment files.
    self.write_environment_files()

    # Regenerate module files.
    if (self.flag_build_gui) and (sys.platform != "darwin") and \
      (not self.base_dir.endswith('conda_base')):
      os.environ["LD_LIBRARY_PATH"] = "lib:%s:%s" % \
        (op.join(self.base_dir, "lib"), op.join(self.base_dir, "lib64"))
      regenerate_module_files.run(
        os.path.join(self.dest_dir, 'base'),
        out=self.out)

    # Write dispatcher_include file.
    print("Generating %s environment additions for dispatchers..." % \
      self.product_name, file=self.out)
    fnsuffix = '.sh'
    envcmd = "export"
    if sys.platform == "win32":
      fnsuffix = '.bat'
      envcmd = "set"
    dispatcher = op.join(self.build_dir, "dispatcher_include_%s%s" %
      (self.dest_dir_prefix, fnsuffix))
    if (op.isfile(dispatcher)):
      os.remove(dispatcher)
    env_prefix = self.product_name.upper() # e.g. "Phenix" -> "PHENIX"
    prologue = "\n".join([
      "%s %s=\"%s\"" % (envcmd, env_prefix, self.dest_dir),
      "%s %s_VERSION=%s" % (envcmd, env_prefix, self.version),
      "%s %s_ENVIRONMENT=1" % (envcmd, env_prefix),
      "%s %s_MTYPE=%s" % (envcmd, env_prefix, self.mtype),
    ] + self.product_specific_dispatcher_prologue())
    epilogue = "\n".join(self.product_specific_dispatcher_epilogue())
    dispatcher_opts = [
      "--build_dir=%s" % self.build_dir,
      "--base_dir=%s" % self.base_dir,
      "--suffix=%s" % self.dest_dir_prefix,
      "--gtk_version=2.10.0", # XXX this can change!
      "--quiet",
    ]
    if (not self.flag_build_gui):
      dispatcher_opts.append("--ignore_missing_dirs")
    # check for conda
    if (self.base_dir.endswith('conda_base')):
      dispatcher_opts += ["--use_conda", "--ignore_missing_dirs"]
    # FIXME this will happen regardless of whether the GUI modules are being
    # distributed or not - will this be problematic?
    print('Calling write_gui_dispatcher_include')
    print('  args %s' % dispatcher_opts)
    print('  prologue %s' % prologue)
    print('  epilogue %s' % epilogue)
    write_gui_dispatcher_include.run(
      args=dispatcher_opts,
      prologue=prologue,
      epilogue=epilogue,
      out=self.out)
    assert op.isfile(dispatcher)

    # Run configure.py to generate dispatchers
    print("Configuring %s components..." % self.product_name, file=self.out)
    os.chdir(self.build_dir)
    # ???
    if (op.exists("libtbx_refresh_is_completed")):
      os.remove("libtbx_refresh_is_completed")
    self.reconfigure(log=log)
    os.chdir(self.build_dir)
    assert op.isfile("setpaths%s" %fnsuffix)
    if sys.platform != "win32":
      os.environ["PATH"] = "%s:%s" % (op.join(self.build_dir, "bin"), os.environ["PATH"])
    else:
      os.environ["PATH"] = "%s;%s" % (op.join(self.build_dir, "bin"), os.environ["PATH"])

    if not self.options.nopycompile:
      # Compile .py files
      print("Precompiling .py files...", file=self.out)
      os.chdir(self.modules_dir)
      call(args="libtbx.py_compile_all -i", log=log)

    # Copy README et al.
    for file_name in ["CHANGES", "LICENSE", "README", "README-DEV", "SOURCES"] :
      src_file = op.join(self.installer_dir, file_name)
      if op.exists(src_file):
        dest_file = op.join(self.dest_dir, file_name)
        # XXX use our own implementation instead of shutil.copyfile
        if sys.platform == "win32" and src_file==dest_file:
          # writing to the same file on Windows renders it empty
          continue
        copy_file(src_file, dest_file)

    # generate .app (Mac only)
    apps_built = False
    if ((sys.platform == "darwin") and (len(self.make_apps) > 0) and
        (not self.options.no_app) and self.flag_build_gui):
      os.chdir(self.build_dir)
      for app_name in self.make_apps :
        args = [
          "libtbx.create_mac_app",
          app_name,
          "--app_name=%s-%s" % (app_name, self.version),
          "--dest=%s" % self.dest_dir,
          "--alias_build"
        ]
        print("Generating Mac app launcher for %s..."%app_name, file=self.out)
        try :
          call(args=" ".join(args), log=log)
        except RuntimeError as e:
          print("  ERROR:")
          print("  " + str(e))
          print("  installation will continue anyway.")
        else :
          app_file = op.join(self.dest_dir, "%s-%s.app" %
            (app_name, self.version))
          if (not op.exists(app_file)):
            print(" failed.", file=self.out)
            app_file = None
          else :
            apps_built = True

    # run custom finalization
    self.product_specific_finalize_install(log)

    # remove source files if desired
    if (self.options.compact):
      self.reduce_installation_size()

    self.display_final_message()

    if sys.platform == "win32":
      return

    # Fix permissions
    call([
      'chmod',
      '-R',
      'u+rw,a+rX',
      self.dest_dir
      ])

    # Show the app.
    if apps_built and (not "SSH_CLIENT" in os.environ):
      try:
        call(args=["open", self.dest_dir], log=self.out)
      except Exception:
        # Will fail in non-interactive environments.
        pass

  #---------------------------------------------------------------------
  # STUBS FOR SUBCLASSABLE METHODS

  def write_environment_files(self):
    """
    Generate shell scripts in the top-level installation directory that can
    be used to set up the user environment to run the software.  This is
    implemented as a separate method because some products (e.g. Phenix) may
    have their own needs.
    """
    # csh/tcsh/bat environment setup file
    print("Generating %s environment setup scripts..."%self.product_name, file=self.out)
    env_prefix = self.product_name.upper() # e.g. "Phenix" -> "PHENIX"
    if sys.platform == "win32":
      f = open(os.path.join(self.dest_dir, '%s_env.bat'%self.dest_dir_prefix), 'w')
      f.write("@echo off\n")
      # Use the %~dp0 alias for specifying the full path to where phenix_env.bat will be located.
      # This presumes phenix_env.bat will always reside where it has originally been installed to.
      f.write("set %s=%%~dp0\n" %env_prefix)
      f.write("set %s_VERSION=%s\n" % (env_prefix, self.version))
      f.write("call \"%%%s%%\\build\\setpaths.bat\"\n" % (env_prefix))
      f.close()
      return

    f = open(os.path.join(self.dest_dir, '%s_env.csh'%self.dest_dir_prefix), 'w')
    f.write("#!/bin/csh -f\n")
    f.write("setenv %s \"%s\"\n" % (env_prefix, self.dest_dir))
    f.write("setenv %s_VERSION %s\n" % (env_prefix, self.version))
    f.write("source $%s/build/setpaths.csh\n" % (env_prefix))
    f.close()

    f = open(os.path.join(self.dest_dir, '%s_env.sh'%self.dest_dir_prefix), 'w')
    f.write("#!/bin/sh\n")
    f.write("#\n")
    f.write("export %s=\"%s\"\n" % (env_prefix, self.dest_dir))
    f.write("export %s_VERSION=%s\n" % (env_prefix, self.version))
    f.write(". $%s/build/setpaths.sh\n" % (env_prefix))
    f.close()

  def get_version(self):
    """
    Determine the version suffix (if any) for the destination directory.  This
    must be implemented by subclasses unless a file named VERSION is present
    at the top level of the installer folder.
    """
    version_file = op.join(self.installer_dir, "VERSION")
    if op.isfile(version_file):
      return open(version_file).read().strip()
    return NotImplementedError()

  def reduce_installation_size(self):
    """
    Remove all files not required for program execution to save disk space,
    such as any C++ sources.  This can potentially save well over 100MB and is
    recommended for purely user-facing packages, but may make it more difficult
    to use packages for development purposes.
    """
    print("Removing unnecessary files to reduce disk usage...", end=' ', file=self.out)
    # XXX should this include .o files?
    remove_extensions = [".cpp", ".cc", ".hpp", ".h", ".hh"]
    n_deleted = 0
    for dirname, dirnames, filenames in os.walk(self.modules_dir):
      for file_name in filenames :
        for ext in remove_extensions :
          if file_name.endswith(ext):
            full_path = op.join(dirname, file_name)
            try :
              os.remove(full_path)
            except Exception as e:
              print("  WARNING: error removing %s" % full_path, file=self.out)
              print(str(e), file=self.out)
            else :
              n_deleted += 1
    n_deleted_other = self.product_specific_reduce_installation_size()
    if (n_deleted_other is not None):
      n_deleted += n_deleted_other
    print("%d files deleted" % n_deleted, file=self.out)

  def add_product_specific_options(self, parser):
    """
    Add command-line options specific to the distributed package.
    """
    pass

  def product_specific_prepackage_hook(self, directory):
    """
    Modify files, etc. before the installer package is created.

    :param directory: base directory of the installer package
    """
    pass

  def product_specific_preinstallation_hook(self):
    """
    Perform additional checks on parsed command line options or the
    destination machine before any installation action takes place.
    """
    pass

  def product_specific_binary_install(self, log):
    """
    Perform additional actions required for the binary installation of a
    specific product.
    """
    pass

  def product_specific_setup_before_compile(self, log):
    """
    Perform any necessary modifications to the sources prior to compilation.
    """
    pass

  def product_specific_source_install(self, log):
    """
    Build additional sources, e.g. Rosetta
    """
    pass

  def product_specific_dispatcher_prologue(self):
    """
    Environment modifications to be included near the start of the dispatchers.
    """
    return []

  def product_specific_dispatcher_epilogue(self):
    """
    Environment modifications to be included at the end of the dispatchers.
    """
    return []

  def product_specific_finalize_install(self, log):
    """
    Additional installation setup, file cleanup, more add-ons, etc.
    """
    pass

  def product_specific_reduce_installation_size(self, log):
    """
    Remove unused files specific to this product, and return the number deleted.
    """
    return 0

  def display_final_message(self):
    """
    Final instructions for user, etc.
    """
    pass

  def print_header(self, msg):
    print("", file=self.out)
    print("*"*(len(msg) + 4), file=self.out)
    print("* %s *"%msg, file=self.out)
    print("*"*(len(msg) + 4), file=self.out)
    print("", file=self.out)


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/installer_utils.py
from __future__ import absolute_import, division, print_function, with_statement

import errno
import os
import os.path as op
import platform
import shutil
import stat
import subprocess
import sys
import tarfile
import time

# CCTBX itself requires Python 2.7, but this script is intended to bootstrap an
# installation on older systems as well
def check_python_version():
  if sys.hexversion < 0x2060000:
    sys.exit("Python version 2.6 or greater required to run this script")

def call(args, log=None, shell=True, cwd=None, verbose=False, env=None):
  if log is None: log = sys.stdout
  # shell=True requires string as args.
  if shell and isinstance(args, list):
    args = " ".join(args)
  if verbose:
    stdout = subprocess.PIPE
  else:
    stdout = log
  p = subprocess.Popen(
    args=args,
    shell=shell,
    cwd=cwd,
    bufsize=-1,
    stdin=None,
    stdout=stdout,
    stderr=subprocess.STDOUT,
    universal_newlines=True,
    close_fds=False,
    env=env)
  if verbose:
    while p.poll() is None:
      line = p.stdout.readline()
      # this will cause a deadlock if process is writing to stderr
      # stderr is redirected to stdout, so this cannot happen
      if line:
        print(": " + line.strip())
        log.write(line)
  #o, e = p.communicate()
  #log.write(o)
  log.flush()
  p.wait()
  log.flush()
  rc = p.returncode
  if rc != 0:
    raise RuntimeError("Call to '%s' failed with exit code %d" % (args, rc))

def check_output(*popenargs, **kwargs):
  # Back-port of Python 2.7 subprocess.check_output.
  try:
    process = subprocess.Popen(stdout=subprocess.PIPE, *popenargs, **kwargs)
  except OSError as exc:
    if exc.errno == errno.ENOENT:
      raise OSError("No such file or directory (%s)" % popenargs[0])
    raise
  output, unused_err = process.communicate()
  retcode = process.poll()
  if retcode:
    raise RuntimeError("Call to '%s' failed with exit code %d" % (popenargs, retcode))
  return output

def untar(pkg_name, log=sys.stdout, verbose=False, change_ownership=False,
    check_output_path=True):
  assert os.path.isfile(pkg_name), pkg_name
  verbose_flag = owner_flag = ""
  if verbose:
    verbose_flag = "v"
  if change_ownership:
    owner_flag = "o"
  cmd = [ "tar", "x%s%sf" % (owner_flag, verbose_flag) ]
  if pkg_name.endswith("gz"):
    cmd = ["tar", "zx%s%sf" % (owner_flag, verbose_flag) ]
  elif pkg_name.endswith("bz2"):
    cmd = ["tar", "jx%s%sf" % (owner_flag, verbose_flag) ]
  args = cmd + [pkg_name]
  if os.name != 'nt':
    call(" ".join(args), log)
  else:
    # Note: This code breaks
    #   - extracting compressed files
    #   - logging
    #   - function parameters verbose and change_ownership
    #   - insufficient trapping of errors
    # Should import tar_extract from  bootstrap.py to avoid code duplication
    tar = tarfile.open(pkg_name)
    tar.extractall()
    tar.close()

  dir_name = os.path.basename(pkg_name) \
                 .replace(".tar.bz2", "") \
                 .replace(".tar.gz", "") \
                 .replace(".tgz", "") \
                 .replace(".tar", "")
  if check_output_path:
    if not os.path.isdir(dir_name):
      time.sleep(1)
      if not os.path.isdir(dir_name):
        if os.path.isdir(dir_name.capitalize()):
          dir_name = dir_name.capitalize()
        else:
          raise RuntimeError("Expected directory '%s' not found!" % dir_name)
    return os.path.abspath(dir_name)
  return None

def detect_osx_version():
  uname = os.uname()
  version = uname[2]
  major, minor, rev = version.split(".")
  return int(major)

def copy_file(src_path, dest_path, executable=None):
  assert os.path.isfile(src_path)
  with open(src_path, "rb") as fi:
    with open(dest_path, "wb") as fo:
      fo.write(fi.read())
  if os.access(src_path, os.X_OK) or executable:
    mode = os.stat(dest_path).st_mode
    os.chmod(dest_path, mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)

# shutil.copytree replacement - handles symlinks intelligently and also
# circumvents this bug:
# http://bugs.python.org/issue14662
# this is not a general solution, but it is good enough for the installer
# process (at least on Unix).
def copy_tree(src_path, dest_path, verbose=False, log=sys.stdout):
  if sys.hexversion >= 0x2070400:
    return shutil.copytree(src_path, dest_path, symlinks=True)
  assert os.path.isdir(src_path), src_path
  assert not os.path.exists(dest_path), dest_path
  if verbose:
    print("creating %s" % dest_path, file=log)
  os.makedirs(dest_path)
  for path_name in os.listdir(src_path):
    node_src_path = os.path.join(src_path, path_name)
    node_dest_path = os.path.join(dest_path, path_name)
    if os.path.islink(node_src_path):
      target_path = os.readlink(node_src_path)
      os.symlink(target_path, node_dest_path)
    elif os.path.isfile(node_src_path):
      if verbose:
        print("  copy %s -> %s" % (node_src_path, node_dest_path), file=log)
      copy_file(node_src_path, node_dest_path)
    elif os.path.isdir(node_src_path):
      copy_tree(node_src_path, node_dest_path)
    elif verbose:
      print("  skipping %s" % node_src_path, file=log)

def get_os_version():
  uname = os.uname()
  kernel_version = uname[2]
  if uname[0] == "Darwin":
    # Use Python's platform module to determine OSX version
    release, _, _ = platform.mac_ver()
    # Convert X.Y.Z to X.Y - discard minor version
    release_major = ".".join(release.split(".")[:2])
    assert release, "Could not determine OSX version"
    return release_major
  return kernel_version

def machine_type():
  if sys.platform == "win32":
    mtype = "intel-windows"
    arch, os_type = platform.architecture()
    if arch == "64bit":
      mtype += "-x86_64"
    return mtype
  uname = os.uname()
  if uname[0] == "Linux":
    mtype = "intel-linux-2.6"
  elif uname[0] == "Darwin":
    mtype = "mac-intel-osx"
  else:
    mtype = uname[0]
  if uname[-1] == "x86_64":
    mtype += "-x86_64"
  elif mtype == "mac-intel-osx":
    version_fields = uname[2].split(".")
    major_version = int(version_fields[0])
    if major_version >= 10:
      mtype += "-x86_64"
    if major_version >= 13:
      mtype += "-10.9"
  return mtype

def regenerate_relative_symlinks(dir_name, log=sys.stdout):
  """
  Rewrite all symlinks in a directory with relative paths (allows later
  relocation).  This is mostly just for Mac OS where there are a lot of links
  into the Python.framework bundle.
  """
  old_cwd = os.getcwd()
  os.chdir(dir_name)
  for file_name in os.listdir(dir_name):
    # e.g. /usr/bin/cmd
    full_path = op.join(dir_name, file_name)
    if op.islink(full_path):
      real_path = op.realpath(full_path) # e.g. /usr/cctbx/bin/cmd
      prefix = op.commonprefix([full_path, real_path]) # /usr
      rel_path_link = op.relpath(full_path, prefix) # bin/cmd
      rel_path_target = op.relpath(real_path, prefix) # cctbx/bin/cmd
      parent_dirs = [ ".." for d in op.split(rel_path_link) ][1:]
      if parent_dirs:
        parent_dir = op.join(*parent_dirs)
      else:
        parent_dir = "."
      new_path = op.join(parent_dir, rel_path_target) # ../../cctbx/bin/cmd
      print("  creating symlink to %s" % new_path, file=log)
      os.remove(file_name)
      os.symlink(new_path, file_name)

def find_and_delete_files(dir_name, file_name=None, file_ext=None):
  """
  Recursively walk through a directory and delete any files (or directories)
  with the specified file name or extension.  Effectively equivalent to
  running 'find . -name "PATTERN" | xargs rm -rf'.
  """
  deleted = []
  for dirname, dirnames, filenames in os.walk(dir_name):
    for dn in dirnames:
      if dn == file_name:
        full_path = op.join(dirname, dn)
        shutil.rmtree(full_path)
        deleted.append(full_path)
    for fn in filenames:
      full_path = op.join(dirname, fn)
      if fn == file_name:
        os.remove(full_path)
        deleted.append(full_path)
      elif file_ext is not None and fn.endswith(file_ext):
        os.remove(full_path)
        deleted.append(full_path)
  return deleted

def archive_dist(dir_name, create_tarfile=True, use_shutil=True):
  """
  Create a clean copy of a source repository, optionally bundling it as a
  gzipped tar file.
  """
  dir_name = op.abspath(dir_name)
  assert op.isdir(dir_name) and dir_name != os.getcwd()
  module_name = op.basename(dir_name)
  local_path = op.join(os.getcwd(), module_name)
  if use_shutil:
    shutil.copytree(dir_name, local_path)
  else:
    copy_tree(dir_name, local_path)
  if op.exists(op.join(local_path, ".svn")):
    try:
      call("svnversion %s > %s/.svnversion" % (module_name, module_name),
        log=sys.stdout)
    except RuntimeError as e:
      print(e)
  find_and_delete_files(local_path, file_ext=".pyc")
  find_and_delete_files(local_path, file_ext=".pyo")
  find_and_delete_files(local_path, file_ext=".swp")
  find_and_delete_files(local_path, file_name=".svn")
  find_and_delete_files(local_path, file_name=".git")
  find_and_delete_files(local_path, file_name=".sconsign")
  if create_tarfile:
    #call("tar -czf %s.tar.gz %s" % (module_name, module_name), log=sys.stdout)
    tar = tarfile.open("%s.tar.gz" %module_name, "w:gz")
    tar.add(module_name)
    tar.close()

    tar_file = op.join(os.getcwd(), module_name + ".tar.gz")
    assert op.isfile(tar_file)
    shutil.rmtree(local_path)
    return tar_file
  return op.join(os.getcwd(), module_name)

def strip_libs(dir_name, log):
  for dirname, dirnames, filenames in os.walk(dir_name):
    for fn in filenames:
      full_path = op.join(dirname, fn)
      if fn.endswith(".so") and op.isfile(full_path):
        try:
          call("strip %s" % full_path, log=log)
        except RuntimeError:
          pass


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/make_bundle.py
#!/usr/bin/python

"""
Create a "bundle" (.tar.gz) of all Python modules and compiled code in a
product.  The target directory is expected to look something like this:

CCTBX-<version>/
CCTBX-<version>/base/
CCTBX-<version>/build/
CCTBX-<version>/build/lib/
CCTBX-<version>/cctbx_project/

plus any number of module directories in the top level.  The resulting bundle
will be named bundle-<version>-<mtype>.tar.gz.

Since the base modules take an especially long time to compile, they are now
part of a separate bundle.  This will allow re-use of precompiled base packages
with the latest source, which should speed up installer generation.
"""

from __future__ import absolute_import, division, print_function
from optparse import OptionParser
import os.path as op
import shutil
import time
import os
import sys
# local imports
# XXX HACK
libtbx_path = op.abspath(op.dirname(op.dirname(op.dirname(__file__))))
if (not libtbx_path in sys.path):
  print(libtbx_path)
  sys.path.append(libtbx_path)
from libtbx.auto_build.installer_utils import *
from libtbx.auto_build import rpath


def run(args, out=sys.stdout):
  datestamp = time.strftime("%Y_%m_%d", time.localtime())
  parser = OptionParser()
  parser.add_option("--tmp_dir", dest="tmp_dir", action="store",
    help="Temporary staging directory", default=os.getcwd())
  parser.add_option("--version", dest="version", action="store",
    help="Version number or code", default=datestamp)
  parser.add_option("--mtype", dest="mtype", action="store",
    help="Architecture type", default=machine_type())
  parser.add_option("--ignore", dest="ignore", action="append",
    help="Subdirectories to ignore", default=[])
  parser.add_option("--remove_src", dest="remove_src", action="store_true",
    help="Remove compiled source files (.h, .cpp, etc.)", default=False)
  parser.add_option("--dest", dest="dest", action="store",
    help="Destination directory for bundle tarfiles", default=None)
  parser.add_option("--verbose", dest="verbose", action="store_true")
  options, args = parser.parse_args(args)
  target_dir = args[0]
  assert op.isdir(target_dir), target_dir
  target_dir = op.abspath(target_dir)
  if (options.dest is not None):
    assert op.isdir(options.dest)
  os.chdir(options.tmp_dir)
  pkg_dir = op.basename(target_dir)
  build_dir = op.join(target_dir, "build")
  base_dir = op.join(target_dir, "base")

  # XXX a bit of a hack - if 'modules' subdirectory exists, it is assumed that
  # all source/data packages residue there, otherwise they must be at the top
  # level
  modules_dir = op.join(target_dir, "modules")
  if (not op.isdir(modules_dir)):
    modules_dir = target_dir
  stdout_old = sys.stdout
  if (not options.verbose):
    f = open("rpath.log", "w")
    sys.stdout = f
  print("Setting rpath in base packages...", file=out)
  rpath.run([base_dir])
  print("Setting rpath in shared libraries...", file=out)
  rpath.run([build_dir])
  sys.stdout = stdout_old

  # create temp dir
  tmp_dir = op.join(options.tmp_dir, "%s_tmp" % pkg_dir)
  assert op.isdir(build_dir), build_dir
  if op.exists(tmp_dir):
    shutil.rmtree(tmp_dir)
  os.mkdir(tmp_dir)
  os.chdir(tmp_dir)

  # base and build/lib directories
  print("Copying dependencies...", file=out)
  copy_tree(op.join(target_dir, "base"), op.join(tmp_dir, "base"))

  print("Copying shared libraries...", file=out)
  tmp_build_dir = op.join(tmp_dir, "build")
  os.makedirs(tmp_build_dir)

  # save mtype information (for hypothetical future update mechanism)
  open(op.join(tmp_build_dir, "MTYPE"), "w").write(options.mtype)
  copy_tree(op.join(build_dir, "lib"), op.join(tmp_build_dir, "lib"))

  # copy over non-compiled files
  print("Copying base modules...", file=out)
  for file_name in os.listdir(modules_dir):
    if (file_name in ["build", "base"]) or (file_name in options.ignore):
      continue
    full_path = op.join(modules_dir, file_name)
    if op.isdir(full_path):
      print("  copying %s..." % file_name, file=out)
      copy_tree(full_path, op.join(tmp_dir, file_name))
      call("chmod -R a+rX %s" % op.join(tmp_dir, file_name))

  # remove unnecessary base directories/files
  for dir_name in [
      "base/bin/gtk-demo",
      "base/man",
      "base/doc",
      "base/info",
      "base/share/gtk-doc",
      "base/share/locale",
      "base/lib/python2.7/test",
    ] :
    full_path = op.join(tmp_dir, dir_name)
    if op.exists(full_path):
      shutil.rmtree(full_path)

  site_pkg_dir = op.join(tmp_dir, "base/lib/python2.7/site-packages")
  find_and_delete_files(tmp_dir, file_name="tests")
  if sys.platform.startswith("linux"):
    strip_libs(op.join(tmp_dir, "base", "lib"), log=out)

  # XXX what about base/include?

  # copy over build executable directories
  print("Copying standalone executables...", file=out)
  # for j in [i for i in os.listdir(build_dir) if os.path.isdir(os.path.join(build_dir,i,"exe"))]:
  for j in [i for i in os.listdir(build_dir) if os.path.isdir(os.path.join(build_dir, i, "exe"))]:
    print("->", op.join(build_dir, j, "exe"), file=out)
    copy_tree(op.join(build_dir, j, "exe"), op.join(tmp_build_dir, j, "exe"))

  # delete unnecessary files
  print("Deleting unnecessary files.", file=out)
  find_and_delete_files(tmp_dir, file_ext=".pyc")
  find_and_delete_files(tmp_dir, file_ext=".o")
  find_and_delete_files(tmp_dir, file_ext=".pyo")
  find_and_delete_files(tmp_dir, file_name=".sconsign")
  find_and_delete_files(tmp_dir, file_name="CVS")
  find_and_delete_files(tmp_dir, file_name=".svn")
  if (options.remove_src):
    find_and_delete_files(tmp_dir, file_ext=".cpp")
    find_and_delete_files(tmp_dir, file_ext=".hpp")
    find_and_delete_files(tmp_dir, file_ext=".cc")
    find_and_delete_files(tmp_dir, file_ext=".c")
    find_and_delete_files(tmp_dir, file_ext=".h")

  # TODO strip objects?
  os.chdir(tmp_dir)
  call("chmod -R a+rX %s" % op.join(tmp_dir, "base"))
  call("chmod -R a+rX %s" % op.join(tmp_dir, "build"))
  # create base bundle
  base_tarfile = "../base-%(version)s-%(mtype)s.tar.gz" % \
    {"version":options.version, "mtype":options.mtype}
  call("tar -czf %(tarfile)s base" %
    {"tarfile":base_tarfile}, log=out)
  shutil.rmtree("base")

  assert op.isfile(base_tarfile)
  if (options.dest is not None):
    shutil.move(base_tarfile, options.dest)
    base_tarfile = op.join(options.dest, op.basename(base_tarfile))
  print("  created base bundle %s" % base_tarfile, file=out)

  # create the product bundle
  build_tarfile = "../build-%(version)s-%(mtype)s.tar.gz" % \
    {"version":options.version, "mtype":options.mtype}

  modules_tarfile = "../modules-%(version)s-%(mtype)s.tar.gz" % \
    {"version":options.version, "mtype":options.mtype}

  call("tar -czf %(tarfile)s build" % {"tarfile":build_tarfile}, log=out)
  shutil.rmtree("build")
  call("tar -czf %(tarfile)s ." % {"tarfile":modules_tarfile}, log=out)

  assert op.isfile(build_tarfile)
  assert op.isfile(modules_tarfile)
  if (options.dest is not None):
    shutil.move(build_tarfile, options.dest)
    build_tarfile = op.join(options.dest, op.basename(build_tarfile))
    shutil.move(modules_tarfile, options.dest)
    modules_tarfile = op.join(options.dest, op.basename(modules_tarfile))
  print("  created bundle %s" % build_tarfile, file=out)
  print("  created bundle %s" % modules_tarfile, file=out)
  shutil.rmtree(tmp_dir)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/package_defs.py

"""
Listing of current dependencies for CCTBX and related applications (including
LABELIT, xia2, DIALS, and Phenix with GUI).  Not all of these can be downloaded
via the web (yet).
"""

from __future__ import absolute_import, division, print_function

import json
import os
import os.path as op
import sys
try: # Python 3
  from urllib.request import urlopen
except ImportError: # Python 2
  from urllib2 import urlopen

try:
  from .bootstrap import Toolbox
  from .installer_utils import *
except (ValueError, ImportError):
  # When run from bootstrap the auto_build directory will be in the path
  from bootstrap import Toolbox
  from installer_utils import *

BASE_CCI_PKG_URL = [
  "http://cci.lbl.gov/cctbx_dependencies",
  "https://gitcdn.link/repo/dials/dependencies/master",
  "https://github.com/dials/dependencies/raw/master",
]

def get_pypi_package_information(package, version=None, information_only=False):
  '''Retrieve information about a PyPi package.'''
  metadata = 'https://pypi.python.org/pypi/' + package + '/json'
  try:
    pypidata = urlopen(metadata).read()
  except Exception: # TLS <1.2, ...
    if information_only:
      return {'name': '', 'version': '', 'summary': ''}
    raise
  pkginfo = json.loads(pypidata)
  if information_only:
    return pkginfo['info']
  if not version:
    version = pkginfo['info']['version']
  if version not in pkginfo['releases']:
    raise RuntimeError("Could not find release '%s' for %s on pypi." % (version, package))
  candidates = filter(lambda c: c.get('python_version') == 'source' and c.get('packagetype') == 'sdist', pkginfo['releases'][version])
  if not candidates:
    raise RuntimeError("Could not find a source release file for %s %s on pypi." % (package, version))
  package = candidates[0]
  for field in ('name', 'version', 'summary'):
    package[field] = pkginfo['info'][field]
  return package

DEPENDENCIES_BASE = [
  "https://gitcdn.link/repo/dials/dependencies/master",
  "https://github.com/dials/dependencies/raw/master",
  "https://gitcdn.xyz/repo/dials/dependencies/master",
]
OPENSSL_PKG = "openssl-1.0.2s.tar.gz"    # OpenSSL
PYTHON3_PKG = "Python-3.7.2.tgz"
PYTHON_PKG = "Python-2.7.18.tgz"

# from CCI
IMAGING_PKG = "Imaging-1.1.7.tar.gz"     # for labelit, gltbx
REPORTLAB_PKG = "reportlab-3.5.12.tar.gz"   # for labelit
ZLIB_PKG = "zlib-1.2.11.tar.gz"
PYRTF_PKG = "PyRTF-0.45.tar.gz"          # for phenix.table_one, etc.
BIOPYTHON_PKG = "biopython-1.73.tar.gz"  # used in iotbx
IPYTHON_PKG = "ipython-5.8.0.tar.gz"     # IPython
LIBSVM_PKG = "libsvm-3.17_cci.tar.gz"

# from PyPi
CYTHON_VERSION = "0.28.6"
DOCUTILS_VERSION = "0.14"
FUTURE_VERSION = "0.17.1"
H5PY_VERSION = "2.10.0"
JINJA2_VERSION = "2.10"
MOCK_VERSION = "3.0.5"
MPI4PY_VERSION = "3.0.0"
MRCFILE_VERSION = "1.1.2"
MSGPACK_VERSION = "0.6.1"
NUMPY_VERSION="1.15.4"
ORDEREDSET_VERSION = "2.0.1"
PILLOW_VERSION = "5.4.1"
PY2APP_VERSION="0.7.3"
PYTEST_VERSION = "4.6.5"
PYTEST_XDIST_VERSION = "1.29.0"
SCIKIT_LEARN_VERSION = "0.20.2"
SCIPY_VERSION = "1.2.1"
SEND2TRASH_VERSION = "1.5.0"
SIX_VERSION = "1.12.0"
SPHINX_VERSION = "1.8.4" # for documentation
TABULATE_VERSION = "0.8.3"
TQDM_VERSION = "4.23.4"
PSUTIL_VERSION = "5.5.1"

# HDF5
BASE_HDF5_PKG_URL = "https://support.hdfgroup.org/ftp/HDF5/releases/hdf5-1.10/hdf5-1.10.5/src/"
HDF5_PKG = "hdf5-1.10.5.tar.bz2"

# GUI dependencies
LIBPNG_PKG = "libpng-1.6.36.tar.gz"
FREETYPE_PKG = "freetype-2.6.3.tar.gz"

# Linux-only
# libraries based on X11R7.7 (http://www.x.org/releases/X11R7.7/src/everything/)
WXPYTHON_PKG = "wxPython-src-3.0.2.0.tar.bz2"
GETTEXT_PKG = "gettext-0.19.7.tar.gz"
LIBFFI_PKG = "libffi-3.2.1.tar.gz"
GLIB_PKG = "glib-2.46.2.tar.gz"
EXPAT_PKG = "expat-2.1.0.tar.gz"
FONTCONFIG_PKG = "fontconfig-2.11.1.tar.gz"
RENDER_PKG = "renderproto-0.11.1.tar.gz"
XRENDER_PKG = "libXrender-0.9.7.tar.gz"
XFT_PKG = "libXft-2.3.2.tar.gz"

CAIRO_PKG = "cairo-1.14.4.tar.gz"
PIXMAN_PKG = "pixman-0.34.0.tar.gz"
HARFBUZZ_PKG = "harfbuzz-1.1.3.tar.gz"
GDK_PIXBUF_PKG = "gdk-pixbuf-2.32.3.tar.gz"
PANGO_PKG = "pango-1.38.1.tar.gz"
ATK_PKG = "atk-2.18.0.tar.gz"
TIFF_PKG = "tiff-4.0.10.tar.gz"
GTK_PKG = "gtk+-2.24.29.tar.gz"
GTK_ENGINE_PKG = "clearlooks-0.6.2.tar.gz"
GTK_THEME_PKG = "gtk_themes.tar.gz"
# end Linux-only
FONT_PKG = "fonts.tar.gz"

MATPLOTLIB_PKG = "matplotlib-2.2.3.tar.gz"
MATPLOTLIB_DEPS = [
  ("subprocess32", "3.5.4"),
  ("backports.functools-lru-cache", "1.6.1"),
  ("kiwisolver", "1.1.0"),
]

PYOPENGL_PKG = "PyOpenGL-3.1.0.tar.gz"

# Windows precompiled compiled base packages
WIN64PYTHON_PKG = "Python2.7.15_x86_64_plus_relocatable.zip"
WIN32PYTHON_PKG = "python2.7.12_x86_32_plus_relocatable.zip"
WIN64HDF5_PKG = "HDF5-1.8.16-win64.zip"
WIN32HDF5_PKG = "HDF5-1.8.16-win32.zip"
VCREDIST64 = "vcredist_x64.exe"
VCREDIST32 = "vcredist_x86.exe"
WINLIBTIFF64 = "libtiff4.0.6x64.zip"
WINLIBTIFF32 = "libtiff4.0.6x32.zip"

# Various dependencies from external repositories, distributed as static
# tarballs (since they are not under active development by us or our
# collaborators)
dependency_tarballs = {
  "scons":  ("http://cci.lbl.gov/hot", "scons_hot.tar.gz"),
}
# External SVN repositories that may be required for certain components of
# CCTBX to work.  This includes forked versions (with minimal changes) of the
# core CCP4 libraries, MUSCLE, and ksDSSP.
subversion_repositories = {
  "ccp4io": "http://cci.lbl.gov/svn/ccp4io/trunk",
  "ccp4io_adaptbx": "http://cci.lbl.gov/svn/ccp4io_adaptbx/trunk",
  "gui_resources": "http://cci.lbl.gov/svn/gui_resources/trunk",
  "tntbx": "http://cci.lbl.gov/svn/tntbx/trunk",
  "ksdssp": "http://cci.lbl.gov/svn/ksdssp/trunk",
  "muscle": "http://cci.lbl.gov/svn/muscle/trunk",
  # adding for amber
  "amber_adaptbx": "http://cci.lbl.gov/svn/amber_adaptbx/trunk",
}

# External GIT repositories that may be required for certain components of
# CCTBX to work. Note that the format for git repositories can be more
# sophisticated than that for SVN, and can include multiple possible sources,
# including .zip archives to fall back on when git is not available, and git
# command line parameters
git_repositories = {
  # lz4 and bitshuffle compressions for HDF5
  # The git repositories are disabled for both on purpose.
  # Reason: Repositories are deprecated and unlikely to change ever again.
  #         We currently patch the local copies of the repositories, which means
  #         that if they are cloned git repositories you cannot run bootstrap on
  #         them again without bootstrap detecting uncommitted changes and
  #         stopping with an error message.
  "hdf5_lz4": [#'git@github.com:dectris/HDF5Plugin.git',
               #'https://github.com/dectris/HDF5Plugin.git',
               'https://github.com/dectris/HDF5Plugin/archive/master.zip'],
  "bitshuffle": [#'git@github.com:kiyo-masui/bitshuffle.git',
                 #'https://github.com/kiyo-masui/bitshuffle.git',
                 'https://github.com/kiyo-masui/bitshuffle/archive/master.zip'],
}

class fetch_packages(object):
  """
  Download manager for the packages defined by this module - this is used by
  install_base_packages.py but also for setting up installer bundles.
  """
  def __init__(self, dest_dir, log, pkg_dirs=None, no_download=False,
      copy_files=False):
    self.dest_dir = dest_dir
    self.log = log
    self.pkg_dirs = pkg_dirs
    self.no_download = no_download
    self.copy_files = copy_files
    self.toolbox = Toolbox()

  def __call__(self,
                pkg_name,
                pkg_url=None,
                output_file=None,
                return_file_and_status=False,
                download_url=None, # If given this is the URL used for downloading, otherwise construct using pkg_url and pkg_name
                ):
    if (pkg_url is None):
      pkg_url = BASE_CCI_PKG_URL
    if (output_file is None):
      output_file = pkg_name
    os.chdir(self.dest_dir)
    print("  getting package %s..." % pkg_name, file=self.log)
    if (self.pkg_dirs is not None) and (len(self.pkg_dirs) > 0):
      for pkg_dir in self.pkg_dirs :
        static_file = op.join(pkg_dir, pkg_name)
        if (op.exists(static_file)):
          print("    using %s" % static_file, file=self.log)
          if self.copy_files :
            copy_file(static_file, op.join(self.dest_dir, output_file))
            if return_file_and_status:
              return op.join(self.dest_dir, output_file), 0
            return op.join(self.dest_dir, output_file)
          else :
            if return_file_and_status:
              return static_file, 0
            return static_file
    if (self.no_download):
      if (op.exists(pkg_name)):
        print("    using ./%s" % pkg_name, file=self.log)
        if return_file_and_status:
          return op.join(self.dest_dir, output_file), 0
        return op.join(self.dest_dir, pkg_name)
      else :
        raise RuntimeError(("Package '%s' not found on local filesystems.  ") %
          pkg_name)

    # Generate list of possible URL candidates
    if download_url:
      if isinstance(download_url, list):
        urls = download_url
      else:
        urls = [download_url]
    else:
      if isinstance(pkg_url, list):
        urls = ["%s/%s" % (p, pkg_name) for p in pkg_url]
      else:
        urls = ["%s/%s" % (pkg_url, pkg_name)]

    for url_attempt in urls:
      self.log.write("    downloading from %s : " % url_attempt)
      for retry in (3,3,0):
        try:
          size = self.toolbox.download_to_file(url_attempt, output_file, log=self.log)
          if (size == -2):
            print("    using ./%s (cached)" % pkg_name, file=self.log)
            if return_file_and_status:
              return op.join(self.dest_dir, output_file), size
            return op.join(self.dest_dir, output_file)
          assert size > 0, "File %s has size %d" % (pkg_name, size)
          if return_file_and_status:
            return op.join(self.dest_dir, output_file), size
          return op.join(self.dest_dir, output_file)
        except Exception as e:
          self.log.write("    download failed with %s" % str(e))
          if retry:
            self.log.write("    retrying in %d seconds" % retry)
            time.sleep(retry)
    raise RuntimeError("Could not download " + pkg_name)

def fetch_all_dependencies(dest_dir,
    log,
    pkg_dirs=None,
    copy_files=True,
    gui_packages=True,
    dials_packages=True):
  """
  Download or copy all dependencies into a local directory (prepping for
  source installer bundling).
  """
  fetch_package = fetch_packages(
    dest_dir=dest_dir,
    log=log,
    pkg_dirs=pkg_dirs,
    copy_files=copy_files)
  for pkg_name in [
      PYTHON_PKG, IMAGING_PKG, REPORTLAB_PKG, ZLIB_PKG,
      PYRTF_PKG, BIOPYTHON_PKG,
      IPYTHON_PKG,
    ] :
    fetch_package(pkg_name)
  if (gui_packages):
    for pkg_name in [
        LIBPNG_PKG, FREETYPE_PKG, GETTEXT_PKG, GLIB_PKG, EXPAT_PKG,
        FONTCONFIG_PKG, RENDER_PKG, XRENDER_PKG, XFT_PKG, PIXMAN_PKG,
        CAIRO_PKG, HARFBUZZ_PKG, PANGO_PKG, ATK_PKG, TIFF_PKG, GTK_PKG,
        GTK_ENGINE_PKG, GTK_THEME_PKG, FONT_PKG, WXPYTHON_PKG,
        MATPLOTLIB_PKG, SEND2TRASH_PKG,
      ] :
      fetch_package(pkg_name)

def fetch_svn_repository(pkg_name, pkg_url=None, working_copy=True,
    delete_if_present=False):
  """
  Download an SVN repository, with or without metadata required for ongoing
  development.
  """
  ## TODO: Merge this with _add_svn in bootstrap.py.
  #        Unnecessary code duplication
  if op.exists(pkg_name):
    if delete_if_present :
      shutil.rmtree(pkg_name)
    else :
      raise OSError("Directory '%s' already exists.")
  if (pkg_url is None):
    pkg_url = optional_repositories[pkg_name]
  if working_copy :
    call("svn co --non-interactive --trust-server-cert %s %s" % (pkg_url, pkg_name), sys.stdout)
  else :
    call("svn export --non-interactive --trust-server-cert %s %s" % (pkg_url, pkg_name), sys.stdout)
  assert op.isdir(pkg_name)

def fetch_git_repository(package, use_ssh):
  """ Download a git repository """
  Toolbox.git(package, git_repositories[package], destination=os.path.join(os.getcwd(), package), use_ssh=use_ssh, verbose=True)
  assert op.isdir(package)

def fetch_remote_package(module_name, log=sys.stdout, working_copy=False, use_ssh=False):
  if (module_name in git_repositories):
    fetch_git_repository(module_name, use_ssh)
  elif (module_name in dependency_tarballs):
    if op.isdir(module_name):
      shutil.rmtree(module_name)
    pkg_url, pkg_name = dependency_tarballs[module_name]
    tarfile = module_name + ".tar.gz"
    fetch_packages(
      dest_dir=os.getcwd(),
      log=log).__call__(
        pkg_name=pkg_name,
        pkg_url=pkg_url,
        output_file=tarfile)
    untar(tarfile, log)
    os.remove(tarfile)
  elif (module_name in subversion_repositories):
    if op.isdir(module_name):
      shutil.rmtree(module_name)
    pkg_url = subversion_repositories[module_name]
    fetch_svn_repository(
      pkg_name=module_name,
      pkg_url=pkg_url,
      working_copy=working_copy)


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/plus_installer.py

# XXX This is not a standalone installer!  It must be used as part of the
# framework in libtbx/auto_build.

"""
Installer script for CCTBX-plus packages based on automatically generated
template.  This must be moved to the proper location to work.
"""

from __future__ import absolute_import, division, print_function

import os.path
import sys
libtbx_path = os.path.join(
  os.path.abspath(os.path.dirname(os.path.dirname(__file__))), "lib")
if (not libtbx_path in sys.path):
  sys.path.append(libtbx_path)
from libtbx.auto_build import install_distribution

from libtbx.auto_build.bootstrap import CCTBXBuilder

class installer(install_distribution.installer):
  # XXX most settings can be edited here
  product_name = "CCTBX"
  dest_dir_prefix = "cctbx"
  make_apps = ["cctbx.image_viewer", "phenix.data_viewer"]
  configure_modules = CCTBXBuilder.LIBTBX
  include_gui_packages = True
  base_package_options = ['--all', "--sphinx", "--ipython"]
  modules = CCTBXBuilder.HOT + CCTBXBuilder.CODEBASES

  installer_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

if (__name__ == "__main__"):
  installer(sys.argv[1:]).install()


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/regenerate_module_files.py
#!/usr/bin/python

from __future__ import absolute_import, division, print_function

import os
import sys

from .installer_utils import *

def _generate_pangorc(base_dir):
  return """
#
# Auto-generated file, do not change
#

[Pango]
ModulesPath = %s/lib/pango/1.6.0/modules/
ModuleFiles = %s/etc/pango/pango.modules

[PangoX]
AliasFiles = %s/etc/pango/pangox.aliases
""" % (base_dir, base_dir, base_dir)


def check_pango(base_dir):
  '''Determine whether there is a consistent pangorc file at this location'''

  try:
    pangorc = os.path.join(base_dir, "etc", "pango", "pangorc")
    if not os.path.isfile(pangorc):
      return False
    pango_file = open(pangorc, 'r')
    settings = pango_file.read()
    pango_file.close()
    if settings != _generate_pangorc(base_dir):
      return False
    return True
  except Exception:
    return False


def fix_pango(base_dir, out):
  '''Fix the pango configuration files'''

  pango_dir = os.path.join(base_dir, "etc", "pango")
  if not os.path.isdir(pango_dir):
    print("%s not present, could not regenerate pango files" % pango_dir, file=out)
    # Should really be an exception, but cannot do that because of buildbot
    return

  # pangorc
  pangorc = os.path.join(pango_dir, "pangorc")
  print("generating pangorc file at %s" % pangorc, file=out)
  open(pangorc, "w").write(_generate_pangorc(base_dir))

  os.environ['PANGO_RC_FILE'] = pangorc

  # pango.modules
  pangomodules = "%s/pango.modules" % pango_dir
  print("generating pango.modules file at %s" % pangomodules, file=out)
  call(("%s/bin/pango-querymodules > %s") % (base_dir, pangomodules), log=out)


def fix_gtk(base_dir, out): #--- Gtk+
  gtk_dir = os.path.join(base_dir, "etc", "gtk-2.0")
  if not os.path.isdir(gtk_dir):
    print("%s not present, could not regenerate gdk-pixbuf.loaders" % gtk_dir, file=out)
    return

  # gtk.immodules
  print("generating gtk.immodules file", file=out)
  call(("%s/bin/gtk-query-immodules-2.0 %s/lib/gtk-2.0/2.10.0/immodules/*.so"
        + "> %s/etc/gtk-2.0/gtk.immodules") % (base_dir, base_dir, base_dir),
        log=out)
  # gdk-pixbuf.loaders
  print("generating gdk-pixbuf.loaders file", file=out)
  call(("%s/bin/gdk-pixbuf-query-loaders %s/lib/gdk-pixbuf-2.0/2.10.0/loaders/*.so"+
        " > %s/lib/gdk-pixbuf-2.0/2.10.0/loaders.cache") % (base_dir, base_dir,
          base_dir), log=out)
  call(("%s/bin/gdk-pixbuf-query-loaders %s/lib/gdk-pixbuf-2.0/2.10.0/loaders/*.so"+
        " > %s/etc/gtk-2.0/gdk-pixbuf.loaders") % (base_dir, base_dir,
          base_dir), log=out)


def fix_fonts(base_dir, out): #--- Fonts
  fonts_share_dir = os.path.join(base_dir, "share", "fonts")
  fonts_etc_dir = os.path.join(base_dir, "etc", "fonts")
  fonts_cache_dir = os.path.join(base_dir, 'var', 'cache', 'fontconfig')
  if not os.path.isdir(fonts_etc_dir):
    print("%s not present, could not rebuild fonts" % fonts_etc_dir, file=out)
    return

  print("updating fonts/local.conf file", file=out)
  fonts_in = open(os.path.join(fonts_share_dir, "local.conf.in"))
  fonts_out = open(os.path.join(fonts_etc_dir, "local.conf"), "w")
  for line in fonts_in.readlines():
    if ('FONTCONFIG_PATH' in line):
      line = line.replace('FONTCONFIG_PATH', fonts_share_dir)
    if ('FONTCACHE_PATH' in line):
      line = line.replace('FONTCACHE_PATH', fonts_cache_dir)
    fonts_out.write(line)
  fonts_in.close()
  fonts_out.close()

  os.environ['FONTCONFIG_PATH'] = fonts_etc_dir

  try:
    print("running mkfontscale/mkfontdir on %s" % fonts_share_dir, file=out)
    call("mkfontscale %s" % fonts_share_dir, log=out)
    call("mkfontdir %s" % fonts_share_dir, log=out)
    print("rebuilding font cache", file=out)
    call("%s/bin/fc-cache -v %s" % (base_dir, fonts_share_dir), log=out)
  except Exception:
    print("rebuilding fonts failed", file=out)
    pass


def fix_themes(base_dir, out): #--- Themes
  share_dir = os.path.join(base_dir, "share")
  if not os.path.isdir(share_dir):
    print("problem with installation, could not make index.theme file", file=out)
    return

  print("generating index.theme file", file=out)
  hicolor_dir = os.path.join(share_dir, "icons", "hicolor")
  try:
    os.makedirs(hicolor_dir)
  except Exception:
    pass
  open(os.path.join(hicolor_dir, "index.theme"), "w").write("""
#
# Auto-generated, do not change'
#
[Icon Theme]
Name=Hicolor
Comment=Fallback icon theme
Hidden=true
Directories=48x48/filesystems

[48x48/filesystems]
Size=48
Context=FileSystems
Type=Threshold
""")


def run(base_dir, out=sys.stdout, only_if_needed=False):
  if only_if_needed and check_pango(base_dir):
    return

  if not sys.platform.startswith('linux'):
    print("This script is only applicable to Linux - exiting.", file=out)
    return

  print("Regenerating module files in %s" % base_dir, file=out)
  if not os.path.exists(base_dir):
    if only_if_needed:
      print("Base directory '%s' does not exist." % base_dir, file=out)
      print("  Assuming base-less installation, skipping module file regeneration", file=out)
      return
    raise OSError("Base directory '%s' does not exist." % base_dir)

  fix_pango(base_dir, out)
  fix_gtk(base_dir, out)
  fix_fonts(base_dir, out)
  fix_themes(base_dir, out)


if (__name__ == "__main__"):
  from optparse import OptionParser
  import libtbx.load_env

  default_location = libtbx.env.under_base('.')

  parser = OptionParser(
    description="Generate new config files for various third-party modules " +
      "required for the graphical interface (if any).")
  parser.add_option("--base_dir", dest="base_dir", action="store",
    help="Base directory of the CCTBX installation (%s)" % default_location, default=default_location)
  parser.add_option("--check", dest="check", action="store_true",
    help="Only run if current files are not consistent", default=False)

  options, args = parser.parse_args(sys.argv[1:])
  run(options.base_dir, only_if_needed=options.check)


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/rpath.py
"""Fix RPATH and ORIGIN for relocatable binaries."""
from __future__ import absolute_import, division, print_function

import optparse
import os
import re
import subprocess
import sys

import six

# This code is partially derived from a similar module I wrote
# for EMAN2, previously released under a BSD-like license.

# Binary builds: /net/cci/auto_build/phenix_installers
# export DYLD_PRINT_INITIALIZERS="files"
# For Linux, requires PatchELF.
#   http://nixos.org/patchelf.html
# For Mac, requires otool and install_name_tool,
#   which are included with XCode.

# Ugh
DRY_RUN = False

##### Helper functions #####

def find_exec(root='.'):
  """Find executables (using +x permissions)."""
  # find . -type f -perm +111 -print
  p = check_output(['find', root, '-type', 'f', '-perm', '+111'])
  # unix find may print empty lines; strip those out.
  found = filter(None, [i.strip() for i in p.split("\n")])
  # Filter by real execuable...
  found_exec = []
  for f in found:
    try:
      p = check_output(['file', f])
    except subprocess.CalledProcessError:
      p = ''
    if "Mach-O" in p:
      found_exec.append(f)
  return found_exec

def find_ext(ext='', root='.'):
  """Find files with a particular extension. Include the ".", e.g. ".txt". """
  found = []
  for root, dirs, files in os.walk(root):
    found.extend([os.path.join(root, i) for i in files if i.endswith(ext)])
  return found

def cmd(*popenargs, **kwargs):
  print("Running:", end=' ')
  print(" ".join(*popenargs))
  if DRY_RUN:
    return
  ignorefail = kwargs.pop('ignorefail', False)
  kwargs['stdout'] = subprocess.PIPE
  kwargs['stderr'] = subprocess.PIPE
  process = subprocess.Popen(*popenargs, **kwargs)
  a, b = process.communicate()
  exitcode = process.wait()
  if exitcode:
    if ignorefail:
      print("WARNING: Command returned non-zero exit code: %s"%" ".join(*popenargs))
      print(a)
      print(b)
    else:
      print(a)
      print(b)
      raise Exception("Command returned non-zero exit code")

def echo(*popenargs, **kwargs):
    print("Running:", end=' ')
    print(" ".join(*popenargs))

# "Dry-run"
# cmd = echo

def check_output(*popenargs, **kwargs):
  """Copy of subprocess.check_output()"""
  if 'stdout' in kwargs:
    raise ValueError('stdout argument not allowed, it will be overridden.')
  process = subprocess.Popen(stdout=subprocess.PIPE, *popenargs, **kwargs)
  output, unused_err = process.communicate()
  retcode = process.poll()
  if retcode:
    cmd = kwargs.get("args")
    if cmd is None:
      cmd = popenargs[0]
    raise subprocess.CalledProcessError(retcode, cmd)
  if six.PY3:
    return output.decode("latin-1")
  return output

class FixLinuxRpath(object):
  def find_deps(self, filename):
    ret = []
    p = check_output(['ldd', filename])
    for line in p.split("\n"):
      fields = line.partition("=>")
      try:
        lib, found = fields[0], fields[2]
        if "not found" in found:
          ret.append(lib.strip())
      except Exception as e:
        print("PARSER ERROR:", e)
        print(fields)
    return ret

  def run(self, root, replace=None):
    replace = replace or {}
    targets = set()
    targets |= set(find_ext('.so', root=root))
    # targets |= set(find_exec(root=root))

    # First pass: get all directories.
    origins = {}
    for target in sorted(targets):
      origins[os.path.basename(target)] = os.path.dirname(target)

    # Second pass: find linked libraries, add rpath's
    for target in sorted(targets):
      print("\n\n====", target)
      deps = self.find_deps(target)
      rpath = set()
      # Find a matching library...
      for dep in deps:
        found = [i for i in origins if i in dep]
        # print dep, found, map(origins.get, found)
        for i in found:
          relpath = os.path.relpath(origins[i], os.path.dirname(target))
          relpath = os.path.join('$ORIGIN', relpath)
          rpath.add(relpath)

      if rpath:
        cmd(['patchelf', '--set-rpath', ":".join(rpath), target])

class FixMacRpath(object):
  """Process all binary files (executables, libraries) to rename linked libraries."""

  def find_deps(self, filename):
    """Find linked libraries using otool -L."""
    p = check_output(['otool','-L',filename])
    # otool doesn't return an exit code on failure, so check..
    if "not an object file" in p:
      raise Exception("Not Mach-O binary")
    # Just get the dylib install names
    p = [i.strip().partition(" ")[0] for i in p.split("\n")[1:]]
    return p

  def id_rpath(self, filename):
    """Generate the @rpath for a file, relative to the current directory as @rpath root."""
    p = len(filename.split("/"))-1
    f = os.path.join("@loader_path", *[".."]*p)
    return f

  def run(self, root, replace=None):
    replace = replace or {}
    replace[root] = '@rpath'
    # Find all files that end in .so/.dylib
    targets = set()
    targets |= set(find_ext('.so', root=root))
    targets |= set(find_ext('.dylib', root=root))
    # Find all executable, binary (Mach-O) files.
    targets |= set(find_exec(root=root))

    print("Targets:", len(targets))
    for f in sorted(targets):
      # Get the linked libraries and
      # check if the file is a Mach-O binary
      print("\n==== Target:", f)
      try:
        libs = self.find_deps(f)
      except Exception:
        continue

      # Set the install_name id.
      install_name_id = os.path.join('@rpath', os.path.relpath(f, root))
      cmd(['install_name_tool', '-id', install_name_id, f], cwd=root, ignorefail=True)

      # Set @rpath, this is a reference to the root of the package.
      # Linked libraries will be referenced relative to this.
      rpath = os.path.join('@loader_path', os.path.relpath(root, os.path.dirname(f)))
      cmd(['install_name_tool', '-add_rpath', rpath, f], cwd=root, ignorefail=True)

      for lib in libs:
        rlib = lib
        for k,v in replace.items():
          rlib = re.sub(k, v, rlib)
        if lib != rlib:
          cmd(['install_name_tool', '-change', lib, rlib, f], cwd=root, ignorefail=True)

def run(args):
  parser = optparse.OptionParser()
  parser.add_option("--otherroot", help="Other build path")
  parser.add_option("--dry", help="Dry run", action="store_true")
  options, args = parser.parse_args(args)

  if options.dry:
    DRY_RUN = True

  # Setup args.
  root = os.path.abspath(args[-1]) # needs absolute path
  replace = {}
  replace['^lib'] = '@rpath/lib'
  if options.otherroot:
    replace[options.otherroot] = '@rpath'

  # Run the rpath fixer.
  cls = FixLinuxRpath
  if sys.platform == 'darwin':
    cls = FixMacRpath
  cls().run(root=root, replace=replace)

if __name__ == "__main__":
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/setup_installer.py
#!/usr/bin/python

"""
Script to set up an installer directory tree and copy over most of the
necessary files.  We used to just keep the entire (Phenix) installer in a
separate SVN tree, but this is inconvenient when we have multiple packages
using the same system and also many third-party dependencies which need to be
kept up to date.  Note that this script provides only the bare minimum
functionality for building CCTBX installers, and other distributions will
probably need to perform additional modifications to the installer tree
before it can be tarred.
"""

from __future__ import absolute_import, division, print_function
from optparse import OptionParser
import os.path as op
import shutil
import time
import stat
import os
import sys
# XXX HACK
libtbx_path = op.abspath(op.dirname(op.dirname(__file__)))
if (not libtbx_path in sys.path):
  sys.path.append(libtbx_path)
from .installer_utils import *
from .package_defs import *

def run(args):
  parser = OptionParser()
  parser.add_option("--version", dest="version", action="store",
    help="Package version", default=time.strftime("%Y_%m_%d",time.localtime()))
  parser.add_option("--binary", dest="binary", action="store_true",
    help="Setup for binary installer only (no source packages)", default=False)
  parser.add_option("--pkg_dir", dest="pkg_dirs", action="append",
    help="Directory with source packages", default=None)
  parser.add_option("--basic", dest="basic", action="store_true",
    help="Only include basic prerequisite packages", default=False)
  parser.add_option("--xia2", dest="xia2", action="store_true",
    help="Include xia2 dependencies", default=False)
  parser.add_option("--dials", dest="dials", action="store_true",
    help="Include DIALS dependencies", default=False)
  parser.add_option("--gui", dest="gui", action="store_true",
    help="Include GUI dependencies", default=False)
  parser.add_option("-a", "--all", dest="all", action="store_true",
    help="Include all recommended dependencies", default=False)
  parser.add_option("--dest", dest="dest", action="store",
    help="Destination folder", default=os.getcwd())
  parser.add_option("--readme", dest="readme", action="append",
    help="Readme file", default=[])
  parser.add_option("--license", dest="license", action="store",
    help="License file", default=op.join(libtbx_path, "LICENSE_2_0.txt"))
  parser.add_option("--script", dest="install_script",
    help="Final installation script", default=None, metavar="FILE")
  parser.add_option("--modules", dest="modules", action="store",
    help="Local modules to include", default=None)
  parser.add_option("--base-modules", dest="base_modules", action="store",
    help="Additional local modules placed in base/ directory", default=None)
  parser.add_option("--product_name", dest="product_name", action="store",
    help="Name of installed package", default=None)
  parser.add_option("--cctbx_bundle", dest="cctbx_bundle", action="store",
    help="Path to CCTBX installer bundle (if not downloaded)", default=None)
  parser.add_option("--bin-dir", dest="bin_dir", action="store",
    help="Directory containing additional binaries/scripts", default=None)
  options, args_ = parser.parse_args(args=args)
  assert len(args_) == 1
  package_name = args_[-1]
  if (options.product_name is None):
    options.product_name = package_name
  if (options.install_script is not None):
    assert op.isfile(options.install_script)
    options.install_script = op.abspath(options.install_script)
  module_list = options.modules
  base_module_list = options.base_modules
  os.chdir(options.dest)

  # setup directory structure
  installer_dir = "%s-installer-%s" % (package_name, options.version)
  print("Installer will be %s" % installer_dir)
  os.mkdir(installer_dir)
  os.chdir(installer_dir)
  os.mkdir("bin")
  os.mkdir("lib")
  if (not options.binary):
    os.mkdir("source")
    os.mkdir("dependencies")

  # copy 'binary' programs if defined
  if options.bin_dir :
    assert op.isdir(options.bin_dir)
    for file_name in os.listdir(options.bin_dir):
      if (file_name == ".svn") : continue
      full_path = op.join(options.bin_dir, file_name)
      copy_file(full_path, op.join("bin", file_name))

  # copy over libtbx
  lib_dir = op.join(os.getcwd(), "lib")
  shutil.copytree(libtbx_path, op.join(lib_dir, "libtbx"))
  find_and_delete_files(lib_dir, file_ext=".pyc")
  find_and_delete_files(lib_dir, file_name=".svn")

  # write VERSION
  open("VERSION", "w").write(options.version)
  if options.readme :
    for file_name in options.readme :
      if op.isfile(file_name):
        base_name = op.basename(file_name)
        print("copying %s" % base_name)
        open(base_name, "w").write(open(file_name).read())
  else : # fallback to CCTBX copyright
    file_name = op.join(libtbx_path, "COPYRIGHT_2_0.txt")
    open("README", "w").write(open(file_name).read())
  if op.isfile(options.license):
    open("LICENSE", "w").write(open(options.license).read())
  os.chdir(op.join(options.dest, installer_dir))

  # actual Python installer script
  if (options.install_script is not None):
    assert op.isfile(options.install_script)
    open("bin/install.py", "w").write(open(options.install_script).read())
  else :
    print("WARNING: using default installation script")
    # default stub.  this is pretty minimal but it will work for simple
    # packages.
    modules_list = []
    if (options.modules is not None):
      modules_list = options.modules.split(",")
    base_package_options = []
    if (options.gui or options.all):
      base_package_options.append("--gui")
    if (options.dials or options.all or options.xia2):
      base_package_options.append("--dials")
    f = open("bin/install.py", "w")
    f.write("""\
import os.path
import sys
libtbx_path = os.path.join(
  os.path.abspath(os.path.dirname(os.path.dirname(__file__))), "lib")
if (not libtbx_path in sys.path):
  sys.path.append(libtbx_path)
from libtbx.auto_build import install_distribution

class installer(install_distribution.installer):
  product_name = "%(product)s"
  dest_dir_prefix = "%(pkg)s"
  make_apps = []
  configure_modules = install_distribution.installer.configure_modules + \\
    %(modules)s
  include_gui_packages = %(gui)s
  base_package_options = %(baseopts)s
  source_packages = [ "cctbx_bundle" ] + %(modules)s

  installer_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

if (__name__ == "__main__"):
  installer(sys.argv[1:])
""" % { "pkg" : package_name, "product" : options.product_name,
        "modules" : modules_list, "baseopts" : base_package_options,
        "gui" : (options.gui or options.all) })
    f.close()

  # write executable Bash script wrapping Python script
  f = open("install", "w")
  f.write("""\
#!/bin/bash
#
#

UNAME=`uname`
if [ -z "$PYTHON_EXE" ]; then
  PYTHON_EXE='/usr/bin/python'
  if [ -f "/usr/bin/python2.7" ]; then
    PYTHON_EXE='/usr/bin/python2.7'
  elif [ -f "/usr/bin/python2.6" ]; then
    PYTHON_EXE='/usr/bin/python2.6'
  elif [ -f "/usr/bin/python2" ]; then
    PYTHON_EXE='/usr/bin/python2'
  fi
fi
$PYTHON_EXE ./bin/install.py $@
""")
  f.close()
  st = os.stat("install")
  os.chmod("install", st.st_mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)

  #
  have_modules = []
  def get_module(module_name):
    for pkg_dir in options.pkg_dirs :
      dist_dir = op.join(pkg_dir, module_name)
      tarfile = op.join(pkg_dir, module_name + "_hot.tar.gz")
      if op.exists(tarfile):
        print("using module '%s' from %s" % (module_name, tarfile))
        copy_file(tarfile, module_name + ".tar.gz")
        have_modules.append(module_name)
        break
      elif op.isdir(dist_dir):
        print("using module '%s' from %s" % (module_name, dist_dir))
        archive_dist(dist_dir)
        assert op.isfile(module_name + ".tar.gz")
        have_modules.append(module_name)
        break

  if (not options.binary):
    print("")
    print("********** FETCHING DEPENDENCIES **********")
    print("")
    fetch_all_dependencies(
      dest_dir=op.join(options.dest, installer_dir, "dependencies"),
      log=sys.stdout,
      pkg_dirs=options.pkg_dirs,
      gui_packages=(options.dials or options.gui or options.all),
      dials_packages=(options.dials or options.xia2 or options.all))
    # local packages
    fetch_package = fetch_packages(
      dest_dir=op.join(options.dest, installer_dir, "source"),
      log=sys.stdout,
      pkg_dirs=options.pkg_dirs,
      copy_files=True)
    os.chdir(op.join(options.dest, installer_dir, "source"))
    if (options.cctbx_bundle is None):
      fetch_package(
        pkg_name="cctbx_bundle_for_installer.tar.gz",
        pkg_url="http://cci.lbl.gov/build/results/current")
      os.rename("cctbx_bundle_for_installer.tar.gz", "cctbx_bundle.tar.gz")
    else :
      assert op.isfile(options.cctbx_bundle)
      copy_file(options.cctbx_bundle, "cctbx_bundle.tar.gz")
    if (module_list is not None):
      print("")
      print("********** FETCHING MODULES **********")
      print("")
      module_list = re.sub(",", " ", module_list)
      for module_name in module_list.split():
        get_module(module_name)

  # Additional modules that are included in both the source and the binary
  # installer - in Phenix this includes restraints, examples, documentation,
  # and regression tests
  if (base_module_list is not None):
    base_module_dir = op.join(options.dest, installer_dir, "base")
    os.makedirs(base_module_dir)
    os.chdir(base_module_dir)
    base_module_list = re.sub(",", " ", base_module_list)
    for module_name in base_module_list.split():
      get_module(module_name)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/write_gui_dispatcher_include.py
#!/usr/bin/python

from __future__ import absolute_import, division, print_function

import os.path
import sys
from optparse import OptionParser

def run(args, prologue=None, epilogue=None, out=sys.stdout):
  parser = OptionParser(
    description="Generate the dispatcher include file for using "+
      "locally installed GUI (and related) libraries.  (Used in Phenix "+
      "installer and binary cctbx_plus builds.)")
  parser.add_option("--suffix", dest="suffix", action="store",
    help="Suffix for dispatcher_include file", default="gui")
  parser.add_option("--build_dir", dest="build_dir", action="store",
    help="Build directory (and dispatcher destination)", default=os.getcwd())
  parser.add_option("--prologue", dest="prologue", action="store",
    help="Additional dispatcher include to prepend")
  parser.add_option("--epilogue", dest="epilogue", action="store",
    help="Additional dispatcher include to append")
  parser.add_option("--base_dir", dest="base_dir", action="store",
    help="Directory for base packages (Python etc.)", default=None)
  parser.add_option("--ignore_missing_dirs", dest="ignore_missing_dirs",
    action="store_true", help="Don't raise error if GTK paths don't exist")
  parser.add_option("--quiet", action="store_true")
  parser.add_option("--use_conda", dest="use_conda", action="store_true",
    help="Use conda dependencies")
  # this is detached in case we need to upgrade GTK - setting GTK_PATH is
  # essential for the themes to be used correctly
  parser.add_option("--gtk_version", dest="gtk_version", action="store",
    help="Version number (major.minor.rev) for GTK+", default="2.10.0")
  options, args = parser.parse_args(args)
  build_path = options.build_dir
  if (not os.path.isdir(build_path)):
    raise OSError("The specified build directory (%s) does not exist." %
      build_path)
  build_path = os.path.abspath(build_path)
  base_path = options.base_dir
  if (base_path is None):
    base_path = os.path.join(build_path, "base")
  if (not os.path.isdir(base_path)):
    raise OSError("%s does not exist." % base_path)
  base_path = os.path.abspath(base_path)
  ld_library_paths = [ os.path.join(base_path, "lib"), ]
  if (sys.platform.startswith('linux')):
    lib64_path = os.path.join(base_path, "lib64")
    if (os.path.isdir(lib64_path)):
      ld_library_paths.append(lib64_path)
  dyld_library_paths = ld_library_paths
  if not options.use_conda and sys.platform == "darwin":
    dyld_library_paths += [
    os.path.join(base_path,"Python.framework","Versions","Current","lib"), ]
  check_libs = ld_library_paths
  if (sys.platform == "darwin") : check_libs = dyld_library_paths
  if sys.platform != "win32":
    for lib_dir in check_libs :
      if (not os.path.isdir(lib_dir)):
        raise OSError("%s does not exist." % lib_dir)
  gtk_path = os.path.join(base_path, "lib", "gtk-2.0", options.gtk_version)
  if ((sys.platform.startswith("linux")) and
      (not os.path.isdir(gtk_path)) and
      (not options.ignore_missing_dirs)):
    raise OSError("The path for the specified version of GTK+ does not "+
      "exist (%s)." % gtk_path)
  dispatcher = os.path.join(build_path, "dispatcher_include_%s.sh" %
    options.suffix)
  if sys.platform == "win32":
    dispatcher = os.path.join(build_path, "dispatcher_include_%s.bat" %
      options.suffix)
  f = open(dispatcher, "w")
  if (prologue is not None):
    f.write(prologue + "\n")
  if (options.prologue is not None):
    if not os.path.exists(options.prologue) and options.prologue.find("\n")>-1:
      f.write("%s\n" % options.prologue)
    else:
      f.write(open(options.prologue).read() + "\n")
  if sys.platform != "win32" and not options.use_conda:
    print("""\
# include at start
if [ "$LIBTBX_DISPATCHER_NAME" != "libtbx.scons" ] && \
   [ -z "$PHENIX_TRUST_OTHER_ENV" ]; then
  # work around broken library environments
  LD_LIBRARY_PATH=""
  PYTHONPATH=""
fi
# include before command
#
# GUI dependencies
CCTBX_BUILD_BASE="%s"
LIBTBX_OS_NAME=`uname -s`
if [ "$PHENIX_GUI_ENVIRONMENT" = "1" ]; then
  if [ -z "$DISABLE_PHENIX_GUI" ]; then
    export BOOST_ADAPTBX_FPE_DEFAULT=1
    export BOOST_ADAPTBX_SIGNALS_DEFAULT=1
  fi
  # echo $LIBTBX_OS_NAME
  if [ "$LIBTBX_OS_NAME" = "Linux" ]; then
    export OLD_LD_LIBRARY_PATH=$LD_LIBRARY_PATH
    export OLD_XDG_DATA_DIRS=$XDG_DATA_DIRS
    if [ -z "$LD_LIBRARY_PATH" ]; then
      LD_LIBRARY_PATH=%s
    else
      LD_LIBRARY_PATH=%s:$LD_LIBRARY_PATH
    fi
    export LD_LIBRARY_PATH
#
    unset GTK_MODULES
    GTK_PATH=$CCTBX_BUILD_BASE/lib/gtk-2.0/%s
    PANGO_RC_FILE=$CCTBX_BUILD_BASE/etc/pango/pangorc
    GTK_IM_MODULE_FILE=$CCTBX_BUILD_BASE/etc/gtk-2.0/gtk.immodules
    GDK_PIXBUF_MODULE_FILE=$CCTBX_BUILD_BASE/etc/gtk-2.0/gdk-pixbuf.loaders
    GTK2_RC_FILES=$CCTBX_BUILD_BASE/share/themes/Clearlooks/gtk-2.0/gtkrc
    FONTCONFIG_PATH=$CCTBX_BUILD_BASE/etc/fonts
    FONTCONFIG_FILE=$CCTBX_BUILD_BASE/etc/fonts/fonts.conf
    if [ -z "$XDG_DATA_DIRS" ]; then
      XDG_DATA_DIRS=$CCTBX_BUILD_BASE/share:/usr/share
    else
      XDG_DATA_DIRS=$CCTBX_BUILD_BASE/share:$XDG_DATA_DIRS
    fi
    GNOME_DISABLE_CRASH_DIALOG=1
    export PANGO_RC_FILE
    export GTK_IM_MODULE_FILE
    export GDK_PIXBUF_MODULE_FILE
    export FONTCONFIG_PATH
    export FONTCONFIG_FILE
    export XDG_DATA_DIRS
    export GTK_PATH
    export GTK2_RC_FILES
    export GNOME_DISABLE_CRASH_DIALOG
    PATH=$CCTBX_BUILD_BASE/bin:$PATH
    export PATH
  fi
fi
""" % (base_path, ":".join(ld_library_paths), ":".join(ld_library_paths), options.gtk_version), file=f)
  # restore some variables for conda
  if sys.platform != "win32" and options.use_conda:
    print("""
# include at start
if [ "$LIBTBX_DISPATCHER_NAME" != "libtbx.scons" ] && \
   [ -z "$PHENIX_TRUST_OTHER_ENV" ]; then
  # work around broken library environments
  LD_LIBRARY_PATH=""
  DYLD_LIBRARY_PATH=""
  DYLD_FALLBACK_LIBRARY_PATH=""
  PYTHONPATH=""
fi
# include before command
if [ "$PHENIX_GUI_ENVIRONMENT" = "1" ]; then
  if [ -z "$DISABLE_PHENIX_GUI" ]; then
    export BOOST_ADAPTBX_FPE_DEFAULT=1
    export BOOST_ADAPTBX_SIGNALS_DEFAULT=1
  fi
fi
""", file=f)
  # QBio DivCon paths
  if sys.platform != "win32":
    print("""
if [ ! -z "$QB_PYTHONPATH" ]; then
  export PYTHONPATH=$PYTHONPATH:$QB_PYTHONPATH
fi
if [ ! -z "$QB_LD_LIBRARY_PATH" ]; then
  export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$QB_LD_LIBRARY_PATH
fi
if [ ! -z "$QB_DYLD_LIBRARY_PATH" ]; then
  export DYLD_LIBRARY_PATH=$DYLD_LIBRARY_PATH:$QB_DYLD_LIBRARY_PATH
fi
""", file=f)
  if (epilogue is not None):
    f.write(epilogue + "\n")
  if (options.epilogue is not None):
    f.write(open(options.epilogue).read() + "\n")
  f.close()
  if (not options.quiet):
    print("Wrote %s" % dispatcher, file=out)
    print("You should now run libtbx.refresh to regenerate dispatchers.", file=out)

# obsolete???
pymol_paths = """
 if [ "$PHENIX_MTYPE" != "mac-ppc-osx" ] && \
    [ "$PHENIX_MTYPE" != "mac-intel-osx" ] && \
    [ "$PHENIX_MTYPE" != "mac-intel-osx-x86_64" ]; then
   export PYMOL_PATH=$PHENIX/pymol
 fi
"""

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/binary_search.py
from __future__ import absolute_import, division, print_function

class true_false_bad_biased_up(object):
  """
Example application: binary search in svn history, with handling
of "bad" revisions that do not build.

Example callback:

  def callback(point):
    bad_points = set([3,8,10])
    critical_point = 7
    if (point in bad_points): return None
    return (point < critical_point)

The initial low point is assumed to be True, the initial high point
is assumed to be False; these assumptions are not verified, i.e.
callback is never called with point=low or point=high.

Illustration of binary search steps in region with bad points:
  T . . . . . . . F
  T . . . B . . . F
  T . . . B . B . F
  T . . . B . B B F
  T . . . B . B b F
  T . . . B . b b F
  T . . . B B b b F
  T . . . B b b b F
  T . . . b b b b F
  T . B . b b b b F
  T . B B b b b b F
  T . B b b b b b F
  T . b b b b b b F
  T B b b b b b b F
  T b b b b b b b F
Each row shows the state at a step of the search.
Each column is for a search point (e.g. svn revision).
T = point known to be True
F = point known to be False
. = point not tried yet
B = point known to be bad (e.g. the True/False decision cannot be made)
b = point known to be bad and contiguously preceding F or b

In the algorithm below, T and B are stored in the i_true_or_bad list.
This reflects that bad points are initially treated as if they were
True. If the binary search converges with a bad point preceding a False
one, the bad point is reinterpreted as False. The final result is the
last point certain to be True and the first point certain to be False.
All revisions in between, if any, are known to be bad.
"""

  __slots__ = [
    "low", "high", "bad_points", "high_point_true", "low_point_false",
    "number_of_iterations", "number_of_callbacks", "bad_gap_width"]

  def __init__(O, low, high, callback, known_bad_points=()):
    assert low < high
    O.low = low
    O.high = high
    O.bad_points = set(known_bad_points)
    i_true_or_bad = [low]
    O.low_point_false = i_false_or_bad = high
    O.number_of_iterations = 0
    O.number_of_callbacks = 0
    while (i_true_or_bad[0] + 1 != i_false_or_bad):
      if (i_true_or_bad[-1] + 1 == i_false_or_bad):
        i_false_or_bad = i_true_or_bad.pop()
      else:
        i_trial = i_true_or_bad[-1] + (i_false_or_bad - i_true_or_bad[-1]) // 2
        O.number_of_iterations += 1
        if (i_trial in O.bad_points):
          cb_result = None
        else:
          cb_result = callback(i_trial)
          O.number_of_callbacks += 1
          if (cb_result is None):
            O.bad_points.add(i_trial)
        if (cb_result is None):
          i_true_or_bad.append(i_trial)
        elif (cb_result):
          i_true_or_bad = [i_trial]
        else:
          del i_true_or_bad[1:]
          O.low_point_false = i_false_or_bad = i_trial
    assert len(i_true_or_bad) == 1
    O.high_point_true = i_true_or_bad[0]
    O.bad_gap_width = O.low_point_false - O.high_point_true - 1


 *******************************************************************************


 *******************************************************************************
libtbx/bundle/__init__.py


 *******************************************************************************


 *******************************************************************************
libtbx/bundle/copy_all.py
from __future__ import absolute_import, division, print_function
from libtbx.bundle import copy_runtime_sources
from libtbx.bundle import copy_build_libtbx
import sys

def run(prefix):
  copy_runtime_sources.run(prefix+"_sources")
  copy_build_libtbx.run(prefix+"_build")

if (__name__ == "__main__"):
  assert len(sys.argv) == 2
  run(sys.argv[1])


 *******************************************************************************


 *******************************************************************************
libtbx/bundle/copy_build_libtbx.py
from __future__ import absolute_import, division, print_function
import libtbx.bundle.utils
import libtbx.load_env
import libtbx.path
import shutil
import sys, os

def copy_lib_and_exe_files(target_root_dir, dirname, names):
  create_target_dir = True
  for file_name in names:
    name = file_name.lower()
    if (   name == ".sconsign"
        or name.endswith(".pyc")
        or name.endswith(".lib")
        or name.endswith(".exp")
        or name.endswith(".a")):
      continue
    src = os.path.normpath(os.path.join(dirname, file_name))
    if (os.path.isdir(src)): continue
    dest = os.path.normpath(os.path.join(target_root_dir, src))
    if (create_target_dir):
      libtbx.path.create_target_dir(dest)
      create_target_dir = False
    shutil.copy(src, dest)

def copy_base_files(target_root_dir, dirname, names):
  create_target_dir = True
  for file_name in names:
    name = file_name.lower()
    if (name.endswith(".pyc")):
      continue
    src = os.path.normpath(os.path.join(dirname, file_name))
    if (os.path.isdir(src)): continue
    dest = os.path.normpath(os.path.join(target_root_dir, src))
    if (create_target_dir):
      libtbx.path.create_target_dir(dest)
      create_target_dir = False
    shutil.copy(src, dest)

def run(target_root):
  cwd = os.getcwd()
  abs_target_root = os.path.normpath(os.path.abspath(target_root))
  def copy_sub_dir(sub_dir, visitor):
    source_dir = libtbx.env.under_build(sub_dir)
    if (os.path.isdir(source_dir)):
      target_dir = libtbx.path.norm_join(abs_target_root, sub_dir)
      os.chdir(source_dir)
      for root, dirs, files in os.walk("."):
        visitor(target_dir, root, files)
  for sub_dir,visitor in (("lib", copy_lib_and_exe_files),
                          ("exe", copy_lib_and_exe_files),
                          ("base", copy_base_files)):
    copy_sub_dir(sub_dir=sub_dir, visitor=visitor)
  for module in libtbx.env.module_list:
    for name in module.names:
      copy_sub_dir(
        sub_dir=os.path.join(name, "exe"),
        visitor=copy_lib_and_exe_files)
  libtbx.bundle.utils.write_bundle_info(
    abs_target_root, write_build_options=True)
  file_name = "command_version_suffix"
  src = libtbx.env.under_build(file_name)
  if (os.path.isfile(src)):
    shutil.copy(src, libtbx.path.norm_join(abs_target_root, file_name))
  os.chdir(cwd)

if (__name__ == "__main__"):
  assert len(sys.argv) == 2
  run(sys.argv[1])


 *******************************************************************************


 *******************************************************************************
libtbx/bundle/copy_runtime_sources.py
from __future__ import absolute_import, division, print_function
import libtbx.bundle.utils
import libtbx.load_env
import libtbx.path
import re
import shutil
import sys, os

def copy_dist_files(bundle_options, dirname, names):
  (exclude_from_binary_bundle, dist_copy) = bundle_options
  create_target_dir = True
  names_keep = []
  for file_name in names:
    name = file_name.lower()
    def name_is_sub_dir_with_file(sub_dir, file_in_subdir):
      if (sub_dir != name): return False
      path = os.path.join(dirname, name)
      if (not os.path.isdir(path)): return False
      path = os.path.join(path, file_in_subdir)
      return os.path.isfile(path)
    if (   name_is_sub_dir_with_file("cvs", "Entries")
        or name_is_sub_dir_with_file(".svn", "README.txt")
        or name_is_sub_dir_with_file(".svn", "entries")):
      continue
    names_keep.append(file_name)
    if (name.startswith(".")): continue
    if (name == "sconscript"): continue
    if (name.startswith("makefile")): continue
    if (name.endswith(".exe") and os.name != "nt"): continue
    for ext in [".pyc", ".pyo", ".h", ".c", ".hpp", ".cpp", ".cc", ".f"]:
      if (name.endswith(ext)):
        break
    else:
      src = libtbx.path.norm_join(dirname, file_name)
      if (os.path.isdir(src)): continue
      for pattern in exclude_from_binary_bundle:
        if (re.search(pattern, src) is not None):
          break
      else:
        dest = libtbx.path.norm_join(dist_copy, src)
        if (create_target_dir):
          libtbx.path.create_target_dir(dest)
          create_target_dir = False
        shutil.copy(src, dest)
  if (len(names_keep) != len(names)):
    del names[:]
    names.extend(names_keep)

def run(target_root):
  cwd = os.getcwd()
  abs_target_root = os.path.normpath(os.path.abspath(target_root))
  for module in libtbx.env.module_list:
    for name,dist_path in module.name_and_dist_path_pairs():
      if (name == "boost"): continue
      dist_path = abs(dist_path)
      dist_copy = libtbx.path.norm_join(
        abs_target_root, os.path.basename(dist_path))
      if not os.path.exists(dist_path):
        print("Warning - could not locate: %s, skipping" %dist_path)
        continue
      os.chdir(dist_path)
      options = (module.exclude_from_binary_bundle, dist_copy)
      for root, dirs, files in os.walk("."):
        copy_dist_files(options, root, files)
  libtbx.bundle.utils.write_bundle_info(abs_target_root)
  os.chdir(cwd)

if (__name__ == "__main__"):
  assert len(sys.argv) == 2
  run(sys.argv[1])


 *******************************************************************************


 *******************************************************************************
libtbx/bundle/install_bat.py
from __future__ import absolute_import, division, print_function
import sys

def create_script(bundle, top_modules, single_dir=False):
  py_major, py_minor = sys.version_info[:2]
  script = r"""@echo off

set PYTHONHOME=
set PYTHONSTARTUP=
set PYTHONDEBUG=
set PYTHONINSPECT=
set PYTHONSUPPRESS=
set PYTHONUNBUFFERED=
set PYTHONVERBOSE=
set PYTHONCASEOK=1
"""
  if (single_dir):
    script += r"""
cd %(bundle)s
"""
  script += r"""
if not exist %(bundle)s_sources\TAG goto find_python
echo.
echo Build tag:
type %(bundle)s_sources\TAG

:find_python
echo.
echo Trying to find Python:
cd %(bundle)s_build
if not exist base\python\python.exe goto try_plain_python
set python=base\python\python
call "%%python%%" -V
if %%errorlevel%% == 0 goto have_python
:try_plain_python
set python=python
call "%%python%%" -V
if %%errorlevel%% == 0 goto have_python
set python=C:\python%(py_major)d%(py_minor)d\python
call "%%python%%" -V
if %%errorlevel%% == 0 goto have_python
cd ..
echo.
echo Cannot find a Python interpreter.
echo.
echo Please download an installer with Python included
echo or add a matching Python to the PATH environment variable.
echo.
echo Installation aborted.
echo.
goto end

:have_python
echo.
echo Configuring %(bundle)s build directory
call "%%python%%" ..\%(bundle)s_sources\libtbx\configure.py %(top_modules)s
set el=%%errorlevel%%
cd ..
if not %%el%% == 0 goto end
call %(bundle)s_build\setpaths_all.bat

if not exist %(bundle)s_install_finalize.bat goto run_tests
echo Running final setup script %(bundle)s_install_finalize.bat
call %(bundle)s_install_finalize.bat

:run_tests
if not exist "%%BOOST_ADAPTBX_DIST%%\tst_rational.py" goto skip_test
echo.
echo Running a selected test
echo libtbx.python "%%BOOST_ADAPTBX_DIST%%\tst_rational.py"
call libtbx.python "%%BOOST_ADAPTBX_DIST%%\tst_rational.py"
if not %%errorlevel%% == 0 goto end
:skip_test

echo.
echo ***
echo *** To use this installation in a new shell or process run the command:
echo ***
echo ***     %%LIBTBX_BUILD%%\setpaths.bat
echo ***
echo *** You may want to add this line to some startup file.
echo ***

:end
if not defined LIBTBX_BATCH_INSTALL goto end_prompt
if not %%LIBTBX_BATCH_INSTALL%% == 0 goto final_exit
:end_prompt
pause
:final_exit
"""
  return script % vars()

if (__name__ == "__main__"):
  assert len(sys.argv) == 3
  sys.stdout.write(create_script(sys.argv[1], sys.argv[2]))


 *******************************************************************************


 *******************************************************************************
libtbx/bundle/install_csh.py
from __future__ import absolute_import, division, print_function
import sys

def create_script(
      bundle,
      top_modules,
      test_py="`libtbx.show_dist_paths boost_adaptbx`/tst_rational.py",
      minimum_python_version="2.3"):
  return """\
#! /bin/csh -f

set install_root="$cwd"
set bundle="%(bundle)s"
set sources="$cwd/${bundle}_sources"
set build="$cwd/${bundle}_build"

set build_mode=release

set minimum_python_version=%(minimum_python_version)s

unsetenv PYTHONHOME
unsetenv PYTHONPATH
unsetenv PYTHONSTARTUP
unsetenv PYTHONDEBUG
unsetenv PYTHONINSPECT
unsetenv PYTHONSUPPRESS
unsetenv PYTHONUNBUFFERED
unsetenv PYTHONVERBOSE
unsetenv PYTHONCASEOK
set noglob
unalias cat
unalias cut
unalias cd
unalias grep
unalias head
unalias ls
unalias mkdir
unalias sort
unalias tr
unalias uname

if ("`uname`" == "Darwin") then
  limit stacksize 8192k
endif

if (-f "$sources/TAG") then
  echo "Build tag:"
  cat "$sources/TAG"
endif

if (-d "$sources/boost") then
  set have_sources=1
else
  set have_sources=0
endif

set required_python_version=None
if (-e "$build/lib/PYTHON_VERSION_MAJOR_MINOR") then
  set required_python_version=`grep -v '^#' "$build/lib/PYTHON_VERSION_MAJOR_MINOR"`
endif

set aborted="Installation aborted."

set number_of_cpus=None
set python_exe=None

if ($#argv <= 2) goto process_args

show_usage:
  echo "usage: $0 [/path/to/python/executable] [number_of_cpus]"
  exit 1

def_try_python_exe:
  set python_version_full=None
  set python_version=None
  set ok_minimum_python_version=0
  set q=`("$trial_python_exe" -c 'import sys; from string import upper, split, find, join; print upper("ok"); v=split(sys.version)[0]; print v; ac,ic=split(v, ".")[:2]; print ac+"."+ic; am,im=split("'"$minimum_python_version"'", ".")[:2]; print int(int(ac) < int(am)); print int(int(ac) == int(am) and int(ic) < int(im))' |& cat)`
  if ($#q == 5) then
    if (X"$q[1]" == X"OK") then
      set python_version_full="$q[2]"
      set python_version="$q[3]"
      if (X"$q[4]" == X"0" && X"$q[5]" == X"0") then
        set ok_minimum_python_version=1
      endif
    endif
  endif
  unset q
  goto "$try_python_rtnpt"

def_cmdln_number_of_cpus:
  if (X"$arg" == X) goto show_usage
  set n=(`echo "$arg" | tr -s '[0-9]' '[ *]'`)
  if ($#n == 0) then
    set n=(`echo "$arg"`)
    if ($#n == 1) then
      set number_of_cpus="$n[1]"
      echo "Number of available CPUs: $number_of_cpus"
      if ("$number_of_cpus" == "0") exit 0
    endif
  endif
  goto "$cmdln_number_of_cpus_rtnpt"

def_cmdln_python:
  set trial_python_exe="$arg"
  set try_python_rtnpt=try_cmdln_python_return
  goto def_try_python_exe
  try_cmdln_python_return:
  if ("$python_version" == "None") then
    echo "$0"": command line argument is not a working Python executable: $arg"
    exit 1
  endif
  if (! $ok_minimum_python_version) then
    echo "$0"": command line argument is not a sufficiently recent Python: $arg"
    exit 1
  endif
  set python_exe="$trial_python_exe"
  if (   "$required_python_version" != "None" \
      && "$required_python_version" != "$python_version") then
    echo "$0"": command line argument $python_exe (Python version" \
         "$python_version_full) is not the required version" \
         "($required_python_version)."
    exit 1
  endif
  goto have_python_exe

def_prompt_number_of_cpus:
  if ("$number_of_cpus" == "None") then
    set counter=0
    show_prompt:
    @ counter++
    echo -n "Please enter the number of available CPUs [1]: "
    set arg=(`echo "$<"`)
    if ($#arg == 0) set arg="1"
    set cmdln_number_of_cpus_rtnpt=prompt_n_return
    goto def_cmdln_number_of_cpus
    prompt_n_return:
    if ("$number_of_cpus" == "None") then
      echo "Not a number!"
      if ($counter > 2) then
        echo "Giving up."
        echo "$aborted"
        exit 1
      endif
      echo "Please try again."
      goto show_prompt
    endif
  endif
  goto "$prompt_number_of_cpus_rtnpt"

process_args:

if ($#argv == 1) then
  set arg="$1"
  set cmdln_number_of_cpus_rtnpt=argv1_return
  goto def_cmdln_number_of_cpus
  argv1_return:
  if ("$number_of_cpus" == "None") then
    goto def_cmdln_python
  endif
else if ($#argv == 2) then
  set arg="$1"
  set cmdln_number_of_cpus_rtnpt=argv2_return1
  goto def_cmdln_number_of_cpus
  argv2_return1:
  if ("$number_of_cpus" == "None") then
    set arg="$2"
    set cmdln_number_of_cpus_rtnpt=argv2_return2
    goto def_cmdln_number_of_cpus
    argv2_return2:
    if ("$number_of_cpus" == "None") goto show_usage
    set arg="$1"
    goto def_cmdln_python
  else
    set arg="$2"
    goto def_cmdln_python
  endif
endif

set python_sources=None
if ("$required_python_version" == "None") then
  set python_sources=(`ls | grep '^Python-'`)
  if ($#python_sources == 0) then
    set python_sources=None
  else if ($#python_sources == 1) then
    set python_sources="$python_sources[1]"
  else
    echo "ERROR: Multiple Python source code directories:"
    set noglob
    foreach d ($python_sources)
      echo "         $d"
    end
    echo "       Move or remove all but one directory."
    exit 1
  endif
endif

if ("$python_sources" != "None") then
  set prompt_number_of_cpus_rtnpt=inst_py_src_return
  goto def_prompt_number_of_cpus
  inst_py_src_return:
  #
  echo "Installing $python_sources from sources"
  mkdir -p "$build"
  cd "$build"
  cd ..
  cd "$python_sources"
  set py_install_log="../py_install_log"
  echo "Configuring Python"
  if ("X`uname`" == "XHP-UX") then
    # tested with HP aC++/ANSI C B3910B A.06.06 [Nov 7 2005]
    env CC=cc CXX="aCC -mt" BASECFLAGS="+DD64 -mt" LDFLAGS="+DD64 -lxnet" ./configure --without-gcc --prefix="$build/base" >& "$py_install_log"
    if (-f pyconfig.h) then
      grep -v _POSIX_C_SOURCE pyconfig.h > zz; mv zz pyconfig.h
    endif
  else
    ./configure --prefix="$build/base" >& "$py_install_log"
  endif
  echo "Compiling Python. This may take a while."
  if ("$number_of_cpus" == "1" || X"`uname`" != X"Linux") then
    echo "Command: make" >>& "$py_install_log"
    make >>& "$py_install_log"
  else
    echo "Command: make -j $number_of_cpus" >>& "$py_install_log"
    make -j "$number_of_cpus" >>& "$py_install_log"
  endif
  echo "Installing Python"
  make install >>& "$py_install_log"
  echo "Done installing Python."
  cd "$install_root"
  set trial_python_exe="$build/base/bin/python"
  set try_python_rtnpt=try_base_bin_python_return
  goto def_try_python_exe
  try_base_bin_python_return:
  if ("$python_version" == "None") then
    echo "ERROR: Python installation failed."
    echo "       Please check the log file for errors:"
    echo "         $py_install_log"
    exit 1
  endif
  set python_exe="$trial_python_exe"
  goto have_python_exe
endif

set trial_python_exe="$build/base/bin/python"
if (-e "$trial_python_exe") then
  set try_python_rtnpt=try_python_bb_return
  goto def_try_python_exe
  try_python_bb_return:
  if ("$python_version" == "None") then
    echo "Sorry: The installer is not suitable for this platform."
    echo "$aborted"
    exit 1
  endif
  set python_exe="$trial_python_exe"
  goto have_python_exe
endif
#
set trial_python_exe="python"
set try_python_rtnpt=try_python_return
goto def_try_python_exe
try_python_return:
if ("$python_version" != "None") then
  if (   "$required_python_version" == "None" \
      || "$required_python_version" == "$python_version") then
    if ($ok_minimum_python_version) then
      set python_exe="$trial_python_exe"
      goto have_python_exe
    endif
    echo "INFO: python on PATH (version $python_version_full) is not a" \
         "recent enough version (minimum $minimum_python_version)."
  else
    echo "INFO: python on PATH (version $python_version_full) is not the" \
         "required version ($required_python_version)."
  endif
endif
#
if ("`uname`" == "Darwin") then

  set lib_fw_vers="/Library/Frameworks/Python.framework/Versions"
  set sys_lib_fw_vers="/System/Library/Frameworks/Python.framework/Versions"

  set pyv="$required_python_version"
  if ("$pyv" == "None") then
    set pyv="`ls "$lib_fw_vers" "$sys_lib_fw_vers" | grep '^[1-9]' | sort -r | head -1`"
    if ("X$pyv" == "X") set pyv=None
  endif
  if (-d "$lib_fw_vers/$pyv") then
    set python_exe="$lib_fw_vers/$pyv/bin/python"
    if (-x "$python_exe") goto have_python_exe
    if (-f "$python_exe") then
      echo "INFO: $python_exe is not executable."
    else
      echo "INFO: $python_exe does not exist."
    endif
  endif
  if (-d "$sys_lib_fw_vers/$pyv") then
    set python_exe="$sys_lib_fw_vers/$pyv/bin/python"
    if (-x "$python_exe") goto have_python_exe
    if (-f "$python_exe") then
      echo "INFO: $python_exe is not executable."
    else
      echo "INFO: $python_exe does not exist."
    endif
  endif
#
endif
#
if ("$required_python_version" != "None") then
  set trial_python_exe="/usr/local/bin/python$required_python_version"
  set try_python_rtnpt=try_ulb_python_return
  goto def_try_python_exe
  try_ulb_python_return:
  if ("$python_version" != "None") then
    set python_exe="$trial_python_exe"
    goto have_python_exe
  endif
endif
#
if ("$required_python_version" == "None") then
  set trial_python_exe="/usr/bin/python"
  set try_python_rtnpt=try_ub_python_return
  goto def_try_python_exe
  try_ub_python_return:
  if ("$python_version" != "None" && $ok_minimum_python_version) then
    set python_exe="$trial_python_exe"
    goto have_python_exe
  endif
endif
#
if ("$required_python_version" != "None") then
  set trial_python_exe="/usr/bin/python$required_python_version"
  set try_python_rtnpt=try_ub_pythonv_return
  goto def_try_python_exe
  try_ub_pythonv_return:
  if ("$python_version" != "None") then
    set python_exe="$trial_python_exe"
    goto have_python_exe
  endif
endif

if ("$required_python_version" == "None") then
  set pyv=""
else
  set pyv=" (version $required_python_version)"
endif
echo ""
echo "Sorry: Cannot find a suitable Python interpreter$pyv."
echo ""
echo "  Please download an installer with Python included or"
echo "  run this command with the full path to a suitable Python"
echo "  executable as an argument, e.g.:"
echo ""
if ("$number_of_cpus" == "None") then
  set n=""
else
  set n=" $number_of_cpus"
endif
echo "    $0 some/path/bin/python$n"
echo ""
echo "$aborted"
exit 1

have_python_exe:

if ($have_sources) then
  set prompt_number_of_cpus_rtnpt=have_py_exe_return
  goto def_prompt_number_of_cpus
  have_py_exe_return:
endif

"$python_exe" -V

echo ""
echo "Precompiling all .py files. This may take a minute or two."
"$python_exe" "$sources/libtbx/command_line/py_compile_all.py"

echo ""
if (! -d "$build") mkdir -p "$build"
cd "$build"
echo "Configuring $bundle build directory"
"$python_exe" "$sources/libtbx/configure.py" --current_working_directory="$build" --build="$build_mode" %(top_modules)s
source setpaths.csh

if ($have_sources) then
  echo ""
  echo "Installing $bundle modules. This may take a while."
  libtbx.scons -j "$number_of_cpus" .
endif

set test_py="%(test_py)s"
if (-f "$test_py") then
  echo ""
  echo "Running a selected test"
  set cmd='libtbx.python "'"$test_py"'"'
  echo "$cmd"
  eval $cmd
endif

cat << EOT

***
*** csh and tcsh users:
***     To use this installation in a new shell or process run the command:
***
***         source "$build/setpaths.csh"
***
***     You may want to add this line to your .cshrc file.
***
*** sh and bash users:
***     To use this installation in a new shell or process run the command:
***
***         . "$build/setpaths.sh"
***
***     You may want to add this line to your .profile or .bashrc file.
***
EOT
""" % vars()

if (__name__ == "__main__"):
  assert len(sys.argv) == 3
  sys.stdout.write(create_script(sys.argv[1], sys.argv[2]))


 *******************************************************************************


 *******************************************************************************
libtbx/bundle/utils.py
from __future__ import absolute_import, division, print_function
import libtbx.load_env
import libtbx.env_config
import libtbx.path
import libtbx.utils
import sys, os

def copy_tags(target_root):
  if (os.path.isdir(target_root)):
    flds = []
    for path in libtbx.env.repository_paths:
      src = libtbx.path.norm_join(abs(path), "TAG")
      if (os.path.isfile(src)):
        flds.extend(open(src).read().split())
    if (len(flds) > 0):
      dest = libtbx.path.norm_join(target_root, "TAG")
      print(" ".join(flds), file=open(dest, "w"))

def write_bundle_info(target_root, write_build_options=False):
  copy_tags(target_root)
  if (os.path.isdir(target_root)):
    dest = libtbx.path.norm_join(target_root, "bundle_info")
    f = open(dest, "w")
    print("date_and_time:", libtbx.utils.date_and_time(), file=f)
    print("hostname:", libtbx.env_config.get_hostname(), file=f)
    print("os.name:", os.name, file=f)
    print("sys.platform:", sys.platform, file=f)
    print("sys.executable:", sys.executable, file=f)
    print("sys.version:", " ".join(sys.version.splitlines()), file=f)
    print("repository_paths:", libtbx.env.repository_paths, file=f)
    if (write_build_options):
      libtbx.env.build_options.report(f=f)
    f.close()


 *******************************************************************************


 *******************************************************************************
libtbx/callbacks.py
"""
Using GUI callbacks in CCTBX
----------------------------

The libtbx.callbacks module provides (or intends to) a transparent way of
sending information (in the form of pickled Python objects) from a running
non-graphical process to a graphical interface.  The intent is that any
program in CCTBX and derived works can import this module and call methods in
the global manager instance (libtbx.call_back), without worrying whether or
how the data will be sent to the parent process (if any - when the program is
being run by itself independently of a GUI or another process, the callbacks
will be ignored).  An example:

import libtbx.callbacks
libtbx.call_back(message="r_free",
  data=fmodel.r_free())
if (fmodel.r_free() > r_free_start):
  libtbx.warn("R-free increased during refinement")

For the callbacks, the message argument should be a short string (possibly
an actual message, or a statistic name, or a GUI method to call, or some kind
ofID), and the data argument can be any pickle-able object from a number to a
custom class.  There is no limit on the size of this object, but in practice it
will be faster not to pickle the contents of entire files if the filesystem is
being used for communication.  Since some callback data may be important as
part of a sequence, or needs to be shown to the user regardless of
communication latency, the accumulate and cached arguments toggle how
individual callbacks are handled.  The utility warn method sends a specific
type of message, a generic warning to the user, which in Phenix will be
prominently displayed in various windows.

The actual communication is handled either via connection objects from the
multiprocessing module (implemented in libtbx.thread_utils) or intermediate
files (Python pickles, as implemented in libtbx.runtime_utils).  These
modules handle the instantiation of processes (by whatever method) and the
interception of all output and status information, and its transmission to the
parent process.  (Note that standard output and exceptions are propagated
automatically, and do not require any additional callbacks.)  The GUI will
define its own methods to handle the various types of information,
which are called as necessary during runtime.  Ultimately the callbacks are
sent to the GUI as a specific type of event, which can be handled by custom
methods or ignored.  The module wxtbx.process_control provides an example of
how this could be done in wxPython (and is used in the Phenix GUI).

In theory it would be possible to implement a network-transparent callback
system , but we have not attempted this due to the difficulty of making it
work across a wide range of installations, varying levels of network security,
etc.

In practice, the callbacks used in Phenix include refinement statistics,
entire models or maps, plot data, progress bar control, and calls to window
methods.  They may be relatively frequent (as implied by the use of process
bars), but should not be so frequent or so large as to overwhelm the windowing
system (or filesystem, if intermediate files are used).  Standard output is
again handled automatically and buffered to limit the frequency.  Parallel
code should never use callbacks, as the behavior is undefined (but likely to
break).

A final note: while this is of course intended to be called from Python code,
it is possible to send callbacks from C++ code as well, and this is
implemented in the Phaser software.
"""
from __future__ import absolute_import, division, print_function

import six

from libtbx import str_utils
from libtbx import group_args, adopt_init_args
from libtbx.utils import to_unicode
import os
import sys

class manager(object):
  def __init__(self):
    self.handlers = []
    self._pid = os.getpid()
    self._log = None

  def set_warning_log(self, log):
    self._log = log

  def add_piped_callback(self, connection):
    cb = piped_callback(connection)
    self.register_handler(cb)

  def register_handler(self, handler):
    assert hasattr(handler, "__call__")
    self.handlers.append(handler)

  def __call__(self, message, data, accumulate=True, cached=True):
    for handler in self.handlers :
      handler(message=message,
              data=data,
              accumulate=accumulate,
              cached=cached)

  def add_citation(self, citation_info):
    self.__call__("citation", citation_info, accumulate=True)

  def showwarning(self, message, category, filename, lineno,
      *args, **kwds):
    # XXX ADDED *args because some calls come in here incorrectly with extra
    #   arguments, this way we just throw those away as this is just a warning
    self.warn(message)

  def warn(self, message):
    if (not isinstance(message, (six.text_type, six.binary_type))):
      message = to_unicode(message)
    self.__call__(message="warn", data=message, accumulate=True, cached=True)
    if (self._log is not None):
      log = self._log
    else :
      log = sys.stdout
    msg = "WARNING: %s\n" % message
    print("", file=log)
    for line in str_utils.line_breaker(msg, 72):
      print("  " + line, file=log)
    #print >> log, str_utils.wordwrap(msg, 79)

class piped_callback(object):
  def __init__(self, connection):
    adopt_init_args(self, locals())

  def __call__(self, message, data, accumulate=False, cached=True):
    self.connection.send(
      group_args(message=message,
                 data=data,
                 accumulate=accumulate,
                 cached=cached))

import libtbx
if not hasattr(libtbx, "call_back"):
  libtbx.call_back = manager()
  libtbx.warn = libtbx.call_back.warn


 *******************************************************************************


 *******************************************************************************
libtbx/citations.py
'''
Functionality for handling citations
'''
from __future__ import absolute_import, division, print_function

import importlib
import os
import string

from operator import attrgetter

import libtbx.load_env
import libtbx.phil
from libtbx import str_utils
from libtbx.utils import to_unicode

# =============================================================================
# PHIL definition for citations
master_citation_phil_str = '''
citation
  .multiple = True
{
  article_id = None
    .type = str
    .optional = False
  caption = None
    .type = str
  authors = None
    .type = str
  title = None
    .type = str
  year = None
    .type = int
  journal = None
    .type = str
  volume = None
    .type = str
  pages = None
    .type = str
  pmid = None
    .type = int
  doi_id = None
    .type = str
  url = None
    .type = str
}
'''
master_citation_phil = libtbx.phil.parse(master_citation_phil_str)

# -----------------------------------------------------------------------------
# PHIL definition for journals
# This is used for providing information in CIF blocks
master_journal_phil_str = '''
journal
  .multiple = True
{
  name = None
    .type = str
    .multiple = True
  name_full = None
    .type = str
  abbrev_CAS = None
    .type = str
    .help = Abbreviated name of the cited journal as given in the \
            Chemical Abstracts Service Source Index.
  id_ASTM = None
    .type = str
    .help = The American Society for Testing and Materials (ASTM) code \
            assigned to the journal cited (also referred to as the CODEN \
            designator of the Chemical Abstracts Service).
  id_CSD = None
    .type = str
    .help = The Cambridge Structural Database (CSD) code assigned to the \
            journal cited.
  id_ISSN = None
    .type = str
    .help = The International Standard Serial Number (ISSN) code assigned to \
            the journal cited.
}
'''
master_journal_phil = libtbx.phil.parse(master_journal_phil_str)

# -----------------------------------------------------------------------------
# Construct common database of citations and journals
# This prevents duplication of citations in individual programs if methods from
# different references are used in multiple programs

citations_and_journals = libtbx.phil.read_default(__file__)
citations = master_citation_phil.fetch(source=citations_and_journals).extract()
citations_db = dict( [ (c.article_id, c) for c in citations.citation ] )

journals_db = dict()
journals = master_journal_phil.fetch(source=citations_and_journals).extract()
for journal in journals.journal:
  for name in journal.name:
    journals_db[name] = journal

# =============================================================================
def format_citation(article):
  authors = article.authors
  author_list = authors.split(", ")
  if len(author_list) == 1 :
    authors_out = authors
  else :
    authors_out = ", ".join(author_list[:-1]) + ", and %s" % author_list[-1]
  output = "%s." % authors
  if article.year is not None :     output += " (%d)" % article.year
  title = article.title
  if (title is not None):
    title = title.strip()
    if (not title.endswith(".")):
      title += "."
    output += " %s" % title
  if article.journal is not None :  output += " %s" % article.journal
  if article.volume is not None :
    if article.journal is not None and 'Acta Cryst. ' in article.journal:
      # special case for Acta Cryst journals to get e.g.:
      #   Acta Cryst. D66
      output += "%s" % article.volume
    else:
      output += " %s" % article.volume
  if article.pages is not None :
    if article.volume is not None : output += ":%s" % article.pages
    else :                          output += ", pp. %s" % article.pages
  if output[-1] != '.' :            output += "."
  return output

# -----------------------------------------------------------------------------
def author_list_with_periods(authors, initials_first=False):
  author_list = authors.split(", ")
  authors_formatted = []
  for author in author_list :
    names = author.split(" ")
    if len(names) == 1 :
      authors_formatted.append(names[0])
    else :
      initials = names[-1]
      new_initials = ""
      for letter in initials :
        if letter in string.ascii_letters :
          new_initials += ("%s." % letter)
        else : # usually '-'
          new_initials += letter
      if initials_first :
        reformatted = "%s %s" % (new_initials, " ".join(names[:-1]))
      else :
        reformatted = "%s %s" % (" ".join(names[:-1]), new_initials)
      authors_formatted.append(reformatted)
  return authors_formatted

# -----------------------------------------------------------------------------
def format_citation_cell(article):
  author_list = author_list_with_periods(article.authors)
  if len(author_list) == 1 :
    authors_out = author_list[0]
  else :
    authors_out = ", ".join(author_list[:-1]) + ", and %s" % author_list[-1]
  output = "%s" % authors_out # XXX no extra period at end!
  if article.year is not None :     output += " (%d)." % article.year
  title = article.title
  if (title is not None):
    title = title.strip()
    if (not title.endswith(".")):
      title += "."
    output += " %s" % title
  if article.journal is not None :  output += " %s" % article.journal
  if article.volume is not None :
    if article.journal is not None and 'Acta Cryst. ' in article.journal:
      # special case for Acta Cryst journals to get e.g.:
      #   Acta Cryst. D66
      output += "%s" % article.volume
    else:
      output += " %s" % article.volume
  if article.pages is not None :
    if article.volume is not None : output += ", %s" % article.pages
    else :                          output += ", pp. %s" % article.pages
  if output[-1] != '.' :    output += "."
  return output

# -----------------------------------------------------------------------------
def format_citation_iucr(article):
  author_list = author_list_with_periods(article.authors)
  if len(author_list) == 1 :
    authors_out = author_list[0]
  else :
    authors_out = ", ".join(author_list[:-1]) + ", & %s" % author_list[-1]
  output = "%s" % authors_out
  if article.year is not None :     output += " (%d)." % article.year
  if article.journal is not None :  output += " %s" % article.journal
  if article.volume is not None :
    if article.journal is not None and 'Acta Cryst. ' in article.journal:
      # special case for Acta Cryst journals to get e.g.:
      #   Acta Cryst. D66
      output += "%s" % article.volume
    else:
      output += " %s" % article.volume
  if article.pages is not None :
    if article.volume is not None : output += ", %s" % article.pages
    else :                          output += ", pp. %s" % article.pages
  if output[-1] != '.' :            output += "."
  return output

# -----------------------------------------------------------------------------
def format_citation_doc(article_id):
  # check database
  article = citations_db.get(article_id)

  output = '<ul>'

  # check program templates
  if (article is None):

    # construct dictionary of program templates
    modules_dict = dict()
    for module in libtbx.env.module_list:
      for p in module.program_directory_paths():
        modules = list()
        for f in p.listdir():
          if ( f.endswith('.py') and (f != '__init__.py') and
               (not f.startswith('.')) ):
            basename = os.path.splitext(os.path.basename(f))[0]
            modules.append(basename)
        if (len(modules) > 0):
          modules_dict[module.name] = modules

    # find specific program template by article_id
    for module in modules_dict.keys():
      for package in modules_dict[module]:
        if (package == article_id):
          importlib.import_module(module)
          program_template = importlib.import_module(
            '.' + package, package='.'.join([module, 'programs']))
          if (hasattr(program_template, 'Program')):
            working_phil = master_citation_phil.fetch(
              source=program_template.Program.citations)
            for article in working_phil.extract().citation:
              output += '<li>'
              output += format_citation_html(article)
              output += '</li>\n'
          else:
            raise ValueError('Citations for %s could not be found.' % article_id)
          break
  else:
    output += '<li>'
    output += format_citation_html(article)
    output += '</li>\n'

  output += '</ul>'
  return output

# -----------------------------------------------------------------------------
def format_citation_html(article):
  if (article.journal is None):
    raise ValueError("Missing journal name for '%s'." % article.article_id)
  author_list = author_list_with_periods(article.authors, initials_first=True)
  if len(author_list) == 1 :
    authors_out = author_list[0]
  else :
    authors_out = ", ".join(author_list[:-1]) + ", and %s" % author_list[-1]
  title = article.title.strip()
  if (not title.endswith(".")):
    title += "."
  output = "<b>%s</b> %s. " % (title, authors_out)
  if 'Acta Cryst.' in article.journal:
    journal_ref = "<i>Acta Cryst.</i>"
    journal_section = article.journal.split("Acta Cryst. ")[1]
  else:
    journal_ref = "<i>%s</i>" % article.journal
    journal_section = None
  if (article.volume is not None):
    if journal_section is not None:
      journal_ref += " %s<b>%s</b>" %(journal_section, article.volume)
    else:
      journal_ref += " <b>%s</b>" % article.volume
  if (article.pages is not None):
    journal_ref += ", %s" % article.pages
  if (article.year is not None):
    journal_ref += " (%s)" % article.year
  if (article.url is not None):
    output += """<a href="%s">%s</a>.""" % (article.url, journal_ref)
  elif (article.doi_id is not None):
    output += """<a href="https://doi.org/%s">%s</a>.""" % (article.doi_id,
      journal_ref)
  elif (article.pmid is not None):
    output += """<a href="http://www.ncbi.nlm.nih.gov/pubmed/%s">%s</a>.""" % \
      (article.pmid, journal_ref)
  else :
    output += " %s." % journal_ref
  return output

# -----------------------------------------------------------------------------
def show_citation(article, out=None, max_width=79, format='default'):
  if format == 'default' :
    output = format_citation(article)
  elif format == 'iucr' :
    output = format_citation_iucr(article)
  elif format == 'cell' :
    output = format_citation_cell(article)
  if max_width is None or max_width < 1 :
    print(to_unicode(output), file=out)
  else :
    for line in str_utils.line_breaker(output, max_width):
      print(to_unicode(line), file=out)
  print(to_unicode(''), file=out)

def show_citations(articles, out=None, max_width=79, sort_by_name=True,
                   format='default'):
  if (sort_by_name): # sort in place
    articles.sort(key=attrgetter('authors'))
  for article in articles:
    show_citation(article, out, max_width, format)

# =============================================================================
# end


 *******************************************************************************


 *******************************************************************************
libtbx/clear_paths.py
"""
Tools to safely add and remove files
"""
from __future__ import absolute_import, division, print_function
import random
import stat
import os
import os.path as op
from shutil import rmtree
from six.moves import range

def make_paths_writable_if_possible(paths):
  """Safely make a list of paths writable (if possible)"""
  os_stat = os.stat
  os_chmod = os.chmod
  irwusr = stat.S_IRUSR | stat.S_IWUSR
  irwxusr = irwusr | stat.S_IXUSR
  for path in paths:
    try:
      mode = os_stat(path).st_mode
    except KeyboardInterrupt: raise
    except Exception:
      pass
    else:
      if (op.isdir(path)):
        new_mode = mode | irwxusr
      else:
        new_mode = mode | irwusr
      if (new_mode != mode):
        try:
          os_chmod(path, new_mode)
        except KeyboardInterrupt: raise
        except Exception:
          pass

def remove_directories_if_possible(paths):
  """Safely remove a list of directories (if possible)"""
  remaining = []
  for path in paths:
    if (op.isdir(path)):
      try:
        rmtree(path, ignore_errors=True)
      except KeyboardInterrupt: raise
      except Exception:
        pass
    if (op.isdir(path)):
      remaining.append(path)
  return remaining

def remove_files_if_possible(paths):
  """Safely remove a list of files (if possible)"""
  remaining = []
  for path in paths:
    if (op.exists(path)):
      try:
        os.remove(path)
      except KeyboardInterrupt: raise
      except Exception:
        pass
    if (op.exists(path)):
      remaining.append(path)
  return remaining

def rename_files_and_directories_if_possible(paths):
  """Safely rename a list of files or directories and append _OBSOLETE_xxx
    (if possible)"""
  remaining = []
  for path in paths:
    if (op.exists(path)):
      path = op.normpath(path) # strips trailing slash
      for i_trial in range(1000):
        new_path = path + "_OBSOLETE_%8.8X" % random.randrange(2**32)
        if (not op.exists(new_path)):
          try:
            os.rename(path, new_path)
          except KeyboardInterrupt: raise
          except Exception:
            pass
          break
    if (op.exists(path)):
      remaining.append(path)
  return remaining

def remove_or_rename_files_and_directories_if_possible(paths):
  """Safely remove a list of files and directories,
    and if not successful, rename them with the extension _OBSOLETE_xxx
    (if possible)"""
  make_paths_writable_if_possible(paths=paths)
  remaining_dirs = remove_directories_if_possible(paths=paths)
  remaining_files = remove_files_if_possible(paths=paths)
  remaining = []
  for remaining_paths in [remaining_dirs, remaining_files]:
    remaining.extend(
      rename_files_and_directories_if_possible(paths=remaining_paths))
  return remaining


 *******************************************************************************


 *******************************************************************************
libtbx/cli.py
from __future__ import absolute_import, division, print_function

try:
  import argparse

except ImportError:
  from libtbx.utils import Sorry
  raise Sorry("The argparse module is not available. Check Python version >= 2.7")

import libtbx.phil


def phil_from_string(string):

  try:
    return libtbx.phil.parse( string )

  except RuntimeError:
    raise ValueError("Incorrect PHIL format")


def phil_from_file(file_name):

  with open( file_name ) as f:
    string = f.read()

  return phil_from_string( string = string )


class PhilArgumentFactory(object):

  def __init__(self, master_phil):

    from libtbx.phil import command_line
    self.interpreter = command_line.argument_interpreter( master_phil = master_phil )
    self.file_handlers = []


  def add_file_handler(self, handler):

    self.file_handlers.append( handler )


  def __call__(self, argument):

    if "=" in argument:
      try:
        return self.interpreter.process( arg = argument )

      except Exception as e:
        raise argparse.ArgumentTypeError( "Cannot interpret assignment '%s': %s" % ( argument, e ) )

    import os.path

    if os.path.isfile( argument ):
      for handler in self.file_handlers:
        try:
          return handler( argument = argument )

        except ValueError:
          continue

      try:
        return phil_from_file( file_name = argument )

      except ValueError:
        pass

      raise argparse.ArgumentTypeError( "Does not recognize file: %s" % argument )

    raise argparse.ArgumentTypeError( "Cannot interpret argument: %s" % argument )


# File recognition
class ExtensionFileHandler(object):

  def __init__(self, extensions, philpath):

    self.extensions = set( extensions )
    self.philpath = philpath


  def __call__(self, argument):

    import os.path

    if os.path.splitext( argument )[1] in self.extensions:
      return phil_from_string( string = "%s=%s" % ( self.philpath, argument ) )

    raise ValueError("Unrecognized file: %s" % argument)


# Parser actions
class PhilPrintAction(argparse.Action):
  """
  Action to print phil
  """

  def __init__(
    self,
    option_strings,
    dest = argparse.SUPPRESS,
    default = argparse.SUPPRESS,
    help = None,
    ):

    super( PhilPrintAction, self ).__init__(
      option_strings = option_strings,
      dest = dest,
      default = default,
      nargs = 0,
      help = help,
      )


  def __call__(self, parser, namespace, values, option_string = None):

    parser.print_phil()
    parser.exit()


class CaptureStdinPhilAction(argparse.Action):
  """
  Action to capture stdin
  """

  def __init__(self, option_strings, dest, default = argparse.SUPPRESS, help = None):

    super( CaptureStdinPhilAction, self ).__init__(
      option_strings = option_strings,
      dest = dest,
      default = default,
      nargs = 0,
      help = help,
      )


  def __call__(self, parser, namespace, values, option_string = None):

    import sys

    string = sys.stdin.read()

    try:
      value = libtbx.phil.parse( string )

    except RuntimeError:
      parser.error( "Could not interpret input from stdin: %s\n" % string )

    setattr( namespace, self.dest, value )


class Parser(argparse.ArgumentParser):
  """
  Extended parser that handles help and phil
  """

  def __init__(self, master_phil, *args, **kwargs):

    super( Parser, self ).__init__( *args, **kwargs )
    self.master_phil = master_phil
    self.factory = PhilArgumentFactory( master_phil = self.master_phil )

    self.add_argument(
      "phils",
      nargs = "+",
      metavar = "PHIL",
      action = "store",
      default = [],
      type = self.factory,
      help = "PHIL argument (file name or PHIL command line assignment)"
      )

    prefix = self.prefix_chars[0]
    self.add_argument(
      prefix * 2 + "show-defaults",
      action = PhilPrintAction,
      help= "print PHIL and exit",
      )
    self.add_argument(
      prefix + "i", prefix * 2 + "stdin",
      action = CaptureStdinPhilAction,
      help= "read PHIL from stdin as well",
      )


  def recognize_file_type_as(self, extensions, philpath):

    self.factory.add_file_handler(
      ExtensionFileHandler( extensions = extensions, philpath = philpath ),
      )


  def print_phil(self, file = None):

    super( Parser, self )._print_message(
      self.master_phil.as_str() + "\n",
      file,
      )


  def parse_args(self, args = None, namespace = None):

    args = super( Parser, self ).parse_args(
      args = args,
      namespace = namespace
      )

    if hasattr( args, "stdin" ):
      args.phils.append( args.stdin )
      delattr( args, "stdin" )

    try:
      merged = self.master_phil.fetch( sources = args.phils )

    except Exception as e:
      self.error( "Error while merging arguments: %s" % e )

    delattr( args, "phils" )
    args.phil = merged

    try:
      args.phil_extract = args.phil.extract()

    except RuntimeError as e:
      self.error( str( e ) )

    return args



 *******************************************************************************


 *******************************************************************************
libtbx/cluster.py
"""
http://pypi.python.org/pypi/cluster/1.1.1b3
"""
from __future__ import absolute_import, division, print_function

#
# This is part of "python-cluster". A library to group similar items together.
# Copyright (C) 2006   Michel Albert
#
# This library is free software; you can redistribute it and/or modify it under
# the terms of the GNU Lesser General Public License as published by the Free
# Software Foundation; either version 2.1 of the License, or (at your option)
# any later version.
# This library is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more
# details.
# You should have received a copy of the GNU Lesser General Public License
# along with this library; if not, write to the Free Software Foundation, Inc.,
# 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
#

from six.moves import range

class ClusteringError(Exception):
   pass

def flatten(L):
   """
   Flattens a list.
   Example:
   flatten([a,b,[c,d,[e,f]]]) = [a,b,c,d,e,f]
   """
   if not isinstance(L, type([])): return [L]
   if L == []: return L
   return flatten(L[0]) + flatten(L[1:])

def median(numbers):
   """Return the median of the list of numbers.

   found at: http://mail.python.org/pipermail/python-list/2004-December/253517.html"""
   # Sort the list and take the middle element.
   n = len(numbers)
   copy = sorted(numbers[:]) # So that "numbers" keeps its original order
   if n & 1:         # There is an odd number of elements
      return copy[n // 2]
   else:
      return (copy[n // 2 - 1] + copy[n // 2]) / 2.0

def mean(numbers):
   """Returns the arithmetic mean of a numeric list.

   found at: http://mail.python.org/pipermail/python-list/2004-December/253517.html"""
   return float(sum(numbers)) / float(len(numbers))

def minkowski_distance(x, y, p=2):
   """
   Calculates the minkowski distance between two points.

   PARAMETERS
      x - the first point
      y - the second point
      p - the order of the minkowski algorithm.
          Default = 2. This is equal to the euclidian distance.
                       If the order is 1, it is equal to the manhatten
                       distance.
                       The higher the order, the closer it converges to the
                       Chebyshev distance, which has p=infinity
   """
   from math import pow
   assert(len(y)==len(x))
   sum = 0
   for i in range(len(x)):
      sum += abs(x[i]-y[i]) ** p
   return pow(sum, 1.0/float(p))

def genmatrix(list, combinfunc, symmetric=False, diagonal=None):
   """
   Takes a list and generates a 2D-matrix using the supplied combination
   function to calculate the values.

   PARAMETERS
      list        - the list of items
      combinfunc  - the function that is used to calculate teh value in a cell.
                    It has to cope with two arguments.
      symmetric   - Whether it will be a symmetric matrix along the diagonal.
                    For example, it the list contains integers, and the
                    combination function is abs(x-y), then the matrix will be
                    symmetric.
                    Default: False
      diagonal    - The value to be put into the diagonal. For some functions,
                    the diagonal will stay constant. An example could be the
                    function "x-y". Then each diagonal cell will be "0".
                    If this value is set to None, then the diagonal will be
                    calculated.
                    Default: None
   """
   matrix = []
   row_index = 0
   for item in list:
      row = []
      col_index = 0
      for item2 in list:
         if diagonal is not None and col_index == row_index:
            # if this is a cell on the diagonal
            row.append(diagonal)
         elif symmetric and col_index < row_index:
            # if the matrix is symmetric and we are "in the lower left triangle"
            row.append( matrix[col_index][row_index] )
         else:
            # if this cell is not on the diagonal
            row.append(combinfunc(item, item2))
         col_index += 1
      matrix.append(row)
      row_index += 1
   return matrix

def printmatrix(list):
   """
   Prints out a 2-dimensional list cleanly.
   This is useful for debugging.

   PARAMETERS
      list  -  the 2D-list to display
   """
   # determine maximum length
   maxlen = 0
   colcount = len(list[0])
   for col in list:
      for cell in col:
         maxlen = max(len(str(cell)), maxlen)
   # print data
   format =  " %%%is |" % maxlen
   format = "|" + format*colcount
   for row in list:
      print(format % tuple(row))

def magnitude(a):
   "calculates the magnitude of a vecor"
   from math import sqrt
   sum = 0
   for coord in a:
      sum += coord ** 2
   return sqrt(sum)

def dotproduct(a, b):
   "Calculates the dotproduct between two vecors"
   assert(len(a) == len(b))
   out = 0
   for i in range(len(a)):
      out += a[i]*b[i]
   return out

def centroid(list, method=median):
   "returns the central vector of a list of vectors"
   out = []
   for i in range(len(list[0])):
      out.append( method( [x[i] for x in list] ) )
   return tuple(out)

class Cluster:
   """
   A collection of items. This is internally used to detect clustered items in
   the data so we could distinguish other collection types (lists, dicts, ...)
   from the actual clusters. This means that you could also create clusters of
   lists with this class.
   """

   def __str__(self):
      return "<Cluster@%s(%s)>" % (self.__level, self.__items)

   def __repr__(self):
      return self.__str__()

   def __init__(self, level, *args):
      """
      Constructor

      PARAMETERS
         level - The level of this cluster. This is used in hierarchical
                 clustering to retrieve a specific set of clusters. The higher
                 the level, the smaller the count of clusters returned. The
                 level depends on the difference function used.
         *args - every additional argument passed following the level value
                 will get added as item to the cluster. You could also pass a
                 list as second parameter to initialise the cluster with that
                 list as content
      """
      self.__level = level
      if len(args) == 0: self.__items = []
      else:              self.__items = list(args)

   def append(self, item):
      """
      Appends a new item to the cluster

      PARAMETERS
         item  -  The item that is to be appended
      """
      self.__items.append(item)

   def items(self, newItems = None):
      """
      Sets or gets the items of the cluster

      PARAMETERS
         newItems (optional) - if set, the items of the cluster will be
                               replaced with that argument.
      """
      if newItems is None: return self.__items
      else:                self.__items = newItems

   def fullyflatten(self, *args):
      """
      Completely flattens out this cluster and returns a one-dimensional list
      containing the cluster's items. This is useful in cases where some items
      of the cluster are clusters in their own right and you only want the
      items.

      PARAMETERS
         *args - only used for recursion.
      """
      flattened_items = []
      if len(args) == 0: collection = self.__items
      else:              collection = args[0].items()

      for item in collection:
         if isinstance(item, Cluster):
            flattened_items = flattened_items + self.fullyflatten(item)
         else:
            flattened_items.append(item)

      return flattened_items

   def level(self):
      """
      Returns the level associated with this cluster
      """
      return self.__level

   def display(self, depth=0):
      """
      Pretty-prints this cluster. Useful for debuging
      """
      print(depth*"   " + "[level %s]" % self.__level)
      for item in self.__items:
         if isinstance(item, Cluster):
            item.display(depth+1)
         else:
            print(depth*"   "+"%s" % item)

   def topology(self):
      """
      Returns the structure (topology) of the cluster as tuples.

      Output from cl.data:
          [<Cluster@0.833333333333(['CVS', <Cluster@0.818181818182(['34.xls',
          <Cluster@0.789473684211([<Cluster@0.555555555556(['0.txt',
          <Cluster@0.181818181818(['ChangeLog', 'ChangeLog.txt'])>])>,
          <Cluster@0.684210526316(['20060730.py',
          <Cluster@0.684210526316(['.cvsignore',
          <Cluster@0.647058823529(['About.py',
          <Cluster@0.625(['.idlerc', '.pylint.d'])>])>])>])>])>])>])>]

      Corresponding output from cl.topo():
          ('CVS', ('34.xls', (('0.txt', ('ChangeLog', 'ChangeLog.txt')),
          ('20060730.py', ('.cvsignore', ('About.py',
          ('.idlerc', '.pylint.d')))))))
      """

      left  = self.__items[0]
      right = self.__items[1]
      if isinstance(left, Cluster):
          first = left.topology()
      else:
          first = left
      if isinstance(right, Cluster):
          second = right.topology()
      else:
          second = right
      return first, second

   def getlevel(self, threshold):
      """
      Retrieve all clusters up to a specific level threshold. This
      level-threshold represents the maximum distance between two clusters. So
      the lower you set this threshold, the more clusters you will receive and
      the higher you set it, you will receive less but bigger clusters.

      PARAMETERS
         threshold - The level threshold

      NOTE
         It is debatable whether the value passed into this method should
         really be as strongly linked to the real cluster-levels as it is right
         now. The end-user will not know the range of this value unless s/he
         first inspects the top-level cluster. So instead you might argue that
         a value ranging from 0 to 1 might be a more useful approach.
      """

      left  = self.__items[0]
      right = self.__items[1]

      # if this object itself is below the threshold value we only need to
      # return it's contents as a list
      if self.level() <= threshold:
         return [self.fullyflatten()]

      # if this cluster's level is higher than the threshold we will investgate
      # it's left and right part. Their level could be below the threshold
      if isinstance(left, Cluster) and left.level() <= threshold:
         if isinstance(right, Cluster):
            return [left.fullyflatten()] + right.getlevel(threshold)
         else:
            return [left.fullyflatten()] + [[right]]
      elif isinstance(right, Cluster) and right.level() <= threshold:
         if isinstance(left, Cluster):
            return left.getlevel(threshold) + [right.fullyflatten()]
         else:
            return [[left]] + [right.fullyflatten()]

      # Alright. We covered the cases where one of the clusters was below the
      # threshold value. Now we'll deal with the clusters that are above by
      # recursively applying the previous cases.
      if isinstance(left, Cluster) and isinstance(right, Cluster):
         return left.getlevel(threshold) + right.getlevel(threshold)
      elif isinstance(left, Cluster):
         return left.getlevel(threshold) + [[right]]
      elif isinstance(right, Cluster):
         return [[left]] + right.getlevel(threshold)
      else:
         return [[left], [right]]

class BaseClusterMethod:
   """
   The base class of all clustering methods.
   """

   def __init__(self, input, distance_function):
      """
      Constructs the object and starts clustering

      PARAMETERS
         input             - a list of objects
         distance_function - a function returning the distance - or opposite of
                             similarity ( distance = -similarity ) - of two
                             items from the input. In other words, the closer
                             the two items are related, the smaller this value
                             needs to be. With 0 meaning they are exactly the
                             same.

      NOTES
         The distance function should always return the absolute distance
         between two given items of the list. Say,

         distance(input[1], input[4]) = distance(input[4], input[1])

         This is very important for the clustering algorithm to work!
         Naturally, the data returned by the distance function MUST be a
         comparable datatype, so you can perform arithmetic comparisons on
         them (< or >)! The simplest examples would be floats or ints. But as
         long as they are comparable, it's ok.
      """
      self.distance = distance_function
      self._input = input    # the original input
      self._data  = input[:] # clone the input so we can work with it

   def topo(self):
      """
      Returns the structure (topology) of the cluster.

      See Cluster.topology() for information.
      """
      return self.data[0].topology()

   def __get_data(self):
      """
      Returns the data that is currently in process.
      """
      return self._data
   data = property(__get_data)

   def __get_raw_data(self):
      """
      Returns the raw data (data without being clustered).
      """
      return self._input
   raw_data = property(__get_raw_data)

class HierarchicalClustering(BaseClusterMethod):
   """
   Implementation of the hierarchical clustering method as explained in
   http://www.elet.polimi.it/upload/matteucc/Clustering/tutorial_html/hierarchical.html

   USAGE
      >>> from cluster import HierarchicalClustering
      >>> # or: from cluster import *
      >>> cl = HierarchicalClustering([123,334,345,242,234,1,3], lambda x,y: float(abs(x-y)))
      >>> cl.getlevel(90)
      [[345, 334], [234, 242], [123], [3, 1]]

      Note that all of the returned clusters are more that 90 apart

   """

   def __init__(self, data, distance_function, linkage='single'):
      """
      Constructor

      See BaseClusterMethod.__init__ for more details.
      """
      BaseClusterMethod.__init__(self, data, distance_function)

      # set the linkage type to single
      self.setLinkageMethod(linkage)
      self.__clusterCreated = False

   def setLinkageMethod(self, method):
      """
      Sets the method to determine the distance between two clusters.

      PARAMETERS:
         method - The name of the method to use. It must be one of 'single',
                  'complete', 'average' or 'uclus'
      """
      if method == 'single':
         self.linkage = self.singleLinkageDistance
      elif method == 'complete':
         self.linkage = self.completeLinkageDistance
      elif method == 'average':
         self.linkage = self.averageLinkageDistance
      elif method == 'uclus':
         self.linkage = self.uclusDistance
      else:
         raise ValueError('distance method must be one of single, complete, average of uclus')

   def uclusDistance(self, x, y):
      """
      The method to determine the distance between one cluster an another
      item/cluster. The distance equals to the *average* (median) distance from
      any member of one cluster to any member of the other cluster.

      PARAMETERS
         x  -  first cluster/item
         y  -  second cluster/item
      """
      # create a flat list of all the items in <x>
      if not isinstance(x, Cluster): x = [x]
      else: x = x.fullyflatten()

      # create a flat list of all the items in <y>
      if not isinstance(y, Cluster): y = [y]
      else: y = y.fullyflatten()

      distances = []
      for k in x:
         for l in y:
            distances.append(self.distance(k,l))
      return median(distances)

   def averageLinkageDistance(self, x, y):
      """
      The method to determine the distance between one cluster an another
      item/cluster. The distance equals to the *average* (mean) distance from
      any member of one cluster to any member of the other cluster.

      PARAMETERS
         x  -  first cluster/item
         y  -  second cluster/item
      """
      # create a flat list of all the items in <x>
      if not isinstance(x, Cluster): x = [x]
      else: x = x.fullyflatten()

      # create a flat list of all the items in <y>
      if not isinstance(y, Cluster): y = [y]
      else: y = y.fullyflatten()

      distances = []
      for k in x:
         for l in y:
            distances.append(self.distance(k,l))
      return mean(distances)

   def completeLinkageDistance(self, x, y):
      """
      The method to determine the distance between one cluster an another
      item/cluster. The distance equals to the *longest* distance from any
      member of one cluster to any member of the other cluster.

      PARAMETERS
         x  -  first cluster/item
         y  -  second cluster/item
      """

      # create a flat list of all the items in <x>
      if not isinstance(x, Cluster): x = [x]
      else: x = x.fullyflatten()

      # create a flat list of all the items in <y>
      if not isinstance(y, Cluster): y = [y]
      else: y = y.fullyflatten()

      # retrieve the minimum distance (single-linkage)
      maxdist = self.distance(x[0], y[0])
      for k in x:
         for l in y:
            maxdist = max(maxdist, self.distance(k,l))

      return maxdist

   def singleLinkageDistance(self, x, y):
      """
      The method to determine the distance between one cluster an another
      item/cluster. The distance equals to the *shortest* distance from any
      member of one cluster to any member of the other cluster.

      PARAMETERS
         x  -  first cluster/item
         y  -  second cluster/item
      """

      # create a flat list of all the items in <x>
      if not isinstance(x, Cluster): x = [x]
      else: x = x.fullyflatten()

      # create a flat list of all the items in <y>
      if not isinstance(y, Cluster): y = [y]
      else: y = y.fullyflatten()

      # retrieve the minimum distance (single-linkage)
      mindist = self.distance(x[0], y[0])
      for k in x:
         for l in y:
            mindist = min(mindist, self.distance(k,l))

      return mindist

   def cluster(self, matrix=None, level=None, sequence=None):
      """
      Perform hierarchical clustering. This method is automatically called by
      the constructor so you should not need to call it explicitly.

      PARAMETERS
         matrix   -  The 2D list that is currently under processing. The matrix
                     contains the distances of each item with each other
         level    -  The current level of clustering
         sequence -  The sequence number of the clustering
      """

      if matrix is None:
         # create level 0, first iteration (sequence)
         level    = 0
         sequence = 0
         matrix   = []

      # if the matrix only has two rows left, we are done
      while len(matrix) > 2 or matrix == []:

         matrix = genmatrix(self._data, self.linkage, True, 0)

         smallestpair = None
         mindistance  = None
         rowindex = 0   # keep track of where we are in the matrix
         # find the minimum distance
         for row in matrix:
            cellindex = 0 # keep track of where we are in the matrix
            for cell in row:
               # if we are not on the diagonal (which is always 0)
               # and if this cell represents a new minimum...
               if (rowindex != cellindex) and (
                     (mindistance is not None and cell < mindistance) or
                     smallestpair is None ):
                  smallestpair = ( rowindex, cellindex )
                  mindistance  = cell
               cellindex += 1
            rowindex += 1

         sequence += 1
         level     = matrix[smallestpair[1]][smallestpair[0]]
         cluster   = Cluster(level, self._data[smallestpair[0]], self._data[smallestpair[1]])

         # maintain the data, by combining the the two most similar items in the list
         # we use the min and max functions to ensure the integrity of the data.
         # imagine: if we first remove the item with the smaller index, all the
         # rest of the items shift down by one. So the next index will be
         # wrong. We could simply adjust the value of the second "remove" call,
         # but we don't know the order in which they come. The max and min
         # approach clarifies that
         self._data.remove(self._data[max(smallestpair[0], smallestpair[1])]) # remove item 1
         self._data.remove(self._data[min(smallestpair[0], smallestpair[1])]) # remove item 2
         self._data.append(cluster)               # append item 1 and 2 combined

      # all the data is in one single cluster. We return that and stop
      self.__clusterCreated = True
      return

   def getlevel(self, threshold):
      """
      Returns all clusters with a maximum distance of <threshold> in between
      each other

      PARAMETERS
         threshold - the maximum distance between clusters

      SEE-ALSO
         Cluster.getlevel(threshold)
      """

      # if it's not worth clustering, just return the data
      if len(self._input) <= 1: return self._input

      # initialize the cluster if not yet done
      if not self.__clusterCreated: self.cluster()

      return self._data[0].getlevel(threshold)

class KMeansClustering:
   """
   Implementation of the kmeans clustering method as explained in
   http://www.elet.polimi.it/upload/matteucc/Clustering/tutorial_html/kmeans.html

   USAGE
   =====

     >>> from cluster import KMeansClustering
     >>> cl = KMeansClustering([(1,1), (2,1), (5,3), ...])
     >>> clusters = cl.getclusters(2)
   """

   def __init__(self, data, distance=None):
      """
      Constructor

      PARAMETERS
         data     - A list of tuples or integers.
         distance - A function determining the distance between two items.
                    Default: It assumes the tuples contain numeric values and
                             appiles a generalised form of the
                             euclidian-distance algorithm on them.
      """
      self.__data = data
      self.distance = distance
      self.__initial_length = len(data)

      # test if each item is of same dimensions
      if len(data) > 1 and isinstance(data[0], tuple):
         control_length = len(data[0])
         for item in data[1:]:
            if len(item) != control_length:
               raise ValueError("Each item in the data list must have the same amount of dimensions. Item", item, "was out of line!")
      # now check if we need and have a distance function
      if len(data) > 1 and not isinstance(data[0], tuple) and distance is None:
         raise ValueError("You supplied non-standard items but no distance function! We cannot continue!")
      # we now know that we have tuples, and assume therefore that it's items are numeric
      elif distance is None:
         self.distance = minkowski_distance

   def getclusters(self, n):
      """
      Generates <n> clusters

      PARAMETERS
         n - The amount of clusters that should be generated.
             n must be greater than 1
      """

      # only proceed if we got sensible input
      if n <= 1:
         raise ClusteringError("When clustering, you need to ask for at least two clusters! You asked for %d" % n)

      # return the data straight away if there is nothing to cluster
      if self.__data == [] or len(self.__data) == 1 or n == self.__initial_length:
         return self.__data

      # It makes no sense to ask for more clusters than data-items available
      if n > self.__initial_length:
         raise ClusteringError( """Unable to generate more clusters than items
available. You supplied %d items, and asked for %d clusters.""" %
               (self.__initial_length, n) )

      self.initialiseClusters(self.__data, n)

      items_moved = True     # tells us if any item moved between the clusters,
                             # as we initialised the clusters, we assume that
                             # is the case
      while items_moved is True:
         items_moved = False
         for cluster in self.__clusters:
            for item in cluster:
               res = self.assign_item(item, cluster)
               if items_moved is False: items_moved = res
      return self.__clusters

   def assign_item(self, item, origin):
      """
      Assigns an item from a given cluster to the closest located cluster

      PARAMETERS
         item   - the item to be moved
         origin - the originating cluster
      """
      closest_cluster = origin
      for cluster in self.__clusters:
         if self.distance(item, centroid(cluster)) < self.distance(item, centroid(closest_cluster)):
            closest_cluster = cluster

      if closest_cluster != origin:
         self.move_item(item, origin, closest_cluster)
         return True
      else:
         return False

   def move_item(self, item, origin, destination):
      """
      Moves an item from one cluster to anoter cluster

      PARAMETERS

         item        - the item to be moved
         origin      - the originating cluster
         destination - the target cluster
      """
      destination.append( origin.pop( origin.index(item) ) )

   def initialiseClusters(self, input, clustercount):
      """
      Initialises the clusters by distributing the items from the data evenly
      across n clusters

      PARAMETERS
         input        - the data set (a list of tuples)
         clustercount - the amount of clusters (n)
      """
      # initialise the clusters with empty lists
      self.__clusters = []
      for x in range(clustercount): self.__clusters.append([])

      # distribute the items into the clusters
      count = 0
      for item in input:
         self.__clusters[ count % clustercount ].append(item)
         count += 1


 *******************************************************************************


 *******************************************************************************
libtbx/clusterTests.py
"""
http://pypi.python.org/pypi/cluster/1.1.1b3
"""
from __future__ import absolute_import, division, print_function

#
# This is part of "python-cluster". A library to group similar items together.
# Copyright (C) 2006   Michel Albert
#
# This library is free software; you can redistribute it and/or modify it under
# the terms of the GNU Lesser General Public License as published by the Free
# Software Foundation; either version 2.1 of the License, or (at your option)
# any later version.
# This library is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more
# details.
# You should have received a copy of the GNU Lesser General Public License
# along with this library; if not, write to the Free Software Foundation, Inc.,
# 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
#

from libtbx.cluster import *
from difflib import SequenceMatcher
import unittest
import sys

def compare_list(x, y):
   """
   Compare lists by content. Ordering does not matter.
   Returns True if both lists contain the same items (and are of identical
   length)
   """

   cmpx = [set(cluster) for cluster in x]
   cmpy = [set(cluster) for cluster in y]

   all_ok = True

   for cset in cmpx:
      all_ok &= cset in cmpy

   for cset in cmpy:
      all_ok &= cset in cmpx

   return all_ok


class HClusterSmallListTestCase(unittest.TestCase):
   " Test for Bug #1516204 "

   def testClusterLen1(self):
      "Testing if hierarchical clustering a set of length 1 returns a set of length 1"
      cl = HierarchicalClustering([876], lambda x,y: abs(x-y))
      self.assertEqual([876], cl.getlevel(40))

   def testClusterLen0(self):
      "Testing if hierarchical clustering an empty list returns an empty list"
      cl = HierarchicalClustering([], lambda x,y: abs(x-y))
      self.assertEqual([], cl.getlevel(40))

class HClusterIntegerTestCase(unittest.TestCase):

   def setUp(self):
      self.__data = [791, 956, 676, 124, 564, 84, 24, 365, 594, 940, 398,
                     971, 131, 365, 542, 336, 518, 835, 134, 391]

   def testCluster(self):
      "Basic Hierarchical Clustering test with integers"
      cl = HierarchicalClustering(self.__data, lambda x,y: abs(x-y))
      cl.cluster()
      self.assertEqual( [
            [24],
            [84, 124, 131, 134],
            [336, 365, 365, 365, 398, 391],
            [940, 956, 971],
            [791],
            [835],
            [676],
            [518, 564, 542]
            ],
            cl.getlevel(40))

class HClusterStringTestCase(unittest.TestCase):

   def sim(self, x, y):
      sm = SequenceMatcher(lambda x: x in ". -", x, y)
      return 1-sm.ratio()

   def setUp(self):
      self.__data = "Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Ut elit. Phasellus consequat ultricies mi. Sed congue leo at neque. Nullam.". split()

   def testDataTypes(self):
      "Test for bug #?"
      cl = HierarchicalClustering(self.__data, self.sim)
      for item in cl.getlevel(0.5):
         self.assertEqual(
               type(item), type([]),
               "Every item should be a list!")

   def testCluster(self):
      "Basic Hierachical clustering test with strings"
      cl = HierarchicalClustering(self.__data, self.sim)
      self.assertEqual([
               ['Nullam.'],
               ['Sed'],
               ['mi.'],
               ['ultricies'],
               ['Phasellus'],
               ['amet,', 'at'],
               ['sit', 'elit.', 'elit.', 'elit.'],
               ['leo', 'Lorem', 'dolor'],
               ['neque.', 'congue', 'consectetuer', 'consequat'],
               ['ipsum'],
               ['adipiscing']
               ],
            cl.getlevel(0.5)
            )

class KClusterSmallListTestCase(unittest.TestCase):

   def testClusterLen1(self):
      "Testing that a search space of length 1 returns only one cluster"
      cl = KMeansClustering([876])
      self.assertEqual([876], cl.getclusters(2))
      self.assertEqual([876], cl.getclusters(5))

   def testClusterLen0(self):
      "Testing if clustering an empty set, returns an empty set"
      cl = KMeansClustering([])
      self.assertEqual([], cl.getclusters(2))
      self.assertEqual([], cl.getclusters(7))

class KCluster2DTestCase(unittest.TestCase):

   def testClusterCount(self):
      "Test that asking for less than 2 clusters raises an error"
      cl = KMeansClustering([876, 123, 344, 676], distance=lambda x,y: abs(x-y))
      self.assertRaises(ClusteringError, cl.getclusters, 0)
      self.assertRaises(ClusteringError, cl.getclusters, 1)

   def testNonsenseCluster(self):
      "Test that asking for more clusters than data-items available raises an error"
      cl = KMeansClustering([876, 123], distance=lambda x,y: abs(x-y))
      self.assertRaises(ClusteringError, cl.getclusters, 5)

   def testUniformLength(self):
      "Test if there is an item in the cluster that has a different cardinality"
      data = [ (1,5), (2,5), (2,6), (3,4), (3,5), (3,6,7), (7,3), (8,1), (8,2), (8), (9,2), (9,3) ]
      self.assertRaises(ValueError, KMeansClustering, data)

   def testPointDoubling(self):
      "test for bug #1604868"
      data = [ (18,13), (15, 12), (17,12), (18,12), (19,12), (16,11), (18, 11),
             (19,10), (0,0), (1, 4), (1,2), (2,3), (4,1), (4,3), (5,2), (6,1)]
      cl = KMeansClustering(data)
      clusters = cl.getclusters(2)
      expected = [[(18,13), (15, 12), (17,12), (18,12), (19,12), (16,11), (18, 11), (19,10)],
             [(0,0), (1, 4), (1,2), (2,3), (4,1), (5,2), (6,1), (4,3)]]
      self.assertEqual( True, compare_list(
            clusters,
            expected ),
            "Elements differ!\n%s\n%s" % (clusters, expected))

   def testClustering(self):
      "Basic clustering test"
      data = [ (8,2), (7,3), (2,6), (3,5), (3,6), (1,5), (8,1), (3,4), (8,3), (9,2), (2,5), (9,3) ]
      cl = KMeansClustering(data)
      clusters = cl.getclusters(2)
      self.assertEqual(
            cl.getclusters(2),
            [[(8, 2), (8, 1), (8, 3), (7, 3), (9, 2), (9, 3)],
             [(3, 5), (1, 5), (3, 4), (2, 6), (2, 5), (3, 6)]])

class KClusterSFBugs(unittest.TestCase):

   def testLostFunctionReference(self):
      "test for bug #1727558"
      cl = KMeansClustering([(1,1), (20,40), (20,41)], lambda x,y:x+y)
      clusters = cl.getclusters(3)
      expected = [(1,1), (20,40), (20,41)]
      self.assertEqual( True, compare_list(
            clusters,
            expected ),
            "Elements differ!\n%s\n%s" % (clusters, expected))

if (__name__ == "__main__"):
  unittest.TextTestRunner(stream=sys.stdout, verbosity=0).run(
      unittest.TestSuite((
            unittest.defaultTestLoader.loadTestsFromTestCase(HClusterSmallListTestCase),
            unittest.defaultTestLoader.loadTestsFromTestCase(HClusterIntegerTestCase),
            unittest.defaultTestLoader.loadTestsFromTestCase(HClusterStringTestCase),
            unittest.defaultTestLoader.loadTestsFromTestCase(KClusterSmallListTestCase),
            unittest.defaultTestLoader.loadTestsFromTestCase(KCluster2DTestCase),
            unittest.defaultTestLoader.loadTestsFromTestCase(KClusterSFBugs),
         ))
      )


 *******************************************************************************


 *******************************************************************************
libtbx/code_analysis.py
""" Tools to statically analyse source code in various languages """
from __future__ import absolute_import, division, print_function

import os
import re
from glob import glob


class comments(object):
  """ Information about comment lines """

  def __init__(self, files, debug=False):
    """ Construct the information for the given files """
    self.debug = debug
    self.commented_lines = 0
    self.lines = 0
    for f in files:
      for p in glob(f):
        p = os.path.expanduser(p)
        root, ext = os.path.splitext(p)
        ext = ext.lower()
        if ext in ('.f', '.fpp', '.inc', '.f77', '.f90'):
          self.process_fortran(p)
        else:
          raise NotImplemented(ext)

  fortran_start_of_line = re.compile(r'^ (?: C | \* | !) \W* \w', re.X)
  fortran_bang_anywhere = re.compile(r'! \W* \w', re.X)

  def process_fortran(self, file_path):
    n = 0
    for line in open(file_path):
      self.lines += 1
      if self.fortran_start_of_line.search(line):
        n += 1
        if self.debug: print(self.lines, line)
        continue
      bang = line.rfind('!')
      if bang < 0: continue
      single_quote, double_quote = line.rfind("'"), line.rfind('"')
      if single_quote >= 0 or double_quote >= 0:
        if single_quote >= 0 and double_quote >= 0:
          quote = max(single_quote, double_quote)
        elif single_quote >= 0:
          quote = single_quote
        else:
          quote = double_quote
        if quote < bang: continue
      if self.fortran_bang_anywhere.search(line, pos=bang):
        n += 1
        if self.debug: print(self.lines, line)
    self.commented_lines += n


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/__init__.py


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/add_from_future_import_division.py
from __future__ import absolute_import, division, print_function
import ast
import os
import sys
import libtbx.load_env

def fix(module_path, imports=None):
  if not imports:
    imports = ['division']
  want = set(imports)

  if os.path.getsize(module_path) == 0: # Do not add __future__ imports to empty files
    return

  with open(module_path) as fh:
    module_lines = fh.readlines()
  syntax_tree = ast.parse(''.join(module_lines), filename=module_path)
  # the attribute lineno is the index of the line *following* that node
  if ast.get_docstring(syntax_tree):
    insertion_lineno = syntax_tree.body[0].lineno
  else:
    insertion_lineno = 0

  for node in ast.iter_child_nodes(syntax_tree):
    if isinstance(node, ast.ImportFrom) and node.module == '__future__':
      insertion_lineno = node.lineno
      for n in node.names:
        want.discard(n.name)

  if not want:
    return

  missing_future = ", ".join(sorted(want))
  module_lines.insert(insertion_lineno, "from __future__ import %s\n" % missing_future)

  # Check syntax before making change
  try:
    modified_syntax_tree = ast.parse(''.join(module_lines))
  except SyntaxError:
    print("Cannot add {stmt} to {file}, causes syntax error".format(stmt=missing_future, file=module_path))
    return

  # Compare the modified syntax tree to the original tree
  for n, node in enumerate(modified_syntax_tree.body):
    if isinstance(node, ast.ImportFrom) and node.module == '__future__' and node.names[0].name in want:
      del(modified_syntax_tree.body[n])
      break
  if ast.dump(modified_syntax_tree) != ast.dump(syntax_tree):
    print("Cannot add {stmt} to {file}, changes parsing tree".format(stmt=missing_future, file=module_path))
    return

  print("Adding {stmt} to {file}".format(stmt=missing_future, file=module_path))
  with open(module_path, mode='w') as fh:
    fh.writelines(module_lines)

def run(locations):
  check_for_imports = ['division']
  if '--absolute_import' in locations:
    check_for_imports.append('absolute_import')
    locations.remove('--absolute_import')
  if '--print_function' in locations:
    check_for_imports.append('print_function')
    locations.remove('--print_function')
  if '-3' in locations:
    check_for_imports.append('absolute_import')
    check_for_imports.append('print_function')
    locations.remove('-3')

  if not locations:
    locations = [ os.path.dirname(libtbx.env.dist_path('libtbx')) ]
  for l in locations:
    if os.path.isfile(l) and l.endswith('.py'):
      fix(l, imports=check_for_imports)
    else:
      for dirpath, dirs, filenames in os.walk(l):
        dirs[:] = [d for d in dirs if not d.endswith('jinja2') and d not in ('.git', '__pycache__')]
        for f in filenames:
          if f.endswith('.py'):
            fix(os.path.join(dirpath, f), imports=check_for_imports)

if __name__ == '__main__':
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/analyse_code_comments.py
from __future__ import absolute_import, division, print_function
from libtbx import code_analysis
from libtbx.option_parser import option_parser

def run(args, debug=False):
  comments = code_analysis.comments(args, debug=debug)
  print(comments.commented_lines, comments.lines,\
        round(comments.commented_lines/comments.lines * 100, 1))

if __name__ == '__main__':
  import sys
  command_line = (option_parser(
    usage="",
    description="")
    .option(None, "--debug",
            dest='debug',
            action="store_true",
            default=False)
  ).process(args=sys.argv[1:])
  run(command_line.args, **command_line.options.__dict__)


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/any2unix.py
from __future__ import absolute_import, division, print_function
import sys, os

def run(args):
  for path in args:
    problem = None
    if (not os.path.isfile(path) or os.path.islink(path)):
      problem = "not a regular file"
    else:
      try:
        file_content = open(path, "rb").read()
      except Exception:
        problem = "no read access"
      else:
        if (not os.access(path, os.W_OK)):
          problem = "no write access"
    if (problem is not None):
      print("%s: %s -> no action" % (path, problem))
    else:
      n_cr = file_content.count("\r")
      n_lf = file_content.count("\n")
      n_crlf = file_content.count("\r\n")
      action = "unknown -> no action"
      unix_content = None
      if (n_crlf > 0 and n_crlf == n_cr):
        action = "dos -> unix"
        unix_content = file_content.replace("\r\n", "\n")
        if (ord(unix_content[-1]) == 26):
          unix_content = unix_content[:-1]
      elif (n_cr > 0 and n_lf == 0):
        action = "mac -> unix"
        unix_content = file_content.replace("\r", "\n")
      elif (n_lf > 0 and n_cr == 0):
        action = "unix -> no action"
      print("%s: %s" % (path, action))
      if (unix_content is not None):
        if (unix_content[-1] != "\n"):
          unix_content += "\n"
        try:
          open(path, "wb").write(unix_content)
        except Exception:
          print("FATAL ERROR: Cannot write file:", path, file=sys.stdout)
          path_copy = path + "_copy"
          print("Saving copy of old content as file:", path_copy, file=sys.stdout)
          open(path_copy, "wb").write(file_content)
          sys.exit(1)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/assert_line_count.py
from __future__ import absolute_import, division, print_function
import sys

def run(args):
  assert len(args) == 1
  expected_count = int(args[0])
  assert len(sys.stdin.read().splitlines()) == expected_count

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/assert_not_show_diff.py
from __future__ import absolute_import, division, print_function
import sys

def run(args):
  assert len(args) == 2, "file1 file2"
  from libtbx.test_utils import show_diff
  texts = ["\n".join(open(arg).read().splitlines()) for arg in args]
  assert not show_diff(texts[0], texts[1])

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/assert_stdin.py
from __future__ import absolute_import, division, print_function
import sys

def run():
  input = " ".join([line.rstrip() for line in sys.stdin.readlines()])
  pattern = " ".join(sys.argv[1:])
  if (input != pattern):
    sys.tracebacklimit = 0
    raise AssertionError('"%s" != "%s"' % (input, pattern))

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/assert_stdin_contains_strings.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME libtbx.assert_stdin_contains_strings
# LIBTBX_SET_DISPATCHER_NAME libtbx.assert_stdin_does_not_contain_strings
import libtbx.load_env
import sys

def run(args):
  dn = libtbx.env.dispatcher_name
  does_not = (dn.find("does_not") >= 0)
  input = "\n".join(sys.stdin.read().splitlines()) + "\n"
  for arg in args:
    s = "\n".join(arg.splitlines())
    if ((input.find(s) < 0) == does_not): continue
    print("BEGIN OF INPUT (%s)" % dn)
    print("v" * 79)
    sys.stdout.write(input)
    print("^" * 79)
    print("END OF INPUT (%s)" % dn)
    if (does_not): s = "found"
    else:          s = "not"
    raise AssertionError("String %s in input: %s" % (s, arg))

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/assert_stdin_ends_with.py
from __future__ import absolute_import, division, print_function
import sys

def run(args):
  assert len(args) == 1
  expected_last_line = args[0]
  assert sys.stdin.read().splitlines()[-1] == expected_last_line

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/bootstrap.py
from __future__ import absolute_import, division, print_function
import os
import libtbx.auto_build.bootstrap

def run():
  root = os.environ.get('LIBTBX_BUILD')
  if root:
    root = os.path.join(root, '..')
    os.chdir(root)
  libtbx.auto_build.bootstrap.run()

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/bundle_as_exe.py
from __future__ import absolute_import, division, print_function
import sys, os

def create_autorun(bundle_prefix, single_dir=False):
  if (not single_dir):
    return """\
$AUTORUN$>.\\%(bundle_prefix)s_install_script.bat
.
""" % vars()
  else :
    return """\
$AUTORUN$>.\\%(bundle_prefix)s\\%(bundle_prefix)s_install_script.bat
.
""" % vars()

def run(args):
  no_unzipsfx = (len(args) > 0 and args[0] == "--no-unzipsfx")
  if (no_unzipsfx):
    args = args[1:]
  single_dir = (len(args) > 0 and args[0] == "--single_directory")
  if (single_dir):
    args = args[1:]
  if (len(args) < 2):
    from libtbx.utils import Usage
    import libtbx.load_env
    raise Usage(
      "%s [--no-unzipsfx] [--single_directory] bundle_prefix platform_string [addl_files...]"
        % libtbx.env.dispatcher_name)
  if (os.name == "nt"):
    exe_suffix = ".exe"
  else:
    exe_suffix = ""
  import libtbx.path
  path_zip = libtbx.path.full_command_path(
    command="zip"+exe_suffix, search_first=["."])
  if (path_zip is None):
    raise RuntimeError("Fatal: zip executable not found.")
  bundle_prefix = args[0]
  if (single_dir) and (not os.path.isdir(bundle_prefix)):
    from libtbx.utils import Sorry
    raise Sorry("%s does not exist or is not a directory." % bundle_prefix)
  platform_string = args[1]
  addl_files = args[2:]
  zip_file_name = "%(bundle_prefix)s_%(platform_string)s.zip" % vars()
  open("autorun", "w").write(create_autorun(bundle_prefix, single_dir))
  if (single_dir):
    cmd = ("\"%(path_zip)s\" -q -r -z %(zip_file_name)s"
        + " %(bundle_prefix)s") % vars()
  else :
    cmd = ("\"%(path_zip)s\" -q -r -z %(zip_file_name)s"
        + " %(bundle_prefix)s_sources"
        + " %(bundle_prefix)s_build"
        + " %(bundle_prefix)s_install_script.bat") % vars()
  for addl in addl_files:
    cmd += " " + addl
  cmd += " < autorun"
  print(cmd)
  from libtbx import easy_run
  easy_run.fully_buffered(command=cmd).raise_if_errors().show_stdout()
  if (not no_unzipsfx):
    from libtbx.command_line import create_unzipsfx
    create_unzipsfx.create(zip_file_name=zip_file_name)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/check_libcpp.py
#!/usr/bin/env python
# -*- coding: utf-8 -*-
from __future__ import absolute_import, division, print_function

import sys
from   libtbx import easy_run
from   os     import listdir



def check_libcpp():

  #______________________________________________________________________________
  # get the libstd version that the python executable links against
  #
  python_libstdcxx_so = None
  ldd_exec = easy_run.fully_buffered(command="ldd " + str(sys.executable))
  for line in ldd_exec.stdout_lines:
    if line.strip().startswith("libstdc++.so"):
      python_libstdcxx_so = line.split()[0]
      break

  if python_libstdcxx_so is None:
    return False
  #
  #------------------------------------------------------------------------------

  #______________________________________________________________________________
  # Go through all installed *.so's and ensure that they are linking to the same
  # libstdc++ as python executable
  #
  lib_dir = join(
      libtbx.env.lib_path._anchor._path, libtbx.env.lib_path.relocatable
  )
  libs = [join(lib_dir, name) for name in listdir(lib_dir) if name.endswith(".so")]
  for lib in libs:
    ldd_lib = easy_run.fully_buffered(command="ldd " + str(lib))
    for line in ldd_lib.stdout_lines:
      if line.strip().startswith("libstdc++.so"):
        lib_libstdcxx_so = line.split()[0]
        if lib_libstdcxx_so != python_libstdcxx_so:
          raise SystemError(
            "FATAL: libstdc++.so mismatch\n"
            "sys.executable: " + str(sys.executable) + "\n"
            "lib_file:" + str(lib)
          )
        break
  #
  #------------------------------------------------------------------------------

  return True



if __name__=="__main__":

  if not sys.platform.startswith("linux"):
    print("This test only works on Linux at the moment")
  else:
    if check_libcpp():
      print("Success!")
    else:
      print(
        "This test was not run because your python executable was not linked "
        "against libstdc++ => this test is not needed."
      )


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/chunk.py
from __future__ import absolute_import, division, print_function
from libtbx.queuing_system_utils import chunk_manager
from libtbx.utils import Usage
import sys

def usage():
  raise Usage("libtbx.chunk [n] [i]")

def run(args):
  if (len(args) == 0): usage()
  for arg in args:
    if (arg not in ["n", "i"]): usage()
  cm = chunk_manager(n=1, i=0).queuing_system_overrides_chunk()
  for arg in args:
    if   (arg == "n"): print(cm.n, end=' ')
    elif (arg == "i"): print(cm.i, end=' ')
  print()

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/clean_clutter.py
from __future__ import absolute_import, division, print_function
import sys
import os
import shutil
from libtbx.option_parser import option_parser
import libtbx.file_clutter

def clean_clutter_in(files, tabsize=8):
  if not files: return
  for fname in files:
    tmpname = fname + '.bak'
    if os.path.isfile(tmpname):
      print("found temporary file {temp}, ignoring {original}.".format(temp=tmpname, original=fname))
      continue
    if os.path.isfile(fname):
      try:
        print(fname)
        with open(fname, 'rb') as ifh, open(tmpname, 'wb') as ofh:
          # explicitly convert Windows linebreaks into Unix linebreaks
          lines = ifh.read().replace(b'\r\n', b'\n').split(b'\n')
          n_empty = 0
          for line in lines:
            clean_line = line.expandtabs(tabsize).rstrip()
            if clean_line:
              ofh.write(b"\n" * n_empty + clean_line + b"\n")
              n_empty = 0
            else:
              n_empty += 1
        shutil.move(tmpname, fname)
      except: # intentional
              # to trap KeyboardInterrupt, too
        os.remove(tmpname)
        raise

def isort(path):
  # Potential ImportErrors are caught upstream
  import mock
  from isort.main import main
  return # Disable isort pending resolution of https://github.com/timothycrosley/isort/issues/606
  with mock.patch.object(sys, 'argv', ['isort', '-y', '-ac', '-vb']):
    oldcwd = os.getcwd()
    try:
      os.chdir(path)
      main()
    finally:
      os.chdir(oldcwd)

def run():
  opt_parser = (option_parser(
    usage="""
clean_clutter [-t n | --tabsize=n] file1 file2 ...
clean_clutter [-t n | --tabsize=n] [directory]""",
    description="""The first form cleans the specified files whereas the second
form cleans all files in the hierarchy rooted in the given directory or
the current directory is none is given.""")
    .option("-t", "--tabsize",
      action="store",
      type="int",
      default=8,
      help="the number of spaces a tab is to be replaced by",
      metavar="INT")
  )
  command_line = opt_parser.process(args=sys.argv[1:])
  co = command_line.options
  files = command_line.args
  run_isort_in_path = False
  if len(files) <= 1:
    if not files: dir = '.'
    else: dir = files[0]
    files = [ c.path for c in libtbx.file_clutter.gather([dir])
              if c.is_cluttered(flag_x=False) ]
    if os.path.exists(os.path.join(dir, '.isort.cfg')):
      run_isort_in_path = dir
  clean_clutter_in(files, tabsize=co.tabsize)
  if run_isort_in_path:
    try:
      isort(run_isort_in_path)
    except Exception as e:
      print("Did not run isort (%s)" % str(e))

if __name__ == "__main__":
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/clear_paths.py
from __future__ import absolute_import, division, print_function
from libtbx.clear_paths \
  import remove_or_rename_files_and_directories_if_possible
import sys

def run(args):
  remaining = remove_or_rename_files_and_directories_if_possible(paths=args)
  for path in remaining:
    "WARNING: unable to remove or rename:", path

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/create_cctbx_bundle_for_installer.py

from __future__ import absolute_import, division, print_function
import sys

if (__name__ == "__main__"):
  import libtbx.auto_build.create_cctbx_bundle_for_installer
  libtbx.auto_build.create_cctbx_bundle_for_installer.run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/create_install_script_bat.py
from __future__ import absolute_import, division, print_function
import sys

def run(args):
  from libtbx.utils import Usage
  import libtbx.load_env
  if (len(args) != 2):
    raise Usage("%s bundle_name top_modules" % libtbx.env.dispatcher_name)
  bundle_name, top_modules = args
  install_script = bundle_name+"_install_script.bat"
  from libtbx.bundle import install_bat
  open(install_script, "w").write(
    install_bat.create_script(
      bundle=bundle_name,
      top_modules=top_modules))

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/create_installer.py
from __future__ import absolute_import, division, print_function
import sys

if (__name__ == "__main__"):
  from libtbx.auto_build import create_installer
  sys.exit(create_installer.run(sys.argv[1:]))


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/create_mac_app.py

from __future__ import absolute_import, division, print_function
import sys

if (__name__ == "__main__"):
  from libtbx.auto_build import create_mac_app
  sys.exit(create_mac_app.run(sys.argv[1:]))


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/create_selfx.py
from __future__ import absolute_import, division, print_function
import sys, os

buf_size = 1000000

def perl_header(selfx, command):
  print("""\
#! /usr/bin/env perl
#
# This is a self-extracting tar.gz file.
# Usage:
#   perl name_of_this_file
#
# The perl header of this file is
#
# Copyright (c) 2003 The Regents of the University of California
# through E.O. Lawrence Berkeley National Laboratory, subject to
# approval by the U.S. Department of Energy.
#
# and was written in May 2003 by Ralf W. Grosse-Kunstleve.
# See also:
#   http://cctbx.svn.sourceforge.net/viewvc/*checkout*/cctbx/trunk/libtbx/LICENSE_2_0.txt
#
# The above copyright notice does *not* apply to the attached tar.gz file.
#
print "Unpacking self-extracting archive\\n";
$my_size = -s $0;
open(SELF,"<$0") or die "ERROR: Cannot read self-extracting archive!\\n";
binmode SELF;
$last_seven = "0000000";
$n_end = 0;
$n_header = 0;
while ($n_header < $my_size && $n_end < 2) {
  $n_header++;
  $ch = getc(SELF);
  $last_seven = substr($last_seven, 1, 6) . $ch;
  if ($last_seven eq "__END__") {
    $n_end += 1;
  }
}
while ($n_header < $my_size && $ch ne "@") {
  $n_header++;
  $ch = getc(SELF);
}
if ($n_header == $my_size) {
  die "ERROR: Corrupt self-extracting archive!\\n";
}
open(TAR_PIPE, "|gunzip -c | tar xf -");
binmode TAR_PIPE;
while (read(SELF, $buf, %d) != 0) {
  syswrite(TAR_PIPE, $buf, length($buf));
}
close(TAR_PIPE);""" % buf_size, file=selfx)
  if (command != None):
    print('$cmd = join(" ", ("%s", @ARGV));' % command, file=selfx)
    print('print "Running command: $cmd\\n";', file=selfx)
    print('system("$cmd");', file=selfx)
  print("__END__", file=selfx)
  selfx.write("@")

def create(tar_file_name, command):
  assert tar_file_name.endswith(".tar.gz") or tar_file_name.endswith(".tgz")
  assert command == None or isinstance(command, str)
  assert command.startswith("./")
  tar_file = open(tar_file_name, "rb")
  selfx_file_name = os.path.split(tar_file_name)[-1]
  if (selfx_file_name.endswith(".tar.gz")):
    selfx_file_name = selfx_file_name[:-7]
  else:
    selfx_file_name = selfx_file_name[:-4]
  selfx_file_name += ".selfx"
  selfx = open(selfx_file_name, "wb")
  perl_header(selfx, command)
  while True:
    buf = tar_file.read(buf_size)
    if (buf == ""): break
    selfx.write(buf)
  tar_file.close()
  selfx.close()

def run(args):
  "usage: libtbx.create_selfx tar_file_name [command]"
  if (not len(args) in (1,2) or "-h" in args or "--help" in args):
    print(run.__doc__)
    return
  tar_file_name = args[0]
  command = None
  if (len(args) == 2):
    command = args[1]
  create(tar_file_name, command)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/create_unzipsfx.py
from __future__ import absolute_import, division, print_function
import libtbx.path
import sys

buf_size = 1000000

def copy(src, dest):
  while True:
    buf = src.read(buf_size)
    if (buf == ""): break
    dest.write(buf)

def find_unzipsfx():
  for command in ("unzipsfx_autorun_yes.exe",
                  "unzipsfx_autorun.exe",
                  "unzipsfx.exe"):
    path_cmd = libtbx.path.full_command_path(
      command=command, search_first=["."])
    if (path_cmd is not None): return path_cmd
  return None

def create(zip_file_name, path_unzipsfx_exe=None):
  if (path_unzipsfx_exe is None):
    path_unzipsfx_exe = find_unzipsfx()
  if (path_unzipsfx_exe is None):
    raise RuntimeError("Fatal: unzipsfx executable not found.")
  assert zip_file_name.endswith(".zip")
  exe_file_name = zip_file_name[:-4] + ".exe"
  exe_file = open(exe_file_name, "wb")
  copy(open(path_unzipsfx_exe, "rb"), exe_file)
  copy(open(zip_file_name, "rb"), exe_file)
  exe_file.close()

def run(args):
  "usage: libtbx.create_unzipsfx [path_unzipsfx_exe] zip_file_name"
  if (not len(args) in (1,2) or "-h" in args or "--help" in args):
    print(run.__doc__)
    return
  if (len(args) == 1):
    create(zip_file_name=args[0])
  else:
    create(zip_file_name=args[1], path_unzipsfx_exe=args[0])

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/create_windows_exe.py

from __future__ import absolute_import, division, print_function
import sys

if (__name__ == "__main__"):
  from libtbx.auto_build import create_windows_exe
  sys.exit(create_windows_exe.run(sys.argv[1:]))


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/dtrace.py
from __future__ import absolute_import, division, print_function
import sys, os
import libtbx.load_env

def run():
  if len(sys.argv) < 2: help()
  libtbx_path = libtbx.env.find_in_repositories('libtbx')
  dtrace_directory = os.path.join(libtbx_path, 'dtrace')
  dtrace_script = sys.argv[1]
  params = []
  python_script_and_its_arguments = []
  for opt in sys.argv[2:]:
    if '=' in opt:
      params.append("-D%s" % opt)
    else:
      python_script_and_its_arguments.append(opt)
  python_script_and_its_arguments = " ".join(python_script_and_its_arguments)
  if (not os.path.isfile(dtrace_script)
      and not os.path.dirname(dtrace_script)):
    if dtrace_script[-2:] != '.d': dtrace_script += '.d'
    dtrace_script = os.path.join(dtrace_directory, dtrace_script)
  if not os.path.isfile(dtrace_script): help()
  args = [ "dtrace",
           "-Z", # essential because the Python probes are dynamically
                 # created after Python has launched to run the script
           "-C",
           "-s", dtrace_script,
         ] + params + [
            "-c", "%s %s" % (sys.executable, python_script_and_its_arguments)
         ]
  os.execvp("dtrace", args)


def help():
  print("usage: libtbx.dtrace dtrace_script [ param=value ...] ", end=' ')
  print("python_script [args ...]")
  print()
  print("       dtrace_script can be either the path of a dtrace script")
  print("       or if there is no file at that path, a dtrace script")
  print("       in libtbx/dtrace. In the latter case, the extension .d can")
  print("       omitted on the command line.")
  sys.exit(1)

if __name__ == '__main__':
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/easy_qsub.py
"""
libtbx.qsub(
 where=path_to_where_you_want_to_run_your_jobs,
 source="/net/chevy/raid1/afonine/build/setpaths.csh",
 commands=[list of commands])

where [list of commands]) is

["python run.py model1.pdb data1.mtz",
 "python run.py model2.pdb data2.mtz",
...,
"python run.py modelN.pdb dataN.mtz" ]
"""
from __future__ import absolute_import, division, print_function
import os
import re
import subprocess
from six.moves import cStringIO as StringIO
import sys
import time
import stat

from libtbx import easy_run
from libtbx.utils import Sorry
from six.moves import range

key_words = {
  "phenix_source"    : str,
  "where"            : str,
  "commands"         : str,
  "number_of_chunks" : int,
  "size_of_chunks"   : int,
  "code"             : str,
  "js"               : int,
  "qsub_cmd"         : str,
  "start"            : int,
  "end"              : int,
  "host_scratch_dir" : str,
  "python_script"    : str,
  "parallel_nodes"   : int,
  'fake_queue'       : bool,
  }

script_file = """
import os, sys
from libtbx import easy_run

cmds = [
%s
]

def run(only_i=None,
        chunk_n=1,
        chunk_size=len(cmds),
        ):
  try: only_i = int(only_i)
  except ValueError: only_i=None

  try: chunk_n = int(chunk_n)
  except ValueError: chunk_n=1
  try: chunk_size = int(chunk_size)
  except ValueError: chunk_size=len(cmds)

  #assert chunk_size==len(cmds) or chunk_n==1
  assert chunk_n>0
  assert chunk_size>0
  #if chunk_n!=1:
  #  chunk_size = (len(cmds)-1)//chunk_n+1
  #elif chunk_size!=1:
  #  chunk_n = len(cmds)%%chunk_size+1

  for i, cmd in enumerate(cmds):
    if only_i is None:
      print(i, cmd)
      continue
    else:
      if chunk_n!=1 or chunk_size!=len(cmds):
        if only_i!=i//chunk_size+1: continue
      else:
        if only_i!=i+1: continue
    print('Running', i+1)
    print('Command', cmd)
    easy_run.call(cmd)

if __name__=="__main__":
  run(*tuple(sys.argv[1:]))
"""

host_scratch_dir_pre = """
set work_dir=$PWD

set host_scratch_dir=/net/$host/scratch1/$user
if (! -d $host_scratch_dir) then
  echo "================================"
  echo " Creating host scratch directory $host_scratch_dir"
  echo "================================"
  mkdir $host_scratch_dir
endif

set host_scratch_dir=/net/$host/scratch1/$user/%s
if (! -d $host_scratch_dir) then
  echo "================================"
  echo " Creating host scratch directory $host_scratch_dir"
  echo "================================"
  mkdir $host_scratch_dir
endif

set host_scratch_dir=/net/$host/scratch1/$user/%s/$SGE_TASK_ID
if (! -d $host_scratch_dir) then
  echo "================================"
  echo " Creating host scratch directory $host_scratch_dir"
  echo "================================"
  mkdir $host_scratch_dir
endif

echo "=============="
echo " Changing into $host_scratch_dir"
echo "=============="
cd $host_scratch_dir
"""
host_scratch_dir_post = """
echo "==================="
echo " Move files back to $work_dir"
echo "==================="
mv * $work_dir
"""

run_file = """#! /bin/csh -q
#$ -cwd
#$ -o %s_queue.output -j y -N %s
limit datasize 2000000

source %s

%s

libtbx.python %s $SGE_TASK_ID %s %s >& %s.$SGE_TASK_ID.out

%s

exit

"""

test_run_script = """
import os, sys

def run(only_i=None):
  print("%s " % only_i)
  f=open("test_%s.output" % only_i, "w")
  f.write("Testing %s\\n" % only_i)
  f.close()

if __name__=="__main__":
  run(*tuple(sys.argv[1:]))
"""

qblock = """#! /bin/csh -q
#$ -j y
while (1)
  sleep 3600
end
"""

def run_sh(cmd):
  t0=time.time()
  rc = easy_run.call(cmd)
  print('done "%s" in %0.1f' % (cmd.strip(),
                                time.time()-t0))

def test_easy_qsub():
  def _clean():
    for filename in os.listdir(os.getcwd()):
      if filename.startswith("commands"):
        print('remove',filename)
        os.remove(filename)
  def _write_cmds(number_of_cmds):
    print("\n  test list of commands")
    outl = ""
    for i in range(number_of_cmds):
      outl += "echo %d\n" % (i+101)
    print(outl)
    f=open("commands.txt", "w")
    f.write(outl[:-1])
    f.close()
  def _wait():
    import time
    time.sleep(5)
    running=True
    while running:
      running=False
      for line in os.popen("qstat"):
        if line.find("commands")>-1:
          print('running',line)
          running=True
          break
  def _check(number_of_output_files,
             number_of_runs,
             ):
    runs=[]
    for filename in os.listdir(os.getcwd()):
      if filename.startswith("commands") and filename.endswith(".out"):
        number_of_output_files-=1
        f=open(filename, "r")
        lines=f.readlines()
        f.close()
        for line in lines:
          if line.find("Running")>-1:
            number_of_runs-=1
            tmp = line.split()
            assert tmp[1] not in runs
            runs.append(tmp[1])

    assert not number_of_output_files
    assert not number_of_runs

  print('#'*80)
  print('# testing easy_qsub')
  print('#'*80)
  cmd = 'libtbx.easy_qsub phenix_source="/net/cci/xp/phenix/phenix_env" commands=commands.txt'
  old_cmd = cmd
  for cmds, new_cmd, number_of_output_files, number_of_runs in [
      [10,"",10,10],
      [10," number_of_chunks=2", 2, 10],
      [11," number_of_chunks=2", 2, 11],
      [10," size_of_chunks=2",   5, 10],
      [11," size_of_chunks=2",   6, 11],
      [10," start=6",            5, 5],
      [10," end=5",              5, 5],
      [20," start=5 size_of_chunks=2", 6, 12],
      [20," end=5 size_of_chunks=2", 5, 10],
      ]:
    cmd = old_cmd + new_cmd
    _clean()
    _write_cmds(cmds)
    os.system(cmd)
    _wait()
    _check(number_of_output_files=number_of_output_files,
           number_of_runs=number_of_runs,
      )
  _clean()
  #
  sys.exit()

def process_args(args):
  kwds = {}
  for t in args:
    if t in ["--help", "-h"]:
      print("""
  Program to sumbit jobs easily to a SGE queue
    e.g.

    libtbx.easy_qsub phenix_source="/net/cci/xp/phenix/phenix_env" commands=commands.txt

  """)
      sys.exit()
    elif t=="--test":
      test_easy_qsub()
      return {}
    elif t=="--dry":
      kwds["dry_run"]=True
    for key in key_words:
      if t.find("%s=" % key)==0:
        kwds[key]=t.split("=")[1]
        kwds[key] = key_words[key](kwds[key])
        break
    else:
      if t not in ["--dry"]:
        print('\n  failed to process "%s"\n' % t)
        assert 0
  return kwds

def get_queue_machine_details():
  cmd = "qstat -f"
  ero = easy_run.fully_buffered(command = cmd)
  out = StringIO()
  ero.show_stdout(out = out)
  rc = {}
  for line in out.getvalue().split("\n"):
    if line.find("all.q@")>-1:
      tmp = line.split()
      rc.setdefault(tmp[0], [])
      rc[tmp[0]].append(int(tmp[2].split("/")[0]))
      rc[tmp[0]].append(int(tmp[2].split("/")[1]))
  return rc

def get_python_bin(source):
  import libtbx.load_env
  return libtbx.env.python_exe.sh_value()

def run(phenix_source=None,
        where=None,
        commands=None,
        size_of_chunks=1,
        number_of_chunks=None,
        code=None,
        js=0,
        qsub_cmd="qsub",
        start=1,
        end=None,
        host_scratch_dir=None,
        python_script=None,
        parallel_nodes=1,
        fake_queue=False,
        dry_run=False,
        ):
  help = """
  Submits a job to run commands on the queueing system using qsub. One master
  job is sent, which then deploys multiple sub jobs (Of the same job ID) to run
  each separate command.

  phenix_source: A path to the script used to initial the phenix environment
  where: A path to the directory in which to run the commands
  commands: A list of commands to run on the queue
  size_of_chunks: Number of commands to run within each queue job
  code: The task name used during submissions
  js: queue priority (default 0)
  qsub_cmd: The command to submit a job from a shell
  start: The start number for the task range
  end: The end number for the task range
  host_scratch_dir: If not None, will run the job within a local scratch
                    directory on each queue machine, then copy back all output
                    files to the directory set by where

  Returns the job id of the submission.

  Example of python script:
  run(
    where = path_to_where_you_want_to_run_your_jobs,
    phenix_source = "/net/chevy/raid1/nigel/build/setpaths.csh",
    commands = ["phenix.fetch_pdb 101m", "phenix.fetch_pdb 1s72"])

  For more help type:
    libtbx.easy_qsub --help
  """
  if not phenix_source:
    print('-'*80)
    if not os.environ.get("PHENIX", ""):
      print(help)
      return
    print("\n  Automatically setting phenix_source to current $PHENIX/phenix_env\n")
    phenix_source = "%s/phenix_env" % os.environ.get("PHENIX", "")

  if not (commands or python_script):
    print('-'*80)
    print("\n  Generating a test run script and queuing 10 times\n")
    f=open("easy_qsub_test_script.py", "w")
    f.write(test_run_script)
    f.close()
    commands = []
    for i in range(10):
      commands.append("libtbx.python %s %s" % (os.path.join(
                                               os.getcwd(),
                                               "easy_qsub_test_script.py"),
                                               i+100,
                                              )
        )


  print('-'*80)
  print('  Inputs')
  print('    phenix_source',phenix_source)
  if phenix_source.find("phenix_env")==-1 and phenix_source.find("setpath")==-1:
    print('  Need to supply file to source. e.g. phenix_env')
    return False
  if not os.path.exists(phenix_source):
    raise Sorry('source file for PHENIX environment not found "%s"' % phenix_source)
  print('    where',where)
  if isinstance(commands, type([])):
    if code is None: code = "easy_qsub"
    print('    commands',len(commands), end=' ')
    if len(commands)>1:
      print('similar to\n\n> %s\n' % (commands[0]))

  elif commands is not None and os.path.exists(commands):
    if code is None: code = commands[:10]

  elif python_script is not None and os.path.exists(python_script):
    if code is None: code = python_script.replace("../","")[:10]

  code = code.replace("/", "")

  print('    size_of_chunks',size_of_chunks)
  print('    number_of_chunks',number_of_chunks)
  if number_of_chunks==1:
    print('\n  Need to choose number_of_chunks>1')
    return
  print('-'*80)
  old_where = os.getcwd()
  if where is None:
    where = old_where

  assert phenix_source

  if isinstance(commands, type([])):
    lines = commands
  elif commands is not None and os.path.exists(commands):
    f=open(commands, "r")
    lines = f.readlines()
    f.close()

  elif python_script is not None and os.path.exists(python_script):
    if not end: raise Sorry('Need to supply "end=n" for python_script')
    phenix_python_bin = get_python_bin(phenix_source)
    assert phenix_python_bin
    lines = []
    for i in range(start, end+1):
      lines.append("%s %s %d" % (phenix_python_bin, python_script, i))

  number_of_jobs = len(lines)
  print('\n  Number of lines in command file',number_of_jobs)
  if number_of_chunks is not None:
    number_of_chunks = min(number_of_chunks, number_of_jobs)
  if number_of_chunks is None:
    if size_of_chunks==1:
      number_of_chunks=len(lines)
    else:
      number_of_chunks=number_of_jobs//size_of_chunks
      if number_of_jobs%size_of_chunks: number_of_chunks+=1
  else:
    size_of_chunks = number_of_jobs//number_of_chunks
    size_of_chunks = max(1, size_of_chunks)
    if number_of_chunks%size_of_chunks: size_of_chunks+=1

  number_of_jobs = number_of_chunks

  print('\n  Number of queue jobs',number_of_jobs)
  print('  Number of command in each queue job',size_of_chunks)

  if fake_queue:
    print('\nCreating fake queue with %s parallel nodes' % parallel_nodes)
    print(commands)
    f=open(commands, 'r')
    lines = f.readlines()
    f.close()
    from multiprocessing import Pool
    pool = Pool(parallel_nodes)
    pool.map(run_sh, lines)
    return None

  elif parallel_nodes>1:
    assert 0, 'parallel_nodes removed'
    def _cmp_gap(k1, k2):
      if details[k1][1]-details[k1][0]>details[k2][1]-details[k2][0]:
        return -1
      return 1
    #
    assert number_of_jobs==1, "Only one job can be run in parallel"
    details = get_queue_machine_details()
    keys = sorted(details, cmp=_cmp_gap)
    for queue_name in keys:
      if parallel_nodes<=details[queue_name][1]-details[queue_name][0]:
        # submit
        f=open("qblock.csh", "w")
        f.write(qblock)
        f.close()
        os.chmod("qblock.csh", stat.S_IREAD|stat.S_IWRITE|stat.S_IXUSR)
        qsub_cmd += " -q %s" % queue_name
        cmd = "%s -t 1-%d qblock.csh" % (qsub_cmd, parallel_nodes-1)
        print("  Blocking %d slots on %s" % (parallel_nodes-1, queue_name))
        print("    Need to remove them manually")
        print("   ",cmd)
        easy_run.call(cmd)
        break
    else:
      raise Sorry("No queue machine found with %d available slots" % parallel_nodes)

  #print '\n  Changing to work directory : %s' % where
  os.chdir(where)

  if host_scratch_dir:
    print('\n  Setting up scratch directories on queue hosts')
    pre = host_scratch_dir_pre % (host_scratch_dir, host_scratch_dir)
    post = host_scratch_dir_post
  else:
    pre = ""
    post = ""

  python_run_filename = "easy_qsub_python_script.py"
  qsub_run_filename = "easy_qsub_qsub_script.sh"

  outl = ""
  for line in lines:
    if line[-1]=="\n": line = line[:-1]
    outl += "  '''%s ''',\n" % line
  python_run_filename = os.path.join(os.getcwd(), python_run_filename)
  print("  Writing queue python script:\n    %s" % python_run_filename)
  f=open(python_run_filename, "w")
  f.write(script_file % outl)
  f.close()

  qsub_run_filename = os.path.join(os.getcwd(), qsub_run_filename)
  print("  Writing queue command script:\n    %s" % qsub_run_filename)
  f=open(qsub_run_filename, "w")
  f.write(run_file % (
    code,
    code,
    phenix_source,
    pre,
    python_run_filename,
    number_of_chunks,
    size_of_chunks,
    code,
    post,
    )
    )
  f.close()

  if end is not None:
    number_of_jobs = min(number_of_jobs, end)

  cmd = "%s -t %d-%d -js %d %s" % (
    qsub_cmd,
    start,
    number_of_jobs,
    js,
    qsub_run_filename,
    )
  print('\n  Queue command\n')
  print("> %s\n" % cmd)
  if dry_run:
    print('  Skipping run...')

  # Run the command, and then find the job id in the output
  ero = easy_run.fully_buffered(command = cmd)
  out = StringIO()
  ero.show_stdout(out = out)
  # Line looks like:
  # "Your job-array 5436256.1-122:1 ("easy_qsub") has been submitted"
  pattern = re.compile(
      r"Your job-array (\d+)\..* \(\".*\"\) has been submitted")

  for line in out.getvalue().split("\n"):
    if not line: continue

    match = pattern.search(line)
    if match:
      job_id = int(match.group(1))
      break
  else:
    print("Unable to determine job ID")
    job_id = None

  os.chdir(old_where)

  return job_id

def wait(task_name = "easy_qsub",
         job_id = None,
         user = None,
         qstat_cmd = "qstat",
         sleep_time = 10):
  """
  Repeatedly checks the queue and waits until all jobs for a user have
  completed. The caller may specify further information, such as the job name,
  id, and user if jobs of another user are to be monitored.

  This function returns when there are no more jobs matching any of the
  parameters. i.e. No jobs matching <user>, no jobs matching <job_id>, and no
  jobs matching <task_name>.

  Parameters
  ----------
  task_name : int or str or list of int or list of str or None, optional
  job_id : int or str or list of int or list of str or None, optional
  user : str, optional
  qstat_cmd : str, optional
  sleep_time : int, optional
  """

  # Turn job_id into an array of strings if it isn't already one
  if job_id:
    if hasattr(job_id, "__iter__"):
      job_id = [str(i).strip() for i in job_id]
    else:
      job_id = [str(job_id).strip()]

  # Do the same for task_name
  if task_name:
    if hasattr(task_name, "__iter__"):
      task_name = [str(i).strip() for i in task_name]
    else:
      task_name = [str(task_name).strip()]

  # Monitor the queue until we don't see any more tasks for the user
  # or with a given job id / task name
  while True:
    p = subprocess.Popen([qstat_cmd], stdout = subprocess.PIPE)
    stdout = p.communicate()[0]
    for line in stdout.split("\n")[2:]:
      if not line: continue

      # Check for a job with the same ID
      if job_id and line[:7].strip() in job_id:
        # Break the for loop
        break

      if line[27:39].strip() == user:
        if task_name is not None:
          if line[16:26].strip() in task_name:
            # Break the for loop
            break
        else:
          # Break the for loop
          break
    else:
      # No lines matched, so break the while loop
      break

    time.sleep(sleep_time)

if __name__=="__main__":
  args=sys.argv[1:]
  kwds = process_args(args)
  run(**kwds)


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/env_run.py
from __future__ import absolute_import, division, print_function
import subprocess
import libtbx.load_env # implicit import
import sys, os

def run():
  if len(sys.argv) < 3:
    raise RuntimeError(
      "usage: libtbx.env_run MODULE_DIST path/to/command [arg ...]")
  try:
    cmd_root = os.environ[sys.argv[1]]
  except KeyError:
    raise RuntimeError('Environment variable "%s" not defined.' % sys.argv[1])
  args = []
  if sys.argv[2].lower().endswith(".py"):
    args.append(sys.executable)
  args.append(os.path.normpath(os.path.join(cmd_root, sys.argv[2])))
  args.extend(sys.argv[3:])
  if not os.path.isfile(args[0]):
    raise RuntimeError("No such file: %s" % args[0])
  if not os.access(args[0], os.X_OK):
    raise RuntimeError("Permission denied: %s" % args[0])
  sys.exit(subprocess.call(args))

if __name__ == "__main__":
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/epydoc_run.py
from __future__ import absolute_import, division, print_function
import epydoc
import epydoc.docwriter
import epydoc.docwriter.xlink
import epydoc.cli

help_text = """Synopsis

libtbx.epydoc [options]

Description

Generate the epydoc documentation specified by the given configuration file.
Any option understood by epydoc may be passed to this script.
If the configuration file is not specified, the file epydoc.conf in the current directory is used.

Requirements

Epydoc 3.0 and docutils.

Instructions for documentation writers

When a pure Python class A uses the Boost.Python wrapping of a C++ class B,
the docstring of A should feature a link to the doxygen-generated
documentation of B. That link shall be written as e.g.
  :doxyclass:`scitbx::lbfgs::drop_convergence_test`
and will give
<a href="../c_plus_plus/classscitbx_1_1lbfgs_1_1drop__convergence__test.html">
class scitbx::lbfgs::drop_convergence_test</a>
The other magic keyword is "doxystruct" for struct instead of class.

This relies on an essential requirement on the part of the C++ documentation writers: the C++ documentation root directory and the Python documentation
root directory shall be in the same directory on the server.
"""

def help():
  print(help_text)
  exit(1)

# create our own custom external link classes
class DoxygenUrlGenerator(epydoc.docwriter.xlink.UrlGenerator):

  def get_url(self, name):
    url = name.replace('_', '__')     \
              .replace('::', '_1_1')
    url = "../c_plus_plus/%s%s.html" % (self.what_is_documented, url)
    return url

class DoxygenClassUrlGenerator(DoxygenUrlGenerator):
  what_is_documented = 'class'

class DoxygenStructUrlGenerator(DoxygenUrlGenerator):
  what_is_documented = 'struct'


def run():
  # register our custom external link classes
  epydoc.docwriter.xlink.register_api('doxyclass', DoxygenClassUrlGenerator())
  epydoc.docwriter.xlink.create_api_role('doxyclass', problematic=False)
  epydoc.docwriter.xlink.register_api('doxystruct', DoxygenClassUrlGenerator())
  epydoc.docwriter.xlink.create_api_role('doxystruct', problematic=False)

  # let epydoc handle the command-line arguments
  import sys
  if '--conf=' not in sys.argv[1:]:
    sys.argv.append('--conf=epydoc.conf')
  options = epydoc.cli.parse_arguments()

  # run it
  epydoc.cli.main(options)

if __name__ == "__main__":
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/extract_code_from_txt.py
from __future__ import absolute_import, division, print_function
from itertools import count
import sys, os
from six.moves import zip

def run(args, command_name="libtbx.extract_code_from_txt"):
  markup_extract_begin = "  ## extract code begin: "
  markup_extract_end = "  ## extract code end"
  outputs = {}
  for file_name in args:
    rst = []
    i_line_lines = iter(zip(count(), open(file_name).read().splitlines()))
    for i_line,line in i_line_lines:
      if (not line.startswith(markup_extract_begin)):
        rst.append(line)
      else:
        destination = line[len(markup_extract_begin):].strip()
        buffer = [("  # ---- line %d " % (i_line+1) + "-"*75)[:79]]
        def check_next_is_empty_line():
          i_line,line = next(i_line_lines)
          if (len(line) != 0):
            raise RuntimeError(
              "Markup must be followed by an empty line (line %d)" %
                (i_line+1))
        check_next_is_empty_line()
        buffer.append("")
        for i_line,line in i_line_lines:
          if (line.startswith(markup_extract_begin)):
            raise RuntimeError(
              'Unexpected markup: "%s" (line %d)' % (
                markup_extract_begin, i_line+1))
          if (line.rstrip() == markup_extract_end):
            check_next_is_empty_line()
            break
          buffer.append(line)
          rst.append(line)
        else:
          raise RuntimeError(
            'Unexpected end of file: missing "%s"' % markup_extract_end)
        outputs.setdefault(destination, []).extend(buffer)
    file_rst = os.path.basename(file_name)
    if (file_rst.endswith(".txt")):
      file_rst = file_rst[:-4]
    file_rst += ".rst"
    print("Writing: %s (%d lines)" % (file_rst, len(rst)))
    print("\n".join(rst), file=open(file_rst, "w"))
  for destination,lines in outputs.items():
    lines.insert(0, 'if (__name__ == "__main__"):')
    lines.insert(1, "")
    print("Writing: %s (%d lines)" % (destination, len(lines)))
    print("\n".join(lines), file=open(destination, "w"))

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/find_clutter.py
from __future__ import absolute_import, division, print_function
import sys
from libtbx.file_clutter import gather

def run(args):
  flag_x = False
  flag_ni = False
  flag_dos_format = True
  flag_indentation = False
  verbose = False
  #
  only_whitespace = False
  only_dos = False
  only_future = False
  flag_absolute_import = False
  flag_print_function = False
  #
  paths = []
  for arg in args:
    if (arg == "-x"):
      flag_x = True
    elif (arg == "-ni"):
      flag_ni = True
    elif (arg == "-ndos"):
      flag_dos_format = False
    elif (arg == "--verbose") or (arg == '-v'):
      verbose = True
    elif (arg == "--indentation"):
      flag_indentation = True
    elif (arg == "--only_whitespace"):
      only_whitespace = True
    elif (arg == "--only_dos"):
      only_dos = True
    elif (arg == "--only_future"):
      only_future = True
    elif (arg == "--absolute_import"):
      flag_absolute_import = True
    elif (arg == "--print_function"):
      flag_print_function = True
    else:
      paths.append(arg)
  if (len(paths) == 0): paths = ["."]
  n_is_cluttered = 0
  n_bare_excepts = 0
  n_has_unused_imports = 0
  message_lines = []
  n_missing_from_future_import_division = 0
  n_too_many_from_future_import_division = 0
  n_missing_from_future_import_absolute_import = 0
  n_too_many_from_future_import_absolute_import = 0
  n_missing_from_future_import_print_function = 0
  n_too_many_from_future_import_print_function = 0
  n_bad_indentation = 0
  for info in gather(paths=paths, find_unused_imports=not flag_ni,
      find_bad_indentation=flag_indentation, flag_absolute_import=flag_absolute_import,
      flag_print_function=flag_print_function):
    if (info.is_cluttered(flag_x=flag_x)):
      n_is_cluttered += 1
    if (info.n_bare_excepts > 0):
      n_bare_excepts += info.n_bare_excepts
    if (info.has_unused_imports()):
      n_has_unused_imports += 1
    if info.n_from_future_import_division == 0:
      n_missing_from_future_import_division += 1
    elif info.n_from_future_import_division > 1:
      n_too_many_from_future_import_division += 1
    if info.n_from_future_import_absolute_import == 0:
      n_missing_from_future_import_absolute_import += 1
    elif info.n_from_future_import_absolute_import > 1:
      n_too_many_from_future_import_absolute_import += 1
    if info.n_from_future_import_print_function == 0:
      n_missing_from_future_import_print_function += 1
    elif info.n_from_future_import_print_function > 1:
      n_too_many_from_future_import_print_function += 1
    if (info.bad_indentation is not None) and (flag_indentation):
      n_bad_indentation += 1
    info.show(
      flag_x=flag_x,
      flag_dos_format=flag_dos_format,
      append=message_lines.append,
      flag_indentation=flag_indentation,
      verbose=verbose)
  please_use = []
  if (n_is_cluttered != 0):
    please_use.append("libtbx.clean_clutter")
  if only_whitespace:
    def _is_whitespace(s):
      if s.find("tabs or trailing")>-1: return True
      return False
    message_lines = list(filter(_is_whitespace, message_lines))
  elif only_dos:
    def _is_dos(s):
      if s.find("dos format")>-1: return True
      return False
    message_lines = list(filter(_is_dos, message_lines))
  elif only_future:
    def _is_future(s):
      if s.find("from __future__")>-1: return True
      return False
    message_lines = list(filter(_is_future, message_lines))
  else:
    if (n_has_unused_imports != 0):
      please_use.append("libtbx.find_unused_imports_crude")
    if n_missing_from_future_import_division:
      please_use.append('libtbx.add_from_future_import_division')
    if (len(please_use) != 0):
      message_lines.append("")
      message_lines.append(
        "*** To clean up please use: %s ***" % ", ".join(please_use))
    if (n_bare_excepts > 0):
      message_lines.append("")
      message_lines.extend("""\
  *** Please change bare excepts: ***
        Usually best:
          except Exception:
        Rarely necessary:
          except: # intentional
  """.splitlines())
    if (n_bad_indentation != 0):
      message_lines.append("")
      message_lines.append("*** Please fix indentation in a text editor ***")
  if (len(message_lines) != 0):
    print()
    print("\n".join(message_lines))
    print()
    return (1)
  return (0)

if (__name__ == "__main__"):
  sys.exit(run(sys.argv[1:]))


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/find_files.py
from __future__ import absolute_import, division, print_function
from libtbx.path import walk_source_tree
from libtbx.str_utils import show_string
from libtbx.utils import Sorry
from libtbx.option_parser import option_parser
from fnmatch import fnmatch
import re
import sys, os

def read_lines_if_possible(file_path):
  try: f = open(file_path, "r", errors='ignore')
  except IOError: return []
  return f.read().splitlines()

def run(args, command_name="libtbx.find_files"):
  if (len(args) == 0): args = ["--help"]
  command_line = (option_parser(
    usage="%s [options] pattern ..." % command_name,
    description="Recursively finds all files matching patterns,\n"
      "excluding CVS and .svn directories and .pyc files.")
    .option("-t", "--top",
      action="append",
      type="string",
      metavar="PATH",
      help="top-level directory where search starts"
           " (default is current working directory)")
    .option("-g", "--grep",
      action="append",
      type="string",
      metavar="PATTERN",
      help="find regular expression pattern in each file (multiple"
           " -g/--grep options can be given)")
    .option("-i", "--ignore_case",
      action="store_true",
      default=False,
      help="with -g/--grep: case-insensitive match")
    .option("-f", "--file_names_only",
      action="store_true",
      default=False,
      help="with -g/--grep: show file names only, not the matching lines")
    .option("-q", "--quote",
      action="store_true",
      default=False,
      help="quote file names")
  ).process(args=args)
  fn_patterns = command_line.args
  co = command_line.options
  grep_flags = 0
  if (co.ignore_case):
    grep_flags |= re.IGNORECASE
  if (len(fn_patterns) == 0):
    fn_patterns = ["*"]
  tops = co.top
  if (tops is None):
    tops = ["."]
  for top in tops:
    if (not os.path.isdir(top)):
      raise Sorry("Not a directory: %s" % show_string(top))
    for file_path in walk_source_tree(top=top):
      file_name = os.path.basename(file_path)
      for fn_pattern in fn_patterns:
        if (fnmatch(file_name, fn_pattern)):
          if (co.quote): fp = show_string(file_path)
          else: fp = file_path
          if (co.grep is None):
            print(fp)
          else:
            is_binary_file = co.file_names_only
            for line in read_lines_if_possible(file_path=file_path):
              if (not is_binary_file):
                is_binary_file = "\0" in line
              def line_matches_all_grep_patterns():
                for grep_pattern in co.grep:
                  if (re.search(
                        pattern=grep_pattern,
                        string=line,
                        flags=grep_flags) is None):
                    return False
                return True
              if (line_matches_all_grep_patterns()):
                if (co.file_names_only):
                  print(fp)
                  break
                elif (is_binary_file):
                  print("%s: match in binary file" % fp)
                  break
                else:
                  print("%s: %s" % (fp, line))

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/find_in_repositories.py
from __future__ import absolute_import, division, print_function

import os
import sys

import libtbx.load_env
from libtbx.str_utils import show_string
from libtbx.utils import Sorry

def run(args, this_command="libtbx.find_in_repositories"):
  optional = False
  if "--optional" in args:
    optional = True
    args.remove("--optional")
  if len(args) != 1:
    raise Sorry("usage: %s [--optional] name" % this_command)
  name = args[0]
  result = libtbx.env.find_in_repositories(
    relative_path=name, test=os.path.exists)
  if result is None and not optional:
    raise Sorry("%s: cannot locate %s" % (this_command, show_string(name)))
  print(result)

if __name__ == "__main__":
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/find_old_style_classes.py
from __future__ import absolute_import, division, print_function
import os, fnmatch
from libtbx import python_code_parsing

def run(args):
  if not args: args = [ '.' ]
  work = set()
  arg_filenames = []
  for arg in args:
    if os.path.isdir(arg):
      for dirpath, dirnames, filenames in os.walk(arg):
        work.update( os.path.join(dirpath, f)
                     for f in fnmatch.filter(filenames, '*.py') )
    else:
      arg_filenames.append(arg)
  work.update(fnmatch.filter(arg_filenames, '*.py'))
  for filename in work:
    try:
      old_style = python_code_parsing.find_old_style_classes(
        python_source_filename=filename)
    except Exception as e:
      import traceback
      print(filename)
      print(traceback.format_exc())
      continue
    if old_style:
      print('In file %s:' % filename)
      print(old_style)
      print()


if __name__ == '__main__':
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/find_pdb_mmcif_problems.py
from __future__ import absolute_import, division, print_function
import os, sys


from libtbx.utils import display_context


''' Tool to find instances in code where PDB formatting is assumed and
    should be made general to include PDB or mmcif formatting
'''

# =============================================================================
def find_pdb_mmcif_problems(path, n_context = 7, overall_exclude = None,
    mark_files = None, unmark_files = None):

  # Run on all paths supplied in file if a .list file is supplied
  if os.path.isfile(path) and path.endswith(".list"):
    print("Working on all paths listed in '%s'" %(path))
    all_problems = []
    total_files = 0
    for full_fn in open(path).readlines():
      full_fn = full_fn.strip()
      print("Working on '%s'" %(full_fn))
      if os.path.isdir(full_fn) or full_fn.endswith('.py'):
        problems, number_of_files_examined = find_pdb_mmcif_problems(full_fn,
           n_context = n_context, overall_exclude = overall_exclude,
            mark_files = mark_files, unmark_files = unmark_files)
        all_problems += problems
        total_files += number_of_files_examined
    return all_problems, total_files

  # Run recursively if a directory is supplied
  if os.path.isdir(path):
    print("Working recursively on the path '%s'" %(path))
    all_problems = []
    total_files = 0
    for fn in os.listdir(path):
      if fn.startswith("."): continue
      if fn.startswith("tst_"): continue
      full_fn = os.path.join(path, fn)
      if os.path.isdir(full_fn) or full_fn.endswith('.py'):
        problems, number_of_files_examined = find_pdb_mmcif_problems(full_fn,
           n_context = n_context, overall_exclude = overall_exclude,
           mark_files = mark_files, unmark_files = unmark_files)
        all_problems += problems
        total_files += number_of_files_examined
    return all_problems, total_files

  # Normal run here on one file in path

  if not os.path.isfile(path):
    print("The path %s is not a file" %path)
    return [],0
  if (not path.endswith('.py')):
    print("The file %s is not a python file" %path)
    return [], 0
  if (os.path.split(path)[-1].startswith('tst_')):
    print("The file %s is a test file" %path)
    return [], 0

  # Run on one file
  all_problems = []
  text = open(path).read()
  for problem in (
     write_model_file_without_assignment,
     pdb_write_statements,
     pdb_format_interpretation,
     raw_records,
     pdb_file_name,
   ):
    all_problems += problem(text, file_name = path, n_context = n_context,
      overall_exclude = overall_exclude)

  if mark_files: # mark all problems in the files themselves
    mark_problems_in_file(text,path, all_problems, n_context = n_context)
  if unmark_files: # unmark all problems in the files
    unmark_problems_in_file(text,path)

  return all_problems, 1

def unmark_problems_in_file(text,path):
  if text.find(" # XXX CHECK PDB:") < 0:
     return # nothing to do

  lines = text.splitlines()
  for i in range(len(lines)):
    line = lines[i]
    index = line.find(" # XXX CHECK PDB:")
    if index > -1:
      lines[i] = line[:index]
  f = open(path,'w')
  print("\n".join(lines), file = f)
  f.close()
  print("Removed CHECK PDB text from %s" %(path))


def mark_problems_in_file(text, path, all_problems,
     n_context = 5):
  if not all_problems:
     return  # nothing to do
  lines = text.splitlines()
  for p in all_problems:
    sw = [p.search_word, p.required_word]
    if None in sw: sw.remove(None)
    line = lines[p.line_number-1].rstrip()
    next_ending = None
    for w in sw:
      if line.find(w):
        next_ending = w
        break
    if (not next_ending):
       next_ending = " ".join(sw)
    new_text = " # XXX CHECK PDB: %s" %(next_ending)
    for i in range(p.line_number-1, p.line_number + n_context - 1):
      line = lines[i]
      if (not line.endswith("\\")) and (not line.find("XXX CHECK PDB") > -1):
        line = line.rstrip()
        blanks = max(0, 80 - len(line) - len(new_text))
        if blanks > 0:
          new_text = blanks *" " + new_text
        line +=  new_text
        lines[i] = line
        break
  f = open(path,'w')
  print("\n".join(lines), file = f)
  f.close()
  print("Marked problems with CHECK PDB text in %s" %(path))

def run(args, n_context = 7, overall_exclude = None):
  if len(args) < 1:
    print("phenix.python find_pdb_mmcif_problems.py <file_name or directory> <n_context> <mark_files> <unmark_files>")
    return

  mark_files = False
  unmark_files = False
  if 'mark_files' in args:
    args.remove('mark_files')
    mark_files = True
  if 'unmark_files' in args:
    args.remove('unmark_files')
    unmark_files = True

  path = args[0]
  if not os.path.exists(path):
    print("The path '%s' does not exist?" %path)
    return []

  if not overall_exclude:
    overall_exclude = ['get_refine_file_stem',
    'DEBUG',        # debugging code
    'PDB OK',       # marked as ok
    'PDB REQUIRED', # marked as ok
    'must be PDB',  # marked as ok
    'MUST BE PDB',  # marked as ok
    'XXX OK',  # marked as ok
    'XXX ok',  # marked as ok
    'set_model_ext_and_target_output_format',  # function to set the extension
    'forward_compatible', # using pdb deliberately
    'transfer_ext', # function to set the extension
    'get_cif_or_pdb_file_if_present', # function to set the extension
    '.pdb_or_mmcif_string_info', # function to set the extension
    'mmcif', # the author has considered cif
    '.cif',  # the author has considered cif
    'write_model(',  # the write_model function is cif-aware
    'write_output_file(',  # the write_output_file function is cif-aware
    '.type = ',  # This is in parameters
    ]

  if len(args) > 1:
    n_context = int(args[1])
    print("Set n_context to ",n_context)
  all_problems, total_files  = find_pdb_mmcif_problems(
     path, n_context = n_context, overall_exclude = overall_exclude,
     mark_files = mark_files, unmark_files = unmark_files)

  # Summarize results

  all_file_names = get_all_unique(all_problems, key = 'file_name')
  all_categories = get_all_unique(all_problems, key = 'category')
  all_search_words = get_all_unique(all_problems, key = 'search_word')

  print("All unique categories: ",all_categories)
  print("All unique file_names: ",all_file_names)
  print("All unique search words: ",all_search_words)

  print("\nAll problems:")
  for file_name in all_file_names:
    print("\n"+70*"=")
    print("FILE NAME: %s" %(file_name))
    print(70*"=")
    problem_list = select_problems(all_problems, key = 'file_name',
      value = file_name, n_context = n_context)
    for p in problem_list:
      display_problem(p)

  print("\nSummary of problems by file:")
  for file_name in all_file_names:
    problem_list = select_problems(all_problems, key = 'file_name',
      value = file_name, n_context = n_context)
    total_problems = 0
    from six.moves import StringIO
    f = StringIO()
    for sw in all_search_words:
       search_words = [sw]
       p_list = select_problems(problem_list, key = 'search_word',
         value = sw, n_context = 0)
       if p_list:
         for p in p_list:
           if p.required_word and (not p.required_word in search_words):
              search_words.append(p.required_word)
         print(" TEXT FOUND:   %s  NUMBER OF TIMES: %s" %(
           search_words, len(p_list)), file = f)
         total_problems += len(p_list)
    print("\n%s: %s problems" %(file_name,total_problems))
    print(f.getvalue())
  total_files_with_problems = len(all_file_names)
  print("\nTotal files with problems: %s (of %s)" %(
    total_files_with_problems, total_files))

  print("\nSummary of problems by code:\n")
  total_problems = 0
  for sw in all_search_words:
     search_words = [sw]
     p_list = select_problems(all_problems, key = 'search_word',
       value = sw, n_context = 0)
     if p_list:
       for p in p_list:
         if p.required_word and (not p.required_word in search_words):
            search_words.append(p.required_word)
       print(" TEXT FOUND:   %s  NUMBER OF TIMES: %s" %(
         search_words, len(p_list)))
       total_problems += len(p_list)

  print("\nTotal problems found in %s: %s" %(path,total_problems))


def display_problem(p, out = sys.stdout):
  print("%s  Line: %s  :: %s\n" %(
     p.file_name,p.line_number,p.category)+ 70*"-", file = out)
  sw = [p.search_word, p.required_word]
  if None in sw: sw.remove(None)
  next_ending = None
  for line in p.text_block.splitlines():
    line = line.rstrip()
    if line.startswith("  **"):
      for w in sw:
        if line.find(w):
          next_ending = w
          break
      if (not next_ending):
          next_ending = " ".join(sw)
    if next_ending and (not line.endswith("\\")):
      line = line.rstrip()
      new_text = " # XXX CHECK PDB: %s" %(next_ending)
      blanks = max(0, 80 - len(line) - len(new_text))
      if blanks > 0:
        new_text = blanks *" " + new_text
      line +=  new_text
      next_ending = None
    print(line, file = out)
  print(70*"-", file = out)

def select_problems(all_problems, key = 'file_name', value = None,
    n_context = 7):
  new_problems = []
  for p in all_problems:
    if getattr(p,key,None) == value:
      new_problems.append(p)
  new_problems = sorted(new_problems, key = lambda p: p.line_number)
  sieved_problems = []
  last_line_number = None
  for p in new_problems:
    if (last_line_number is None) or (
      p.line_number >= last_line_number + n_context - 1):
      sieved_problems.append(p)
      last_line_number = p.line_number
  return sieved_problems

def get_all_unique(all_problems, key = 'file_name'):
  all_unique = []
  for p in all_problems:
    x = getattr(p,key,None)
    if (x is not None) and not x in all_unique:
      all_unique.append(x)
  return all_unique

def write_model_file_without_assignment(text, file_name = None, n_context = 7,
    overall_exclude = None):
  all_problems = []
  for search_word in [ "dm.write_model_file(",
     "data_manager.write_model_file(", ]:
    all_problems += display_context(file_name = file_name, text = text,
       n_context = n_context, search_word = search_word,quiet = True,
       excluded_words = [
         '=dm.write_model_file',
         '= dm.write_model_file',
         '=data_manager.write_model_file',
         '= data_manager.write_model_file',
         '=self.dm.write_model_file',
         '= self.dm.write_model_file',
         '=self.data_manager.write_model_file',
         '= self.data_manager.write_model_file',
            ] + overall_exclude,
       category = 'write_model_file_without_assignment')
  return all_problems

def pdb_write_statements(text, file_name = None, n_context = 7,
    overall_exclude = None):
  all_problems = []
  for search_word in [".model_as_pdb(", ".as_pdb_string(", # PDB OK
      ".write_pdb_file("]:
    all_problems += display_context(file_name = file_name, text = text,
       n_context = n_context, search_word = search_word,quiet = True,
       excluded_words = overall_exclude,
       category = 'pdb_write_statements')
  return all_problems

def pdb_format_interpretation(text, file_name = None, n_context = 7,
      overall_exclude = None):
  all_problems = []
  for search_word in ['.open(']:
    for required_word in ['.pdb"',".pdb'",'pdb_file','model_file']: # PDB OK
      all_problems += display_context(file_name = file_name, text = text,
       n_context = n_context,
       search_word = search_word,
       required_word=required_word,
       excluded_words= overall_exclude,
       quiet = True,
       category = 'pdb_format_interpretation')
  all_problems += display_context(file_name = file_name, text = text,
       n_context = n_context,
       search_word = ".splitlines(",
       required_word="pdb",
       excluded_words=["cmds.","iotbx.pdb",
          'pdb_interpretation.process',
          'traceback','phil_string',] + overall_exclude,
       quiet = True,
       category = 'pdb_format_interpretation')
  for search_word in ['HETATM','"ATOM',"'ATOM",'"TER',"'TER",
         '"BREAK',"'BREAK",' CA ',' N ']: # PDB OK
    for required_word in ['startswith','find(','re.search(']:
      all_problems += display_context(file_name = file_name, text = text,
       n_context = n_context,
       search_word = search_word,
       required_word=required_word,
       excluded_words = ['group_PDB'] + overall_exclude,
       quiet = True,
       category = 'pdb_format_interpretation')
  return all_problems

def raw_records(text, file_name = None, n_context = 7, overall_exclude = None):
  all_problems = []
  for search_word in ['raw_records=','raw_records =']:
    for required_word in ['pdb']:
      all_problems += display_context(file_name = file_name, text = text,
       n_context = n_context,
       search_word = search_word,
       required_word=required_word,
       excluded_words=['pdb.input','iotbx.pdb','input.pdb',
         '.pdb_or_mmcif_string_info','get_cif_or_pdb_file_if_present'
          'pdb_interpretation.process'] +
         overall_exclude,
       quiet = True,
       category = 'raw_records')
  return all_problems

def pdb_file_name(text, file_name = None,
      n_context = 7, overall_exclude = None):
  all_problems = []
  for search_word in ['file_name',' fn=',' fn = ','filename']:
    for required_word in ['.pdb"',".pdb'"]:
      all_problems += display_context(file_name = file_name, text = text,
       n_context = n_context,
       search_word = search_word,
       required_word=required_word,
       excluded_words = ['.pdb_or_mmcif_string_info',
         'get_cif_or_pdb_file_if_present','write_model',
          'pdb.input','iotbx.pdb','.cif','input.pdb',
          'map_file_name','restraint_file',] + overall_exclude,
       quiet = True,
       category = 'pdb_file_name')
  return all_problems


# =============================================================================
if __name__ == '__main__':
  import sys
  run(sys.argv[1:])

# =============================================================================
# end


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/find_reserved_names.py
from __future__ import absolute_import, division, print_function
import ast
import builtins
import keyword
import os
import sys

reserved_words = keyword.kwlist + [b for b in dir(builtins) if not b.startswith("_")]
reserved_words.remove("copyright")


def check(filename):
    root = ast.parse(open(filename).read())
    text = open(filename).readlines()

    for node in ast.walk(root):
        if isinstance(node, ast.Name) and isinstance(node.ctx, ast.Store):
            if node.id in reserved_words:
                print('%s:%d "%s"' % (filename, node.lineno, node.id))
                print(text[node.lineno - 1])


def main(start):
    for path, dnames, fnames in os.walk(start):
        for f in fnames:
            if f.endswith(".py"):
                check(os.path.join(path, f))


if __name__ == "__main__":
    if len(sys.argv) == 1:
        args = ["."]
    else:
        args = sys.argv[1:]
    for arg in args:
        print("Checking %s" % arg)
        main(arg)


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/find_under_build.py
from __future__ import absolute_import, division, print_function
import libtbx.load_env
from libtbx.str_utils import show_string
from libtbx.utils import Sorry
import sys

def run(args, this_command="libtbx.find_under_build"):
  optional = False
  if ("--optional" in args):
    optional = True
    args.remove("--optional")
  if (len(args) != 1):
    raise Sorry("usage: %s [--optional] name" % this_command)
  name = args[0]
  result = libtbx.env.under_build(name)
  if (result is None and not optional):
    raise Sorry("%s: cannot locate %s" % (this_command, show_string(name)))
  print(result)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/find_untested.py
from __future__ import absolute_import, division, print_function
import os, sys
import libtbx.load_env
from libtbx import easy_run
from libtbx.utils import Sorry
import ast

find_blame = True

def find_majority_blame(full_path):
  cmd = 'git blame %s' % full_path
  rc = easy_run.go(cmd)
  blames = {}
  for line in rc.stdout_lines:
    key = line[line.find('(')+1:line.find('(')+11]
    blames.setdefault(key, 0)
    blames[key]+=1
  m = max(blames.values())
  for key, item in blames.items():
    if item==m: return key

def find_all_tst_dot_py_files(root_dir):
  result = []
  for root, dirs, files in os.walk(root_dir):
    for f in files:
      if([f.startswith("tst"),f.startswith("test")].count(True)==1 and
          f.endswith(".py")):
        result.append("/".join([root,f]))
  return result

def extract_tests_from_run_tests_dot_py(file_name, full_path):
  fo = open(file_name,"r")
  unique_files = []
  for line in fo.readlines():
    line = line.strip()
    if(line.count("$D") and line.count(".py") and
       (line.count("") or line.count("test")) and not line.count("#")):
      line = line.split()[0]
      for c in ["[","$D",",",'"',"]"]: line=line.replace(c,"")
      if(not line in unique_files): unique_files.append(line)
  fo.close()
  result = []
  for uf in unique_files:
    result.append(full_path+uf)
  for r in result:
    assert os.path.isfile(r), r
  return result

def find_mismatch(from_run_tests, from_dirs, full_path, force_stop=False):
  print("  Number of tests in:")
  print("    run_tests.py         :", len(from_run_tests))
  print("    actual in folder-tree:", len(from_dirs))
  if(len(from_run_tests)!=len(from_dirs)):
    print("  Tests listed below are never executed:")
  for f1 in from_dirs:
    if(not f1 in from_run_tests):
      rc = ''
      if find_blame:
        rc = find_majority_blame(f1)
      if(1): print("    '%s' %s" % (rc, f1))
      if(force_stop):
        raise Sorry("Add test to run_tests.py first.")

def run(args):
  assert len(args) in [0,2]
  force_stop = False
  include = ["cctbx", "iotbx", "mmtbx", "scitbx"]
  if(len(args)==2):
    module, force_stop = args
    force_stop = ast.literal_eval(force_stop)
    include = [module]
  root_dir = libtbx.env.find_in_repositories("cctbx_project")
  for subdir in os.listdir(root_dir):
    full_path = "/".join([root_dir,subdir])
    if(subdir in include):
      assert os.path.isdir(full_path)
      print(full_path)
      run_tests_file = "/".join([full_path, "run_tests.py"])
      assert os.path.isfile(run_tests_file)
      #
      from_run_tests = extract_tests_from_run_tests_dot_py(
        file_name=run_tests_file, full_path=full_path)
      from_dirs = find_all_tst_dot_py_files(root_dir=full_path)
      find_mismatch(from_run_tests, from_dirs, full_path, force_stop)

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************
