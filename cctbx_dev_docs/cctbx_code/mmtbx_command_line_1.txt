

 *******************************************************************************
mmtbx/command_line/map_comparison.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.map_comparison

from cctbx import crystal
from cctbx import maptbx, miller
from cctbx.sgtbx import space_group_info
from iotbx import file_reader, phil
import iotbx.ccp4_map
from libtbx.utils import Sorry
from scitbx.array_family import flex
import os, sys
from six.moves import zip
from six.moves import range

master_phil = phil.parse("""
include scope libtbx.phil.interface.tracking_params
input
{
  map_1 = None
    .type = path
    .short_caption = Map 1
    .help = A CCP4-formatted map
    .style = file_type:ccp4_map bold input_file
  map_2 = None
    .type = path
    .short_caption = Map 2
    .help = A CCP4-formatted map
    .style = file_type:ccp4_map bold input_file
  mtz_1 = None
    .type = path
    .short_caption = Map 1
    .help = MTZ file containing map
    .style = file_type:hkl bold input_file process_hkl child:map_labels:mtz_label_1
  mtz_2 = None
    .type = path
    .short_caption = Map 2
    .help = MTZ file containing map
    .style = file_type:hkl bold input_file process_hkl child:map_labels:mtz_label_2
  mtz_label_1 = None
    .type = str
    .short_caption = Data label
    .help = Data label for complex map coefficients in MTZ file
    .style = renderer:draw_map_arrays_widget
  mtz_label_2 = None
    .type = str
    .short_caption = Data label
    .help = Data label for complex map coefficients in MTZ file
    .style = renderer:draw_map_arrays_widget
}
options
{
  resolution_factor = 0.25
    .type = float
    .short_caption = Resolution gridding factor
    .help = Determines grid spacing in map
  shift_origin = True
    .type = bool
    .short_caption = Shift origin(s) to (0,0,0)
    .help = Shift origin if necessary
  contour_to_match = None
    .type = float
    .short_caption = Contour to match
    .help = Contour level in map1 to match in map2 by volume equalization.

}
""", process_includes=True)

master_params = master_phil

def show_overall_statistics(out=sys.stdout, s=None, header=None):
  print(header, file=out)
  print("  min/max/mean: %6.4f %6.4f %6.4f"%(s.min(), s.max(), s.mean()), file=out)
  print("  kurtosis    : %6.4f" % s.kurtosis(), file=out)
  print("  skewness    : %6.4f" % s.skewness(), file=out)
  print("  sigma       : %6.4f" % s.sigma(), file=out)

def create_statistics_dict(out=sys.stdout, s=None):
  statistics_dict = dict()
  statistics_dict['min'] = s.min()
  statistics_dict['max'] = s.max()
  statistics_dict['mean'] = s.mean()
  statistics_dict['kurtosis'] = s.kurtosis()
  statistics_dict['skewness'] = s.skewness()
  statistics_dict['sigma'] = s.sigma()
  return statistics_dict

def show_citation(out=sys.stdout):
  print("-"*79, file=out)
  msg = """Map comparison and statistics. For details see:
  Acta Cryst. (2014). D70, 2593-2606
  Metrics for comparison of crystallographic maps
  A. Urzhumtsev, P. V. Afonine, V. Y. Lunin, T. C. Terwilliger and P. D. Adams"""
  print(msg, file=out)
  print("-"*79, file=out)
def match_contour_level(m1=None,m2=None,
       contour_to_match=None,results=None):
  # just find map value in m2 that is bigger than same number of grid points
  #   as contour_to_match is for m1
  s=(m1>=contour_to_match)
  from cctbx.maptbx.segment_and_split_map import find_threshold_in_map
  contour_in_map_2=find_threshold_in_map(target_points=s.count(True),
         map_data=m2)
  s2=(m2>=contour_in_map_2)
  results['matching_contour']=contour_in_map_2
  results['v1']=s.count(True)/s.size()
  results['v2']=s2.count(True)/s2.size()
  return results

# =============================================================================
def run(args, out=sys.stdout, validated=False):
  show_citation(out=out)
  if (len(args) == 0):
    master_phil.show(out=out)
    print('\nUsage: phenix.map_comparison <CCP4> <CCP4>\n',\
      '       phenix.map_comparison <CCP4> <MTZ> mtz_label_1=<label>\n',\
      '       phenix.map_comparison <MTZ 1> mtz_label_1=<label 1> <MTZ 2> mtz_label_2=<label 2>\n', file=out)
    sys.exit()

  # process arguments
  params = None
  input_attributes = ['map_1', 'mtz_1', 'map_2', 'mtz_2']
  try: # automatic parsing
    params = phil.process_command_line_with_files(
      args=args, master_phil=master_phil).work.extract()
  except Exception: # map_file_def only handles one map phil
    from libtbx.phil.command_line import argument_interpreter
    arg_int = argument_interpreter(master_phil=master_phil)
    command_line_args = list()
    map_files = list()
    for arg in args:
      if (os.path.isfile(arg)):
        map_files.append(arg)
      else:
        command_line_args.append(arg_int.process(arg))
    params = master_phil.fetch(sources=command_line_args).extract()

    # check if more files are necessary
    n_defined = 0
    for attribute in input_attributes:
      if (getattr(params.input, attribute) is not None):
        n_defined += 1

    # matches files to phil scope, stops once there is sufficient data
    for map_file in map_files:
      if (n_defined < 2):
        current_map = file_reader.any_file(map_file)
        if (current_map.file_type == 'ccp4_map'):
          n_defined += 1
          if (params.input.map_1 is None):
            params.input.map_1 = map_file
          elif (params.input.map_2 is None):
            params.input.map_2 = map_file
        elif (current_map.file_type == 'hkl'):
          n_defined += 1
          if (params.input.mtz_1 is None):
            params.input.mtz_1 = map_file
          elif (params.input.mtz_2 is None):
            params.input.mtz_2 = map_file
      else:
        print('WARNING: only the first two files are used', file=out)
        break

  # validate arguments (GUI sets validated to true, no need to run again)
  assert (params is not None)
  if (not validated):
    validate_params(params)

  # ---------------------------------------------------------------------------
  # check if maps need to be generated from mtz
  n_maps = 0
  maps = list()
  map_names = list()
  for attribute in input_attributes:
    filename = getattr(params.input, attribute)
    if (filename is not None):
      map_names.append(filename)
      current_map = file_reader.any_file(filename)
      maps.append(current_map)
      if (current_map.file_type == 'ccp4_map'):
        n_maps += 1

  # construct maps, if necessary
  crystal_gridding = None
  m1 = None
  m2 = None
  assert params.options.shift_origin==True
  # 1 map, 1 mtz file
  if (n_maps == 1):
    for current_map in maps:
      if (current_map.file_type == 'ccp4_map'):
        uc = current_map.file_object.unit_cell()
        sg_info = space_group_info(current_map.file_object.space_group_number)
        n_real = current_map.file_object.unit_cell_grid
        crystal_gridding = maptbx.crystal_gridding(
          uc, space_group_info=sg_info, pre_determined_n_real=n_real)
        m1 = current_map.file_object.map_data()
        if params.options.shift_origin:
          m1=m1.shift_origin()
    if (crystal_gridding is not None):
      label = None
      for attribute in [('mtz_1', 'mtz_label_1'),
                        ('mtz_2', 'mtz_label_2')]:
        filename = getattr(params.input, attribute[0])
        label = getattr(params.input, attribute[1])
        if ( (filename is not None) and (label is not None) ):
          break
      # labels will match currently open mtz file
      for current_map in maps:
        if (current_map.file_type == 'hkl'):
          m2 = miller.fft_map(
            crystal_gridding=crystal_gridding,
            fourier_coefficients=current_map.file_server.get_miller_array(
              label)).apply_sigma_scaling().real_map_unpadded()
    else:
      raise Sorry('Gridding is not defined.')

  # 2 mtz files
  elif (n_maps == 0):
    crystal_symmetry = get_crystal_symmetry(maps[0])
    d_min = min(get_d_min(maps[0]), get_d_min(maps[1]))
    crystal_gridding = maptbx.crystal_gridding(
      crystal_symmetry.unit_cell(), d_min=d_min,
      resolution_factor=params.options.resolution_factor,
      space_group_info=crystal_symmetry.space_group_info())
    m1 = miller.fft_map(
      crystal_gridding=crystal_gridding,
      fourier_coefficients=maps[0].file_server.get_miller_array(
        params.input.mtz_label_1)).apply_sigma_scaling().real_map_unpadded()
    m2 = miller.fft_map(
      crystal_gridding=crystal_gridding,
      fourier_coefficients=maps[1].file_server.get_miller_array(
        params.input.mtz_label_2)).apply_sigma_scaling().real_map_unpadded()

  # 2 maps
  else:
    m1 = maps[0].file_object.map_data()
    m2 = maps[1].file_object.map_data()
    if params.options.shift_origin:
      m1=m1.shift_origin()
      m2=m2.shift_origin()

  # ---------------------------------------------------------------------------
  # analyze maps
  assert ( (m1 is not None) and (m2 is not None) )
  if (list(m1.origin()) != [0,0,0]) or  \
     (list(m2.origin()) != [0,0,0]):
    raise Sorry(
       "Shift_origin must be set if maps do not have origin at (0,0,0)")
  if m1.size() != m2.size():
    raise Sorry ("Maps must be the same size")
  results=dict()
  results['map_files'] = None
  results['map_statistics'] = None
  results['cc_input_maps'] = None
  results['cc_quantile'] = None
  results['cc_peaks'] = None
  results['discrepancies'] = None
  results['map_histograms'] = None

  if params.options.contour_to_match:
    match_contour_level(m1=m1,m2=m2,
       contour_to_match=params.options.contour_to_match,
        results=results)
    print ("Contour level map 1: %.4f (fractional volume of %.3f ) " %(
       params.options.contour_to_match,results['v1']),\
       "\nmatches enclosed volume of "+\
       "contour level map 2 of : %.4f (volume %.3f )" %(
       results['matching_contour'],results['v2']),file=out)
    return results
  # show general statistics
  s1 = maptbx.more_statistics(m1)
  s2 = maptbx.more_statistics(m2)
  show_overall_statistics(out=out, s=s1, header="Map 1 (%s):"%map_names[0])
  show_overall_statistics(out=out, s=s2, header="Map 2 (%s):"%map_names[1])
  cc_input_maps = flex.linear_correlation(x = m1.as_1d(),
                                          y = m2.as_1d()).coefficient()
  print("CC, input maps: %6.4f" % cc_input_maps, file=out)

  # compute CCpeak
  cc_peaks = list()
  m1_he = maptbx.volume_scale(map = m1,  n_bins = 10000).map_data()
  m2_he = maptbx.volume_scale(map = m2,  n_bins = 10000).map_data()
  cc_quantile = flex.linear_correlation(x = m1_he.as_1d(),
                                        y = m2_he.as_1d()).coefficient()
  print("CC, quantile rank-scaled (histogram equalized) maps: %6.4f" % \
    cc_quantile, file=out)
  print("Peak correlation:", file=out)
  print("  cutoff  CCpeak", file=out)
  cutoffs = [i/100.  for i in range(1,90)]+ [i/1000 for i in range(900,1000)]
  for cutoff in cutoffs:
    cc_peak = maptbx.cc_peak(map_1=m1_he, map_2=m2_he, cutoff=cutoff)
    print("  %3.2f   %7.4f" % (cutoff, cc_peak), file=out)
    cc_peaks.append((cutoff, cc_peak))

  # compute discrepancy function (D-function)
  discrepancies = list()
  cutoffs = flex.double(cutoffs)
  df = maptbx.discrepancy_function(map_1=m1_he, map_2=m2_he, cutoffs=cutoffs)
  print("Discrepancy function:", file=out)
  print("  cutoff  D", file=out)
  for c, d in zip(cutoffs, df):
    print("  %3.2f   %7.4f" % (c,d), file=out)
    discrepancies.append((c, d))

  # compute and output histograms
  h1 = maptbx.histogram(map=m1, n_bins=10000)
  h2 = maptbx.histogram(map=m2, n_bins=10000)
  print("Map histograms:", file=out)
  print("Map 1 (%s)     Map 2 (%s)"%\
    (params.input.map_1,params.input.map_2), file=out)
  print("(map_value,cdf,frequency) <> (map_value,cdf,frequency)", file=out)
  for a1,c1,v1, a2,c2,v2 in zip(h1.arguments(), h1.c_values(), h1.values(),
                                h2.arguments(), h2.c_values(), h2.values()):
    print("(%9.5f %9.5f %9.5f) <> (%9.5f %9.5f %9.5f)"%\
      (a1,c1,v1, a2,c2,v2), file=out)

  # store results
  s1_dict = create_statistics_dict(s=s1)
  s2_dict = create_statistics_dict(s=s2)
  results = dict()
  inputs = list()
  for attribute in input_attributes:
    filename = getattr(params.input,attribute)
    if (filename is not None):
      inputs.append(filename)
  assert (len(inputs) == 2)
  results['map_files'] = inputs
  results['map_statistics'] = (s1_dict, s2_dict)
  results['cc_input_maps'] = cc_input_maps
  results['cc_quantile'] = cc_quantile
  results['cc_peaks'] = cc_peaks
  results['discrepancies'] = discrepancies
  # TODO, verify h1,h2 are not dicts, e.g. .values is py2/3 compat. I assume it is here
  results['map_histograms'] = ( (h1.arguments(), h1.c_values(), h1.values()),
                                (h2.arguments(), h2.c_values(), h2.values()) )

  return results

# -----------------------------------------------------------------------------
def get_crystal_symmetry(file_handle):
  '''
  Helper function for get crystal symmetry from files
  '''
  file_object = file_handle.file_object
  cs = None
  if (hasattr(file_object, 'space_group_number')):     # CCP4 map
    cs = crystal.symmetry(file_object.unit_cell().parameters(),
                          file_object.space_group_number)
  elif (hasattr(file_object, 'as_miller_arrays')):     # MTZ file
    ma = file_object.as_miller_arrays()
    for a in ma:
      if (a.is_complex_array()):
        cs = a.crystal_symmetry()
        break
    if (cs is None):
      raise Sorry('No map coefficients found in %s.' %
                file_handle.file_name)
  if (cs is None):
    raise Sorry('Could not find crystal symmetry in %s.' %
                file_handle.file_name)
  return cs

def get_d_min(file_handle):
  '''
  Helper function for getting d_min from mtz file
  '''
  miller_arrays = file_handle.file_server.miller_arrays
  d_min = 10.0
  for miller_array in miller_arrays:
    d_min = min(d_min, miller_array.d_min())
  return d_min

def get_mtz_labels(file_handle):
  '''
  Helper function for getting data labels for complex miller arrays
  Returns list of labels for complex arrays
  '''
  miller_arrays = file_handle.file_server.miller_arrays
  labels = list()
  for miller_array in miller_arrays:
    if (miller_array.is_complex_array()):
      labels.append(miller_array.info().label_string())
  return labels

# =============================================================================
# Parameter validation for CLI and GUI
def validate_params(params):

  # check that only 2 files, in any combination, are provided
  input_attributes = ['map_1', 'mtz_1', 'map_2', 'mtz_2']
  n_defined = 0
  for attribute in input_attributes:
    if (getattr(params.input, attribute) is not None):
      n_defined += 1
  if (n_defined != 2):
    raise Sorry('Insufficient data, please provide 2 files' +
                ' (CCP4-formated map or MTZ)')

  # check file type
  maps = list()
  for attribute in input_attributes:
    filename = getattr(params.input, attribute)
    if (filename is not None):
      file_handle = file_reader.any_file(filename)
      if ( (file_handle.file_type != 'ccp4_map') and
           (file_handle.file_type != 'hkl') ):
        raise Sorry('Please input a CCP4-formatted map or MTZ file for %s.'\
                    % filename)
      else:
        maps.append(file_handle)

  # check symmetry
  cs1 = get_crystal_symmetry(maps[0])
  cs2 = get_crystal_symmetry(maps[1])
  if (cs1.is_similar_symmetry(cs2) is False):
    raise Sorry('The symmetry of the two files is not similar.')

  # check gridding if 2 map files are provided
  if ( (maps[0].file_type == 'ccp4_map') and
       (maps[1].file_type == 'ccp4_map') ):
    m1 = maps[0].file_object.map_data()
    m2 = maps[1].file_object.map_data()
    if ( (m1.accessor().all() != m2.accessor().all()) or
         (m1.accessor().focus() != m2.accessor().focus()) or
         (m1.accessor().origin() != m2.accessor().origin()) ):
      raise Sorry('The gridding of the two maps is not compatible.')
  else:
  # check if MTZ files have complex arrays and labels
    for i in range(len(maps)):
      if (maps[i].file_type == 'hkl'):
        labels = get_mtz_labels(maps[i])
        if (len(labels) == 0):
          raise Sorry('%s does not have complex map coefficients' %
                      maps[i].file_name)
        label_phil = getattr(params.input, 'mtz_label_' + str(i+1))
        if (label_phil is None):
          raise Sorry('No labels were specified for %s.' % maps[i].file_name)
        elif (label_phil not in labels):
          raise Sorry('%s does not exist in %s' %
                      (label_phil, maps[i].file_name))

  # check for valid resolution gridding
  if (params.options.resolution_factor < 0.0):
    raise Sorry(
      'Please use a positive value for the resolution gridding factor.')
  return True

# =============================================================================
# GUI-specific class for running command
from libtbx import runtime_utils
class launcher(runtime_utils.target_with_save_result):
  def run(self):
    result = run(args=self.args, validated=True, out=sys.stdout)
    return result

# =============================================================================
if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/map_to_model_histogram.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.map_to_model_histogram

import sys, math
import iotbx.pdb
import iotbx.phil
import mmtbx.f_model
from iotbx import reflection_file_reader
from cctbx.array_family import flex
from cctbx import maptbx
import mmtbx.utils
from iotbx import reflection_file_reader
from iotbx import reflection_file_utils
import mmtbx.masks
from six.moves import zip
from six.moves import range
from iotbx import extract_xtal_data

master_params_str = """\
bulk_solvent_mode = *fast slow
  .type=choice(multi=False)
remove_outliers = True
  .type = bool
f_obs_label = None
  .type = str
r_free_flags_label = None
  .type = str
grid_step = 0.5
  .type = float
map_type = Fo-Fc
  .type = str
apply_sigma_scaling = False
  .type = bool
apply_volume_scaling = True
  .type = bool
neutron = False
  .type = bool
n_radial_shells = 1
  .type = int
include_f000 = True
  .type = bool
use_exact_phases = False
  .type = bool
"""

def master_params():
  return iotbx.phil.parse(master_params_str, process_includes=False)


def show_histogram(data, n_slots):
  print(flex.min(data), flex.max(data), flex.mean(data))
  hm = flex.histogram(data = data, n_slots = n_slots)
  lc_1 = hm.data_min()
  s_1 = enumerate(hm.slots())
  for (i_1,n_1) in s_1:
    hc_1 = hm.data_min() + hm.slot_width() * (i_1+1)
    print("%10.3f - %-10.3f : %10.2f" % (lc_1, hc_1, float(n_1)/(data.size())*100.))
    lc_1 = hc_1

def get_f_obs_and_flags(reflection_file_name,
                        crystal_symmetry,
                        f_obs_label = None,
                        r_free_flags_label = None,
                        log = None):
  reflection_files = []
  reflection_files.append(reflection_file_reader.any_reflection_file(
    file_name = reflection_file_name, ensure_read_access = False))
  reflection_file_server = reflection_file_utils.reflection_file_server(
    crystal_symmetry = crystal_symmetry,
    force_symmetry   = True,
    reflection_files = reflection_files,
    err              = log)
  parameters = extract_xtal_data.data_and_flags_master_params().extract()
  if(f_obs_label is not None):
    parameters.labels = command_line.options.f_obs_label
  if(r_free_flags_label is not None):
    parameters.r_free_flags.label = command_line.options.r_free_flags_label
  determine_data_and_flags_result = extract_xtal_data.run(
    reflection_file_server = reflection_file_server,
    parameters             = parameters,
    keep_going             = True)
  f_obs = determine_data_and_flags_result.f_obs
  r_free_flags = determine_data_and_flags_result.r_free_flags
  return f_obs, r_free_flags

def expand_to_p1(xrs):
  xrsp1 = xrs.expand_to_p1()
  for sc in xrsp1.scatterers():
    site = sc.site
    x,y,z = site
    for t in range(3):
      if x < 0: x = x + 1.
      if x > 1: x = x - 1.
      #
      if y < 0: y = y + 1.
      if y > 1: y = y - 1.
      #
      if z < 0: z = z + 1.
      if z > 1: z = z - 1.
    #
    sc.site = [x,y,z]
    #
    site = sc.site
    assert site[0] >= 0 and site[0] <= 1
    assert site[1] >= 0 and site[1] <= 1
    assert site[2] >= 0 and site[2] <= 1
  return xrsp1

def map_stat(distances, map_values):
  result = []
  #
  n_points_max = -1
  nn=20
  x = [[i/100,i/100+nn/100.] for i in range(0,800, nn)]
  for x_ in x:
    l,r = x_
    sel  = distances >= l
    sel &= distances < r
    mv = map_values.select(sel)
    if(mv.size()>n_points_max): n_points_max = mv.size()
  #
  for x_ in x:
    l,r = x_
    sel  = distances >= l
    sel &= distances < r
    mv = map_values.select(sel)
    if(mv.size()>0):
      sz = mv.size()
      rms = math.sqrt( flex.sum(mv*mv)/sz )
      #fr = sz*100./map_values.size()
      fr = sz*1./n_points_max
      result.append([l, r, flex.mean(mv), rms, sz, fr])
  return result

def get_map_values_and_grid_sites_frac(
      fmodel,
      map_type,
      grid_step,
      d_min,
      apply_sigma_scaling,
      apply_volume_scaling,
      include_f000,
      sel_bb,
      use_exact_phases):
  #
  resolution_factor = grid_step/d_min
  mp = mmtbx.masks.mask_master_params.extract()
  mp.grid_step_factor = 1./resolution_factor
  mmtbx_masks_asu_mask_obj = mmtbx.masks.asu_mask(
    xray_structure = fmodel.xray_structure,
    d_min          = d_min,
    mask_params    = mp)
  bulk_solvent_mask = mmtbx_masks_asu_mask_obj.mask_data_whole_uc()
  sel = bulk_solvent_mask > 0
  bulk_solvent_mask = bulk_solvent_mask.set_selected(sel, 1)
  cr_gr = maptbx.crystal_gridding(
    unit_cell             = fmodel.xray_structure.unit_cell(),
    space_group_info      = fmodel.f_obs().space_group_info(),
    pre_determined_n_real = bulk_solvent_mask.focus())
  from mmtbx import map_tools
  from cctbx import miller
  #
  #mc = map_tools.electron_density_map(fmodel = fmodel).map_coefficients(
  #  map_type = map_type,
  #  acentrics_scale = 1.0,
  #  centrics_pre_scale = 1.0)
  if not use_exact_phases:
    k = fmodel.k_isotropic()*fmodel.k_anisotropic()
    print("flex.mean(k):", flex.mean(k))
    f_model = fmodel.f_model()
    mc_data = abs(fmodel.f_obs()).data()/k - abs(f_model).data()/k

    tmp = miller.array(miller_set = f_model,
      data = flex.double(f_model.indices().size(), 1)
      ).phase_transfer(phase_source = f_model)
    mc = miller.array(miller_set = tmp,
      data = mc_data * tmp.data())
  else:
    fmodel.update_all_scales(fast=True, remove_outliers=False)
    k = fmodel.k_isotropic()*fmodel.k_anisotropic()
    fo = fmodel.f_obs().customized_copy(data = fmodel.f_obs().data()/k)
    fo = fo.phase_transfer(phase_source = fmodel.f_model())
    fc = fmodel.f_calc().customized_copy(data = fmodel.f_calc().data())
    mc = miller.array(miller_set = fo,
      data = fo.data()-fc.data())




  ######## XXX
  fft_map = miller.fft_map(
    crystal_gridding     = cr_gr,
    fourier_coefficients = mc)
  fft_map.apply_volume_scaling()
  map_data = fft_map.real_map_unpadded()

  xrs = fmodel.xray_structure
  sites_cart = xrs.sites_cart().select(sel_bb)
  sel = maptbx.grid_indices_around_sites(
    unit_cell  = xrs.unit_cell(),
    fft_n_real = map_data.focus(),
    fft_m_real = map_data.all(),
    sites_cart = sites_cart,
    site_radii = flex.double(sites_cart.size(), 0.5))
  map_in  = map_data.select(sel)
  mm = flex.mean(map_in)
  print("mean in (1):", mm)
  #
  #sites_frac = xrs.sites_frac().select(sel_bb)
  #mm = 0
  #for sf in sites_frac:
  #  mm += map_data.eight_point_interpolation(sf)
  #mm = mm/sites_frac.size()
  #print "mean in (2):", mm
  ########

  #
  # Add F000
  #reg = fmodel.xray_structure.scattering_type_registry(table = "wk1995")
  #f_000 = reg.sum_of_scattering_factors_at_diffraction_angle_0() +\
  #  0.4*fmodel.xray_structure.unit_cell().volume()
  if(include_f000):
    #f_000 = include_f000*fmodel.xray_structure.unit_cell().volume()*0.3
    #f_000 = None # XXX
    f_000 = abs(mm * xrs.unit_cell().volume())
    #f_000 = 0.626*fmodel.xray_structure.unit_cell().volume()*0.35
  else:
    f_000 = None
  print("f_000:", f_000)
  #print "XXX", include_f000*fmodel.xray_structure.unit_cell().volume()*0.3
  #
  fft_map = miller.fft_map(
    crystal_gridding     = cr_gr,
    fourier_coefficients = mc,
    f_000 = f_000)
  #
  assert [apply_sigma_scaling, apply_volume_scaling].count(True) == 1
  if(apply_sigma_scaling):    fft_map.apply_sigma_scaling()
  elif(apply_volume_scaling): fft_map.apply_volume_scaling()
  else: assert RuntimeError
  nx,ny,nz = fft_map.n_real()
  map_data = fft_map.real_map_unpadded()

  #map_data = map_data * bulk_solvent_mask
  print("n_real:", nx,ny,nz, map_data.size())
  grid_sites_frac = flex.vec3_double()
  map_values = flex.double()
  for ix in range(nx):
    for iy in range(ny):
      for iz in range(nz):
        mv = map_data[(ix,iy,iz)]
        if 1: #if(mv != 0):
          xf,yf,zf = ix/float(nx), iy/float(ny), iz/float(nz)
          grid_sites_frac.append([xf,yf,zf])
          map_at_ixiyiz = map_data[(ix,iy,iz)]
          map_values.append(map_at_ixiyiz)
  return map_values, grid_sites_frac

def show_fmodel(fmodel, prefix=""):
  print("%s r_work=%6.4f r_free=%6.4f d_min=%6.4f nref=%d"%(prefix,
    fmodel.r_work(),fmodel.r_free(),fmodel.f_obs().d_min(),
    fmodel.f_obs().data().size()))

def get_stats(pdb_file_name,
              f_obs,
              r_free_flags,
              map_type,
              grid_step,
              apply_volume_scaling,
              apply_sigma_scaling,
              mode,
              neutron,
              n_radial_shells,
              include_f000,
              remove_outliers,
              use_exact_phases):
  results = []
  for bulk_solvent in [True, False]:
    print("bulk_solvent:", bulk_solvent, "-"*50)
    pdb_inp = iotbx.pdb.input(file_name = pdb_file_name)
    pdb_hierarchy = pdb_inp.construct_hierarchy()
    sstring = """ pepnames and (name ca or name n or name c) and altloc " " """
    sel_bb = pdb_hierarchy.atom_selection_cache().selection(string = sstring)
    xrs = pdb_inp.xray_structure_simple()
    if(neutron):
      xrs.switch_to_neutron_scattering_dictionary()
    mask_params = mmtbx.masks.mask_master_params.extract()
    mask_params.n_radial_shells = n_radial_shells
    fmodel = mmtbx.f_model.manager(
      f_obs          = f_obs,
      xray_structure = xrs,
      r_free_flags   = r_free_flags,
      mask_params    = mask_params)
    #
    show_fmodel(fmodel=fmodel, prefix="start:")
    if(mode=="fast"): fast=True
    elif(mode=="slow"): fast=False
    else: assert 0
    fmodel.update_all_scales(fast=fast, remove_outliers=remove_outliers)
    if(not bulk_solvent):
      k_mask = flex.double(fmodel.f_obs().data().size(), 0)
      fmodel.update(k_mask = k_mask)
    show_fmodel(fmodel=fmodel, prefix="final:")
    #
    map_values, grid_sites_frac = get_map_values_and_grid_sites_frac(
      fmodel               = fmodel,
      map_type             = map_type,
      grid_step            = grid_step,
      d_min                = f_obs.d_min(),
      apply_sigma_scaling  = apply_sigma_scaling,
      apply_volume_scaling = apply_volume_scaling,
      include_f000         = include_f000,
      sel_bb               = sel_bb,
      use_exact_phases     = use_exact_phases)
    #
    res = mmtbx.utils.density_distribution_per_atom(
      sites_frac_atoms = expand_to_p1(xrs = xrs).sites_frac(),
      sites_frac_peaks = grid_sites_frac,
      density_values   = map_values,
      unit_cell        = xrs.unit_cell())
    distances = res.distances()
    map_values = res.map_values()
    #
    result = map_stat(distances=distances, map_values=map_values)
    results.append(result)
  for result in zip(results[0],results[1]):
    l,r,p = result[0][0], result[0][1], result[0][5]
    m1,r1 = result[0][2], result[0][3]
    m2,r2 = result[1][2], result[1][3]
    print("%4.2f-%4.2f %10.4f | %8.4f %8.4f | %8.4f %8.4f" % (l, r, p, m1,r1, m2,r2))

def run(args, log = None):
  if(log is None): log = sys.stdout
  if(len(args)==0):
    print("Usage:\n")
    print("phenix.map_to_model_histogram model.pdb data.mtz [parameters]")
  processed_args = mmtbx.utils.process_command_line_args(args = args, log = log,
    master_params = master_params())
  print("-"*79, file=log)
  print("\nParameters:\n", file=log)
  processed_args.params.show(out = log, prefix=" ")
  if(len(args)==0): return
  params = processed_args.params.extract()
  #
  print("-"*79, file=log)
  print("\nData:\n", file=log)
  f_obs, r_free_flags = get_f_obs_and_flags(
    reflection_file_name = processed_args.reflection_file_names[0],
    crystal_symmetry     = processed_args.crystal_symmetry,
    log                  = log)
  print("-"*79, file=log)
  print("\nCalculations:\n", file=log)
  get_stats(pdb_file_name        = processed_args.pdb_file_names[0],
            f_obs                = f_obs,
            r_free_flags         = r_free_flags,
            grid_step            = params.grid_step,
            map_type             = params.map_type,
            apply_volume_scaling = params.apply_volume_scaling,
            apply_sigma_scaling  = params.apply_sigma_scaling,
            mode                 = params.bulk_solvent_mode,
            neutron              = params.neutron,
            n_radial_shells      = params.n_radial_shells,
            include_f000         = params.include_f000,
            remove_outliers      = params.remove_outliers,
            use_exact_phases     = params.use_exact_phases)

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/map_to_structure_factors.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.map_to_structure_factors

import iotbx.ccp4_map
from cctbx.array_family import flex
import mmtbx.utils
import sys
from libtbx.utils import Sorry
from six.moves import range

master_params_str = """
output_file_name = map_to_structure_factors.mtz
  .type=str
d_min = None
  .type=float
  .help = Resolution of output structure factors. Default is based on the\
           gridding of the map and can lead to map coefficients that are \
           at much higher resolution than the map.
  .short_caption = Resolution
resolution_factor = 1./3
  .type = float
  .help = Scale factor to guess resolution of output structure factors.\
          A scale factor of 0.5 gives the highest-resolution data allowed by \
          the map.  Usual is 0.33 or 0.25.
  .short_caption = Resolution factor
scale_max = 99999
  .type = float
  .help = Maximum value of output map coefficients amplitudes.  If None \
           use volume scaling
  .short_caption = Scale max
k_blur = 1
  .type = float
  .help = Scale applied to HL coefficients.  The HL coefficients are arbitrary\
          as no error information is available. The HL coefficients will have\
          values of k_blur at low resolution, falling off with an effective\
          B-value of b_blur at higher resolution.
  .short_caption = Scale on HL coefficients
b_blur  = 100
  .type = float
  .help = Blurring applied to HL coefficients.  The HL coefficients are \
          arbitrary\
          as no error information is available. The HL coefficients will have\
          values of k_blur at low resolution, falling off with an effective\
          B-value of b_blur at higher resolution.
  .short_caption = Blurring of HL coefficients
box = False
  .type = bool
  .help = You can choose to generate a full box of map coefficients based on\
          the gridding of the map.  Default is to generate map coefficients to\
          a specific resolution
  .short_caption = Box of Fourier coefficients
keep_origin = True
  .type = bool
  .help = Default (keep_origin=True) is to set the origin for the output map\
           coefficients to be the same as the input map. A map calculated from\
           the output map coefficients will superimpose on the input map. If \
           keep_origin=False then the new origin will be at (0,0,0). \
           Note: keep_origin=True is only available if the map covers an \
           entire unit cell. It will be automatically set to False if \
           less than a full unit cell is available.
  .short_caption = Keep origin
output_origin_grid_units = None
  .type = ints
  .help = You can set the origin of the output map (in grid units)
  .short_caption = Output origin (grid units)

# for wx GUI
map_file = None
  .type = path
  .help = Input map file
include scope libtbx.phil.interface.tracking_params
gui
  .help = "GUI-specific parameter required for output directory"
{
  output_dir = None
  .type = path
  .style = output_dir
}
"""

def master_params():
  return iotbx.phil.parse(master_params_str, process_includes=True)

def broadcast(m, log):
  print("-"*79, file=log)
  print(m, file=log)
  print("*"*len(m), file=log)

def get_cc(f, hl):
  map_coeffs = abs(f).phase_transfer(phase_source = hl)
  return map_coeffs.map_correlation(other=f)

def get_shift_cart(map_data, crystal_symmetry, origin=None):
  # this is the shift applied to the map when origin moves to (0,0,0)
  N = map_data.all()
  if origin is None:
    O = map_data.origin()
  else:
    O = tuple(origin)
  if(not crystal_symmetry.space_group().type().number() in [0,1]):
      raise Sorry("Space groups other than P1 are not supported.")
  a,b,c = crystal_symmetry.unit_cell().parameters()[:3]
  sx,sy,sz = O[0]/N[0],O[1]/N[1], O[2]/N[2]
  shift_frac = [-sx,-sy,-sz]
  shift_cart = crystal_symmetry.unit_cell().orthogonalize(shift_frac)
  return shift_cart

def run(args, log=None, ccp4_map=None,
    return_as_miller_arrays=False, nohl=False, return_f_obs=False,
    space_group_number=None,
    out=sys.stdout):
  if log is None: log=out
  inputs = mmtbx.utils.process_command_line_args(args = args,
    master_params = master_params())
  got_map = False
  if ccp4_map: got_map=True
  broadcast(m="Parameters:", log=log)
  inputs.params.show(prefix="  ",out=out)
  params = inputs.params.extract()
  if(ccp4_map is None and inputs.ccp4_map is not None):
    broadcast(m="Processing input CCP4 map file: %s"%inputs.ccp4_map_file_name,
      log=log)
    ccp4_map = inputs.ccp4_map
    ccp4_map.show_summary(prefix="  ",out=out)
    got_map = True
  if(not got_map):
    raise Sorry("Map file is needed.")
  #
  m = ccp4_map
  if(m.unit_cell_crystal_symmetry().space_group_number()> 1):
    raise Sorry("Input map space group: %d. Must be P1."%m.unit_cell_crystal_symmetry().space_group_number())
  broadcast(m="Input map information:", log=log)
  print("m.all()   :", m.map_data().all(), file=out)
  print("m.focus() :", m.map_data().focus(), file=out)
  print("m.origin():", m.map_data().origin(), file=out)
  print("m.nd()    :", m.map_data().nd(), file=out)
  print("m.size()  :", m.map_data().size(), file=out)
  print("m.focus_size_1d():", m.map_data().focus_size_1d(), file=out)
  print("m.is_0_based()   :", m.map_data().is_0_based(), file=out)
  print("map: min/max/mean:", flex.min(m.map_data()), flex.max(m.map_data()), flex.mean(m.map_data()), file=out)
  print("unit cell:", m.unit_cell().parameters(), file=out)
  #
  if m.unit_cell_grid == m.map_data().all():
    print("\nOne unit cell of data is present in map", file=out)
  else:
    if params.keep_origin:
      print("\nNOTE: This map does not have exactly one unit cell of data, so \n"+\
        "keep_origin is not available\n", file=out)
      print("--> Setting keep_origin=False and creating a new cell and gridding.\n", file=out)
      params.keep_origin=False
    print("Moving origin of input map to (0,0,0)", file=out)
    print("New cell will be: (%.3f, %.3f, %.3f, %.1f, %.1f, %.1f) A " %(
       m.crystal_symmetry().unit_cell().parameters()), file=out)
    print("New unit cell grid will be: (%s, %s, %s) "%(
      m.map_data().all()), file=out)
    m.unit_cell_grid = m.map_data().all()

  import iotbx.map_manager
  mm = iotbx.map_manager.map_manager(
    map_data                   = m.map_data().as_double(),
    unit_cell_grid             = m.unit_cell_grid,
    unit_cell_crystal_symmetry = m.crystal_symmetry(),
    wrapping                   = True)

  # Get origin in grid units and new position of origin in grid units
  original_origin=mm.map_data().origin()
  print("\nInput map has origin at grid point (%s,%s,%s)" %(
        tuple(original_origin)), file=out)

  if params.output_origin_grid_units is not None:
    params.keep_origin=False
    new_origin=tuple(params.output_origin_grid_units)
    print("User-specified origin at grid point (%s,%s,%s)" %(
        tuple(params.output_origin_grid_units)), file=out)
    if tuple(params.output_origin_grid_units)==tuple(original_origin):
      print("This is the same as the input origin. No origin shift.", file=out)
  elif params.keep_origin:
    new_origin=original_origin
    print("Keeping origin at grid point  (%s,%s,%s)" %(
        tuple(original_origin)), file=out)
  else:
    new_origin=(0,0,0,)
    print("New origin at grid point (%s,%s,%s)" %(
        tuple((0,0,0,))), file=out)

  # shift_cart is shift away from (0,0,0)
  if new_origin != (0,0,0,):
    shift_cart=get_shift_cart(map_data=mm.map_data(), crystal_symmetry=mm.crystal_symmetry(),
      origin=new_origin)
  else:
    shift_cart=(0,0,0,)

  # Shift the map data if necessary
  mm.shift_origin()

  f_obs_cmpl = mm.map_as_fourier_coefficients(
     d_min             = params.d_min,
     box               = params.box,
     resolution_factor = params.resolution_factor)

  if params.scale_max is not None:
    f_obs_cmpl = f_obs_cmpl.apply_scaling(target_max=params.scale_max)

  from scitbx.matrix import col
  if col(shift_cart) != col((0,0,0,)):
    print("Output origin is at: (%.3f, %.3f, %.3f) A "%(
      tuple(-col(shift_cart))), file=out)
    f_obs_cmpl=f_obs_cmpl.translational_shift(
        mm.crystal_symmetry().unit_cell().fractionalize(-col(shift_cart)), deg=False)
  else:
    print("Output origin is at (0.000, 0.000, 0.000) A", file=out)

  if nohl and return_as_miller_arrays and not return_f_obs:
    return f_obs_cmpl

  mtz_dataset = f_obs_cmpl.as_mtz_dataset(column_root_label="F")
  f_obs = abs(f_obs_cmpl)
  f_obs.set_sigmas(sigmas=flex.double(f_obs_cmpl.data().size(),1))
  if nohl and return_as_miller_arrays and return_f_obs:
     return f_obs
  mtz_dataset.add_miller_array(
    miller_array      = f_obs,
    column_root_label = "F-obs")
  mtz_dataset.add_miller_array(
    miller_array      = f_obs.generate_r_free_flags(),
    column_root_label = "R-free-flags")
  if not nohl and params.k_blur is not None and params.b_blur is not None:
    # convert phases into HL coefficeints
    broadcast(m="Convert phases into HL coefficients:", log=log)
    hl = f_obs_cmpl.make_up_hl_coeffs(k_blur=params.k_blur, b_blur=params.b_blur)
    cc = get_cc(f = f_obs_cmpl, hl = hl)
    print("cc:", cc, file=out)
    if(abs(1.-cc)>1.e-3):
      print("Supplied b_blur is not good. Attempting to find optimal b_blur.", file=out)
      cc_best = 999.
      b_blur_best = params.b_blur
      for b_blur in range(1, 100):
        hl = f_obs_cmpl.make_up_hl_coeffs(k_blur=params.k_blur, b_blur=b_blur)
        cc = get_cc(f = f_obs_cmpl, hl = hl)
        if(cc<cc_best):
          cc_best = cc
          b_blur_best = b_blur
        if(abs(1.-cc)<1.e-3):
          b_blur_best = b_blur
          break
      hl = f_obs_cmpl.make_up_hl_coeffs(k_blur=params.k_blur, b_blur=b_blur_best)
      print("cc:", get_cc(f = f_obs_cmpl, hl = hl), file=out)
      print("b_blur_best:", b_blur_best, file=out)
    mtz_dataset.add_miller_array(
      miller_array      = hl,
      column_root_label = "HL")
  else:
    hl=None
  if return_as_miller_arrays:
    if return_f_obs:
      return f_obs,hl
    else:
      return f_obs_cmpl,hl
  else:
    # write output MTZ file with all the data
    broadcast(m="Writing output MTZ file:", log=log)
    print("  file name:", params.output_file_name, file=log)
    mtz_object = mtz_dataset.mtz_object()
    mtz_object.write(file_name = params.output_file_name)

if(__name__ == "__main__"):
  run(sys.argv[1:])
  print("All done.")


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/maps.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.maps

import mmtbx.maps
from scitbx.array_family import flex
import os, sys, random
import iotbx.pdb
from libtbx.utils import Sorry
from libtbx import runtime_utils
import mmtbx.utils
from iotbx import reflection_file_reader
from iotbx import reflection_file_utils
from iotbx import crystal_symmetry_from_any
from cctbx import crystal
from iotbx import extract_xtal_data

random.seed(0)
flex.set_random_seed(0)


legend = """
phenix.maps: a command line tool to compute various maps and save them in most
             of known formats.

How to run the command line version:

  1. Run phenix.maps without any arguments: just type phenix.maps in the command
     line and hit Enter. This will creare a parameter file called maps.params,
     which can be renamed if desired.

  2. Edit maps.params file to specify input/output file names, data labels and
     the desired maps. It is possible to request as many maps as desired. By
     default, the file maps.params specifies 5 maps to be created: 2mFo-DFc,
     2mFo-DFc with missing Fobs filled with DFcalc, mFo-DFc and anomalous
     difference maps will be output in MTZ format, and one 2mFo-DFc map will be
     output in CCP4 format.
     NOTE: the anomalous difference map will only be created if the input
     reflection data file contains Bijvoet maps (F+/F- or I+/I-).

  3. Run this command to compute requested maps: phenix.maps maps.params

Alternately, you may specify input files (and additional parameters) directly
on the command line:

  % phenix.maps model.pdb data.mtz

and it will automatically generate the default maps as described above.

Important Facts:

  - phenix.maps is available in PHENIX GUI.

  - The scope of parameters 'map_coefficients' defines the map that will be
    output as Fourier map coefficients. The scope of parameters 'map' defines
    the maps that will be output as CCP4 or X-plor format.

  - To create several maps: duplicate either 'map_coefficients' or 'map' or both
    scopes of parameters as many times as many maps is desired. Then edit each
    of them to define the maps.

  - A map is defined by specifying a map type using 'map_type' keyword available
    within each scope of parameters: 'map_coefficients' or 'map'. The general
    supported format for 'map_type' is: [p][m]Fo+[q][D]Fc[_filled]. For
    example: 2Fo-Fc, 2mFobs-DFcalc, 3Fobs-2Fmodel, Fo-Fc, mfobs-Dfcalc, anom,
    llg.  The 'map_type' parser will automatically recognize which map is
    requested.

  - The program creates as many files with CCP4 or X-plor formatted maps as
    is requested, and it creates only one MTZ formatted file with
    all Fourier map coefficients in it.

  - The CCP4 or X-plor formatted maps can be computed in the entire unit cell
    or around selected atoms only.

  - Twinning (if detected) will be accounted for automatically. This can be
    disabled by using "skip_twin_detection=True" keyword.

  - All arrays used in map calculation, for example: Fobs, Fmodel, Fcalc, Fmask,
    m, D, etc., can be output into a CNS or MTZ formatted reflection file.

  - For those who likes to experiment: bulk solvent correction and anisotropic
    scaling can be turned off, the data can be filtered by sigma and resolution.

  - For some map types certain 'map_coefficients' or 'map' scope parameters may
    not be applicable. For example, for "map_type=anomalous" the keywords
    "fill_missing_f_obs" and some other are not applicable.

  - For LLG map calculation, if you specify the wavelength any existing heavy
    atoms (P or heavier) will be modeled as anomalous scatterers using the
    theoretical values of f' and f''.
"""

default_params = """\
maps {
  map_coefficients {
    map_type = 2mFo-DFc
    format = *mtz phs
    mtz_label_amplitudes = 2FOFCWT
    mtz_label_phases = PH2FOFCWT
    fill_missing_f_obs = False
  }
  map_coefficients {
    map_type = 2mFo-DFc
    format = *mtz phs
    mtz_label_amplitudes = 2FOFCWT_fill
    mtz_label_phases = PH2FOFCWT_fill
    fill_missing_f_obs = True
  }
  map_coefficients {
    map_type = mFo-DFc
    format = *mtz phs
    mtz_label_amplitudes = FOFCWT
    mtz_label_phases = PHFOFCWT
    fill_missing_f_obs = False
  }
  map_coefficients {
    map_type = anomalous
    format = *mtz phs
    mtz_label_amplitudes = ANOM
    mtz_label_phases = PHANOM
  }
  map {
    map_type = 2mFo-DFc
    fill_missing_f_obs = False
    grid_resolution_factor = 1/4.
  }
}
"""

def analyze_input_params(params):
  # Analyze map_coefficients
  mcp = params.maps.map_coefficients
  i = 0
  while (i < len(mcp)):
    mcp_ = mcp[i]
    if (mcp_.map_type is None):
      del mcp[i]
      continue
    if(mmtbx.map_names(mcp_.map_type).anomalous):
      mcp_.fill_missing_f_obs = False
      mcp_.acentrics_scale = 2.0
      mcp_.centrics_pre_scale = 1.0
      mcp_.sharpening = False
      mcp_.sharpening_b_factor = None
    i += 1
  # Analyze maps
  mp = params.maps.map
  i = 0
  while (i < len(mp)):
    mp_ = mp[i]
    if (mp_.map_type is None):
      del mp[i]
      continue
    if(mmtbx.map_names(mp_.map_type).anomalous):
      mp_.fill_missing_f_obs = False
      mp_.acentrics_scale = 2.0
      mp_.centrics_pre_scale = 1.0
      mp_.sharpening = False
      mp_.sharpening_b_factor = None
    i += 1

def run(args, log = sys.stdout, use_output_directory=True,
    suppress_fmodel_output=False):
  print(legend, file=log)
  print("-"*79, file=log)
  master_params = mmtbx.maps.maps_including_IO_master_params()
  if(len(args)==0 or (len(args)==1 and args[0]=="NO_PARAMETER_FILE")):
    if(not (len(args)==1 and args[0]=="NO_PARAMETER_FILE")):
      parameter_file_name = "maps.params"
      print("Creating parameter file '%s' in the following directory:\n%s"%(
        parameter_file_name, os.path.abspath('.')), file=log)
      if(os.path.isfile(parameter_file_name)):
        msg="File '%s' exists already. Re-name it or move and run the command again."
        raise Sorry(msg%parameter_file_name)
      pfo = open(parameter_file_name, "w")
    else:
      pfo = log
      print("\nAll phenix.maps parameters::\n", file=pfo)
    master_params = master_params.fetch(iotbx.phil.parse(default_params))
    master_params.show(out = pfo, prefix = " ", expert_level=1)
    return
  processed_args = mmtbx.utils.process_command_line_args(
    args=args,
    log=log,
    master_params=master_params)
  working_phil = processed_args.params
  params = working_phil.extract()
  fmodel_data_file_format = params.maps.output.fmodel_data_file_format
  if (len(params.maps.map_coefficients) == 0) and (len(params.maps.map) == 0):
    print("No map input specified - using default map types", file=log)
    working_phil = master_params.fetch(sources=[working_phil,
        iotbx.phil.parse(default_params)])
    params = working_phil.extract()
  # XXX BUG - the extra fetch will always set fmodel_data_file_format to
  # mtz; this is probaby a low-level phil problem
  if (fmodel_data_file_format is None) or (suppress_fmodel_output):
    params.maps.output.fmodel_data_file_format = None
  analyze_input_params(params=params)
  have_phil_file_input = len(processed_args.phil_file_names) > 0
  if (len(processed_args.pdb_file_names) > 1):
    raise Sorry("Only one model file is allowed as input.")
  if ((params.maps.input.pdb_file_name is None) and
      (len(processed_args.pdb_file_names) == 1)):
    params.maps.input.pdb_file_name = processed_args.pdb_file_names[0]
  if(not os.path.isfile(str(params.maps.input.pdb_file_name))):
    raise Sorry(
      "model file is not given: maps.input.pdb_file_name=%s is not a file"%\
      str(params.maps.input.pdb_file_name))
  if ((params.maps.input.reflection_data.file_name is None) and
      (params.maps.input.reflection_data.r_free_flags.file_name is None) and
      (len(processed_args.reflection_file_names) == 1)):
    params.maps.input.reflection_data.file_name = \
      processed_args.reflection_file_names[0]
  print("FORMAT:", params.maps.output.fmodel_data_file_format, file=log)
  working_phil = master_params.format(python_object=params)
  print("-"*79, file=log)
  print("\nParameters to compute maps::\n", file=log)
  working_phil.show(out = log, prefix=" ")
  pdb_inp = iotbx.pdb.input(file_name = params.maps.input.pdb_file_name)
  # get all crystal symmetries
  cs_from_coordinate_files = [pdb_inp.crystal_symmetry_from_cryst1()]
  cs_from_reflection_files = []
  for rfn in [params.maps.input.reflection_data.file_name,
             params.maps.input.reflection_data.r_free_flags.file_name]:
    if(os.path.isfile(str(rfn))):
      try:
        cs_from_reflection_files.append(crystal_symmetry_from_any.extract_from(rfn))
      except KeyboardInterrupt: raise
      except RuntimeError: pass
  crystal_symmetry = None
  try :
    crystal_symmetry = crystal.select_crystal_symmetry(
      from_coordinate_files=cs_from_coordinate_files,
      from_reflection_files=cs_from_reflection_files)
  except AssertionError as e :
    if ("No unit cell and symmetry information supplied" in str(e)):
      raise Sorry("Missing or incomplete symmetry information.  This program "+
        "will only work with reflection file formats that contain both "+
        "unit cell and space group records, such as MTZ files.")
  #
  reflection_files = []
  reflection_file_names = []
  for rfn in [params.maps.input.reflection_data.file_name,
             params.maps.input.reflection_data.r_free_flags.file_name]:
    if(os.path.isfile(str(rfn))) and (not rfn in reflection_file_names):
      reflection_files.append(reflection_file_reader.any_reflection_file(
        file_name = rfn, ensure_read_access = False))
      reflection_file_names.append(rfn)
  reflection_file_server = reflection_file_utils.reflection_file_server(
    crystal_symmetry = crystal_symmetry,
    force_symmetry   = True,
    reflection_files = reflection_files, #[],
    err              = log)
  #
  reflection_data_master_params = extract_xtal_data.data_and_flags_master_params(
    master_scope_name="reflection_data")
  reflection_data_input_params = processed_args.params.get(
    "maps.input.reflection_data")
  reflection_data_params = reflection_data_master_params.fetch(
    reflection_data_input_params).extract().reflection_data
  #
  determine_data_and_flags_result = extract_xtal_data.run(
    reflection_file_server = reflection_file_server,
    parameters             = reflection_data_params,
    keep_going             = True)
  f_obs = determine_data_and_flags_result.f_obs
  r_free_flags = determine_data_and_flags_result.r_free_flags
  test_flag_value = determine_data_and_flags_result.test_flag_value
  if(r_free_flags is None):
    r_free_flags=f_obs.array(data=flex.bool(f_obs.data().size(), False))
    test_flag_value=None
  print("-"*79, file=log)
  print("\nInput model file:", params.maps.input.pdb_file_name, file=log)
  pdb_hierarchy = pdb_inp.construct_hierarchy(set_atom_i_seq=True)
  atom_selection_manager = pdb_hierarchy.atom_selection_cache()
  xray_structure = pdb_hierarchy.extract_xray_structure(
    crystal_symmetry = crystal_symmetry)
  # apply omit selection
  if(params.maps.omit.selection is not None):
    omit_selection = atom_selection_manager.selection(
      string = params.maps.omit.selection)
    keep_selection = ~omit_selection
    xray_structure = xray_structure.select(selection = keep_selection)
    pdb_hierarchy = pdb_hierarchy.select(keep_selection)
    atom_selection_manager = pdb_hierarchy.atom_selection_cache()
  #
  mmtbx.utils.setup_scattering_dictionaries(
    scattering_table = params.maps.scattering_table,
    xray_structure   = xray_structure,
    d_min            = f_obs.d_min(),
    log              = log)
  if (params.maps.wavelength is not None):
    if (params.maps.scattering_table == "neutron"):
      raise Sorry("Wavelength parameter not supported when the neutron "+
        "scattering table is used.")
    xray_structure.set_inelastic_form_factors(
      photon=params.maps.wavelength,
      table="sasaki")
  xray_structure.show_summary(f = log, prefix="  ")
  print("-"*79, file=log)
  print("Bulk solvent correction and anisotropic scaling:", file=log)
  fmodel = mmtbx.utils.fmodel_simple(
    xray_structures         = [xray_structure],
    scattering_table        = params.maps.scattering_table,
    f_obs                   = f_obs,
    r_free_flags            = r_free_flags,
    outliers_rejection      = params.maps.input.reflection_data.outliers_rejection,
    skip_twin_detection     = params.maps.skip_twin_detection,
    bulk_solvent_correction = params.maps.bulk_solvent_correction,
    anisotropic_scaling     = params.maps.anisotropic_scaling)
  fmodel_info = fmodel.info()
  fmodel_info.show_rfactors_targets_scales_overall(out = log)
  print("-"*79, file=log)
  print("Compute maps.", file=log)
  # XXX if run from the Phenix GUI, the output directory parameter is actually
  # one level up from the current directory, and use_output_directory=False
  if (params.maps.output.directory is not None) and (use_output_directory):
    assert os.path.isdir(params.maps.output.directory)
    output_dir = params.maps.output.directory
  else :
    output_dir = os.getcwd()
  if params.maps.output.prefix is not None :
    file_name_base = os.path.join(output_dir,
      os.path.basename(params.maps.output.prefix))
  else :
    file_name_base = params.maps.input.pdb_file_name
    if(file_name_base.count(".")>0):
      file_name_base = file_name_base[:file_name_base.index(".")]
  xplor_maps = mmtbx.maps.compute_xplor_maps(
    fmodel                 = fmodel,
    params                 = params.maps.map,
    atom_selection_manager = atom_selection_manager,
    file_name_prefix       = None,
    file_name_base         = file_name_base,
    pdb_hierarchy          = pdb_hierarchy)
  cmo = mmtbx.maps.compute_map_coefficients(
    fmodel = fmodel,
    params = params.maps.map_coefficients,
    pdb_hierarchy = pdb_hierarchy,
    log = log)
  map_coeff_file_name = file_name_base+"_map_coeffs.mtz"
  r_free_flags_output = None
  if (params.maps.output.include_r_free_flags):
    r_free_flags_output = fmodel.r_free_flags().average_bijvoet_mates()
  write_mtz_file_result = cmo.write_mtz_file(file_name = map_coeff_file_name,
    r_free_flags=r_free_flags_output)
  if(params.maps.output.fmodel_data_file_format is not None):
    fmodel_file_name = file_name_base + "_fmodel." + \
      params.maps.output.fmodel_data_file_format
    print("Writing fmodel arrays (Fobs, Fcalc, m, ...) to %s file."%\
      fmodel_file_name, file=log)
    fmodel_file_object = open(fmodel_file_name,"w")
    fmodel.export(out = fmodel_file_object, format =
      params.maps.output.fmodel_data_file_format)
    fmodel_file_object.close()
  print("All done.", file=log)
  if (write_mtz_file_result):
    print("Map coefficients: %s" % map_coeff_file_name, file=log)
  for file_name in xplor_maps :
    print("CCP4 or XPLOR map: %s" % file_name, file=log)
  print("-"*79, file=log)
  return (map_coeff_file_name, xplor_maps)

class launcher(runtime_utils.target_with_save_result):
  def run(self):
    os.mkdir(self.output_dir)
    os.chdir(self.output_dir)
    return run(args=list(self.args),
      log=sys.stdout,
      use_output_directory=False,
      suppress_fmodel_output=True) # XXX bug fix

def validate_params(params, callback=None):
  if params.maps.input.pdb_file_name is None :
    raise Sorry("No model file defined.")
  elif params.maps.input.reflection_data.file_name is None :
    raise Sorry("No reflection file defined.")
  elif params.maps.input.reflection_data.labels is None :
    raise Sorry("No labels chosen for reflection data.")
  elif len(params.maps.map) == 0 and len(params.maps.map_coefficients) == 0 :
    raise Sorry("You have not requested any maps for output.")
  elif ((params.maps.output.directory is not None) and
        (not os.path.isdir(params.maps.output.directory))):
    raise Sorry(("The output directory %s does not exist; please choose a "+
      "valid directory, or leave this parameter blank.") %
      params.maps.output.directory)
  if (params.maps.wavelength is not None):
    if (params.maps.scattering_table == "neutron"):
      raise Sorry("Wavelength parameter not supported when the neutron "+
        "scattering table is used.")
  validate_map_params(params.maps)
  # TODO double-check this - can we get None by accident in GUI?
  #for map_coeffs in params.maps.map_coefficients :
  #  if (map_coeffs.map_type is None):
  #    raise Sorry("One or more map coefficients is missing a map type "+
  #      "definition.")
  return True

def validate_map_params(params):
  from mmtbx import map_names
  labels = []
  for map_coeffs in params.map_coefficients :
    if (map_coeffs.map_type is not None):
      try :
        decode_map = map_names(map_coeffs.map_type)
      except RuntimeError as e :
        raise Sorry(str(e))
      f = map_coeffs.mtz_label_amplitudes
      phi = map_coeffs.mtz_label_phases
      if (f in labels) or (phi in labels):
        raise Sorry(("The map coefficients with MTZ labels %s,%s duplicates at"+
          " least one previously defined label.  You may output multiple sets "+
          "of coefficients with the same map type, but the column labels must "+
          "be unique.") % (f, phi))
      elif (None in [f, phi]):
        raise Sorry("Please specify both MTZ column labels for map_type '%s'."%
          map_coeffs.map_type)
      labels.extend([f,phi])
  if (hasattr(params, "map")):
    for map in params.map :
      if (map.grid_resolution_factor > 0.5):
        # XXX can't we enforce this in phil?
        raise Sorry("The grid resolution factor for CCP4 and X-PLOR maps "+
          "must be 0.5 or less.")
  return True

def finish_job(results):
  (mtz_file, map_files) = results
  output_files = []
  if mtz_file is not None and os.path.isfile(mtz_file):
    output_files.append((mtz_file, "MTZ file"))
  for map_file in map_files :
    if os.path.isfile(map_file):
      output_files.append((map_file, "XPLOR map"))
  return (output_files, [])

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/mask.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.mask

from iotbx.cli_parser import run_program
from mmtbx.programs import mask

if __name__ == "__main__":
  run_program(mask.Program)



 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/massage_data.py

"""
Tool for modifying experimental data, spun off from Xtriage.
"""

from __future__ import absolute_import, division, print_function
from libtbx.utils import Sorry
import os.path as op
import sys

master_phil_str = """
crystal_symmetry {
  space_group = None
    .type = space_group
  unit_cell = None
    .type = unit_cell
  symm_file = None
    .type = path
}
input {
  data = None
    .type = path
    .help = Data file
  labels = None
    .type = strings
}
options {
  include scope mmtbx.scaling.massage_twin_detwin_data.master_params
}
output {
  include scope mmtbx.scaling.massage_twin_detwin_data.output_params_str
}
"""

def run(args, out=sys.stdout):
  import iotbx.phil
  cmdline = iotbx.phil.process_command_line_with_files(
    args=args,
    master_phil_string=master_phil_str,
    pdb_file_def="crystal_symmetry.symm_file",
    reflection_file_def="input.data",
    space_group_def="crystal_symmetry.space_group",
    unit_cell_def="crystal_symmetry.unit_cell",
    usage_string="""\
mmtbx.massage_data data.mtz [labels=I,SIGI] [options]

Modification of experimental data: remove anisotropy, apply B-factor, filter
negative intensities, add or remove twinning.  For expert use (and extreme
cases) only.
""")
  params = cmdline.work.extract()
  if (params.input.data is None):
    raise Sorry("No data file supplied.")
  from mmtbx.scaling import massage_twin_detwin_data
  from iotbx import crystal_symmetry_from_any
  from iotbx import reflection_file_utils
  from cctbx import crystal
  crystal_symmetry = space_group = unit_cell = None
  if (params.crystal_symmetry.space_group is not None):
    space_group = params.crystal_symmetry.space_group
  if (params.crystal_symmetry.unit_cell is not None):
    unit_cell = params.crystal_symmetry.unit_cell
  crystal_symmetry = None
  if (params.crystal_symmetry.symm_file is not None):
    crystal_symmetry = crystal_symmetry_from_any.extract_from(
      file_name=params.crystal_symmetry.symm_file)
    if (crystal_symmetry is None):
      raise Sorry("No crystal symmetry defined in %s" %
        params.crystal_symmetry.symm_file)
  if (crystal_symmetry is None) and (not None in [space_group, unit_cell]):
    crystal_symmetry = crystal.symmetry(
      space_group_info=space_group,
      unit_cell=unit_cell)
  hkl_in = cmdline.get_file(params.input.data)
  hkl_server = reflection_file_utils.reflection_file_server(
    crystal_symmetry=crystal_symmetry,
    force_symmetry=True,
    reflection_files=[hkl_in.file_object],
    err=sys.stderr)
  data = hkl_server.get_xray_data(
    file_name=params.input.data,
    labels=params.input.labels,
    ignore_all_zeros=True,
    parameter_scope="input",
    prefer_anomalous=True,
    prefer_amplitudes=False)
  result = massage_twin_detwin_data.massage_data(
    miller_array=data,
    parameters=params.options,
    out=out)
  if (params.output.hklout is None):
    file_base = op.splitext(op.basename(params.input.data))[0]
    if (params.output.hklout_type in ["Auto", "mtz"]):
      params.output.hklout = file_base + ".mtz"
    else :
      params.output.hklout = file_base + ".sca"
  result.write_data(
    file_name=params.output.hklout,
    output_type=params.output.hklout_type,
    label_extension=params.output.label_extension)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/matthews.py
# LIBTBX_SET_DISPATCHER_NAME mmtbx.matthews
from __future__ import absolute_import, division, print_function

from iotbx.cli_parser import run_program
from mmtbx.programs import matthews

if __name__ == '__main__':
  run_program(program_class=matthews.Program)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/maximum_entropy_map.py
# LIBTBX_SET_DISPATCHER_NAME phenix.maximum_entropy_map

from __future__ import absolute_import, division, print_function
import mmtbx.utils
import iotbx.phil
from iotbx import reflection_file_utils
import cctbx.maptbx.mem as mem
from libtbx.utils import user_plus_sys_time, Sorry
from libtbx import runtime_utils
import os.path
import sys

master_params_str="""\
hkl_file_name = None
  .type = path
  .short_caption = Map coefficients
  .style = bold file_type:mtz process_hkl child:map_arrays:label input_file
label = None
  .type = str
  .input_size = 160
  .short_caption = Column labels
  .style = bold renderer:draw_map_arrays_widget noauto
pdb_file_name = None
  .type = path
  .short_caption = Model file
  .style = file_type:pdb
scattering_table = wk1995  it1992  *n_gaussian  neutron
  .type = choice
solvent_fraction = None
  .type = float
f_000 = None
  .type = float
  .short_caption = F(0,0,0)
lam = 0.05
  .type = float
  .short_caption = Lambda
lambda_increment_factor = 1.02
  .type = float
output_file_name = None
  .type = path
  .short_caption = Output file
  .style = bold output_file file_type:mtz
column_root_label = MEM
  .type = str
  .input_size = 100
  .short_caption = Output label base
output_high_resolution = None
  .type = float
mean_solvent_density = 0.35
  .type = float
max_iterations = 1000
  .type = float
resolution_factor = 0.3
  .type = float
  .short_caption = Grid resolution factor
beta = 0.7
  .type = float
convergence_at_r_factor = 0.05
  .type = float
convergence_r_threshold = 0.1
  .type = float
gui_output_dir = None
  .type = path
  .short_caption = Output directory
  .style = output_dir
include scope libtbx.phil.interface.tracking_params
"""

def master_params():
  return iotbx.phil.parse(master_params_str, process_includes=True)

def broadcast(m, log):
  print("-"*79, file=log)
  print(m, file=log)
  print("*"*len(m), file=log)

def format_usage_message(log):
  print("-"*79, file=log)
  msg = """\
phenix.max_entropy_map: map modification using Maximum Entropy Method (MEM)

Usage examples:
  phenix.max_entropy_map map_coeffs.mtz
  phenix.max_entropy_map model.pdb map_coeffs.mtz
  phenix.max_entropy_map model.pdb map.mtz label="2FOFCWT,PH2FOFCWT"

Feedback:
  PAfonine@lbl.gov or phenixbb@phenix-online.org"""
  print(msg, file=log)
  print("-"*79, file=log)

def run(args, log):
  timer = user_plus_sys_time()
  format_usage_message(log = log)
  if(len(args)==0): return
  parsed = master_params()
  inputs = mmtbx.utils.process_command_line_args(
    args=args, master_params=parsed, log=log)
  params = inputs.params.extract()
  broadcast(m="Input parameters", log = log)
  inputs.params.show(prefix="  ")
  ###
  xray_structure = None
  if(len(inputs.pdb_file_names)>0):
    broadcast(m="Input model", log = log)
    assert len(inputs.pdb_file_names) == 1
    print("  file name:", inputs.pdb_file_names[0], file=log)
    xray_structure = iotbx.pdb.input(
      file_name = inputs.pdb_file_names[0]).xray_structure_simple()
    assert xray_structure is not None
    xray_structure.show_summary(prefix="  ", f=log)
    mmtbx.utils.setup_scattering_dictionaries(
      scattering_table = params.scattering_table,
      xray_structure   = xray_structure,
      d_min            = 0.25)
    xray_structure.scattering_type_registry().show(prefix="  ", out = log)
  ###
  broadcast(m="Input reflection data", log = log)
  reff = inputs.reflection_file_names
  if(len(reff) > 1):
    raise Sorry("One reflection file should be provided.")
  elif(len(reff) == 0):
    if(params.hkl_file_name is None):
      raise Sorry("No reflection file provided.")
    else: reff = [params.hkl_file_name]
  map_coeffs = reflection_file_utils.extract_miller_array_from_file(
    file_name = reff[0],
    label     = params.label,
    type      = "complex",
    log       = log)
  assert map_coeffs is not None
  map_coeffs.show_comprehensive_summary(prefix="  ", f=log)
  ###
  broadcast(m="MEM calculations begin", log = log)
  f_000 = params.f_000
  solvent_fraction = params.solvent_fraction
  if(f_000 is None):
    f_000_obj = mmtbx.utils.f_000(
      xray_structure       = xray_structure,
      unit_cell_volume     = map_coeffs.unit_cell().volume(),
      solvent_fraction     = params.solvent_fraction,
      mean_solvent_density = params.mean_solvent_density)
    f_000 = f_000_obj.f_000
    solvent_fraction = f_000_obj.solvent_fraction
  print("F(0,0,0): %12.6f"%f_000, file=log)
  if(solvent_fraction is not None):
    print("solvent_fraction: %6.4f" % solvent_fraction, file=log)
  result = mem.run(
    f                       = map_coeffs,
    f_000                   = f_000,
    lam                     = params.lam,
    lambda_increment_factor = params.lambda_increment_factor,
    resolution_factor       = params.resolution_factor,
    verbose                 = True,
    start_map               = "min_shifted",
    max_iterations          = params.max_iterations,
    use_modification        = True,
    beta                    = params.beta,
    convergence_at_r_factor = params.convergence_at_r_factor,
    xray_structure          = xray_structure,
    convergence_r_threshold = params.convergence_r_threshold,
    log                     = log)
  ###
  broadcast(m="Output MEM map coefficients", log = log)
  ind = max(0,reff[0].rfind("."))
  ofn = params.output_file_name
  if (ofn is None):
    ofn = reff[0]+"_mem.mtz" if ind==0 else reff[0][:ind]+"_mem.mtz"
  print("  Output file name:", ofn, file=log)
  result.write_mtz_file(file_name = ofn,
    column_root_label=params.column_root_label,
    d_min=params.output_high_resolution)
  broadcast(m="All done", log=log)
  return os.path.abspath(ofn)

class launcher(runtime_utils.target_with_save_result):
  def run(self):
    os.mkdir(self.output_dir)
    os.chdir(self.output_dir)
    return run(args=list(self.args), log=sys.stdout)

def validate_params(params):
  if (params.hkl_file_name is None):
    raise Sorry("Please specify an MTZ file containing map coefficients.")
  elif (params.label is None):
    raise Sorry("No column labels specified.")
  if (params.resolution_factor > 0.5):
    raise Sorry("The grid resolution factor must be a decimal number <= 0.5.")
  return True

def finish_job(result):
  output_files, stats = [], []
  if (result is not None) and (os.path.isfile(result)):
    output_files.append((result, "Maximum entropy map"))
  return output_files, stats

if(__name__ == "__main__"):
  timer = user_plus_sys_time()
  log = sys.stdout
  run(sys.argv[1:], log=log)
  print("Total time: %-8.3f" % timer.elapsed(), file=log)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/model_idealization.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.model_idealization

import sys, os
import datetime
from time import time
from libtbx.utils import Sorry, multi_out, null_out
from libtbx import easy_pickle, group_args
import libtbx.load_env
from scitbx.array_family import flex
from six.moves import cStringIO as StringIO

from cctbx import crystal
from cctbx import xray
from iotbx import reflection_file_utils
from iotbx.phil import process_command_line_with_files
import iotbx.ncs
import iotbx.phil
from cctbx import maptbx, miller

from mmtbx.secondary_structure.build import ss_idealization as ssb
from mmtbx.secondary_structure import manager, sec_str_master_phil
import mmtbx.utils
from mmtbx.building.loop_idealization import loop_idealization
from mmtbx.building.cablam_idealization import cablam_idealization
import mmtbx.building.loop_closure.utils
from mmtbx.refinement.geometry_minimization import minimize_wrapper_for_ramachandran
from mmtbx.refinement.real_space.individual_sites import minimize_wrapper_with_map
import mmtbx.model
import mmtbx.refinement.real_space.fit_residues
import scitbx.math
import mmtbx.idealized_aa_residues.rotamer_manager
from iotbx import extract_xtal_data

from elbow.command_line.ready_set import model_interface as ready_set_model_interface

from phenix.programs import phi_psi_2
import six

turned_on_ss = ssb.ss_idealization_master_phil_str
turned_on_ss = turned_on_ss.replace("enabled = False", "enabled = True")
master_params_str = """
model_file_name = None
  .type = path
  .multiple = True
  .short_caption = Model file
  .style = file_type:pdb bold input_file
  .expert_level = 0
map_file_name = None
  .type = path
  .help = User-provided map that will be used as reference
  .expert_level = 0
hkl_file_name = None
  .type = path
  .help = User-provided X-ray data to generate 2mFo-DFc map that will be used \
    as reference
  .expert_level = 0
data_labels = None
  .type = str
  .short_caption = Data labels
  .help = Labels for experimental data.
r_free_flags_labels = None
  .type = str
  .short_caption = Rfree labels
  .help = Labels for free reflections.
ligands_file_name = None
  .type = path
  .multiple = True
  .help = User-provided ligand restraints
  .expert_level = 0
mask_and_he_map = False
  .type = bool
  .help = Mask and histogram equalization of the input map
trim_alternative_conformations = False
  .type = bool
  .help = Leave only atoms with empty altloc
  .expert_level = 2
additionally_fix_rotamer_outliers = True
  .type = bool
  .help = At the late stage if rotamer is still outlier choose another one \
    with minimal clash with surrounding atoms
  .expert_level = 2
use_ss_restraints = True
  .type = bool
  .help = Use Secondary Structure restraints
  .expert_level = 2
use_starting_model_for_final_gm = False
  .type = bool
  .help = Use supplied model for final geometry minimization. Otherwise just \
    use self.
  .expert_level = 3
output_prefix = None
  .type = str
  .expert_level = 0
output_pkl = False
  .type = bool
  .expert_level = 3
output_model_h = True
  .type = bool
  .expert_level = 2
use_map_for_reference = True
  .type = bool
  .expert_level = 1
run_minimization_first = True
  .type = bool
  .expert_level = 2
run_minimization_last = True
  .type = bool
  .expert_level = 2
use_hydrogens_in_minimization = False
  .type = bool
  .expert_level = 3
reference_map_resolution = 5
  .type = float
  .expert_level = 2
number_of_refinement_cycles = 5
  .type = int
  .expert_level = 1
cycles_to_converge = 2
  .type = int
  .help = Nuber of cycles of geometry optimization without considerable stat \
    change before stopping
  .expert_level=1
ignore_ncs = False
  .type = bool
  .help = Don't use NCS even if it is present in model.
  .expert_level = 2
filter_input_ss = True
  .type = bool
  .help = Filter input annotation
  .expert_level = 3
debug = False
  .type = bool
  .help = Output all intermediate files
  .expert_level = 3
verbose = False
  .type = bool
  .help = More output to log
nonbonded_weight=10000
  .type = float
apply_all_trans = True
  .type = bool

%s
include scope mmtbx.geometry_restraints.ramachandran.old_master_phil
include scope mmtbx.secondary_structure.sec_str_master_phil_str
include scope mmtbx.building.loop_idealization.loop_idealization_master_phil_str
include scope mmtbx.building.cablam_idealization.master_phil_str
""" % turned_on_ss

def master_params():
  return iotbx.phil.parse(master_params_str, process_includes=True)

def format_usage_message(log):
  print("-"*79, file=log)
  msg = """\
phenix.model_idealization: Idealize model geometry.

Usage examples:
 phenix.model_idealization model.pdb
"""
  print(msg, file=log)
  print("-"*79, file=log)
  print(master_params().show(), file=log)

class model_idealization():
  def __init__(self,
               model, # shifted, with shift_manager
               map_data = None, # shifted map_data
               params=None,
               log=sys.stdout,
               verbose=True):
    t_0 = time()
    self.model = model
    # self.cif_objects = cif_objects
    self.params = params
    self.log = log
    self.verbose = verbose

    # self.shift_manager = self.model.get_shift_manager()

    self.rmsd_from_start = None
    self.init_model_statistics = None
    self.init_gm_model_statistics = None
    self.after_ss_idealization = None
    self.after_loop_idealization = None
    self.after_rotamer_fixing = None
    self.final_model_statistics = None
    self.user_supplied_map = map_data
    self.reference_map = None # Whole map for all NCS copies
    self.master_map = None # Map for only one NCS copy, or == reference_map if no NCS
    self.init_ref_map = None # separate map for initial GM. Should be tighter than the 2 above

    params = mmtbx.model.manager.get_default_pdb_interpretation_params()
    params.pdb_interpretation.clash_guard.nonbonded_distance_threshold=None

    params.pdb_interpretation.peptide_link.ramachandran_restraints = True
    params.pdb_interpretation.peptide_link.restrain_rama_outliers = self.params.restrain_rama_outliers
    params.pdb_interpretation.peptide_link.restrain_rama_allowed = self.params.restrain_rama_allowed
    params.pdb_interpretation.peptide_link.restrain_allowed_outliers_with_emsley = self.params.restrain_allowed_outliers_with_emsley
    params.pdb_interpretation.peptide_link.rama_weight = self.params.rama_weight
    params.pdb_interpretation.peptide_link.oldfield.weight_scale=self.params.oldfield.weight_scale
    params.pdb_interpretation.peptide_link.oldfield.plot_cutoff=self.params.oldfield.plot_cutoff

    params.pdb_interpretation.peptide_link.apply_peptide_plane = True
    if self.params.loop_idealization.make_all_trans:
      params.pdb_interpretation.peptide_link.apply_all_trans = self.params.apply_all_trans
    params.pdb_interpretation.nonbonded_weight = self.params.nonbonded_weight
    params.pdb_interpretation.c_beta_restraints=True
    params.pdb_interpretation.max_reasonable_bond_distance = None
    params.pdb_interpretation.ncs_search.enabled = True
    params.pdb_interpretation.ncs_search.chain_max_rmsd=4.0
    params.pdb_interpretation.ncs_search.chain_similarity_threshold=0.99
    params.pdb_interpretation.ncs_search.residue_match_radius=999.0
    params.pdb_interpretation.restraints_library.rdl = True
    params.pdb_interpretation.secondary_structure = self.params.secondary_structure
    self.params_for_model = params
    self.model.process(
      make_restraints=True, pdb_interpretation_params=params)


    self.original_hierarchy = self.model.get_hierarchy().deep_copy() # original pdb_h, without any processing
    self.original_boxed_hierarchy = None # original and boxed (if needed)

    self.filtered_ncs_restr_group_list = []

    self.init_ss_annotation = self.model.get_ss_annotation()

    # various checks, shifts, trims
    self.cs = self.original_cs = self.model.crystal_symmetry()

    # check self.cs (copy-paste from secondary_sturcure_restraints)
    corrupted_cs = False
    if self.cs is not None:
      if [self.cs.unit_cell(), self.cs.space_group()].count(None) > 0:
        corrupted_cs = True
        self.cs = None
      elif self.cs.unit_cell().volume() < 10:
        corrupted_cs = True
        self.cs = None
    # couple checks if pdb_h is ok
    o_c = self.original_hierarchy.overall_counts()
    o_c.raise_duplicate_atom_labels_if_necessary()
    # o_c.raise_residue_groups_with_multiple_resnames_using_same_altloc_if_necessary()
    o_c.raise_chains_with_mix_of_proper_and_improper_alt_conf_if_necessary()
    o_c.raise_improper_alt_conf_if_necessary()
    if len(self.original_hierarchy.models()) > 1:
      raise Sorry("Multi model files are not supported")
    ca_only_present = False
    for c in self.original_hierarchy.only_model().chains():
      if c.is_ca_only():
        ca_only_present = True
    if ca_only_present:
      raise Sorry("Don't support models with chains containing only CA atoms.")

    self.original_boxed_hierarchy = self.model.get_hierarchy().deep_copy()
    self.shift_vector = None
    if self.cs is None:
      assert self.model.get_shift_manager() is None
      # should it happen here?
      if corrupted_cs:
        print("Symmetry information is corrupted, ", file=self.log)
      else:
        print("Symmetry information was not found, ", file=self.log)
      print("putting molecule in P1 box.", file=self.log)
      self.log.flush()
      from cctbx import uctbx
      box = uctbx.non_crystallographic_unit_cell_with_the_sites_in_its_center(
        sites_cart=self.model.get_sites_cart(),
        buffer_layer=3)
      # Creating new xrs from box, inspired by extract_box_around_model_and_map
      sp = crystal.special_position_settings(box.crystal_symmetry())
      sites_frac = box.sites_frac()
      xrs_box = self.model.get_xray_structure().replace_sites_frac(box.sites_frac())
      xray_structure_box = xray.structure(sp, xrs_box.scatterers())
      self.model.set_xray_structure(xray_structure_box)
      self.cs = box.crystal_symmetry()
      self.shift_vector = box.shift_vector

    if self.shift_vector is not None and self.params.debug:
      self.model.pdb_or_mmcif_string_info(
        target_filename="%s_boxed.pdb" % self.params.output_prefix,
        write_file=True)

    if self.params.trim_alternative_conformations:
      self.model.remove_alternative_conformations(always_keep_one_conformer=True)

    self.model = self.model.remove_hydrogens()
    self.model_h = None

    self.time_for_init = time()-t_0

  def get_statistics(self, model):
    # should we shift here? No
    # should we multiply NCS here? No
    geometry = model.geometry_statistics().result()
    motifs = phi_psi_2.results_manager(model=model, log=null_out()).get_motif_count()
    mcounts = motifs.get_counts()
    res = {}
    # TODO is mcounts a dict ? If not consider changing back
    for key, value in six.iteritems(mcounts):
      res[key] = value.percent
    geometry.merge(group_args(**res))
    return geometry

  def prepare_user_map(self):
    print("Preparing user map...", file=self.log)
    self.map_shift_manager = mmtbx.utils.shift_origin(
      map_data         = self.user_supplied_map,
      xray_structure   = self.model.get_xray_structure(),
      crystal_symmetry = self.cs)
    if(self.map_shift_manager.shift_cart is not None):
      # Need to figure out way to save the shift to shift back
      # and apply it to whole_pdb, master_pdb, etc. Don't forget about
      # boxing hierarchy when symmetry is not available or corrupted...
      raise Sorry("Map origin is not at (0,0,0). This is not implemented for model_idealization")
    map_data = self.map_shift_manager.map_data
    self.reference_map = map_data
    self.master_map = self.reference_map.deep_copy()
    if self.model.ncs_constraints_present():
      mask = maptbx.mask(
              xray_structure=self.model.get_xray_structure().select(self.model.get_master_selection()),
              n_real=self.master_map.focus(),
              mask_value_inside_molecule=1,
              mask_value_outside_molecule=-1,
              solvent_radius=0,
              atom_radius=1.)
      self.master_map = self.reference_map * mask
      if self.params.debug:
        iotbx.mrcfile.write_ccp4_map(
            file_name="%s_3_master.map" % self.params.output_prefix,
            unit_cell=self.cs.unit_cell(),
            space_group=self.cs.space_group(),
            map_data=self.master_map,
            labels=flex.std_string([""]))
        iotbx.mrcfile.write_ccp4_map(
            file_name="%s_reference.map" % self.params.output_prefix,
            unit_cell=self.cs.unit_cell(),
            space_group=self.cs.space_group(),
            map_data=self.reference_map,
            labels=flex.std_string([""]))
      self.master_map = map_data

  def prepare_init_reference_map(self):
    xrs = self.model.get_xray_structure().deep_copy_scatterers()
    pdb_h = self.model.get_hierarchy().deep_copy()
    if self.user_supplied_map is not None:
      print("Using user-supplied map for initial GM.", file=self.log)
      self.init_ref_map = self.reference_map
      return
    print("Preparing map for initial GM...", file=self.log)
    asc = self.model.get_atom_selection_cache()
    outlier_selection_txt = mmtbx.building.loop_closure.utils. \
          rama_score_selection(pdb_h, self.model.get_ramachandran_manager(), "outlier",1)
    rama_out_sel = asc.selection(outlier_selection_txt)

    allowed_selection_txt = mmtbx.building.loop_closure.utils. \
          rama_score_selection(pdb_h, self.model.get_ramachandran_manager(), "allowed",0)
    rama_allowed_sel = asc.selection(allowed_selection_txt)


    side_chain_no_cb_selection = ~ self.model.sel_backbone()
    sc_rama_out = rama_out_sel & side_chain_no_cb_selection
    sc_rama_allowed =rama_allowed_sel & side_chain_no_cb_selection
    xrs=xrs.set_b_iso(value=10)
    xrs = xrs.set_b_iso(value=20, selection=side_chain_no_cb_selection)
    xrs = xrs.set_b_iso(value=25, selection=rama_allowed_sel)
    xrs = xrs.set_b_iso(value=50, selection=rama_out_sel)
    xrs = xrs.set_b_iso(value=40, selection=sc_rama_allowed)
    xrs = xrs.set_b_iso(value=70, selection=rama_out_sel)

    crystal_gridding = maptbx.crystal_gridding(
        unit_cell        = xrs.unit_cell(),
        space_group_info = xrs.space_group_info(),
        symmetry_flags   = maptbx.use_space_group_symmetry,
        d_min             = self.params.reference_map_resolution)
    fc = xrs.structure_factors(d_min = 2, algorithm = "fft").f_calc()
    fft_map = miller.fft_map(
        crystal_gridding=crystal_gridding,
        fourier_coefficients=fc)
    fft_map.apply_sigma_scaling()
    init_reference_map = fft_map.real_map_unpadded(in_place=False)
    if self.params.debug:
      fft_map.as_xplor_map(file_name="%s_init.map" % self.params.output_prefix)
    self.init_ref_map = init_reference_map

  def prepare_reference_map_3(self):
    """ with ramachandran outliers """
    xrs = self.model.get_xray_structure().deep_copy_scatterers()
    pdb_h = self.model.get_hierarchy()
    print("Preparing reference map, method 3", file=self.log)
    outlier_selection_txt = mmtbx.building.loop_closure.utils. \
          rama_score_selection(pdb_h, self.model.get_ramachandran_manager(), "outlier",1)
    asc = self.model.get_atom_selection_cache()
    # print >> self.log, "rama outlier selection:", outlier_selection_txt
    rama_out_sel = asc.selection(outlier_selection_txt)
    xrs=xrs.set_b_iso(value=50)

    side_chain_no_cb_selection = ~ self.model.sel_backbone()
    xrs = xrs.set_b_iso(value=200, selection=side_chain_no_cb_selection)
    xrs = xrs.set_b_iso(value=150, selection=rama_out_sel)
    # xrs = xrs.set_occupancies(value=0.3, selection=rama_out_sel)

    crystal_gridding = maptbx.crystal_gridding(
        unit_cell        = xrs.unit_cell(),
        space_group_info = xrs.space_group_info(),
        symmetry_flags   = maptbx.use_space_group_symmetry,
        d_min             = self.params.reference_map_resolution)
    fc = xrs.structure_factors(
        d_min = self.params.reference_map_resolution,
        algorithm = "direct").f_calc()
    fft_map = miller.fft_map(
        crystal_gridding=crystal_gridding,
        fourier_coefficients=fc)
    fft_map.apply_sigma_scaling()
    self.reference_map = fft_map.real_map_unpadded(in_place=False)
    if self.params.debug:
      fft_map.as_xplor_map(file_name="%s_3.map" % self.params.output_prefix)
    self.master_map = self.reference_map.deep_copy()
    if self.model.ncs_constraints_present():
      # here we are negating non-master part of the model
      # self.master_sel=master_sel
      # self.master_map = self.reference_map.deep_copy()
      mask = maptbx.mask(
              xray_structure=xrs.select(self.model.get_master_selection()),
              n_real=self.master_map.focus(),
              mask_value_inside_molecule=1,
              mask_value_outside_molecule=-1,
              solvent_radius=0,
              atom_radius=1.)
      self.master_map = self.reference_map * mask
      if self.params.debug:
        iotbx.mrcfile.write_ccp4_map(
            file_name="%s_3_master.map" % self.params.output_prefix,
            unit_cell=xrs.unit_cell(),
            space_group=xrs.space_group(),
            map_data=self.master_map,
            labels=flex.std_string([""]))

  def update_ss_in_grm(self, ss_annotation):
    self.set_ss_restraints(ss_annotation)

  def set_ss_restraints(self, ss_annotation, params=None):
    log = self.log
    if not self.verbose:
      log = null_out()
    if self.params.use_ss_restraints and ss_annotation is not None:
      ss_manager = manager(
          pdb_hierarchy=self.model.get_hierarchy(),
          geometry_restraints_manager=self.model.get_restraints_manager().geometry,
          sec_str_from_pdb_file=ss_annotation,
          params=None,
          mon_lib_srv=self.model.get_mon_lib_srv(),
          verbose=-1,
          log=log)
      self.model.get_restraints_manager().geometry.set_secondary_structure_restraints(
          ss_manager=ss_manager,
          hierarchy=self.model.get_hierarchy(),
          log=log)

  def _setup_model_h(self):
    if self.model_h is not None:
      return
    if not self.model.has_hd():
      # runs reduce internally
      assert (libtbx.env.has_module(name="reduce"))
      assert (libtbx.env.has_module(name="elbow"))
      self.model_h = ready_set_model_interface(
          model=self.model,
          params=["add_h_to_water=False",
                  "optimise_final_geometry_of_hydrogens=False"],
          )
    else:
      self.model_h = self.model.deep_copy()
    params_h = mmtbx.model.manager.get_default_pdb_interpretation_params()
    params_h.pdb_interpretation = self.model.get_current_pdb_interpretation_params().pdb_interpretation
    # customization for model with H
    params_h.pdb_interpretation.clash_guard.nonbonded_distance_threshold=None
    params_h.pdb_interpretation.max_reasonable_bond_distance = None
    params_h.pdb_interpretation.use_neutron_distances=True
    params_h.pdb_interpretation.ncs_search = self.params_for_model.pdb_interpretation.ncs_search
    params_h.pdb_interpretation.ncs_search.exclude_selection="water"
    #self.model_h.set_pdb_interpretation_params(params_h)
    self.model_h.get_restraints_manager()
    self.model_h.idealize_h_riding()
    self.model_h.setup_ncs_constraints_groups(filter_groups=True)
    self.model_h._update_master_sel()
    if self.params.debug:
      self.shift_and_write_result(
        model = self.model_h,
        fname_suffix="model_h")

  def _update_model_h(self):
    if self.model_h is None:
      self._setup_model_h()
    # transfer coords model -> model_h
    sc = self.model_h.get_sites_cart()
    sc.set_selected(~self.model_h.get_hd_selection(), self.model.get_sites_cart())
    self.model_h.set_sites_cart(sc)
    self.model_h.idealize_h_riding()

  def _update_model_from_model_h(self):
    self.model.set_sites_cart(
      sites_cart = self.model_h.get_hierarchy().select(~self.model_h.get_hd_selection()).atoms().extract_xyz())
    self.model.set_sites_cart_from_hierarchy(multiply_ncs=True)

  def idealize_rotamers(self):
    print("Fixing rotamers...", file=self.log)
    self.log.flush()
    if self.params.debug:
      self.shift_and_write_result(
        model = self.model,
        fname_suffix="just_before_rota")

    self._update_model_h()
    rotman = mmtbx.idealized_aa_residues.rotamer_manager.load(
          rotamers="favored")
    self.model_h.process(make_restraints=True)
    o = mmtbx.refinement.real_space.side_chain_fit_evaluator(
      pdb_hierarchy      = self.model_h.get_hierarchy(),
      crystal_symmetry   = self.model.crystal_symmetry(),
      rotamer_evaluator  = rotman.rotamer_evaluator,
      map_data           = self.master_map)
    result = mmtbx.refinement.real_space.fit_residues.run(
        vdw_radii         = self.model_h.get_vdw_radii(),
        bselection        = o.sel_all(),
        pdb_hierarchy     = self.model_h.get_hierarchy(),
        crystal_symmetry  = self.model.crystal_symmetry(),
        map_data          = self.master_map,
        rotamer_manager   = rotman,
        rotatable_hd      = self.model_h.rotatable_hd_selection(iselection=False),
        sin_cos_table     = scitbx.math.sin_cos_table(n=10000),
        backbone_sample   = False,
        mon_lib_srv       = self.model_h.get_mon_lib_srv(),
        log               = self.log)
    self.model_h.set_sites_cart_from_hierarchy()
    self._update_model_from_model_h()
    if self.params.debug:
      self.shift_and_write_result(
          model = self.model,
          fname_suffix="rota_ideal")

  def run(self):
    t_0 = time()
    self.ann = self.model.get_ss_annotation()
    self._setup_model_h()
    self.model.set_restraint_objects(self.model_h.get_restraint_objects())

    self.model.process(make_restraints=True)
    # set SS restratins
    self.set_ss_restraints(self.ann)

    self.model.setup_ncs_constraints_groups()

    self.init_model_statistics = self.get_statistics(self.model)

    #
    # Cablam idealization
    #
    if self.params.debug:
      self.shift_and_write_result(
          model = self.model,
          fname_suffix="start")
      self.shift_and_write_result(
          model = self.model_h,
          fname_suffix="start_h")
    self.params.cablam_idealization.find_ss_after_fixes = False
    ci_results = cablam_idealization(
        model=self.model,
        params=self.params.cablam_idealization,
        log=self.log).get_results()
    self.model = ci_results.model
    self.after_cablam_statistics = self.get_statistics(self.model)
    if self.params.debug:
      self.shift_and_write_result(
          model = self.model,
          fname_suffix="cablam_id")


    # Here we are preparing maps if needed.
    if self.user_supplied_map is not None:
      self.prepare_user_map()

    if self.reference_map is None and self.params.use_map_for_reference:
      self.prepare_reference_map_3()

    if self.params.run_minimization_first:
      # running simple minimization and updating all
      # self.master, self.working, etc...
      # self.whole_pdb_h.reset_atom_i_seqs()
      if self.init_ref_map is None:
        self.prepare_init_reference_map()
      print("Minimization first", file=self.log)
      self.minimize(
          model=self.model,
          original_pdb_h=self.original_hierarchy,
          excl_string_selection=None, # don't need if we have map
          reference_map=self.init_ref_map,
          )
      self.init_gm_model_statistics = self.get_statistics(self.model)
      if self.params.debug:
        self.shift_and_write_result(
            model = self.model,
            fname_suffix="init_gm")

    if (self.init_gm_model_statistics is not None
        and self.init_gm_model_statistics.ramachandran.outliers == 0
        and self.init_gm_model_statistics.omega.twisted_general <= 0.01
        and self.init_gm_model_statistics.omega.twisted_proline <= 0.01
        and self.init_gm_model_statistics.omega.cis_general <= 0.01
        and self.init_gm_model_statistics.omega.cis_proline <= 0.01
        and self.init_gm_model_statistics.rotamer.outliers <= 0.01):
      print("Simple minimization was enough", file=self.log)
      # Early exit!!!
      self.shift_and_write_result(
          model=self.model,
          fname_suffix="all_idealized")
      if self.params.output_model_h:
        self.shift_and_write_result(
            model=self.model_h,
            fname_suffix="all_idealized_h")

      self.final_model_statistics = self.get_statistics(self.model)
      self.time_for_run = time() - t_0
      if self.params.output_pkl:
        easy_pickle.dump(
            file_name="%s.pkl" % self.params.output_prefix,
            obj = self.get_stats_obj())
      return

    self.filtered_whole_ann = None
    if self.ann is not None:
      self.filtered_whole_ann = self.ann.deep_copy()
      print("Original SS annotation", file=self.log)
      print(self.ann.as_pdb_str(), file=self.log)
      if self.params.filter_input_ss:
        self.filtered_whole_ann = self.ann.filter_annotation(
            hierarchy=self.model.get_hierarchy(),
            asc=self.model.get_atom_selection_cache())
      print("Filtered SS annotation", file=self.log)
      print(self.filtered_whole_ann.as_pdb_str(), file=self.log)
      self.model.set_ss_annotation(self.filtered_whole_ann)

    # getting grm with SS restraints
    self.update_ss_in_grm(self.filtered_whole_ann)

    if (self.ann is None or
        self.ann.get_n_helices() + self.ann.get_n_sheets() == 0 or
        not self.params.ss_idealization.enabled):
      print("No secondary structure annotations found or SS idealization is disabled.", file=self.log)
      print("Secondary structure substitution step will be skipped", file=self.log)
      self.log.flush()
      # here we want to do geometry minimization anyway!
      negate_selection = None
      if self.reference_map is None:
        outlier_selection_txt = mmtbx.building.loop_closure.utils. \
          rama_score_selection(self.model.get_hierarchy(), self.model.get_ramachandran_manager(), "outlier",1)
        print("outlier_selection_txt", outlier_selection_txt, file=self.log)
        negate_selection = "all"
        if outlier_selection_txt != "" and outlier_selection_txt is not None:
          negate_selection = "not (%s)" % outlier_selection_txt
      # if self.params.run_minimization_first:
      # self.minimize(
      #     model=self.model,
      #     original_pdb_h=self.whole_pdb_h,
      #     ncs_restraints_group_list=self.filtered_ncs_restr_group_list,
      #     excl_string_selection=negate_selection,
      #     reference_map=self.reference_map)
    else:
      if self.params.debug:
        self.params.ss_idealization.file_name_before_regularization = \
            "%s_ss_before_reg.pdb" % self.params.output_prefix # PDB OK
      self.params.ss_idealization.skip_good_ss_elements = True
      ssb.substitute_ss(
          model = self.model,
          params=self.params.ss_idealization,
          reference_map=self.master_map,
          log=self.log)
      self.log.flush()

    self.after_ss_idealization = self.get_statistics(self.model)
    self.shift_and_write_result(
          model=self.model,
          fname_suffix="ss_ideal_stat")

    # Write resulting pdb file.
    if self.params.debug:
      self.shift_and_write_result(
          model=self.model,
          fname_suffix="ss_ideal",
          )
    # self.params.loop_idealization.minimize_whole = not self.model.ncs_constraints_present() and self.params.loop_idealization.minimize_whole
    self.params.loop_idealization.debug = self.params.debug or self.params.loop_idealization.debug
    # self.params.loop_idealization.enabled = False
    # self.params.loop_idealization.variant_search_level = 0
    print("Starting loop idealization", file=self.log)
    loop_ideal = loop_idealization(
        self.model,
        params=self.params.loop_idealization,
        reference_map=self.master_map,
        log=self.log,
        verbose=True)
    self.log.flush()
    if self.params.debug:
      self.shift_and_write_result(
          model = self.model,
          fname_suffix="rama_ideal")
    self.after_loop_idealization = self.get_statistics(self.model)

    # fixing remaining rotamer outliers
    if (self.params.additionally_fix_rotamer_outliers and
        self.after_loop_idealization.rotamer.outliers > 0.004):
      self.idealize_rotamers()



    self.after_rotamer_fixing = self.get_statistics(self.model)
    ref_hierarchy_for_final_gm = self.original_boxed_hierarchy
    if not self.params.use_starting_model_for_final_gm:
      ref_hierarchy_for_final_gm = self.model.get_hierarchy().deep_copy()
    ref_hierarchy_for_final_gm.reset_atom_i_seqs()

    if self.model.ncs_constraints_present():
      print("Using ncs", file=self.log)
      # assert 0
    else:
      print("Not using ncs", file=self.log)
      # assert 0

    # need to update SS manager for the whole model here.
    if self.params.use_ss_restraints:
      ss_params = sec_str_master_phil.fetch().extract()
      ss_params.secondary_structure.protein.remove_outliers = not self.params.ss_idealization.enabled
      self.set_ss_restraints(
          ss_annotation=self.filtered_whole_ann,
          params=ss_params.secondary_structure)
    if self.params.run_minimization_last:
      print("loop_ideal.ref_exclusion_selection", loop_ideal.ref_exclusion_selection, file=self.log)
      print("Minimizing whole model", file=self.log)
      self.minimize(
          model = self.model,
          original_pdb_h=ref_hierarchy_for_final_gm,
          excl_string_selection=loop_ideal.ref_exclusion_selection,
          reference_map = self.reference_map)
    self.shift_and_write_result(
        model = self.model,
        fname_suffix="all_idealized")
    if self.params.output_model_h:
      self.shift_and_write_result(
          model=self.model_h,
          fname_suffix="all_idealized_h")

    self.final_model_statistics = self.get_statistics(self.model)
    self.time_for_run = time() - t_0
    if self.params.output_pkl or self.params.debug:
      easy_pickle.dump(
          file_name="%s.pkl" % self.params.output_prefix, # PDB OK
          obj = self.get_stats_obj())

  def minimize(self,
      model,
      original_pdb_h,
      excl_string_selection,
      reference_map):
    # print "ncs_restraints_group_list", ncs_restraints_group_list
    # assert 0
    if reference_map is None:
      minimize_wrapper_for_ramachandran(
          model=model,
          original_pdb_h=original_pdb_h,
          excl_string_selection=excl_string_selection,
          number_of_cycles=self.params.number_of_refinement_cycles,
          log=self.log,
          )
      self._update_model_h()
    else:
      print("Using map as reference", file=self.log)
      self.log.flush()
      if self.params.use_hydrogens_in_minimization:
        self._update_model_h()
        mwwm = minimize_wrapper_with_map(
            model=self.model_h,
            target_map=reference_map,
            number_of_cycles=self.params.number_of_refinement_cycles,
            cycles_to_converge=self.params.cycles_to_converge,
            log=self.log)
        self._update_model_from_model_h()
      else:
        mwwm = minimize_wrapper_with_map(
            model=model,
            target_map=reference_map,
            number_of_cycles=self.params.number_of_refinement_cycles,
            cycles_to_converge=self.params.cycles_to_converge,
            log=self.log)
        self._update_model_h()

  def shift_and_write_result(self, model, fname_suffix=""):
    model.pdb_or_mmcif_string_info(
      target_filename="%s_%s.pdb" % (self.params.output_prefix, fname_suffix),
      write_file=True)
    if self.params.debug:
      model.pdb_or_mmcif_string_info(
        target_filename="%s_%s_nosh.pdb" % (self.params.output_prefix, fname_suffix),
        write_file=True,
        do_not_shift_back=True)

  def get_rmsd_from_start(self):
    if self.rmsd_from_start is not None:
      return self.rmsd_from_start
    # calculate rmsd
    self.rmsd_from_start = ssb.calculate_rmsd_smart(
        self.original_boxed_hierarchy,
        self.model.get_hierarchy(),
        backbone_only=True)
    return self.rmsd_from_start

  def get_rmsd_from_start2(self):
    return ssb.calculate_rmsd_smart(
        self.original_boxed_hierarchy,
        self.model.get_hierarchy(),
        backbone_only=False)

  def get_stats_obj(self):
    if self.params.run_minimization_first:
      stat_obj_list = [self.init_model_statistics,
          self.init_gm_model_statistics,
          self.after_ss_idealization,
          self.after_loop_idealization,
          self.after_rotamer_fixing,
          self.final_model_statistics,]
    else:
      stat_obj_list = [self.init_model_statistics,
          self.after_ss_idealization,
          self.after_loop_idealization,
          self.after_rotamer_fixing,
          self.final_model_statistics,]
    if self.after_cablam_statistics is not None:
      stat_obj_list.insert(1, self.after_cablam_statistics)
    return group_args(
        geoms=stat_obj_list,
        rmsds=(self.get_rmsd_from_start(), self.get_rmsd_from_start2()),
        runtime=self.time_for_init + self.time_for_run)

  def print_stat_comparison(self):
    stat_obj_list = self.get_stats_obj()
    if self.after_cablam_statistics is None:
      if self.params.run_minimization_first:
        print("                        Starting    Init GM   SS ideal    Rama      Rota     Final", file=self.log)
      else:
        print("                        Starting    SS ideal    Rama      Rota     Final", file=self.log)
    else:
      if self.params.run_minimization_first:
        print("                        Starting     Cablam   Init GM   SS ideal    Rama      Rota     Final", file=self.log)
      else:
        print("                        Starting     Cablam   SS ideal    Rama      Rota     Final", file=self.log)
    #                         Starting    SS ideal    Rama      Rota     Final
    # Molprobity Score     :      4.50      3.27      2.66      2.32      2.54
    for val_caption, val_name, val_subname, val_format in [
        ("Molprobity Score", "molprobity_score", "", "{:10.2f}"),
        ("Clashscore", "clash", "score", "{:10.2f}"),
        ("CBeta deviations", "c_beta", "outliers", "{:10.2f}"),
        ("Ramachandran outliers", "ramachandran", "outliers", "{:10.2f}"),
        ("Ramachandran allowed", "ramachandran", "allowed", "{:10.2f}"),
        ("Rotamer outliers", "rotamer", "outliers", "{:10.2f}"),
        ("Cis-prolines", "omega", "cis_proline", "{:10.2f}"),
        ("Cis-general", "omega", "cis_general", "{:10.2f}"),
        ("Twisted prolines", "omega", "twisted_proline", "{:10.2f}"),
        ("Twisted general", "omega", "twisted_general", "{:10.2f}"),
        ("CaBLAM outliers", "cablam", "outliers", "{:10.2f}"),
        ("CaBLAM disfavored", "cablam", "disfavored", "{:10.2f}"),
        ("CaBLAM CA outliers", "cablam", "ca_outliers", "{:10.2f}"),
        ("phi-psy2: Motif(10)", "MOTIF", "", "{:10.2f}"),
        ("phi-psy2: Motif(20)", "MOTIF20", "", "{:10.2f}"),
        ("phi-psy2: Motif(->)", "MOTIF...", "", "{:10.2f}"),
        ("phi-psy2: General", "GENERAL", "", "{:10.2f}"),
        ("phi-psy2: Outlier", "OUTLIER", "", "{:10.2f}"),
        ]:
      l = "%-21s:" % val_caption
      for stat_obj in stat_obj_list.geoms:
        value = 99999
        if stat_obj is not None:
          sub_class = getattr(stat_obj, val_name, None)
          if sub_class is not None:
            if val_subname != "":
              value = getattr(sub_class, val_subname, None)
            else:
              value = sub_class
          l += val_format.format(value)
        else:
          l += val_format.format(0)
      print(l, file=self.log)

  def print_runtime(self):
    print("Time taken for idealization: %s" % str(
        datetime.timedelta(seconds=int(self.time_for_init + self.time_for_run))), file=self.log)

def get_map_from_hkl(hkl_file_object, params, xrs, log):
  print("Processing input hkl file...", file=log)
  crystal_symmetry = hkl_file_object.crystal_symmetry()
  rfs = reflection_file_utils.reflection_file_server(
    crystal_symmetry = crystal_symmetry,
    force_symmetry   = True,
    reflection_files = [hkl_file_object.file_content],
    err              = StringIO())


  parameters = extract_xtal_data.data_and_flags_master_params().extract()
  if (params.data_labels is not None):
    parameters.labels = params.data_labels
  if (params.r_free_flags_labels is not None):
    parameters.r_free_flags.label = params.r_free_flags_labels
  determined_data_and_flags = extract_xtal_data.run(
    reflection_file_server = rfs,
    parameters             = parameters,
    keep_going             = True,
    working_point_group = crystal_symmetry.space_group().build_derived_point_group())
  f_obs = determined_data_and_flags.f_obs

  if (params.data_labels is None):
    params.data_labels = f_obs.info().label_string()
  r_free_flags = determined_data_and_flags.r_free_flags
  assert f_obs is not None
  print("Input data:", file=log)
  print("  Iobs or Fobs:", f_obs.info().labels, file=log)
  if (r_free_flags is not None):
    print("  Free-R flags:", r_free_flags.info().labels, file=log)
    params.r_free_flags_labels = r_free_flags.info().label_string()
  else:
    print("  Free-R flags: Not present", file=log)

  fmodel = mmtbx.f_model.manager(
      f_obs        = f_obs,
      r_free_flags = r_free_flags,
      xray_structure = xrs)
  fmodel.update_all_scales()

  fft_map = fmodel.electron_density_map().fft_map(
    resolution_factor = 0.25,
    map_type          = "2mFo-DFc",
    use_all_data      = False) # Exclude free reflections
  fft_map.apply_sigma_scaling()
  map_data = fft_map.real_map_unpadded(in_place=False)
  if params.debug:
    fft_map.as_xplor_map(file_name="%s_21.map" % params.output_prefix)
    iotbx.mrcfile.write_ccp4_map(
        file_name="%s_21.ccp4" % params.output_prefix,
        unit_cell=crystal_symmetry.unit_cell(),
        space_group=crystal_symmetry.space_group(),
        map_data=map_data,
        labels=flex.std_string([""]))
  return map_data, crystal_symmetry

def get_map_from_map(map_file_object, params, xrs, log):
  print("Processing input CCP4 map file...", file=log)
  map_data = map_file_object.file_content.map_data()
  try:
    # map_cs = map_content.file_object.crystal_symmetry()
    map_cs = map_file_object.crystal_symmetry()
  except NotImplementedError as e:
    pass
  print("Input map min,max,mean: %7.3f %7.3f %7.3f"%\
      map_data.as_1d().min_max_mean().as_tuple(), file=log)
  if map_cs.space_group().type().number() not in [0,1]:
    print(map_cs.space_group().type().number())
    raise Sorry("Only P1 group for maps is supported.")
  map_data = map_data - flex.mean(map_data)
  sd = map_data.sample_standard_deviation()
  map_data = map_data/sd
  print("Rescaled map min,max,mean: %7.3f %7.3f %7.3f"%\
    map_data.as_1d().min_max_mean().as_tuple(), file=log)
  map_file_object.file_content.show_summary(prefix="  ")
  shift_manager = mmtbx.utils.extract_box_around_model_and_map(
      xray_structure = xrs,
      map_data       = map_data.deep_copy(),
      box_cushion    = 5)
  sys.stdout.flush()
  xray_structure = shift_manager.xray_structure_box
  crystal_symmetry = xray_structure.crystal_symmetry()
  map_data = shift_manager.map_box

  if params.mask_and_he_map:
    print("Masking and histogram equalizing...", file=log)
    import boost_adaptbx.boost.python as bp
    cctbx_maptbx_ext = bp.import_ext("cctbx_maptbx_ext")
    xrs_p1 = xray_structure.expand_to_p1(sites_mod_positive=True)
    radii = flex.double(xrs_p1.scatterers().size(), 5.0)
    mask = cctbx_maptbx_ext.mask(
      sites_frac                  = xrs_p1.sites_frac(),
      unit_cell                   = xrs_p1.unit_cell(),
      n_real                      = map_data.all(),
      mask_value_inside_molecule  = 1,
      mask_value_outside_molecule = 0,
      radii                       = radii)
    map_data = mask*map_data
    from phenix.command_line.real_space_refine import write_ccp4_map
    write_ccp4_map(o=xray_structure.crystal_symmetry(), file_name="junk_mask.map",
     map_data=mask)
    del mask
    map_data = maptbx.volume_scale(map = map_data, n_bins = 10000).map_data()
    write_ccp4_map(o=xray_structure.crystal_symmetry(), file_name="junk_map.map",
     map_data=map_data)
  return map_data, map_cs, shift_manager

def run(args):
  # processing command-line stuff, out of the object
  log = multi_out()
  log.register("stdout", sys.stdout)
  if len(args) == 0:
    format_usage_message(log)
    return
  input_objects = process_command_line_with_files(
      args=args,
      master_phil=master_params(),
      pdb_file_def="model_file_name",
      map_file_def="map_file_name",
      reflection_file_def="hkl_file_name",
      cif_file_def="ligands_file_name")
  work_params = input_objects.work.extract()
  if [work_params.map_file_name, work_params.hkl_file_name].count(None) < 1:
    raise Sorry("Only one source of map could be supplied.")
  input_objects.work.show(prefix=" ", out=log)
  if len(work_params.model_file_name) == 0:
    raise Sorry("No PDB file specified")
  if work_params.output_prefix is None:
    work_params.output_prefix = os.path.basename(work_params.model_file_name[0])
  log_file_name = "%s.log" % work_params.output_prefix
  logfile = open(log_file_name, "w")
  log.register("logfile", logfile)
  err_log = multi_out()
  err_log.register(label="log", file_object=log)
  # err_log.register(label="stderr", file_object=sys.stderr)
  sys.stderr = err_log

  if work_params.loop_idealization.output_prefix is None:
    work_params.loop_idealization.output_prefix = "%s_rama_fixed" % work_params.output_prefix

  # Here we start opening files provided,
  # collect crystal symmetries
  pdb_combined = iotbx.pdb.combine_unique_pdb_files(file_names=work_params.model_file_name)
  pdb_input = iotbx.pdb.input(source_info=None,
    lines=flex.std_string(pdb_combined.raw_records))
  pdb_cs = pdb_input.crystal_symmetry()
  crystal_symmetry = None
  map_cs = None
  map_content = input_objects.get_file(work_params.map_file_name)
  if map_content is not None:
    try:
      map_cs = map_content.crystal_symmetry()
    except NotImplementedError as e:
      pass

  try:
    crystal_symmetry = crystal.select_crystal_symmetry(
        from_command_line     = None,
        from_parameter_file   = None,
        from_coordinate_files = [pdb_cs],
        from_reflection_files = [map_cs],
        enforce_similarity    = True)
  except AssertionError as e:
    if len(e.args)>0 and e.args[0].startswith("No unit cell and symmetry information supplied"):
      pass
    else:
      raise e


  model = mmtbx.model.manager(
      model_input = pdb_input,
      restraint_objects = input_objects.cif_objects,
      crystal_symmetry = crystal_symmetry,
      log=log)

  map_data = None
  shift_manager = None

  if map_content is not None:
    map_data, map_cs, shift_manager = get_map_from_map(
        map_content,
        work_params,
        xrs=model.get_xray_structure(),
        log=log)
    model.shift_model_and_set_crystal_symmetry(
      shift_cart=shift_manager.shift_cart)
    # model.get_hierarchy().write_pdb_file("junk_shift.pdb")

  hkl_content = input_objects.get_file(work_params.hkl_file_name) # PDB OK
  if hkl_content is not None:
    map_data, map_cs = get_map_from_hkl(
        hkl_content,
        work_params,
        xrs=model.get_xray_structure(), # here we don't care about atom order
        log=log)

  mi_object = model_idealization(
      model = model,
      map_data = map_data,
      params=work_params,
      log=log,
      verbose=False)
  mi_object.run()
  mi_object.print_stat_comparison()
  print("RMSD from starting model (backbone, all): %.4f, %.4f" % (
      mi_object.get_rmsd_from_start(), mi_object.get_rmsd_from_start2()), file=log)
  mi_object.print_runtime()
  # add hydrogens if needed ?
  print("All done.", file=log)
  log.flush()
  sys.stderr = sys.__stderr__
  log.close()

if __name__ == "__main__":
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/model_map.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.model_map

import sys
import iotbx.pdb
from libtbx.utils import Sorry
from cctbx import maptbx
from mmtbx.maps import fem
import mmtbx.real_space
import mmtbx.utils

legend = """phenix.model_map: Given PDB file calculate model map

How to run:
  phenix.model_map model.pdb
"""

master_params_str = """
grid_step=0.3
  .type=float
output_file_name_prefix = None
  .type=str
scattering_table = *n_gaussian wk1995 it1992 electron neutron
  .type = choice(multi=False)
  .help = Choices of scattering table for structure factors calculations
"""

def master_params():
  return iotbx.phil.parse(master_params_str)

def run(args, log=sys.stdout):
  print("-"*79, file=log)
  print(legend, file=log)
  print("-"*79, file=log)
  inputs = mmtbx.utils.process_command_line_args(args = args,
    master_params = master_params())
  inputs.params.show(prefix="  ", out=log)
  print(file=log)
  file_names = inputs.pdb_file_names
  if(len(file_names) != 1): raise Sorry("A PDB file is expected.")
  pdb_inp = iotbx.pdb.input(file_name = file_names[0])
  awl = list(pdb_inp.atoms_with_labels())
  xrs = pdb_inp.xray_structure_simple().expand_to_p1(sites_mod_positive=True)
  # Check for B=0
  bs = xrs.extract_u_iso_or_u_equiv()
  sel_zero = bs<1.e-3
  n_zeros = sel_zero.count(True)
  if(n_zeros>0):
    print("Atoms with B=0:")
    for i_seq in sel_zero.iselection():
      print(awl[i_seq].format_atom_record())
    raise Sorry("Input model contains %d atoms with B=0"%n_zeros)
  #
  params = inputs.params.extract()
  mmtbx.utils.setup_scattering_dictionaries(
    scattering_table = params.scattering_table,
    xray_structure   = xrs,
    d_min            = 0.5)
  #
  crystal_gridding = maptbx.crystal_gridding(
    unit_cell        = xrs.unit_cell(),
    space_group_info = xrs.space_group_info(),
    symmetry_flags   = maptbx.use_space_group_symmetry,
    step             = params.grid_step)
  m = mmtbx.real_space.sampled_model_density(
    xray_structure = xrs,
    n_real         = crystal_gridding.n_real())
  map_data = m.data()
  #
  prefix = "model_map"
  if(params.output_file_name_prefix is not None):
    prefix = params.output_file_name_prefix
  #
  m.write_as_xplor_map(file_name = "%s.xplor"%prefix)
  fem.ccp4_map(cg=crystal_gridding, file_name="%s.ccp4"%prefix,
    map_data=map_data)

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/model_model_distances.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.model_model_distances

from scitbx.array_family import flex
import sys
import iotbx.pdb
from libtbx.utils import Sorry
import mmtbx.utils
from six.moves import zip

legend = """phenix.model_model_distances:
  Given two PDB files output distances per atom, residue, chain, model and overall.
  It is assumed (and asserted in the code!) that the amount and order of atoms
  in both files are identical.

How to run:
  phenix.model_model_distances model_1.pdb model_2.pdb

Feedback:
  PAfonine@lbl.gov
  phenixbb@phenix-online.org"""

def compute_overall(h1,h2,log):
  x1 = h1.extract_xray_structure()
  x2 = h2.extract_xray_structure()
  d = x1.distances(other=x2)
  d= d.min_max_mean().as_tuple()
  print("Overall  min/max/mean: %8.3f %8.3f %8.3f"%d, file=log)
  print(file=log)

def compute_overall_backbone(h1,h2,log):
  selection_cache1 = h1.atom_selection_cache()
  isel1 = selection_cache1.iselection("name ca or name n or name o or name c")
  selection_cache2 = h2.atom_selection_cache()
  isel2 = selection_cache2.iselection("name ca or name n or name o or name c")
  x1 = h1.select(isel1).extract_xray_structure()
  x2 = h2.select(isel2).extract_xray_structure()
  d = x1.distances(other=x2)
  d= d.min_max_mean().as_tuple()
  print("Backbone min/max/mean: %8.3f %8.3f %8.3f"%d, file=log)
  print(file=log)


def compute_per_model(h1,h2,log):
  if(len(h1.models())==1): return
  print("Per model (min/max/mean):", file=log)
  for m1,m2 in zip(h1.models(), h2.models()):
    r1 = m1.atoms().extract_xyz()
    r2 = m2.atoms().extract_xyz()
    d = flex.sqrt((r1 - r2).dot()).min_max_mean().as_tuple()
    print(m1.id, ": %-8.3f %-8.3f %-8.3f"%d, file=log)
  print(file=log)

def compute_per_chain(h1,h2,log):
  cs1 = list(h1.chains())
  cs2 = list(h2.chains())
  if(len(cs1)==1): return
  print("Per chain (min/max/mean):", file=log)
  for c1, c2 in zip(cs1, cs2):
    label = c1.id
    r1 = c1.atoms().extract_xyz()
    r2 = c2.atoms().extract_xyz()
    d = flex.sqrt((r1 - r2).dot()).min_max_mean().as_tuple()
    print(label, ": %-8.3f %-8.3f %-8.3f"%d, file=log)
  print(file=log)

def compute_per_residue(h1,h2,log):
  rgs1 = list(h1.residue_groups())
  rgs2 = list(h2.residue_groups())
  if(len(rgs1)==1): return
  print("Per residue (min/max/mean):", file=log)
  for rg1, rg2 in zip(rgs1, rgs2):
    label = "%10s"%"/".join([
      rg1.parent().id.strip(),
      rg1.resid().strip(),
      "_".join(list(rg1.unique_resnames()))])
    r1 = rg1.atoms().extract_xyz()
    r2 = rg2.atoms().extract_xyz()
    d = flex.sqrt((r1 - r2).dot()).min_max_mean().as_tuple()
    print(label, ": %-8.3f %-8.3f %-8.3f"%d, file=log)
  print(file=log)

def compute_per_atom(h1,h2,log):
  as1 = list(h1.atoms())
  as2 = list(h2.atoms())
  if(len(as1)==1): return
  print("Per atom:", file=log)
  for a1, a2 in zip(as1, as2):
    r1 = flex.vec3_double([a1.xyz])
    r2 = flex.vec3_double([a2.xyz])
    d = flex.sqrt((r1 - r2).dot())
    print(a1.format_atom_record()[:30], ": %-8.3f"%d[0], file=log)

def run(args, log=sys.stdout):
  print("-"*79, file=log)
  print(legend, file=log)
  print("-"*79, file=log)
  inputs = mmtbx.utils.process_command_line_args(args = args)
  file_names = inputs.pdb_file_names
  if(len(file_names) != 2): raise Sorry("Two PDB files has to given.")
  pi1 = iotbx.pdb.input(file_name = file_names[0])
  pi2 = iotbx.pdb.input(file_name = file_names[1])
  if pi1.crystal_symmetry_from_cryst1() is not None:
    if(not pi1.crystal_symmetry_from_cryst1().is_similar_symmetry(
           pi2.crystal_symmetry_from_cryst1())):
      raise Sorry("CRYST1 records must be identical.")
  h1 = pi1.construct_hierarchy()
  h2 = pi2.construct_hierarchy()
  if(not h1.is_similar_hierarchy(h2)):
    raise Sorry("Input PDB files have different content or atom order.")
  #
  print(file=log)
  compute_overall(    h1=h1, h2=h2, log=log)
  compute_overall_backbone(h1=h1, h2=h2, log=log)
  compute_per_model(  h1=h1, h2=h2, log=log)
  compute_per_chain(  h1=h1, h2=h2, log=log)
  compute_per_residue(h1=h1, h2=h2, log=log)
  compute_per_atom(   h1=h1, h2=h2, log=log)

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/model_vs_data.py
from __future__ import absolute_import, division, print_function
from mmtbx import model_vs_data
import sys

if(__name__ == "__main__"):
  model_vs_data.run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/model_vs_map.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.model_vs_map

from scitbx.array_family import flex
import iotbx.pdb
from libtbx.utils import Sorry
from libtbx.str_utils import make_sub_header
from cctbx import maptbx
from cctbx import miller
import mmtbx.utils
import mmtbx.maps.correlation
import mmtbx.model.statistics
import mmtbx.model
import sys, time

legend = """phenix.development.model_map_statistics:
  Given PDB file and a map compute various statistics.

How to run:
  phenix.development.model_map_statistics model.pdb map.ccp4 resolution=3

Feedback:
  PAfonine@lbl.gov"""

master_params_str = """
  map_file_name = None
    .type = str
  model_file_name = None
    .type = str
  resolution = None
    .type = float
  scattering_table = wk1995  it1992  *n_gaussian  neutron electron
    .type = choice
"""

def master_params():
  return iotbx.phil.parse(master_params_str, process_includes=False)

def broadcast(m, log):
  print("-"*79, file=log)
  print(m, file=log)
  print("*"*len(m), file=log)

def show_histogram(data=None, n_slots=None, data_min=None, data_max=None,
                   log=None):
  from cctbx.array_family import flex
  hm = flex.histogram(data = data, n_slots = n_slots, data_min = data_min,
    data_max = data_max)
  lc_1 = hm.data_min()
  s_1 = enumerate(hm.slots())
  for (i_1,n_1) in s_1:
    hc_1 = hm.data_min() + hm.slot_width() * (i_1+1)
    print("%10.4f - %-10.4f : %d" % (lc_1, hc_1, n_1), file=log)
    lc_1 = hc_1

def run(args, log=sys.stdout):
  print("-"*79, file=log)
  print(legend, file=log)
  print("-"*79, file=log)
  inputs = mmtbx.utils.process_command_line_args(args = args,
    master_params = master_params())
  params = inputs.params.extract()
  # estimate resolution
  d_min = params.resolution
  broadcast(m="Map resolution:", log=log)
  if(d_min is None):
    raise Sorry("Resolution is required.")
  print("  d_min: %6.4f"%d_min, file=log)
  # model
  broadcast(m="Input PDB:", log=log)
  file_names = inputs.pdb_file_names
  if(len(file_names) != 1): raise Sorry("PDB file has to given.")
  if(inputs.crystal_symmetry is None):
    raise Sorry("No crystal symmetry defined.")
  pdb_inp = iotbx.pdb.input(file_name=file_names[0])
  model = mmtbx.model.manager(
      model_input = pdb_inp,
      crystal_symmetry=inputs.crystal_symmetry)
  model.process(make_restraints=True)
  if model.get_number_of_models() > 1:
    raise Sorry("Only one model allowed.")
  model.setup_scattering_dictionaries(scattering_table=params.scattering_table)
  model.get_xray_structure().show_summary(f=log, prefix="  ")
  broadcast(m="Input map:", log=log)
  if(inputs.ccp4_map is None): raise Sorry("Map file has to given.")
  inputs.ccp4_map.show_summary(prefix="  ")
  map_data = inputs.ccp4_map.map_data()
  print("  Actual map (min,max,mean):", \
    map_data.as_1d().min_max_mean().as_tuple(), file=log)
  make_sub_header("Histogram of map values", out=log)
  md = map_data.as_1d()
  show_histogram(data=md, n_slots=10, data_min=flex.min(md),
    data_max=flex.max(md), log=log)
  # shift origin if needed
  soin = maptbx.shift_origin_if_needed(map_data=map_data,
    sites_cart=model.get_sites_cart(), crystal_symmetry=model.crystal_symmetry())
  map_data = soin.map_data
  model.set_sites_cart(soin.sites_cart)
  ####
  # Compute and show all stats
  ####
  broadcast(m="Model statistics:", log=log)
  make_sub_header("Overall", out=log)
  info = mmtbx.model.statistics.info(model=model)
  info.geometry.show()

  # XXX - these are not available anymore due to refactoring
  # make_sub_header("Histogram of devations from ideal bonds", out=log)
  # show_histogram(data=ms.bond_deltas, n_slots=10, data_min=0, data_max=0.2,
  #   log=log)
  # #
  # make_sub_header("Histogram of devations from ideal angles", out=log)
  # show_histogram(data=ms.angle_deltas, n_slots=10, data_min=0, data_max=30.,
  #   log=log)
  # #
  # make_sub_header("Histogram of non-bonded distances", out=log)
  # show_histogram(data=ms.nonbonded_distances, n_slots=10, data_min=0,
  #   data_max=5., log=log)
  #
  make_sub_header("Histogram of ADPs", out=log)
  info.adp.show(log=log)
  # bs = xrs.extract_u_iso_or_u_equiv()*adptbx.u_as_b(1.)
  # show_histogram(data=bs, n_slots=10, data_min=flex.min(bs),
  #   data_max=flex.max(bs), log=log)
  #
  # Compute CC
  broadcast(m="Map-model CC (overall):", log=log)
  five_cc_result = mmtbx.maps.correlation.five_cc(map = map_data,
    xray_structure = model.get_xray_structure(), d_min = d_min)
  atom_radius = five_cc_result.atom_radius
  if atom_radius is None:
    atom_radius = five_cc_result._atom_radius()
  print("  CC_mask  : %6.4f"%five_cc_result.result.cc_mask, file=log)
  print("  CC_volume: %6.4f"%five_cc_result.result.cc_volume, file=log)
  print("  CC_peaks : %6.4f"%five_cc_result.result.cc_peaks, file=log)
  # Compute FSC(map, model)
  broadcast(m="Model-map FSC:", log=log)
  fsc = mmtbx.maps.correlation.fsc_model_vs_map(
    xray_structure = model.get_xray_structure(),
    map            = map_data,
    atom_radius    = atom_radius,
    d_min          = d_min)
  fsc.show(prefix="  ")
  # Local CC
  cc_calculator = mmtbx.maps.correlation.from_map_and_xray_structure_or_fmodel(
    xray_structure = model.get_xray_structure(),
    map_data       = map_data,
    d_min          = d_min)
  broadcast(m="Map-model CC (local):", log=log)
  # per residue
  print("Per residue:", file=log)
  residue_results = list()
  ph = model.get_hierarchy()
  xrs = model.get_xray_structure()
  for rg in ph.residue_groups():
    cc = cc_calculator.cc(selection=rg.atoms().extract_i_seq())
    chain_id = rg.parent().id
    print("  chain id: %s resid %s: %6.4f"%(
      chain_id, rg.resid(), cc), file=log)
  # per chain
  print("Per chain:", file=log)
  for chain in ph.chains():
    print("  chain %s: %6.4f"%(chain.id, cc_calculator.cc(
      selection=chain.atoms().extract_i_seq())), file=log)
  # per residue detailed counts
  print("Per residue (histogram):", file=log)
  crystal_gridding = maptbx.crystal_gridding(
    unit_cell             = xrs.unit_cell(),
    space_group_info      = xrs.space_group_info(),
    pre_determined_n_real = map_data.accessor().all())
  f_calc = xrs.structure_factors(d_min=d_min).f_calc()
  fft_map = miller.fft_map(
    crystal_gridding     = crystal_gridding,
    fourier_coefficients = f_calc)
  fft_map.apply_sigma_scaling()
  map_model = fft_map.real_map_unpadded()
  sites_cart = xrs.sites_cart()
  cc_per_residue = flex.double()
  for rg in ph.residue_groups():
    cc = mmtbx.maps.correlation.from_map_map_atoms(
      map_1      = map_data,
      map_2      = map_model,
      sites_cart = sites_cart.select(rg.atoms().extract_i_seq()),
      unit_cell  = xrs.unit_cell(),
      radius     = 2.)
    cc_per_residue.append(cc)
  show_histogram(data=cc_per_residue, n_slots=10, data_min=-1., data_max=1.0,
    log=log)
  #

"""
THIS IS NOT USED ANYWHERE BUT MIGHT BE USEFUL IN FUTURE, REMOVE LATER

def min_nonbonded_distance(sites_cart, geometry, xray_structure, selection):
  selw = xray_structure.selection_within(radius = 3.0, selection =
    flex.bool(xray_structure.scatterers().size(), selection)).iselection()
  sites_cart_w = sites_cart.select(selw)
  #
  g = geometry.select(iselection=selw)
  pair_proxy_list_sorted=[]
  bond_proxies_simple, asu = g.get_all_bond_proxies(
    sites_cart = sites_cart_w)
  for proxy in bond_proxies_simple:
    tmp = list(proxy.i_seqs)
    tmp.sort()
    pair_proxy_list_sorted.append(tmp)
  pair_proxy_list_sorted.sort()
  #
  dist_min=999
  i_min,j_min = None,None
  for i, si in enumerate(sites_cart_w):
    for j, sj in enumerate(sites_cart_w):
      if(i<j):
        p = [i,j]
        p.sort()
        if(not p in pair_proxy_list_sorted):
          dist_ij = math.sqrt(
            (si[0]-sj[0])**2+
            (si[1]-sj[1])**2+
            (si[2]-sj[2])**2)
          if(dist_ij<dist_min):
            dist_min = dist_ij
            i_min,j_min = i, j
  return i_min,j_min,dist_min

class residue_monitor(object):
  def __init__(self,
               residue,
               id_str,
               bond_rmsd=None,
               angle_rmsd=None,
               map_cc=None,
               map_min=None,
               map_mean=None,
               rotamer_status=None,
               ramachandran_status=None,
               cbeta_status=None,
               min_nonbonded=None):
    adopt_init_args(self, locals())

  def show(self):
    print "%12s %6s %6s %6s %6s %6s %7s %9s %7s %7s"%(
      self.id_str,
      format_value("%6.3f",self.map_cc),
      format_value("%5.2f",self.map_min),
      format_value("%5.2f",self.map_mean),
      format_value("%6.3f",self.bond_rmsd),
      format_value("%6.2f",self.angle_rmsd),
      format_value("%6.3f",self.min_nonbonded),
      self.rotamer_status,
      self.ramachandran_status,
      self.cbeta_status)

class structure_monitor(object):
  def __init__(self,
               pdb_hierarchy,
               xray_structure,
               map_1, # map data
               map_2,
               geometry,
               atom_radius):
    adopt_init_args(self, locals())
    self.unit_cell = self.xray_structure.unit_cell()
    self.xray_structure = xray_structure.deep_copy_scatterers()
    self.unit_cell = self.xray_structure.unit_cell()
    self.rotamer_manager = RotamerEval()
    #
    sc1 = self.xray_structure.sites_cart()
    sc2 = self.pdb_hierarchy.atoms().extract_xyz()
    assert approx_equal(sc1, sc2, 1.e-3)
    #
    self.sites_cart = self.xray_structure.sites_cart()
    self.sites_frac = self.xray_structure.sites_frac()
    #
    self.map_cc_whole_unit_cell = None
    self.map_cc_around_atoms = None
    self.map_cc_per_atom = None
    self.rmsd_b = None
    self.rmsd_a = None
    self.dist_from_start = 0
    self.dist_from_previous = 0
    self.number_of_rotamer_outliers = 0
    self.residue_monitors = None
    #
    ramalyze_obj = ramalyze(pdb_hierarchy=pdb_hierarchy, outliers_only=False)
    self.rotamer_outlier_selection = ramalyze_obj.outlier_selection()
    #
    cbetadev_obj = cbetadev(
        pdb_hierarchy = pdb_hierarchy,
        outliers_only = False,
        out           = null_out())
    self.cbeta_outlier_selection = cbetadev_obj.outlier_selection()
    #
    self.initialize()

  def initialize(self):
    # residue monitors
    print "    ID-------|MAP-----------------|RMSD----------|NONB-|ROTAMER--|RAMA---|CBETA--|"
    print "             |CC     MIN    MEAN  |BOND    ANGLE |     |         |       |        "
    self.residue_monitors = []
    sites_cart = self.xray_structure.sites_cart()
    for model in self.pdb_hierarchy.models():
      for chain in model.chains():
        for residue_group in chain.residue_groups():
          for conformer in residue_group.conformers():
            for residue in conformer.residues():
              id_str="%s,%s,%s"%(chain.id,residue.resname,residue.resseq.strip())
              selection = residue.atoms().extract_i_seq()
              cc = correlation.from_map_map_atoms(
                map_1      = self.map_1,
                map_2      = self.map_2,
                sites_cart = self.sites_cart.select(selection),
                unit_cell  = self.unit_cell,
                radius     = self.atom_radius)
              rotamer_status = self.rotamer_manager.evaluate_residue(residue)
              grm = self.geometry.select(iselection=selection)
              es = grm.energies_sites(sites_cart=residue.atoms().extract_xyz())
              ramachandran_status="VALID"
              if(selection[0] in self.rotamer_outlier_selection):
                ramachandran_status="OUTLIER"
              cbeta_status="VALID"
              if(selection[0] in self.cbeta_outlier_selection):
                cbeta_status="OUTLIER"
              mnd = min_nonbonded_distance(
                sites_cart     = sites_cart,
                geometry       = self.geometry,
                xray_structure = self.xray_structure,
                selection      = selection)
              mi,me = self.map_values_min_mean(selection = selection)
              rm = residue_monitor(
                residue             = residue,
                id_str              = id_str,
                bond_rmsd           = es.bond_deviations()[2],
                angle_rmsd          = es.angle_deviations()[2],
                map_cc              = cc,
                map_min             = mi,
                map_mean            = me,
                min_nonbonded       = mnd[2],
                rotamer_status      = rotamer_status,
                ramachandran_status = ramachandran_status,
                cbeta_status        = cbeta_status)
              self.residue_monitors.append(rm)
              rm.show()

  def show(self):
    print "     ID       MAP CC    BOND      ANGLE  NONB     ROTAMER    RAMA      CBETA"
    for rm in self.residue_monitors:
      rm.show()

  def map_values_min_mean(self, selection):
    map_values = flex.double()
    for i in selection:
      mv = self.map_1.eight_point_interpolation(self.sites_frac[i])
      map_values.append(mv)
    mi,ma,me = map_values.min_max_mean().as_tuple()
    return mi, me

  def map_map_sites_cc(self, selection):
    return correlation.from_map_map_atoms(
      map_1      = self.map_1,
      map_2      = self.map_2,
      sites_cart = self.sites_cart.select(selection),
      unit_cell  = self.unit_cell,
      radius     = self.atom_radius)
"""

if (__name__ == "__main__"):
  t0 = time.time()
  run(args=sys.argv[1:])
  print()
  print("Time:", round(time.time()-t0, 3))


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/models_as_chains.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.models_as_chains

import sys
import iotbx.pdb
from libtbx.utils import Sorry
import string

legend = """phenix.models_as_chains:
  Convert multi-model PDB file (MODEL-ENDMDL) into multi-chain PDB file.

How to run:
  phenix.models_as_chains model.pdb

Feedback:
  PAfonine@lbl.gov
  phenixbb@phenix-online.org"""

def run(args):
  if(len(args)!=1): raise Sorry("PDB file is expected.")
  try:
    pdb_inp = iotbx.pdb.input(file_name=args[0])
  except Exception:
    raise Sorry("PDB file is expected.")
  h = pdb_inp.construct_hierarchy()
  r = iotbx.pdb.hierarchy.root()
  m = iotbx.pdb.hierarchy.model()
  idl = [i for i in string.ascii_lowercase]
  idu = [i for i in string.ascii_uppercase]
  taken = []
  c1 = None
  c2 = None
  n_atoms = []
  for m_ in h.models():
    for c_ in m_.chains():
      n_at = len(c_.atoms())
      if(not n_at in n_atoms): n_atoms.append(n_at)
      c_ = c_.detached_copy()
      found = False
      for idu_ in idu:
        for idl_ in idl:
          id_ = idu_+idl_
          if(not id_ in taken):
            taken.append(id_)
            found = id_
            break
        if(found): break
      c_.id = found
      m.append_chain(c_)
  r.append_model(m)
  r.write_pdb_file(
    file_name        = "chains_"+args[0],
    crystal_symmetry = pdb_inp.crystal_symmetry())

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/molprobity.py
# LIBTBX_SET_DISPATCHER_NAME phenix.molprobity
# LIBTBX_SET_DISPATCHER_NAME molprobity.molprobity
# LIBTBX_PRE_DISPATCHER_INCLUDE_SH export PHENIX_GUI_ENVIRONMENT=1

from __future__ import absolute_import, division, print_function
from libtbx.program_utils.result import program_result
from libtbx.utils import Sorry, multi_out
from libtbx import Auto, easy_pickle, runtime_utils
import iotbx.phil
import libtbx.load_env
import mmtbx.model
import os.path
import sys

def get_master_phil():
  from mmtbx.command_line import generate_master_phil_with_inputs
  phil_scope = generate_master_phil_with_inputs(
    enable_automatic_twin_detection=True,
    enable_twin_law=True,
    enable_experimental_phases=False,  # Off by default here in MolProbity
    enable_pdb_interpretation_params=True,
    enable_stop_for_unknowns=False,
    enable_unmerged_data=True,
    enable_cdl=Auto,
    phil_string="""
molprobity {
  outliers_only = True
    .type = bool
  keep_hydrogens = Auto
    .type = bool
    .help = Keep hydrogens in input file (instead of re-generating them with \
      Reduce).  If set to Auto, the behavior will depend on whether the \
      neutron scattering table is used (regardless of whether we actually \
      have experimental data).
  # nuclear = False     # redundant parameter, same as
  #   .type = bool      # pdb_interpretation.use_neutron_distances
  #   .short_caption = "Use nuclear hydrogen positions"
  min_cc_two_fofc = 0.8
    .type = float
    .short_caption = "CC threshold"
    .help = Values for real-space correlations below the CC threshold are \
      considered outliers
  n_bins = 10
    .type = int
    .short_caption = Number of resolution bins
  use_pdb_header_resolution_cutoffs = False
    .type = bool
    .short_caption = Use resolution cutoffs in PDB header
  count_anomalous_pairs_separately = False
    .type = bool
    .expert_level = 2
  rotamer_library = 500 *8000
    .type = choice
    .help = Library of rotamer probabilities (Top500 or Top8000)
    .expert_level = 2
  flags
    .expert_level = 3
  {
    include scope mmtbx.validation.molprobity.master_phil_str
  }
  ligand_selection = None
    .type = atom_selection
    .expert_level = 3
}
polygon {
  include scope mmtbx.polygon.polygon_params_str
}
output {
  quiet = False
    .type = bool
  probe_dots = True
    .type = bool
    .short_caption = Save Probe dots for Coot
  kinemage = False
    .type = bool
    .short_caption = Save Kinemage file for KiNG
  percentiles = False
    .type = bool
    .help = Show percentile rankings for summary statistics
  coot = True
    .type = bool
    .help = Write Coot script
  maps = Auto
    .type = bool
    .short_caption = Save map coefficients
    .help = Write map coefficients (if experimental data supplied)
  map_options
    .short_caption = Advanced options for map coefficients
  {
    fill_missing_f_obs = True
      .type = bool
    exclude_free_r_reflections = False
      .type = bool
  }
  prefix = None
    .type = str
    .style = hidden
  pickle = False
    .type = bool
    .style = hidden
  wxplots = False
    .type = bool
    .help = Display plots in wxPython
    .style = hidden
  gui_dir = None
    .type = path
    .short_caption = Output directory
    .help = Output directory (Phenix GUI only).
    .style = output_dir
  include scope libtbx.phil.interface.tracking_params
}
""")
  phil_extract = phil_scope.extract()

  # change default
  phil_extract.pdb_interpretation.clash_guard.nonbonded_distance_threshold = None
  new_str = phil_scope.format(python_object=phil_extract).as_str(
    expert_level=4, attributes_level=4)

  phil_scope = iotbx.phil.parse(new_str, process_includes=True)

  return phil_scope

usage_string = """\
phenix.molprobity model.pdb [data.mtz] [options ...]

Run comprehensive MolProbity validation plus R-factor calculation (if data
supplied).
"""

def run(args,
    out=sys.stdout,
    program_name="phenix.molprobity",
    ignore_missing_modules=False,
    return_input_objects=False) : # for testing
  rotarama_dir = libtbx.env.find_in_repositories(
    relative_path="chem_data/rotarama_data",
    test=os.path.isdir)
  if (rotarama_dir is None):
    raise ImportError("Rotamer and Ramachandran distributions not available; "+
      "you will need these to run MolProbity.")
  elif (((not libtbx.env.has_module("reduce")) or
         (not libtbx.env.has_module("probe"))) and
         (not ignore_missing_modules)):
    raise ImportError("Reduce and/or Probe not configured.")
  import mmtbx.validation.molprobity
  import mmtbx.command_line
  cmdline = mmtbx.command_line.load_model_and_data(
    args=args,
    master_phil=get_master_phil(),
    require_data=False,
    create_fmodel=True,
    process_pdb_file=True,
    usage_string=usage_string,
    prefer_anomalous=True,
    out=out)
  params = cmdline.params
  fmodel = cmdline.fmodel
  if (params.output.maps is Auto) and (fmodel is not None):
    params.output.maps = True
  elif (params.output.maps == True) and (fmodel is None):
    raise Sorry("Map output requires experimental data.")
  if (params.molprobity.keep_hydrogens is Auto):
    params.molprobity.keep_hydrogens = \
      ( (params.input.scattering_table == "neutron") or
        (params.pdb_interpretation.use_neutron_distances) )
  header_info = mmtbx.validation.molprobity.pdb_header_info(
    pdb_file=params.input.pdb.file_name[0],
    pdb_hierarchy=cmdline.pdb_hierarchy)
  pdb_prefix = os.path.splitext(os.path.basename(
    params.input.pdb.file_name[0]))[0]
  if (params.output.prefix is None):
    params.output.prefix = "molprobity"
  probe_file = None
  if (params.output.probe_dots) or (params.output.kinemage):
    probe_file = params.output.prefix + "_probe.txt"
  raw_data = cmdline.raw_data

  # check map parameters
  from mmtbx.real_space_correlation import check_map_file
  check_map_file(None, params.input.maps)

  validation = mmtbx.validation.molprobity.molprobity(
    model=cmdline.model,
    fmodel=fmodel,
    flags=params.molprobity.flags,
    sequences=cmdline.sequence,
    raw_data=cmdline.raw_data,
    unmerged_data=cmdline.unmerged_i_obs,
    header_info=header_info,
    keep_hydrogens=params.molprobity.keep_hydrogens,
    nuclear=params.pdb_interpretation.use_neutron_distances,
    save_probe_unformatted_file=probe_file,
    min_cc_two_fofc=params.molprobity.min_cc_two_fofc,
    n_bins_data=params.molprobity.n_bins,
    outliers_only=params.molprobity.outliers_only,
    use_pdb_header_resolution_cutoffs=\
      params.molprobity.use_pdb_header_resolution_cutoffs,
    count_anomalous_pairs_separately=\
      params.molprobity.count_anomalous_pairs_separately,
    use_internal_variance=params.input.unmerged_data.use_internal_variance,
    file_name=params.input.pdb.file_name[0],
    ligand_selection=params.molprobity.ligand_selection,
    rotamer_library=params.molprobity.rotamer_library,
    map_params=params)
  map_file = None

  # polygon statistics
  validation.polygon_stats = validation.get_polygon_statistics(
    params.polygon.keys_to_show)
  if ('pdb_header_r_work' in params.polygon.keys_to_show):
    validation.polygon_stats['pdb_header_r_work'] = header_info.r_work
  if ('pdb_header_r_free' in params.polygon.keys_to_show):
    validation.polygon_stats['pdb_header_r_free'] = header_info.r_free

  if (not params.output.quiet):
    out2 = multi_out()
    out2.register("stdout", out)
    f = open(params.output.prefix + ".out", "w")
    out2.register("txt_out", f)
    validation.show(out=out2,
      outliers_only=params.molprobity.outliers_only,
      show_percentiles=params.output.percentiles)
    f.close()
    print("", file=out)
    print("Results written to %s.out" % params.output.prefix, file=out)
    if (params.output.kinemage):
      if (cmdline.pdb_hierarchy.models_size() == 1):
        assert (probe_file is not None)
        import mmtbx.kinemage.validation
        cmdline.pdb_hierarchy.atoms().reset_i_seq()
        kin_file = "%s.kin" % params.output.prefix
        kin_out = \
          mmtbx.kinemage.validation.export_molprobity_result_as_kinemage(
            result=validation,
            pdb_hierarchy=cmdline.pdb_hierarchy,
            geometry=cmdline.geometry,
            probe_file=probe_file,
            keep_hydrogens=params.molprobity.keep_hydrogens,
            pdbID=pdb_prefix)
        f = open(kin_file, "w")
        f.write(kin_out)
        f.close()
        if (not params.output.quiet):
          print("Wrote kinemage to %s" % kin_file, file=out)
      else :
        print("Kinemage output not available for multiple MODELs.", file=out)
    if (params.output.pickle):
      if validation.hydrogens is not None:
        validation.hydrogens.log = None
      easy_pickle.dump("%s.pkl" % params.output.prefix, validation)
      if (not params.output.quiet):
        print("Saved result to %s.pkl" % params.output.prefix, file=out)
    if (params.output.coot):
      coot_file = "%s_coot.py" % params.output.prefix
      validation.write_coot_script(coot_file)
      if (not params.output.quiet):
        print("Wrote script for Coot: %s" % coot_file, file=out)
    if (params.output.maps == True):
      import mmtbx.maps.utils
      import iotbx.map_tools
      map_file = "%s_maps.mtz" % params.output.prefix
      two_fofc_map, fofc_map = mmtbx.maps.utils.get_maps_from_fmodel(
        fmodel=fmodel,
        fill_missing_f_obs=params.output.map_options.fill_missing_f_obs,
        exclude_free_r_reflections=\
          params.output.map_options.exclude_free_r_reflections)
      anom_map = None
      if (fmodel.f_obs().anomalous_flag()):
        anom_map = mmtbx.maps.utils.get_anomalous_map(fmodel)
      iotbx.map_tools.write_map_coeffs(
        file_name=map_file,
        fwt_coeffs=two_fofc_map,
        delfwt_coeffs=fofc_map,
        anom_coeffs=anom_map)
      print("Wrote map coefficients to %s" % map_file, file=out)
  else :
    print("", file=out)
    validation.show_summary(out=out, show_percentiles=params.output.percentiles)
  if (params.output.wxplots):
    try :
      import wxtbx.app
    except ImportError as e :
      raise Sorry("wxPython not available.")
    else :
      app = wxtbx.app.CCTBXApp(0)
      validation.display_wx_plots()
      app.MainLoop()
  if (return_input_objects):
    return validation, cmdline

  # remove unpicklable attributes
  validation.model = None
  validation.pdb_hierarchy = None
  validation.model_statistics_geometry.model = None
  if validation.hydrogens is not None:
    validation.hydrogens.log = None

  return result(
    program_name="phenix.molprobity",
    job_title=params.output.job_title,
    directory=os.getcwd(),
    map_file=map_file,
    other_result=validation,
    other_files=[ params.input.pdb.file_name[0] ])

class launcher(runtime_utils.target_with_save_result):
  def run(self):
    os.mkdir(self.output_dir)
    os.chdir(self.output_dir)
    return run(args=self.args, out=sys.stdout)

class result(program_result):
  """
  Wrapper object for Phenix GUI.
  """
  @property
  def validation(self):
    return self.other_result

  @property
  def pdb_file(self):
    return self.other_files[0]

  def get_final_stats(self):
    return self.validation.get_statistics_for_phenix_gui()

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/mon_lib_cif_triage.py
from __future__ import absolute_import, division, print_function
from mmtbx.monomer_library import cif_triage
from libtbx.str_utils import show_string
from libtbx.utils import Sorry, Usage
import libtbx.load_env
import sys

def run(args, command_name=libtbx.env.dispatcher_name):
  if (len(args) == 0):
    raise Usage("%s cif [...]" % command_name)
  for file_name in args:
    obj_count = cif_triage.check_comp(file_name=file_name)
    if (obj_count == 0):
      raise Sorry("No data found in file: %s" % show_string(file_name))
  print("OK")

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/mp_geo.py

from __future__ import absolute_import, division, print_function
import sys
from mmtbx.validation.molprobity import mp_geo

if __name__ == "__main__":
  mp_geo.run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/mp_validate_bonds.py
# LIBTBX_SET_DISPATCHER_NAME phenix.mp_validate_bonds
# LIBTBX_SET_DISPATCHER_NAME molprobity.mp_validate_bonds

from __future__ import absolute_import, division, print_function
import sys
from iotbx.cli_parser import CCTBXParser
from libtbx.utils import multi_out, show_total_time
from mmtbx.programs import mp_validate_bonds
from iotbx.cli_parser import run_program

def old_run(args, out=sys.stdout, quiet=False):
  # create parser
  logger = multi_out()
  logger.register('stderr', sys.stderr)
  logger2 = multi_out()
  logger2.register('stdout', sys.stdout)

  parser = CCTBXParser(
    program_class=mp_validate_bonds.Program,
    logger=logger)
  namespace = parser.parse_args(sys.argv[1:])

  # start program
  print('Starting job', file=logger)
  print('='*79, file=logger)
  task = mp_validate_bonds.Program(
    parser.data_manager, parser.working_phil.extract(), logger=logger2)

  # validate inputs
  task.validate()

  # run program
  task.run()

  # stop timer
  print('', file=logger)
  print('='*79, file=logger)
  print('Job complete', file=logger)
  show_total_time(out=logger)

if (__name__ == "__main__"):
  #run(sys.argv[1:])
  run_program(program_class=mp_validate_bonds.Program, hide_parsing_output=True)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/mtz2map.py
# LIBTBX_SET_DISPATCHER_NAME phenix.mtz2map
# LIBTBX_SET_DISPATCHER_NAME phenix.fft
# LIBTBX_SET_DISPATCHER_NAME mmtbx.fft

# TODO: remove R-free set from map coefficients?

from __future__ import absolute_import, division, print_function
from mmtbx.maps import utils
import iotbx.map_tools
import iotbx.phil
from iotbx import file_reader
import iotbx.pdb
from libtbx import runtime_utils
import libtbx.phil
from libtbx.utils import Sorry, Usage
import sys, os
import iotbx.phil

master_phil = iotbx.phil.parse("""
mtz_file = None
  .type = path
  .short_caption = MTZ file
  .style = bold file_type:hkl OnChange:extract_map_coeffs_for_fft
  .help = MTZ file containing map coefficients
pdb_file = None
  .type = path
  .multiple = True
  .short_caption = Model file
  .help = Model file around which to draw the map.  If not supplied, the map \
    will fill the unit cell.
labels = None
  .type = strings
  .multiple = True
  .help = Map column labels.  Common examples are "2FOFCWT,PH2FOFCWT" and \
    "FP,SIGFP" "PHIM" "FOMM".  If left blank, all maps present in the input \
    file will be used.
buffer = 5.0
  .type = float
  .short_caption = Region padding
  .help = Extra padding (in Angstroms) around the selected region (or unit \
    cell)
selection = None
  .type = str
  .input_size = 400
  .short_caption = Atom selection
  .help = Atom selection around which to draw map (plus buffer).  If left \
    blank, the entire model file will be used.
d_min = None
  .type = float
  .help = High-resolution cutoff
d_max = None
  .type = float
  .help = Low-resolution cutoff
grid_resolution_factor = 0.25
  .type = float
  .help = Grid spacing (multiplied by the high-resolution limit)
gridding = None
  .type = ints
  .help = Gridding
scale = *sigma volume
  .type = choice(multi=False)
  .expert_level = 1
  .short_caption = Map scaling
  .help = Scaling method for map values
output {
  directory = None
    .type = path
    .short_caption = Output directory
    .help = Output directory (defaults to current)
    .style = output_dir bold
  prefix = None
    .type = str
    .input_size = 400
    .short_caption = Output file prefix
    .help = Output file prefix (defaults to the MTZ file name base)
  include scope libtbx.phil.interface.tracking_params
  format = xplor *ccp4 dsn6
    .type = choice
    .caption = XPLOR CCP4 DSN6
  extension = *Auto ccp4 xplor map dsn6
    .type = choice
}
r_free_flags {
  remove = False
    .type = bool
    .short_caption = Remove R-free set from map
  file_name = None
    .type = path
    .short_caption = R-free flags
    .style = OnChange:extract_r_free_flags_for_fft
  label = None
    .type = str
    .input_size = 120
    .short_caption = R-free label
    .style = renderer:draw_rfree_label_widget
  test_flag_value = None
    .type = int
}
include_fmodel = False
  .type = bool
  .short_caption = Include F(model) if present
show_maps = False
  .type = bool
""", process_includes=True)
master_params = master_phil

def find_array(miller_arrays, labels):
  for array in miller_arrays :
    if array.info().label_string() == labels :
      return array
  return None

def run(args, log=sys.stdout, run_in_current_working_directory=False):
  import iotbx.phil # FIXME this should not be necessary!
  pdb_file = None
  mtz_file = None
  input_phil = []
  if len(args) == 0 :
    print("Parameter syntax:", file=log)
    master_phil.show(out=log, prefix="  ")
    raise Usage("phenix.mtz2map [mtz_file] [pdb_file] [param_file] " +
      "[--show_maps]")
  input_objects = iotbx.phil.process_command_line_with_files(
    args=args,
    master_phil=master_phil,
    pdb_file_def="pdb_file",
    reflection_file_def="mtz_file")
  params = input_objects.work.extract()

  if params.mtz_file is None:
    raise Sorry("Please specify an MTZ file containing map coefficients.")
  if (not run_in_current_working_directory):
    if params.output.directory is None :
      params.output.directory = os.getcwd()
    if (not os.path.exists(params.output.directory)):
      os.makedirs(params.output.directory)
    elif (not os.path.isdir(params.output.directory)):
      raise Sorry("The specified output path '%s' is not a directory!" %
        params.output.directory)
    output_dir = params.output.directory
  else :
    output_dir = os.getcwd()
  if params.output.prefix is None :
    params.output.prefix = os.path.splitext(
      os.path.basename(params.mtz_file))[0]
  mtz_file = file_reader.any_file(params.mtz_file,
    force_type="hkl",
    raise_sorry_if_errors=True)
  all_labels=[]
  if params.show_maps or len(params.labels) == 0 :
    map_labels = utils.get_map_coeff_labels(mtz_file.file_server,
      exclude_anomalous=False,
      exclude_fmodel=not params.include_fmodel,
      keep_array_labels=True)
    if (not params.include_fmodel):
      all_labels = utils.get_map_coeff_labels(mtz_file.file_server,
        exclude_anomalous=False,
        exclude_fmodel=False,
        keep_array_labels=True)
    else :
      all_labels = map_labels
    if len(all_labels) > 0 :
      print("Available map coefficients in this MTZ file:", file=log)
      for labels in all_labels :
        if isinstance(labels, str):
          labels_list = [labels]
        else :
          labels_list = labels
        if (not labels in map_labels):
          extra = " (skipping, add include_fmodel=True to include)"
        else :
          extra = ""
          params.labels.append(labels_list)
        print("  %s%s" % (labels_list, extra), file=log)
    else :
      raise Sorry("No map coefficients found in this MTZ file.")
    if params.show_maps : return False
  pdb_file = None
  if len(params.pdb_file) > 0:
    pdb_file = iotbx.pdb.input(params.pdb_file[0])
  miller_arrays = mtz_file.file_object.as_miller_arrays()
  r_free_flags = None
  if params.r_free_flags.remove :
    if params.r_free_flags.file_name is not None :
      rfree_file = file_reader.any_file(params.r_free_flags.file_name,
        force_type="hkl")
    else :
      rfree_file = mtz_file
    raw_array, flag_value = rfree_file.file_server.get_r_free_flags(
      file_name=rfree_file.file_name,
      label=params.r_free_flags.label,
      test_flag_value=params.r_free_flags.test_flag_value,
      disable_suitability_test=False,
      parameter_scope="r_free_flags")
    r_free_flags = raw_array.array(
      data=raw_array.data()==flag_value).map_to_asu().average_bijvoet_mates()
  sites_cart = None
  if pdb_file is not None :
    pdb_hierarchy = pdb_file.construct_hierarchy()
    sites_cart = pdb_hierarchy.atoms().extract_xyz()
    if params.selection is not None :
      selection_cache = pdb_hierarchy.atom_selection_cache()
      selection = selection_cache.selection(params.selection)
      sites_cart = sites_cart.select(selection)
      if (len(sites_cart) == 0):
        raise Sorry("No atoms found matching the specified selection.")
  else :
    print("No model input - will output map(s) in unit cell.", file=log)
  file_info = []
  suffixes = []
  for i, map_labels in enumerate(params.labels):
    map_coeffs = None
    if (len(map_labels) == 1):
      map_coeffs = find_array(miller_arrays, map_labels[0])
      if (map_coeffs is None):
        all_labels = utils.get_map_coeff_labels(mtz_file.file_server,
          keep_array_labels=True,
          exclude_anomalous=False,
          exclude_fmodel=not params.include_fmodel)
        labels_out = []
        if len(all_labels) > 0 :
          for labels in all_labels :
            if isinstance(labels, str):
              labels = [labels]
            labels_out.append("  " + " ".join(labels))
          raise Sorry(("No map coefficients found with labels %s.  Possible "+
            "choices are:\n%s") % (map_labels[0], "\n".join(labels_out)))
        else :
          raise Sorry(("No map coefficients found with labels %s; this file "+
            "does not appear to contain any other map coefficients!") %
            map_labels[0])
    else :
      if len(map_labels) == 2 :
        map_labels.append(None)
      (f, phi, fom) = utils.extract_map_coeffs(miller_arrays=miller_arrays,
        f_lab=map_labels[0],
        phi_lab=map_labels[1],
        fom_lab=map_labels[2])
      assert f.is_xray_amplitude_array()
      assert phi.is_real_array()
      assert (fom is None) or (fom.is_real_array())
      map_coeffs = iotbx.map_tools.combine_f_phi_and_fom(f=f, phi=phi, fom=fom)
    print("Processing map: %s" % " ".join(map_labels), file=log)
    assert map_coeffs.is_complex_array()
    map_coeffs = map_coeffs.map_to_asu().average_bijvoet_mates()
    map_coeffs = map_coeffs.resolution_filter(d_min=params.d_min,
      d_max=params.d_max)
    if (r_free_flags is not None):
      map_coeffs, flags = map_coeffs.common_sets(other=r_free_flags)
      print("  removing %d R-free flagged reflections" % \
        flags.data().count(True), file=log)
      map_coeffs = map_coeffs.select(~(flags.data()))
    from cctbx import maptbx

    if params.gridding:
      from cctbx.maptbx import crystal_gridding
      cg=crystal_gridding(
        unit_cell=map_coeffs.crystal_symmetry().unit_cell(),
        space_group_info=
           map_coeffs.crystal_symmetry().space_group_info(),
        pre_determined_n_real=params.gridding)
    else:
      cg=None
    map = map_coeffs.fft_map(resolution_factor=params.grid_resolution_factor,
      symmetry_flags=maptbx.use_space_group_symmetry,
      crystal_gridding=cg)
    if params.scale == "sigma" :
      print("  applying sigma-scaling", file=log)
      map.apply_sigma_scaling()
    elif params.scale == "volume" :
      print("  applying volume-scaling", file=log)
      map.apply_volume_scaling()
    suffix = None
    if map_labels == ["FP,SIGFP", "PHIM", "FOMM"] :
      suffix = ""
    elif map_labels[0].startswith("2FOFCWT"):
      if map_labels[0].endswith("no_fill"):
        suffix = "_2mFo-DFc_no_fill"
      else :
        suffix = "_2mFo-DFc"
    elif map_labels[0].startswith("FOFCWT"):
      suffix = "_mFo-DFc"
    elif map_labels[0] == "FWT,PHWT" : # refmac
      suffix = "_2mFo-DFc"
    elif map_labels[0] == "DELFWT,PHDELWT" : # refmac
      suffix = "_mFo-DFc"
    elif map_labels[0].startswith("ANOM"):
      suffix = "_anom"
    elif (map_labels[0].startswith("LLG")):
      suffix = "_llg"
    elif (map_labels[0].startswith("FMODEL") or
          map_labels[0].startswith("F-model")):
      suffix = "_fmodel"
    elif (map_labels[0].startswith("FC")):
      suffix = "_fcalc"
    else :
      suffix = "_%d" % (i+1)
    if ("_no_fill" in map_labels[0]):
      suffix += "_no_fill"
    elif ("_fill" in map_labels[0]):
      suffix += "_filled"
    # check for duplicate suffixes, append a number if necessary
    if (suffix in suffixes):
      suffixes.append(suffix)
      n = suffixes.count(suffix)
      suffix += "_%d" % n
    else :
      suffixes.append(suffix)
    format = params.output.format
    if params.output.extension == "Auto" :
      if format == "ccp4" :
        extension = "ccp4"
      elif format == "dsn6" :
        extension = "omap"
      else :
        extension = "xplor"
    else :
      extension = params.output.extension
      if format == "xplor" and not extension in ["xplor", "map"] :
        raise Sorry("%s is not an appropriate extension for Xplor maps." %
          extension)
      elif format == "ccp4" and not extension in ["ccp4", "map"] :
        raise Sorry("%s is not an appropriate extension for CCP4 maps." %
          extension)
    map_file_name = os.path.join(output_dir,
      params.output.prefix + suffix + "." + extension)
    if format == "xplor" :
      utils.write_xplor_map(
        sites_cart=sites_cart,
        unit_cell=map_coeffs.unit_cell(),
        map_data=map.real_map(),
        n_real=map.n_real(),
        file_name=map_file_name,
        buffer=params.buffer)
      file_info.append((map_file_name, "XPLOR map"))
    elif (format == "dsn6"):
      if (sites_cart is not None):
        import iotbx.map_tools
        iotbx.map_tools.write_dsn6_map(
          sites_cart=sites_cart,
          unit_cell=map_coeffs.unit_cell(),
          map_data=map.real_map(),
          n_real=map.n_real(),
          file_name=map_file_name,
          buffer=params.buffer)
      else :
        map.as_dsn6_map(file_name=map_file_name)
    else :
      if sites_cart is not None :
        import iotbx.map_tools
        iotbx.map_tools.write_ccp4_map(
          sites_cart=sites_cart,
          unit_cell=map_coeffs.unit_cell(),
          map_data=map.real_map(),
          n_real=map.n_real(),
          file_name=map_file_name,
          buffer=params.buffer)
      else :
        map.as_ccp4_map(file_name=map_file_name)
      file_info.append((map_file_name, "CCP4 map"))
    print("  wrote %s" % map_file_name, file=log)
  return file_info

def finish_job(result):
  return (result, []) # XXX result is already a file name/desc. list

class launcher(runtime_utils.target_with_save_result):
  def run(self):
    os.makedirs(self.output_dir)
    os.chdir(self.output_dir)
    return run(args=list(self.args),
      log=sys.stdout,
      run_in_current_working_directory=True)

def validate_params(params):
  if params.mtz_file is None:
    raise Sorry("No MTZ file was provided.")

if __name__ == "__main__" :
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/nonbonded_overlaps.py
# LIBTBX_SET_DISPATCHER_NAME mmtbx.nonbonded_overlaps
from __future__ import division, print_function

from iotbx.cli_parser import run_program
from mmtbx.programs import nonbonded_overlaps

if __name__ == '__main__':
  run_program(program_class=nonbonded_overlaps.Program)


# from __future__ import division
# from __future__ import print_function
# import mmtbx.monomer_library.pdb_interpretation as pdb_inter
# import cctbx.geometry_restraints.nonbonded_overlaps as nbo
# import mmtbx.validation.clashscore as mvc
# from libtbx.utils import null_out
# from libtbx.utils import Sorry
# from libtbx.utils import Usage
# import iotbx.phil
# import sys

# master_phil_str = """
#   model = None
#     .type = path
#     .optional = False
#     .help = '''input PDB file'''

#   cif = None
#     .type = path
#     .optional = True
#     .help = '''Optional Crystallographic Information File (CIF)'''

#   verbose = True
#     .type = bool

#   keep_hydrogens = True
#     .type = bool
#     .help = '''Keep hydrogens in input file
#     (if there are no hydrogens in input file they will be added)'''

#   skip_hydrogen_test = False
#     .type = bool
#     .help = '''Ignore hydrogen considerations, check NBO on PDB file as-is '''

#   nuclear = False
#     .type = bool
#     .help = '''Use nuclear hydrogen positions'''

#   time_limit = 120
#     .type = int
#     .help = '''Time limit (sec) for Reduce optimization'''

#   show_overlap_type = *all sym macro selection
#   .type = choice(multi=False)
#   .help = '''When using cctbx method, this parameter allows selecting to show
#   all clashes 'all', clashes dues to symmetry operation 'sym' or clashes in
#   the macro molecule 'macro'.'''

#   substitute_non_crystallographic_unit_cell_if_necessary = False
#     .type = bool
#     .help = '''\
#     Will replace the crystallographic unit cell when the model
#     crystallographic information is bad'''

#   show_normalized_nbo = False
#     .type = bool
#     .help = When True, will show non-bonded overlaps per 1000 atoms

#   show_non_binary_overlap_values = True
#     .type = bool
#     .help = use a function
# """

# usage_string = """\
# phenix.clashscore file.pdb [params.eff] [options ...]

# Options:

#   model=input_file          input PDB file
#   cif=input_file            input CIF file for additional model information
#   keep_hydrogens=True       keep input hydrogen files (otherwise regenerate)
#   skip_hydrogen_test=False  Ignore hydrogen considerations,
#                             check NBO on PDB file as-is
#   nuclear=False             use nuclear x-H distances and vdW radii
#   verbose=True              verbose text output
#   time_limit=120            Time limit (sec) for Reduce optimization
#   show_overlap_type=all     what type of overlaps to show (all,sym or macro)
#   show_normalized_nbo=False Show non-bonded overlaps per 1000 atoms
#   substitute_non_crystallographic_unit_cell_if_necessary=false
#                             fix CRYST1 records if needed

# Example:

# >>> mmtbx.nonbonded_overlaps xxxx.pdb keep_hydrogens=True

# >>> mmtbx.nonbonded_overlaps xxxx.pdb verbose=false
# """

# def run(args, out=None):
#   """
#   Calculates number of non-bonded atoms overlaps in a model

#   prints to log:
#     When verbose=True the function print detailed results to log
#     When verbose=False it will print:
#         nb_overlaps_macro_molecule,
#         nb_overlaps_due_to_sym_op,
#         nb_overlaps_all

#   Args:
#     args (list): list of options.
#       model=input_file          input PDB file
#       cif=input_file            input CIF file for additional model information
#       keep_hydrogens=True       keep input hydrogen files (otherwise regenerate)
#       nuclear=False             use nuclear x-H distances and vdW radii
#       verbose=True              verbose text output
#       time_limit=120            Time limit (sec) for Reduce optimization
#       show_overlap_type=all     what type of overlaps to show
#       show_normalized_nbo=False Show non-bonded overlaps per 1000 atoms
#       substitute_non_crystallographic_unit_cell_if_necessary=false
#                                 fix CRYST1 records if needed
#     out : where to wrote the output to.

#   Returns:
#     nb_overlaps (obj): Object containing overlap and overlap per thousand
#     atoms information
#   """
#   if not out: out = sys.stdout
#   if not args:
#     print(usage_string, file=out)
#     return None
#   cmdline = iotbx.phil.process_command_line_with_files(
#     args=args,
#     master_phil_string=master_phil_str,
#     pdb_file_def="model",
#     cif_file_def="cif",
#     usage_string=usage_string)
#   params = cmdline.work.extract()
#   if (params.model is None):
#     raise Usage(usage_string)

#   pdb_file_name = [x for x in args if x.endswith('.pdb')]
#   cif_file_name = [x for x in args if x.endswith('.cif')]
#   assert pdb_file_name
#   pdb_file_name = pdb_file_name[0]
#   if not params.skip_hydrogen_test:
#     pdb_with_h, h_were_added = mvc.check_and_add_hydrogen(
#         file_name=pdb_file_name,
#         model_number=0,
#         nuclear=params.nuclear,
#         verbose=params.verbose,
#         time_limit=params.time_limit,
#         keep_hydrogens=params.keep_hydrogens,
#         allow_multiple_models=False,
#         log=out)
#     if h_were_added:
#       pdb_file_name = pdb_file_name.replace('.pdb','_with_h.pdb')
#       open(pdb_file_name,'w').write(pdb_with_h)
#   files = [pdb_file_name]
#   if cif_file_name:
#       files += cif_file_name

#   pdb_processed_file = pdb_inter.run(
#     args=files,
#     assume_hydrogens_all_missing=False,
#     hard_minimum_nonbonded_distance=0.0,
#     nonbonded_distance_threshold=None,
#     substitute_non_crystallographic_unit_cell_if_necessary=
#     params.substitute_non_crystallographic_unit_cell_if_necessary,
#     log=null_out()    )
#   # test that CRYST1 records are ok
#   sps = pdb_processed_file.all_chain_proxies.special_position_settings
#   if not sps:
#     msg = 'None valid CRSYT1 records.\n'
#     msg += 'Consider running mmtbx.nonbonded_overlaps with the option:\n'
#     msg += 'substitute_non_crystallographic_unit_cell_if_necessary=true'
#     raise Sorry(msg)
#   grm = pdb_processed_file.geometry_restraints_manager()
#   xrs = pdb_processed_file.xray_structure()
#   sites_cart = xrs.sites_cart()
#   site_labels = xrs.scatterers().extract_labels()
#   hd_sel = xrs.hd_selection()
#   macro_mol_sel = nbo.get_macro_mol_sel(pdb_processed_file)
#   nb_overlaps = nbo.info(
#     geometry_restraints_manager=grm,
#     macro_molecule_selection=macro_mol_sel,
#     sites_cart=sites_cart,
#     site_labels=site_labels,
#     hd_sel=hd_sel)
#   if params.verbose:
#     nb_overlaps.show(
#       log=out,
#       nbo_type=params.show_overlap_type,
#       normalized_nbo=params.show_normalized_nbo)
#   else:
#     all = nb_overlaps.result.nb_overlaps_all
#     macro_molecule = nb_overlaps.result.nb_overlaps_macro_molecule
#     sym = nb_overlaps.result.nb_overlaps_due_to_sym_op
#     out_list = map(lambda x: str(round(x,2)),[macro_molecule,sym,all])
#     print(', '.join(out_list), file=out)
#   return nb_overlaps

# if (__name__ == "__main__"):
#   run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/omegalyze.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.omegalyze
# LIBTBX_SET_DISPATCHER_NAME molprobity.omegalyze
###
###import sys
###from mmtbx.validation import omegalyze
###
###if __name__ == "__main__":
###  omegalyze.run(sys.argv[1:])

import sys

from iotbx.cli_parser import CCTBXParser
from libtbx.utils import multi_out, show_total_time #, null_out

from iotbx.cli_parser import run_program
from mmtbx.programs import omegalyze

# =============================================================================
def old_run(args):

  # create parser
  #logger = multi_out() #logging.getLogger('main')
  #logger.register('stdout', sys.stdout)
  #logger = null_out()
  logger = multi_out()
  logger.register('stderr', sys.stderr)
  logger2 = multi_out()
  logger2.register('stdout', sys.stdout)
  #only omegalyze output is sent to stdout for backward compatibility with
  #  MolProbity website

  parser = CCTBXParser(
    program_class=omegalyze.Program,
    logger=logger)
  namespace = parser.parse_args(sys.argv[1:])

  # start program
  print('Starting job', file=logger)
  print('='*79, file=logger)
  task = omegalyze.Program(
    parser.data_manager, parser.working_phil.extract(), logger=logger2)

  # validate inputs
  task.validate()

  # run program
  task.run()

  # stop timer
  print('', file=logger)
  print('='*79, file=logger)
  print('Job complete', file=logger)
  show_total_time(out=logger)

# =============================================================================
if __name__ == '__main__':
  # old_run(sys.argv[1:])
  run_program(program_class=omegalyze.Program, hide_parsing_output=True)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/pdb_atom_selection.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.pdb_atom_selection

from iotbx.cli_parser import CCTBXParser, run_program
from mmtbx.programs import atom_selection

def custom_args_proc(cli_parser):
  """
  This is going to put inselection positional argument into phil scope of the
  program.
  Useful things are:
  cli_parser.namespace
  cli_parser.data_manager
  cli_parser.namespace.unknown - where these argument is going to be
  cli_parser.working_phil
  """
  wf = cli_parser.working_phil.extract()

  # Since we have phil parameters for these as well, we want to make
  # sure that we don't overwrite them if nothing was provided via
  # command-line.
  if cli_parser.namespace.cryst1_replacement_buffer_layer is not None:
    wf.atom_selection_program.cryst1_replacement_buffer_layer = \
        cli_parser.namespace.cryst1_replacement_buffer_layer
  if cli_parser.namespace.write_pdb_file is not None:
    wf.atom_selection_program.write_pdb_file = \
        cli_parser.namespace.write_pdb_file

  if len(cli_parser.namespace.unknown) > 0:
    # print("What is unknown: %s" % cli_parser.namespace.unknown)
    # print("Curr selection: '%s'" % wf.atom_selection_program.inselection)
    wf.atom_selection_program.inselection = cli_parser.namespace.unknown
    cli_parser.namespace.unknown = []
  cli_parser.working_phil = cli_parser.master_phil.format(python_object=wf)

class SelectionParser(CCTBXParser):

  def add_default_options(self):
    super(SelectionParser, self).add_default_options()

    # Stick in additional keyword args
    # They going to end up in namespace.cryst1_replacement_buffer_layer etc
    # file_name is obsolet, parser takes care of it putting it in data manager
    # inselections is going to be handled by custom_args_proc function
    # because it is intended to be positional argument
    #
    # !!! This is done here for legacy support and illustrative purposes.
    # Don't do it anywhere else, since we strive to have the same
    # command-line flags across all programs, like --overwrite etc.

    self.add_argument(
      "--cryst1-replacement-buffer-layer",
      action="store",
      type=float,
      help="replace CRYST1 with pseudo unit cell covering the selected"
        " atoms plus a surrounding buffer layer",
      default=None)
    self.add_argument(
      "--write-pdb-file", "--write_pdb_file", "--write_pdb-file", "--write-pdb_file",
      action="store",
      help="write selected atoms to new PDB file",
      default=None)

if (__name__ == "__main__"):
  run_program(parser_class=SelectionParser,
              program_class=atom_selection.Program,
              custom_process_arguments=custom_args_proc)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/pdb_interpretation.py
# LIBTBX_SET_DISPATCHER_NAME phenix.pdb_interpretation
# LIBTBX_SET_DISPATCHER_NAME mmtbx.pdb_interpretation
from __future__ import absolute_import, division, print_function
from iotbx.file_reader import any_file
import sys

def get_master_phil():
  import iotbx.phil
  return iotbx.phil.parse("""\
strict_processing = False
  .type = bool
build_geometry_restraints_manager = True
  .type = bool
build_xray_structure = True
  .type = bool
max_atoms = None
  .type = int
write_geo_files = False
  .type = bool
write_tardy_geo_files = False
  .type = bool
model_file_name = None
  .type = path
  .multiple = True
restraints_cif_file_name = None
  .type = path
  .multiple = True
include scope mmtbx.monomer_library.pdb_interpretation.grand_master_phil_str
""", process_includes=True)

def run(args):
  from libtbx.str_utils import show_string
  #
  master_phil = get_master_phil()
  import iotbx.phil
  input_objects = iotbx.phil.process_command_line_with_files(
    args=args,
    pdb_file_def="model_file_name",
    cif_file_def="restraints_cif_file_name",
    master_phil=master_phil)
  input_objects.work.show()
  work_params = input_objects.work.extract()
  #
  import mmtbx.monomer_library.server
  mon_lib_srv = mmtbx.monomer_library.server.server()
  ener_lib = mmtbx.monomer_library.server.ener_lib()
  for file_name in work_params.restraints_cif_file_name:
    print("Processing CIF file: %s" % show_string(file_name))
    af = any_file(file_name = file_name)
    for i, srv in enumerate([mon_lib_srv, ener_lib]):
      srv.process_cif_object(
        cif_object=af.file_object.model(),
        file_name=af.file_name,
        process_tor=not i)
  #
  import mmtbx.monomer_library.pdb_interpretation
  from libtbx.utils import Sorry
  processed_pdb_files = []
  for file_name in work_params.model_file_name:
    processed_pdb_file = mmtbx.monomer_library.pdb_interpretation.process(
      mon_lib_srv=mon_lib_srv,
      ener_lib=ener_lib,
      params=work_params.pdb_interpretation,
      file_name=file_name,
      strict_conflict_handling=work_params.strict_processing,
      substitute_non_crystallographic_unit_cell_if_necessary=True,
      max_atoms=work_params.max_atoms,
      log=sys.stdout)
    if (work_params.strict_processing):
      msg = processed_pdb_file.all_chain_proxies.fatal_problems_message()
      if (msg is not None):
        raise Sorry(msg)
    if (work_params.build_geometry_restraints_manager):
      processed_pdb_file.geometry_restraints_manager(
        params_edits=work_params.geometry_restraints.edits,
        params_remove=work_params.geometry_restraints.remove,
        )
    if (work_params.build_xray_structure):
      processed_pdb_file.xray_structure()
    processed_pdb_files.append(processed_pdb_file)
  print()
  if (   work_params.write_geo_files
      or work_params.write_tardy_geo_files):
    import os.path as op
    for processed_pdb_file in processed_pdb_files:
      acp = processed_pdb_file.all_chain_proxies
      source = acp.pdb_inp.source_info()
      assert source.startswith("file ")
      pdb_file_name = source[5:]
      sites_cart = acp.sites_cart_exact()
      site_labels = [atom.id_str() for atom in acp.pdb_atoms]
      def write_geo(label, geo, geo_file_name):
        from libtbx.utils import date_and_time
        header = "# %sgeometry restraints for file:\n" % label
        header += "#   %s\n# %s\n" % (show_string(pdb_file_name),
            date_and_time())
        geo.write_geo_file(
            sites_cart=sites_cart,
            site_labels=site_labels,
            file_name=geo_file_name,
            header=header)
      geo = processed_pdb_file.geometry_restraints_manager()
      if (work_params.write_geo_files):
        geo_file_name = op.basename(pdb_file_name) + ".geo"
        print("Writing file: %s" % show_string(geo_file_name))
        write_geo(label="", geo=geo, geo_file_name=geo_file_name)
        print()
      if (work_params.write_tardy_geo_files):
        geo_file_name = op.basename(pdb_file_name) + ".tardy.geo"
        print("Writing file: %s" % show_string(geo_file_name))
        tardy_tree = geo.construct_tardy_tree(sites_cart=sites_cart)
        reduced_geo = geo.reduce_for_tardy(tardy_tree=tardy_tree)
        write_geo(label="tardy ", geo=reduced_geo, geo_file_name=geo_file_name)
        print()
  return processed_pdb_files

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/pdbtools.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.pdbtools

from iotbx.cli_parser import run_program
from mmtbx.programs import pdbtools

run_program(pdbtools.Program)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/perigee.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.perigee
import os, sys
from math import sqrt

import iotbx
import iotbx.pdb

import libtbx
from libtbx import phil
import libtbx.phil.command_line
from libtbx.option_parser import OptionParser
#from libtbx.utils import Sorry
#from libtbx import runtime_utils

master_phil_string = """

perigee
  .caption = None
{
  input
  {
    pdb_file_name = None
      .type = path
      .short_caption = model
      .help = PDB filename
      .style = bold file_type:pdb
  }
  control
  {
    distance_cutoff = 3.
      .type = float
    chain = None
      .type = str
    other_chain = None
      .type = str
    residue = None
      .type = str
  }
  output
  {
    residues_only = False
      .type = bool
  }
}
"""
old = """
    file_name = None
      .type = path
      .short_caption = Output file
      .help = Defaults to current directory
      .style = bold new_file file_type:pdb
"""
master_params = master_phil_string # need for auto documentation
if 0:
  print('-'*80)
  print(master_phil_string)
  print('-'*80)
master_phil = phil.parse(master_phil_string)

def setup_parser():
  parser = OptionParser(
    prog="phenix.perigee",
    version="""
  up-to-date version
""",
    usage="""
  phenix.perigee pdb_file_name=pdb3a37.ent
""",
    )
  # Input options
  parser.add_option("",
                    "--show_defaults",
                    dest="show_defaults",
                    default=False,
                    action="store_true",
                    help="Display defaults",
                    )
  return parser

def get_chains(hierarchy, verbose=False):
  tmp = []
  for model in hierarchy.models():
    if verbose: print('model: "%s"' % model.id)
    for chain in model.chains():
      if verbose: print('chain: "%s"' % chain.id)
      if chain.id not in tmp: tmp.append(chain.id)
  return tmp

def get_het_residues(hierarchy):
  tmp = []
  for atom in hierarchy.atoms():
    if atom.hetero:
      if atom.parent().resname not in tmp:
        tmp.append(atom.parent().resname)
  return tmp

def get_distance2(atom1, atom2):
  d2 = (atom1.xyz[0]-atom2.xyz[0])**2
  d2 += (atom1.xyz[1]-atom2.xyz[1])**2
  d2 += (atom1.xyz[2]-atom2.xyz[2])**2
  return d2

def loop_over_residues_chain(hierarchy,
                             only_chain=None,
                             exclude_chain=None,
                             verbose=False,
                             ):
  #assert len(filter(None, [only_chain, exclude_chain]))==1
  for model in hierarchy.models():
    if verbose: print('model: "%s"' % model.id)
    for chain in model.chains():
      if(only_chain is not None and
         only_chain.strip()!=chain.id.strip()
         ): continue
      if(exclude_chain is not None and
         exclude_chain.strip()==chain.id.strip()
         ): continue
      if verbose: print('chain: "%s"' % chain.id)
      for resi, residue_group in enumerate(chain.residue_groups()):
        if verbose: print('  residue_group: resseq="%s" icode="%s"' % (
          residue_group.resseq, residue_group.icode))
        yield residue_group

def loop_over_residues_residue(hierarchy,
                               only_residue=None,
                               exclude_residue=None,
                               verbose=False,
                               ):
  assert len(list(filter(None, [only_residue, exclude_residue])))==1
  for model in hierarchy.models():
    if verbose: print('model: "%s"' % model.id)
    for chain in model.chains():
      if verbose: print('chain: "%s"' % chain.id)
      for resi, residue_group in enumerate(chain.residue_groups()):
        if verbose: print('  residue_group: resseq="%s" icode="%s"' % (
          residue_group.resseq, residue_group.icode))
        for atom_group in residue_group.atom_groups():
          if verbose: print('    atom_group: altloc="%s" resname="%s"' % (
            atom_group.altloc, atom_group.resname))
          if(only_residue is not None and
             only_residue.strip()!=atom_group.resname.strip()
             ): continue
          if(exclude_residue is not None and
             exclude_residue.strip()==atom_group.resname.strip()
             ): continue
          yield residue_group
          break

def get_interacting_atoms(hierarchy,
                          distance_cutoff=3.,
                          chain1=None,
                          chain2=None,
                          residue1=None,
                          residue2=None,
                          ):
  def _compare_residues(residue_1,
                        residue_2,
                        distance_cutoff=3.,
                        exclude_water=True,
                        ):
    distance_cutoff *= distance_cutoff
    atom_pairs = []
    atom1 = residue_1.atoms()[0]
    atom2 = residue_2.atoms()[0]
    d2 = get_distance2(atom1, atom2)
    if d2>distance_cutoff*100: return atom_pairs
    if exclude_water:
      if atom1.quote().find("HOH")!=-1: return []
      if atom2.quote().find("HOH")!=-1: return []
    for atom1 in residue_1.atoms():
      for atom2 in residue_2.atoms():
        d2 = get_distance2(atom1, atom2)
        if d2<distance_cutoff:
          atom_pairs.append([atom1, atom2])
    return atom_pairs
  ###################
  if chain1:
    assert residue1 is None
    assert residue2 is None
  elif residue1:
    assert chain1 is None
    assert chain2 is None

  atom_pairs = []
  if chain1:
    for i, residue_1 in enumerate(loop_over_residues_chain(
        hierarchy,
        only_chain=chain1,
        )
                                  ):
      for j, residue_2 in enumerate(loop_over_residues_chain(
          hierarchy,
          only_chain=chain2,
          exclude_chain=chain1,
          )
                                    ):
        tmp = _compare_residues(residue_1,
                                residue_2,
                                distance_cutoff=distance_cutoff,
                                )
        atom_pairs += tmp
  else:
    for i, residue_1 in enumerate(loop_over_residues_residue(
        hierarchy,
        only_residue=residue1,
        )
                                  ):
      for j, residue_2 in enumerate(loop_over_residues_residue(
          hierarchy,
          exclude_residue=residue1,
          )
                                    ):
        tmp = _compare_residues(residue_1,
                                residue_2,
                                distance_cutoff,
                                )
        atom_pairs += tmp
  return atom_pairs

def run_probe_on_pdb_string(pdb_filename):
  cmd = 'phenix.probe -u -condense -self -mc -NOVDWOUT -NOCLASHOUT ALL -'
  assert 0

def run(rargs):
  print("""

    Running interaction finder

  """)
  rargs = list(rargs)
  parser = setup_parser()
  (options, args) = parser.parse_args(args=rargs)
  if options.show_defaults:
    for line in master_phil_string.splitlines():
      if line.strip().find(".")==0: continue
      print(line)
    sys.exit()
  if len(args)==0:
    parser.print_help()
    sys.exit()
  #
  argument_interpreter = libtbx.phil.command_line.argument_interpreter(
    master_phil=master_phil,
    home_scope="perigee")
  #
  phils = []
  phil_args = []
  pdbs = []
  for arg in args:
    if os.path.isfile(arg):
      if iotbx.pdb.is_pdb_file(arg):
        pdbs.append(arg)
        continue
      try :
        file_phil = phil.parse(file_name=arg)
      except RuntimeError :
        pass
      else :
        phils.append(file_phil)
    else :
      phil_args.append(arg)
      phils.append(argument_interpreter.process(arg))
  working_phil = master_phil.fetch(sources=phils)
  #working_phil.show()
  working_params = working_phil.extract()
  in_scope = working_params.perigee.input
  control_scope = working_params.perigee.control
  output_scope = working_params.perigee.output

  for i, pdb in enumerate(pdbs):
    if i==0 and not in_scope.pdb_file_name:
      in_scope.pdb_file_name = pdbs[i]
  #
  #if not output_scope.file_name:
  #  output_scope.file_name = in_scope.pdb_file_name
  #  d = os.path.dirname(output_scope.file_name)
  #  output_scope.file_name = os.path.basename(output_scope.file_name)
  #  output_scope.file_name = output_scope.file_name.split(".")[0]
  #  if True:
  #    output_scope.file_name += "_loaded.pdb"
  #  else:
  #    output_scope.file_name += "_%s.pdb" % os.path.basename(
  #      in_scope.carbohydrate_file_name).split(".")[0]
  #  output_scope.file_name = os.path.join(d, output_scope.file_name)
  #
  #preamble = output_scope.file_name.split(".")[0]
  #print "    Writing effective parameters to %s.eff\n" % preamble
  working_phil.format(python_object=working_params).show()
  #f=open("%s.eff" % preamble, "wb")
  #f.write(working_phil.format(python_object=working_params).as_str())
  #f.close()

  pdb_inp = iotbx.pdb.input(in_scope.pdb_file_name,
                            #source_info="model PDB",
                            #lines=flex.split_lines(input_lines),
                            )
  hierarchy = pdb_inp.construct_hierarchy()
  #hierarchy.show()

  if control_scope.chain and control_scope.residue:
    assert 0
  elif control_scope.chain is None and control_scope.residue is None:
    if control_scope.chain is None:
      chains = get_chains(hierarchy)
      print("\n  Chains")
      for chain in chains:
        print('    "%s"' % chain)
    if control_scope.residue is None:
      print("Residues that may be of interest")
      residues = get_het_residues(hierarchy)
      for residue in residues:
        print('    "%s"' % residue)
    return

  def display_atom_pairs(atom_pairs, residues_only=False):
    def _comp_on_d2(pair1, pair2):
      d21 = get_distance2(pair1[0], pair1[1])
      d22 = get_distance2(pair2[0], pair2[1])
      if d21<d22: return -1
      return 1
    ##########
    atom_pairs.sort(_comp_on_d2)
    outl = ""
    done = []
    for atom1, atom2 in atom_pairs:
      key = None
      if residues_only:
        key = [atom1.quote()[17:27],
               atom2.quote()[17:27],
               ]
        if key in done: continue
      d2 = get_distance2(atom1, atom2)
      if residues_only:
        outl += "%s - %s : %6.1f\n" % (atom1.quote()[17:27],
                                       atom2.quote()[17:27],
                                       sqrt(d2),
                                       )
      else:
        outl += "%s - %s : %6.1f\n" % (atom1.quote(),
                                       atom2.quote(),
                                       sqrt(d2),
                                       )
      if residues_only: done.append(key)
    print(outl)

  if control_scope.chain:
    atom_pairs = get_interacting_atoms(
      hierarchy,
      distance_cutoff=control_scope.distance_cutoff,
      chain1=control_scope.chain,
      chain2=control_scope.other_chain,
      )
  elif control_scope.residue:
    atom_pairs = get_interacting_atoms(
      hierarchy,
      distance_cutoff=control_scope.distance_cutoff,
      residue1=control_scope.residue,
      )
  print('-'*80)
  if output_scope.residues_only:
    display_atom_pairs(atom_pairs, residues_only=True)
  else:
    display_atom_pairs(atom_pairs)
  print('-'*80)

if __name__=="__main__":
  args = sys.argv[1:]
  del sys.argv[1:]
  run(args)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/plan_sad_experiment.py
from __future__ import absolute_import, division, print_function
import mmtbx.scaling.plan_sad_experiment
from mmtbx.scaling.plan_sad_experiment import get_fp_fdp, get_residues_and_ha
import iotbx.phil
from libtbx.utils import Sorry, null_out
from libtbx import runtime_utils
from libtbx import Auto
import os.path
import sys
from six.moves import range

master_params = """
include scope libtbx.phil.interface.tracking_params
input_files {
    data = None
      .type = path
      .help = Data file (I or I+ and I- or F or F+ and F-).  \
         Any standard format is fine.
      .short_caption = Data file
      .style = bold file_type:hkl input_file process_hkl child:fobs:data_labels\
        child:space_group:space_group child:unit_cell:unit_cell anom
    data_labels = None
      .type = str
      .input_size = 160
      .help = Optional label specifying which columns of anomalous data to use.\
        Not necessary if your input file has only one set of anomalous data.
      .short_caption = Data label
      .style = bold renderer:draw_fobs_label_widget
}
crystal_info {
  resolution = None
    .type = float
    .help = High-resolution limit.  \
       Either a high-resolution limit or a \
       (Wilson) b_value or both is required
    .short_caption = High-resolution limit
    .style = resolution
   .input_size = 64

  b_value = None
    .type = float
    .help = Estimated Wilson B-value for the dataset. \
       Either a high-resolution limit or a \
       (Wilson) b_value or both is required

  b_value_anomalous = None
    .type = float
    .help = Estimated Wilson B-value for the anomalously-scattering atoms. \
       Normally leave as None and it will be estimated from b_value.

  seq_file = None
    .type = path
    .help = "Optional sequence file (1-letter code)."
             "Separate chains with a blank line or line starting with &gt;."
    .short_caption = Sequence file
    .style = bold file_type:seq input_file

  chain_type = *PROTEIN RNA DNA
    .type = choice
    .short_caption = Chain type
    .help = Chain type (PROTEIN RNA DNA). This is used to estimate the \
            number of atoms from the number of residues

  ncs_copies = None
    .type = int
    .short_caption = NCS copies
    .help = Optional estimate of NCS copies in your crystals (only used if \
            a data file is supplied).
   .input_size = 64

  solvent_fraction = None
    .type = float
    .short_caption = Solvent fraction
    .help = Optional estimate of solvent fraction in your crystals (0 to 1)
   .input_size = 64

  residues = None
    .type = int
    .short_caption = Number of residues
    .help = The number of residues in the molecule or asymmetric unit. \
          Note that it is the ratio of residues to anomalously-scattering \
          atoms that matters.
    .input_size = 64

  atom_type = None
    .type = str
    .short_caption = Anomalously-scattering atom
    .help = Optional name of anomalously-scattering atom.  If supplied, \
            you also need to supply the wavelength for X-ray data \
            collection.  If not supplied, then you need to supply a \
            value for f_double_prime.
    .style = renderer:draw_phaser_scatterer_widget
    .input_size = 64

  number_of_s = None
    .type = int
    .short_caption = Number of S atoms
    .help = You can specify the number of S atoms in the asymmetric unit. \
            Only used if include_weak_anomalous_scattering=True.  If not \
            set, the number is guessed from the sequence file if present.
  f_double_prime = None
    .type = float
    .short_caption = F-double-prime
    .help = F-double-prime value for the anomalously-scattering atom. \
            Alternatively you can specify the atom type and wavelength.
    .input_size = 64

  wavelength = None
    .type = float
    .short_caption = Wavelength
    .help = Wavelength for X-ray data collection.  If supplied, also \
            specify the atom_type. \
            Alternatively you can specify the value of f_double_prime
    .input_size = 64

  sites = None
    .type = int
    .short_caption = Number of anomalously-scattering atoms
    .help = The number of anomalously-scattering atoms in the molecule \
          or asymmetric unit. \
          Note that it is the ratio of residues to anomalously-scattering \
          atoms that matters.
    .input_size = 64

  sites_min = None
    .type = int
    .short_caption = Low bound for sites
    .help = If you set sites_min and sites_max and not sites the sites will\
            be varied from sites_min to sites_max
    .input_size = 64

  sites_max = None
    .type = int
    .short_caption = Upper bound for sites
    .help = If you set sites_min and sites_max and not sites the sites will\
            be varied from sites_min to sites_max
    .input_size = 64

  occupancy = 1
    .type = float
    .short_caption = Occupancy of anomalously-scattering atoms
    .help = Estimate of occupancy of anomalously-scattering atoms


   }
   i_over_sigma = None
     .type = float
     .short_caption = I/sigI
     .help = Optional I/sigI.  If supplied, \
        the expected values of half-dataset correlation and cc*_ano based \
        on this I/sigI be calculated.

   max_i_over_sigma = 100
     .type = float
     .short_caption = Maximum I/sigI
     .help = Limit search of necessary I/sigI to less than this value.  \
             You might increase this if you plan to do a very careful or very \
             high-multiplicity experiment.

   i_over_sigma_range_low = None
     .type = float
     .short_caption = Lower range for i_over_sigma
     .help = If you set i_over_sigma_range_low and i_over_sigma_range_high \
         then the value of i_over_sigma will be varied between these limits

   i_over_sigma_range_high = None
     .type = float
     .short_caption = Upper range for i_over_sigma
     .help = If you set i_over_sigma_range_low and i_over_sigma_range_high \
         then the value of i_over_sigma will be varied between these limits

   steps = 20
     .type = int
     .short_caption = Steps
     .help = Number of steps for sampling ranges (i.e., i_over_sigma_low to \
        i_over_sigma_high)

   min_in_bin = 50
     .type = int
     .short_caption = Minimum point per bin
     .help = Minimum data points per bin in Bayesian estimation. Higher values \
             smooth the predictor.

   target_signal = 30.
       .type = float
       .short_caption = Target anomalous signal
       .help = The anomalous signal that you would like to obtain. \
               The value of I/sigma will be adjusted to obtain this signal.\
               Typically you will need a signal of 15-30 so solve the \
               substructure.
   min_cc_ano = 0.15
     .type = float
     .short_caption = Target minimum anomalous correlation
     .help = You can set the target minimum (true) anomalous correlation \
             (CC*_ano). This value affects the phasing accuracy after \
             the substructure is determined.

   ideal_cc_anom = 0.75
     .type = float
     .short_caption = Anomalous correlation with perfect data
     .help = The ideal_cc_anom is the expected anomalous \
             correlation between an accurate model with isotropic anomalous \
             scatterers and perfectly-measured data. The ideal_cc_anom is  \
             determined empirically.  It is typically not unity because \
             anomalous scatterers may have multiple locations with low \
             occupancy or may be non-isotropic. A value of about 0.75 \
             is a reasonable guess.

   include_weak_anomalous_scattering = Auto
     .type = bool
     .short_caption = Include weak anomalous scattering
     .help = At longer wavelengths the scattering of C, N, and O become \
             significant relative to S. Default is to consider the \
             scattering from C, N, O as noise.  Additionally, \
             (see intrinsic_scatterers_as_noise) if intrinsic \
             anomalous scatterers (P and S) are weak, they will be counted \
             as noise.  This weak anomalous scattering is effectively noise \
             and has the same effect as the ideal_cc_anom but it can be \
             calculated from the composition. Its effects are added to those \
             modeled by the ideal_cc_anom parameter. Default is to include \
             weak anomalous scattering if a sequence file or the number of \
             sulfurs is provided

   intrinsic_scatterers_as_noise = None
     .type = bool
     .short_caption = Intrinsic scatterers as noise
     .help = Applies if include_weak_anomalous_scattering=True.\
             You can choose to treat any intrinsic scatterers (S for \
             protein, P for nucleic acid) as noise, just like any \
             contributions from C, N, or O atoms. This is default if \
             anomalous scattering (f-double-prime) from these atoms is \
             less than half that of your specified anomalous scatterer. \
             Alternatively these atoms are excluded from the noise \
             calculation and are assumed to be included in the \
             number of sites you specify.

   bayesian_updates = False
     .type = bool
     .short_caption = Bayesian updates
     .help = Use Bayesian updates of half-dataset CC and signal. First \
             predict these values using standard approach, then use empirical \
             half-dataset CC and signal for a training set of datasets to \
             re-estimate these values.  This helps correct for typical errors \
             in measurement and typical resolution-dependent effects.\
             Note that if you use bayesian_updates=True then the predictions \
             may not vary smoothly with resolution or changes in parameters.

   control {
      fixed_resolution = False
        .type = bool
        .help = Only run calculation at high_resolution limit
        .short_caption = Run at high_resolution only

      show_summary = False
        .type = bool
        .help = Show summary only
        .short_caption = Show summary only

      verbose = False
        .type = bool
        .help = '''Verbose output'''
        .short_caption = Verbose output
   }
"""
master_phil = iotbx.phil.parse(master_params, process_includes=True)

def get_params(args,out=sys.stdout):
  command_line = iotbx.phil.process_command_line_with_files(
    args=args,
    master_phil=master_phil,
    reflection_file_def="input_files.data",
    seq_file_def="crystal_info.seq_file")
  params = command_line.work.extract()
  print("\nPlan a SAD experiment\n", file=out)
  master_phil.format(python_object=params).show(out=out)
  return params

def setup_params(params, out):
  if not params.crystal_info.wavelength:
    raise Sorry("Please supply a wavelength for data collection.")
  if not params.crystal_info.atom_type:
    raise Sorry(
      "Please supply an atom_type for the anomalously-scattering atom.")
  if not params.crystal_info.f_double_prime:
     fp_fdp=get_fp_fdp(
      atom_type=params.crystal_info.atom_type,
      wavelength=params.crystal_info.wavelength,out=out)
     if fp_fdp is not None:
       params.crystal_info.f_double_prime=fp_fdp.fdp()
     else:
       raise Sorry(
        "Please specify f_double_prime as the wavelength %7.2f A is" %(
         params.crystal_info.wavelength)+
         "\nout of range of the Sasaki tables used here.")

  if params.crystal_info.solvent_fraction and \
     params.crystal_info.solvent_fraction > 1.01:
    raise Sorry("Solvent fraction should be from 0 to 1")

  if params.crystal_info.seq_file and \
       os.path.isfile(params.crystal_info.seq_file):
    residues,sites,number_of_s,solvent_fraction,ncs_copies=get_residues_and_ha(
      seq_file=params.crystal_info.seq_file,
      atom_type=params.crystal_info.atom_type,
      chain_type=params.crystal_info.chain_type,
      solvent_fraction=params.crystal_info.solvent_fraction,
      data=params.input_files.data,
      ncs_copies=params.crystal_info.ncs_copies,
      out=out)
    if not params.crystal_info.residues:
      print("Number of residues based on sequence file: %d" %(
        residues), file=out)
      params.crystal_info.residues=residues
    if not params.crystal_info.number_of_s:
      print("Number of S atoms based on sequence file: %d" %(
        number_of_s), file=out)
      params.crystal_info.number_of_s=number_of_s

    if not params.crystal_info.sites:
      print("Number of sites for anomalously-scattering atom "+\
        "based on sequence file: %d" %( sites), file=out)
      params.crystal_info.sites=sites

    if ncs_copies and not params.crystal_info.ncs_copies:
      print("NCS copies "+\
        "based on sequence file and data : %d" %( ncs_copies), file=out)
      params.crystal_info.ncs_copies=ncs_copies

    if solvent_fraction and not params.crystal_info.solvent_fraction:
      print("Solvent fraction "+\
        "based on sequence file and data : %5.2f" %( solvent_fraction), file=out)
      params.crystal_info.solvent_fraction=solvent_fraction

  else:
    if params.crystal_info.number_of_s is None and \
         params.include_weak_anomalous_scattering is True:
      raise Sorry("Sorry need a sequence file or number_of_s if "+
        "\ninclude_weak_anomalous_scattering=True")
    elif params.crystal_info.number_of_s is None and \
         params.include_weak_anomalous_scattering is Auto:
      print("Note: not applying include_weak_anomalous_scattering as"+\
        " no sequence \nfile or number_of_s are supplied", file=out)
      params.include_weak_anomalous_scattering=False

  if params.crystal_info.solvent_fraction is None:
    params.crystal_info.solvent_fraction=0.50  # just guess

  if not params.crystal_info.residues:
    raise Sorry("Please specify number of residues (residues=500) or a sequence file")
  if params.crystal_info.sites:
    pass # OK
  elif (params.crystal_info.sites_min and params.crystal_info.sites_max):
    pass # OK
  else:
    raise Sorry(
      "Please specify number of sites or a sequence file and atom_type")


class result_table:
  def __init__(self):
    self.table_rows=[]
    self.table_header=[]
    self.number_of_columns=0

  def add_table_header(self,header): # must be first
    self.table_header=header
    self.number_of_columns=len(header)

  def add_table_row(self,row):
    assert self.table_header and len(row)==len(self.table_header)
    self.table_rows.append(row)

  def get_formats(self,buffer=0):
    self.widths=[]
    self.formats=[]
    for i in range(self.number_of_columns):
      w=len(self.table_header[i])
      for tr in self.table_rows:
        w=max(w,len(tr[i]))
      self.widths.append(w)
      self.formats.append("%s%ss" %("%",w+buffer))

  def show_summary(self,buffer=3,gui_output=False,out=sys.stdout):
    assert not gui_output # not implemented yet
    self.get_formats(buffer=buffer)
    for i in range(self.number_of_columns):
      print(self.formats[i] %(self.table_header[i]), end=' ', file=out)
    print(file=out)

    for tr in self.table_rows:
      for i in range(self.number_of_columns):
        print(self.formats[i] %(tr[i]), end=' ', file=out)
      print(file=out)

def run(args,params=None,return_plan=False,out=sys.stdout):
  # NOTE: can call with params and skip reading any files.
  if not params:
    params=get_params(args,out=out)

  setup_params(params, out=out)

  if params.crystal_info.sites_min and params.crystal_info.sites_max:
    return run_varying_sites(params,out=out)
  elif params.i_over_sigma_range_low and params.i_over_sigma_range_high:
    return run_varying_i_over_sigma(params,out=out)
  else:
    return run_with_params(params,out=out)

def run_varying_i_over_sigma(params,out=sys.stdout):
  from copy import deepcopy
  local_params=deepcopy(params)
  local_params.i_over_sigma_range_low=None
  local_params.i_over_sigma_range_high=None
  local_params.control.fixed_resolution=True

  local_params.control.show_summary=True
  t=result_table()
  t.add_table_header([
     "I/sigI",
     "cc_half",
     "cc*_anom",
     "Signal",
     "p(Substr)",
     "FOM",
   ])

  delta=max(0.001,
    (params.i_over_sigma_range_high-params.i_over_sigma_range_low)/max(1,
     params.steps))
  i_over_sigma=params.i_over_sigma_range_low
  while i_over_sigma <= params.i_over_sigma_range_high+0.01:
    local_params.i_over_sigma=i_over_sigma
    plan=run_with_params(local_params,quiet=True,out=out)
    [dmin,nsites,nrefl,fpp,local_i_over_sigma,
        sigf,cc_half_weak,cc_half,cc_ano_weak,cc_ano,s_ano,solved,fom]=\
      plan.representative_values
    t.add_table_row([
        "%6.2f" % (i_over_sigma),
        "%6.3f" % (cc_half),
        "%6.3f" % ( cc_ano),
        "%5.2f" % ( s_ano),
        "%5.2f" % (solved),
        "%4.3f" % (fom),
      ])
    i_over_sigma+=delta

  plan.show_characteristics(out=out)
  print("\nExpected data utility varying the value of overall I/sigI", file=out)
  t.show_summary(out=out)

def run_varying_sites(params,out=sys.stdout):
  if not params.i_over_sigma:
    raise Sorry("For varying sites you need to set i_over_sigma")
  from copy import deepcopy
  local_params=deepcopy(params)
  local_params.crystal_info.sites_min=None
  local_params.crystal_info.sites_max=None
  local_params.control.show_summary=True
  local_params.control.fixed_resolution=True
  t=result_table()
  t.add_table_header([
     "Sites",
     "cc_half",
     "cc*_anom",
     "Signal",
     "p(Substr)",
     "FOM",
   ])

  if params.crystal_info.sites_min>params.crystal_info.sites_max:
    raise Sorry("Please set sites_min < sites_max")
  for sites in range(params.crystal_info.sites_min,
     params.crystal_info.sites_max+1):
    local_params.crystal_info.sites=sites
    plan=run_with_params(local_params,quiet=True,out=out)
    [dmin,nsites,nrefl,fpp,local_i_over_sigma,
        sigf,cc_half_weak,cc_half,cc_ano_weak,cc_ano,s_ano,solved,fom]=\
      plan.representative_values
    t.add_table_row([
        "%3d" % (nsites),
        "%6.3f" % (cc_half),
        "%6.3f" % ( cc_ano),
        "%5.2f" % ( s_ano),
        "%5.1f" % (solved),
        "%4.3f" % (fom),
      ])
  plan.show_characteristics(out=out)

  print("\nExpected data utility varying the number of sites", file=out)
  t.show_summary(out=out)


def run_with_params(params,quiet=False,out=sys.stdout):
  plan=mmtbx.scaling.plan_sad_experiment.estimate_necessary_i_sigi(
    chain_type=params.crystal_info.chain_type,
    residues=params.crystal_info.residues,
    number_of_s=params.crystal_info.number_of_s,
    solvent_fraction=params.crystal_info.solvent_fraction,
    nsites=params.crystal_info.sites,
    wavelength=params.crystal_info.wavelength,
    atom_type=params.crystal_info.atom_type,
    fpp=params.crystal_info.f_double_prime,
    target_s_ano=params.target_signal,
    i_over_sigma=params.i_over_sigma,
    max_i_over_sigma=params.max_i_over_sigma,
    min_cc_ano=params.min_cc_ano,
    min_in_bin=params.min_in_bin,
    data=params.input_files.data,
    data_labels=params.input_files.data_labels,
    resolution=params.crystal_info.resolution,
    b_value=params.crystal_info.b_value,
    b_value_anomalous=params.crystal_info.b_value_anomalous,
    fixed_resolution=params.control.fixed_resolution,
    occupancy=params.crystal_info.occupancy,
    ideal_cc_anom=params.ideal_cc_anom,
    bayesian_updates=params.bayesian_updates,
    include_weak_anomalous_scattering=params.include_weak_anomalous_scattering,
    intrinsic_scatterers_as_noise=params.intrinsic_scatterers_as_noise,)
  if quiet:
    return plan
  elif params.control.show_summary:
    plan.show_summary()
  else:
    return plan.show(out=out)

def validate_params(params):
  return setup_params(params, out=null_out())

class launcher(runtime_utils.target_with_save_result):
  def run(self):
    return run(self.args, out=sys.stdout)

def finish_job(result):
  return ([], [])

if __name__=="__main__":
  run(sys.argv[1:])



 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/polder.py
# LIBTBX_SET_DISPATCHER_NAME phenix.polder
from __future__ import absolute_import, division, print_function

from iotbx.cli_parser import run_program
from mmtbx.programs import polder

if __name__ == '__main__':
  run_program(program_class=polder.Program)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/prepare_pdb_deposition.py
from __future__ import absolute_import, division, print_function

from iotbx.cli_parser import run_program
from mmtbx.programs import prepare_pdb_deposition

if __name__ == '__main__':
  run_program(program_class=prepare_pdb_deposition.Program)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/probe2.py
from __future__ import absolute_import, division, print_function

from iotbx.cli_parser import run_program
from mmtbx.programs import probe2

if __name__ == "__main__":
  run_program(probe2.Program)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/probescore_ligand.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME molprobity.probescore_ligand

import sys
from libtbx.utils import multi_out, show_total_time
from iotbx.cli_parser import CCTBXParser

from mmtbx.programs import probescore_ligand

def custom_args_proc(cli_parser):
  """
  This is going to put inselection positional argument into phil scope of the
  program.
  Useful things are:
  cli_parser.namespace
  cli_parser.data_manager
  cli_parser.namespace.unknown - where these argument is going to be
  cli_parser.working_phil
  """
  wf = cli_parser.working_phil.extract()

  if len(cli_parser.namespace.unknown) > 0:
    # print("What is unknown: %s" % cli_parser.namespace.unknown)
    # print("Curr selection: '%s'" % wf.atom_selection_program.inselection)
    wf.atom_selection_program.inselection = cli_parser.namespace.unknown
    cli_parser.namespace.unknown = []
  cli_parser.working_phil = cli_parser.master_phil.format(python_object=wf)

def run(args):
  # create parser
  logger = multi_out()
  logger.register('stderr', sys.stderr)
  logger2 = multi_out()
  logger2.register('stdout', sys.stdout)

  parser = CCTBXParser(
    program_class = probescore_ligand.Program,
    custom_process_arguments = custom_args_proc,
    logger=logger)

  namespace = parser.parse_args(sys.argv[1:])

  # start program
  print('Starting job', file=logger)
  print('='*79, file=logger)

  task = probescore_ligand.Program(
      parser.data_manager, parser.working_phil.extract(),
      master_phil=parser.master_phil,
      logger=logger)

  # validate inputs
  task.validate()

  # run program
  task.run()

  # stop timer
  print('', file=logger)
  print('='*79, file=logger)
  print('Job complete', file=logger)
  show_total_time(out=logger)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/process_predicted_model.py
# LIBTBX_SET_DISPATCHER_NAME mmtbx.process_predicted_model
# LIBTBX_SET_DISPATCHER_NAME phenix.process_predicted_model
from __future__ import division, print_function

from iotbx.cli_parser import run_program
from mmtbx.programs import process_predicted_model

if __name__ == '__main__':
  run_program(program_class=process_predicted_model.Program)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/prune_model.py

# TODO trim sidechains one atom at a time

from __future__ import absolute_import, division, print_function
from libtbx.str_utils import make_header
from libtbx.utils import multi_out
from libtbx import group_args
import os
import sys
from six.moves import range

model_prune_master_phil = """
  resolution_factor = 1/4.
    .type = float
    .help = Map grid spacing (multiplied times d_min).
  sidechains = True
    .type = bool
    .help = Remove poor sidechains
  mainchain = False
    .type = bool
    .help = Remove entire residues in poor density
  min_backbone_2fofc = 0.8
    .type = float
    .help = Minimum 2mFo-DFc sigma level at C-alpha to keep.  Residues with \
      C-alpha in density below this cutoff will be deleted.
  min_backbone_fofc = -3.0
    .type = float
    .help = Maximum mFo-DFc sigma level at C-alpha to keep.  Residues with \
      C-alpha in difference density below this cutoff will be deleted.
  min_sidechain_2fofc = 0.6
    .type = float
    .help = Minimum mean 2mFo-DFc sigma level for sidechain atoms to keep. \
      Residues with sidechains below this level will be truncated.
  max_sidechain_fofc = -2.8
    .type = float
    .help = Maximum mean 2mFo-DFc sigma level for sidechain atoms to keep. \
      Residues with sidechains below this level will be truncated.
  min_cc = 0.7
    .type = float
    .help = Minimum overall CC for entire residue to keep.
  min_cc_sidechain = 0.6
    .type = float
    .help = Minimum overall CC for sidechains to keep.
  min_fragment_size = 3
    .type = int
    .help = Minimum fragment size to keep.  Fragments smaller than this will \
      be deleted in the final step (based on the assumption that the adjacent \
      residues were already removed).  Set this to None to prevent fragment \
      filtering.
  check_cgamma = True
    .type = bool
    .help = Check for poor density at the C-gamma atom for long sidechains.  \
      Useful in cases where the terminal atoms may have been misfit into \
      nearby density.
"""

def get_master_phil():
  from mmtbx.command_line import generate_master_phil_with_inputs
  return generate_master_phil_with_inputs(
    enable_automatic_twin_detection=True,
    phil_string="""
prune {
  %s
}
output {
  file_name = None
    .type = path
}
""" % model_prune_master_phil)

def id_str(chain, residue_group, atom_group):
  return "%3s %s%4s%s" % (atom_group.resname, chain.id, residue_group.resseq,
    residue_group.icode)

class residue_summary(object):
  def __init__(self,
                chain_id,
                residue_group,
                atom_group,
                score,
                score_type="CC",
                map_type="2mFo-DFc",
                atoms_type="residue"):
    self.resname = atom_group.resname
    self.chain_id = chain_id
    self.resseq = residue_group.resseq
    self.icode = residue_group.icode
    self.score = score
    self.score_type = score_type
    self.atoms_type = atoms_type
    self.map_type = map_type

  def show(self, out=None):
    if (out is None) : out = sys.stdout
    id_str = "%3s %s%4s%s" % (self.resname, self.chain_id, self.resseq,
      self.icode)
    if (self.score is not None):
      print("%s : %s %s %s = %.2f" % (id_str, self.atoms_type,
        self.map_type, self.score_type, self.score), file=out)
    else :
      print("%s : not part of a continuous chain" % id_str, file=out)

class prune_model(object):
  def __init__(self,
                f_map_coeffs,
                diff_map_coeffs,
                model_map_coeffs,
                pdb_hierarchy,
                params):
    """
    Removes atoms with poor electron density, as judged by several sigma-level
    cutoffs and overall CC.  This is basically an attempt to apply the same
    visual intuition we use when editing in Coot (etc.).
    """
    # XXX or, viewed a different way, this is one giant hack.  need to make
    # the logic smarter!
    assert (len(pdb_hierarchy.models()) == 1)
    from mmtbx.real_space_correlation import set_detail_level_and_radius
    from cctbx import maptbx
    from scitbx.array_family import flex
    self.params = params
    self.pdb_hierarchy = pdb_hierarchy
    self.unit_cell = f_map_coeffs.unit_cell()
    f_map_fft = f_map_coeffs.fft_map(resolution_factor=params.resolution_factor)
    self.f_map = f_map_fft.apply_sigma_scaling().real_map()
    diff_map_fft = diff_map_coeffs.fft_map(
      resolution_factor=params.resolution_factor)
    self.diff_map = diff_map_fft.apply_sigma_scaling().real_map()
    model_map_fft = model_map_coeffs.fft_map(
      resolution_factor=params.resolution_factor)
    self.model_map = model_map_fft.apply_sigma_scaling().real_map()
    detail, self.atom_radius = \
      set_detail_level_and_radius(
        detail="automatic",
        d_min=f_map_coeffs.d_min(),
        atom_radius=None)

  def get_map_stats_for_atoms(self, atoms):
    from cctbx import maptbx
    from scitbx.array_family import flex
    sites_cart = flex.vec3_double()
    sites_cart_nonH = flex.vec3_double()
    values_2fofc = flex.double()
    values_fofc = flex.double()
    for atom in atoms :
      sites_cart.append(atom.xyz)
      if (not atom.element.strip() in ["H","D"]) : #XXX trap: neutrons?
        sites_cart_nonH.append(atom.xyz)
        site_frac = self.unit_cell.fractionalize(atom.xyz)
        values_2fofc.append(self.f_map.eight_point_interpolation(site_frac))
        values_fofc.append(self.diff_map.eight_point_interpolation(site_frac))
    if (len(sites_cart_nonH) == 0):
      return None
    sel = maptbx.grid_indices_around_sites(
      unit_cell=self.unit_cell,
      fft_n_real=self.f_map.focus(),
      fft_m_real=self.f_map.all(),
      sites_cart=sites_cart,
      site_radii=get_atom_radii(atoms, self.atom_radius))
    f_map_sel = self.f_map.select(sel)
    model_map_sel = self.model_map.select(sel)
    diff_map_sel = self.diff_map.select(sel)
    cc = flex.linear_correlation(x=f_map_sel, y=model_map_sel).coefficient()
    return group_args(cc=cc,
      mean_2fofc=flex.mean(values_2fofc),
      mean_fofc=flex.mean(values_fofc))

  def get_density_at_atom(self, atom):
    site_frac = self.unit_cell.fractionalize(site_cart=atom.xyz)
    two_fofc_value = self.f_map.eight_point_interpolation(site_frac)
    fofc_value = self.diff_map.eight_point_interpolation(site_frac)
    return group_args(two_fofc=two_fofc_value, fofc=fofc_value)

  def process_residues(self, out=None):
    if (out is None):
      out = sys.stdout
    n_res_removed = 0
    n_sc_removed = 0
    n_res_protein = 0
    pruned = []
    make_header("Pruning residues and sidechains", out=out)
    for chain in self.pdb_hierarchy.models()[0].chains():
      if (not chain.is_protein()):
        continue
      residue_id_hash = {}
      removed_resseqs = []
      if (len(chain.conformers()) > 1):
        print("WARNING: chain '%s' has multiple conformers" % chain.id, file=out)
      for j_seq, residue_group in enumerate(chain.residue_groups()):
        n_res_protein += 1
        residue_id_hash[residue_group.resid()] = j_seq
        for atom_group in residue_group.atom_groups():
          ag_id_str = id_str(chain, residue_group, atom_group)
          resname = atom_group.resname
          remove_atom_group = False
          sidechain_atoms = []
          backbone_atoms = []
          for atom in atom_group.atoms():
            if (atom.name.strip() in ["N", "O", "C", "H", "CA", "CB"]):
              backbone_atoms.append(atom)
            elif (not atom_group.resname in ["ALA", "GLY"]):
              sidechain_atoms.append(atom)
          if (len(backbone_atoms) > 0) and (self.params.mainchain):
            mc_stats = self.get_map_stats_for_atoms(backbone_atoms)
            if (mc_stats.mean_2fofc < self.params.min_backbone_2fofc):
              pruned.append(residue_summary(
                chain_id=chain.id,
                residue_group=residue_group,
                atom_group=atom_group,
                score=mc_stats.mean_2fofc,
                score_type="sigma",
                atoms_type="C-alpha"))
              remove_atom_group = True
            elif (mc_stats.mean_fofc < self.params.min_backbone_fofc):
              pruned.append(residue_summary(
                chain_id=chain.id,
                residue_group=residue_group,
                atom_group=atom_group,
                score=mc_stats.mean_fofc,
                score_type="sigma",
                atoms_type="C-alpha"))
              remove_atom_group = True
          # map values look okay - now check overall CC
          if (not remove_atom_group):
            res_stats = self.get_map_stats_for_atoms(atom_group.atoms())
            if (res_stats.cc < self.params.min_cc) and (self.params.mainchain):
              pruned.append(residue_summary(
                chain_id=chain.id,
                residue_group=residue_group,
                atom_group=atom_group,
                score=res_stats.cc))
              remove_atom_group = True
            elif (len(sidechain_atoms) > 0) and (self.params.sidechains):
              # overall CC is acceptable - now look at sidechain alone
              remove_sidechain = False
              sc_stats = self.get_map_stats_for_atoms(sidechain_atoms)
              if (sc_stats is None):
                continue
              if (sc_stats.cc < self.params.min_cc_sidechain):
                pruned.append(residue_summary(
                  chain_id=chain.id,
                  residue_group=residue_group,
                  atom_group=atom_group,
                  score=sc_stats.cc,
                  atoms_type="sidechain"))
                remove_sidechain = True
              else :
                if (sc_stats.mean_2fofc < self.params.min_sidechain_2fofc):
                  pruned.append(residue_summary(
                    chain_id=chain.id,
                    residue_group=residue_group,
                    atom_group=atom_group,
                    score=sc_stats.mean_2fofc,
                    score_type="sigma",
                    atoms_type="sidechain"))
                  remove_sidechain = True
                elif (sc_stats.mean_fofc < self.params.max_sidechain_fofc):
                  pruned.append(residue_summary(
                    chain_id=chain.id,
                    residue_group=residue_group,
                    atom_group=atom_group,
                    score=sc_stats.mean_fofc,
                    score_type="sigma",
                    atoms_type="sidechain",
                    map_type="mFo-Dfc"))
                  remove_sidechain = True
                if ((self.params.check_cgamma) and
                    (resname in ["ARG","LYS","TYR","TRP","PHE"])):
                  c_gamma = c_delta = None
                  for atom in atom_group.atoms():
                    if (atom.name.strip() == "CG"):
                      c_gamma = atom
                    elif (atom.name.strip() == "CD"):
                      c_delta = atom
                  if (c_gamma is not None):
                    map_values = self.get_density_at_atom(c_gamma)
                    # FIXME this is horribly subjective, but so is the logic
                    # I use for manual pruning...
                    if ((map_values.two_fofc < 0.8) or
                        ((map_values.two_fofc < 1.0) and
                         (map_values.fofc < -3.0))):
                      pruned.append(residue_summary(
                        chain_id=chain.id,
                        residue_group=residue_group,
                        atom_group=atom_group,
                        score=map_values.two_fofc,
                        score_type="sigma",
                        atoms_type="sidechain",
                        map_type="2mFo-Dfc"))
                      remove_sidechain = True
              if (remove_sidechain):
                assert (self.params.sidechains)
                for atom in sidechain_atoms :
                  atom_group.remove_atom(atom)
                n_sc_removed += 1
          if (remove_atom_group):
            assert (self.params.mainchain)
            residue_group.remove_atom_group(atom_group)
        if (len(residue_group.atom_groups()) == 0):
          chain.remove_residue_group(residue_group)
          n_res_removed += 1
          removed_resseqs.append(residue_group.resseq_as_int())
      # Final pass: remove lone single/pair residues
      if ((self.params.mainchain) and
          (self.params.min_fragment_size is not None)):
        n_rg = len(chain.residue_groups())
        for j_seq, residue_group in enumerate(chain.residue_groups()):
          if (residue_group.icode.strip() != ""):
            continue
          resseq = residue_group.resseq_as_int()
          remove = False
          if (resseq - 1 in removed_resseqs) or (j_seq == 0):
            print("candidate:", resseq)
            for k in range(1, self.params.min_fragment_size+1):
              if (resseq + k in removed_resseqs):
                remove = True
                break
              elif ((j_seq + k) >= len(chain.residue_groups())):
                remove = True
                break
          if (remove):
            pruned.append(residue_summary(
              chain_id=chain.id,
              residue_group=residue_group,
              atom_group=atom_group,
              score=None))
            chain.remove_residue_group(residue_group)
            removed_resseqs.append(resseq)
            n_res_removed += 1
    for outlier in pruned :
      outlier.show(out)
    print("Removed %d residues and %d sidechains" % (n_res_removed,
      n_sc_removed), file=out)
    return group_args(
      n_res_protein=n_res_protein,
      n_res_removed=n_res_removed,
      n_sc_removed=n_sc_removed,
      outliers=pruned)

def get_atom_radii(atoms, atom_radius):
  from scitbx.array_family import flex
  radii = flex.double([atom_radius] * len(atoms))
  for i_seq, atom in enumerate(atoms):
    if (atom.element.strip().upper() in ["H", "D"]):
      radii[i_seq] = 1.0
  return radii

def run_post_refinement(
    pdb_file,
    map_coeffs_file,
    output_file=None,
    params=None,
    f_map_label="2FOFCWT",
    diff_map_label="FOFCWT",
    model_map_label="F-model",
    write_model=True,
    out=None):
  if (out is None) : out = sys.stdout
  if (params is None):
    params = get_master_phil().fetch().extract().prune
  from iotbx import file_reader
  import iotbx.pdb
  pdb_in = iotbx.pdb.input(pdb_file)
  pdb_hierarchy = pdb_in.construct_hierarchy()
  pdb_hierarchy.atoms().reset_i_seq()
  # XXX this probably shouldn't be necessary
  pdb_hierarchy.atoms().set_chemical_element_simple_if_necessary()
  mtz_in = file_reader.any_file(map_coeffs_file, force_type="hkl")
  mtz_in.assert_file_type("hkl")
  f_map_coeffs = diff_map_coeffs = model_map_coeffs = None
  for array in mtz_in.file_server.miller_arrays :
    labels = array.info().labels
    if (labels[0] == f_map_label):
      f_map_coeffs = array
    elif (labels[0] == diff_map_label):
      diff_map_coeffs = array
    elif (labels[0] in [model_map_label, model_map_label + "(+)"]):
      model_map_coeffs = array.average_bijvoet_mates()
  if (f_map_coeffs is None):
    raise RuntimeError("2mFo-DFc map not found (expected labels %s)." %
      f_map_label)
  elif (diff_map_coeffs is None):
    raise RuntimeError("mFo-DFc map not found (expected labels %s)." %
      diff_map_label)
  elif (model_map_coeffs is None):
    raise RuntimeError("Fc map not found (expected labels %s)." %
      model_map_label)
  result = prune_model(
    f_map_coeffs=f_map_coeffs,
    diff_map_coeffs=diff_map_coeffs,
    model_map_coeffs=model_map_coeffs,
    pdb_hierarchy=pdb_hierarchy,
    params=params).process_residues(out=out)
  if (write_model):
    if (output_file is None):
      base_name = os.path.basename(pdb_file)
      output_file = os.path.splitext(base_name)[0] + "_pruned.pdb"
    f = open(output_file, "w")
    f.write("%s\n" % "\n".join(
      pdb_in.crystallographic_section()))
    f.write(pdb_hierarchy.as_pdb_string())
    f.close()
    result.output_file = output_file
  return result

def run(args, out=None):
  if (out is None) : out = sys.stdout
  usage_string = """\
mmtbx.prune_model model.pdb data.mtz [options...]

Filters protein residues based on CC to 2mFo-DFc map and absolute
(sigma-scaled) values in 2mFo-DFc and mFo-DFc maps.  For fast automatic
correction of MR solutions after initial refinement (ideally with rotamer
correction) to remove spurious loops and sidechains.
"""
  from mmtbx.command_line import load_model_and_data
  cmdline = load_model_and_data(
    args=args,
    master_phil=get_master_phil(),
    out=out,
    process_pdb_file=False,
    create_fmodel=True)
  params = cmdline.params
  fmodel = cmdline.fmodel
  if (params.output.file_name is None):
    base_name = os.path.basename(params.input.pdb.file_name[0])
    params.output.file_name = os.path.splitext(base_name)[0] + "_pruned.pdb"
  log_file = os.path.splitext(os.path.basename(params.output.file_name))[0] + \
    ".log"
  log = open(log_file, "w")
  out2 = multi_out()
  out2.register("out", out)
  out2.register("log", log)
  map_helper = fmodel.electron_density_map()
  f_map_coeffs = map_helper.map_coefficients(map_type="2mFo-DFc")
  diff_map_coeffs = map_helper.map_coefficients(map_type="mFo-DFc")
  model_map_coeffs = map_helper.map_coefficients(map_type="Fc")
  result = prune_model(
    f_map_coeffs=f_map_coeffs,
    diff_map_coeffs=diff_map_coeffs,
    model_map_coeffs=model_map_coeffs,
    pdb_hierarchy=cmdline.pdb_hierarchy,
    params=params.prune).process_residues(out=out2)
  f = open(params.output.file_name, "w")
  f.write("REMARK edited by mmtbx.prune_model\n")
  f.write(cmdline.pdb_hierarchy.as_pdb_string(
    crystal_symmetry=fmodel.xray_structure))
  f.close()
  log.close()
  print("Wrote %s" % params.output.file_name, file=out)
  return params.output.file_name

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/quantum_interface.py
from __future__ import absolute_import, division, print_function

from iotbx.cli_parser import run_program
from mmtbx.programs.quantum_interface import Program

if (__name__ == '__main__'):
  results = run_program(program_class=Program)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/r_factor_statistics.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.r_factor_statistics

import os,sys
from cctbx.array_family import flex
from libtbx import easy_pickle
import libtbx.load_env
from libtbx.str_utils import format_value

def show_histogram(data, n_slots):
  hm = flex.histogram(data = data, n_slots = n_slots)
  lc_1 = hm.data_min()
  s_1 = enumerate(hm.slots())
  for (i_1,n_1) in s_1:
    hc_1 = hm.data_min() + hm.slot_width() * (i_1+1)
    print("%10.3f - %-10.3f : %d" % (lc_1, hc_1, n_1))
    lc_1 = hc_1

help_message = """\
phenix.r_factor_statistics: a tool to show Rwork, Rfree and Rfree-Rwork
                            statistics for PDB structures.

Usage:
  - running phenix.r_factor_statistics without arguments will consider all PDB
    structures;
  - runing with single numeric argument
      phenix.r_factor_statistics 2.5
    will consider structures in resolution range [2.5-0.1, 2.5+0.1]
  - one can specify left and right offsets as well as the number of bins
      phenix.r_factor_statistics 2.5 left_offset=0.1 right_offset=0.5 n_bins=10
"""

def run(args, left_offset=0.1, right_offset=0.1, n_bins=10):
  need_help_msg = False
  if(len(args)==0): need_help_msg = True
  else:
    for arg in args:
      if(str(arg).lower() in ["help","-h","--help","--h","h"]):
        need_help_msg = True
        break
  if(need_help_msg):
    print(help_message)
  #
  def get_value(x):
    result = None
    try:
      result = float(x[x.index("=")+1:])
    except IndexError: pass
    except ValueError: pass
    return result
  d_min = None
  for arg in args:
    arg = str(arg).lower()
    try: d_min = float(arg)
    except ValueError: pass
    if(arg.count("left_offset")):
      x = get_value(arg)
      if(x is not None): left_offset=x
    if(arg.count("right_offset")):
      x = get_value(arg)
      if(x is not None): right_offset=x
    if(arg.count("n_bins")):
      x = int(get_value(arg))
      if(x is not None): n_bins=x
  dl,dr = [0,1.e+6]
  if(d_min is not None):
    cmd = "phenix.r_factor_statistics %s left_offset=%s right_offset=%s n_bins=%s"%(
      format_value("%6.3f",d_min).strip(),
      format_value("%6.3f",left_offset).strip(),
      format_value("%6.3f",right_offset).strip(),
      format_value("%d",n_bins).strip())
    print("Command used:\n\n%s\n\n"%cmd)
    dl = d_min-left_offset
    dr = d_min+right_offset
  file = libtbx.env.find_in_repositories(relative_path=
    "chem_data/polygon_data/all_mvd.pickle",
    test=os.path.isfile)
  database_dict = easy_pickle.load(file)
  # Python 3 pickle fix
  # =========================================================================
  if sys.version_info.major == 3:
    database_dict = easy_pickle.fix_py2_pickle(database_dict)
  # =========================================================================

  r_work_pdb = database_dict["pdb_header_r_work"]
  r_free_pdb = database_dict["pdb_header_r_free"]
  d_min = database_dict["high_resolution"]
  sel = r_work_pdb != "none"
  sel &= r_free_pdb != "none"
  sel &= d_min != "none"
  #
  r_work_pdb = r_work_pdb.select(sel)
  r_free_pdb = r_free_pdb.select(sel)
  d_min      = d_min.select(sel)
  #
  def str_to_float(x):
    tmp = flex.double()
    for x_ in x:
      tmp.append(float(x_))
    return tmp
  #
  d_min = str_to_float(d_min)
  r_work_pdb = str_to_float(r_work_pdb)
  r_free_pdb = str_to_float(r_free_pdb)
  diff = r_free_pdb - r_work_pdb
  #
  sel  = d_min > dl
  sel &= d_min < dr
  sel &= diff > 0.
  sel &= diff < 0.1
  #
  r_work_pdb = r_work_pdb.select(sel)
  r_free_pdb = r_free_pdb.select(sel)
  d_min      = d_min.select(sel)
  diff = diff.select(sel)
  #
  print("Histogram of Rwork for models in PDB at resolution %4.2f-%4.2f A:"%(dl,dr))
  show_histogram(data = r_work_pdb, n_slots=n_bins)
  print("Histogram of Rfree for models in PDB at resolution %4.2f-%4.2f A:"%(dl,dr))
  show_histogram(data = r_free_pdb, n_slots=n_bins)
  print("Histogram of Rfree-Rwork for all model in PDB at resolution %4.2f-%4.2f A:"%(dl,dr))
  show_histogram(data = diff, n_slots=n_bins)
  print("Number of structures considered:", diff.size())

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/rama_z.py
from __future__ import absolute_import, division, print_function

# LIBTBX_SET_DISPATCHER_NAME mmtbx.rama_z
# LIBTBX_SET_DISPATCHER_NAME phenix.rama_z

from mmtbx.programs import rama_z
from iotbx.cli_parser import run_program

if __name__ == "__main__":
  result = run_program(rama_z.Program)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/ramalyze.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.ramalyze
# LIBTBX_SET_DISPATCHER_NAME molprobity.ramalyze
# LIBTBX_PRE_DISPATCHER_INCLUDE_SH export PHENIX_GUI_ENVIRONMENT=1

import sys

from iotbx.cli_parser import CCTBXParser
from libtbx.utils import multi_out, show_total_time
from mmtbx.programs import ramalyze
from iotbx.cli_parser import run_program

#=============================================================================
def old_run(args):

  # create parser
  logger = multi_out()
  logger.register('stderr', sys.stderr)
  logger2 = multi_out()
  logger2.register('stdout', sys.stdout)

  parser = CCTBXParser(
    program_class=ramalyze.Program,
    logger=logger)
  namespace = parser.parse_args(sys.argv[1:])

  # start program
  print('Starting job', file=logger)
  print('='*79, file=logger)
  task = ramalyze.Program(
    parser.data_manager, parser.working_phil.extract(), logger=logger2)

  # validate inputs
  task.validate()

  # run program
  task.run()

  # stop timer
  print('', file=logger)
  print('='*79, file=logger)
  print('Job complete', file=logger)
  show_total_time(out=logger)

# =============================================================================
if __name__ == '__main__':
  #run(sys.argv[1:])
  run_program(program_class=ramalyze.Program, hide_parsing_output=True)



 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/rank_scale_map.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.rank_scale_map

from cctbx import maptbx
from libtbx.utils import Sorry
import sys, time
from iotbx.data_manager import DataManager

def show_overall_statistics(m, header):
  s = maptbx.more_statistics(m)
  print(header)
  print("  min/max/mean: %6.4f %6.4f %6.4f"%(s.min(), s.max(), s.mean()))
  print("  kurtosis    : %6.4f" % s.kurtosis())
  print("  skewness    : %6.4f" % s.skewness())
  print("  sigma       : %6.4f" % s.sigma())

def show_citation():
  print("-"*79)
  msg = """Compute rank-scaled (histogram equalized) map.

Input: CCP4 formatted map file.

Example:
  phenix.rank_scale_map map.ccp4

Citation:
  Map comparison and statistics. For details see:
  Acta Cryst. (2014). D70, 2593-2606
  Metrics for comparison of crystallographic maps
  A. Urzhumtsev, P. V. Afonine, V. Y. Lunin, T. C. Terwilliger and P. D. Adams"""
  print(msg)
  print("-"*79)

def run(args):
  show_citation()
  if(len(args)!=1): raise Sorry("Need to provide CCP4 formatted map file.")
  # map
  dm = DataManager()
  dm.set_overwrite(True)
  map_manager = dm.get_real_map(args[0])
  map_manager.shift_origin()

  cs = map_manager.crystal_symmetry()
  m = map_manager.map_data().as_double()
  # show general statistics
  show_overall_statistics(m=m, header="Map basic info (%s):"%args[0])
  # HE
  m_he = maptbx.volume_scale(map = m,  n_bins = 10000).map_data()
  show_overall_statistics(m=m_he, header="Rank-scaled (HE) map info:")
  #
  file_name=args[0]+"_rank_scaled.ccp4"
  he_map_manager = map_manager.customized_copy(map_data = m_he)
  he_map_manager.add_label("Histogram-equalized map")
  dm.write_real_map_file(he_map_manager, file_name)

if (__name__ == "__main__"):
  t0 = time.time()
  run(sys.argv[1:])
  print("Time: %-8.3f"%(time.time()-t0))
  print("All done.")


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/real_space_correlation.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.real_space_correlation

from mmtbx import real_space_correlation
import sys

if(__name__ == "__main__"):
  real_space_correlation.cmd_run(
    args         = sys.argv[1:],
    command_name = "phenix.real_space_correlation")


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/real_space_diff_map.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.real_space_diff_map

from scitbx.array_family import flex
import sys
import iotbx.pdb
from libtbx.utils import Sorry
import mmtbx.utils
from cctbx import maptbx
from cctbx import miller
from cctbx import uctbx
from cctbx import crystal
from libtbx import adopt_init_args
from six.moves import zip
from six.moves import range

import boost_adaptbx.boost.python as bp
cctbx_maptbx_ext = bp.import_ext("cctbx_maptbx_ext")

legend = """phenix.real_space_diff_map:
  Given PDB file and a map file calculate difference map:
    ExperimentalMap-ModelMap (like Fo-Fc map, in reciprocal space).

How to run:
  phenix.real_space_diff_map model.pdb map.ccp4 resolution=3.5

Feedback:
  PAfonine@lbl.gov
  phenixbb@phenix-online.org"""

master_params_str = """
  map_type = *vector *obs_phase mask_model
    .type = choice(multi=True)
    .help = vector: (Fobs,Pobs)-(Fcalc,Pcalc), obs_phase: (Fobs-Fcalc,Pobs), \
            mask_model: mask out interpreted density and eliminate weak and \
            low-volume map values
  map_file_name = None
    .type = str
  model_file_name = None
    .type = str
  resolution = None
    .type = float
  scattering_table = wk1995  it1992  *n_gaussian  neutron electron
    .type = choice
  wrapping = False
    .type = bool
    .short_caption = Wrapping
    .help = Wrapping defines whether values outside map boundary can be mapped \
            inside with unit cell translations. Normally True for crystal \
            structures and False for cryo-EM
  ignore_symmetry_conflicts = None
    .type = bool
    .short_caption = Ignore symmetry conflicts
    .help = Ignore symmetry differences between input model and map (use values \
            from map).
"""

def master_params():
  return iotbx.phil.parse(master_params_str, process_includes=False)

def broadcast(m, log):
  print("-"*79, file=log)
  print(m, file=log)
  print("*"*len(m), file=log)

def run(args, log=sys.stdout):
  print("-"*79, file=log)
  print(legend, file=log)
  print("-"*79, file=log)
  inputs = mmtbx.utils.process_command_line_args(args = args,
    master_params = master_params(),
    suppress_symmetry_related_errors = True)
  params = inputs.params.extract()
  # model
  broadcast(m="Input PDB:", log=log)
  file_names = inputs.pdb_file_names
  if(len(file_names) != 1): raise Sorry("PDB file has to given.")
  from iotbx.data_manager import DataManager
  dm = DataManager()
  dm.set_overwrite(True)
  model = dm.get_model(file_names[0])

  # map
  broadcast(m="Input map:", log=log)
  if(inputs.ccp4_map is None): raise Sorry("Map file has to given.")

  from iotbx.map_model_manager import map_model_manager
  mam = map_model_manager(model = model, map_manager = inputs.ccp4_map,
     wrapping = params.wrapping,
     ignore_symmetry_conflicts = params.ignore_symmetry_conflicts)

  mam.model().setup_scattering_dictionaries(
     scattering_table=params.scattering_table)
  mam.model().get_xray_structure().show_summary(f=log, prefix="  ")
  inputs.ccp4_map.show_summary(prefix="  ")

  # estimate resolution
  d_min = params.resolution
  if(d_min is None):
    raise Sorry("Map resolution must be given.")
  print("  d_min: %6.4f"%d_min, file=log)
  #
  if("obs_phase" in params.map_type):
    result_obj = compdiff(
      map_data_obs = mam.map_manager().map_data(), # NOTE this will always wrap map
      xrs          = mam.model().get_xray_structure(),
      d_min        = d_min,
      vector_map   = False)
    output_map_manager=mam.map_manager().customized_copy(
        map_data=result_obj.map_result)
    dm.write_real_map_file(output_map_manager, "map_model_difference_1.ccp4")
  #
  if("vector" in params.map_type):
    result_obj = compdiff(
      map_data_obs = mam.map_manager().map_data(),
      xrs          = mam.model().get_xray_structure(),
      d_min        = d_min,
      vector_map   = True)
    output_map_manager=mam.map_manager().customized_copy(
        map_data=result_obj.map_result)
    dm.write_real_map_file(output_map_manager, "map_model_difference_2.ccp4")
  #
  if("mask_model" in params.map_type):
    map_data_result = remove_model_density(
      map_data = mam.map_manager().map_data(),
      xrs      = mam.model().get_xray_structure())
    output_map_manager=mam.map_manager().customized_copy(
        map_data=map_data_result)
    dm.write_real_map_file(output_map_manager, "map_model_difference_3.ccp4")

def remove_model_density(map_data, xrs, rad_inside=2):
  #
  map_data = map_data - flex.mean(map_data)
  map_data = map_data.set_selected(map_data < 0, 0)
  sd = map_data.sample_standard_deviation()
  assert sd != 0
  map_data = map_data / sd
  #
  map_at_atoms = flex.double()
  for site_frac in xrs.sites_frac():
    mv = map_data.tricubic_interpolation(site_frac)
    map_at_atoms.append( mv )
  print (flex.mean(map_at_atoms), flex.max(map_at_atoms))
  mmax = flex.max(map_at_atoms)
  cut = 0
  print (dir(map_data))
  while cut<mmax:
    map_data_ = map_data.deep_copy()
    map_data_ = map_data_.set_selected(map_data<cut, 0)
    map_data_ = map_data_.set_selected(map_data>=cut, 1)
    cut+=1

    zz = flex.double()
    for site_frac in xrs.sites_frac():
      mv = map_data_.value_at_closest_grid_point(site_frac)
      zz.append( mv )
    print(cut,  (zz==1).count(True)/zz.size()*100. )

  #
  #radii = flex.double(xrs.sites_frac().size(), rad_inside)
  #mask = cctbx_maptbx_ext.mask(
  #  sites_frac                  = xrs.sites_frac(),
  #  unit_cell                   = xrs.unit_cell(),
  #  n_real                      = map_data.all(),
  #  mask_value_inside_molecule  = 0,
  #  mask_value_outside_molecule = 1,
  #  radii                       = radii)

  mask = mmtbx.masks.mask_from_xray_structure(
    xray_structure           = xrs,
    p1                       = True,
    for_structure_factors    = True,
    solvent_radius           = None,
    shrink_truncation_radius = None,
    n_real                   = map_data.accessor().all(),
    in_asu                   = False).mask_data
  maptbx.unpad_in_place(map=mask)


  map_data = map_data * mask
  map_data = map_data.set_selected(map_data < flex.mean(map_at_atoms)/6, 0)
  #
  n = map_data.accessor().all()
  abc = xrs.unit_cell().parameters()[:3]
  print(abc[0]/n[0], abc[1]/n[1], abc[2]/n[2])

  step = abc[0]/n[0]

  co = maptbx.connectivity(
    map_data                   = map_data.deep_copy(),
    threshold                  = 0.0,
    preprocess_against_shallow = True,
    wrapping                   = False)
  conn = co.result().as_double()
  z = zip(co.regions(),range(0,co.regions().size()))
  sorted_by_volume = sorted(z, key=lambda x: x[0], reverse=True)
  mask_ = flex.double(flex.grid(n), 0)
  for i_seq, p in enumerate(sorted_by_volume):
    v, i = p
    if i_seq==0: continue
    volume = v*step**3
    print(v, volume)
    if 1:#(volume<3):
      sel = conn==i
      mask_ = mask_.set_selected(sel, 1)

  #
  return map_data*mask_

def scale_k1(x,y):
  x = x.as_1d()
  y = y.as_1d()
  den=flex.sum(y*y)
  if(abs(den)<1.e-9): return 0
  return flex.sum(x*y)/den

def write_ccp4_map(map_data, unit_cell, space_group, file_name):
  iotbx.mrcfile.write_ccp4_map(
    file_name      = file_name,
    unit_cell      = unit_cell,
    space_group    = space_group,
    map_data       = map_data.as_double(),
    labels=flex.std_string([" "]))

def scale_two_real_maps_in_fourier_space(m1, m2, cs, d_min, vector_map):
  f1 = maptbx.map_to_map_coefficients(m=m1, cs=cs, d_min=d_min)
  f2 = maptbx.map_to_map_coefficients(m=m2, cs=cs, d_min=d_min)
  if(vector_map):
    f2 = f2.phase_transfer(phase_source=f1)
  ss = 1./flex.pow2(f1.d_spacings().data()) / 4.
  bs = flex.double([i for i in range(0,100)])
  mc = mmtbx.bulk_solvent.complex_f_minus_f_kb_scaled(
    f1.data(),f2.data(),bs,ss)
  crystal_gridding = maptbx.crystal_gridding(
    unit_cell             = cs.unit_cell(),
    space_group_info      = cs.space_group_info(),
    pre_determined_n_real = m1.all())
  fft_map = miller.fft_map(
    crystal_gridding     = crystal_gridding,
    fourier_coefficients = f1.array(data=mc))
  return fft_map.real_map_unpadded()

class compdiff(object):
  def __init__(
        self,
        map_data_obs,
        xrs,
        d_min,
        vector_map,
        box_dimension=30):
    adopt_init_args(self, locals())
    self.crystal_gridding = maptbx.crystal_gridding(
      unit_cell             = self.xrs.unit_cell(),
      space_group_info      = self.xrs.space_group_info(),
      pre_determined_n_real = self.map_data_obs.all())
    self.n_real = self.crystal_gridding.n_real()
    crystal_gridding = maptbx.crystal_gridding(
      unit_cell             = self.xrs.unit_cell(),
      space_group_info      = self.xrs.space_group_info(),
      pre_determined_n_real = self.map_data_obs.all())
    mc = xrs.structure_factors(d_min=d_min).f_calc()
    fft_map = miller.fft_map(
      crystal_gridding     = crystal_gridding,
      fourier_coefficients = mc)
    fft_map.apply_sigma_scaling()
    self.map_data_calc = fft_map.real_map_unpadded()
    scale = scale_k1(x=self.map_data_obs, y=self.map_data_calc)
    self.map_data_calc = self.map_data_calc * scale
    #
    # result map
    self.map_result = flex.double(flex.grid(self.map_data_obs.all()))
    # iterate over boxes
    self.box_iterator()

  def box_iterator(self):
    p = self.xrs.unit_cell().parameters()
    b = maptbx.boxes_by_dimension(
      n_real = self.n_real,
      dim    = self.box_dimension,
      abc    = p[:3])
    i_box = 0
    for s,e in zip(b.starts, b.ends):
      i_box+=1
      map_box_obs  = maptbx.copy(self.map_data_obs,  s, e)
      map_box_calc = maptbx.copy(self.map_data_calc, s, e)
      map_box_obs.reshape(flex.grid(map_box_obs.all()))
      map_box_calc.reshape(flex.grid(map_box_calc.all()))
      #######
      # XXX Copy-paste from map_box
      abc = []
      for i in range(3):
        abc.append( p[i] * map_box_calc.all()[i]/self.n_real[i] )
      ucb = uctbx.unit_cell(
        parameters=(abc[0],abc[1],abc[2],p[3],p[4],p[5]))
      cs = crystal.symmetry(unit_cell=ucb, space_group="P1")
      #######
      diff_map = scale_two_real_maps_in_fourier_space(
        m1         = map_box_obs,
        m2         = map_box_calc,
        cs         = cs,
        d_min      = self.d_min,
        vector_map = self.vector_map)
      maptbx.set_box(
        map_data_from = diff_map,
        map_data_to   = self.map_result,
        start         = s,
        end           = e)
    sd = self.map_result.sample_standard_deviation()
    if(sd!=0):
      self.map_result = self.map_result/sd


if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/rebuild_cablam_cache.py
from __future__ import absolute_import, division, print_function
import libtbx.load_env
from libtbx import easy_pickle, dlite
from libtbx.utils import format_cpu_times
from libtbx.str_utils import show_string
from mmtbx.rotamer.n_dim_table import NDimTable
import os, sys
# NB:  this can be run from the command line as "mmtbx.rebuild_cablam_cache"

file_suffixes = [
  'expected.general',
  'expected.gly',
  'expected.transpro',
  'expected.cispro',
  'expected.general_CA',
  'expected.gly_CA',
  'expected.transpro_CA',
  'expected.cispro_CA',
  'motif.loose_alpha',
  'motif.loose_beta',
  'motif.loose_threeten',
  'motif.regular_alpha',
  'motif.regular_beta',
  'motif.regular_threeten',
  'proline.cis',
  'proline.trans']

def run():
  starting_dir = os.getcwd()
  #---Find cablam_data dir---
  cablam_dir = libtbx.env.find_in_repositories(
    os.path.join('chem_data','cablam_data'))
  if cablam_dir is None:
    cablam_dir = libtbx.env.find_in_repositories('cablam_data')
    if cablam_dir is None:
      cablam_dir = libtbx.env.find_in_repositories(
        os.path.join('ext_ref_files','cablam_data'))
      if cablam_dir is None:
        print('  Rebuilding CaBLAM contours skipped. Needs chem_data/cablam_data directory.')
        return
  #---end find cablam_data_dir---

  target_db = dlite.try_loading_db(os.path.join(cablam_dir,'cablam.dlite'))
  rebuild_pickle_files(
    data_dir=cablam_dir,
    file_prefix='cablam.8000.',
    target_db=target_db,
    suffixes=file_suffixes)
  os.chdir(starting_dir)
  print(format_cpu_times())

def rebuild_pickle_files(data_dir, file_prefix, target_db, suffixes):
  os.chdir(data_dir)
  print('Processing data files in %s:' % show_string(data_dir))
  for suffix in suffixes:
    data_file =   file_prefix + suffix + '.stat'
    pickle_file = file_prefix + suffix + '.pickle'
    pair_info = target_db.pair_info(
      source_path=data_file,
      target_path=pickle_file,
      path_prefix=data_dir)
    print("  %s -> %s:" % (data_file, pickle_file), end=' ')
    if not pair_info.needs_update: print("already up to date.")
    else:
      print("converting ...", end=' ')
      sys.stdout.flush()
      pair_info.start_building_target()
      ndt = NDimTable.createFromText(data_file)
      easy_pickle.dump(file_name=pickle_file, obj=ndt)
      pair_info.done_building_target()
      print("done.")
    sys.stdout.flush()
  target_db.write()

if __name__ == "__main__":
    run()


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/rebuild_rotarama_cache.py
from __future__ import absolute_import, division, print_function

import os
import sys

# NB:  this can be run from the command line as "mmtbx.rebuild_rotarama_cache"
def run():
  from libtbx.utils import format_cpu_times
  from mmtbx.rotamer import rotamer_eval
  from mmtbx.rotamer import ramachandran_eval

  initial_current_working_directory = os.getcwd()
  rotamer_data_dir = rotamer_eval.find_rotarama_data_dir(optional=True)
  if rotamer_data_dir is None:
    print('  Rebuilding rotarama library skipped. Needs rotamer library.')
    return
  target_db = rotamer_eval.open_rotarama_dlite(
    rotarama_data_dir=rotamer_data_dir)
# rebuild_pickle_files(data_dir=rotamer_data_dir,
#   file_prefix="rota500-",
#   target_db=target_db,
#   amino_acids=rotamer_eval.aminoAcids)
  rebuild_pickle_files(data_dir=rotamer_data_dir,
    file_prefix="rota8000-",
    target_db=target_db,
    amino_acids=rotamer_eval.aminoAcids)
  #
  ramachandran_data_dir = rotamer_eval.find_rotarama_data_dir()
  target_db = rotamer_eval.open_rotarama_dlite(
    rotarama_data_dir=ramachandran_data_dir)
  rebuild_pickle_files(data_dir=rotamer_data_dir,
    file_prefix="rama8000-",
    target_db=target_db,
    amino_acids=ramachandran_eval.aminoAcids_8000)
# rebuild_pickle_files(data_dir=rotamer_data_dir,
#   file_prefix="rama500-",
#   target_db=target_db,
#   amino_acids=ramachandran_eval.aminoAcids)
  os.chdir(initial_current_working_directory)
  print(format_cpu_times())

def rebuild_pickle_files(data_dir, file_prefix, target_db, amino_acids):
  from libtbx import easy_pickle
  from libtbx.str_utils import show_string
  from mmtbx.rotamer.n_dim_table import NDimTable
  os.chdir(data_dir)
  print("Processing data files in %s:" % show_string(data_dir))
  for aa, aafile in amino_acids.items():
    data_file = file_prefix+aafile+".data"
    pickle_file = file_prefix+aafile+".pickle"
    pair_info = target_db.pair_info(
      source_path=data_file,
      target_path=pickle_file,
      path_prefix=data_dir)
    print("  %s -> %s:" % (data_file, pickle_file), end=' ')
    if not pair_info.needs_update:
      print("already up to date.")
    else:
      print("converting ...", end=' ')
      sys.stdout.flush()
      pair_info.start_building_target()
      ndt = NDimTable.createFromText(data_file)
      easy_pickle.dump(file_name=pickle_file, obj=ndt)
      pair_info.done_building_target()
      print("done.")
    sys.stdout.flush()
  target_db.write()

if __name__ == "__main__":
  run()


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/reciprocal_space_arrays.py
# LIBTBX_SET_DISPATCHER_NAME phenix.reciprocal_space_arrays

from __future__ import absolute_import, division, print_function
import mmtbx.utils
import mmtbx.f_model
import mmtbx.model
from iotbx import reflection_file_utils
from iotbx import file_reader
import iotbx.phil
import iotbx.pdb
from libtbx import runtime_utils
from libtbx.utils import Sorry
from six.moves import cStringIO as StringIO
import sys, os
from iotbx import extract_xtal_data

legend = """\

phenix.reciprocal_space_arrays:
compute various arrays such as Fcalc, Fmask, Fmodel, Fbulk, and more.

Inputs:
  - File with reflection data (Fobs or Iobs), R-free flags, and optionally HL
    coefficients. It can be in most of known formats and spread across
    multiple files;
  - label(s) selecting which reflection data arrays should be used (in case
    there are multiple choices in input file, there is no need to provide labels
    otherwise);
  - Model file (PDB or mmCIF) with input model.

Usage examples:
  1. phenix.reciprocal_space_arrays model.pdb data.hkl f_obs_label="IOBS"
  2. phenix.reciprocal_space_arrays model.pdb data.hkl r_free_flags_label="FREE"

Output:
  MTZ file with data arrays. Depending on the input data, the following arrays
  may be present:

  - FOBS         : data from input reflection file
  - SIGFOBS      : corresponding sigmas
  - R_FREE_FLAGS : R-free flags (0 - work, 1 - test)
  - FMODEL       : total model structure factor. See phenix.fmodel for details
  - PHIFMODEL    : corresponding phases
  - FCALC        : Fcalc from atomic model
  - PHIFCALC     : corresponding phases
  - FMASK        : Fmask from bulk-solvent mask. See phenix.fmodel for details
  - PHIFMASK     : corresponding phases
  - FBULK        : bulk-solvent contribution. See phenix.fmodel for details
  - PHIFBULK     : corresponding phases
  - FB_CART      : overall anisotropic scale factor
  - FOM          : figures of merit
  - ALPHA        : ML parameter used in m&D calculation for 2mFo-DFc maps
  - BETA         : ML parameter used in m&D calculation for 2mFo-DFc maps
  - HLA          : HL coefficients from from input reflection file
  - HLB          : HL coefficients from from input reflection file
  - HLC          : HL coefficients from from input reflection file
  - HLD          : HL coefficients from from input reflection file
  - HLmodelA     : HL coefficients from the model (C=D=0)
  - HLmodelB     : HL coefficients from the model (C=D=0)
  - HLmodelC     : HL coefficients from the model (C=D=0)
  - HLmodelD     : HL coefficients from the model (C=D=0)
  - HLcombA      : combined HL: model + input
  - HLcombB      : combined HL: model + input
  - HLcombC      : combined HL: model + input
  - HLcombD      : combined HL: model + input
  - RESOLUTION   : resolution per reflection
"""

master_params_str="""\
hkl_file = None
  .type = path
  .short_caption = Experimental data
  .style = bold file_type:hkl input_file process_hkl child:fobs:f_obs_label \
    child:rfree:r_free_flags_label child:space_group:space_group \
    child:unit_cell:unit_cell \
    child:hl_coeffs:hendrickson_lattman_coefficients_label
pdb_file = None
  .type = path
  .short_caption = Model file
  .style = bold file_type:pdb input_file
f_obs_label = None
  .type = str
  .short_caption = Data labels
  .input_size = 160
  .style = bold renderer:draw_fobs_label_widget
r_free_flags_label = None
  .type = str
  .short_caption = R-free flags
  .input_size = 160
  .style = bold renderer:draw_rfree_label_widget
remove_f_obs_outliers = True
  .type = bool
  .short_caption = Remove F-obs outliers
bulk_solvent_and_scaling = True
  .type = bool
  .short_caption = Bulk solvent correction and scaling
hendrickson_lattman_coefficients_label = None
  .type = str
  .short_caption = Hendrickson-Lattman coefficients
  .input_size = 160
  .style = renderer:draw_hl_label_widget
output_file_name = None
  .type = path
  .style = bold new_file
space_group = None
  .type = space_group
unit_cell = None
  .type = unit_cell
include scope libtbx.phil.interface.tracking_params
"""

def defaults(log):
  print("Default params::\n", file=log)
  parsed = iotbx.phil.parse(master_params_str, process_includes=True)
  parsed.show(prefix="  ", out=log)
  print(file=log)
  return parsed

def extract_experimental_phases(experimental_phases, f_obs):
  if(experimental_phases is not None):
    if(not f_obs.anomalous_flag()):
      if(experimental_phases.anomalous_flag()):
        experimental_phases = experimental_phases.average_bijvoet_mates()
    elif(not experimental_phases.anomalous_flag()):
      experimental_phases = experimental_phases.generate_bijvoet_mates()
    return experimental_phases.map_to_asu().matching_set(other = f_obs,
      data_substitute=(0,0,0,0))
  else: return None

def run(args, log = sys.stdout):
  if(len(args)==0):
    print(legend, file=log)
    defaults(log=log)
    return
  #
  parsed = defaults(log=log)
  processed_args = mmtbx.utils.process_command_line_args(args = args,
    log = sys.stdout, master_params = parsed)
  params = processed_args.params.extract()
  reflection_files = processed_args.reflection_files
  if(len(reflection_files) == 0):
    if (params.hkl_file is None):
      raise Sorry("No reflection file found.")
    else :
      hkl_in = file_reader.any_file(params.hkl_file, force_type="hkl")
      hkl_in.assert_file_type("hkl")
      reflection_files = [ hkl_in.file_object ]
  crystal_symmetry = processed_args.crystal_symmetry
  if(crystal_symmetry is None):
    if (params.space_group is not None) and (params.unit_cell is not None):
      from cctbx import crystal
      crystal_symmetry = crystal.symmetry(
        space_group_info=params.space_group,
        unit_cell=params.unit_cell)
    else :
      raise Sorry("No crystal symmetry found.")
  if(len(processed_args.pdb_file_names) == 0):
    if (params.pdb_file is None):
      raise Sorry("No model file found.")
    else :
      pdb_file_names = [ params.pdb_file ]
  else :
    pdb_file_names = processed_args.pdb_file_names
  #
  rfs = reflection_file_utils.reflection_file_server(
    crystal_symmetry = crystal_symmetry,
    force_symmetry   = True,
    reflection_files = reflection_files,
    err              = StringIO())
  parameters = extract_xtal_data.data_and_flags_master_params().extract()
  parameters.labels = params.f_obs_label
  parameters.r_free_flags.label = params.r_free_flags_label
  determine_data_and_flags_result = extract_xtal_data.run(
    reflection_file_server = rfs,
    parameters             = parameters,
    keep_going             = True)
  f_obs = determine_data_and_flags_result.f_obs
  print("Input data:")
  print("  Iobs or Fobs:", f_obs.info().labels)
  r_free_flags = determine_data_and_flags_result.r_free_flags
  print("  Free-R flags:", r_free_flags.info().labels)
  #
  experimental_phases = determine_data_and_flags_result.experimental_phases
  #
  if(r_free_flags is None):
    r_free_flags=f_obs.array(data=flex.bool(f_obs.data().size(), False))
  #
  pdb_inp = mmtbx.utils.pdb_inp_from_multiple_files(pdb_file_names, log=sys.stdout)
  model = mmtbx.model.manager(
    model_input      = pdb_inp,
    crystal_symmetry = crystal_symmetry,
    log              = sys.stdout)
  if(model.get_number_of_models()>1): #XXX support multi-models
    raise Sorry("Multiple model file not supported in this tool.")
  # XXX Twining not supported
  xray_structure = model.get_xray_structure()
  if (not xray_structure.unit_cell().is_similar_to(f_obs.unit_cell())):
    raise Sorry("The unit cells in the model and reflections files are not "+
      "isomorphous.")
  print("Input model:")
  print("  number of atoms:", xray_structure.scatterers().size())
  fmodel = mmtbx.f_model.manager(
    xray_structure = xray_structure,
    r_free_flags   = r_free_flags,
    f_obs          = f_obs,
    abcd           = experimental_phases)
  fmodel.update_all_scales(
    update_f_part1 = True,
    remove_outliers = params.remove_f_obs_outliers,
    bulk_solvent_and_scaling = params.bulk_solvent_and_scaling)
  print("Overall statistics:")
  fmodel.info().show_all()
  #
  print("Output data:")
  if(params.output_file_name is not None):
    output_file_name = params.output_file_name
  else:
    pdb_file_bn = os.path.basename(pdb_file_names[0])
    hkl_file_bn = os.path.basename(reflection_files[0].file_name())
    try: pdb_file_prefix = pdb_file_bn[:pdb_file_bn.index(".")]
    except ValueError: pdb_file_prefix = pdb_file_bn
    try:
      hkl_file_prefix = hkl_file_bn[:hkl_file_bn.index(".")]
    except ValueError: hkl_file_prefix = hkl_file_bn
    output_file_name = "%s_%s.mtz"%(pdb_file_prefix, hkl_file_prefix)
  print("  file name:", output_file_name)
  print("  to see the contnt of %s:"%output_file_name)
  print("    phenix.mtz.dump %s"%output_file_name)
  out = open(output_file_name,"w")
  fmodel.export(out = out)
  out.close()
  print("All done.")
  return output_file_name

def validate_params(params):
  if (params.hkl_file is None):
    raise Sorry("No reflections file provided.")
  elif (params.pdb_file is None):
    raise Sorry("No model file provided.")
  elif (params.output_file_name is None):
    raise Sorry("No output file name provided.")
  elif (params.f_obs_label is None):
    raise Sorry("No data label selected.")
  elif (params.r_free_flags_label is None):
    raise Sorry("No R-free flags label selected.  This program requires R-free "+
      "flags to run and will not generate them automatically; use the "+
      "reflection file editor to add them to your data file.")
  elif (params.space_group is None) or (params.unit_cell is None):
    raise Sorry("Missing or incomplete symmetry information.")
  return True

def finish_job(result):
  output_files, stats = [], []
  if (result is not None) and (os.path.isfile(result)):
    output_files.append((result, "Data and phases"))
  return output_files, stats

class launcher(runtime_utils.target_with_save_result):
  def run(self):
    return run(args=self.args, log=sys.stdout)

if(__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/reduce2.py
from __future__ import absolute_import, division, print_function

from iotbx.cli_parser import run_program
from mmtbx.programs import reduce2

if __name__ == "__main__":
  run_program(reduce2.Program)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/refine_anomalous_substructure.py

from __future__ import absolute_import, division, print_function
from libtbx.utils import Sorry
import sys

def run(args, out=sys.stdout):
  from mmtbx.refinement import anomalous_scatterer_groups
  import mmtbx.command_line
  master_phil = mmtbx.command_line.generate_master_phil_with_inputs(
    phil_string="""
map_type = *anom_residual llg
  .type = choice
exclude_waters = False
  .type = bool
exclude_non_water_light_elements = True
  .type = bool
n_cycles_max=None
  .type = int
map_sigma_min = 3.0
  .type = float
wavelength = None
  .type = float
refine = *f_prime *f_double_prime
  .type = choice(multi=True)
reset_water_u_iso = True
  .type = bool
""",
    enable_automatic_twin_detection=True)
  usage_string = """\
mmtbx.refine_anomalous_substructure model.pdb data.mtz [options]

Iterative identification of anomalously scattering atoms in the anomalous
residual map (simple or Phaser LLG), followed by refinement of the anomalous
scattering coefficients.  Intended as a diagnostic/development tool only!
"""
  cmdline = mmtbx.command_line.load_model_and_data(
    args=args,
    master_phil=master_phil,
    out=out,
    process_pdb_file=False,
    prefer_anomalous=True,
    usage_string=usage_string)
  fmodel = cmdline.fmodel
  if (not fmodel.f_obs().anomalous_flag()):
    raise Sorry("Anomalous data required.")
  pdb_hierarchy = cmdline.pdb_hierarchy
  params = cmdline.params
  return anomalous_scatterer_groups.refine_anomalous_substructure(
    fmodel=fmodel,
    pdb_hierarchy=pdb_hierarchy,
    wavelength=params.wavelength,
    map_type=params.map_type,
    exclude_waters=params.exclude_waters,
    exclude_non_water_light_elements=params.exclude_non_water_light_elements,
    n_cycles_max=params.n_cycles_max,
    map_sigma_min=params.map_sigma_min,
    refine=params.refine,
    reset_water_u_iso=params.reset_water_u_iso,
    out=out)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/remove_outliers.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.remove_outliers

from mmtbx.scaling import remove_outliers
import sys

if (__name__ == "__main__"):
  remove_outliers.run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/ribbons.py
from __future__ import absolute_import, division, print_function

from iotbx.cli_parser import run_program
from mmtbx.programs import ribbons

if __name__ == "__main__":
  run_program(ribbons.Program)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/rigid_bond_test.py

from __future__ import absolute_import, division, print_function
from libtbx.utils import Usage, Sorry
import libtbx.phil
import sys

master_phil = libtbx.phil.parse("""
model = None
  .type = path
restraints = None
  .type = path
  .multiple = True
""")

def run(args, out=sys.stdout):
  if (len(args) == 0) or ("--help" in args):
    raise Usage("mmtbx.rigid_bond_test model.pdb")
  import mmtbx.restraints
  import mmtbx.model
  import iotbx.phil
  cmdline = iotbx.phil.process_command_line_with_files(
    args=args,
    master_phil=master_phil,
    pdb_file_def="model",
    cif_file_def="restraints")
  params = cmdline.work.extract()
  validate_params(params)
  model = mmtbx.model.manager(
    model_input = iotbx.pdb.input(file_name = params.model))
  model.process(make_restraints=True)
  model.get_xray_structure()
  model.show_rigid_bond_test(
    out=out,
    use_id_str=True,
    prefix="  ")

def validate_params(params):
  if (params.model is None):
    raise Sorry("Please specify a PDB file.")
  return True

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/ringer.py
# LIBTBX_PRE_DISPATCHER_INCLUDE_SH PHENIX_GUI_ENVIRONMENT=1
# LIBTBX_PRE_DISPATCHER_INCLUDE_SH export PHENIX_GUI_ENVIRONMENT

"""
Implementation of the Ringer method, with plots

Reference:
  Lang PT, Ng HL, Fraser JS, Corn JE, Echols N, Sales M, Holton JM, Alber T.
  Automated electron-density sampling reveals widespread conformational
  polymorphism in proteins. Protein Sci. 2010 Jul;19(7):1420-31. PubMed PMID:
  20499387
"""

from __future__ import absolute_import, division, print_function
from mmtbx.ringer import * # this is deliberate!
import libtbx.phil
from libtbx import easy_pickle
from libtbx.str_utils import make_header
from libtbx.utils import Sorry
from libtbx import runtime_utils
import mmtbx.model
from iotbx.map_model_manager import map_model_manager
import time
import os
import sys
from six.moves import range

master_phil = libtbx.phil.parse("""
model = None
  .type = path
  .style = file_type:pdb bold input_file
cif_file = None
  .type = path
  .multiple = True
  .short_caption = Restraints
  .style = file_type:cif bold input_file
map_coeffs = None
  .type = path
  .short_caption = Map coefficients
  .style = file_type:hkl bold input_file OnChange:extract_ringer_map_labels
map_label = 2FOFCWT,PH2FOFCWT
  .type = str
  .input_size = 200
  .short_caption = 2Fo-FC map labels
  .style = bold renderer:draw_map_arrays_widget noauto
difference_map_label = FOFCWT,PHFOFCWT
  .type = str
  .input_size = 200
  .short_caption = Fo-Fc map labels
  .style = bold renderer:draw_map_arrays_widget noauto
map_file = None
  .type = path
include scope mmtbx.ringer.ringer_phil_str
sampling_method = linear *spline direct
  .type = choice(multi=False)
grid_spacing = 1./5
  .type = float
gui = False
  .type = bool
  .style = hidden
ignore_symmetry_conflicts = False
  .type = bool
  .help = Allow running with PDB file with symmetry that does not match map
output_base = None
  .type = str
output_dir = None
  .type = path
  .style = output_dir
include scope libtbx.phil.interface.tracking_params
""", process_includes=True)
master_params = master_phil

def run(args, out=None, verbose=True):
  t0 = time.time()
  if (out is None) : out = sys.stdout
  from iotbx import file_reader
  import iotbx.phil
  cmdline = iotbx.phil.process_command_line_with_files(
    args=args,
    master_phil=master_phil,
    pdb_file_def="model",
    reflection_file_def="map_coeffs",
    map_file_def="map_file",
    cif_file_def="cif_file",
    usage_string="""\
mmtbx.ringer model.pdb map_coeffs.mtz [cif_file ...] [options]

%s
""" % __doc__)
  cmdline.work.show()
  params = cmdline.work.extract()
  validate_params(params)
  pdb_in = file_reader.any_file(params.model, force_type="pdb")
  pdb_in.check_file_type("pdb")

  pdb_inp = iotbx.pdb.input(file_name=params.model)
  model = mmtbx.model.manager(
    model_input      = pdb_inp)
  crystal_symmetry_model = model.crystal_symmetry()
  if crystal_symmetry_model is not None:
    crystal_symmetry_model.show_summary()

  hierarchy = model.get_hierarchy()
  map_coeffs = map_inp = difference_map_coeffs = None
  map_data, unit_cell = None, None
  # get miller array if map coefficients are provided
  if (params.map_coeffs is not None):
    mtz_in = file_reader.any_file(params.map_coeffs, force_type="hkl")
    mtz_in.check_file_type("hkl")
    best_guess = None
    best_labels = []
    all_labels = []
    for array in mtz_in.file_server.miller_arrays :
      if (array.is_complex_array()):
        labels = array.info().label_string()
        if (labels == params.map_label):
          map_coeffs = array
        elif (labels == params.difference_map_label):
          difference_map_coeffs = array
        else :
          if (params.map_label is None):
            all_labels.append(labels)
            if (labels.startswith("2FOFCWT") or labels.startswith("2mFoDFc") or
                labels.startswith("FWT")):
              best_guess = array
              best_labels.append(labels)
          if (params.difference_map_label is None):
            if (labels.startswith("FOFCWT") or labels.startswith("DELFWT")):
              difference_map_coeffs = array
    if (map_coeffs is None):
      if (len(all_labels) == 0):
        raise Sorry("No valid (pre-weighted) map coefficients found in file.")
      elif (best_guess is None):
        raise Sorry("Couldn't automatically determine appropriate map labels. "+
          "Choices:\n  %s" % "  \n".join(all_labels))
      elif (len(best_labels) > 1):
        raise Sorry("Multiple appropriate map coefficients found in file. "+
          "Choices:\n  %s" % "\n  ".join(best_labels))
      map_coeffs = best_guess
      print("  Guessing %s for input map coefficients" % best_labels[0], file=out)
  # get map_inp object and do sanity checks if map is provided
  else :
    ccp4_map_in = file_reader.any_file(params.map_file, force_type="ccp4_map")
    ccp4_map_in.check_file_type("ccp4_map")
    map_inp = ccp4_map_in.file_object
    base = map_model_manager(
      map_manager               = map_inp,
      model            = model,
      ignore_symmetry_conflicts = params.ignore_symmetry_conflicts)
    cs_consensus = base.crystal_symmetry()
    hierarchy = base.model().get_hierarchy()
    map_data = base.map_data()
    unit_cell = map_inp.grid_unit_cell()

  hierarchy.atoms().reset_i_seq()

  make_header("Iterating over residues", out=out)
  t1 = time.time()
  results = iterate_over_residues(
    pdb_hierarchy=hierarchy,
    map_coeffs=map_coeffs,
    difference_map_coeffs=difference_map_coeffs,
    map_data  = map_data,
    unit_cell = unit_cell,
    params=params,
    log=out).results
  t2 = time.time()
  if (verbose):
    print("Time excluding I/O: %8.1fs" % (t2 - t1), file=out)
    print("Overall runtime:    %8.1fs" % (t2 - t0), file=out)
  if (params.output_base is None):
    pdb_base = os.path.basename(params.model)
    params.output_base = os.path.splitext(pdb_base)[0] + "_ringer"
  easy_pickle.dump("%s.pkl" % params.output_base, results)
  print("Wrote %s.pkl" % params.output_base, file=out)
  csv = "\n".join([ r.format_csv() for r in results ])
  with open("%s.csv" % params.output_base, "w") as f:
    f.write(csv)
  print("Wrote %s.csv" % params.output_base, file=out)
  print("\nReference:", file=out)
  print("""\
  Lang PT, Ng HL, Fraser JS, Corn JE, Echols N, Sales M, Holton JM, Alber T.
  Automated electron-density sampling reveals widespread conformational
  polymorphism in proteins. Protein Sci. 2010 Jul;19(7):1420-31. PubMed PMID:
  20499387""", file=out)
  if (params.gui):
    run_app(results)
  else :
    return results

def validate_params(params):
  if (params.model is None):
    raise Sorry("No PDB file supplied (parameter: model)")
  if (params.map_coeffs is None) and (params.map_file is None):
    raise Sorry("No map coefficients supplied (parameter: map_coeffs)")
  if (not (1 < params.sampling_angle < 60)):
    raise Sorry("The sampling angle must be an integer between 1 and 60 "+
      "degrees")
  if (not (0 < params.grid_spacing < 0.5)):
    raise Sorry("The grid spacing must be greater than zero but less than 0.5")
  return True

class launcher(runtime_utils.target_with_save_result):
  def run(self):
    os.makedirs(self.output_dir)
    os.chdir(self.output_dir)
    return run(args=list(self.args), out=sys.stdout)
########################################################################
# GUI
try :
  import wx
except ImportError :
  def run_app(results):
    raise Sorry("wxPython not available.")
else :
  from wxtbx import plots

  def run_app(results):
    app = wx.App(0)
    frame = RingerFrame(None, -1, "Ringer results")
    frame.show_results(results)
    frame.Show()
    app.MainLoop()

  class RingerFrame(plots.plot_frame):
    def create_plot_panel(self):
      plot = RingerPlot(self, figure_size=(6,8))
      plot.canvas.Bind(wx.EVT_CHAR, self.OnChar)
      return plot

    def draw_top_panel(self):
      self.top_panel = wx.Panel(self, style=wx.SUNKEN_BORDER)
      panel_szr = wx.BoxSizer(wx.VERTICAL)
      self.top_panel.SetSizer(panel_szr)
      szr2 = wx.BoxSizer(wx.HORIZONTAL)
      panel_szr.Add(szr2)
      txt1 = wx.StaticText(self.top_panel, -1, "Residue to display:")
      szr2.Add(txt1, 0, wx.ALL|wx.ALIGN_CENTER_VERTICAL, 5)
      self.chooser = wx.Choice(self.top_panel, -1, size=(200,-1))
      szr2.Add(self.chooser, 0, wx.ALL|wx.ALIGN_CENTER_VERTICAL, 5)
      self.Bind(wx.EVT_CHOICE, self.OnSelect, self.chooser)
      self.Bind(wx.EVT_CHAR, self.OnChar)
      self.chooser.Bind(wx.EVT_CHAR, self.OnChar)
      return self.top_panel

    def OnSelect(self, event):
      selection = event.GetEventObject().GetSelection()
      self.plot_panel.show_residue(self.results[selection])
      self.selection_callback(self.results[selection])

    # override in subclasses
    def selection_callback(self, residue):
      pass

    def show_results(self, results):
      self.results = results
      choices = [ result.format() for result in results ]
      self.chooser.SetItems(choices)
      self.chooser.SetSelection(0)
      self.plot_panel.show_residue(self.results[0])

    def OnChar(self, event):
      key = event.GetKeyCode()
      if (len(self.results) == 0) : return
      selection = self.chooser.GetSelection()
      if (key in [wx.WXK_TAB, wx.WXK_RETURN, wx.WXK_SPACE]):
        if (selection < (len(self.results) - 1)):
          selection += 1
        elif (len(self.results) > 0):
          selection = 0
      elif (key in [wx.WXK_DELETE, wx.WXK_BACK]):
        if (selection > 0):
          selection -= 1
        else :
          selection = len(results) - 1
      self.chooser.SetSelection(selection)
      self.plot_panel.show_residue(self.results[selection])

  class RingerPlot(plots.plot_container):
    def show_residue(self, residue, show_background_boxes=True):
      if (self.disabled) : return
      self.figure.clear()
      subplots = []
      for i in range(1, residue.n_chi + 1):
        chi = residue.get_angle(i)
        if (chi is None) : continue
        if (len(subplots) > 0):
          p = self.figure.add_subplot(4, 1, i, sharex=subplots[0])
        else :
          p = self.figure.add_subplot(4, 1, i)
          p.set_title(residue.format())
        p.set_position([0.15, 0.725 - 0.225*(i-1), 0.8, 0.225])
        x = [ k*chi.sampling for k in range(len(chi.densities)) ]
        p.plot(x, chi.densities, 'r-', linewidth=1)
        if (chi.fofc_densities is not None):
          p.plot(x, chi.fofc_densities, linestyle='--', color=[0.5,0.0,1.0])
        p.axvline(chi.angle_current, color='b', linewidth=2, linestyle='--')
        p.axhline(0, color=(0.4,0.4,0.4), linestyle='--', linewidth=1)
        if show_background_boxes:
          p.axhspan(0.3,1,facecolor="green",alpha=0.5)
          p.axhspan(-1,0.3,facecolor="grey",alpha=0.5)
        p.set_xlim(0,360)
        p.set_ylabel("Rho")
        p.set_xlabel("Chi%d" % i)
        subplots.append(p)
      for p in subplots[:-1] :
        for label in p.get_xticklabels():
          label.set_visible(False)
      self.canvas.draw()
      self.canvas.Fit()
      self.Layout()
      self.parent.Refresh()

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/rna_validate.py
# LIBTBX_SET_DISPATCHER_NAME phenix.rna_validate
# LIBTBX_SET_DISPATCHER_NAME molprobity.rna_validate

from __future__ import absolute_import, division, print_function
import sys
from iotbx.cli_parser import CCTBXParser
from libtbx.utils import multi_out, show_total_time
from mmtbx.programs import rna_validate
from iotbx.cli_parser import run_program

def old_run(args, out=sys.stdout, quiet=False):
  # create parser
  logger = multi_out()
  logger.register('stderr', sys.stderr)
  logger2 = multi_out()
  logger2.register('stdout', sys.stdout)

  parser = CCTBXParser(
    program_class=rna_validate.Program,
    logger=logger)
  namespace = parser.parse_args(sys.argv[1:])

  # start program
  print('Starting job', file=logger)
  print('='*79, file=logger)
  task = rna_validate.Program(
    parser.data_manager, parser.working_phil.extract(), logger=logger2)

  # validate inputs
  task.validate()

  # run program
  task.run()

  # stop timer
  print('', file=logger)
  print('='*79, file=logger)
  print('Job complete', file=logger)
  show_total_time(out=logger)

if (__name__ == "__main__"):
  #run(sys.argv[1:])
  run_program(program_class=rna_validate.Program, hide_parsing_output=True)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/rna_validate_bonds.py
# LIBTBX_SET_DISPATCHER_NAME phenix.rna_validate_bonds
# LIBTBX_SET_DISPATCHER_NAME molprobity.rna_validate_bonds

from __future__ import absolute_import, division, print_function
import sys
from iotbx.cli_parser import CCTBXParser
from libtbx.utils import multi_out, show_total_time
from mmtbx.programs import rna_validate_bonds

def run(args, out=sys.stdout, quiet=False):
  # create parser
  logger = multi_out()
  logger.register('stderr', sys.stderr)
  logger2 = multi_out()
  logger2.register('stdout', sys.stdout)

  parser = CCTBXParser(
    program_class=rna_validate_bonds.Program,
    logger=logger)
  namespace = parser.parse_args(sys.argv[1:])

  # start program
  print('Starting job', file=logger)
  print('='*79, file=logger)
  task = rna_validate_bonds.Program(
    parser.data_manager, parser.working_phil.extract(), logger=logger2)

  # validate inputs
  task.validate()

  # run program
  task.run()

  # stop timer
  print('', file=logger)
  print('='*79, file=logger)
  print('Job complete', file=logger)
  show_total_time(out=logger)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/rna_validate_puckers.py
# LIBTBX_SET_DISPATCHER_NAME phenix.rna_validate_puckers
# LIBTBX_SET_DISPATCHER_NAME molprobity.rna_validate_puckers

from __future__ import absolute_import, division, print_function
import sys
from iotbx.cli_parser import CCTBXParser
from libtbx.utils import multi_out, show_total_time
from mmtbx.programs import rna_validate_puckers
from iotbx.cli_parser import run_program

def old_run(args, out=sys.stdout, quiet=False):
  # create parser
  logger = multi_out()
  logger.register('stderr', sys.stderr)
  logger2 = multi_out()
  logger2.register('stdout', sys.stdout)

  parser = CCTBXParser(
    program_class=rna_validate_puckers.Program,
    logger=logger)
  namespace = parser.parse_args(sys.argv[1:])

  # start program
  print('Starting job', file=logger)
  print('='*79, file=logger)
  task = rna_validate_puckers.Program(
    parser.data_manager, parser.working_phil.extract(), logger=logger2)

  # validate inputs
  task.validate()

  # run program
  task.run()

  # stop timer
  print('', file=logger)
  print('='*79, file=logger)
  print('Job complete', file=logger)
  show_total_time(out=logger)

if (__name__ == "__main__"):
  #run(sys.argv[1:])
  run_program(program_class=rna_validate_puckers.Program, hide_parsing_output=True)



 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/rna_validate_suites.py
# LIBTBX_SET_DISPATCHER_NAME phenix.rna_validate_suites
# LIBTBX_SET_DISPATCHER_NAME molprobity.rna_validate_suites

from __future__ import absolute_import, division, print_function
import sys
from iotbx.cli_parser import CCTBXParser
from libtbx.utils import multi_out, show_total_time
from mmtbx.programs import rna_validate_suites
from iotbx.cli_parser import run_program

def old_run(args, out=sys.stdout, quiet=False):
  # create parser
  logger = multi_out()
  logger.register('stderr', sys.stderr)
  logger2 = multi_out()
  logger2.register('stdout', sys.stdout)

  parser = CCTBXParser(
    program_class=rna_validate_suites.Program,
    logger=logger)
  namespace = parser.parse_args(sys.argv[1:])

  # start program
  print('Starting job', file=logger)
  print('='*79, file=logger)
  task = rna_validate_suites.Program(
    parser.data_manager, parser.working_phil.extract(), logger=logger2)

  # validate inputs
  task.validate()

  # run program
  task.run()

  # stop timer
  print('', file=logger)
  print('='*79, file=logger)
  print('Job complete', file=logger)
  show_total_time(out=logger)

if (__name__ == "__main__"):
  #run(sys.argv[1:])
  run_program(program_class=rna_validate_suites.Program, hide_parsing_output=True)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/rotalyze.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.rotalyze
# LIBTBX_SET_DISPATCHER_NAME molprobity.rotalyze
# LIBTBX_PRE_DISPATCHER_INCLUDE_SH export PHENIX_GUI_ENVIRONMENT=1

import sys

from iotbx.cli_parser import CCTBXParser
from libtbx.utils import multi_out, show_total_time
from mmtbx.programs import rotalyze
from iotbx.cli_parser import run_program

# =============================================================================
def old_run(args):

  # create parser
  logger = multi_out()
  logger.register('stderr', sys.stderr)
  logger2 = multi_out()
  logger2.register('stdout', sys.stdout)

  parser = CCTBXParser(
    program_class=rotalyze.Program,
    logger=logger)
  namespace = parser.parse_args(sys.argv[1:])

  # start program
  print('Starting job', file=logger)
  print('='*79, file=logger)
  task = rotalyze.Program(
    parser.data_manager, parser.working_phil.extract(), logger=logger2)

  # validate inputs
  task.validate()

  # run program
  task.run()

  # stop timer
  print('', file=logger)
  print('='*79, file=logger)
  print('Job complete', file=logger)
  show_total_time(out=logger)

# =============================================================================
if __name__ == '__main__':
  #run(sys.argv[1:])
  run_program(program_class=rotalyze.Program, hide_parsing_output=True)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/search_pdb_symmetry.py
from __future__ import absolute_import, division, print_function

import iotbx.phil
from libtbx.utils import Sorry, Usage
from libtbx import group_args
import sys

master_phil = iotbx.phil.parse("""
symmetry_search
  .short_caption = PDB symmetry search
  .caption = This utility allows you to search the PDB for structures with \
    similar unit cell parameters.  Crystallization artifacts due to \
    impurities in the protein solution can often be detected this way, if the \
    protein which actually crystallized has been solved before.  Note that \
    a large number of false positives are usually expected for genuinely \
    novel structures, so the presence of similar unit cells is not \
    necessarily a bad sign.
  .style = box auto_align caption_img:icons/custom/pdb_import64.png
{
  file_name = None
    .type = path
    .short_caption = File name (PDB or MTZ)
  unit_cell = None
    .type = unit_cell
  space_group = None
    .type = space_group
  max_rmsd = None
    .type = float
    .short_caption = Max. RMSD to consider
  max_hits_to_display = 50
    .type = int
    .short_caption = Max. number of hits
}
""")

def run(args=(), params=None, out=sys.stdout):
  if (len(args) > 0):
    cmdline = iotbx.phil.process_command_line_with_files(
      args=args,
      master_phil=master_phil,
      pdb_file_def="symmetry_search.file_name",
      reflection_file_def="symmetry_search.file_name")
    params = cmdline.work.extract().symmetry_search
  elif (params is None):
    raise Usage("""mmtbx.search_pdb_symmetry [file] [space_group] [unit_cell]
  Utility for finding similar unit cells deposited in the PDB.
""")
  else :
    params = params.symmetry_search
  from mmtbx import pdb_symmetry
  from iotbx import crystal_symmetry_from_any
  from cctbx import crystal
  db = pdb_symmetry.load_db()
  if (params.file_name is not None):
    symm = crystal_symmetry_from_any.extract_from(file_name=params.file_name)
    if (symm is None):
      raise Sorry("The file %s does not include symmetry information." %
        params.file_name)
    elif (symm.space_group() is None) or (symm.unit_cell() is None):
      raise Sorry("Incomplete symmetry information in %s." % params.file_name)
  else :
    symm = crystal.symmetry(
      unit_cell=params.unit_cell,
      space_group_info=params.space_group)
  print("", file=out)
  print("Input symmetry:", file=out)
  symm.show_summary()
  scores = pdb_symmetry.symmetry_search(db, symm, max_rmsd=params.max_rmsd)
  niggli_cell = symm.niggli_cell().unit_cell().parameters()
  print("", file=out)
  print("Top %d matches (sorted by RMSD):", file=out)
  results = []
  for scored in scores[:params.max_hits_to_display] :
    print("%s (rmsd = %.3f, volume ratio = %.2f)" % \
      (scored.entry.pdb_id, scored.rmsd, scored.volume_ratio), file=out)
    print("    Unit cell: %8.3f %8.3f %8.3f %8.3f %8.3f %8.3f" % \
      scored.entry.crystal_symmetry.unit_cell().parameters(), file=out)
    print("  Niggli cell: %8.3f %8.3f %8.3f %8.3f %8.3f %8.3f" % \
      scored.entry.niggli_cell.unit_cell().parameters(), file=out)
    print("  Target cell: %8.3f %8.3f %8.3f %8.3f %8.3f %8.3f" % \
      niggli_cell, file=out)
    print("", file=out)
    results.append(group_args(
      pdb_id=scored.entry.pdb_id,
      rmsd=scored.rmsd,
      volume_ratio=scored.volume_ratio,
      pdb_symmetry=scored.entry.crystal_symmetry))
  return group_args(
    crystal_symmetry=symm,
    hits=results)

def validate_params(params):
  params = params.symmetry_search
  have_symm = (not None in [params.unit_cell, params.space_group])
  if (not have_symm) and (params.file_name is None):
    raise Sorry("Missing or incomplete symmetry information.")
  return True

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************
