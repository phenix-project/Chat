

 *******************************************************************************
iotbx/cif/__init__.py
"""
Tools for reading and writing mmCIF files.

R. J. Gildea, L. J. Bourhis, O. V. Dolomanov, R. W. Grosse-Kunstleve,
H. Puschmann, P. D. Adams and J. A. K. Howard:
iotbx.cif: a comprehensive CIF toolbox.
J. Appl. Cryst. (2011). 44, 1259-1263.

https://doi.org/10.1107/S0021889811041161

"""
from __future__ import absolute_import, division, print_function

import boost_adaptbx.boost.python as bp
from six.moves import range
from six.moves import zip
import six
ext = bp.import_ext("iotbx_cif_ext")

from cctbx.array_family import flex
from cctbx import miller
from iotbx.cif import model, builders, geometry
from libtbx.containers import OrderedDict
from libtbx.utils import Sorry
from libtbx.utils import flat_list
from libtbx.utils import detect_binary_file
from libtbx import smart_open

import sys

distances_as_cif_loop = geometry.distances_as_cif_loop
angles_as_cif_loop = geometry.angles_as_cif_loop

class CifParserError(Sorry):
  __orig_module__ = __module__
  __module__ = Exception.__module__

class reader(object):

  def __init__(self,
               file_path=None,
               file_object=None,
               input_string=None,
               cif_object=None,
               builder=None,
               raise_if_errors=True,
               strict=True):
    assert [file_path, file_object, input_string].count(None) == 2
    self.file_path = file_path
    if builder is None:
      builder = builders.cif_model_builder(cif_object)
    else: assert cif_object is None
    self.builder = builder
    self.original_arrays = None
    if file_path is not None:
      file_object = smart_open.for_reading(file_path)
    else:
      file_path = "memory"
    if file_object is not None:
      input_string = file_object.read()
      file_object.close()
    # check input_string for binary, and abort if necessary
    binary_detector = detect_binary_file()
    binary_detector.monitor_initial = min(
      len(input_string), binary_detector.monitor_initial)
    if binary_detector.is_binary_file(block=input_string):
      raise CifParserError("Binary file detected, aborting parsing.")
    self.parser = ext.fast_reader(builder, input_string, file_path, strict)
    if raise_if_errors and len(self.parser.lexer_errors()):
      raise CifParserError(self.parser.lexer_errors()[0])
    if raise_if_errors and len(self.parser.parser_errors()):
      raise CifParserError(self.parser.parser_errors()[0])

  def model(self):
    return self.builder.model()

  def error_count(self):
    return self.parser.lexer_errors().size()\
           + self.parser.parser_errors().size()

  def show_errors(self, max_errors=50, out=None):
    if out is None: out = sys.stdout
    for msg in self.parser.lexer_errors()[:max_errors]:
      print(msg, file=out)
    for msg in self.parser.parser_errors()[:max_errors]:
      print(msg, file=out)

  def build_crystal_structures(self, data_block_name=None):
    xray_structures = cctbx_data_structures_from_cif(
      cif_model=self.model(),
      file_path=self.file_path,
      data_block_name=data_block_name,
      data_structure_builder=builders.crystal_structure_builder).xray_structures
    if data_block_name is not None:
      return xray_structures[data_block_name]
    else:
      return xray_structures

  def build_miller_arrays(self,
                          data_block_name=None,
                          base_array_info=None):
    cctbxdat = cctbx_data_structures_from_cif(
      cif_model=self.model(),
      file_path=self.file_path,
      data_block_name=data_block_name,
      data_structure_builder=builders.miller_array_builder,
      base_array_info=base_array_info)

    self.original_arrays = cctbxdat.original_arrays
    if data_block_name is not None:
      return cctbxdat.miller_arrays[data_block_name]
    else:
      return cctbxdat.miller_arrays

  def as_miller_arrays(self, data_block_name=None,
                       crystal_symmetry=None,
                       force_symmetry=False,
                       merge_equivalents=True,
                       base_array_info=None,
                       anomalous=None):
    if base_array_info is None:
      base_array_info = miller.array_info(
        source=self.file_path, source_type="cif")
    if data_block_name is not None:
      arrays = list(self.build_miller_arrays(
        data_block_name=data_block_name,
        base_array_info=base_array_info).values())
    else:
      arrays = flat_list([
        list(arrays.values()) for arrays in
        self.build_miller_arrays(base_array_info=base_array_info).values()])
    other_symmetry=crystal_symmetry
    for i in range(len(arrays)):
      if crystal_symmetry is not None:
        crystal_symmetry_from_file = arrays[i].crystal_symmetry()
        crystal_symmetry = crystal_symmetry_from_file.join_symmetry(
          other_symmetry=other_symmetry,
          force=force_symmetry)
        arrays[i] = arrays[i].customized_copy(
          crystal_symmetry=crystal_symmetry, info=arrays[i].info())
      if anomalous is not None:
        arrays[i] = arrays[i].customized_copy(
          anomalous_flag=anomalous, info=arrays[i].info())
    return arrays

  def as_original_arrays(self):
    return self.original_arrays

fast_reader = reader # XXX backward compatibility 2010-08-25

def atom_type_cif_loop(xray_structure, format="mmcif"):
  format = format.lower()
  assert format in ("corecif", "mmcif")
  if format == "mmcif": separator = '.'
  else: separator = '_'

  sources = {
    "it1992": "International Tables Volume C Table 6.1.1.4 (pp. 500-502)",
    "wk1995": "Waasmaier & Kirfel (1995), Acta Cryst. A51, 416-431",
  }
  inelastic_references = {
    "henke" : "Henke, Gullikson and Davis, At. Data and Nucl. Data Tables, 1993, 54, 2",
    "sasaki" : "Sasaki, KEK Report, 1989, 88-14, 1",
  }

  scattering_type_registry = xray_structure.scattering_type_registry()
  unique_gaussians = scattering_type_registry.unique_gaussians_as_list()
  max_n_gaussians = max([gaussian.n_terms() for gaussian in unique_gaussians])
  max_n_gaussians = max(max_n_gaussians, 4) # Need for compliance with mmcif_pdbx_v50
  # _atom_type_* loop
  header = ['_atom_type%ssymbol' %separator,
            '_atom_type%sscat_dispersion_real' %separator,
            '_atom_type%sscat_dispersion_imag' %separator]
  header.extend(['_atom_type%sscat_Cromer_Mann_a%i' %(separator, i+1)
                 for i in range(max_n_gaussians)])
  header.extend(['_atom_type%sscat_Cromer_Mann_b%i' %(separator, i+1)
                 for i in range(max_n_gaussians)])
  header.extend(['_atom_type%sscat_Cromer_Mann_c' %separator,
                 '_atom_type%sscat_source' %separator,
                 '_atom_type%sscat_dispersion_source' %separator])
  atom_type_loop = model.loop(header=header)
  gaussian_dict = scattering_type_registry.as_type_gaussian_dict()
  scattering_type_registry = xray_structure.scattering_type_registry()
  params = xray_structure.scattering_type_registry_params
  fp_fdp_table = {}
  for sc in xray_structure.scatterers():
    fp_fdp_table.setdefault(sc.scattering_type, (sc.fp, sc.fdp))
  disp_source = inelastic_references.get(
    xray_structure.inelastic_form_factors_source)
  # custom?
  if disp_source is None:
    disp_source = xray_structure.inelastic_form_factors_source
  if disp_source is None:
    disp_source = "."
  for atom_type, gaussian in six.iteritems(scattering_type_registry.as_type_gaussian_dict()):
    scat_source = sources.get(params.table)
    if params.custom_dict and atom_type in params.custom_dict:
      scat_source = "Custom %i-Gaussian" %gaussian.n_terms()
    elif scat_source is None:
      scat_source = """\
%i-Gaussian fit: Grosse-Kunstleve RW, Sauter NK, Adams PD:
Newsletter of the IUCr Commission on Crystallographic Computing 2004, 3, 22-31."""
      scat_source = scat_source %gaussian.n_terms()
    if disp_source == ".":
      fp, fdp = ".", "."
    else:
      fp, fdp = fp_fdp_table[atom_type]
      fp = "%.5f" %fp
      fdp = "%.5f" %fdp
    row = [atom_type, fp, fdp]
    #gaussian = gaussian_dict[sc.scattering_type]
    gaussian_a = ["%.5f" %a for a in gaussian.array_of_a()]
    gaussian_b = ["%.5f" %a for a in gaussian.array_of_b()]
    gaussian_a.extend(["."]*(max_n_gaussians-gaussian.n_terms()))
    gaussian_b.extend(["."]*(max_n_gaussians-gaussian.n_terms()))
    row.extend(gaussian_a + gaussian_b)
    row.extend([gaussian.c(), scat_source, disp_source])
    atom_type_loop.add_row(row)

  return atom_type_loop


def miller_indices_as_cif_loop(indices, prefix='_refln_'):
    refln_loop = model.loop(header=(
      '%sindex_h' %prefix, '%sindex_k' %prefix, '%sindex_l' %prefix))
    for hkl in indices:
      refln_loop.add_row(hkl)
    return refln_loop


class miller_arrays_as_cif_block():

  def __init__(self, array, array_type=None,
               column_name=None, column_names=None,
               miller_index_prefix='_refln',
               format="mmcif"):
    wformat = format.lower()
    assert wformat in ("corecif", "mmcif")
    if wformat == "mmcif":
      separator = '.'
    else:
      separator = '_'
    self.cif_block = array.crystal_symmetry().as_cif_block(format=format)
    self.prefix = miller_index_prefix + separator
    self.indices = array.indices().deep_copy()
    self.refln_loop = None
    self.add_miller_array(array, array_type, column_name, column_names)
    self.cif_block.add_loop(self.refln_loop)

  def add_miller_array(self, array, array_type=None,
                       column_name=None, column_names=None):
    """
    Accepts a miller array, and one of array_type, column_name or column_names.
    """

    assert [array_type, column_name, column_names].count(None) == 2
    if array_type is not None:
      assert array_type in ('calc', 'meas')
    elif column_name is not None:
      column_names = [column_name]
    if array.is_complex_array():
      if column_names is None:
        column_names = [self.prefix+'F_'+array_type,
                        self.prefix+'phase_'+array_type]
      else: assert len(column_names) == 2
      if (('_A_' in column_names[0] and '_B_' in column_names[1]) or
          ('.A_' in column_names[0] and '.B_' in column_names[1])):
        data = [flex.real(array.data()).as_string(),
                 flex.imag(array.data()).as_string()]
      else:
        data = [flex.abs(array.data()).as_string(),
                 array.phases(deg=True).data().as_string()]
    elif array.is_hendrickson_lattman_array():
      if column_names is None:
        column_names = [self.prefix+'HL_%s_iso' %abcd for abcd in 'ABCD']
      else: assert len(column_names) == 4
      data = [d.as_string() for d in array.data().as_abcd()]
    else:
      if array_type is not None:
        if array.is_xray_intensity_array():
          obs_ext = 'squared_'
        else: obs_ext = ''
        column_names = [self.prefix+'F_'+obs_ext+array_type]
        if array.sigmas() is not None:
          column_names.append(self.prefix+'F_'+obs_ext+'sigma')
      if isinstance(array.data(), flex.std_string):
        data = [array.data()]
      else:
        data = [array.data().as_string()]
      if array.anomalous_flag():
        if ((array.sigmas() is not None and len(column_names) == 4) or
            (array.sigmas() is None and len(column_names) == 2)):
          data = []
          asu, matches = array.match_bijvoet_mates()
          for anomalous_sign in ("+", "-"):
            sel = matches.pairs_hemisphere_selection(anomalous_sign)
            sel.extend(matches.singles_hemisphere_selection(anomalous_sign))
            if (anomalous_sign == "+"):
              indices = asu.indices().select(sel)
              hemisphere_column_names = column_names[:len(column_names)//2]
            else:
              indices = -asu.indices().select(sel)
              hemisphere_column_names = column_names[len(column_names)//2:]
            hemisphere_data = asu.data().select(sel)
            hemisphere_array = miller.array(miller.set(
              array.crystal_symmetry(), indices), hemisphere_data)
            if array.sigmas() is not None:
              hemisphere_array.set_sigmas(asu.sigmas().select(sel))
            if self.refln_loop is None:
              # then this is the first array to be added to the loop,
              # hack so we don't have both hemispheres of indices
              self.indices = indices
            self.add_miller_array(
              hemisphere_array, column_names=hemisphere_column_names)
          return
      if array.sigmas() is not None and len(column_names) == 2:
        data.append(array.sigmas().as_string())
    if not (self.indices.size() == array.indices().size() and
            self.indices.all_eq(array.indices())):
      from cctbx.miller import match_indices
      other_indices = array.indices().deep_copy()
      match = match_indices(self.indices, other_indices)
      if match.singles(0).size():
        # array is missing some reflections indices that already appear in the loop
        # therefore pad the data with '?' values
        other_indices.extend(self.indices.select(match.single_selection(0)))
        for d in data:
          d.extend(flex.std_string(['?']*(other_indices.size() - d.size())))
        for d in data:
          assert d.size() == other_indices.size()
        match = match_indices(self.indices, other_indices)
      if match.singles(1).size():
        # this array contains some reflections that are not already present in the
        # cif loop, therefore need to add rows of '?' values
        single_indices = other_indices.select(match.single_selection(1))
        self.indices.extend(single_indices)
        n_data_columns = len(self.refln_loop) - 3
        for hkl in single_indices:
          row = list(hkl) + ['?'] * n_data_columns
          self.refln_loop.add_row(row)
        match = match_indices(self.indices, other_indices)

      match = match_indices(self.indices, other_indices)
      perm = match.permutation()
      data = [d.select(perm) for d in data]

    if self.refln_loop is None:
      self.refln_loop = miller_indices_as_cif_loop(self.indices, prefix=self.prefix)
    columns = OrderedDict(zip(column_names, data))
    for key in columns:
      assert key not in self.refln_loop
    self.refln_loop.add_columns(columns)


class cctbx_data_structures_from_cif(object):
  def __init__(self,
               file_object=None,
               file_path=None,
               cif_model=None,
               data_structure_builder=None,
               data_block_name=None,
               base_array_info=None,
              **kwds):
    assert file_object is None or cif_model is None
    if data_structure_builder is None:
      data_structure_builders = (
        builders.miller_array_builder, builders.crystal_structure_builder)
    else:
      assert data_structure_builder in (
        builders.miller_array_builder, builders.crystal_structure_builder)
      data_structure_builders = (data_structure_builder,)

    self.xray_structures = OrderedDict()
    self.miller_arrays = OrderedDict()
    self.original_arrays = OrderedDict()
    if cif_model is None:
      cif_model = reader(file_path=file_path, file_object=file_object).model()
    if not len(cif_model):
      raise Sorry("No data block found in CIF")
    if data_block_name is not None and not data_block_name in cif_model:
      if (file_path is None):
        msg = 'Unknown CIF data block name: "%s"' % data_block_name
      else:
        msg = 'Unknown CIF data block name "%s" in file: "%s"' % (
          data_block_name, file_path)
      raise RuntimeError(msg)
    errors = []
    wavelengths = {}
    for key, block in cif_model.items():
      if data_block_name is not None and key != data_block_name: continue
      for builder in data_structure_builders:
        if builder == builders.crystal_structure_builder:
          if '_atom_site_fract_x' in block or '_atom_site_Cartn_x' in block:
            self.xray_structures.setdefault(key, builder(block).structure)
        elif builder == builders.miller_array_builder:
          block_wavelengths = builders.get_wavelengths(block)
          if (block_wavelengths is not None):
            wavelengths = block_wavelengths
          if base_array_info is not None:
            base_array_info = base_array_info.customized_copy(labels=[key])
          if ( '_refln_index_h' in block or '_refln.index_h' in block or
               '_diffrn_refln' in block
               ):
            b = builder(block, base_array_info=base_array_info,
                wavelengths=wavelengths)
            self.miller_arrays.setdefault( key, b.arrays())
            self.original_arrays.setdefault( key, b.origarrays())


# This defines the order that categories will appear in the CIF file
category_order = [
  '_cell',
  '_space_group',
  '_space_group_symop',
  '_symmetry',
  '_computing',
  '_software',
  '_em_software',
  '_citation',
  '_citation_author',
  '_reflns',
  '_reflns_shell',
  '_refine',
  '_refine_ls_restr',
  '_refine_ls_shell',
  '_pdbx_refine_tls',
  '_pdbx_refine_tls_group',
  '_struct_asym',
  '_struct_conf_type',
  '_struct_conf',
  '_struct_conn',
  '_struct_sheet',
  '_struct_sheet_order',
  '_struct_sheet_range',
  '_pdbx_struct_sheet_hbond',
  '_struct_ncs_ens',
  '_struct_ncs_dom',
  '_struct_ncs_ens_gen',
  '_struct_ncs_dom_lim',
  '_struct_ncs_oper',
  '_refine_ls_restr_ncs',
  '_entity',
  '_entity_poly',
  '_entity_poly_seq',
  '_atom_type',
  '_chem_comp',
  '_chem_comp_atom',
  '_atom_site',
]

def category_sort_function(key):
  key_category = key.split('.')[0]
  try:
    return category_order.index(key_category)
  except ValueError as e:
    # any categories we don't know about will end up at the end of the file
    return len(category_order)


 *******************************************************************************


 *******************************************************************************
iotbx/cif/builders.py
from __future__ import absolute_import, division, print_function
from cctbx import adptbx, crystal, miller, sgtbx, uctbx, xray
from cctbx.array_family import flex
import iotbx.cif
from iotbx.cif import model
from libtbx.utils import Sorry
from libtbx.containers import OrderedDict, OrderedSet
import warnings
from six import string_types
from six.moves import range
import six, re
from six.moves import zip

# Refer to https://www.iucr.org/__data/iucr/cifdic_html/2/cif_mm.dic/index.html for definitons
# of elements and columns in a CIF file

class CifBuilderError(Sorry):
  __module__ = Exception.__module__

def CifBuilderWarning(message):
  warnings.showwarning(message, UserWarning, 'CifBuilderWarning', '')

class cif_model_builder(object):

  def __init__(self, cif_object=None):
    self._model = cif_object
    if self._model is None:
      self._model = model.cif()
    self._current_block = None
    self._current_save = None

  def add_data_block(self, data_block_heading):
    self._current_block = model.block()
    if data_block_heading.lower() == 'global_':
      block_name = data_block_heading
    else:
      block_name = data_block_heading[data_block_heading.find('_')+1:]
    self._model[block_name] = self._current_block

  def add_loop(self, header, columns):
    if self._current_save is not None:
      block = self._current_save
    else:
      block = self._current_block
    loop = model.loop()
    assert len(header) == len(columns)
    n_columns = len(columns)
    for i in range(n_columns):
      loop[header[i]] = columns[i]
    if loop.name() not in block.loops.keys():
      block.add_loop(loop)
    else:
      raise Sorry("Loop containing tags %s appears repeated" %', '.join(loop.keys()))

  def add_data_item(self, key, value):
    if self._current_save is not None:
      if key not in self._current_save:
        self._current_save[key] = value
      else:
        raise Sorry("Data item %s received multiple values" % key)
    elif self._current_block is not None:
      if key not in self._current_block:
        self._current_block[key] = value
      else:
        raise Sorry("Data item %s received multiple values" % key)
    else: # support for global_ blocks in non-strict mode
      pass

  def start_save_frame(self, save_frame_heading):
    assert self._current_save is None
    self._current_save = model.save()
    save_name = save_frame_heading[save_frame_heading.find('_')+1:]
    self._current_block[save_name] = self._current_save

  def end_save_frame(self):
    self._current_save = None

  def model(self):
    return self._model


class builder_base(object):

  __equivalents__ = {
    '_space_group_symop_operation_xyz': ('_symmetry_equiv_pos_as_xyz',
                                         '_space_group_symop.operation_xyz',
                                         '_symmetry_equiv.pos_as_xyz'),
    '_space_group_symop_id': ('_symmetry_equiv_pos_site_id',
                              '_space_group_symop.id',
                              '_symmetry_equiv.id'),
    '_space_group_name_Hall': ('_symmetry_space_group_name_Hall',
                               '_space_group.name_Hall',
                               '_symmetry.space_group_name_Hall'),
    '_space_group_name_H-M_alt': ('_symmetry_space_group_name_H-M',
                                  '_space_group.name_H-M_alt',
                                  '_symmetry.space_group_name_H-M'),
    '_space_group_IT_number': ('_symmetry_Int_Tables_number',
                                 '_symmetry.Int_Tables_number'
                                 '_space_group.IT_number'),
    '_cell_length_a': ('_cell.length_a',),
    '_cell_length_b': ('_cell.length_b',),
    '_cell_length_c': ('_cell.length_c',),
    '_cell_angle_alpha': ('_cell.angle_alpha',),
    '_cell_angle_beta': ('_cell.angle_beta',),
    '_cell_angle_gamma': ('_cell.angle_gamma',),
    '_cell_volume': ('_cell.volume',),
    '_refln_index_h': ('_refln.index_h',),
    '_refln_index_k': ('_refln.index_k',),
    '_refln_index_l': ('_refln.index_l',),
  }

  def get_cif_item(self, key, default=None):
    value = self.cif_block.get(key)
    if value is not None: return value
    for equiv in self.__equivalents__.get(key, []):
      value = self.cif_block.get(equiv)
      if value is not None: return value
    return default


class crystal_symmetry_builder(builder_base):

  def __init__(self, cif_block, strict=False):
    # The order of priority for determining space group is:
    #   sym_ops, hall symbol, H-M symbol, space group number
    self.cif_block = cif_block
    sym_ops = self.get_cif_item('_space_group_symop_operation_xyz')
    sym_op_ids = self.get_cif_item('_space_group_symop_id')
    space_group = None
    space_group_from_ops = None
    space_group_from_other = None
    # Symmetry from operators
    if sym_ops is not None:
      if isinstance(sym_ops, string_types):
        sym_ops = flex.std_string([sym_ops])
      if sym_op_ids is not None:
        if isinstance(sym_op_ids, string_types):
          sym_op_ids = flex.std_string([sym_op_ids])
        assert len(sym_op_ids) == len(sym_ops)
      self.sym_ops = {}
      space_group_from_ops = sgtbx.space_group()
      if isinstance(sym_ops, string_types): sym_ops = [sym_ops]
      for i, op in enumerate(sym_ops):
        try:
          s = sgtbx.rt_mx(op)
        except RuntimeError as e:
          str_e = str(e)
          if "Parse error: " in str_e:
            raise CifBuilderError("Error interpreting symmetry operator: %s" %(
              str_e.split("Parse error: ")[-1]))
          else:
            raise
        if sym_op_ids is None:
          sym_op_id = i+1
        else:
          try:
            sym_op_id = int(sym_op_ids[i])
          except ValueError as e:
            raise CifBuilderError("Error interpreting symmetry operator id: %s" %(
              str(e)))
        self.sym_ops[sym_op_id] = s
        space_group_from_ops.expand_smx(s)
    # Symmetry from other
    hall_symbol = self.get_cif_item('_space_group_name_Hall')
    hm_symbol = self.get_cif_item('_space_group_name_H-M_alt')
    sg_number = self.get_cif_item('_space_group_IT_number')
    if sg_number not in (None, '?'):
      try: space_group_from_other = sgtbx.space_group_info(number=sg_number).group()
      except Exception: pass
    if hall_symbol not in (None, '?'):
      try: space_group_from_other = sgtbx.space_group(hall_symbol)
      except Exception: pass
    if hm_symbol not in (None, '?'):
      try: space_group_from_other = sgtbx.space_group_info(symbol=hm_symbol).group()
      except Exception: pass
    # Check consistency.
    # Use space group equivalence operation in cctbx.sgtbx.space_group

    if (space_group_from_other is not None) and (
       space_group_from_ops is not None) and (not
         space_group_from_other == space_group_from_ops):
      ops1 = [o.as_xyz() for o in space_group_from_other.all_ops()]
      ops2 = [o.as_xyz() for o in space_group_from_ops.all_ops()]
      ops1.sort()
      ops2.sort()
      msg1 = "\n"+"\n".join(ops1)+"\n"
      msg2 = "\n"+"\n".join(ops2)
      raise CifBuilderError(
          "Inconsistent symmetry information found:%s ---vs---%s"%(msg1, msg2))
    for sg in [space_group_from_other, space_group_from_ops]:
      if(sg is not None):
        space_group = sg
        break
    if (space_group is None and strict):
      raise CifBuilderError(
        "No symmetry instructions could be extracted from the cif block")
    #
    items = [self.get_cif_item("_cell_length_"+s) for s in "abc"]
    for i, item in enumerate(items):
      if isinstance(item, flex.std_string):
        raise CifBuilderError(
          "Data item _cell_length_%s cannot be declared in a looped list"
          %("abc"[i]))
    for s in ["alpha", "beta", "gamma"]:
      item = self.get_cif_item("_cell_angle_"+s)
      if isinstance(item, flex.std_string):
        raise CifBuilderError(
          "Data item _cell_angle_%s cannot be declared in a looped list" %s)
      if (item == "?"):
        item = "90" # enumeration default for angles is 90 degrees
      items.append(item)
    ic = items.count(None)
    ic_question = items.count('?')
    if ic == 6 or ic_question > 0:
      if (strict):
        raise CifBuilderError(
          "Unit cell parameters not found in the cif file")
      unit_cell = None
    elif (ic == 0):
      try:
        vals = [float_from_string(s) for s in items]
      except ValueError:
        raise CifBuilderError("Invalid unit cell parameters are given")
      try:
        unit_cell = uctbx.unit_cell(vals)
      except RuntimeError as e:
        if "cctbx Error: Unit cell" in str(e):
          raise CifBuilderError(e)
        else:
          raise
    elif (space_group is not None):
      unit_cell = uctbx.infer_unit_cell_from_symmetry(
        [float_from_string(s) for s in items if s is not None], space_group)
    else:
      raise CifBuilderError(
        "Not all unit cell parameters are given in the cif file")
    if unit_cell is not None and space_group is not None:
      if not space_group.is_compatible_unit_cell(unit_cell):
        # try primitive setting
        space_group_input = space_group
        space_group = space_group.info().primitive_setting().group()
        if not space_group.is_compatible_unit_cell(unit_cell):
          raise CifBuilderError(
            "Space group is incompatible with unit cell parameters:\n" + \
            "  Space group: %s\n" %space_group_input.info() + \
            "  Unit cell: %s" %unit_cell)
    self.crystal_symmetry = crystal.symmetry(unit_cell=unit_cell,
                                             space_group=space_group)

class crystal_structure_builder(crystal_symmetry_builder):

  def __init__(self, cif_block):
    # XXX To do: interpret _atom_site_refinement_flags
    crystal_symmetry_builder.__init__(self, cif_block, strict=True)
    atom_sites_frac = [
      as_double_or_none_if_all_question_marks(
        _, column_name='_atom_site_fract_%s' %axis)
      for _, axis in [(cif_block.get('_atom_site_fract_%s' %axis), axis)
                      for axis in ('x','y','z')]]
    if atom_sites_frac.count(None) == 3:
      atom_sites_cart = [as_double_or_none_if_all_question_marks(
        _, column_name='_atom_site_Cartn_%s' %axis)
                         for _ in [cif_block.get('_atom_site_Cartn_%s' %axis)
                                   for axis in ('x','y','z')]]
      if atom_sites_cart.count(None) != 0:
        raise CifBuilderError("No atomic coordinates could be found")
      atom_sites_cart = flex.vec3_double(*atom_sites_cart)
      # XXX do we need to take account of _atom_sites_Cartn_tran_matrix_ ?
      atom_sites_frac = self.crystal_symmetry.unit_cell().fractionalize(
        atom_sites_cart)
    else:
      if atom_sites_frac.count(None) != 0:
        raise CifBuilderError("No atomic coordinates could be found")
      atom_sites_frac = flex.vec3_double(*atom_sites_frac)
    labels = cif_block.get('_atom_site_label')
    type_symbol = cif_block.get('_atom_site_type_symbol')
    if type_symbol:
      type_symbol = flex.std_string(
        s.replace('0+', '').replace('0-', '') for s in type_symbol)
    U_iso_or_equiv = flex_double_else_none(
      cif_block.get('_atom_site_U_iso_or_equiv',
      cif_block.get('_atom_site_U_equiv_geom_mean')))
    if U_iso_or_equiv is None:
      B_iso_or_equiv = flex_double_else_none(
        cif_block.get('_atom_site_B_iso_or_equiv',
        cif_block.get('_atom_site_B_equiv_geom_mean')))
    adp_type = cif_block.get('_atom_site_adp_type')
    occupancy = flex_double_else_none(cif_block.get('_atom_site_occupancy'))
    scatterers = flex.xray_scatterer()
    atom_site_aniso_label = flex_std_string_else_none(
      cif_block.get('_atom_site_aniso_label'))
    if atom_site_aniso_label is not None:
      atom_site_aniso_label = atom_site_aniso_label
      adps = [cif_block.get('_atom_site_aniso_U_%i' %i)
              for i in (11,22,33,12,13,23)]
      have_Bs = False
      if adps.count(None) > 0:
        adps = [cif_block.get('_atom_site_aniso_B_%i' %i)
                for i in (11,22,33,12,13,23)]
        have_Bs = True
      if adps.count(None) == 6:
        adps = None
      elif adps.count(None) > 0:
        CifBuilderError("Some ADP items are missing")
      else:
        sel = None
        for adp in adps:
          f = (adp == "?")
          if (sel is None): sel = f
          else:             sel &= f
        sel = ~sel
        atom_site_aniso_label = atom_site_aniso_label.select(sel)
        try:
          adps = [flex.double(adp.select(sel)) for adp in adps]
        except ValueError as e:
          raise CifBuilderError("Error interpreting ADPs: " + str(e))
        adps = flex.sym_mat3_double(*adps)
    for i in range(len(atom_sites_frac)):
      kwds = {}
      if labels is not None:
        kwds.setdefault('label', str(labels[i]))
      if type_symbol is not None:
        kwds.setdefault('scattering_type', str(type_symbol[i]))
      if (atom_site_aniso_label is not None
          and adps is not None
          and labels is not None
          and labels[i] in atom_site_aniso_label):
        adp = adps[flex.first_index(atom_site_aniso_label, labels[i])]
        if have_Bs: adp = adptbx.b_as_u(adp)
        kwds.setdefault('u', adptbx.u_cif_as_u_star(
          self.crystal_symmetry.unit_cell(), adp))
      elif U_iso_or_equiv is not None:
        kwds.setdefault('u', float_from_string(U_iso_or_equiv[i]))
      elif B_iso_or_equiv is not None:
        kwds.setdefault('b', float_from_string(B_iso_or_equiv[i]))
      if occupancy is not None:
        kwds.setdefault('occupancy', float_from_string(occupancy[i]))
      scatterers.append(xray.scatterer(**kwds))
    scatterers.set_sites(atom_sites_frac)

    wvl_str = self.get_cif_item('_diffrn_radiation_wavelength')
    if not isinstance(wvl_str, str) and wvl_str is not None:
      wvl_str = wvl_str[0]
    wavelength = float_from_string(wvl_str) if (wvl_str and wvl_str!='?') else None

    self.structure = xray.structure(crystal_symmetry=self.crystal_symmetry,
                                    scatterers=scatterers,
                                    wavelength=wavelength)


class miller_array_builder(crystal_symmetry_builder):
  # Changes to this class should pass regression tests:
  # cctbx_project\mmtbx\regression\tst_cif_as_mtz_wavelengths.py
  # cctbx_project\iotbx\cif\tests\tst_lex_parse_build.py
  # phenix_regression\cif_as_mtz\tst_cif_as_mtz.py

  observation_types = {
    # known types of column data to be tagged as either amplitudes or intensities as per
    # https://www.iucr.org/__data/iucr/cifdic_html/2/cif_mm.dic/index.html
    '_refln.F_squared': xray.intensity(),
    '_refln_F_squared': xray.intensity(),
    '_refln.intensity': xray.intensity(),
    '_refln.I(+)': xray.intensity(),
    '_refln.I(-)': xray.intensity(),
    '_refln.F_calc': xray.amplitude(),
    '_refln.F_meas': xray.amplitude(),
    '_refln.FP': xray.amplitude(),
    '_refln.F-obs': xray.amplitude(),
    '_refln.Fobs': xray.amplitude(),
    '_refln.F-calc': xray.amplitude(),
    '_refln.Fcalc': xray.amplitude(),
    '_refln.pdbx_F_': xray.amplitude(),
    '_refln.pdbx_I_': xray.intensity(),
    '_refln.pdbx_anom_difference': xray.amplitude(),
  }

  def guess_observationtype(self, labl):
    for okey in self.observation_types.keys():
      if labl.startswith(okey):
        return self.observation_types[okey]
    return None

  def __init__(self, cif_block, base_array_info=None, wavelengths=None):
    crystal_symmetry_builder.__init__(self, cif_block)
    self._arrays = OrderedDict()
    self._origarrays = OrderedDict() # used for presenting raw data tables in HKLviewer
    basearraylabels = []
    if base_array_info is not None:
      self.crystal_symmetry = self.crystal_symmetry.join_symmetry(
        other_symmetry=base_array_info.crystal_symmetry_from_file,
      force=True)
      if base_array_info.labels:
        basearraylabels = base_array_info.labels
    if (wavelengths is None):
      wavelengths = {}
    if base_array_info is None:
      base_array_info = miller.array_info(source_type="cif")
    refln_containing_loops = self.get_miller_indices_containing_loops()
    for self.indices, refln_loop in refln_containing_loops:
      self.wavelength_id_array = None
      self.crystal_id_array = None
      self.scale_group_array = None
      wavelength_ids = [None]
      crystal_ids = [None]
      scale_groups = [None]
      for key, value in six.iteritems(refln_loop):
        # Get wavelength_ids, crystal_id, scale_group_code columns for selecting data of other
        # columns in self.get_selection() used by self.flex_std_string_as_miller_array()
        if (key.endswith('wavelength_id') or
            key.endswith('crystal_id') or
            key.endswith('scale_group_code')):
          data = as_int_or_none_if_all_question_marks(value, column_name=key)
          if data is None:
            continue
          counts = data.counts()
          if key.endswith('wavelength_id'):
            wavelength_ids = list(counts.keys())
          if len(counts) == 1: continue
          array = miller.array(
            miller.set(self.crystal_symmetry, self.indices).auto_anomalous(), data)
          if key.endswith('wavelength_id'):
            self.wavelength_id_array = array
            wavelength_ids = list(counts.keys())
          elif key.endswith('crystal_id'):
            self.crystal_id_array = array
            crystal_ids = list(counts.keys())
          elif key.endswith('scale_group_code'):
            self.scale_group_array = array
            scale_groups = list(counts.keys())
      labelsuffix = []
      wavelbl = []
      cryslbl = []
      scalegrplbl = []
      self._origarrays["HKLs"] = self.indices
      alllabels = list(sorted(refln_loop.keys()))
      remaininglabls = alllabels[:] # deep copy the list
      # Parse labels matching cif column conventions
      # https://mmcif.wwpdb.org/dictionaries/mmcif_pdbx_v50.dic/Categories/refln.html
      # and extract groups of labels or just single columns.
      # Groups corresponds to the map coefficients, phase and amplitudes,
      # amplitudes or intensities with sigmas and hendrickson-lattman columns.
      phaseamplabls, remaininglabls = self.get_phase_amplitude_labels(remaininglabls)
      mapcoefflabls, remaininglabls = self.get_mapcoefficient_labels(remaininglabls)
      HLcoefflabls, remaininglabls = self.get_HL_labels(remaininglabls)
      data_sig_obstype_labls, remaininglabls = self.get_FSigF_ISigI_labels(remaininglabls)
      for w_id in wavelength_ids:
        for crys_id in crystal_ids:
          for scale_group in scale_groups:
            # If reflection data files contain more than one crystal, wavelength or scalegroup
            # then add their id(s) as a suffix to data labels computed below. Needed for avoiding
            # ambuguity but avoid when not needed to make labels more human readable!
            if (len(wavelength_ids) > 1 or len(wavelengths) > 1) and w_id is not None:
              wavelbl = ["wavelength_id=%i" %w_id]
            if len(crystal_ids) > 1 and crys_id is not None:
              cryslbl = ["crystal_id=%i" %crys_id]
            if len(scale_groups) > 1 and scale_group is not None:
              scalegrplbl = ["scale_group_code=%i" %scale_group]
            labelsuffix = scalegrplbl + cryslbl + wavelbl
            jlablsufx = ""
            if len(labelsuffix):
              jlablsufx = "," + ",".join(labelsuffix)
            for mapcoefflabl in mapcoefflabls:
              A_array = refln_loop[ mapcoefflabl[0] ]
              B_array = refln_loop[ mapcoefflabl[1] ]
              # deselect any ? marks in the two arrays, assuming both A and B have the same ? marks
              selection = self.get_selection( A_array, wavelength_id=w_id,
               crystal_id=crys_id, scale_group_code=scale_group)
              A_array = A_array.select(selection)
              B_array = B_array.select(selection)
              # form the miller array with map coefficients
              data = flex.complex_double( flex.double(A_array), flex.double(B_array) )
              millarr = miller.array( miller.set(self.crystal_symmetry,
                                             self.indices.select(selection)
                                            ).auto_anomalous(), data)
              # millarr will be None for column data not matching w_id,crys_id,scale_group values
              if millarr is None: continue
              labl = basearraylabels + mapcoefflabl + labelsuffix
              millarr.set_info(base_array_info.customized_copy(labels= labl ,
                                                wavelength=wavelengths.get(w_id, None)))
              self._arrays[mapcoefflabl[0] + jlablsufx ] = millarr
            for phaseamplabl in phaseamplabls:
              amplitudestrarray = refln_loop[ phaseamplabl[0] ]
              phasestrarray = refln_loop[ phaseamplabl[1] ]
              millarr = self.flex_std_string_as_miller_array(
                amplitudestrarray, wavelength_id=w_id, crystal_id=crys_id,
                scale_group_code=scale_group)
              phasesmillarr = self.flex_std_string_as_miller_array(
                phasestrarray, wavelength_id=w_id, crystal_id=crys_id,
                scale_group_code=scale_group)
              # millarr will be None for column data not matching w_id,crys_id,scale_group values
              if millarr is None or phasesmillarr is None: continue
              if(not check_array_sizes(millarr, phasesmillarr, phaseamplabl[0], phaseamplabl[1])):
                continue
              phases = as_flex_double(phasesmillarr, phaseamplabl[1])
              millarr = millarr.phase_transfer(phases, deg=True)
              labl = basearraylabels + phaseamplabl + labelsuffix
              millarr.set_info(base_array_info.customized_copy(labels= labl ,
                                                wavelength=wavelengths.get(w_id, None)))
              self._arrays[phaseamplabl[0] +jlablsufx ] = millarr
            for datlabl,siglabl,otype in data_sig_obstype_labls:
              datastrarray = refln_loop[datlabl]
              millarr = self.flex_std_string_as_miller_array(
                datastrarray, wavelength_id=w_id, crystal_id=crys_id,
                scale_group_code=scale_group)
              # millarr will be None for column data not matching w_id,crys_id,scale_group values
              if millarr is None: continue
              millarr = as_flex_double(millarr, datlabl)
              datsiglabl = [datlabl]
              if siglabl:
                sigmasstrarray = refln_loop[siglabl]
                sigmas = self.flex_std_string_as_miller_array(
                  sigmasstrarray, wavelength_id=w_id, crystal_id=crys_id,
                  scale_group_code=scale_group)
                sigmas = as_flex_double(sigmas, siglabl)
                if check_array_sizes(millarr, sigmas, datlabl, siglabl):
                  millarr.set_sigmas(sigmas.data())
                  datsiglabl = [datlabl, siglabl]
                else:
                  sigmas.set_info(base_array_info.customized_copy(labels= [siglabl],
                                                    wavelength=wavelengths.get(w_id, None)))
                  self._arrays[ siglabl +jlablsufx ] = sigmas

              datsiglabl = basearraylabels + datsiglabl + labelsuffix
              millarr.set_info(base_array_info.customized_copy(labels= datsiglabl,
                                                wavelength=wavelengths.get(w_id, None)))
              if otype is not None:
                millarr.set_observation_type(otype)
              self._arrays[ datlabl +jlablsufx ] = millarr
            for hl_labels in HLcoefflabls:
              hl_values = [ cif_block.get(hl_key) for hl_key in hl_labels ]
              if hl_values.count(None) == 0:
                selection = self.get_selection(
                  hl_values[0], wavelength_id=w_id,
                  crystal_id=crys_id, scale_group_code=scale_group)
                hl_values = [as_double_or_none_if_all_question_marks(
                  hl.select(selection), column_name=lab)
                              for hl, lab in zip(hl_values, hl_labels)]
                # hl_values will be None for column data not matching w_id,crys_id,scale_group values
                if hl_values == [None,None,None,None]: continue
                millarr = miller.array(miller.set(
                  self.crystal_symmetry, self.indices.select(selection)
                  ).auto_anomalous(), flex.hendrickson_lattman(*hl_values))
                hlabels = basearraylabels + hl_labels + labelsuffix
                millarr.set_info(base_array_info.customized_copy(labels= hlabels,
                                                  wavelength=wavelengths.get(w_id, None)))
                self._arrays[ hl_labels[0] + jlablsufx ] = millarr
            # pick up remaining columns if any that weren't identified above
            for label in alllabels:
              if "index_" in label:
                continue
              datastrarray = refln_loop[label]
              if label in remaininglabls:
                labels = basearraylabels + [label]  + labelsuffix
                lablsufx = jlablsufx
                millarr = self.flex_std_string_as_miller_array(
                  datastrarray, wavelength_id=w_id, crystal_id=crys_id,
                  scale_group_code=scale_group)
                # millarr will be None for column data not matching w_id,crys_id,scale_group values
                if (label.endswith('wavelength_id') or
                 label.endswith('crystal_id') or # get full array if any of these labels, not just subsets
                 label.endswith('scale_group_code')):
                  millarr = self.flex_std_string_as_miller_array(
                    datastrarray, wavelength_id=None, crystal_id=None,
                    scale_group_code=None)
                  lablsufx = ""
                  labels = basearraylabels + [label]
                if millarr is None: continue
                otype = self.guess_observationtype(label)
                if otype is not None:
                  millarr.set_observation_type(otype)
                millarr.set_info(base_array_info.customized_copy(labels= labels,
                                                  wavelength=wavelengths.get(w_id, None)))
                self._arrays[ label + lablsufx ] = millarr
              origarr = self.flex_std_string_as_miller_array(
                  datastrarray, wavelength_id=w_id, crystal_id=crys_id,
                  scale_group_code=scale_group,
                  allowNaNs=True)
              newlabel = label.replace("_refln.", "")
              newlabel2 = newlabel.replace("_refln_", "")
              if origarr: # want only genuine miller arrays
                self._origarrays[newlabel2 + jlablsufx ] = origarr.data()
    # Convert any groups of I+,I-,SigI+,SigI- (or amplitudes) arrays into anomalous arrays
    # i.e. both friedel mates in the same array
    for key, array in six.iteritems(self._arrays.copy()):
      plus_key = ""
      if '_minus' in key:
        minus_key = key
        plus_key = key.replace('_minus', '_plus')
      elif '-' in key:
        minus_key = key
        plus_key = key.replace('-', '+')
      elif '_plus' in key:
        plus_key = key
        minus_key = key.replace('_plus', '_minus')
      elif '+' in key:
        plus_key = key
        minus_key = key.replace('+', '-')
      if plus_key in self._arrays and minus_key in self._arrays:
        plus_array = self._arrays.pop(plus_key)
        minus_array = self._arrays.pop(minus_key)
        minus_array = minus_array.customized_copy(
          indices=-minus_array.indices()).set_info(minus_array.info())
        array = plus_array.concatenate(
          minus_array, assert_is_similar_symmetry=False)
        array = array.customized_copy(anomalous_flag=True)
        array.set_info(minus_array.info().customized_copy(
          labels=list(
            OrderedSet(plus_array.info().labels+minus_array.info().labels))))
        array.set_observation_type(plus_array.observation_type())
        self._arrays.setdefault(key, array)
    if len(self._arrays) == 0:
      raise CifBuilderError("No reflection data present in cif block")
    # Sort the ordered dictionary to resemble the order of columns in the cif file
    # This is to avoid any F_meas arrays accidentally being put adjacent to
    # pdbx_anom_difference arrays in the self._arrays OrderedDict. Otherwise these
    # arrays may unintentionally be combined into a reconstructed anomalous amplitude
    # array when saving as an mtz file due to a problem in the iotbx/mtz module.
    # See http://phenix-online.org/pipermail/cctbxbb/2021-March/002289.html
    arrlstord = []
    arrlst = list(self._arrays)
    for arr in arrlst:
      for i,k in enumerate(refln_loop.keys()):
        if arr.split(",")[0] == k:
          arrlstord.append((arr, i))
    # arrlstord must have the same keys as in the self._arrays dictionary
    assert sorted(arrlst) == sorted([ e[0] for e in arrlstord] )
    sortarrlst = sorted(arrlstord, key=lambda arrord: arrord[1])
    self._ordarrays = OrderedDict()
    for sortkey,i in sortarrlst:
      self._ordarrays.setdefault(sortkey, self._arrays[sortkey])
    self._arrays = self._ordarrays


  def get_HL_labels(self, keys):
    lstkeys = list(keys) # cast into list if not a list
    HLquads = []
    alllabels = " ".join(lstkeys)
    """ Hendrickson-Lattmann labels could look like: 'HLAM', 'HLBM', 'HLCM', 'HLDM'
    or like 'HLanomA', 'HLanomB', 'HLanomC', 'HLanomD'
    Use a regular expression to group them accordingly
    """
    allmatches = re.findall(r"(\S*(HL(\S*)[abcdABCD](\S*)))", alllabels )
    HLtagslst = list(set([ (e[2], e[3]) for e in allmatches ]))
    usedkeys = []
    for m in HLtagslst:
      hllist = []
      for hm in allmatches:
        if m==(hm[2], hm[3]):
          hllist.append((hm[0], hm[1]))
      if len(hllist) == 4:
        HLquads.append([ e[0] for e in hllist])
        for e in hllist:
          usedkeys.append(e[0])
    remainingkeys = []
    for e in lstkeys:
      if e not in usedkeys:
        remainingkeys.append(e)
    return HLquads, remainingkeys


  def get_mapcoefficient_labels(self, keys):
    # extract map coeffficients labels from list of cif column labels
    # e.g. ( _refln.A_calc_au _refln.B_calc_au ) , ( _refln.A_calc _refln.B_calc )
    lstkeys = list(keys) # cast into list if not a list
    remainingkeys = lstkeys[:] # deep copy the list
    alllabels = " ".join(lstkeys)
    mapcoefflabels = []
    A_matches = re.findall(r"( (\s*_refln[\._]A_)(\S*) )", alllabels, re.VERBOSE ) # [('_refln.PHWT', '_refln.PH', 'WT'), ('_refln.PHDELWT', '_refln.PH', 'DELWT')]
    for label in lstkeys:
      for m in A_matches:
        Blabel = m[1].replace("A_","B_") + m[2]
        if Blabel == label:
          mapcoefflabels.append([ m[0], label])
          remainingkeys.remove(m[0])
          remainingkeys.remove(label)
    return mapcoefflabels, remainingkeys


  def get_phase_amplitude_labels(self, keys):
    # extract phase and amplitudes labels from list of cif column labels
    # e.g. ( _refln.F_calc _refln.phase_calc ) , ( _refln.FC_ALL _refln.PHIC_ALL ), ( _refln.FWT _refln.PHWT )
    lstkeys = list(keys) # cast into list if not a list
    remainingkeys = lstkeys[:] # deep copy the list
    alllabels = " ".join(lstkeys)
    phase_amplitudelabels = []
    PHmatches = re.findall(r"((\S*PH)([^I]\S*))", alllabels ) # [('_refln.PHWT', '_refln.PH', 'WT'), ('_refln.PHDELWT', '_refln.PH', 'DELWT')]
    for label in lstkeys:
      for m in PHmatches:
        PFlabel = m[1].replace("PH","F") + m[2]
        Flabel = m[1].replace("PH","") + m[2]
        if Flabel == label or PFlabel == label:
          phase_amplitudelabels.append([ label, m[0]])
          remainingkeys.remove(label)
          remainingkeys.remove(m[0])
    alllabels = " ".join(remainingkeys)
    PHImatches = re.findall(r"((\S*PHI)(\S*))", alllabels ) # [('_refln.PHIC', '_refln.PHI', 'C'), ('_refln.PHIC_ALL', '_refln.PHI', 'C_ALL')]
    for label in lstkeys:
      for m in PHImatches:
        PFlabel = m[1].replace("PHI","F") + m[2]
        Flabel = m[1].replace("PHI","") + m[2]
        if Flabel == label or PFlabel == label:
          phase_amplitudelabels.append([ label, m[0]])
          remainingkeys.remove(label)
          remainingkeys.remove(m[0])
    alllabels = " ".join(remainingkeys)
    PHDELmatches = re.findall(r"(((\S*)PH)([^I]\S*(WT)))", alllabels ) # [('_refln.PHDELWT', '_refln.PH', '_refln.', 'DELWT', 'WT')]
    for label in lstkeys:
      for m in PHDELmatches:
        Flabel = m[2] + m[3].replace("WT","FWT")
        if Flabel == label:
          phase_amplitudelabels.append([ label, m[0]])
          remainingkeys.remove(label)
          remainingkeys.remove(m[0])
    alllabels = " ".join(remainingkeys)
    phase_matches = re.findall(r"((\S*[\._])phase(\S*))", alllabels ) # [('_refln.phase_calc', '_refln.', '')]
    for label in lstkeys:
      for m in phase_matches:
        phaselabel = m[0]
        Flabl = m[1] + m[2]
        Flabel = m[1] + "F" + m[2]
        Faulabel = m[1] + "F" + m[2] + "_au"
        if Flabl in label or Flabel in label or Faulabel in label: # in case of _refln.F_calc_au and _refln.phase_calc
          if label in remainingkeys and m[0] in remainingkeys: # in case
            if (Flabel + "_sigma_au") in remainingkeys or (Flabel + "_sigma") in remainingkeys:
              continue # give priority to F_meas, F_meas_sigma or  F_meas_au, F_meas_sigma_au
            phase_amplitudelabels.append([ label, m[0]])
            remainingkeys.remove(label)
            remainingkeys.remove(m[0])
    return phase_amplitudelabels, remainingkeys


  def get_FSigF_ISigI_labels(self, keys):
    # extract amplitudea, sigmas or intensitiy, sigmas labels from list of cif column labels
    # e.g. ( _refln.F_meas_sigma_au _refln.F_meas), ( _refln.intensity_sigma _refln.intensity ) ,
    # ( _refln.pdbx_I_plus_sigma _refln.pdbx_I_plus )
    lstkeys = list(keys) # cast into list if not a list
    remainingkeys = lstkeys[:] # deep copy the list
    alllabels = " ".join(lstkeys)
    labelpairs = []
    sigma_matches = re.findall(r"((\S*[\._])SIG(\S*))", alllabels ) # catch label pairs like F(+),SIGF(+)
    for label in lstkeys:
      for m in sigma_matches:
        FIlabel = m[1] + m[2]
        if FIlabel == label:
          labelpairs.append([ label, m[0], self.guess_observationtype(label)])
          remainingkeys.remove(label)
          remainingkeys.remove(m[0])
    alllabels = " ".join(remainingkeys)
    sigma_matches = re.findall(r"((\S*)_sigma(_*\S*))", alllabels ) # [('_refln.F_meas_sigma_au', '_refln.F_meas', '_au'), ('_refln.intensity_sigma', '_refln.intensity', ''), ('_refln.pdbx_I_plus_sigma', '_refln.pdbx_I_plus', '')]
    for label in lstkeys:
      for m in sigma_matches:
        FIlabel = m[1] + m[2]
        if FIlabel == label:
          labelpairs.append([ label, m[0], self.guess_observationtype(label)])
          remainingkeys.remove(label)
          remainingkeys.remove(m[0])
    alllabels = " ".join(remainingkeys)
    # catch generic meas and sigma labels
    anymeas_matches = re.findall(r"((\S*)_meas(\S*))", alllabels ) + re.findall(r"((\S*)_calc(\S*))", alllabels )
    anysigma_matches = re.findall(r"((\S*)_sigma(\S*))", alllabels )
    for mmatch in anymeas_matches:
      for smatch in anysigma_matches:
        if mmatch[1]==smatch[1] and mmatch[2]==smatch[2]:
          remainingkeys.remove(mmatch[0])
          if smatch[0] in remainingkeys: # in case of say F_squared_calc, F_squared_meas, F_squared_sigma all being present
            remainingkeys.remove(smatch[0])
            labelpairs.append([ mmatch[0], smatch[0], self.guess_observationtype(mmatch[0])])
          else:
            labelpairs.append([ mmatch[0], None, self.guess_observationtype(mmatch[0])])
    return labelpairs, remainingkeys


  def get_miller_indices_containing_loops(self):
    loops = []
    for loop in self.cif_block.loops.values():
      for key in loop.keys():
        if 'index_h' not in key: continue
        hkl_str = [loop.get(key.replace('index_h', 'index_%s' %i)) for i in 'hkl']
        if hkl_str.count(None) > 0:
          raise CifBuilderError(
            "Miller indices missing from current CIF block (%s)"
            %key.replace('index_h', 'index_%s' %'hkl'[hkl_str.index(None)]))
        hkl_int = []
        for i,h_str in enumerate(hkl_str):
          try:
            h_int = flex.int(h_str)
          except ValueError as e:
            raise CifBuilderError(
              "Invalid item for Miller index %s: %s" % ("HKL"[i], str(e)))
          hkl_int.append(h_int)
        indices = flex.miller_index(*hkl_int)
        loops.append((indices, loop))
        break
    return loops


  def get_selection(self, value,
                    wavelength_id=None,
                    crystal_id=None,
                    scale_group_code=None,
                    allowNaNs = False):
    if allowNaNs:
      selection = flex.bool(value.size(), True)
    else:
      selection = ~((value == '.') | (value == '?'))
    if self.wavelength_id_array is not None and wavelength_id is not None:
      selection &= (self.wavelength_id_array.data() == wavelength_id)
    if self.crystal_id_array is not None and crystal_id is not None:
      selection &= (self.crystal_id_array.data() == crystal_id)
    if self.scale_group_array is not None and scale_group_code is not None:
      selection &= (self.scale_group_array.data() == scale_group_code)
    return selection


  def flex_std_string_as_miller_array(self, value,
                                      wavelength_id=None,
                                      crystal_id=None,
                                      scale_group_code=None,
                                      allowNaNs = False):
    # Create a miller_array object of only the data and indices matching the
    # wavelength_id, crystal_id and scale_group_code submitted or full array if these are None
    selection = self.get_selection(
      value, wavelength_id=wavelength_id,
      crystal_id=crystal_id, scale_group_code=scale_group_code,
      allowNaNs=allowNaNs)
    data = value.select(selection)
    try:
      data = flex.int(data)
      indices = self.indices.select(selection)
    except ValueError:
      try:
        data = flex.double(data)
        indices = self.indices.select(selection)
      except ValueError:
        # if flex.std_string return all values including '.' and '?'
        data = value
        indices = self.indices
    if data.size() == 0: return None
    return miller.array(
      miller.set(self.crystal_symmetry, indices).auto_anomalous(), data)


  def arrays(self):
    return self._arrays


  def origarrays(self):
    """
    return dictionary of raw data found in cif file cast into flex.double arrays
    or just string arrays as a fall back.
    """
    return self._origarrays


def as_flex_double(array, key):
  if isinstance(array.data(), flex.double):
    return array
  elif isinstance(array.data(), flex.int):
    return array.customized_copy(
      data=array.data().as_double()).set_info(array.info())
  else:
    try:
      flex.double(array.data())
    except ValueError as e:
      e_str = str(e)
      if e_str.startswith("Invalid floating-point value: "):
        i = e_str.find(":") + 2
        raise CifBuilderError("Invalid floating-point value for %s: %s"
                              %(key, e_str[i:].strip()))
      else:
        raise CifBuilderError(e_str)

def check_array_sizes(array1, array2, key1, key2):
  if array1.size() != array2.size():
    msg = "Miller arrays '%s' and '%s' are of different sizes" %(key1, key2)
    CifBuilderWarning(message=msg)
    return False
  return True

def none_if_all_question_marks_or_period(cif_block_item):
  if (cif_block_item is None): return None
  result = cif_block_item
  if (result.all_eq("?")): return None
  elif (result.all_eq(".")): return None
  return result

def as_int_or_none_if_all_question_marks(cif_block_item, column_name=None):
  strings = none_if_all_question_marks_or_period(cif_block_item)
  if (strings is None): return None
  try:
    return flex.int(strings)
  except ValueError as e:
    # better error message if column_name is given
    e_str = str(e)
    if column_name is not None and e_str.startswith(
      "Invalid integer value: "):
      i = e_str.find(":") + 2
      raise CifBuilderError("Invalid integer value for %s: %s"
                            %(column_name, e_str[i:].strip()))
    else:
      raise CifBuilderError(e_str)

def as_double_or_none_if_all_question_marks(cif_block_item, column_name=None):
  strings = none_if_all_question_marks_or_period(cif_block_item)
  if (strings is None): return None
  try:
    return flex.double(strings)
  except ValueError as e:
    # better error message if column_name is given
    e_str = str(e)
    if column_name is not None and e_str.startswith(
      "Invalid floating-point value: "):
      i = e_str.find(":") + 2
      raise CifBuilderError("Invalid floating-point value for %s: %s"
                            %(column_name, e_str[i:].strip()))
    else:
      raise CifBuilderError(e_str)

def flex_double(flex_std_string):
  try:
    return flex.double(flex_std_string)
  except ValueError as e:
    raise CifBuilderError(str(e))

def flex_double_else_none(cif_block_item):
  strings = none_if_all_question_marks_or_period(cif_block_item)
  if (strings is None): return None
  try:
    return flex.double(strings)
  except ValueError:
    pass
  return None

def flex_std_string_else_none(cif_block_item):
  if isinstance(cif_block_item, flex.std_string):
    return cif_block_item
  else:
    return None

def float_from_string(string):
  """a cif string may be quoted,
and have an optional esd in brackets associated with it"""
  if isinstance(string, float):
    return string
  return float(string.strip('\'').strip('"').split('(')[0])

def get_wavelengths(cif_block):
  for loop in cif_block.loops.values():
    for key in loop.keys():
      if ("_diffrn_radiation_wavelength." in key):
        wavelength_ids = loop.get("_diffrn_radiation_wavelength.id")
        wavelength_strs = loop.get("_diffrn_radiation_wavelength.wavelength")
        if (not None in [wavelength_ids, wavelength_strs]):
          wl_ = {}
          for wavelength_id,wavelength in zip(wavelength_ids,wavelength_strs):
            try :
              wl_id = int(wavelength_id)
              wl_[int(wavelength_id)] = float(wavelength)
            except ValueError :
              pass
          return wl_
        else :
          return None
  wavelength_id = cif_block.get("_diffrn_radiation_wavelength.id")
  wavelength_str = cif_block.get("_diffrn_radiation_wavelength.wavelength")
  if (not None in [wavelength_id, wavelength_str]):
    try :
      wl_id = int(wavelength_id)
      return { int(wavelength_id) : float(wavelength_str) }
    except ValueError :
      pass
  return None


 *******************************************************************************


 *******************************************************************************
iotbx/cif/citations.py
'''
Functionality for handling citations
'''
from __future__ import absolute_import, division, print_function

from libtbx.citations import journals_db

# =============================================================================
def citations_as_cif_block(articles, cif_block=None):
  import iotbx.cif.model
  if cif_block is None:
    cif_block = iotbx.cif.model.block()
  def replace_none_with_question_mark(s):
    if s is None: return '?'
    return s
  citation_loop = iotbx.cif.model.loop(header=(
    '_citation.id', '_citation.title', '_citation.journal_abbrev',
    '_citation.journal_volume', '_citation.page_first', '_citation.page_last',
    '_citation.year', '_citation.journal_id_ASTM', '_citation.journal_id_ISSN',
    '_citation.journal_id_CSD'))
  for article in articles:
    if article.pages is None:
      first_page, last_page = "?", "?"
    else:
      pages = article.pages.split('-')
      first_page = pages[0]
      if len(pages) == 1:
        last_page = '?'
      else:
        assert len(pages) == 2
        last_page = pages[1]
    journal = journals_db.get(article.journal)
    assert journal is not None
    citation_loop.add_row(
      {'_citation.id': article.article_id,
       '_citation.title': article.title,
       '_citation.journal_abbrev': journal.abbrev_CAS,
       '_citation.journal_volume': article.volume,
       '_citation.page_first': first_page,
       '_citation.page_last': last_page,
       '_citation.year': article.year,
       '_citation.journal_id_ASTM':
         replace_none_with_question_mark(journal.id_ASTM),
       '_citation.journal_id_ISSN':
         replace_none_with_question_mark(journal.id_ISSN),
       '_citation.journal_id_CSD':
         replace_none_with_question_mark(journal.id_CSD),
       })
  cif_block.add_loop(citation_loop)
  return cif_block

# =============================================================================
# end


 *******************************************************************************


 *******************************************************************************
iotbx/cif/cod_tools.py
from __future__ import absolute_import, division, print_function
import os, sys
op = os.path

class build_hkl_cif(object):
  def __init__(self, cod_ids=None, ext=None):
    if ext is not None:
      assert ext in ('cif','hkl')
    envar = "COD_SVN_WORKING_COPY"
    cod_svn = os.environ.get(envar)
    if (cod_svn is None):
      msg = [
        "Environment variable %s not defined:" % envar,
        "  Usage:",
        "    mkdir /some/path",
        "    cd /some/path",
        "    svn checkout svn://www.crystallography.net/cod",
        "    export %s=/some/path/cod" % envar]
      raise RuntimeError("\n".join(msg))
    cif_dir = op.join(cod_svn, "cif")
    hkl_dir = op.join(cod_svn, "hkl")
    def cod_path(cod_dir, cod_id, ext):
      return op.join(cod_dir, cod_id[0], cod_id[1:3], cod_id[3:5], cod_id+ext)
    self.hkl_cif_pairs = {}
    self.hkl = {}
    self.cif = {}
    if (cod_ids is None or len(cod_ids)==0):
      if ext is None or ext == "hkl":
        for root, dirs, files in os.walk(hkl_dir):
          if '.svn' in dirs: dirs.remove('.svn')
          for file_name in sorted(files):
            if (file_name.startswith(".")): continue
            if (not file_name.endswith(".hkl")): continue
            cod_id = file_name[:-4]
            hkl_path = op.join(root, file_name)
            self.hkl.setdefault(cod_id, hkl_path)
      if ext is None or ext == "cif":
        for root, dirs, files in os.walk(cif_dir):
          if '.svn' in dirs: dirs.remove('.svn')
          for file_name in sorted(files):
            if (file_name.startswith(".")): continue
            if (not file_name.endswith(".cif")): continue
            cod_id = file_name[:-4]
            cif_path = op.join(root, file_name)
            self.cif.setdefault(cod_id, cif_path)
            if (cod_id in self.hkl):
              self.hkl_cif_pairs.setdefault(
                cod_id, (self.hkl[cod_id], cif_path))
    else:
      n_missing_all = 0
      for cod_id in cod_ids:
        hkl_path = cod_path(hkl_dir, cod_id, ".hkl")
        cif_path = cod_path(cif_dir, cod_id, ".cif")
        n_missing = 0
        if (op.isfile(cif_path)):
          self.cif.setdefault(cod_id, cif_path)
        else:
          print("Missing COD cif file:", cif_path)
          n_missing += 1
        if (op.isfile(hkl_path)):
          self.hkl.setdefault(cod_id, hkl_path)
        else:
          print("Missing COD hkl file:", hkl_path)
          n_missing += 1
        if (n_missing == 0):
          self.hkl_cif_pairs.setdefault(cod_id, (hkl_path, cif_path))
        else:
          n_missing_all += n_missing
      if (n_missing_all != 0):
        raise RuntimeError("Number of missing COD files: %d" % n_missing_all)

  def show_summary(self, out=None):
    if out is None: out = sys.stdout
    print("Number of hkl without cif:", len(
      set(self.hkl_cif_pairs.keys())-set(self.hkl.keys())), file=out)
    print("Number of cif: ", len(self.cif), file=out)
    print("Number of hkl: ", len(self.hkl), file=out)
    print("Number of hkl+cif:", len(self.hkl_cif_pairs), file=out)


 *******************************************************************************


 *******************************************************************************
iotbx/cif/crystal_symmetry_from_cif.py
from __future__ import absolute_import, division, print_function
import iotbx.cif
from iotbx.cif.builders import crystal_symmetry_builder

def extract_from(file_name=None, file=None):
  assert [file_name, file].count(None) == 1
  cif_block = list(iotbx.cif.reader(file_path=file_name,
                               file_object=file).model().values())[0] # FIXME
  builder = crystal_symmetry_builder(cif_block)
  return builder.crystal_symmetry


 *******************************************************************************


 *******************************************************************************
iotbx/cif/errors.py
from __future__ import absolute_import, division, print_function
# Lists of error messages thrown during CIF validation

error_dicts = {}

def add_error_dict(language, error_dict):
  error_dicts[language.lower()] = error_dict

def get_error_dict(language):
  return error_dicts[language.lower()]

english = {

  # warnings
  1001: "Unknown data item: '%(key)s' not present in dictionary",
  1002: "Warning: case-sensitive match failure for value '%(value)s' for '%(key)s'",
  1003: "Warning: obsolete definition: '%(key)s' replaced by '%(related_item)s'",

  # Type errors
  2001: "Type error for %(key)s: '%(value)s' is not interpretable as type '%(item_type)s'",
  2002: "Type error for %(key)s: su is not allowed",

  # Enumeration errors
  2101: "Invalid enumeration value for %(key)s: '%(value)s' is outside of the permitted range: %(enum)s",
  2102: "Invalid enumeration value for %(key)s: '%(value)s' not in %(enum)s",

  # Related errors
  2201: "Both data item '%(key)s' and exclusive alternate '%(related_item)s' present in data block",
  2202: "Associated value item '%(related_item)s' missing for '%(key)s'",
  2203: "Mandatory category key item '%(key)s' for category '%(category)s' not present in data block",

  # Dependent errors
  2301: "Dependent item '%(dependent)s' not present in data block for '%(key)s'",


  # Loop errors
  2501: "Invalid loop: data item '%(key)s' cannot be declared in a looped list",
  2502: "Invalid loop: data names from multiple categories present (for loop containing '%(key)s')",
  2503: "Invalid loop: value '%(value)s' present in child '%(child)s' but not found in parent '%(parent)s'",
  2504: "Invalid loop: missing parent for loop containing '%(child)s': '%(parent)s' required but not present in data block",
  2505: "Invalid loop: missing reference for loop containing '%(key)s': '%(reference)s' required but not present",
  2506: "data item '%(key)s' can only be declared in a looped list",

  }

add_error_dict("en", english)


 *******************************************************************************


 *******************************************************************************
iotbx/cif/geometry.py
from __future__ import absolute_import, division, print_function
from cctbx.array_family import flex
from cctbx import crystal, sgtbx
from cctbx import covariance, geometry
from iotbx.cif import model
from libtbx.utils import format_float_with_standard_uncertainty \
     as format_float_with_su
from libtbx import adopt_init_args

import math


class distances_as_cif_loop(object):

  def __init__(self,
               pair_asu_table,
               site_labels,
               sites_frac=None,
               sites_cart=None,
               covariance_matrix=None,
               cell_covariance_matrix=None,
               parameter_map=None,
               include_bonds_to_hydrogen=False,
               fixed_distances=None,
               eps=2e-16):
    assert [sites_frac, sites_cart].count(None) == 1
    fmt = "%.4f"
    asu_mappings = pair_asu_table.asu_mappings()
    space_group_info = sgtbx.space_group_info(group=asu_mappings.space_group())
    unit_cell = asu_mappings.unit_cell()
    if sites_cart is not None:
      sites_frac = unit_cell.fractionalize(sites_cart)
    self.loop = model.loop(header=(
      "_geom_bond_atom_site_label_1",
      "_geom_bond_atom_site_label_2",
      "_geom_bond_distance",
      "_geom_bond_site_symmetry_2"
    ))
    distances = crystal.calculate_distances(
      pair_asu_table, sites_frac,
      covariance_matrix=covariance_matrix,
      cell_covariance_matrix=cell_covariance_matrix,
      parameter_map=parameter_map)
    for d in distances:
      if (not include_bonds_to_hydrogen
          and (site_labels[d.i_seq].startswith('H') or
               site_labels[d.j_seq].startswith('H'))):
        continue
      if (d.variance is not None and d.variance > eps
          and not(fixed_distances is not None and
                  ((d.i_seq, d.j_seq) in fixed_distances or
                   (d.j_seq, d.i_seq) in fixed_distances))):
        distance = format_float_with_su(d.distance, math.sqrt(d.variance))
      else:
        distance = fmt % d.distance
      sym_code = space_group_info.cif_symmetry_code(d.rt_mx_ji)
      if sym_code == "1": sym_code = "."
      self.loop.add_row((site_labels[d.i_seq],
                         site_labels[d.j_seq],
                         distance,
                         sym_code))
    self.distances = distances.distances
    self.variances = distances.variances
    self.pair_counts = distances.pair_counts

class angles_as_cif_loop(object):

  def __init__(self,
               pair_asu_table,
               site_labels,
               sites_frac=None,
               sites_cart=None,
               covariance_matrix=None,
               cell_covariance_matrix=None,
               parameter_map=None,
               include_bonds_to_hydrogen=False,
               fixed_angles=None,
               conformer_indices=None,
               eps=2e-16):
    assert [sites_frac, sites_cart].count(None) == 1
    fmt = "%.1f"
    asu_mappings = pair_asu_table.asu_mappings()
    space_group_info = sgtbx.space_group_info(group=asu_mappings.space_group())
    unit_cell = asu_mappings.unit_cell()
    if sites_cart is not None:
      sites_frac = unit_cell.fractionalize(sites_cart)
    self.loop = model.loop(header=(
      "_geom_angle_atom_site_label_1",
      "_geom_angle_atom_site_label_2",
      "_geom_angle_atom_site_label_3",
      "_geom_angle",
      "_geom_angle_site_symmetry_1",
      "_geom_angle_site_symmetry_3"
    ))
    angles = crystal.calculate_angles(
      pair_asu_table, sites_frac,
      covariance_matrix=covariance_matrix,
      cell_covariance_matrix=cell_covariance_matrix,
      parameter_map=parameter_map,
      conformer_indices=conformer_indices)
    for a in angles:
      i_seq, j_seq, k_seq = a.i_seqs
      if (not include_bonds_to_hydrogen
          and (site_labels[i_seq].startswith('H') or
               site_labels[k_seq].startswith('H'))):
        continue
      sym_code_ji = space_group_info.cif_symmetry_code(a.rt_mx_ji)
      sym_code_ki = space_group_info.cif_symmetry_code(a.rt_mx_ki)
      if sym_code_ji == "1": sym_code_ji = "."
      if sym_code_ki == "1": sym_code_ki = "."
      if (a.variance is not None and a.variance > eps
          and not(fixed_angles is not None and
                  ((i_seq, j_seq, k_seq) in fixed_angles or
                   (k_seq, j_seq, i_seq) in fixed_angles))):
        angle = format_float_with_su(a.angle, math.sqrt(a.variance))
      else:
        angle = fmt % a.angle
      self.loop.add_row((site_labels[i_seq],
                         site_labels[j_seq],
                         site_labels[k_seq],
                         angle,
                         sym_code_ji,
                         sym_code_ki,
                         ))
    self.angles = angles.angles
    self.variances = angles.variances

class dihedral_angles_as_cif_loop(object):
  def __init__(self,
               angles,
               space_group_info,
               site_labels,
               include_bonds_to_hydrogen=False,
               eps=2e-16):
    fmt = "%.1f"
    self.loop = model.loop(header=(
      "_geom_torsion_atom_site_label_1",
      "_geom_torsion_atom_site_label_2",
      "_geom_torsion_atom_site_label_3",
      "_geom_torsion_atom_site_label_4",
      "_geom_torsion",
      "_geom_torsion_site_symmetry_1",
      "_geom_torsion_site_symmetry_2",
      "_geom_torsion_site_symmetry_3",
      "_geom_torsion_site_symmetry_4"
    ))
    for a in angles:
      i_seq, j_seq, k_seq, l_seq = a.i_seqs
      if (not include_bonds_to_hydrogen
          and (site_labels[i_seq].startswith('H') or
               site_labels[j_seq].startswith('H') or
               site_labels[k_seq].startswith('H') or
               site_labels[l_seq].startswith('H'))):
        continue
      sym_code_i = space_group_info.cif_symmetry_code(a.rt_mxs[0])
      sym_code_j = space_group_info.cif_symmetry_code(a.rt_mxs[1])
      sym_code_k = space_group_info.cif_symmetry_code(a.rt_mxs[2])
      sym_code_l = space_group_info.cif_symmetry_code(a.rt_mxs[3])
      if sym_code_i == "1": sym_code_i = "."
      if sym_code_j == "1": sym_code_j = "."
      if sym_code_k == "1": sym_code_k = "."
      if sym_code_l == "1": sym_code_l = "."
      if a.variance is not None and a.variance > eps:
        angle = format_float_with_su(a.angle, math.sqrt(a.variance))
      else:
        angle = fmt % a.angle
      self.loop.add_row((site_labels[i_seq],
                         site_labels[j_seq],
                         site_labels[k_seq],
                         site_labels[l_seq],
                         angle,
                         sym_code_i,
                         sym_code_j,
                         sym_code_k,
                         sym_code_l,
                         ))

class hbond(object):
  def __init__(self, d_seq, a_seq, rt_mx=None):
    # rt_mx is the optional symmetry operator for the acceptor atom
    adopt_init_args(self, locals())


unit_mx = sgtbx.rt_mx()

class hbonds_as_cif_loop(object):

  def __init__(self,
               hbonds,
               pair_asu_table,
               site_labels,
               sites_frac=None,
               sites_cart=None,
               min_dha_angle=150, # degrees
               max_da_distance=2.9, # angstrom
               covariance_matrix=None,
               cell_covariance_matrix=None,
               parameter_map=None,
               eps=2e-16,
               fixed_distances=None,
               fixed_angles=None):
    assert [sites_frac, sites_cart].count(None) == 1
    fmt_a = "%.1f"
    pair_asu_table = pair_asu_table
    asu_mappings = pair_asu_table.asu_mappings()
    space_group_info = sgtbx.space_group_info(group=asu_mappings.space_group())
    self.unit_cell = asu_mappings.unit_cell()
    self.fixed_distances = fixed_distances
    self.fixed_angles = fixed_angles
    if sites_cart is not None:
      sites_frac = self.unit_cell.fractionalize(sites_cart)
    if sites_frac is not None:
      sites_cart = self.unit_cell.orthogonalize(sites_frac)
    if covariance_matrix is not None:
      assert parameter_map is not None
      self.covariance_matrix_cart = covariance.orthogonalize_covariance_matrix(
        covariance_matrix, self.unit_cell, parameter_map)
    else: self.covariance_matrix_cart = None
    self.cell_covariance_matrix = cell_covariance_matrix
    self.eps = eps
    self.parameter_map = parameter_map
    self.loop = model.loop(header=(
      "_geom_hbond_atom_site_label_D",
      "_geom_hbond_atom_site_label_H",
      "_geom_hbond_atom_site_label_A",
      "_geom_hbond_distance_DH",
      "_geom_hbond_distance_HA",
      "_geom_hbond_distance_DA",
      "_geom_hbond_angle_DHA",
      "_geom_hbond_site_symmetry_A",
    ))
    for hbond in hbonds:
      d_seq, a_seq = hbond.d_seq, hbond.a_seq
      site_cart_d = sites_cart[d_seq]
      if hbond.rt_mx is not None:
        site_frac_a = sites_frac[a_seq]
        site_frac_a = hbond.rt_mx * site_frac_a
        site_cart_a = self.unit_cell.orthogonalize(site_frac_a)
      else:
        site_cart_a = sites_cart[a_seq]
      distance_da = geometry.distance((site_cart_d, site_cart_a))
      for h_seq, h_sym_groups in pair_asu_table.table()[hbond.d_seq].items():
        if site_labels[h_seq][0] not in ('H','D'):
          # XXX better to pass scattering types instead?
          continue
        site_cart_h = sites_cart[h_seq]
        distance_dh = geometry.distance((site_cart_d, site_cart_h))
        distance_ha = geometry.distance((site_cart_h, site_cart_a))
        angle_dha = geometry.angle((site_cart_d, site_cart_h, site_cart_a))
        if (angle_dha.angle_model < min_dha_angle or
            distance_da.distance_model > max_da_distance):
          continue
        if hbond.rt_mx is not None:
          sym_code = space_group_info.cif_symmetry_code(hbond.rt_mx)
        else: sym_code = '.'
        self.loop.add_row((
          site_labels[d_seq],
          site_labels[h_seq],
          site_labels[a_seq],
          self.formatted_distance(d_seq, h_seq, distance_dh, unit_mx),
          self.formatted_distance(h_seq, a_seq, distance_ha, unit_mx),
          self.formatted_distance(d_seq, a_seq, distance_da, hbond.rt_mx),
          self.formatted_angle(d_seq, h_seq, a_seq, angle_dha, hbond.rt_mx),
          sym_code
        ))

  def formatted_distance(self, i_seq, j_seq, distance, rt_mx_ji):
    if rt_mx_ji is None: rt_mx_ji = unit_mx
    if self.covariance_matrix_cart is not None:
      cov = covariance.extract_covariance_matrix_for_sites(
        flex.size_t((i_seq,j_seq)),
        self.covariance_matrix_cart,
        self.parameter_map)
      if self.cell_covariance_matrix is not None:
        var = distance.variance(
          cov, self.cell_covariance_matrix, self.unit_cell, rt_mx_ji)
      else:
        var = distance.variance(cov, self.unit_cell, rt_mx_ji)
      if var > self.eps and not(self.fixed_distances is not None and
        ((i_seq, j_seq) in self.fixed_distances or
         (j_seq, i_seq) in self.fixed_distances)):
        return format_float_with_su(distance.distance_model, math.sqrt(var))
    return "%.4f" %distance.distance_model

  def formatted_angle(self, i_seq, j_seq, k_seq, angle, rt_mx_ki):
    if rt_mx_ki is None: rt_mx_ki = unit_mx
    if self.covariance_matrix_cart is not None:
      cov = covariance.extract_covariance_matrix_for_sites(
        flex.size_t((i_seq,j_seq,k_seq)),
        self.covariance_matrix_cart,
        self.parameter_map)
      if self.cell_covariance_matrix is not None:
        var = angle.variance(cov, self.cell_covariance_matrix, self.unit_cell,
                             (unit_mx, unit_mx, rt_mx_ki))
      else:
        var = angle.variance(cov, self.unit_cell, (unit_mx, unit_mx, rt_mx_ki))
      if var > self.eps and not(self.fixed_angles is not None and
        ((i_seq, j_seq, k_seq) in self.fixed_angles or
          (k_seq, j_seq, i_seq) in self.fixed_angles)):
        return format_float_with_su(angle.angle_model, math.sqrt(var))
    return "%.1f" %angle.angle_model


 *******************************************************************************


 *******************************************************************************
iotbx/cif/model.py
from __future__ import absolute_import, division, print_function
from libtbx.containers import OrderedDict, OrderedSet
from libtbx.utils import Sorry
import sys
import string
import copy
from six.moves import cStringIO as StringIO
from collections import Counter
try:
  from collections.abc import MutableMapping
except ImportError:
  from collections import MutableMapping
from cctbx.array_family import flex
from six.moves import range
from six.moves import zip
from six import string_types
import six


class cif(MutableMapping):
  def __init__(self, blocks=None):
    self._errors = None
    if blocks is not None:
      self.blocks = OrderedDict(blocks)
    else:
      self.blocks = OrderedDict()
    self.keys_lower = dict([(key.lower(), key) for key in self.blocks.keys()])

  def __len__(self):
    return len(self.keys())

  def __iter__(self):
    for k in self.keys():
      yield k

  def __setitem__(self, key, value):
    assert isinstance(value, block)
    if not re.match(tag_re, '_'+key):
      raise Sorry("%s is not a valid data block name" %key)
    self.blocks[key] = value
    self.keys_lower[key.lower()] = key

  def get(self, key, default=None):
    key_lower = self.keys_lower.get(key.lower())
    if (key_lower is None):
      return default
    return self.blocks.get(key_lower, default)

  def __getitem__(self, key):
    result = self.get(key)
    if (result is None):
      raise KeyError('Unknown CIF data block name: "%s"' % key)
    return result

  def __delitem__(self, key):
    del self.blocks[self.keys_lower[key.lower()]]
    del self.keys_lower[key.lower()]

  def keys(self):
    return list(self.blocks.keys())

  def __repr__(self):
    return repr(OrderedDict(six.iteritems(self)))

  def __copy__(self):
    return cif(self.blocks.copy())

  copy = __copy__

  def __deepcopy__(self, memo):
    return cif(copy.deepcopy(self.blocks, memo))

  def deepcopy(self):
    return copy.deepcopy(self)

  def show(self, out=None, indent="  ", indent_row=None,
           data_name_field_width=34,
           loop_format_strings=None,
           align_columns=True):
    if out is None:
      out = sys.stdout
    for name, block in self.items():
      print("data_%s" %name, file=out)
      block.show(
        out=out, indent=indent, indent_row=indent_row,
        data_name_field_width=data_name_field_width,
        loop_format_strings=loop_format_strings,
        align_columns=align_columns)

  def __str__(self):
    s = StringIO()
    self.show(out=s)
    return s.getvalue()

  def validate(self, dictionary, show_warnings=True, error_handler=None, out=None):
    if out is None: out = sys.stdout
    from iotbx.cif import validation
    self._errors = {}
    if error_handler is None:
      error_handler = validation.ErrorHandler()
    for key, block in six.iteritems(self.blocks):
      error_handler = error_handler.__class__()
      dictionary.set_error_handler(error_handler)
      block.validate(dictionary)
      self._errors.setdefault(key, error_handler)
      if error_handler.error_count or error_handler.warning_count:
        error_handler.show(show_warnings=show_warnings, out=out)
    return error_handler

  def get_errors(self):
    return self._errors

  def sort(self, recursive=False, key=None, reverse=False):
    self.blocks = OrderedDict(sorted(self.blocks.items(), key=key, reverse=reverse))
    if recursive:
      for b in self.blocks.values():
        b.sort(recursive=recursive, reverse=reverse)

class block_base(MutableMapping):
  def __init__(self):
    self._items = {}
    self.loops = {}
    self._set = OrderedSet()
    self.keys_lower = {}

  def __len__(self):
    return len(self.keys())

  def __iter__(self):
    for k in self.keys():
      yield k

  def __setitem__(self, key, value):
    if not re.match(tag_re, key):
      raise Sorry("%s is not a valid data name" %key)
    if isinstance(value, loop):
      self.loops[key] = value
      self.keys_lower[key.lower()] = key
      for k in value.keys():
        self.keys_lower[k.lower()] = k
    elif isinstance(value, string_types):
      v = str(value)
      if not (re.match(any_print_char_re, v) or
              re.match(quoted_string_re, v) or
              re.match(semicolon_string_re, v)):
        raise Sorry("Invalid data item for %s" %key)
      self._items[key] = v
      self.keys_lower[key.lower()] = key
    else:
      try:
        float(value)
        self[key] = str(value)
      except TypeError:
        if key in self._items:
          del self._items[key]
        for loop_ in self.loops.values():
          if key in loop_:
            loop_[key] = value
        if key not in self:
          self.add_loop(loop(header=(key,), data=(value,)))
    if key in self._items or isinstance(value, loop):
      self._set.add(key)

  def __getitem__(self, key):
    key = self.keys_lower.get(key.lower(), key)
    if key in self._items:
      return self._items[key]
    else:
      # give precedence to returning the actual data items in the event of a
      # single looped item when the loop name and data name coincide
      for loop in self.loops.values():
        if key in loop:
          return loop[key]
      if key in self.loops:
        return self.loops[key]
      # special key added to GeoStd
      if key in ['_chem_comp.initial_date',
                 '_chem_comp.modified_date',
                 '_chem_comp.source',
                 ]:
        return '.'
    raise KeyError(key)

  def __delitem__(self, key):
    key = self.keys_lower.get(key.lower(), key)
    if key in self._items:
      del self._items[key]
      self._set.discard(key)
    elif key in self.loops:
      del self.loops[key]
      self._set.discard(key)
    elif key in self.keys():
      # must be a looped item
      for k, loop in six.iteritems(self.loops):
        if key in loop:
          if len(loop) == 1:
            # remove the now empty loop
            del self[k]
          else:
            del loop[key]
          return
      raise KeyError(key)
    else:
      raise KeyError

  def get_looped_item(self,
                      key,
                      key_error=KeyError,
                      value_error=None,
                      default=None):
    if key not in self:
      if key_error is None:
        return default
      else:
        raise key_error(key)
    value = self[key]
    if isinstance(value, flex.std_string):
      return value
    elif value_error is not None:
      raise value_error("%s is not a looped item" %key)
    elif default is not None:
      return default
    else:
      return flex.std_string([value])

  def loop_keys(self):
    done = []
    for key in self:
      key = key.split(".")[0]
      if key in done: continue
      done.append(key)
    return done

  def iterloops(self):
    for key in self.loop_keys():
      yield self.get(key)

  def get_single_item(self,
                      key,
                      key_error=KeyError,
                      value_error=ValueError,
                      default=None):
    if key not in self:
      if key_error is None:
        return default
      else:
        raise key_error(key)
    value = self[key]
    if not isinstance(value, flex.std_string):
      return value
    elif value_error is not None:
      raise value_error("%s appears as a looped item" %key)
    else:
      return default

  def keys(self):
    keys = []
    for key in self._set:
      if key in self._items:
        keys.append(key)
      elif key in self.loops:
        keys.extend(self.loops[key].keys())
    return keys

  def item_keys(self):
    '''Returns names of all entries that are not loops'''
    return list(self._items.keys())

  def __repr__(self):
    return repr(OrderedDict(six.iteritems(self)))

  def update(self, other=None, **kwargs):
    if other is None:
      return
    if isinstance(other, OrderedDict) or isinstance(other, dict):
      for key, value in six.iteritems(other):
        self[key] = value
    else:
      self._items.update(other._items)
      self.loops.update(other.loops)
      self._set |= other._set
      self.keys_lower.update(other.keys_lower)

  def add_data_item(self, tag, value):
    self[tag] = value

  def add_loop(self, loop):
    try:
      self.setdefault(loop.name(), loop)
    except Sorry:
      # create a unique loop name
      self.setdefault('_'+str(hash(tuple(loop.keys()))), loop)

  def get_loop(self, loop_name, default=None):
    loop_ = self.loops.get(self.keys_lower.get(loop_name.lower(), loop_name))
    if loop_ is None:
      return default
    return loop_

  def get_loop_or_row(self, loop_name, default=None):
    loop_ = self.get_loop(loop_name, None)
    if loop_ is None:
      ln = loop_name
      if ln[-1] != '.':
        ln += '.'
        found_keys = {}
      for key, value in six.iteritems(self):
        if key.startswith(ln):
          found_keys[key] = flex.std_string([value])
      # constructing the loop
      if len(found_keys) > 0:
        loop_ = loop(data=found_keys)
    if loop_ is None:
      return default
    return loop_

  def get_loop_with_defaults(self, loop_name, default_dict):
    loop_ = self.get_loop(loop_name)
    if loop_ is None:
      loop_ = loop(header=default_dict.keys())
    n_rows = loop_.n_rows()
    for key, value in six.iteritems(default_dict):
      if key not in loop_:
        loop_.add_column(key, flex.std_string(n_rows, value))
    return loop_

  def __copy__(self):
    new = self.__class__()
    new._items = self._items.copy()
    new.loops = self.loops.copy()
    new._set = copy.copy(self._set)
    new.keys_lower = self.keys_lower.copy()
    return new

  copy = __copy__

  def __deepcopy__(self, memo):
    new = self.__class__()
    new._items = copy.deepcopy(self._items, memo)
    new.loops = copy.deepcopy(self.loops, memo)
    new._set = copy.deepcopy(self._set, memo)
    new.keys_lower = copy.deepcopy(self.keys_lower, memo)
    return new

  def deepcopy(self):
    return copy.deepcopy(self)

  def __str__(self):
    s = StringIO()
    self.show(out=s)
    return s.getvalue()

  def validate(self, dictionary):
    for key, value in six.iteritems(self._items):
      dictionary.validate_single_item(key, value, self)
    for loop in self.loops.values():
      dictionary.validate_loop(loop, self)
    if isinstance(self, block):
      for value in six.itervalues(self.saves):
        value.validate(dictionary)

  def sort(self, recursive=False, key=None, reverse=False):
    self._set = OrderedSet(
      sorted(self._items.keys(), key=key, reverse=reverse) \
      + sorted(self.loops.keys(), key=key, reverse=reverse))
    if recursive:
      for l in self.loops.values():
        l.sort(key=key, reverse=reverse)

  """Items that either appear in both self and other and the value has changed
     or appear in self but not other."""
  def difference(self, other):
    new = self.__class__()
    for items in (self._items, self.loops):
      for key, value in six.iteritems(items):
        if key in other:
          other_value = other[key]
          if other_value == value: continue
          else:
            new[key] = other_value
        else:
          new[key] = value
    return new

class save(block_base):

  def show(self, out=None, indent="  ", data_name_field_width=34, align_columns=True):
    if out is None:
      out = sys.stdout
      assert indent.strip() == ""
    format_str = "%%-%is" %(data_name_field_width-1)
    for k in self._set:
      v = self._items.get(k)
      if v is not None:
        print(indent + format_str %k, format_value(v), file=out)
      else:
        print(indent, end=' ', file=out)
        self.loops[k].show(out=out, indent=(indent+indent),align_columns=align_columns)
        print(file=out)


class block(block_base):

  def __init__(self):
    block_base.__init__(self)
    self.saves = {}

  def __setitem__(self, key, value):
    if isinstance(value, save):
      self.saves[key] = value
      self.keys_lower[key.lower()] = key
      self._set.add(key)
    else:
      block_base.__setitem__(self, key, value)

  def __getitem__(self, key):
    key = self.keys_lower.get(key.lower(), key)
    if key in self.saves:
      return self.saves[key]
    else:
      return block_base.__getitem__(self, key)

  def __delitem__(self, key):
    key = self.keys_lower.get(key.lower(), key)
    if key in self.saves:
      del self.saves[key]
      self._set.discard(key)
    else:
      block_base.__delitem__(self, key)

  def keys(self):
    keys = block_base.keys(self)
    keys.extend(self.saves.keys())
    return keys

  def update(self, other=None, **kwargs):
    if other is None:
      return
    block_base.update(self, other, **kwargs)
    self.saves.update(other.saves)

  def show(self, out=None, indent="  ", indent_row=None,
           data_name_field_width=34,
           loop_format_strings=None,
           align_columns=True):
    assert indent.strip() == ""
    if out is None:
      out = sys.stdout
    format_str = "%%-%is" %(data_name_field_width-1)
    for k in self._set:
      v = self._items.get(k)
      if v is not None:
        print(format_str %k, format_value(v), file=out)
      elif k in self.saves:
        print(file=out)
        print("save_%s" %k, file=out)
        self.saves[k].show(out=out, indent=indent,
                           data_name_field_width=data_name_field_width)
        print(indent + "save_", file=out)
        print(file=out)
      else:
        lp = self.loops[k]
        if lp.n_rows() == 0:
          continue
        if loop_format_strings is not None and k in loop_format_strings:
          lp.show(
            out=out, indent=indent, indent_row=indent_row,
            fmt_str=loop_format_strings[k],
            align_columns=align_columns)
        else:
          lp.show(out=out, indent=indent, indent_row=indent_row,
            align_columns=align_columns)
        print(file=out)

  def sort(self, recursive=False, key=None, reverse=False):
    block_base.sort(self, recursive=recursive, key=key, reverse=reverse)
    if recursive:
      for s in self.saves.values():
        s.sort(recursive=recursive, key=key, reverse=reverse)

  def __deepcopy__(self, memo):
    new = block_base.__deepcopy__(self, memo)
    new.saves = copy.deepcopy(self.saves, memo)
    return new

  def __copy__(self):
    new = block_base.copy(self)
    new.saves = self.saves.copy()
    return new

class loop(MutableMapping):
  def __init__(self, header=None, data=None):
    self._columns = OrderedDict()
    self.keys_lower = {}
    if header is not None:
      for key in header:
        self.setdefault(key, flex.std_string())
      if data is not None:
        # the number of data items must be an exact multiple of the number of headers
        assert len(data) % len(header) == 0, "Wrong number of data items for loop"
        n_rows = len(data)//len(header)
        n_columns = len(header)
        for i in range(n_rows):
          self.add_row([data[i*n_columns+j] for j in range(n_columns)])
    elif header is None and data is not None:
      assert isinstance(data, dict) or isinstance(data, OrderedDict)
      self.add_columns(data)
      self.keys_lower = dict(
        [(key.lower(), key) for key in self._columns.keys()])

  def __len__(self):
    return len(self.keys())

  def __iter__(self):
    for k in self.keys():
      yield k

  def __setitem__(self, key, value):
    if not re.match(tag_re, key):
      raise Sorry("%s is not a valid data name" %key)
    if len(self) > 0:
      assert len(value) == self.size()
    if isinstance(value, flex.size_t):
      value = value.as_int()
    if not isinstance(value, flex.std_string):
      for flex_numeric_type in (flex.int, flex.double):
        if isinstance(value, flex_numeric_type):
          value = value.as_string()
        else:
          try:
            value = flex_numeric_type(value).as_string()
          except TypeError:
            continue
          else:
            break
      if not isinstance(value, flex.std_string):
        value = flex.std_string(value)
    # value must be a mutable type
    assert hasattr(value, '__setitem__')
    self._columns[key] = value
    self.keys_lower[key.lower()] = key

  def __getitem__(self, key):
    return self._columns[self.keys_lower[key.lower()]]

  def __delitem__(self, key):
    del self._columns[self.keys_lower[key.lower()]]
    del self.keys_lower[key.lower()]

  def keys(self):
    return self._columns.keys()

  def __repr__(self):
    return repr(OrderedDict(six.iteritems(self)))

  def name(self):
    return common_substring(list(self.keys())).rstrip('_').rstrip('.')

  def size(self):
    size = 0
    for column in self.values():
      size = max(size, len(column))
    return size

  def n_rows(self):
    return self.size()

  def n_columns(self):
    return len(self.keys())

  def add_row(self, row, default_value="?"):
    if isinstance(row, dict):
      for key in self:
        if key in row:
          self[key].append(str(row[key]))
        else:
          self[key].append(default_value)
    else:
      assert len(row) == len(self)
      for i, key in enumerate(self):
        self[key].append(str(row[i]))

  def add_column(self, key, values):
    if self.size() != 0:
      assert len(values) == self.size()
    self[key] = values
    self.keys_lower[key.lower()] = key

  def add_columns(self, columns):
    assert isinstance(columns, dict) or isinstance(columns, OrderedDict)
    for key, value in six.iteritems(columns):
      self.add_column(key, value)

  def update_column(self, key, values):
    assert type(key)==type(""), "first argument is column key string"
    if self.size() != 0:
      assert len(values) == self.size(), "len(values) %d != self.size() %d" % (
        len(values),
        self.size(),
        )
    self[key] = values
    self.keys_lower[key.lower()] = key

  def delete_row(self, index):
    assert index < self.n_rows()
    for column in self._columns.values():
      del column[index]

  def __copy__(self):
    new = loop()
    new._columns = self._columns.copy()
    new.keys_lower = self.keys_lower.copy()
    return new

  copy = __copy__

  def __deepcopy__(self, memo):
    new = loop()
    new._columns = copy.deepcopy(self._columns, memo)
    new.keys_lower = copy.deepcopy(self.keys_lower, memo)
    return new

  def deepcopy(self):
    return copy.deepcopy(self)

  def show(self, out=None, indent="  ", indent_row=None, fmt_str=None, align_columns=True):
    assert self.n_rows() > 0 and self.n_columns() > 0, "keys: %s %d %d" % (
      self.keys(),
      self.n_rows(),
      self.n_columns(),
      )
    if out is None:
      out = sys.stdout
    if indent_row is None:
      indent_row = indent
    assert indent.strip() == ""
    assert indent_row.strip() == ""
    print("loop_", file=out)
    for k in self.keys():
      print(indent + k, file=out)

    values = list(self._columns.values())
    range_len_values = range(len(values))
    if fmt_str is not None:
      # Pretty printing:
      #   The user is responsible for providing a valid format string.
      #   Values are not quoted - it is the user's responsibility to place
      #   appropriate quotes in the format string if a particular value may
      #   contain spaces.
      # Avoid modifying self in place
      values = copy.deepcopy(values)
      for i, v in enumerate(values):
        for flex_numeric_type in (flex.int, flex.double):
          if not isinstance(v, flex_numeric_type):
            try:
              values[i] = flex_numeric_type(v)
            except ValueError:
              continue
            else:
              break
      if fmt_str is None:
        fmt_str = indent_row + ' '.join(["%s"]*len(values))
      for i in range(self.size()):
        print(fmt_str % tuple([values[j][i] for j in range_len_values]), file=out)
    elif align_columns:
      fmt_str = []
      # Avoid modifying self in place
      values = copy.deepcopy(values)
      for i, v in enumerate(values):
        for i_v in range(v.size()):
          v[i_v] = format_value(v[i_v])
        # exclude and semicolon text fields from column width calculation
        v_ = flex.std_string(item for item in v if "\n" not in item)
        width = v_.max_element_length()
        # See if column contains only number, '.' or '?'
        # right-align numerical columns, left-align everything else
        v = v.select(~( (v == ".") | (v == "?") ))
        try:
          flex.double(v)
        except ValueError:
          width *= -1
        fmt_str.append("%%%is" %width)
      fmt_str = indent_row + "  ".join(fmt_str)
      for i in range(self.size()):
        print((fmt_str %
                       tuple([values[j][i]
                              for j in range_len_values])).rstrip(), file=out)
    else:
      for i in range(self.size()):
        values_to_print = [format_value(values[j][i]) for j in range_len_values]
        print(' '.join([indent] + values_to_print), file=out)

  def __str__(self):
    s = StringIO()
    self.show(out=s)
    return s.getvalue()

  def iterrows(self):
    """ Warning! Still super-slow! """
    keys = self.keys()
    s_values = list(self.values())
    range_len_self = range(len(self))
    # tuple (s_values...) is slightly faster than list
    for j in range(self.size()):
      yield OrderedDict(zip(keys, (s_values[i][j] for i in range_len_self)))

  def find_row(self, kv_dict):
    self_keys = self.keys()
    for k in kv_dict.keys():
      assert k in self_keys
    result = []
    s_values = list(self.values())
    range_len_self = range(len(self))
    for i in range(self.size()):
      goodrow = True
      for k, v in six.iteritems(kv_dict):
        if self[k][i] != v:
          goodrow = False
          break
      if goodrow:
        result.append(OrderedDict(zip(self_keys, [s_values[j][i] for j in range_len_self])))
    return result

  def check_key_is_unique(self, key_list):
    """
    Majority (if not all) loops have 1 or more keys that should be unique
    to identify a row. This function checks if this holds up
    """
    self_keys = self.keys()
    for k in key_list:
      assert k in self_keys
    key_comb_list = []
    for i in range(self.size()):
      key_comb_list.append(tuple([self[k][i] for k in key_list]))
    c = Counter(key_comb_list)
    duplicates = [k for k in c.keys() if c[k] > 1]
    return duplicates

  def sort(self, key=None, reverse=False):
    self._columns = OrderedDict(
      sorted(self._columns.items(), key=key, reverse=reverse))

  def order(self, order):
    def _cmp_key(k1, k2):
      for i, o in enumerate(order):
        if k1==o: break
      for j, o in enumerate(order):
        if k2==o: break
      if k1<k2: return -1
      return 1
    keys = self._columns.keys()
    keys.sort(_cmp_key)
    tmp = OrderedDict()
    for o in order:
      tmp[o]=self._columns[o]
    self._columns = tmp

  def __eq__(self, other):
    if (len(self) != len(other) or
        self.size() != other.size() or
        list(self.keys()) != list(other.keys())):
      return False
    for value, other_value in zip(list(self.values()), list(other.values())):
      if (value == other_value).count(True) != len(value):
        return False
    return True


def common_substring(seq):
  # DDL1 dictionaries permit a cif loop to contain a local prefix as the
  # first element of any data name:
  #
  #   http://www.iucr.org/resources/cif/spec/ancillary/reserved-prefixes

  seq = list(seq) # indexable list for Py3 compatibility
  if len(seq) == 1: return seq[0]
  substr = seq[0]
  for s in seq:
    substr = LCSubstr_set(substr, s).pop()
  if not (substr.endswith('_') or substr.endswith('.')):
    if '.' in substr:
      substr = substr.split('.')[0]
    elif substr not in seq and substr.count('_') > 1:
      substr = '_'.join(substr.split('_')[:-1])
  return substr

def LCSubstr_set(S, T):
  """Longest common substring function taken from:
  http://en.wikibooks.org/wiki/Algorithm_Implementation/Strings/Longest_common_substring#Python"""

  m = len(S); n = len(T)
  L = [[0] * (n+1) for i in range(m+1)]
  LCS = set()
  longest = 0
  for i in range(m):
    for j in range(n):
      if S[i] == T[j]:
        v = L[i][j] + 1
        L[i+1][j+1] = v
        if v > longest:
          longest = v
          LCS = set()
        if v == longest:
          LCS.add(S[i-v+1:i+1])
  return LCS


import re
_ordinary_char_set = r"!%&()*+,\-./0-9:<=>?@A-Z\\^`a-z{|}~"
_non_blank_char_set = r"%s\"#$'_;[\]"%_ordinary_char_set
_any_print_char_set = r"%s\"#$'_ \t;[\]" %_ordinary_char_set
_text_lead_char_set = r"%s\"#$'_ \t[\]" %_ordinary_char_set

any_print_char_re = re.compile(r"[%s]*" %_any_print_char_set)
tag_re = re.compile(r"_[%s]+" %_non_blank_char_set)
unquoted_string_re = re.compile(
  r"[%s][%s]*" %(_ordinary_char_set, _non_blank_char_set))
quoted_string_re = re.compile(r"('|\")[%s]*('|\")" %_any_print_char_set)
semicolon_string_re = re.compile(r"(\s*)(;).*?(;)(\s*)", re.DOTALL)

def format_value(value_string):
  string_is_quoted = False
  if not value_string:
    return "''"
  # s[0] == "a" is appears to be faster than s.startswith("a")
  if value_string[0] in ("'",'"'):
    m = re.match(quoted_string_re, value_string)
    string_is_quoted = m is not None
  if not string_is_quoted:
    if len(value_string) == 0:
      return "''"
    elif (';' in value_string and value_string.lstrip()[0] == ';'
          and  re.match(semicolon_string_re, value_string) is not None):
      # a semicolon text field
      return "\n%s\n" %value_string.strip()
    elif '\n' in value_string:
      if value_string[0] != '\n':
        value_string = '\n' + value_string
      if value_string[-1] != '\n':
        value_string = value_string + '\n'
      return "\n;%s;\n" %value_string
    elif (value_string[0] in ('#','$','[',']','_')):
      return "'%s'" %value_string
    else:
      for ws in string.whitespace:
        if ws in value_string:
          if ("'" + ws) in value_string:
            if ('"' + ws) in value_string:
              # string can't be quoted, use semi-colon text field instead
              return "\n;\n%s\n;\n" %value_string
            return '"%s"' %value_string
          return "'%s'" %value_string
  return value_string


 *******************************************************************************


 *******************************************************************************
iotbx/cif/restraint_file_merge.py
from __future__ import division, print_function
import os, sys

import iotbx
from iotbx import cif

def merge_block(b1, b2):
  for key, item in b1.items():
    for i in b2[key]:
      item.append(i)

def run(filenames,
        filename,
        no_file_access=False,
        no_file_but_save=False,
        verbose=False,
        ):
  outl = "  Joining"
  for f in filenames:
    if f.find("\n")==-1:
      outl += "\n\t%s" % f
    else:
      outl += "\n\t%s lines" % (len(f.split("\n")))
  outl += "\n  into\n\t%s" % filename
  if not no_file_access:
    if verbose: print(outl)

  cifs = []
  if not no_file_access:
    for cif_file_name in filenames:
      if not os.path.exists(cif_file_name): continue
      cif_object = iotbx.cif.reader(file_path=cif_file_name).model()
      cifs.append(cif_object)
  else:
    for lines in filenames:
      cif_object = iotbx.cif.reader(input_string=lines).model()
      cifs.append(cif_object)

  comp_list = None
  for i, cif_object in enumerate(cifs):
    if comp_list is None:
      comp_list = cif_object['comp_list']
    else:
      merge_block(comp_list, cif_object['comp_list'])
    del cif_object['comp_list']

  outl = 'data_comp_list\n'
  outl += str(comp_list)
  for i, cif_object in enumerate(cifs):
    outl += str(cif_object)

  if verbose:
    print(outl)

  if not no_file_access or no_file_but_save:
    f = open(filename, "w")
    f.write(outl)
    f.close()
  else:
    return outl

if __name__=="__main__":
  if len(sys.argv)<4:
    print("""
  usage:
    iotbx.cif.restraints_file_merge.py merge1 merge2 ... target
""")
    sys.exit()
  target = sys.argv[-1]
  filenames=[]
  for i in range(1,len(sys.argv)-1):
    filenames.append(sys.argv[i])
  run(filenames, target)


 *******************************************************************************


 *******************************************************************************
iotbx/cif/restraints.py
from __future__ import absolute_import, division, print_function
from cctbx import sgtbx
from cctbx import adp_restraints, geometry_restraints
from cctbx.adp_restraints import adp_restraint_params
from cctbx.array_family import flex
from iotbx.cif import model
import math
from six.moves import range

# http://www.iucr.org/__data/iucr/cifdic_html/1/cif_core_restraints.dic/index.html

def add_to_cif_block(cif_block, xray_structure,
                     bond_proxies=None,
                     angle_proxies=None,
                     dihedral_proxies=None,
                     chirality_proxies=None,
                     bond_similarity_proxies=None,
                     rigid_bond_proxies=None,
                     rigu_proxies=None,
                     adp_similarity_proxies=None,
                     isotropic_adp_proxies=None,
                     adp_u_eq_similarity_proxies=None,
                     adp_volume_similarity_proxies=None,
                     fixed_u_eq_adp_proxies=None):
  if bond_proxies is not None:
    cif_block.add_loop(distances_as_cif_loop(xray_structure, bond_proxies))
  if angle_proxies is not None:
    cif_block.add_loop(angles_as_cif_loop(xray_structure, angle_proxies))
  if dihedral_proxies is not None:
    cif_block.add_loop(dihedrals_as_cif_loop(xray_structure, dihedral_proxies))
  if chirality_proxies is not None:
    cif_block.add_loop(chirality_as_cif_loop(xray_structure, chirality_proxies))
  if bond_similarity_proxies is not None:
    loops = bond_similarity_as_cif_loops(xray_structure, bond_similarity_proxies)
    for loop in loops: cif_block.add_loop(loop)
  if rigid_bond_proxies is not None:
    cif_block.add_loop(rigid_bond_as_cif_loop(xray_structure, rigid_bond_proxies))
  if rigu_proxies is not None:
    cif_block.add_loop(rigu_as_cif_loop(xray_structure, rigu_proxies))
  if adp_similarity_proxies is not None:
    cif_block.add_loop(
      adp_similarity_as_cif_loop(xray_structure, adp_similarity_proxies))
  if isotropic_adp_proxies is not None:
    cif_block.add_loop(
      isotropic_adp_as_cif_loop(xray_structure, isotropic_adp_proxies))
  if adp_u_eq_similarity_proxies is not None:
    loops = adp_u_eq_similarity_as_cif_loops(xray_structure,
                                       adp_u_eq_similarity_proxies)
    for l in loops: cif_block.add_loop(l)
  if adp_volume_similarity_proxies is not None:
    loops = adp_volume_similarity_as_cif_loops(xray_structure,
                                        adp_volume_similarity_proxies)
    for l in loops: cif_block.add_loop(l)
  if fixed_u_eq_adp_proxies is not None:
    cif_block.add_loop(
      fixed_u_eq_adp_as_cif_loop(xray_structure, fixed_u_eq_adp_proxies))

def distances_as_cif_loop(xray_structure, proxies):
  space_group_info = sgtbx.space_group_info(group=xray_structure.space_group())
  unit_cell = xray_structure.unit_cell()
  sites_cart = xray_structure.sites_cart()
  site_labels = xray_structure.scatterers().extract_labels()
  fmt = "%.4f"
  loop = model.loop(header=(
    "_restr_distance_atom_site_label_1",
    "_restr_distance_atom_site_label_2",
    "_restr_distance_site_symmetry_2",
    "_restr_distance_target",
    "_restr_distance_target_weight_param",
    "_restr_distance_diff"
  ))
  for proxy in proxies:
    restraint = geometry_restraints.bond(
      unit_cell=unit_cell,
      sites_cart=sites_cart,
      proxy=proxy)
    i_seqs = proxy.i_seqs
    sym_op = proxy.rt_mx_ji
    if sym_op is None: sym_op = sgtbx.rt_mx()
    loop.add_row((site_labels[i_seqs[0]],
                  site_labels[i_seqs[1]],
                  space_group_info.cif_symmetry_code(sym_op),
                  fmt % restraint.distance_ideal,
                  fmt % math.sqrt(1/restraint.weight),
                  fmt % restraint.delta))
  return loop

def angles_as_cif_loop(xray_structure, proxies):
  space_group_info = sgtbx.space_group_info(group=xray_structure.space_group())
  unit_cell = xray_structure.unit_cell()
  sites_cart = xray_structure.sites_cart()
  site_labels = xray_structure.scatterers().extract_labels()
  fmt = "%.4f"
  loop = model.loop(header=(
    "_restr_angle_atom_site_label_1",
    "_restr_angle_atom_site_label_2",
    "_restr_angle_atom_site_label_3",
    "_restr_angle_site_symmetry_1",
    "_restr_angle_site_symmetry_2",
    "_restr_angle_site_symmetry_3",
    "_restr_angle_target",
    "_restr_angle_target_weight_param",
    "_restr_angle_diff",
  ))
  unit_mxs = [sgtbx.rt_mx()]*3
  for proxy in proxies:
    restraint = geometry_restraints.angle(
      unit_cell=unit_cell,
      sites_cart=sites_cart,
      proxy=proxy)
    sym_ops = proxy.sym_ops
    if sym_ops is None: sym_ops = unit_mxs
    i_seqs = proxy.i_seqs
    loop.add_row((site_labels[i_seqs[0]],
                  site_labels[i_seqs[1]],
                  site_labels[i_seqs[2]],
                  space_group_info.cif_symmetry_code(sym_ops[0]),
                  space_group_info.cif_symmetry_code(sym_ops[1]),
                  space_group_info.cif_symmetry_code(sym_ops[2]),
                  fmt % restraint.angle_ideal,
                  fmt % math.sqrt(1/restraint.weight),
                  fmt % restraint.delta))
  return loop

def dihedrals_as_cif_loop(xray_structure, proxies):
  space_group_info = sgtbx.space_group_info(group=xray_structure.space_group())
  unit_cell = xray_structure.unit_cell()
  sites_cart = xray_structure.sites_cart()
  site_labels = xray_structure.scatterers().extract_labels()
  fmt = "%.4f"
  loop = model.loop(header=(
    "_restr_torsion_atom_site_label_1",
    "_restr_torsion_atom_site_label_2",
    "_restr_torsion_atom_site_label_3",
    "_restr_torsion_atom_site_label_4",
    "_restr_torsion_site_symmetry_1",
    "_restr_torsion_site_symmetry_2",
    "_restr_torsion_site_symmetry_3",
    "_restr_torsion_site_symmetry_4",
    "_restr_torsion_angle_target",
    "_restr_torsion_weight_param",
    "_restr_torsion_diff",
  ))
  unit_mxs = [sgtbx.rt_mx()]*4
  for proxy in proxies:
    restraint = geometry_restraints.dihedral(
      unit_cell=unit_cell,
      sites_cart=sites_cart,
      proxy=proxy)
    sym_ops = proxy.sym_ops
    if sym_ops is None: sym_ops = unit_mxs
    i_seqs = proxy.i_seqs
    loop.add_row((site_labels[i_seqs[0]],
                  site_labels[i_seqs[1]],
                  site_labels[i_seqs[2]],
                  site_labels[i_seqs[3]],
                  space_group_info.cif_symmetry_code(sym_ops[0]),
                  space_group_info.cif_symmetry_code(sym_ops[1]),
                  space_group_info.cif_symmetry_code(sym_ops[2]),
                  space_group_info.cif_symmetry_code(sym_ops[3]),
                  fmt % restraint.angle_ideal,
                  fmt % math.sqrt(1/restraint.weight),
                  fmt % restraint.delta))
  return loop

def chirality_as_cif_loop(xray_structure, proxies):
  space_group_info = sgtbx.space_group_info(group=xray_structure.space_group())
  unit_cell = xray_structure.unit_cell()
  sites_cart = xray_structure.sites_cart()
  site_labels = xray_structure.scatterers().extract_labels()
  fmt = "%.4f"
  loop = model.loop(header=(
    "_restr_chirality_atom_site_label_1",
    "_restr_chirality_atom_site_label_2",
    "_restr_chirality_atom_site_label_3",
    "_restr_chirality_atom_site_label_4",
    "_restr_chirality_site_symmetry_1",
    "_restr_chirality_site_symmetry_2",
    "_restr_chirality_site_symmetry_3",
    "_restr_chirality_site_symmetry_4",
    "_restr_chirality_volume_target",
    "_restr_chirality_weight_param",
    "_restr_chirality_diff",
  ))
  unit_mxs = [sgtbx.rt_mx()]*4
  for proxy in proxies:
    restraint = geometry_restraints.chirality(
      unit_cell=unit_cell,
      sites_cart=sites_cart,
      proxy=proxy)
    sym_ops = proxy.sym_ops
    if sym_ops is None: sym_ops = unit_mxs
    i_seqs = proxy.i_seqs
    loop.add_row((site_labels[i_seqs[0]],
                  site_labels[i_seqs[1]],
                  site_labels[i_seqs[2]],
                  site_labels[i_seqs[3]],
                  space_group_info.cif_symmetry_code(sym_ops[0]),
                  space_group_info.cif_symmetry_code(sym_ops[1]),
                  space_group_info.cif_symmetry_code(sym_ops[2]),
                  space_group_info.cif_symmetry_code(sym_ops[3]),
                  fmt % restraint.volume_ideal,
                  fmt % math.sqrt(1/restraint.weight),
                  fmt % restraint.delta))
  return loop

def bond_similarity_as_cif_loops(xray_structure, proxies):
  space_group_info = sgtbx.space_group_info(group=xray_structure.space_group())
  unit_cell = xray_structure.unit_cell()
  sites_cart = xray_structure.sites_cart()
  site_labels = xray_structure.scatterers().extract_labels()
  fmt = "%.4f"
  loop = model.loop(header=(
    "_restr_equal_distance_atom_site_label_1",
    "_restr_equal_distance_atom_site_label_2",
    "_restr_equal_distance_site_symmetry_2",
    "_restr_equal_distance_class_id",
  ))
  class_loop = model.loop(header=(
    "_restr_equal_distance_class_class_id",
    "_restr_equal_distance_class_target_weight_param",
    "_restr_equal_distance_class_average",
    "_restr_equal_distance_class_esd",
    "_restr_equal_distance_class_diff_max",
  ))
  class_id = 0
  for proxy in proxies:
    restraint = geometry_restraints.bond_similarity(
      unit_cell=unit_cell,
      sites_cart=sites_cart,
      proxy=proxy)
    class_id += 1
    esd = math.sqrt(flex.sum(flex.pow2(restraint.deltas())) *
                    (1./proxy.i_seqs.size()))
    class_loop.add_row((class_id,
                        fmt % math.sqrt(1/proxy.weights[0]),# assume equal weights
                        fmt % restraint.mean_distance(),
                        fmt % esd,
                        fmt % flex.max_absolute(restraint.deltas())))
    for i in range(proxy.i_seqs.size()):
      i_seq, j_seq = proxy.i_seqs[i]
      if proxy.sym_ops is None:
        sym_op = sgtbx.rt_mx()
      else:
        sym_op = proxy.sym_ops[i]
      loop.add_row((site_labels[i_seq],
                    site_labels[j_seq],
                    space_group_info.cif_symmetry_code(sym_op),
                    class_id))
  return class_loop, loop

def rigid_bond_as_cif_loop(xray_structure, proxies):
  unit_cell = xray_structure.unit_cell()
  sites_cart = xray_structure.sites_cart()
  u_cart = xray_structure.scatterers().extract_u_cart(unit_cell)
  site_labels = xray_structure.scatterers().extract_labels()
  fmt = "%.4f"
  loop = model.loop(header=(
    "_restr_U_rigid_atom_site_label_1",
    "_restr_U_rigid_atom_site_label_2",
    "_restr_U_rigid_target_weight_param",
    "_restr_U_rigid_U_parallel",
    "_restr_U_rigid_diff",
  ))
  for proxy in proxies:
    restraint = adp_restraints.rigid_bond(
      adp_restraint_params(sites_cart=sites_cart, u_cart=u_cart),
      proxy=proxy)
    loop.add_row((site_labels[proxy.i_seqs[0]],
                  site_labels[proxy.i_seqs[1]],
                  fmt % math.sqrt(1/proxy.weight),
                  fmt % (0.5*(restraint.z_12()+restraint.z_21())),
                  fmt % restraint.delta_z()))
  return loop

def rigu_as_cif_loop(xray_structure, proxies):
  unit_cell = xray_structure.unit_cell()
  sites_cart = xray_structure.sites_cart()
  u_cart = xray_structure.scatterers().extract_u_cart(unit_cell)
  site_labels = xray_structure.scatterers().extract_labels()
  fmt = "%.6f"
  loop = model.loop(header=(
    "_restr_RIGU_atom_site_label_1",
    "_restr_RIGU_atom_site_label_2",
    "_restr_RIGU_target_weight_param",
    "_restr_RIGU_U13_diff",
    "_restr_RIGU_U23_diff",
    "_restr_RIGU_U33_diff"
  ))
  for proxy in proxies:
    restraint = adp_restraints.rigu(
      adp_restraint_params(sites_cart=sites_cart, u_cart=u_cart),
      proxy=proxy)
    loop.add_row((site_labels[proxy.i_seqs[0]],
                  site_labels[proxy.i_seqs[1]],
                  fmt % math.sqrt(1/proxy.weight),
                  fmt % restraint.delta_13(),
                  fmt % restraint.delta_23(),
                  fmt % restraint.delta_33()
                 ))
  return loop

def adp_similarity_as_cif_loop(xray_structure, proxies):
  site_labels = xray_structure.scatterers().extract_labels()
  fmt = "%.4f"
  loop = model.loop(header=(
    "_restr_U_similar_atom_site_label_1",
    "_restr_U_similar_atom_site_label_2",
    "_restr_U_similar_weight_param",
  ))
  for proxy in proxies:
    loop.add_row((site_labels[proxy.i_seqs[0]],
                  site_labels[proxy.i_seqs[1]],
                  fmt % math.sqrt(1/proxy.weight)))
  return loop

def isotropic_adp_as_cif_loop(xray_structure, proxies):
  site_labels = xray_structure.scatterers().extract_labels()
  fmt = "%.4f"
  loop = model.loop(header=(
    "_restr_U_iso_atom_site_label",
    "_restr_U_iso_weight_param",
  ))
  for proxy in proxies:
    loop.add_row((site_labels[proxy.i_seqs[0]], fmt % math.sqrt(1/proxy.weight)))
  return loop

def adp_u_eq_similarity_as_cif_loops(xray_structure, proxies):
  site_labels = xray_structure.scatterers().extract_labels()
  fmt = "%.4f"
  loop = model.loop(header=(
    "_restr_U_Ueq_similar_atom_site_label_1",
    "_restr_U_Ueq_similar_diff",
    "_restr_U_Ueq_similar_class_id",
  ))
  class_loop = model.loop(header=(
    "_restr_U_Ueq_similar_class_class_id",
    "_restr_U_Ueq_similar_class_target_weight_param",
    "_restr_U_Ueq_similar_class_average",
    "_restr_U_Ueq_similar_class_esd",
    "_restr_U_Ueq_similar_class_diff_max",
  ))
  unit_cell = xray_structure.unit_cell()
  params = adp_restraints.adp_restraint_params(
    u_cart=xray_structure.scatterers().extract_u_cart(unit_cell),
    u_iso=xray_structure.scatterers().extract_u_iso(),
    use_u_aniso=xray_structure.use_u_aniso()
    )
  class_id = 0
  for proxy in proxies:
    restraint = adp_restraints.adp_u_eq_similarity(
      params=params,
      proxy=proxy)
    class_id += 1
    class_loop.add_row((class_id,
                        fmt % math.sqrt(1/proxy.weight),
                        fmt % restraint.mean_u_eq,
                        fmt % restraint.rms_deltas(),
                        fmt % flex.max_absolute(restraint.deltas())))
    for i, i_seq in enumerate(proxy.i_seqs):
      loop.add_row((site_labels[i_seq],
                    fmt % restraint.deltas()[i],
                    class_id))
  return class_loop, loop

def fixed_u_eq_adp_as_cif_loop(xray_structure, proxies):
  site_labels = xray_structure.scatterers().extract_labels()
  fmt = "%.4f"
  loop = model.loop(header=(
    "_restr_U_Ueq_atom_site_label_1",
    "_restr_U_Ueq_weight_param",
    "_restr_U_Ueq_target",
    "_restr_U_Ueq_diff"
  ))
  unit_cell = xray_structure.unit_cell()
  params = adp_restraints.adp_restraint_params(
    u_cart=xray_structure.scatterers().extract_u_cart(unit_cell),
    u_iso=xray_structure.scatterers().extract_u_iso(),
    use_u_aniso=xray_structure.use_u_aniso()
    )
  for proxy in proxies:
    restraint = adp_restraints.fixed_u_eq_adp(
      params=params,
      proxy=proxy)
    for i, i_seq in enumerate(proxy.i_seqs):
      loop.add_row((site_labels[i_seq],
                    fmt % math.sqrt(1/proxy.weight),
                    fmt % proxy.u_eq_ideal,
                    fmt % restraint.delta()))
  return loop

def adp_volume_similarity_as_cif_loops(xray_structure, proxies):
  site_labels = xray_structure.scatterers().extract_labels()
  fmt = "%.4e"
  loop = model.loop(header=(
    "_restr_U_volume_similar_atom_site_label_1",
    "_restr_U_volume_similar_diff",
    "_restr_U_volume_similar_class_id",
  ))
  class_loop = model.loop(header=(
    "_restr_U_volume_similar_class_class_id",
    "_restr_U_volume_similar_class_target_weight_param",
    "_restr_U_volume_similar_class_average",
    "_restr_U_volume_similar_class_esd",
    "_restr_U_volume_similar_class_diff_max",
  ))
  unit_cell = xray_structure.unit_cell()
  params = adp_restraints.adp_restraint_params(
    u_cart=xray_structure.scatterers().extract_u_cart(unit_cell),
    u_iso=xray_structure.scatterers().extract_u_iso(),
    use_u_aniso=xray_structure.use_u_aniso()
    )
  class_id = 0
  for proxy in proxies:
    restraint = adp_restraints.adp_volume_similarity(
      params=params,
      proxy=proxy)
    class_id += 1
    class_loop.add_row((class_id,
                        fmt % math.sqrt(1/proxy.weight),
                        fmt % restraint.mean_u_volume,
                        fmt % restraint.rms_deltas(),
                        fmt % flex.max_absolute(restraint.deltas())))
    for i, i_seq in enumerate(proxy.i_seqs):
      loop.add_row((site_labels[i_seq],
                    fmt % restraint.deltas()[i],
                    class_id))
  return class_loop, loop


 *******************************************************************************


 *******************************************************************************
iotbx/cif/tests/analyse_cod_stats.py
from __future__ import absolute_import, division, print_function
from libtbx import easy_pickle
from libtbx.utils import get_svn_revision, get_build_tag, plural_s
from operator import itemgetter
import glob, os, sys
from six.moves import cStringIO as StringIO

class analyse(object):

  def __init__(self):
    self.n_hkl = 0
    self.n_cif = 0
    self.n_hkl_cif_pairs = 0
    self.parsing_errors = {}
    self.build_errors = {}
    self.ignored_errors = {}
    self.skipped = set()
    g = glob.glob("result_*.pickle")
    for f in g:
      r = easy_pickle.load(f)
      self.n_hkl = r.n_hkl
      self.n_cif = r.n_cif
      self.n_hkl_cif_pairs = r.n_hkl_cif_pairs
      self.parsing_errors.update(r.parsing_errors)
      self.build_errors.update(r.build_errors)
      self.ignored_errors.update(r.ignored_errors)
      self.skipped.update(r.skipped)

  def show_summary(self, out=None):
    if out is None: out = sys.stdout
    n_total = self.n_cif + self.n_hkl
    print("Number of cif: %7i" % self.n_cif, file=out)
    print("Number of hkl: %7i" % self.n_hkl, file=out)
    print("Number of hkl+cif pairs: ", self.n_hkl_cif_pairs, file=out)
    print(file=out)

    print("%i parsing error%s" % plural_s(len(self.parsing_errors)), file=out)
    print("%i exception%s" % plural_s(len(self.build_errors)), file=out)
    print("%i ignored exception%s" % plural_s(len(self.ignored_errors)), file=out)
    print("%i skipping" % len(self.skipped), file=out)
    print(file=out)
    rev = get_svn_revision()
    cod_path = os.environ.get("COD_SVN_WORKING_COPY")
    cod_rev = None
    if cod_path is not None:
      cod_rev = get_svn_revision(path=cod_path)
    build_tag = get_build_tag()
    if cod_rev is not None:
      print("COD svn revision: %i" %cod_rev, file=out)
    if rev is not None:
      print("cctbx svn revision: %i" %rev, file=out)
    if build_tag is not None:
      print("cctbx build tag: ", build_tag, file=out)

  def show_all(self, out=None):
    if out is None: out = sys.stdout
    self.show_summary(out=out)
    print(file=out)
    self.show_skipping(out=out)
    print(file=out)
    self.show_exceptions(out=out)

  def show_parsing_errors(self, out=None):
    if out is None: out = sys.stdout
    for cod_id, error in sorted(
      sorted(self.parsing_errors.items()), key=itemgetter(1)):
      print("%s: %s" % (cod_id, error), file=out)

  def show_exceptions(self, out=None):
    if out is None: out = sys.stdout
    for cod_id, error in sorted(
      sorted(self.build_errors.items()), key=itemgetter(1)):
      print("%s: %s" % (cod_id, error), file=out)

  def show_skipping(self, out=None):
    if out is None: out = sys.stdout
    for s in sorted(self.skipped):
      print("SKIPPED: ", s, file=out)

  def as_html(self):
    with open("parsing_errors", "w") as out:
      self.show_parsing_errors(out=out)
    with open("exceptions", "w") as out:
      self.show_exceptions(out=out)
    with open("skipping", "w") as out:
      self.show_skipping(out=out)
    s = StringIO()
    self.show_summary(out=s)
    with open("summary.html", "w") as out:
      print(html % s.getvalue(), file=out)

html = """\
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">

<head>
<META http-equiv=Content-Type content="text/html; charset=utf-8">
<title>COD stats</title>
</head>

<body>

<hr>

<pre>
%s
</pre>

<hr>

<a href="parsing_errors">[parsing errors]</a>
<a href="exceptions">[exceptions]</a>
<a href="skipping">[skipping]</a>

<hr>

<a href="/cod_stats/current">[directory listing]</a>

<hr>

</body>
"""

def run():
  a = analyse()
  a.as_html()


if __name__ == '__main__':
  run()


 *******************************************************************************


 *******************************************************************************
iotbx/cif/tests/crawler.py
from __future__ import absolute_import, division, print_function
import glob, os, sys
from six.moves import urllib

from libtbx.utils import time_log
import libtbx.load_env
from iotbx.option_parser import option_parser
from iotbx import cif

class crawl(object):
  def __init__(self, directory, file_ext,
               build_miller_arrays=False,
               build_xray_structure=False):
    timer = time_log("parsing")
    error_count = 0
    self.parsing_error_count = 0
    for root, dirs, files in os.walk(directory):
      cif_g = glob.glob(os.path.join(root, "*.%s" %file_ext))
      files_to_read = cif_g
      for path in files_to_read:
        timer.start()
        try:
          reader = self.run_once(path, build_miller_arrays=build_miller_arrays,
                            build_xray_structure=build_xray_structure)

        except Exception as e:
          print("error reading %s" %path)
          print(e)
          error_count += 1
        timer.stop()
    print()
    print("%i files read (%i with building errors and %i with parsing errors)" %(
      timer.n, error_count, self.parsing_error_count))
    print(timer.legend)
    print(timer.report())
    sys.stdout.flush()

  def run_once(self, file_path, build_miller_arrays=False,
               build_xray_structure=False):
    reader = cif.reader(file_path=file_path, max_errors=10)
    if reader.error_count(): self.parsing_error_count += 1
    if build_xray_structure:
      xs = reader.build_crystal_structure()
    elif build_miller_arrays:
      ma = reader.build_miller_arrays()

def run_once(file_path, build_miller_arrays=False, build_xray_structure=False):
  reader = cif.reader(file_path=file_path, max_errors=10)
  if build_xray_structure:
    xs = reader.build_crystal_structure()
  elif build_miller_arrays:
    ma = reader.build_miller_arrays()

def run(args, out=sys.stdout):
  assert len(args) > 0
  command_line = (option_parser()
                  .option(None, "--file_ext",
                          action="store",
                          default="cif")
                  .option(None, "--build_xray_structure",
                          action="store_true")
                  .option(None, "--build_miller_arrays",
                          action="store_true")).process(args=args[1:])
  filepath = args[0]
  if not os.path.isabs(filepath):
    abs_path = libtbx.env.find_in_repositories(relative_path=filepath)
    if abs_path is not None: filepath = abs_path
  file_ext = command_line.options.file_ext
  build_miller_arrays = command_line.options.build_miller_arrays == True
  build_xray_structure = command_line.options.build_xray_structure == True

  if os.path.isdir(filepath):
    crawl(filepath, file_ext=file_ext,
          build_miller_arrays=build_miller_arrays,
          build_xray_structure=build_xray_structure)
  elif os.path.isfile(filepath):
    run_once(filepath, build_miller_arrays=build_miller_arrays,
             build_xray_structure=build_xray_structure)
  else:
    try:
      file_object = urllib.request.urlopen(filepath)
    except urllib.error.URLError as e:
      pass
    else:
      cm = reader(file_object=file_object).model()

if __name__ == '__main__':
  run(sys.argv[1:])
  print("OK")


 *******************************************************************************


 *******************************************************************************
iotbx/cif/tests/tst_citations.py
from __future__ import absolute_import, division, print_function

from iotbx.cif.citations import citations_as_cif_block
from libtbx import citations

def test_format():
  article_ids = ['phenix2010', 'phenix.refine', 'phaser', 'molprobity']
  citation_list = [ citations.citations_db[article_id]
                    for article_id in article_ids ]
  cif_block = citations_as_cif_block(citation_list)
  assert list(cif_block['_citation.id']) == [
    'phenix2010', 'phenix.refine', 'phaser', 'molprobity']
  assert list(cif_block['_citation.journal_id_CSD']) == [
    '0766', '0766', '0228', '?']
  assert list(cif_block['_citation.journal_volume']) == ['66', '68', '40', '27']
  expected_keys = ('_citation.id', '_citation.title', '_citation.journal_abbrev',
                   '_citation.journal_volume', '_citation.page_first',
                   '_citation.page_last', '_citation.year',
                   '_citation.journal_id_ASTM', '_citation.journal_id_ISSN',
                   '_citation.journal_id_CSD')
  for key in expected_keys:
    assert key in cif_block

if (__name__ == '__main__'):
  test_format()
  print('OK')


 *******************************************************************************


 *******************************************************************************
iotbx/cif/tests/tst_cod.py
from __future__ import absolute_import, division, print_function
from iotbx.cif import cod_tools
import iotbx.cif
from iotbx.cif.builders import CifBuilderError
from iotbx.cif import CifParserError
from libtbx import easy_pickle, group_args
import os, traceback

def run(args, command_name):
  from iotbx.option_parser import option_parser as iotbx_option_parser
  import libtbx.utils
  show_times = libtbx.utils.show_times(time_start="now")
  command_line = (iotbx_option_parser(
    usage=command_name+" [options] [cod_id...]")
    .enable_chunk(easy_all=True)
    .enable_multiprocessing()
    .option(None, "--parse_only",
            action="store_true")
    .option(None, "--cif_only",
            action="store_true")
    .option(None, "--hkl_only",
            action="store_true")
    .option("-v", "--verbose",
            action="store_true")
  ).process(args=args)
  if (command_line.run_multiprocessing_chunks_if_applicable(
        command_call=[command_name, __file__])):
    show_times()
    return
  co = command_line.options
  cod_ids = command_line.args
  assert [co.cif_only, co.hkl_only].count(True) <= 1
  if co.cif_only: ext = "cif"
  elif co.hkl_only: ext = "hkl"
  else: ext = None
  verbose = co.verbose
  parse_only = co.parse_only
  #
  cod_hkl_cif = cod_tools.build_hkl_cif(cod_ids=cod_ids, ext=ext)
  cod_hkl_cif.show_summary()
  hkl_files = cod_hkl_cif.hkl
  cif_files = cod_hkl_cif.cif
  #
  n_total = 0
  #
  parsing_errors = {}
  build_errors = {}
  ignored_errors = {}
  skipped = set()
  #
  files_to_parse = []
  files_to_parse.extend(hkl_files.values())
  files_to_parse.extend(cif_files.values())
  for i, path in enumerate(files_to_parse):
    n_total += 1
    if (i % command_line.chunk.n != command_line.chunk.i): continue
    try:
      cod_id = os.path.basename(path)
      cif_obj = iotbx.cif.reader(file_path=path)
      if parse_only: continue
      skip_file = False
      for cif_block in cif_obj.model().values():
        value = cif_block.get("_cod_error_flag")
        keys = set(cif_block.keys())
        if (value in ["errors", "retracted"]):
          skip_file = True
          skipped.add(cod_id)
          if verbose:
            print("SKIPPING: _cod_error_flag %s: %s" % (value, cod_id))
        elif (len(set([
          "_space_group_symop_ssg_operation_algebraic",
          "_space_group_ssg_name"]).intersection(keys)) != 0):
          skipped.add(cod_id)
          if verbose:
            print("SKIPPING: COD entry with super-space group:", cod_id)
        elif (len(set([
              "_refln_index_m",
              "_refln_index_m_1"]).intersection(keys)) != 0):
          if verbose:
            print("SKIPPING: COD entry with _refln_index_m:", cod_id)
          skipped.add(cod_id)
      if skip_file: continue
      if path.endswith('.cif'):
        cif_obj.build_crystal_structures()
      elif path.endswith('.hkl'):
        cif_obj.build_miller_arrays()
      else:
        iotbx.cif.cctbx_data_structures_from_cif(cif_model=cif_obj.model())
    except KeyboardInterrupt:
      print("CAUGHT EXCEPTION: KeyboardInterrupt")
      return
    except CifBuilderError as e:
      e_str = str(e)
      if not verbose and (
        e_str.startswith("No atomic coordinates could be found") or
        e_str.startswith(
          "No symmetry instructions could be extracted from the cif block")):
        ignored_errors.setdefault(cod_id, e_str)
        continue
      sys.stdout.flush()
      print("CAUGHT EXCEPTION: %s: %s: %s" % (command_name, cod_id, str(e)), file=sys.stderr)
      if verbose:
        traceback.print_exc()
        print(file=sys.stderr)
      build_errors.setdefault(cod_id, e_str)
      sys.stderr.flush()
    except CifParserError as e:
      sys.stdout.flush()
      e_str = str(e)
      parsing_errors.setdefault(cod_id, e_str)
      print("PARSING ERROR: %s: %s: %s" % (command_name, cod_id, e_str), file=sys.stderr)
      if verbose:
        traceback.print_exc()
        print(file=sys.stderr)
      sys.stderr.flush()
    except Exception as e:
      sys.stdout.flush()
      e_str = str(e)
      build_errors.setdefault(cod_id, e_str)
      print("CAUGHT EXCEPTION: %s: %s: %s" % (command_name, cod_id, e_str), file=sys.stderr)
      if verbose:
        traceback.print_exc()
        print(file=sys.stderr)
      sys.stderr.flush()
  print()

  print("Number successfully parsed: %i/%i" \
        % (n_total-len(parsing_errors),n_total))
  if not parse_only:
    print("Number skipped:", len(skipped))
    print("Number of exceptions caught:", len(build_errors))
    print("Number of exceptions ignored:", len(ignored_errors))
  print()
  #
  show_times()
  result = group_args(
    n_hkl=len(hkl_files),
    n_cif=len(cif_files),
    n_hkl_cif_pairs=len(cod_hkl_cif.hkl_cif_pairs),
    parsing_errors=parsing_errors,
    build_errors=build_errors,
    ignored_errors=ignored_errors,
    skipped=skipped)
  easy_pickle.dump("result_%03i.pickle" %command_line.chunk.i, result)
  print()

if __name__ == '__main__':
  import libtbx.load_env
  import sys
  run(args=sys.argv[1:], command_name=libtbx.env.dispatcher_name)


 *******************************************************************************


 *******************************************************************************
iotbx/cif/tests/tst_crystal_symmetry_builder.py
from __future__ import absolute_import, division, print_function
from iotbx.pdb.mmcif import cif_input

def tst_bad_symmetry_1():
  """ NMR structure with question mark in unit cell parameters.
  Expected outcome - as if absent completely.
  """
  cif_txt_1 = """\
data_1JZC
_cell.entry_id           1JZC
_cell.length_a           ?
_cell.length_b           ?
_cell.length_c           ?
_cell.angle_alpha        ?
_cell.angle_beta         ?
_cell.angle_gamma        ?
_cell.Z_PDB              1
_cell.pdbx_unique_axis   ?
#
loop_
_atom_site.group_PDB
_atom_site.id
_atom_site.type_symbol
_atom_site.label_atom_id
_atom_site.label_alt_id
_atom_site.label_comp_id
_atom_site.label_asym_id
_atom_site.label_entity_id
_atom_site.label_seq_id
_atom_site.pdbx_PDB_ins_code
_atom_site.Cartn_x
_atom_site.Cartn_y
_atom_site.Cartn_z
_atom_site.occupancy
_atom_site.B_iso_or_equiv
_atom_site.pdbx_formal_charge
_atom_site.auth_seq_id
_atom_site.auth_comp_id
_atom_site.auth_asym_id
_atom_site.auth_atom_id
_atom_site.pdbx_PDB_model_num
ATOM 1   O "O5'"  . G A 1 1  ? -4.337  -11.083 -6.294 1.00 2.13 ? 1  G A "O5'"  1
ATOM 2   C "C5'"  . G A 1 1  ? -5.629  -11.603 -6.617 1.00 2.29 ? 1  G A "C5'"  1
ATOM 3   C "C4'"  . G A 1 1  ? -6.489  -11.784 -5.370 1.00 2.23 ? 1  G A "C4'"  1
"""
  c_inp = cif_input(source_info=None, lines=cif_txt_1)
  cs = c_inp.crystal_symmetry()
  assert cs.unit_cell() == None
  assert cs.space_group() == None
  assert cs.is_empty()

def tst_bad_symmetry_2():
  """ Same as #1, but no parameters at all.
  Expected outcome - as if absent completely.
  """
  cif_txt_1 = """\
data_1JZC
#
loop_
_atom_site.group_PDB
_atom_site.id
_atom_site.type_symbol
_atom_site.label_atom_id
_atom_site.label_alt_id
_atom_site.label_comp_id
_atom_site.label_asym_id
_atom_site.label_entity_id
_atom_site.label_seq_id
_atom_site.pdbx_PDB_ins_code
_atom_site.Cartn_x
_atom_site.Cartn_y
_atom_site.Cartn_z
_atom_site.occupancy
_atom_site.B_iso_or_equiv
_atom_site.pdbx_formal_charge
_atom_site.auth_seq_id
_atom_site.auth_comp_id
_atom_site.auth_asym_id
_atom_site.auth_atom_id
_atom_site.pdbx_PDB_model_num
ATOM 1   O "O5'"  . G A 1 1  ? -4.337  -11.083 -6.294 1.00 2.13 ? 1  G A "O5'"  1
ATOM 2   C "C5'"  . G A 1 1  ? -5.629  -11.603 -6.617 1.00 2.29 ? 1  G A "C5'"  1
ATOM 3   C "C4'"  . G A 1 1  ? -6.489  -11.784 -5.370 1.00 2.23 ? 1  G A "C4'"  1
"""
  c_inp = cif_input(source_info=None, lines=cif_txt_1)
  cs = c_inp.crystal_symmetry()
  assert cs.unit_cell() == None
  assert cs.space_group() == None
  assert cs.is_empty()


if __name__ == '__main__':
  tst_bad_symmetry_1()
  tst_bad_symmetry_2()


 *******************************************************************************


 *******************************************************************************
iotbx/cif/tests/tst_geometry.py
from __future__ import absolute_import, division, print_function
from cctbx import crystal, sgtbx, xray
from cctbx.eltbx import covalent_radii
from cctbx.array_family import flex
from libtbx.test_utils import show_diff
from iotbx.cif import geometry
from scitbx import matrix
from six.moves import cStringIO as StringIO

def exercise_cif_from_cctbx():
  quartz = xray.structure(
    crystal_symmetry=crystal.symmetry(
      (5.01,5.01,5.47,90,90,120), "P6222"),
    scatterers=flex.xray_scatterer([
      xray.scatterer("Si", (1/2.,1/2.,1/3.)),
      xray.scatterer("O", (0.197,-0.197,0.83333))]))
  for sc in quartz.scatterers():
    sc.flags.set_grad_site(True)
  s = StringIO()
  loop = geometry.distances_as_cif_loop(
    quartz.pair_asu_table(distance_cutoff=2),
    site_labels=quartz.scatterers().extract_labels(),
    sites_frac=quartz.sites_frac()).loop
  print(loop, file=s)
  assert not show_diff(s.getvalue(), """\
loop_
  _geom_bond_atom_site_label_1
  _geom_bond_atom_site_label_2
  _geom_bond_distance
  _geom_bond_site_symmetry_2
  Si  O  1.6160  4_554
  Si  O  1.6160  2_554
  Si  O  1.6160  3_664
  Si  O  1.6160  5_664

""")
  s = StringIO()
  loop = geometry.angles_as_cif_loop(
    quartz.pair_asu_table(distance_cutoff=2),
    site_labels=quartz.scatterers().extract_labels(),
    sites_frac=quartz.sites_frac()).loop
  print(loop, file=s)
  assert not show_diff(s.getvalue(), """\
loop_
  _geom_angle_atom_site_label_1
  _geom_angle_atom_site_label_2
  _geom_angle_atom_site_label_3
  _geom_angle
  _geom_angle_site_symmetry_1
  _geom_angle_site_symmetry_3
  O   Si  O   101.3  2_554  4_554
  O   Si  O   111.3  3_664  4_554
  O   Si  O   116.1  3_664  2_554
  O   Si  O   116.1  5_664  4_554
  O   Si  O   111.3  5_664  2_554
  O   Si  O   101.3  5_664  3_664
  Si  O   Si  146.9  3      5

""")
  # with a covariance matrix
  flex.set_random_seed(1)
  vcv_matrix = matrix.diag(
    flex.random_double(size=quartz.n_parameters(), factor=1e-5))\
             .as_flex_double_matrix().matrix_symmetric_as_packed_u()
  s = StringIO()
  loop = geometry.distances_as_cif_loop(
    quartz.pair_asu_table(distance_cutoff=2),
    site_labels=quartz.scatterers().extract_labels(),
    sites_frac=quartz.sites_frac(),
    covariance_matrix=vcv_matrix,
    parameter_map=quartz.parameter_map()).loop
  print(loop, file=s)
  assert not show_diff(s.getvalue(), """\
loop_
  _geom_bond_atom_site_label_1
  _geom_bond_atom_site_label_2
  _geom_bond_distance
  _geom_bond_site_symmetry_2
  Si  O  1.616(14)  4_554
  Si  O  1.616(12)  2_554
  Si  O  1.616(14)  3_664
  Si  O  1.616(12)  5_664

""")
  s = StringIO()
  loop = geometry.angles_as_cif_loop(
    quartz.pair_asu_table(distance_cutoff=2),
    site_labels=quartz.scatterers().extract_labels(),
    sites_frac=quartz.sites_frac(),
    covariance_matrix=vcv_matrix,
    parameter_map=quartz.parameter_map()).loop
  print(loop, file=s)
  assert not show_diff(s.getvalue(), """\
loop_
  _geom_angle_atom_site_label_1
  _geom_angle_atom_site_label_2
  _geom_angle_atom_site_label_3
  _geom_angle
  _geom_angle_site_symmetry_1
  _geom_angle_site_symmetry_3
  O   Si  O    101.3(8)  2_554  4_554
  O   Si  O   111.3(10)  3_664  4_554
  O   Si  O    116.1(9)  3_664  2_554
  O   Si  O    116.1(9)  5_664  4_554
  O   Si  O   111.3(10)  5_664  2_554
  O   Si  O    101.3(8)  5_664  3_664
  Si  O   Si   146.9(9)  3      5

""")
  cell_vcv = flex.pow2(matrix.diag(flex.random_double(size=6,factor=1e-1))\
                       .as_flex_double_matrix().matrix_symmetric_as_packed_u())
  s = StringIO()
  loop = geometry.distances_as_cif_loop(
    quartz.pair_asu_table(distance_cutoff=2),
    site_labels=quartz.scatterers().extract_labels(),
    sites_frac=quartz.sites_frac(),
    covariance_matrix=vcv_matrix,
    cell_covariance_matrix=cell_vcv,
    parameter_map=quartz.parameter_map()).loop
  print(loop, file=s)
  assert not show_diff(s.getvalue(), """\
loop_
  _geom_bond_atom_site_label_1
  _geom_bond_atom_site_label_2
  _geom_bond_distance
  _geom_bond_site_symmetry_2
  Si  O  1.616(15)  4_554
  Si  O  1.616(19)  2_554
  Si  O  1.616(15)  3_664
  Si  O  1.616(19)  5_664

""")


def exercise_hbond_as_cif_loop():
  xs = sucrose()
  for sc in xs.scatterers():
    sc.flags.set_grad_site(True)
  radii = [
    covalent_radii.table(elt).radius() for elt in
    xs.scattering_type_registry().type_index_pairs_as_dict() ]
  asu_mappings = xs.asu_mappings(
    buffer_thickness=2*max(radii) + 0.5)
  pair_asu_table = crystal.pair_asu_table(asu_mappings)
  pair_asu_table.add_covalent_pairs(
    xs.scattering_types(),
    tolerance=0.5)
  hbonds = [
    geometry.hbond(1,5, sgtbx.rt_mx('-X,0.5+Y,2-Z')),
    geometry.hbond(5,14, sgtbx.rt_mx('-X,-0.5+Y,1-Z')),
    geometry.hbond(7,10, sgtbx.rt_mx('1+X,+Y,+Z')),
    geometry.hbond(10,0),
    geometry.hbond(12,14, sgtbx.rt_mx('-1-X,0.5+Y,1-Z')),
    geometry.hbond(14,12, sgtbx.rt_mx('-1-X,-0.5+Y,1-Z')),
    geometry.hbond(16,7)
  ]
  loop = geometry.hbonds_as_cif_loop(
    hbonds, pair_asu_table, xs.scatterers().extract_labels(),
    sites_frac=xs.sites_frac()).loop
  s = StringIO()
  print(loop, file=s)
  assert not show_diff(s.getvalue(), """\
loop_
  _geom_hbond_atom_site_label_D
  _geom_hbond_atom_site_label_H
  _geom_hbond_atom_site_label_A
  _geom_hbond_distance_DH
  _geom_hbond_distance_HA
  _geom_hbond_distance_DA
  _geom_hbond_angle_DHA
  _geom_hbond_site_symmetry_A
  O2   H2   O4  0.8200  2.0636  2.8635  165.0  2_557
  O4   H4   O9  0.8200  2.0559  2.8736  174.9  2_546
  O5   H5   O7  0.8200  2.0496  2.8589  169.0  1_655
  O7   H7   O1  0.8200  2.0573  2.8617  166.8  .
  O8   H8   O9  0.8200  2.1407  2.8943  152.8  2_456
  O9   H9   O8  0.8200  2.1031  2.8943  162.1  2_446
  O10  H10  O5  0.8200  2.0167  2.7979  159.1  .

""")
  # with a covariance matrix
  flex.set_random_seed(1)
  vcv_matrix = matrix.diag(
    flex.random_double(size=xs.n_parameters(), factor=1e-5))\
             .as_flex_double_matrix().matrix_symmetric_as_packed_u()
  loop = geometry.hbonds_as_cif_loop(
    hbonds, pair_asu_table, xs.scatterers().extract_labels(),
    sites_frac=xs.sites_frac(),
    covariance_matrix=vcv_matrix,
    parameter_map=xs.parameter_map()).loop
  s = StringIO()
  print(loop, file=s)
  assert not show_diff(s.getvalue(), """\
loop_
  _geom_hbond_atom_site_label_D
  _geom_hbond_atom_site_label_H
  _geom_hbond_atom_site_label_A
  _geom_hbond_distance_DH
  _geom_hbond_distance_HA
  _geom_hbond_distance_DA
  _geom_hbond_angle_DHA
  _geom_hbond_site_symmetry_A
  O2   H2   O4  0.82(3)  2.06(3)    2.86(3)  165.0(18)  2_557
  O4   H4   O9  0.82(4)  2.06(4)    2.87(4)     175(2)  2_546
  O5   H5   O7  0.82(2)  2.05(2)  2.859(19)  169.0(18)  1_655
  O7   H7   O1  0.82(2)  2.06(2)    2.86(2)     167(2)  .
  O8   H8   O9  0.82(3)  2.14(3)    2.89(3)     153(3)  2_456
  O9   H9   O8  0.82(3)  2.10(3)    2.89(3)     162(2)  2_446
  O10  H10  O5  0.82(3)  2.02(3)    2.80(3)     159(3)  .

""")
  cell_vcv = flex.pow2(matrix.diag(flex.random_double(size=6,factor=1e-1))\
                       .as_flex_double_matrix().matrix_symmetric_as_packed_u())
  loop = geometry.hbonds_as_cif_loop(
    hbonds, pair_asu_table, xs.scatterers().extract_labels(),
    sites_frac=xs.sites_frac(),
    covariance_matrix=vcv_matrix,
    cell_covariance_matrix=cell_vcv,
    parameter_map=xs.parameter_map()).loop
  s = StringIO()
  print(loop, file=s)
  assert not show_diff(s.getvalue(), """\
loop_
  _geom_hbond_atom_site_label_D
  _geom_hbond_atom_site_label_H
  _geom_hbond_atom_site_label_A
  _geom_hbond_distance_DH
  _geom_hbond_distance_HA
  _geom_hbond_distance_DA
  _geom_hbond_angle_DHA
  _geom_hbond_site_symmetry_A
  O2   H2   O4  0.82(3)  2.06(4)  2.86(4)  165.0(18)  2_557
  O4   H4   O9  0.82(4)  2.06(4)  2.87(4)     175(2)  2_546
  O5   H5   O7  0.82(2)  2.05(2)  2.86(2)  169.0(18)  1_655
  O7   H7   O1  0.82(2)  2.06(3)  2.86(3)     167(2)  .
  O8   H8   O9  0.82(3)  2.14(4)  2.89(4)     153(3)  2_456
  O9   H9   O8  0.82(3)  2.10(3)  2.89(4)     162(2)  2_446
  O10  H10  O5  0.82(3)  2.02(3)  2.80(3)     159(3)  .

""")


def sucrose():
  return xray.structure(
    crystal_symmetry=crystal.symmetry(
      unit_cell=(7.783, 8.7364, 10.9002, 90, 102.984, 90),
      space_group_symbol='hall:  P 2yb'),
    scatterers=flex.xray_scatterer((
      xray.scatterer( #0
                      label='O1',
                      site=(-0.131694, 0.935444, 0.877178),
                      u=(0.000411, 0.000231, 0.000177,
                         -0.000017, 0.000112, -0.000003)),
      xray.scatterer( #1
                      label='O2',
                      site=(-0.214093, 0.788106, 1.081133),
                      u=(0.000809, 0.000424, 0.000219,
                       0.000105, 0.000177, 0.000051)),
      xray.scatterer( #2
                      label='H2',
                      site=(-0.227111, 0.876745, 1.102068),
                      u=0.050326),
      xray.scatterer( #3
                      label='O3',
                      site=(-0.145099, 0.520224, 0.848374),
                      u=(0.000860, 0.000240, 0.000587,
                         -0.000149, 0.000303, -0.000093)),
      xray.scatterer( #4
                      label='H3',
                      site=(-0.073357, 0.454114, 0.840907),
                      u=0.064297),
      xray.scatterer( #5
                      label='O4',
                      site=(0.202446, 0.586695, 0.808946),
                      u=(0.000848, 0.000352, 0.000315,
                         0.000294, 0.000256, 0.000111)),
      xray.scatterer( #6
                      label='H4',
                      site=(0.234537, 0.569702, 0.743559),
                      u=0.052973),
      xray.scatterer( #7
                      label='O5',
                      site=(0.247688, 0.897720, 0.729153),
                      u=(0.000379, 0.000386, 0.000270,
                         -0.000019, 0.000106, 0.000001)),
      xray.scatterer( #8
                      label='H5',
                      site=(0.323942, 0.957695, 0.764491),
                      u=0.040241),
      xray.scatterer( #9
                      label='O6',
                      site=(-0.183682, 1.239489, 0.712253),
                      u=(0.000240, 0.000270, 0.000208,
                         0.000035, 0.000002, -0.000057)),
      xray.scatterer( #10
                      label='O7',
                      site=(-0.460944, 1.095427, 0.826725),
                      u=(0.000454, 0.000438, 0.000330,
                         0.000029, 0.000103, 0.000091)),
      xray.scatterer( #11
                      label='H7',
                      site=(-0.360598, 1.061356, 0.849066),
                      u=0.048134),
      xray.scatterer( #12
                      label='O8',
                      site=(-0.590098, 1.234857, 0.477504),
                      u=(0.000341, 0.000376, 0.000283,
                         0.000054, -0.000022, 0.000051)),
      xray.scatterer( #13
                      label='H8',
                      site=(-0.596179, 1.326096, 0.493669),
                      u=0.041878),
      xray.scatterer( #14
                      label='O9',
                      site=(-0.294970, 1.016028, 0.425505),
                      u=(0.000509, 0.000266, 0.000191,
                         -0.000031, 0.000056, -0.000050)),
      xray.scatterer( #15
                      label='H9',
                      site=(-0.305666, 0.937198, 0.463939),
                      u=0.035859),
      xray.scatterer( #16
                      label='O10',
                      site=(0.121231, 1.098881, 0.529558),
                      u=(0.000428, 0.000442, 0.000264,
                         0.000037, 0.000149, 0.000061)),
      xray.scatterer( #17
                      label='H10',
                      site=(0.164296, 1.026179, 0.573427),
                      u=0.042667),
      xray.scatterer( #18
                      label='O11',
                      site=(-0.108540, 0.986958, 0.671415),
                      u=(0.000301, 0.000160, 0.000170,
                         -0.000018, 0.000028, 0.000003)),
      xray.scatterer( #19
                      label='C1',
                      site=(-0.205698, 0.782086, 0.859435),
                      u=(0.000378, 0.000249, 0.000211,
                         -0.000046, 0.000020, 0.000007)),
      xray.scatterer( #20
                      label='H1',
                      site=(-0.282033, 0.773748, 0.774955),
                      u=0.033128),
      xray.scatterer( #21
                      label='C2',
                      site=(-0.315620, 0.763019, 0.956870),
                      u=(0.000478, 0.000387, 0.000268,
                         0.000006, 0.000115, 0.000085)),
      xray.scatterer( #22
                      label='H2B',
                      site=(-0.413052, 0.834909, 0.939327),
                      u=0.042991),
      xray.scatterer( #23
                      label='C3',
                      site=(-0.057676, 0.663433, 0.874279),
                      u=(0.000481, 0.000203, 0.000211,
                         -0.000039, 0.000097, -0.000026)),
      xray.scatterer( #24
                      label='H3B',
                      site=(0.010861, 0.664198, 0.961490),
                      u=0.033010),
      xray.scatterer( #25
                      label='C4',
                      site=(0.064486, 0.697929, 0.785789),
                      u=(0.000516, 0.000251, 0.000171,
                         0.000108, 0.000066, 0.000006)),
      xray.scatterer( #26
                      label='H2A',
                      site=(-0.364431, 0.660423, 0.951038),
                      u=0.042991),
      xray.scatterer( #27
                      label='H4B',
                    site=(-0.001643, 0.690588, 0.698163),
                    u=0.034151),
      xray.scatterer( #28
                      label='C5',
                      site=(0.134552, 0.859023, 0.812706),
                      u=(0.000346, 0.000319, 0.000114,
                         0.000016, 0.000027, 0.000034)),
      xray.scatterer( #29
                      label='H5B',
                      site=(0.204847, 0.862433, 0.899373),
                      u=0.028874),
      xray.scatterer( #30
                      label='C6',
                      site=(-0.013996, 0.975525, 0.800238),
                      u=(0.000321, 0.000194, 0.000125,
                         -0.000031, 0.000037, -0.000006)),
      xray.scatterer( #31
                      label='H6',
                      site=(0.037624, 1.075652, 0.827312),
                      u=0.023850),
      xray.scatterer( #32
                      label='C7',
                      site=(-0.130206, 1.141642, 0.624140),
                      u=(0.000313, 0.000143, 0.000184,
                         -0.000000, 0.000045, -0.000001)),
      xray.scatterer( #33
                      label='C8',
                      site=(0.043311, 1.203061, 0.603290),
                      u=(0.000354, 0.000269, 0.000247,
                         -0.000020, 0.000085, 0.000024)),
      xray.scatterer( #34
                      label='H8A',
                      site=(0.023319, 1.300964, 0.560480),
                      u=0.034035),
      xray.scatterer( #35
                      label='H8B',
                      site=(0.123967, 1.219261, 0.684061),
                      u=0.034035),
      xray.scatterer( #36
                      label='C9',
                      site=(-0.285452, 1.143037, 0.507357),
                      u=(0.000294, 0.000203, 0.000181,
                         0.000009, 0.000062, 0.000042)),
      xray.scatterer( #37
                      label='H9B',
                      site=(-0.273079, 1.235040, 0.458631),
                      u=0.026214),
      xray.scatterer( #38
                      label='C10',
                      site=(-0.444628, 1.167026, 0.565148),
                      u=(0.000289, 0.000234, 0.000210,
                         0.000018, 0.000036, 0.000040)),
      xray.scatterer( #39
                      label='H10B',
                      site=(-0.480820, 1.069195, 0.595409),
                      u=0.029493),
      xray.scatterer( #40
                      label='C11',
                      site=(-0.371995, 1.272625, 0.676806),
                      u=(0.000324, 0.000199, 0.000264,
                         0.000054, 0.000089, 0.000009)),
      xray.scatterer( #41
                      label='H11',
                      site=(-0.388144, 1.379127, 0.648319),
                      u=0.031434),
      xray.scatterer( #42
                      label='C12',
                      site=(-0.453277, 1.252159, 0.788677),
                      u=(0.000396, 0.000422, 0.000263,
                         0.000043, 0.000125, -0.000061)),
      xray.scatterer( #43
                      label='H12B',
                      site=(-0.571879, 1.293694, 0.768457),
                      u=0.041343),
      xray.scatterer( #44
                      label='H12A',
                      site=(-0.385488, 1.310416, 0.858834),
                      u=0.041343)
    )))

if __name__ == '__main__':
  exercise_hbond_as_cif_loop()
  exercise_cif_from_cctbx()
  print("OK")


 *******************************************************************************


 *******************************************************************************
iotbx/cif/tests/tst_lex_parse_build.py
from __future__ import absolute_import, division, print_function
from cctbx.array_family import flex
from cctbx import crystal, miller, sgtbx, uctbx
from iotbx import cif
from iotbx.cif import CifParserError
from iotbx.cif.builders import CifBuilderError
from iotbx import crystal_symmetry_from_any
from iotbx.reflection_file_reader import any_reflection_file
from libtbx.test_utils import \
     approx_equal, show_diff, Exception_expected, open_tmp_file
from six.moves import cStringIO as StringIO
import sys
from six.moves import zip


def exercise_miller_arrays_as_cif_block():
  from iotbx.cif import reader
  cif_model = reader(input_string=cif_miller_array,
                     builder=cif.builders.cif_model_builder()).model()
  ma_builder = cif.builders.miller_array_builder(cif_model['global'])
  ma1 = ma_builder.arrays()['_refln_F_squared_meas']
  mas_as_cif_block = cif.miller_arrays_as_cif_block(
    ma1, array_type='meas', format="corecif")
  mas_as_cif_block.add_miller_array(
    ma1.array(data=flex.complex_double([1-1j]*ma1.size())), array_type='calc')
  mas_as_cif_block.add_miller_array(
    ma1.array(data=flex.complex_double([1-2j]*ma1.size())), column_names=[
      '_refln_A_calc', '_refln_B_calc'])
  for key in ('_refln_F_squared_meas', '_refln_F_squared_sigma',
              '_refln_F_calc', '_refln_phase_calc',
              '_refln_A_calc', '_refln_A_calc'):
    assert (key in mas_as_cif_block.cif_block.keys()), key
  #
  mas_as_cif_block = cif.miller_arrays_as_cif_block(
    ma1, array_type='meas', format="mmcif")
  mas_as_cif_block.add_miller_array(
    ma1.array(data=flex.complex_double([1-1j]*ma1.size())), array_type='calc')
  for key in ('_refln.F_squared_meas', '_refln.F_squared_sigma',
              '_refln.F_calc', '_refln.phase_calc',
              '_space_group_symop.operation_xyz',
              '_cell.length_a', '_refln.index_h'):
    assert key in mas_as_cif_block.cif_block.keys()
  #
  mas_as_cif_block = cif.miller_arrays_as_cif_block(
    ma1, column_names=['_diffrn_refln_intensity_net',
                       '_diffrn_refln_intensity_sigma'],
         miller_index_prefix='_diffrn_refln')
  mas_as_cif_block.add_miller_array(
    ma1.array(data=flex.std_string(ma1.size(), 'om')),
    column_name='_diffrn_refln_intensity_u')
  for key in ('_diffrn_refln_intensity_net', '_diffrn_refln_intensity_sigma',
              '_diffrn_refln_intensity_u'):
    assert key in list(mas_as_cif_block.cif_block.keys())
  #
  try: reader(input_string=cif_global)
  except CifParserError as e: pass
  else: raise Exception_expected
  cif_model = reader(input_string=cif_global, strict=False).model()
  assert not show_diff(str(cif_model), """\
data_1
_c                                3
_d                                4
""")
  # exercise adding miller arrays with non-matching indices
  cs = crystal.symmetry(unit_cell=uctbx.unit_cell((10, 10, 10, 90, 90, 90)),
                        space_group_info=sgtbx.space_group_info(symbol="P1"))
  mi = flex.miller_index(((1,0,0), (1,2,3), (2,3,4)))
  ms1 = miller.set(cs, mi)
  ma1 = miller.array(ms1, data=flex.double((1,2,3)))
  mas_as_cif_block = cif.miller_arrays_as_cif_block(
    ma1, column_name="_refln.F_meas_au")
  ms2 = miller.set(cs, mi[:2])
  ma2 = miller.array(ms2, data=flex.complex_double([1-2j]*ms2.size()))
  mas_as_cif_block.add_miller_array(
    ma2, column_names=("_refln.F_calc_au", "_refln.phase_calc")),
  ms3 = miller.set(cs, flex.miller_index(((1,0,0), (5,6,7), (2,3,4))))
  ma3 = miller.array(ms3, data=flex.double((4,5,6)))
  mas_as_cif_block.add_miller_array(ma3, column_name="_refln.F_squared_meas")
  ms4 = miller.set(cs, flex.miller_index(((1,2,3), (5,6,7), (1,1,1), (1,0,0), (2,3,4))))
  ma4 = ms4.d_spacings()
  mas_as_cif_block.add_miller_array(ma4, column_name="_refln.d_spacing")
  # extract arrays from cif block and make sure we get back what we started with
  arrays = cif.builders.miller_array_builder(mas_as_cif_block.cif_block).arrays()
  recycled_arrays = (arrays['_refln.F_meas_au'],
                     arrays['_refln.F_calc_au'],
                     arrays['_refln.F_squared_meas'],
                     arrays['_refln.d_spacing'])
  for orig, recycled in zip((ma1, ma2, ma3, ma4), recycled_arrays):
    assert orig.size() == recycled.size()
    recycled = recycled.customized_copy(anomalous_flag=orig.anomalous_flag())
    orig, recycled = orig.common_sets(recycled)
    assert orig.indices().all_eq(recycled.indices())
    assert approx_equal(orig.data(), recycled.data(), eps=1e-5)
  #
  cif_model = reader(input_string=r3adrsf,
                     builder=cif.builders.cif_model_builder()).model()
  cs = cif.builders.crystal_symmetry_builder(cif_model["r3adrsf"]).crystal_symmetry

  ma_builder = cif.builders.miller_array_builder(
    cif_model['r3adrAsf'],
    base_array_info=miller.array_info(crystal_symmetry_from_file=cs))
  miller_arrays = list(ma_builder.arrays().values())
  assert len(miller_arrays) == 4
  mas_as_cif_block = cif.miller_arrays_as_cif_block(
      miller_arrays[0].map_to_asu(),
      column_names=miller_arrays[0].info().labels,
      format="corecif")
  for array in miller_arrays[1:]:
    labels = array.info().labels
    if len(labels) > 1 :
      for label in labels :
        if label.startswith("wavelength_id"):
          labels.remove(label)
    mas_as_cif_block.add_miller_array(
      array=array.map_to_asu(), column_names=array.info().labels)
  s = StringIO()
  print(mas_as_cif_block.refln_loop, file=s)
  assert not show_diff(s.getvalue(), """\
loop_
  _refln_index_h
  _refln_index_k
  _refln_index_l
  _refln.crystal_id
  _refln.wavelength_id
  _refln.scale_group_code
  _refln.pdbx_I_plus
  _refln.pdbx_I_plus_sigma
  _refln.pdbx_I_minus
  _refln.pdbx_I_minus_sigma
  -87  5  46  1  3  1   40.2  40.4    6.7  63.9
  -87  5  45  1  3  1   47.8  29.7   35.1  30.5
  -87  5  44  1  3  1   18.1  33.2    0.5  34.6
  -87  5  43  1  3  1    6.1  45.4   12.9  51.6
  -87  5  42  1  3  1   -6.6  45.6  -15.5  55.8
  -87  7  37  1  3  1    6.3  43.4      ?     ?
  -87  7  36  1  3  1  -67.2  55.4      ?     ?
  -88  2  44  1  3  1      0    -1     35  38.5
  -88  2  43  1  3  1      0    -1   57.4  41.5
  -88  4  45  1  3  1     -1  46.1   -9.1  45.6
  -88  4  44  1  3  1  -19.8  49.2    0.3  34.7
  -88  6  44  1  3  1   -1.8  34.8      ?     ?

""")




def exercise_lex_parse_build():
  exercise_parser(cif.reader, cif.builders.cif_model_builder)
  cm = cif.reader(input_string=cif_quoted_string).model()
  assert cm['global']['_a'] == 'a"b'
  assert cm['global']['_b'] == "a dog's life"
  stdout = sys.stdout
  s = StringIO()
  sys.stdout = s
  try: cif.reader(input_string=cif_invalid_missing_value)
  except CifParserError: pass
  else: raise Exception_expected
  r = cif.reader(
    input_string=cif_invalid_missing_value, raise_if_errors=False)
  assert r.error_count() == 1
  try: cif.reader(input_string=cif_invalid_string)
  except CifParserError: pass
  else: raise Exception_expected
  a = cif.reader(input_string=cif_cod)
  assert a.error_count() == 0
  try: cif.reader(input_string=cif_invalid_semicolon_text_field)
  except CifParserError: pass
  else: raise Exception_expected
  d = cif.reader(input_string=cif_valid_semicolon_text_field)
  assert d.error_count() == 0
  assert d.model()['1']['_a'] == '\n1\n'
  e = cif.reader(input_string=cif_unquoted_string_semicolon)
  assert not show_diff(str(e.model()), """\
data_1
_a                                ;1
_b                                ;
_c                                2
""")
  cif_str_1 = """\
data_1
_a 1
"""
  cif_str_2 = """\
data_2
_b 2
"""
  cm = cif.reader(input_string=cif_str_1).model()
  assert list(cm.keys()) == ['1']
  cif.reader(input_string=cif_str_2, cif_object=cm).model()
  assert list(cm.keys()) == ['1', '2']
  try: cm = cif.reader(input_string=cif_invalid_loop).model()
  except CifParserError: pass
  else: raise Exception_expected
  try: cm = cif.reader(input_string=cif_invalid_loop_2).model()
  except CifParserError: pass
  else: raise Exception_expected

  sys.stdout = stdout

  arrays = miller.array.from_cif(file_object=StringIO(
    cif_miller_array_template %(
      '_refln_F_calc', '_refln_F_meas', '_refln_F_sigma')),
                                 data_block_name='global')
  assert sorted(arrays.keys()) == ['_refln_F_calc', '_refln_F_meas']
  assert arrays['_refln_F_calc'].sigmas() is None
  assert isinstance(arrays['_refln_F_meas'].sigmas(), flex.double)
  arrays = miller.array.from_cif(file_object=StringIO(
    cif_miller_array_template %(
      '_refln_A_calc', '_refln_B_calc', '_refln_F_meas')),
                                 data_block_name='global')
  assert sorted(arrays.keys()) == ['_refln_A_calc', '_refln_F_meas']
  assert arrays['_refln_A_calc'].is_complex_array()
  arrays = miller.array.from_cif(file_object=StringIO(
    cif_miller_array_template %(
      '_refln_A_meas', '_refln_B_meas', '_refln_F_meas')),
                                 data_block_name='global')
  assert sorted(arrays.keys()) == ['_refln_A_meas', '_refln_F_meas']
  assert arrays['_refln_A_meas'].is_complex_array()
  arrays = miller.array.from_cif(file_object=StringIO(
    cif_miller_array_template %(
      '_refln_intensity_calc', '_refln_intensity_meas',
      '_refln_intensity_sigma')),
                                 data_block_name='global')
  assert sorted(arrays.keys()) == [
    '_refln_intensity_calc', '_refln_intensity_meas']
  arrays = miller.array.from_cif(file_object=StringIO(
    cif_miller_array_template %(
      '_refln_F_calc', '_refln_phase_calc', '_refln_F_sigma')),
                                 data_block_name='global')
  assert arrays['_refln_F_calc'].is_complex_array()

  for data_block_name in (None, "global"):
    miller_arrays = cif.reader(file_object=StringIO(
      cif_miller_array_template %(
        '_refln_F_calc',
        '_refln_F_meas',
        '_refln_F_sigma'))).as_miller_arrays(data_block_name=data_block_name)
    assert " ".join(sorted([str(ma.info()) for ma in miller_arrays])) \
      == "cif:global,_refln_F_calc cif:global,_refln_F_meas,_refln_F_sigma"
  f = open_tmp_file(suffix="cif")
  f.write(cif_miller_array_template %(
        '_refln_F_calc',
        '_refln_F_meas',
        '_refln_F_sigma'))
  f.close()
  miller_arrays = any_reflection_file(file_name=f.name).as_miller_arrays()
  assert len(miller_arrays) == 2
  cs = crystal.symmetry(
    space_group_info=sgtbx.space_group_info("P1")
  )
  miller_arrays = any_reflection_file(file_name=f.name).as_miller_arrays(
    crystal_symmetry=cs, force_symmetry=True, anomalous=True)
  assert miller_arrays[0].anomalous_flag() is True
  assert miller_arrays[0].crystal_symmetry().space_group() == cs.space_group()

def exercise_parser(reader, builder):
  cif_model = reader(
    input_string=cif_xray_structure, builder=builder()).model()
  xs_builder = cif.builders.crystal_structure_builder(cif_model['global'])
  xs1 = xs_builder.structure
  # also test construction of cif model from xray structure
  xs_cif_block = xs1.as_cif_block()
  xs2 = cif.builders.crystal_structure_builder(xs_cif_block).structure
  sio = StringIO()
  xs1.as_cif_simple(out=sio)
  xs3 = reader(input_string=sio.getvalue()).build_crystal_structures(
    data_block_name='global')
  xs_iso = xs1.deep_copy_scatterers()
  xs_iso.convert_to_isotropic()
  xs4 = cif.builders.crystal_structure_builder(xs_iso.as_cif_block()).structure

  for xs in (xs1, xs2, xs3):
    sc = xs.scatterers()
    assert list(sc.extract_labels()) == ['o','c']
    assert list(sc.extract_scattering_types()) == ['O','C']
    assert approx_equal(sc.extract_occupancies(), (0.8, 1))
    assert approx_equal(sc.extract_sites(), ((0.5,0,0),(0,0,0)))
    assert approx_equal(sc.extract_u_star(),
      [(-1, -1, -1, -1, -1, -1), (1e-3, 5e-4, (1e-3)/3, 0, 0, 0)])
    assert approx_equal(sc.extract_u_iso(), (0.1, -1))
    assert approx_equal(xs.unit_cell().parameters(),
                        (10,20,30,90,90,90))
    assert str(xs.space_group_info()) == 'C 1 2/m 1'
  #
  cif_model = reader(
    input_string=cif_miller_array, builder=builder()).model()
  ma_builder = cif.builders.miller_array_builder(cif_model['global'])
  ma1 = ma_builder.arrays()['_refln_F_squared_meas']
  if isinstance(cif_model, cif.model.cif):
    assert (ma_builder.arrays()['_refln_observed_status'].data() ==
            flex.std_string(['o'] * ma1.size()))
  # also test construction of cif model from miller array
  ma2 = cif.builders.miller_array_builder(
    ma1.as_cif_block(array_type='meas')).arrays()['_refln.F_squared_meas']
  for ma in (ma1, ma2):
    sio = StringIO()
    ma.show_array(sio)
    assert not show_diff(sio.getvalue(), """\
(1, 0, 0) 748.71 13.87
(2, 0, 0) 1318.51 24.29
(3, 0, 0) 1333.51 33.75
(4, 0, 0) 196.58 10.85
(5, 0, 0) 3019.71 55.29
(6, 0, 0) 1134.38 23.94
(7, 0, 0) 124.01 15.16
(8, 0, 0) -1.22 10.49
(9, 0, 0) 189.09 20.3
(10, 0, 0) 564.68 35.61
(-10, 1, 0) 170.23 22.26
""")
  sio = StringIO()
  ma1.show_summary(sio)
  # Miller array info: cif:_refln.F_squared_meas,_refln.F_squared_sigma
  assert not show_diff(sio.getvalue(), """\
Miller array info: cif:_refln_F_squared_meas,_refln_F_squared_sigma
Observation type: xray.intensity
Type of data: double, size=11
Type of sigmas: double, size=11
Number of Miller indices: 11
Anomalous flag: False
Unit cell: (7.999, 9.372, 14.736, 82.625, 81.527, 81.726)
Space group: P -1 (No. 2)
""")
  sio = StringIO()
  ma2.show_summary(sio)
  # Miller array info: cif:_refln.F_squared_meas,_refln.F_squared_sigma
  assert not show_diff(sio.getvalue(), """\
Miller array info: cif:_refln.F_squared_meas,_refln.F_squared_sigma
Observation type: xray.intensity
Type of data: double, size=11
Type of sigmas: double, size=11
Number of Miller indices: 11
Anomalous flag: False
Unit cell: (7.999, 9.372, 14.736, 82.625, 81.527, 81.726)
Space group: P -1 (No. 2)
""")

cif_xray_structure = """\
data_global
loop_
    _symmetry_equiv_pos_as_xyz
    'x, y, z'
    '-x, y, -z'
    '-x, -y, -z'
    'x, -y, z'
    'x+1/2, y+1/2, z'
    '-x+1/2, y+1/2, -z'
    '-x+1/2, -y+1/2, -z'
    'x+1/2, -y+1/2, z'
_cell_length_a 10
_cell_length_b 20
_cell_length_c 30
_cell_angle_alpha 90
_cell_angle_beta 90
_cell_angle_gamma 90
loop_ # comment
    _atom_site_label # another comment
    _atom_site_fract_x
    _atom_site_fract_y
    _atom_site_fract_z
    _atom_site_U_iso_or_equiv
    _atom_site_occupancy
    _atom_site_type_symbol
    'o' 0.5 0 0 0.1 0.8 'O'
    'c' 0 0 0 0.2 1 'C'
loop_
    _atom_site_aniso_label
    _atom_site_aniso_U_11
    _atom_site_aniso_U_22
    _atom_site_aniso_U_33
    _atom_site_aniso_U_12
    _atom_site_aniso_U_13
    _atom_site_aniso_U_23
    'c' 0.1 0.2 0.3 0 0 0
"""

cif_miller_array = """\
data_global
loop_
 _symmetry_equiv_pos_as_xyz
 'x, y, z'
 '-x, -y, -z'

_cell_length_a      7.999
_cell_length_b      9.372
_cell_length_c     14.736
_cell_angle_alpha  82.625
_cell_angle_beta   81.527
_cell_angle_gamma  81.726

loop_
 _refln_index_h
 _refln_index_k
 _refln_index_l
 _refln_F_squared_calc
 _refln_F_squared_meas
 _refln_F_squared_sigma
 _refln_observed_status
   1   0   0      756.07      748.71     13.87 o
   2   0   0     1266.94     1318.51     24.29 o
   3   0   0     1381.53     1333.51     33.75 o
   4   0   0      194.77      196.58     10.85 o
   5   0   0     3102.74     3019.71     55.29 o
   6   0   0     1145.05     1134.38     23.94 o
   7   0   0      103.98      124.01     15.16 o
   8   0   0       16.94       -1.22     10.49 o
   9   0   0      194.74      189.09     20.30 o
  10   0   0      581.30      564.68     35.61 o
 -10   1   0      148.83      170.23     22.26 o
"""


cif_miller_array_template = """\
data_global

loop_
 _symmetry_equiv_pos_as_xyz
 'x, y, z'
 '-x, -y, -z'

_cell_length_a     7.9999
_cell_length_b     9.3718
_cell_length_c    14.7362
_cell_angle_alpha  82.625
_cell_angle_beta   81.527
_cell_angle_gamma  81.726

loop_
 _refln_index_h
 _refln_index_k
 _refln_index_l
 %s
 %s
 %s
   1 0 0 1.2 1.3 0.1
   2 0 0 2.3 2.4 0.2
   3 0 0 3.4 3.5 0.3
   4 0 0 4.5 6.7 0.4

# comment with WS before and after

"""

cif_cod = """\
data_global
_a 1
_[b] 2
_c e43
_d # comment
   # another comment
'1 2'
_e )
"""

cif_quoted_string = """\
data_global
# both of these are legal apparently
_a "a"b"
_b 'a dog's life'
"""

cif_invalid_loop = """\
data_global
loop_
  _a
  _b
_c 1
"""

cif_invalid_loop_2 = """\
data_1
loop_
_a _b _c
1 2 3 4 5
"""

cif_invalid_missing_value = """\
data_global
_a 1
_b
_c 3
"""

cif_invalid_string = """\
data_global
_a 'no closing quote
_b 1
"""

cif_invalid_semicolon_text_field = """\
data_1
_a ;
1
;
"""

cif_valid_semicolon_text_field = """\
data_1
_a
;
1
;
"""

cif_unquoted_string_semicolon = """\
data_1
_a ;1
_b ;
_c 2
"""

cif_global = """\
global_
_a 1
_b 2

data_1
_c 3
_d 4
"""

def exercise_atom_type_loop():
  from cctbx import xray
  cif_model = cif.reader(input_string=cif_xray_structure).model()
  xs = cif.builders.crystal_structure_builder(cif_model['global']).structure
  xs.set_inelastic_form_factors(photon=0.71073, table="henke")
  loop = cif.atom_type_cif_loop(xray_structure=xs, format="mmcif")
  s = StringIO()
  print(loop, file=s)
  assert not show_diff(
    "\n".join([li.rstrip() for li in s.getvalue().splitlines()]), """\
loop_
  _atom_type.symbol
  _atom_type.scat_dispersion_real
  _atom_type.scat_dispersion_imag
  _atom_type.scat_Cromer_Mann_a1
  _atom_type.scat_Cromer_Mann_a2
  _atom_type.scat_Cromer_Mann_a3
  _atom_type.scat_Cromer_Mann_a4
  _atom_type.scat_Cromer_Mann_a5
  _atom_type.scat_Cromer_Mann_a6
  _atom_type.scat_Cromer_Mann_b1
  _atom_type.scat_Cromer_Mann_b2
  _atom_type.scat_Cromer_Mann_b3
  _atom_type.scat_Cromer_Mann_b4
  _atom_type.scat_Cromer_Mann_b5
  _atom_type.scat_Cromer_Mann_b6
  _atom_type.scat_Cromer_Mann_c
  _atom_type.scat_source
  _atom_type.scat_dispersion_source
  C  0.00347  0.00161  2.18189  1.77612  1.08772  0.64146  0.20789  0.10522  13.45337  32.57901  0.74729  0.25125  80.97993  0.05873  0.0
;
6-Gaussian fit: Grosse-Kunstleve RW, Sauter NK, Adams PD:
Newsletter of the IUCr Commission on Crystallographic Computing 2004, 3, 22-31.
;
  'Henke, Gullikson and Davis, At. Data and Nucl. Data Tables, 1993, 54, 2'
  O  0.01158  0.00611  2.91262  2.58808  0.98057  0.69663  0.68508  0.13677  14.48462   6.03818  0.42255  0.15446  35.53892  0.03841  0.0
;
6-Gaussian fit: Grosse-Kunstleve RW, Sauter NK, Adams PD:
Newsletter of the IUCr Commission on Crystallographic Computing 2004, 3, 22-31.
;
  'Henke, Gullikson and Davis, At. Data and Nucl. Data Tables, 1993, 54, 2'
""")

def exercise_partial_crystal_symmetry():
  def get_inp(u, s):
    result = ["data_test"]
    if (u):
      result.append("_cell_length_a 12.605(3)")
    if (s):
      result.append("_symmetry_space_group_name_Hall  '-P 2yn'")
    return "\n".join(result)
  def get_cs(input_string):
    cif_model = cif.reader(input_string=input_string).model()
    return cif.builders.crystal_symmetry_builder(
      cif_block=cif_model["test"]).crystal_symmetry
  cs = get_cs(get_inp(False, False))
  assert cs.unit_cell() is None
  assert cs.space_group_info() is None
  cs = get_cs(get_inp(False, True))
  assert cs.unit_cell() is None
  assert str(cs.space_group_info()) == "P 1 21/n 1"
  try:
    get_cs(get_inp(True, False))
  except CifBuilderError as e:
    assert str(e) == "Not all unit cell parameters are given in the cif file"
  else: raise Exception_expected

def exercise_crystal_symmetry():
  cm = cif.reader(input_string=p1_sym_ops).model()
  cs_builder = cif.builders.crystal_symmetry_builder(cm["r1e5xsf"])
  assert cs_builder.crystal_symmetry.space_group_info().symbol_and_number() \
         == 'P 1 (No. 1)'
  file_object = open_tmp_file(suffix=".cif")
  file_object.write(p1_sym_ops)
  file_object.close()
  cs = crystal_symmetry_from_any.extract_from(file_name=file_object.name)
  assert cs.space_group_info().symbol_and_number() == 'P 1 (No. 1)'


def exercise_mmcif_structure_factors():
  miller_arrays = cif.reader(input_string=r3adrsf).as_miller_arrays()
  assert len(miller_arrays) == 16
  hl_coeffs = find_miller_array_from_labels(
    miller_arrays, [
      '_refln.pdbx_HL_A_iso', '_refln.pdbx_HL_B_iso',
      '_refln.pdbx_HL_C_iso', '_refln.pdbx_HL_D_iso',
      'scale_group_code=1', 'crystal_id=2', 'wavelength_id=3'
      ])
  assert hl_coeffs.is_hendrickson_lattman_array()
  assert hl_coeffs.size() == 2
  mas_as_cif_block = cif.miller_arrays_as_cif_block(
    hl_coeffs, column_names=('_refln.pdbx_HL_A_iso', '_refln.pdbx_HL_B_iso',
                             '_refln.pdbx_HL_C_iso', '_refln.pdbx_HL_D_iso'))
  abcd = []
  for key in ('_refln.pdbx_HL_A_iso', '_refln.pdbx_HL_B_iso',
              '_refln.pdbx_HL_C_iso', '_refln.pdbx_HL_D_iso'):
    assert key in list(mas_as_cif_block.cif_block.keys())
    abcd.append(flex.double(mas_as_cif_block.cif_block[key]))
  hl_coeffs_from_cif_block = flex.hendrickson_lattman(*abcd)
  assert approx_equal(hl_coeffs.data(), hl_coeffs_from_cif_block)
  f_meas_au = find_miller_array_from_labels(
    miller_arrays, [
      '_refln.F_meas_au', '_refln.F_meas_sigma_au',
      'scale_group_code=1', 'crystal_id=1', 'wavelength_id=1'])
  assert f_meas_au.is_xray_amplitude_array()
  assert f_meas_au.size() == 5
  assert f_meas_au.sigmas() is not None
  assert f_meas_au.space_group_info().symbol_and_number() == 'C 1 2 1 (No. 5)'
  assert approx_equal(f_meas_au.unit_cell().parameters(),
                      (163.97, 45.23, 110.89, 90.0, 131.64, 90.0))
  pdbx_I_plus_minus = find_miller_array_from_labels(
    miller_arrays, ['_refln.pdbx_I_plus', '_refln.pdbx_I_plus_sigma',
       '_refln.pdbx_I_minus', '_refln.pdbx_I_minus_sigma'])
  assert pdbx_I_plus_minus.is_xray_intensity_array()
  assert pdbx_I_plus_minus.anomalous_flag()
  assert pdbx_I_plus_minus.size() == 21
  assert pdbx_I_plus_minus.unit_cell() is None     # no symmetry information in
  assert pdbx_I_plus_minus.space_group() is None   # this CIF block
  #
  miller_arrays = cif.reader(input_string=r3ad7sf).as_miller_arrays()
  assert len(miller_arrays) == 11
  f_calc = find_miller_array_from_labels(
    miller_arrays, ['r3ad7sf', '_refln.F_calc', '_refln.phase_calc', 'crystal_id=2']) #, 'wavelength_id=1']))
  assert f_calc.is_complex_array()
  assert f_calc.size() == 4
  #
  miller_arrays = cif.reader(input_string=integer_observations).as_miller_arrays()
  assert len(miller_arrays) == 2
  fmeas_sigmeas = find_miller_array_from_labels( miller_arrays, [ '_refln.F_meas_au'])
  assert isinstance(fmeas_sigmeas.data(), flex.double)
  assert isinstance(fmeas_sigmeas.sigmas(), flex.double)
  #
  miller_arrays = cif.reader(input_string=r3v56sf).as_miller_arrays()
  assert len(miller_arrays) == 2
  for ma in miller_arrays: assert ma.is_complex_array()
  find_miller_array_from_labels(miller_arrays, ['r3v56sf', '_refln.pdbx_DELFWT', '_refln.pdbx_DELPHWT'])
  find_miller_array_from_labels(miller_arrays, ['r3v56sf', '_refln.pdbx_FWT', '_refln.pdbx_PHWT'])
  # verify _refln.pdbx_FWT', '_refln.pdbx_PHWT' are parsed as complex arrays in the presence of other columns
  miller_arrays = cif.reader(input_string= r6cxosf).as_miller_arrays()
  assert len(miller_arrays) == 11
  ma = find_miller_array_from_labels(miller_arrays, ['r6cxosf', '_refln.pdbx_FWT', '_refln.pdbx_PHWT'])
  assert ma.is_complex_array()
  ma = find_miller_array_from_labels(miller_arrays, ['r6cxosf', '_refln.pdbx_DELFWT', '_refln.pdbx_DELPHWT'])
  assert ma.is_complex_array()
  # accept unconventional cif column labels resembling mtz column labels
  miller_arrays = cif.reader(input_string= r6c5f_phases).as_miller_arrays()
  assert len(miller_arrays) == 8
  ma = find_miller_array_from_labels(miller_arrays, ['6c5f_phases', '_refln.FP', '_refln.SIGFP'])
  assert ma.is_xray_amplitude_array()
  ma = find_miller_array_from_labels(miller_arrays, ['6c5f_phases', '_refln.FC', '_refln.PHIC'])
  assert ma.is_complex_array()
  ma = find_miller_array_from_labels(miller_arrays, ['6c5f_phases', '_refln.FC_ALL', '_refln.PHIC_ALL'])
  assert ma.is_complex_array()
  ma = find_miller_array_from_labels(miller_arrays, ['6c5f_phases', '_refln.DELFWT', '_refln.PHDELWT'])
  assert ma.is_complex_array()


def find_miller_array_from_labels(miller_arrays, labels):
  for ma in miller_arrays:
    found = True
    for label in labels:
      if label not in ma.info().labels:
        found = False
        break
    if found:
      return ma
  raise RuntimeError("Could not find miller array with labels %s" %labels)

r3adrsf = """
data_r3adrsf
_cell.length_a  163.970
_cell.length_b  45.230
_cell.length_c  110.890
_cell.angle_alpha  90.000
_cell.angle_beta  131.640
_cell.angle_gamma  90.000

#
_symmetry.entry_id    3adr
_symmetry.space_group_name_H-M 'C 1 2 1'

loop_
_refln.crystal_id
_refln.wavelength_id
_refln.scale_group_code
_refln.status
_refln.index_h
_refln.index_k
_refln.index_l
_refln.F_meas_au
_refln.F_meas_sigma_au
_refln.pdbx_HL_A_iso
_refln.pdbx_HL_B_iso
_refln.pdbx_HL_C_iso
_refln.pdbx_HL_D_iso
1 1 1 o    0    2    2   484.70  11.74  -3.168  -3.662   3.247   3.261
1 1 1 o    0    2    3   337.40   4.60   2.287  -3.629   0.053  -0.597
1 1 1 o    0    2    4   735.40   8.43   0.476  -8.605  -4.861   0.921
1 1 1 o    0    2    5   433.70   4.76   2.453  -1.663   0.000  -9.540
1 1 1 o    0    2    6   435.20   4.96  -9.081   3.661   1.511  -2.736
2 3 1 o    0    2    7   427.50   4.56   8.677  -0.013   2.307  -4.220
2 3 1 o    0    2    8   661.00   7.26  -6.468   5.112  -5.411  -6.731
2 3 4 o    0    2    9   211.90   2.64  -2.279   0.914   0.455  -6.038
2 3 4 f    0    2   10   466.80   5.01  -0.005   6.330  -1.916  -0.598
2 3 4 o    0    2   11   424.20   4.66  -0.938   7.011  -1.603   1.724
#END
data_r3adrAsf
#
#
#
loop_
_refln.crystal_id
_refln.wavelength_id
_refln.scale_group_code
_refln.index_h
_refln.index_k
_refln.index_l
_refln.pdbx_I_plus
_refln.pdbx_I_plus_sigma
_refln.pdbx_I_minus
_refln.pdbx_I_minus_sigma
1 3 1   87    5  -46       40.2     40.4        6.7     63.9
1 3 1   87    5  -45       47.8     29.7       35.1     30.5
1 3 1   87    5  -44       18.1     33.2        0.5     34.6
1 3 1   87    5  -43        6.1     45.4       12.9     51.6
1 3 1   87    5  -42       -6.6     45.6      -15.5     55.8
1 3 1   87    7  -37        6.3     43.4          ?        ?
1 3 1   87    7  -36      -67.2     55.4          ?        ?
1 3 1   88    2  -44          0       -1       35.0     38.5
1 3 1   88    2  -43          0       -1       57.4     41.5
1 3 1   88    4  -45       -1.0     46.1       -9.1     45.6
1 3 1   88    4  -44      -19.8     49.2        0.3     34.7
1 3 1   88    6  -44       -1.8     34.8          ?        ?
#END OF REFLECTIONS
"""

r3ad7sf = """
data_r3ad7sf
_cell.length_a             198.9488
_cell.length_b             198.9488
_cell.length_c             196.7646
_cell.angle_alpha           90.0000
_cell.angle_beta            90.0000
_cell.angle_gamma          120.0000

loop_
_symmetry_equiv.id
_symmetry_equiv.pos_as_xyz
1 'X,  Y,  Z'
2 'X-Y,  X,  Z+5/6'
3 '-Y,  X-Y,  Z+2/3'
4 '-X,  -Y,  Z+1/2'
5 '-X+Y,  -X,  Z+1/3'
6 'Y,  -X+Y,  Z+1/6'
7 '-Y,  -X,  -Z+1/6'
8 'X-Y,  -Y,  -Z'
9 'X,  X-Y,  -Z+5/6'
10 'Y,  X,  -Z+2/3'
11 '-X+Y,  Y,  -Z+1/2'
12 '-X,  -X+Y,  -Z+1/3'

loop_
_refln.wavelength_id
_refln.crystal_id
_refln.scale_group_code
_refln.index_h
_refln.index_k
_refln.index_l
_refln.status
_refln.F_meas_au
_refln.F_meas_sigma_au
_refln.F_calc
_refln.phase_calc
_refln.fom
1 1 1       0    0    6 o     267.2   12.1    353.2   180.0  0.04
1 1 1       0    0   12 o    4700.0  113.0   3962.4   360.0  1.00
1 1 1       0    0   18 o   10214.0  222.9   8775.9   360.0  1.00
1 1 1       0    0   24 o    8268.9  192.9  11557.1   180.0  1.00
1 2 1       0    0   30 o    3274.6   77.5   2214.5     0.0  1.00
1 2 1       0    0   36 o     317.8   30.4   1993.3     0.0  0.05
1 2 1       0    0   42 o   12026.4  286.2   6514.5   180.0  1.00
1 2 1       0    0   48 o    1972.6   51.4   1357.9   180.0  0.91
"""

r3v56sf = """
data_r3v56sf

_cell.length_a  121.6330
_cell.length_b  121.6330
_cell.length_c  157.2140
_cell.angle_alpha  90.0000
_cell.angle_beta  90.0000
_cell.angle_gamma  120.0000

loop_
_symmetry_equiv.id
_symmetry_equiv.pos_as_xyz
1  'X,  Y,  Z'
2  'X-Y,  X,  Z+5/6'
3  '-Y,  X-Y,  Z+2/3'
4  '-X,  -Y,  Z+1/2'
5  '-X+Y,  -X,  Z+1/3'
6  'Y,  -X+Y,  Z+1/6'

loop_
_refln.index_h
_refln.index_k
_refln.index_l
_refln.pdbx_FWT
_refln.pdbx_PHWT
_refln.pdbx_DELFWT
_refln.pdbx_DELPHWT
0    0    6 1793.541 297.538 758.340 297.538
0    0   12 926.361   8.616  79.780   8.616
0    0   18 2789.494   3.915 158.391 183.915
0    0   24  18.715 196.581 133.229 196.581
0    0   30 1040.906 174.397 370.046 174.397
0    0   36 2065.720 180.659 163.982   0.659
0    0   42 1850.858 199.047 1496.942 199.047
0    0   48 882.296 190.106 289.614  10.106
0    1    6 161.907 235.025 332.891 235.025
0    1    7 168.822  39.648 511.322  39.648
0    1    8  42.963  55.666 347.014  55.666
0    1    9  81.428  68.620  89.690 248.620
"""

r6cxosf ="""
data_r6cxosf
#
_audit.revision_id     1_0
_audit.creation_date   2018-09-05
_audit.update_record   "Initial release"
#
_cell.entry_id      6cxo
_cell.length_a      52.588
_cell.length_b      149.213
_cell.length_c      165.827
_cell.angle_alpha   90.000
_cell.angle_beta    90.000
_cell.angle_gamma   90.000
#
_diffrn_radiation_wavelength.id           1
_diffrn_radiation_wavelength.wavelength   1.2036
#
_entry.id   6cxo
#
_exptl_crystal.id   1
#
_reflns_scale.group_code   1
#
_symmetry.entry_id               6cxo
_symmetry.space_group_name_H-M   "P 21 2 21"
_symmetry.Int_Tables_number      2018
#
loop_
_refln.crystal_id
_refln.wavelength_id
_refln.scale_group_code
_refln.index_h
_refln.index_k
_refln.index_l
_refln.status
_refln.pdbx_r_free_flag
_refln.F_meas_au
_refln.F_meas_sigma_au
_refln.F_calc_au
_refln.phase_calc
_refln.pdbx_HL_A_iso
_refln.pdbx_HL_B_iso
_refln.pdbx_HL_C_iso
_refln.pdbx_HL_D_iso
_refln.pdbx_FWT
_refln.pdbx_PHWT
_refln.pdbx_DELFWT
_refln.pdbx_DELPHWT
_refln.fom
1 1 1 0  0  6  o 10 2637.91 60.30 80.15   180.00 -0.30   0.00    0.00 0.00 975.82  180.00 895.68  180.00 0.29
1 1 1 0  0  8  o 12 976.72  17.78 1455.08 180.00 -3.75   0.00    0.00 0.00 120.17  0.00   1575.25 0.00   1.00
1 1 1 0  0  10 o 17 473.14  11.64 474.88  0.00   0.84    0.00    0.00 0.00 33.10   180.00 507.98  180.00 0.69
1 1 1 0  0  18 f 0  2590.99 42.02 1898.47 180.00 -32.04  0.00    0.00 0.00 1546.52 180.00 351.95  0.00   1.00
1 1 1 0  1  4  o 16 1300.19 15.72 28.41   180.00 -0.06   0.00    0.00 0.00 71.53   180.00 43.12   180.00 0.06
1 1 1 0  1  5  o 11 106.11  7.63  367.11  90.00  0.00    0.04    0.00 0.00 361.40  270.00 728.52  270.00 0.04
1 1 1 0  1  6  o 14 946.07  10.00 504.84  180.00 -1.32   0.00    0.00 0.00 620.26  180.00 115.42  180.00 0.87
1 1 1 0  1  12 o 4  640.34  9.55  59.40   0.00   0.30    0.00    0.00 0.00 191.03  0.00   131.62  0.00   0.29
1 1 1 0  1  13 o 4  56.14   9.21  53.87   90.00  0.00    0.02    0.00 0.00 52.30   270.00 106.18  270.00 0.02
"""

r6c5f_phases ="""
data_6c5f_phases
#
loop_
  _space_group_symop.id
  _space_group_symop.operation_xyz
  1  x,y,z
  2  -y,x-y,z
  3  -x+y,-x,z

_space_group.crystal_system       trigonal
_space_group.IT_number            143
_space_group.name_H-M_alt         'P 3'
_space_group.name_Hall            ' P 3'
_symmetry.space_group_name_H-M    'P 3'
_symmetry.space_group_name_Hall   ' P 3'
_symmetry.Int_Tables_number       143
_cell.length_a                    83.936
_cell.length_b                    83.936
_cell.length_c                    40.479
_cell.angle_alpha                 90.000
_cell.angle_beta                  90.000
_cell.angle_gamma                 120.000
_cell.volume                      246977.230
loop_
  _refln.index_h
  _refln.index_k
  _refln.index_l
  _refln.FREE
  _refln.FP
  _refln.SIGFP
  _refln.FC
  _refln.PHIC
  _refln.FC_ALL
  _refln.PHIC_ALL
  _refln.FWT
  _refln.PHWT
  _refln.DELFWT
  _refln.PHDELWT
  _refln.FOM
  _refln.FC_ALL_LS
  _refln.PHIC_ALL_LS
   0   0    2  1  676.187   6.17276   2809.82        -154.6    452.62      -175.696     839.275      -175.696      386.655      -175.696   0.955279   390.291      176.785
   0   0    3  1  563.624   5.12057   1839.65       75.6562   786.515       93.5793     309.766       93.5793      476.749      -86.4207   0.972529   862.338      93.9542
   0   0    4  1  344.711   2.51519   677.686      -13.7128   617.668      -3.12039     36.3321      -3.12039      581.336        176.88   0.948621   693.021     -3.41476
   0   0    5  1  669.529   4.32892   1158.44      -95.7759   701.642      -69.0476     610.651      -69.0476      90.9919       110.952   0.980012   815.552      -71.438
   0   0    6  1  208.118   1.47303   348.769       38.3981   150.027      -1.98773     138.218      -1.98773      11.8089       178.012   0.692503   184.095      5.08278
   0   0    7  1  834.241   7.56552   361.555       58.3196   639.886       67.9106     1003.72       67.9106      363.837       67.9106   0.985092   655.782      66.9071
   0   0    8  1  268.459   2.64541   328.863      -136.983   259.118      -124.253      211.27      -124.253      47.8489       55.7467   0.876088   296.701     -128.016
   0   0    9  1  265.482   2.68548    552.45      -169.384   359.081       -166.58     138.292       -166.58      220.789         13.42   0.936738    437.08     -167.718
   0   0   10  1  183.754   1.99406   195.673       33.4295   219.826        58.527     87.9439        58.527      131.882      -121.473   0.837452   210.823      50.7412

"""



integer_observations = """
data_r3ad7sf
_cell.length_a             198.9488
_cell.length_b             198.9488
_cell.length_c             196.7646
_cell.angle_alpha           90.0000
_cell.angle_beta            90.0000
_cell.angle_gamma          120.0000

loop_
_symmetry_equiv.id
_symmetry_equiv.pos_as_xyz
1 'X,  Y,  Z'
2 'X-Y,  X,  Z+5/6'
3 '-Y,  X-Y,  Z+2/3'
4 '-X,  -Y,  Z+1/2'
5 '-X+Y,  -X,  Z+1/3'
6 'Y,  -X+Y,  Z+1/6'
7 '-Y,  -X,  -Z+1/6'
8 'X-Y,  -Y,  -Z'
9 'X,  X-Y,  -Z+5/6'
10 'Y,  X,  -Z+2/3'
11 '-X+Y,  Y,  -Z+1/2'
12 '-X,  -X+Y,  -Z+1/3'

loop_
_refln.index_h
_refln.index_k
_refln.index_l
_refln.status
_refln.F_meas_au
_refln.F_meas_sigma_au
0    0    6 o     267   12
0    0   12 o    4700  113
0    0   18 o   10214  222
0    0   24 o    8268  192
0    0   30 o    3274   77
0    0   36 o     317   30
0    0   42 o   12026  286
0    0   48 o    1972   51
"""

p1_sym_ops = """\
data_r1e5xsf
_cell.entry_id          1E5X
_cell.length_a          57.760
_cell.length_b          62.140
_cell.length_c          76.590
_cell.angle_alpha       109.48
_cell.angle_beta        97.61
_cell.angle_gamma       112.74
_cell.formula_units_Z   2

_symmetry_equiv.id           1
_symmetry_equiv.pos_as_xyz   X,Y,Z
"""

def exercise_detect_binary():
  binary_string = '\xff\xf8\x00\x00\x00\x00\x00\x00'
  from iotbx.cif import reader
  try: reader(input_string=binary_string)
  except CifParserError as e: pass
  else: raise Exception_expected

def exercise_syntax_errors():
  empty_loop_str = """\
data_fred
loop_
loop_
_a
_b
1 2
3 4
"""
  try: cif.reader(input_string=empty_loop_str)
  except CifParserError as e: pass
  else: raise Exception_expected
  bad_semicolon_text_field = """\
data_sucrose
_a 1
_exptl_absorpt_process_details
;
Final HKLF 4 output contains 64446 reflections, Rint = 0.0650
 (47528 with I > 3sig(I), Rint = 0.0624);
"""
  try: cif.reader(input_string=bad_semicolon_text_field)
  except CifParserError as e: pass
  else: raise Exception_expected

def exercise_missing_atom_site_type_symbol():
  m = cif.reader(input_string=cif_with_atom_site_type_symbol).model()
  xs = cif.builders.crystal_structure_builder(m['9000000']).structure
  sc = xs.scatterers()
  assert len(sc) == 18
  assert sc[0].label == 'Fe1'
  assert sc[0].scattering_type == 'Fe'
  assert sc[-1].label == 'O7'
  assert sc[-1].scattering_type == 'O'

cif_with_atom_site_type_symbol = """\
#------------------------------------------------------------------------------
#$Date$
#$Revision$
#$URL: svn://www.crystallography.net/cod/cif/9/00/00/9000000.cif $
#------------------------------------------------------------------------------
#
# This file is available in the Crystallography Open Database (COD),
# http://www.crystallography.net/. The original data for this entry
# were provided the American Mineralogist Crystal Structure Database,
# http://rruff.geo.arizona.edu/AMS/amcsd.php
#
# The file may be used within the scientific community so long as
# proper attribution is given to the journal article from which the
# data were obtained.
#
data_9000000
loop_
_publ_author_name
'Finger, L. W.'
_publ_section_title
;
 The crystal structure and cation distribution of a grunerite
 Locality: Wabush iron formation, Labrador, Canada
;
_journal_name_full
'Mineralogical Society of America Special Paper'
_journal_page_first              95
_journal_page_last               100
_journal_volume                  2
_journal_year                    1969
_chemical_formula_sum            'F0.5 Fe6.1 H1.5 Mg0.9 O23.5 Si8'
_chemical_name_mineral           Grunerite
_space_group_IT_number           12
_symmetry_space_group_name_Hall  '-C 2y'
_symmetry_space_group_name_H-M   'C 1 2/m 1'
_cell_angle_alpha                90
_cell_angle_beta                 101.892
_cell_angle_gamma                90
_cell_length_a                   9.5642
_cell_length_b                   18.393
_cell_length_c                   5.3388
_cell_volume                     919.015
_exptl_crystal_density_diffrn    3.521
_[local]_cod_chemical_formula_sum_orig '(Fe6.1 Mg.9) Si8 O23.5 (F.5 H1.5)'
_cod_database_code               9000000
loop_
_symmetry_equiv_pos_as_xyz
x,y,z
1/2+x,1/2+y,z
x,-y,z
1/2+x,1/2-y,z
-x,y,-z
1/2-x,1/2+y,-z
-x,-y,-z
1/2-x,1/2-y,-z
loop_
_atom_site_aniso_label
_atom_site_aniso_U_11
_atom_site_aniso_U_22
_atom_site_aniso_U_33
_atom_site_aniso_U_12
_atom_site_aniso_U_13
_atom_site_aniso_U_23
Fe1 0.00532 0.00943 0.00498 0.00000 0.00198 0.00000
Mg1 0.00532 0.00943 0.00498 0.00000 0.00198 0.00000
Fe2 0.00532 0.00823 0.00622 0.00000 0.00198 0.00000
Mg2 0.00532 0.00823 0.00622 0.00000 0.00198 0.00000
Fe3 0.00621 0.00857 0.00622 0.00000 0.00074 0.00000
Mg3 0.00621 0.00857 0.00622 0.00000 0.00074 0.00000
Fe4 0.00843 0.01645 0.01106 0.00000 0.00421 0.00000
Mg4 0.00843 0.01645 0.01106 0.00000 0.00421 0.00000
Si1 0.00399 0.00703 0.00553 -0.00026 0.00050 0.00000
Si2 0.00444 0.00651 0.00747 -0.00166 0.00074 0.00000
O1 0.00577 0.01028 0.00899 0.00000 0.00173 0.00146
O2 0.00399 0.01028 0.00940 -0.00087 0.00272 -0.00146
OH3 0.01864 0.01200 0.01272 0.00000 0.00570 0.00000
F3 0.01864 0.01200 0.01272 0.00000 0.00570 0.00000
O4 0.00887 0.00686 0.00567 -0.00087 -0.00050 0.00097
O5 0.00355 0.01371 0.01244 -0.00262 0.00223 0.00730
O6 0.00399 0.02057 0.00760 0.00349 -0.00025 -0.00438
O7 0.00843 0.00000 0.02019 0.00000 0.00520 0.00000
loop_
_atom_site_label
_atom_site_fract_x
_atom_site_fract_y
_atom_site_fract_z
_atom_site_occupancy
_atom_site_U_iso_or_equiv
Fe1 0.00000 0.08781 0.50000 0.84800 0.00646
Mg1 0.00000 0.08781 0.50000 0.15200 0.00646
Fe2 0.00000 0.17936 0.00000 0.77300 0.00646
Mg2 0.00000 0.17936 0.00000 0.22700 0.00646
Fe3 0.00000 0.00000 0.00000 0.88800 0.00709
Mg3 0.00000 0.00000 0.00000 0.11200 0.00709
Fe4 0.00000 0.25741 0.50000 0.98500 0.01165
Mg4 0.00000 0.25741 0.50000 0.01500 0.01165
Si1 0.28670 0.08360 0.27070 1.00000 0.00557
Si2 0.29930 0.16670 0.77800 1.00000 0.00621
O1 0.11200 0.08820 0.20440 1.00000 0.00849
O2 0.12530 0.17350 0.71420 1.00000 0.00747
O-H3 0.11470 0.00000 0.70350 0.75000 0.01381
F3 0.11470 0.00000 0.70350 0.25000 0.01381
O4 0.38390 0.24160 0.76890 1.00000 0.00735
O5 0.34830 0.12750 0.05190 1.00000 0.00975
O6 0.34780 0.11820 0.55300 1.00000 0.01089
O7 0.33760 0.00000 0.27000 1.00000 0.00937
"""

def exercise_build_with_wavelength():
  m = cif.reader(input_string=cif_xray_structure_with_wavelength).model()
  xs = cif.builders.crystal_structure_builder(m['global']).structure
  assert approx_equal(xs.wavelength, 1.54184)
  cif_xray_structure_missing_wavelength = \
      cif_xray_structure_with_wavelength.replace('1.54184', '?')
  m = cif.reader(input_string=cif_xray_structure_missing_wavelength).model()
  xs = cif.builders.crystal_structure_builder(m['global']).structure
  assert xs.wavelength == None

cif_xray_structure_with_wavelength = """\
data_global
loop_
    _symmetry_equiv_pos_as_xyz
    'x, y, z'
    '-x, y, -z'
    '-x, -y, -z'
    'x, -y, z'
    'x+1/2, y+1/2, z'
    '-x+1/2, y+1/2, -z'
    '-x+1/2, -y+1/2, -z'
    'x+1/2, -y+1/2, z'
_cell_length_a 10
_cell_length_b 20
_cell_length_c 30
_cell_angle_alpha 90
_cell_angle_beta 90
_cell_angle_gamma 90
_diffrn_radiation_wavelength 1.54184
loop_ # comment
    _atom_site_label # another comment
    _atom_site_fract_x
    _atom_site_fract_y
    _atom_site_fract_z
    _atom_site_U_iso_or_equiv
    _atom_site_occupancy
    _atom_site_type_symbol
    'o' 0.5 0 0 0.1 0.8 'O'
    'c' 0 0 0 0.2 1 'C'
loop_
    _atom_site_aniso_label
    _atom_site_aniso_U_11
    _atom_site_aniso_U_22
    _atom_site_aniso_U_33
    _atom_site_aniso_U_12
    _atom_site_aniso_U_13
    _atom_site_aniso_U_23
    'c' 0.1 0.2 0.3 0 0 0
"""

def exercise_inconsistent_symmetry():
  cif_str="""data_r6bbrsf
#
_audit.revision_id     1_0
_audit.creation_date   2018-02-28
_audit.update_record   "Initial release"
#
_cell.entry_id      6bbr
_cell.length_a      51.6000
_cell.length_b      86.1000
_cell.length_c      78.8000
_cell.angle_alpha   90.0000
_cell.angle_beta    94.0000
_cell.angle_gamma   90.0000
#
_diffrn.id                  1
_diffrn.crystal_id          1
_diffrn.ambient_temp        ?
_diffrn.crystal_treatment   ?
_diffrn.details             ?
#
_diffrn_radiation_wavelength.id           1
_diffrn_radiation_wavelength.wavelength   1.5418
#
_diffrn_reflns.diffrn_id         1
_diffrn_reflns.pdbx_d_res_high   2.002
_diffrn_reflns.pdbx_d_res_low    30.944
_diffrn_reflns.limit_h_max       25
_diffrn_reflns.limit_h_min       -25
_diffrn_reflns.limit_k_max       41
_diffrn_reflns.limit_k_min       0
_diffrn_reflns.limit_l_max       39
_diffrn_reflns.limit_l_min       0
_diffrn_reflns.number            22584
_diffrn_reflns.pdbx_number_obs   11172
#
_entry.id   6bbr
#
_exptl_crystal.id   1
#
_reflns_scale.group_code   1
#
_symmetry.entry_id               6bbr
_symmetry.space_group_name_H-M   "I 1 2 1"
_symmetry.Int_Tables_number      5
#
loop_
_symmetry_equiv.id
_symmetry_equiv.pos_as_xyz
1 "X,  Y,  Z"
2 "-X,  Y,  -Z"
3 "X+1/2,  Y+1/2,  Z"
4 "-X+1/2,  Y+1/2,  -Z"
#
loop_
_refln.crystal_id
_refln.wavelength_id
_refln.scale_group_code
_refln.index_h
_refln.index_k
_refln.index_l
_refln.status
_refln.intensity_meas
_refln.intensity_sigma
1 1 1 -25 0  1  - 34.600    8.600
1 1 1 -25 0  3  - 3.800     8.200
1 1 1 -25 0  5  - -4.600    7.700
1 1 1 -25 0  7  - 19.900    8.600
1 1 1 -25 0  9  - 6.200     8.200
1 1 1 -25 0  11 - 16.000    8.500
1 1 1 -25 1  2  o -2.297    6.180
1 1 1 -25 1  4  o 12.346    6.577
"""
  with open("exercise_inconsistent_symmetry-sf.cif", "w") as fo:
    fo.write(cif_str)
  expected = """Inconsistent symmetry information found:
-x+1/2,y+1/2,-z+1/2
-x,y,-z
x+1/2,y+1/2,z+1/2
x,y,z
 ---vs---
-x+1/2,y+1/2,-z
-x,y,-z
x+1/2,y+1/2,z
x,y,z
"""
  exception_happened = False
  try:
    miller_arrays = any_reflection_file(file_name =
      "exercise_inconsistent_symmetry-sf.cif").as_miller_arrays()
  except CifBuilderError as e:
    exception_happened=True
    assert str(e).splitlines() == expected.splitlines()
  assert exception_happened

def exercise():
  exercise_inconsistent_symmetry()
  exercise_missing_atom_site_type_symbol()
  exercise_syntax_errors()
  exercise_detect_binary()
  exercise_crystal_symmetry()
  exercise_miller_arrays_as_cif_block()
  exercise_lex_parse_build()
  exercise_partial_crystal_symmetry()
  exercise_mmcif_structure_factors()
  exercise_atom_type_loop()
  exercise_build_with_wavelength()

if __name__ == '__main__':
  exercise()
  print("OK")


 *******************************************************************************


 *******************************************************************************
iotbx/cif/tests/tst_model.py
from __future__ import absolute_import, division, print_function
from cctbx.array_family import flex
from libtbx.test_utils import Exception_expected, show_diff
from libtbx.utils import Sorry
from libtbx.containers import OrderedDict
from six.moves import cStringIO as StringIO
import copy

import iotbx.cif
from iotbx.cif import model

def exercise_cif_model():
  loop = model.loop()
  loop["_loop_a"] = flex.double((1,2,3))
  loop.add_columns({'_loop_c': [4,5,6],
                    '_loop_b': ['7','8','9']})
  loop.add_row((4,7,'0'))
  try: loop["_loop_invalid"] = (7,8)
  except AssertionError: pass
  else: raise Exception_expected
  assert len(loop) == 3 # the number of columns (keys)
  assert loop.size() == 4 # the number of rows (loop iterations)
  assert list(loop.keys()) == ['_loop_a', '_loop_c', '_loop_b']
  try: loop["no_leading_underscore"] = 3
  except Sorry: pass
  else: raise Exception_expected
  loop2 = model.loop(header=("_loop2_a", "_loop2_b"), data=(1,2,3,4,5,6))
  assert list(loop2.keys()) == ["_loop2_a", "_loop2_b"]
  assert list(loop2.values()) == [flex.std_string(['1', '3', '5']),
                            flex.std_string(['2', '4', '6'])]
  assert list(loop2.iterrows()) == [
    {'_loop2_a': '1', '_loop2_b': '2'},
    {'_loop2_a': '3', '_loop2_b': '4'},
    {'_loop2_a': '5', '_loop2_b': '6'}]
  loop3 = model.loop(
    data={
      "_loop3_a": flex.int((-1, 2, 3)),
      "_loop3_b": flex.double((1.1, 2.2, 3.3)),
      "_loop3_c": flex.size_t((1, 2, 3)),
    }
  )
  for k in "abc":
    assert isinstance(loop3["_loop3_%s" % k], flex.std_string)
  #
  block = model.block()
  block["_tag"] = 3
  block["_tag1"] = "'a string'"
  block["_another_tag"] = 3.142
  assert "_tag" in block
  assert "_tag1" in block
  assert "_another_tag" in block
  assert block["_tag"] == '3'
  assert block["_tag1"] == "'a string'"
  assert block["_another_tag"] == "3.142"
  assert list(block.keys()) == ['_tag', '_tag1', '_another_tag']
  assert list(block.values()) == ["3", "'a string'", "3.142"]
  try: block["no_leading_underscore"] = 3
  except Sorry: pass
  else: raise Exception_expected
  block.add_loop(loop)
  assert len(block) == 6
  assert list(block.items()) == [
    ('_tag', '3'), ('_tag1', "'a string'"), ('_another_tag', '3.142'),
    ('_loop_a', flex.std_string(['1', '2', '3', '4'])),
    ('_loop_c', flex.std_string(['4', '5', '6', '7'])),
    ('_loop_b', flex.std_string(['7', '8', '9', '0']))]
  block['_loop_c'] = [11, 12, 13, 14]
  assert '_loop_c' in list(block.loops['_loop'].keys())
  assert list(block['_loop_c']) == ['11', '12', '13', '14']
  #
  block1 = model.block()
  block1["_tag"] = 2
  block1["_tag2"] = 1.2
  loop3 = model.loop(header=("_loop_a", "_loop_b"), data=(6,5,4,3,2,1))
  block1.add_loop(loop2)
  block1.add_loop(loop3)
  block.update(block1)
  for key in block._items.keys():
    assert key in ['_another_tag', '_tag2', '_tag', '_tag1']
  for value in block._items.values():
    assert value in ['3.142', '1.2', '2', "'a string'"]
  assert list(block.loops.keys()) == ['_loop', '_loop2']
  assert list(block.keys()) == ['_tag', '_tag1', '_another_tag', '_loop_a',
                          '_loop_b','_tag2', '_loop2_a', '_loop2_b']
  assert list(block['_loop_a']) == ['6', '4', '2']
  assert list(block['_loop_b']) == ['5', '3', '1']
  assert list(block['_loop2_a']) == ['1', '3', '5']
  assert list(block['_loop2_b']) == ['2', '4', '6']
  try: block['_loop_c']
  except KeyError: pass
  else: raise Exception_expected
  bad_loop = model.loop(header=("_a", "_b"), data=(1,2,3,4,5,6))
  block1.add_loop(bad_loop)
  assert "_a" in block1
  assert "_b" in block1
  assert list(block.get_looped_item("_loop_a")) == ['6', '4', '2']
  try: block.get_looped_item("_tag", value_error=ValueError)
  except ValueError: pass
  else: raise Exception_expected
  assert list(block.get_looped_item("_tag", value_error=None)) == ['2']
  try: block.get_looped_item("_none_existent")
  except KeyError: pass
  else: raise Exception_expected
  assert block.get_looped_item(
    "_none_existent", key_error=None, default="my_default") == "my_default"
  assert block.get_single_item("_tag") == "2"
  try: block.get_single_item("_loop_a")
  except ValueError: pass
  else: raise Exception_expected
  assert block.get_single_item(
    "_loop_a", value_error=None, default="default") == "default"
  try: block.get_single_item("_none_existent")
  except KeyError: pass
  else: raise Exception_expected
  assert block.get_single_item("_none_existent", key_error=None) is None
  #
  cif_model = model.cif()
  cif_model["fred"] = block
  assert "fred" in cif_model
  assert cif_model["frEd"] is block
  assert cif_model["fred"]["_Tag"] == '2'
  cif_model["fred"]["_tag"] = 4
  assert cif_model["fred"]["_tag"] == '4'
  del cif_model["fred"]["_tAg"]
  try: cif_model["fred"]["_tag"]
  except KeyError: pass
  else: raise Exception_expected
  cm = cif_model.deepcopy()
  l = cm["fred"]["_loop"]
  del cm["Fred"]["_loop_B"]
  assert "_loop_b" not in cm["fred"]
  assert "_loop_b" not in l
  assert "_loop" in cm["fred"].loops
  del cm["fred"]["_loop_a"]
  assert "_loop" not in cm["fred"].loops
  del cm["fred"]["_loop2"]
  assert "_loop2" not in cm["fred"].loops
  s = StringIO()
  print(cm, file=s)
  assert not show_diff(s.getvalue(),
"""\
data_fred
_tag1                             'a string'
_another_tag                      3.142
_tag2                             1.2

""")
  #
  cm2 = cif_model.copy()
  cm3 = cif_model.deepcopy()
  assert cm2['fred']['_loop_a'] is cif_model ['fred']['_loop_a']
  assert cm3['fred']['_loop_a'] is not cif_model ['fred']['_loop_a']
  b2 = copy.copy(block)
  b3 = copy.deepcopy(block)
  assert b2['_loop_b'] is block['_loop_b']
  assert b3['_loop_b'] is not block['_loop_b']
  l2 = loop.copy()
  l3 = loop.deepcopy()
  assert l2['_loop_b'] is loop['_loop_b']
  assert l3['_loop_b'] is not loop['_loop_b']
  #
  s = StringIO()
  cif_model.show(out=s)
  assert not show_diff(s.getvalue(),
"""\
data_fred
_tag1                             'a string'
_another_tag                      3.142
loop_
  _loop_a
  _loop_b
  6  5
  4  3
  2  1

_tag2                             1.2
loop_
  _loop2_a
  _loop2_b
  1  2
  3  4
  5  6

""")
  s = StringIO()
  cif_model.show(out=s, indent="    ", data_name_field_width=0)
  assert not show_diff(s.getvalue(),
"""\
data_fred
_tag1 'a string'
_another_tag 3.142
loop_
    _loop_a
    _loop_b
    6  5
    4  3
    2  1

_tag2 1.2
loop_
    _loop2_a
    _loop2_b
    1  2
    3  4
    5  6

""")
  s = StringIO()
  cif_model.show(out=s, indent="", indent_row="   ", data_name_field_width=0)
  assert not show_diff(s.getvalue(),
"""\
data_fred
_tag1 'a string'
_another_tag 3.142
loop_
_loop_a
_loop_b
   6  5
   4  3
   2  1

_tag2 1.2
loop_
_loop2_a
_loop2_b
   1  2
   3  4
   5  6

""")
  cif_model.sort(recursive=True)
  s = StringIO()
  cif_model.show(out=s)
  assert not show_diff(s.getvalue(),
"""\
data_fred
_another_tag                      3.142
_tag1                             'a string'
_tag2                             1.2
loop_
  _loop_a
  _loop_b
  6  5
  4  3
  2  1

loop_
  _loop2_a
  _loop2_b
  1  2
  3  4
  5  6

""")
  save = model.save()
  save.add_loop(l3)
  save['_tag1'] = 3
  block = model.block()
  block['bob'] = save
  cm = model.cif({'fred': block})
  s = StringIO()
  cm.show(out=s)
  assert not show_diff(s.getvalue(),
"""data_fred

save_bob
   loop_
    _loop_a
    _loop_c
    _loop_b
    1  11  7
    2  12  8
    3  13  9
    4  14  0

  _tag1                             3
  save_

""")
  b1 = model.block()
  b1['_a'] = 1
  b1['_b'] = 2
  b1['_c'] = 3
  b2 = model.block()
  b2['_a'] = 2
  b2['_c'] = 3
  b2['_d'] = 4
  b3 = b1.difference(b2)
  b4 = b2.difference(b1)
  for item in b3.items():
    assert item in [('_b', '2'), ('_a', '2')]
  for item in b4.items():
    assert item in [('_d', '4'), ('_a', '1')]
  l = model.loop(data=dict(_loop_d=(1,2),_loop_e=(3,4),_loop_f=(5,6)))
  assert l == l
  assert l == l.deepcopy()
  assert l != l2
  assert l != l3
  l2 = model.loop(data=dict(_loop_d=(1,2,3),_loop_e=(3,4,5),_loop_f=(5,6,7)))
  b1.add_loop(l)
  b2.add_loop(l2)
  b5 = b1.difference(b2)
  assert b5['_loop'] == l2
  l = model.loop(data=OrderedDict((('_loop_a',(1,21,-13)),
                                   ('_loop_b',(-221.3,3.01,4.246)),
                                   ('_loop_c',("a","b","cc")))))
  b = model.block()
  b.add_loop(l)
  cm = model.cif({'fred':b})
  s = StringIO()
  cm.show(out=s, loop_format_strings={'_loop':'% 4i% 8.2f %s'})
  assert not show_diff(s.getvalue(),"""\
data_fred
loop_
  _loop_a
  _loop_b
  _loop_c
   1 -221.30 a
  21    3.01 b
 -13    4.25 cc

""")
  s = StringIO()
  cm.show(out=s)
  assert not show_diff(s.getvalue(),"""\
data_fred
loop_
  _loop_a
  _loop_b
  _loop_c
    1  -221.3  a
   21    3.01  b
  -13   4.246  cc

""")
  l.add_row((".", "?", "."))
  s = StringIO()
  cm.show(out=s)
  assert not show_diff(s.getvalue(),"""\
data_fred
loop_
  _loop_a
  _loop_b
  _loop_c
    1  -221.3  a
   21    3.01  b
  -13   4.246  cc
    .       ?  .

""")
  l.delete_row(index=1)
  s = StringIO()
  cm.show(out=s)
  assert not show_diff(s.getvalue(),"""\
data_fred
loop_
  _loop_a
  _loop_b
  _loop_c
    1  -221.3  a
  -13   4.246  cc
    .       ?  .

""")
  l2 = l.deepcopy()
  l2.delete_row(index=0)
  l2.delete_row(index=0)
  l2.delete_row(index=0)
  try: l2.show(out=s)
  except AssertionError as e: pass
  else: raise Exception_expected
  l.clear()
  try: l.show(out=s)
  except AssertionError as e: pass
  else: raise Exception_expected
  #
  loop = model.loop(data={"_a_1": ('string with spaces','nospaces'),
                          "_a_2": ('a', 'b')})
  s = StringIO()
  loop.show(out=s, align_columns=True)
  assert not show_diff(s.getvalue(), """\
loop_
  _a_1
  _a_2
  'string with spaces'  a
  nospaces              b
""")
  #
  cb = model.block()
  cm = model.cif()
  cm["a"] = cb
  cb["_b"] = ""
  s = StringIO()
  cm.show(out=s)
  assert not show_diff(s.getvalue(), """\
data_a
_b                                ''
""")
  #
  loop = model.loop(data=OrderedDict((
    ("_entity_poly.entity_id", ('1', '2', '3')),
    ("_entity_poly.pdbx_seq_one_letter_code", (
      "TFGSGEADCGLRPLFEKKSLEDKTERELLESYIDGR",
      """\
IVEGSDAEIGMSPWQVMLFRKSPQELLCGASLISDRWVLTAAHCLLYPPWDKNFTENDLLVRIGKHSRTRYERNIEKISM
THVFRLKKWIQKVIDQFGE""",
      "NGDFEEIPEE(TYS)LQ",
    )),
    ("_entity_poly.pdbx_seq_one_letter_code_can", (
      "TFGSGEADCGLRPLFEKKSLEDKTERELLESYIDGR",
      """\
IVEGSDAEIGMSPWQVMLFRKSPQELLCGASLISDRWVLTAAHCLLYPPWDKNFTENDLLVRIGKHSRTRYERNIEKISM
THVFRLKKWIQKVIDQFGE""",
      "NGDFEEIPEEYLQ",
    )),
    ("_entity_poly.pdbx_strand_id", ('L', 'H', 'I'))
  )))
  s = StringIO()
  loop.show(out=s, align_columns=True)
  s.seek(0)
  assert not show_diff("\n".join(l.rstrip() for l in s.readlines()),"""\
loop_
  _entity_poly.entity_id
  _entity_poly.pdbx_seq_one_letter_code
  _entity_poly.pdbx_seq_one_letter_code_can
  _entity_poly.pdbx_strand_id
  1  TFGSGEADCGLRPLFEKKSLEDKTERELLESYIDGR  TFGSGEADCGLRPLFEKKSLEDKTERELLESYIDGR  L
  2
;
IVEGSDAEIGMSPWQVMLFRKSPQELLCGASLISDRWVLTAAHCLLYPPWDKNFTENDLLVRIGKHSRTRYERNIEKISM
THVFRLKKWIQKVIDQFGE
;

;
IVEGSDAEIGMSPWQVMLFRKSPQELLCGASLISDRWVLTAAHCLLYPPWDKNFTENDLLVRIGKHSRTRYERNIEKISM
THVFRLKKWIQKVIDQFGE
;
  H
  3  NGDFEEIPEE(TYS)LQ                     NGDFEEIPEEYLQ                         I\
""")
  #
  cb = model.block()
  cm = model.cif()
  cm["a"] = cb
  cb["_a"] = '1 "a" 2'
  cb["_b"] = "1 'b' 3"
  cb["_c"] = "O1'"
  cb["_d"] = 'O2"'
  cb["_e"] = """1 'a' "b" 3"""
  s = StringIO()
  print(cm, file=s)
  s.seek(0)
  assert not show_diff("\n".join(l.rstrip() for l in s.readlines()), """\
data_a
_a                                '1 "a" 2'
_b                                "1 'b' 3"
_c                                O1'
_d                                O2"
_e
;
1 'a' "b" 3
;

""")
  # verify that what we wrote out above is valid CIF and we can read it back in
  cm2 = iotbx.cif.reader(input_string=s.getvalue()).model()
  cb2 = cm2["a"]
  assert cb2["_a"] == cb["_a"]
  assert cb2["_b"] == cb["_b"]
  assert cb2["_c"] == cb["_c"]
  assert cb2["_d"] == cb["_d"]
  assert cb2["_e"].strip() == cb["_e"]
  #
  cm = iotbx.cif.reader(input_string="""\
data_a
loop_
  _pdbx_refine_tls_group.id
  _pdbx_refine_tls_group.refine_tls_id
  _pdbx_refine_tls_group.selection
  _pdbx_refine_tls_group.selection_details
  1  1  ?  "chain 'A' and (resid    2  through   15 )"
  2  2  ?  "chain 'A' and (resid   16  through   26 )"
  3  3  ?  "chain 'A' and (resid   27  through   43 )"
  4  4  ?  "chain 'B' and (resid    1  through   14 )"
  5  5  ?  "chain 'B' and (resid   15  through   20 )"
""").model()
  print(cm)
  #
  cif_block = model.block()
  loop_a = model.loop(header=("_a.1", "_a.2"), data=(1,2,3,4,5,6))
  cif_block.add_loop(loop_a)
  assert cif_block.get_loop("_a") is loop_a
  assert cif_block.get_loop_or_row("_a") is loop_a
  assert cif_block.get_loop("_b") is None
  assert cif_block.get_loop_or_row("_b") is None
  assert cif_block.get_loop("_b", default=loop_a) is loop_a
  assert cif_block.get_loop_or_row("_b", default=loop_a) is loop_a
  loop_a = cif_block.get_loop_with_defaults(
    "_a", default_dict={"_a.2":".", "_a.3":"?", "_a.4":"."})
  assert list(cif_block["_a.1"]) == ['1', '3', '5']
  assert list(cif_block["_a.2"]) == ['2', '4', '6']
  assert list(cif_block["_a.3"]) == ['?', '?', '?']
  assert list(cif_block["_a.4"]) == ['.', '.', '.']
  loop_a.add_row({"_a.3":"a", "_a.4":"b"})
  loop_a.add_row({"_a.3":"c", "_a.4":"d"}, default_value=".")
  assert list(cif_block["_a.1"]) == ['1', '3', '5', '?', '.']
  assert list(cif_block["_a.2"]) == ['2', '4', '6', '?', '.']
  assert list(cif_block["_a.3"]) == ['?', '?', '?', 'a', 'c']
  assert list(cif_block["_a.4"]) == ['.', '.', '.', 'b', 'd']
  loop_B = model.loop(header=("_B.1", "_B.2", "_B.3"), data=(1,2,3,4,5,6))
  cif_block.add_loop(loop_B)
  assert cif_block.get_loop("_B") is loop_B
  assert cif_block.get_loop_or_row("_B") is loop_B
  assert cif_block.get_loop("_b") is loop_B
  assert cif_block.get_loop_or_row("_b") is loop_B
  #
  cif_block = model.block()
  cif_block['_a'] = """\
123
456"""
  s = StringIO()
  cif_block.show(out=s)
  s.seek(0)
  assert not show_diff("\n".join([l.strip() for l in s.readlines()]), """\
_a
;
123
456
;
""")


  cm = iotbx.cif.reader(input_string="""\
data_a
  _test_row.id 1
  _test_row.data2 2
  _test_row.data3 3
  _test_row.data4 44
#
loop_
_test_row_range.sheet_id
_test_row_range.id
_test_row_range.beg_label_comp_id
_test_row_range.beg_label_asym_id
A 1 SER A
A 2 MET A
#
""").model()
  #
  cif_block = list(cm.values())[0]
  loop_or_row = cif_block.get_loop_or_row('_test_row')
  assert loop_or_row.n_rows() == 1
  assert loop_or_row.n_columns() == 4
  assert list(loop_or_row['_test_row.id']) == ['1']
  assert list(loop_or_row['_test_row.data2']) == ['2']
  assert list(loop_or_row['_test_row.data3']) == ['3']
  assert list(loop_or_row['_test_row.data4']) == ['44']
  for r in loop_or_row.iterrows():
    assert list(r['_test_row.id']) == ['1']
    assert list(r['_test_row.data2']) == ['2']
    assert list(r['_test_row.data3']) == ['3']
    assert list(r['_test_row.data4']) == ['4','4']

def test_301():
  cif_model = iotbx.cif.reader(input_string="""\
data_test
loop_
  _symmetry_symop_operation_xyz
 x,y,z
 -x,y+1/2,-z
""").model()
  del cif_model["test"]["_symmetry_symop_operation_xyz"]
  s = str(cif_model)
  assert s.strip() == 'data_test'

def test_show_not_modify():
  """
  Test that content of the object is not changed during .show()
  """
  cif_str = """\
data_r3p4rsf
#
_symmetry.entry_id               3p4r
_symmetry.space_group_name_H-M   'P 21 21 21'
_symmetry.Int_Tables_number      19
#
loop_
_symmetry_equiv.id
_symmetry_equiv.pos_as_xyz
1 'X,  Y,  Z'
2 '-X+1/2,  -Y,  Z+1/2'
3 'X+1/2,  -Y+1/2,  -Z'
4 '-X,  Y+1/2,  -Z+1/2'
"""
  cif_reader = iotbx.cif.reader(input_string=cif_str)
  model = cif_reader.model()
  print (model['r3p4rsf']['_symmetry.space_group_name_H-M'])
  print (list(model['r3p4rsf']['_symmetry_equiv.pos_as_xyz']))
  assert list(model['r3p4rsf']['_symmetry_equiv.pos_as_xyz']) ==\
      ['X,  Y,  Z', '-X+1/2,  -Y,  Z+1/2', 'X+1/2,  -Y+1/2,  -Z', '-X,  Y+1/2,  -Z+1/2']
  s = StringIO()
  model.show(out=s)
  print (model['r3p4rsf']['_symmetry.space_group_name_H-M'])
  print (list(model['r3p4rsf']['_symmetry_equiv.pos_as_xyz']))
  assert list(model['r3p4rsf']['_symmetry_equiv.pos_as_xyz']) ==\
      ['X,  Y,  Z', '-X+1/2,  -Y,  Z+1/2', 'X+1/2,  -Y+1/2,  -Z', '-X,  Y+1/2,  -Z+1/2']

if __name__ == '__main__':
  exercise_cif_model()
  test_301()
  test_show_not_modify()
  print("OK")


 *******************************************************************************


 *******************************************************************************
iotbx/cif/tests/tst_model_builder.py
from __future__ import absolute_import, division, print_function
import iotbx.cif
from libtbx.utils import Sorry
from libtbx.test_utils import show_diff


def test_repeated_loop_1():
  cif_txt_1 = """\
data_test
loop_
  _geom_bond_atom_site_label_1
  _geom_bond_atom_site_label_2
  _geom_bond_distance
  _geom_bond_site_symmetry_2
  Si  O  1.6160  4_554
  Si  O  1.6160  2_554
  """
  cif_txt_2 = """\
loop_
  _geom_bond_atom_site_label_1
  _geom_bond_atom_site_label_2
  _geom_bond_distance
  _geom_bond_site_symmetry_2
  Si  O  1.6160  3_664
  Si  O  1.6160  5_664
  """
  r = iotbx.cif.reader(input_string=cif_txt_1)
  try:
    r = iotbx.cif.reader(input_string=cif_txt_1+cif_txt_2)
  except Sorry as e:
    assert not show_diff(str(e), "Loop containing tags _geom_bond_atom_site_label_1, _geom_bond_atom_site_label_2, _geom_bond_distance, _geom_bond_site_symmetry_2 appears repeated")
  else:
    assert 0, "Sorry must be raised above."

def test_repeated_loop_2():
  cif_txt_1 = """\
data_test
loop_
  _atom_site_label
  _atom_site_type_symbol
  _atom_site_fract_x
  _atom_site_fract_y
  _atom_site_fract_z
  Rb1  Rb           0.5           0         0.25
  Rb2  Rb    0.31563(3)         0.5   0.14226(3)

loop_
  _atom_site_label
  _atom_site_U_iso_or_equiv
  Rb1 0.5(2)
  Rb2 0.5(3)
  """
  try:
    r = iotbx.cif.reader(input_string=cif_txt_1)
  except Sorry as e:
    assert not show_diff(str(e), "Loop containing tags _atom_site_label, _atom_site_U_iso_or_equiv appears repeated")
  else:
    assert 0, "Sorry must be raised above."

def test_repeated_loop_3_with_typo():
  cif_txt_1 = """\
  data_test
loop_
  _atom_site_displace_Fourier_id
  _atom_site_displace_Fourier_atom_site_label
  _atom_site_displace_Fourier_axis
  _atom_site_displace_Fourier_wave_vector_seq_id
  Rb1y1 Rb1  y  1
  Rb2x1 Rb2  x  1
  Rb2y1 Rb2  y  1
  Rb2z1 Rb2  z  1

loop_
  _atom_site_displace_Fourier_parm_id
  _atom_site_displace_Fourier_param_cos
  _atom_site_displace_Fourier_param_sin
  Rb1y1   -0.0043(3)           0
  Rb2x1            0  -0.0001(1)
  Rb2y1   -0.0027(2)           0
  Rb2z1            0   0.0001(1)
  """
  try:
    r = iotbx.cif.reader(input_string=cif_txt_1)
  except Sorry as e:
    assert not show_diff(str(e), "Loop containing tags _atom_site_displace_Fourier_parm_id, _atom_site_displace_Fourier_param_cos, _atom_site_displace_Fourier_param_sin appears repeated")
  else:
    assert 0, "Sorry must be raised above."

def test_repeated_tags():
  cif_txt_1 = """\
data_RbMo
_audit_block_code                 RbMo

_diffrn_ambient_temperature 200
_diffrn_ambient_temperature 300
  """
  try:
    r = iotbx.cif.reader(input_string=cif_txt_1)
  except Sorry as e:
    assert not show_diff(str(e), "Data item _diffrn_ambient_temperature received multiple values")
  else:
    assert 0, "Sorry must be raised above."

if __name__ == '__main__':
  # from: https://github.com/cctbx/cctbx_project/issues/662
  test_repeated_loop_1()
  test_repeated_loop_2()
  test_repeated_loop_3_with_typo()
  test_repeated_tags()


 *******************************************************************************


 *******************************************************************************
iotbx/cif/tests/tst_parser.py
from __future__ import absolute_import, division, print_function
from six.moves import range
class accu_builder(object):

  __slots__ = ["accu"]

  def __init__(O):
    O.accu = []

  def add_data_block(self, data_block_heading):
    O.accu.append(("add_data_block", data_block_heading))

  def add_loop(self, header, data):
    O.accu.append(("add_loop", (header, data)))

  def add_data_item(self, key, value):
    O.accu.append(("add_data_item", (key, value)))

  def start_save_frame(self, save_frame_heading):
    O.accu.append(("start_save_frame", (save_frame_heading)))

  def end_save_frame(self):
    O.accu.append(("end_save_frame",))

def exercise(verbose):
  builder = accu_builder()
  import iotbx.cif
  reader = iotbx.cif.ext.fast_reader(input_string="", filename="", builder=builder, strict=True)
  assert reader.lexer_errors().size() == 0
  assert reader.parser_errors().size() == 0
  assert len(builder.accu) == 0
  for i in range(256):
    builder = accu_builder()
    reader = iotbx.cif.ext.fast_reader(
      input_string=chr(i), filename="", builder=builder, strict=True)
    if (verbose):
      print(reader.lexer_errors().size(), \
            reader.parser_errors().size(), \
            len(builder.accu))

def run(args):
  assert args in [[], ["--forever"]]
  forever = (len(args) != 0)
  while True:
    exercise(verbose=not forever)
    if (not forever):
      break

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/cif/tests/tst_restraints.py
from __future__ import absolute_import, division, print_function
from cctbx import crystal, sgtbx, xray
from cctbx import geometry_restraints
from cctbx.array_family import flex
import iotbx.cif.restraints
from libtbx.test_utils import show_diff

from six.moves import cStringIO as StringIO

def exercise_geometry_restraints_as_cif():
  quartz = xray.structure(
    crystal_symmetry=crystal.symmetry(
      (5.01,5.01,5.47,90,90,120), "P6222"),
    scatterers=flex.xray_scatterer([
      xray.scatterer("Si", (1/2.,1/2.,1/3.)),
      xray.scatterer("O", (0.197,-0.197,0.83333))]))
  bond_proxies = geometry_restraints.shared_bond_simple_proxy((
    geometry_restraints.bond_simple_proxy(
      i_seqs=[0,1],
      rt_mx_ji=sgtbx.rt_mx("x-y,x,z-2/3"),
      distance_ideal=1.6,
      weight=3.2),
    geometry_restraints.bond_simple_proxy(
      i_seqs=[0,1],
      distance_ideal=1.7,
      weight=1.8),
  ))
  dihedral_proxies = geometry_restraints.shared_dihedral_proxy((
    geometry_restraints.dihedral_proxy(
      i_seqs = [1,0,1,0],
      sym_ops = (sgtbx.rt_mx("1+y,1-x+y, z-1/3"),
                 sgtbx.rt_mx(),
                 sgtbx.rt_mx("x-y,x,z-2/3"),
                 sgtbx.rt_mx("1-x,y-x,1/3-z")),
      angle_ideal=-30,
      weight=2),
    geometry_restraints.dihedral_proxy(
      i_seqs = [1,0,1,0],
      sym_ops = (sgtbx.rt_mx("1+y,1-x+y, z-1/3"),
                 sgtbx.rt_mx(),
                 sgtbx.rt_mx("-y,x-y,z-1/3"),
                 sgtbx.rt_mx("x-y,x,1/3+z")),
      angle_ideal=90,
      weight=3),
  ))
  chirality_proxies = geometry_restraints.shared_chirality_proxy((
    geometry_restraints.chirality_proxy(
      i_seqs = [1,0,1,0],
      sym_ops = (sgtbx.rt_mx("1+y,1-x+y, z-1/3"),
                 sgtbx.rt_mx(),
                 sgtbx.rt_mx("x-y,x,z-2/3"),
                 sgtbx.rt_mx("1-x,y-x,1/3-z")),
      volume_ideal=1.2,
      both_signs=False,
      weight=2),
    geometry_restraints.chirality_proxy(
      i_seqs = [1,0,1,0],
      sym_ops = (sgtbx.rt_mx("1+y,1-x+y, z-1/3"),
                 sgtbx.rt_mx(),
                 sgtbx.rt_mx("x-y,x,z-2/3"),
                 sgtbx.rt_mx("1-x,y-x,1/3-z")),
      volume_ideal=1.2,
      both_signs=True,
      weight=2),
  ))
  angle_proxies = geometry_restraints.shared_angle_proxy((
    geometry_restraints.angle_proxy(
      i_seqs = [1,0,1],
      sym_ops = (sgtbx.rt_mx("x-y,x,z-2/3"),
                 sgtbx.rt_mx(),
                 sgtbx.rt_mx("-y,x-y,z-1/3")),
      angle_ideal=103,
      weight=2),
    geometry_restraints.angle_proxy(
      i_seqs = [1,0,1],
      sym_ops = (sgtbx.rt_mx("y+1,-x+y+1,z-1/3"),
                 sgtbx.rt_mx(),
                 sgtbx.rt_mx("-y,x-y,z-1/3")),
      angle_ideal=110,
      weight=5),
    geometry_restraints.angle_proxy(
      i_seqs = [0,1,0],
      sym_ops = (sgtbx.rt_mx("y,-x+y,z+2/3"),
                 sgtbx.rt_mx(),
                 sgtbx.rt_mx("-x+y,-x,z+1/3")),
      angle_ideal=150,
      weight=5),
  ))
  bond_similarity_proxies = geometry_restraints.shared_bond_similarity_proxy((
    geometry_restraints.bond_similarity_proxy(
      i_seqs=[(0,1),(0,1),(0,1)],
      sym_ops=(sgtbx.rt_mx("x-y,x,z-2/3"),
               sgtbx.rt_mx("-y,x-y,z-1/3"),
               sgtbx.rt_mx("y+1,-x+y+1,z-1/3")),
      weights=(1,1,1)),
  ))
  cif_block = iotbx.cif.model.block()
  iotbx.cif.restraints.add_to_cif_block(
    cif_block, quartz,
    bond_proxies=bond_proxies,
    angle_proxies=angle_proxies,
    dihedral_proxies=dihedral_proxies,
    chirality_proxies=chirality_proxies,
    bond_similarity_proxies=bond_similarity_proxies)
  s = StringIO()
  cif_block.show(out=s)
  assert not show_diff(s.getvalue(), """\
loop_
  _restr_distance_atom_site_label_1
  _restr_distance_atom_site_label_2
  _restr_distance_site_symmetry_2
  _restr_distance_target
  _restr_distance_target_weight_param
  _restr_distance_diff
  Si  O  2_554  1.6000  0.5590  -0.0160
  Si  O  1      1.7000  0.7454  -2.3838

loop_
  _restr_angle_atom_site_label_1
  _restr_angle_atom_site_label_2
  _restr_angle_atom_site_label_3
  _restr_angle_site_symmetry_1
  _restr_angle_site_symmetry_2
  _restr_angle_site_symmetry_3
  _restr_angle_target
  _restr_angle_target_weight_param
  _restr_angle_diff
  O   Si  O   2_554  1  4_554  103.0000  0.7071   1.6926
  O   Si  O   3_664  1  4_554  110.0000  0.4472  -1.3127
  Si  O   Si  3      1  5      150.0000  0.4472   3.0700

loop_
  _restr_torsion_atom_site_label_1
  _restr_torsion_atom_site_label_2
  _restr_torsion_atom_site_label_3
  _restr_torsion_atom_site_label_4
  _restr_torsion_site_symmetry_1
  _restr_torsion_site_symmetry_2
  _restr_torsion_site_symmetry_3
  _restr_torsion_site_symmetry_4
  _restr_torsion_angle_target
  _restr_torsion_weight_param
  _restr_torsion_diff
  O  Si  O  Si  3_664  1  2_554  7_655  -30.0000  0.7071   6.9078
  O  Si  O  Si  3_664  1  4_554  2       90.0000  0.5774  11.7036

loop_
  _restr_chirality_atom_site_label_1
  _restr_chirality_atom_site_label_2
  _restr_chirality_atom_site_label_3
  _restr_chirality_atom_site_label_4
  _restr_chirality_site_symmetry_1
  _restr_chirality_site_symmetry_2
  _restr_chirality_site_symmetry_3
  _restr_chirality_site_symmetry_4
  _restr_chirality_volume_target
  _restr_chirality_weight_param
  _restr_chirality_diff
  O  Si  O  Si  3_664  1  2_554  7_655  1.2000  0.7071   2.4415
  O  Si  O  Si  3_664  1  2_554  7_655  1.2000  0.7071  -0.0415

loop_
  _restr_equal_distance_class_class_id
  _restr_equal_distance_class_target_weight_param
  _restr_equal_distance_class_average
  _restr_equal_distance_class_esd
  _restr_equal_distance_class_diff_max
  1  1.0000  1.6160  0.0000  0.0000

loop_
  _restr_equal_distance_atom_site_label_1
  _restr_equal_distance_atom_site_label_2
  _restr_equal_distance_site_symmetry_2
  _restr_equal_distance_class_id
  Si  O  2_554  1
  Si  O  4_554  1
  Si  O  3_664  1

""")

def exercise_adp_restraints_as_cif():
  import libtbx.load_env
  if not libtbx.env.has_module("smtbx"):
    print("Skipping exercise_adp_restraints_as_cif(): smtbx not available")
    return
  from smtbx.refinement.restraints import adp_restraints as smtbx_adp_restraints
  import smtbx.development
  xs = smtbx.development.sucrose()
  rigid_bond_proxies = smtbx_adp_restraints.rigid_bond_restraints(
    xray_structure=xs).proxies[:3]
  rigu_proxies = smtbx_adp_restraints.rigu_restraints(
    xray_structure=xs).proxies[:3]
  adp_similarity_proxies = smtbx_adp_restraints.adp_similarity_restraints(
    xray_structure=xs).proxies[:3]
  isotropic_adp_proxies = smtbx_adp_restraints.isotropic_adp_restraints(
    xray_structure=xs).proxies[:3]
  cif_block = iotbx.cif.model.block()
  iotbx.cif.restraints.add_to_cif_block(
    cif_block, xs,
    rigid_bond_proxies=rigid_bond_proxies,
    rigu_proxies=rigu_proxies,
    adp_similarity_proxies=adp_similarity_proxies,
    isotropic_adp_proxies=isotropic_adp_proxies)
  s = StringIO()
  cif_block.show(out=s)
  assert not show_diff(s.getvalue(), """\
loop_
  _restr_U_rigid_atom_site_label_1
  _restr_U_rigid_atom_site_label_2
  _restr_U_rigid_target_weight_param
  _restr_U_rigid_U_parallel
  _restr_U_rigid_diff
  O1  C1  0.0100  0.0176   0.0006
  O1  C2  0.0100  0.0194  -0.0053
  O1  C3  0.0100  0.0177   0.0013

loop_
  _restr_RIGU_atom_site_label_1
  _restr_RIGU_atom_site_label_2
  _restr_RIGU_target_weight_param
  _restr_RIGU_U13_diff
  _restr_RIGU_U23_diff
  _restr_RIGU_U33_diff
  O1  C1  0.004000  -0.002618  -0.001550   0.000599
  O1  C2  0.004000  -0.000752   0.002098  -0.005274
  O1  C3  0.004000  -0.002608  -0.001448   0.001305

loop_
  _restr_U_similar_atom_site_label_1
  _restr_U_similar_atom_site_label_2
  _restr_U_similar_weight_param
  O1  C1  0.0400
  O1  C6  0.0400
  O2  C2  0.0800

loop_
  _restr_U_iso_atom_site_label
  _restr_U_iso_weight_param
  O1  0.1000
  O2  0.2000
  O3  0.2000

""")


def run():
  exercise_adp_restraints_as_cif()
  exercise_geometry_restraints_as_cif()
  print("OK")

if __name__ == '__main__':
  run()


 *******************************************************************************


 *******************************************************************************
iotbx/cif/tests/tst_ucif_examples_compilation.py
from __future__ import absolute_import, division, print_function
import os, sys
import libtbx.load_env
from libtbx import easy_run
from libtbx.test_utils import open_tmp_file, open_tmp_directory

def run(args):
  tmp_dir = open_tmp_directory(suffix="example_cif_parser")
  cur_dir = os.path.abspath(os.path.curdir)
  os.chdir(os.path.abspath(tmp_dir))
  try:
    exercise_compilation()
  finally:
    os.chdir(cur_dir)

def exercise_compilation():
  ucif_dist = libtbx.env.dist_path(module_name="ucif")
  antlr3_dist = libtbx.env.under_dist("ucif", "antlr3")
  os.environ["LIBTBX_UCIF"] = ucif_dist
  os.environ["LIBTBX_ANTLR3"] = antlr3_dist
  assert ucif_dist.find('"') < 0
  if sys.platform == "win32":
    cmd = '"%s/examples/build_cif_parser.bat"' %ucif_dist
    ext = ".exe"
  else:
    cmd = '"%s/examples/build_cif_parser.sh"' %ucif_dist
    ext = ""
  result = easy_run.fully_buffered(cmd)
  if result.return_code:
    if len(result.stderr_lines) > 0:
      raise RuntimeError(result.show_stderr())
    raise RuntimeError(result.show_stdout())
  assert os.path.exists("cif_parser"+ext)
  f = open_tmp_file(suffix=".cif")
  f.write(cif_string)
  f.close()
  cmd = 'cif_parser "%s"' %f.name
  cmd = os.path.join(".", cmd)
  r = easy_run.fully_buffered(cmd).raise_if_errors()
  assert r.stdout_lines[0].startswith("Congratulations!")

cif_string = """\
data_a
_a 1
_b 2
"""

if __name__ == '__main__':
  run(sys.argv[1:])
  print("OK")


 *******************************************************************************


 *******************************************************************************
iotbx/cif/tests/tst_validation.py
from __future__ import absolute_import, division, print_function
from iotbx import cif
from iotbx.cif import validation
from iotbx.cif.validation import smart_load_dictionary
import libtbx.load_env
from libtbx.test_utils import Exception_expected

from six.moves.urllib.error import URLError
from six.moves import cStringIO as StringIO
import sys

cif_core_dic_url = "ftp://ftp.iucr.org/pub/cif_core.dic"
cif_mm_dic_url = "ftp://ftp.iucr.org/pub/cif_mm.dic"

def exercise(args):
  import socket
  if socket.getdefaulttimeout() is None:
    socket.setdefaulttimeout(5)
  show_timings = "--show_timings" in args
  exercise_url = "--exercise_url" in args
  try:
    exercise_smart_load(show_timings=show_timings, exercise_url=exercise_url)
  except URLError:
    print("Skipping tst_validation.exercise_smart_load() because of URLError.")
  exercise_dictionary_merging()
  exercise_validation()

def exercise_validation():
  cd = validation.smart_load_dictionary(name="cif_core.dic")
  assert isinstance(cd.deepcopy(), validation.dictionary)
  assert cd.deepcopy() == cd
  assert isinstance(cd.copy(), validation.dictionary)
  assert cd.copy() == cd
  #
  cm_invalid = cif.reader(input_string=cif_invalid).model()
  s = StringIO()
  cm_invalid.validate(cd, out=s)
  assert sorted(cd.err.errors.keys()) == [
    2001, 2002, 2101, 2102, 2501, 2503, 2504, 2505, 2506]
  assert sorted(cd.err.warnings.keys()) == [1001, 1002, 1003]
  cm_valid = cif.reader(input_string=cif_valid).model()
  cd.err.reset()
  s = StringIO()
  cm_valid.validate(cd, out=s)
  assert len(list(cd.err.errors.keys())) == 0
  assert len(list(cd.err.warnings.keys())) == 0
  cd2 = validation.smart_load_dictionary(name="cif_mm.dic")
  cm_invalid_2 = cif.reader(input_string=cif_invalid_2).model()
  s = StringIO()
  cm_invalid_2.validate(cd2, out=s)
  assert sorted(cd2.err.errors.keys()) == [
    2001, 2101, 2102, 2201, 2202, 2203, 2301, 2503, 2504]
  assert cd2.err.error_count == 12
  assert sorted(cd2.err.warnings.keys()) == [1001, 1002]

def exercise_smart_load(show_timings=False, exercise_url=False):
  from libtbx.test_utils import open_tmp_directory
  from libtbx.utils import time_log
  import libtbx
  import os, shutil
  name = ["cif_core.dic", "cif_mm.dic"][0]
  url = [cif_core_dic_url, cif_mm_dic_url][0]
  # from gz
  gz_timer = time_log("from gz").start()
  cd = validation.smart_load_dictionary(name=name)
  gz_timer.stop()
  if exercise_url:
    tempdir = open_tmp_directory()
    store_dir = libtbx.env.under_dist(
      module_name='iotbx', path='cif/dictionaries')
    file_path = os.path.join(store_dir, name) + '.gz'
    shutil.copy(os.path.join(store_dir, name) + '.gz', tempdir)
    # from url
    url_timer = time_log("from url").start()
    cd = validation.smart_load_dictionary(url=url, store_dir=tempdir)
    url_timer.stop()
    # from url to file
    url_to_file_timer = time_log("url to file").start()
    cd = validation.smart_load_dictionary(
      url=url, save_local=True, store_dir=tempdir)
    url_to_file_timer.stop()
    # read local file
    file_timer = time_log("from file").start()
    cd = validation.smart_load_dictionary(file_path=os.path.join(tempdir, name))
    file_timer.stop()
  if show_timings:
    print(time_log.legend)
    print(gz_timer.report())
    if exercise_url:
      print(url_timer.report())
      print(url_to_file_timer.report())
      print(file_timer.report())

def exercise_dictionary_merging():
  #
  # DDL1 merging
  #
  def cif_dic_from_str(string):
    on_this_dict = """
    data_on_this_dictionary
    _dictionary_name dummy
    _dictionary_version 1.0
    """
    return validation.dictionary(
      cif.reader(input_string=on_this_dict+string).model())
  test_cif = cif.reader(input_string="""
  data_test
  _dummy 1234.5
  """).model()
  dict_official = cif_dic_from_str("""
  data_dummy
  _name '_dummy'
  _type numb
  _enumeration_range 0: # i.e. any positive number
  """)
  dict_a = cif_dic_from_str("""
  data_dummy_modified
  _name '_dummy'
  _enumeration_range 0:1000
  """)
  dict_b = cif_dic_from_str("""
  data_dummy
  _name '_dummy'
  _type_extended integer
  """)
  dict_c = cif_dic_from_str("""
  data_dummy
  _name '_dummy'
  _type char
  """)
  test_cif.validate(dict_official)
  try: dict_official.deepcopy().update(other=dict_a, mode="strict")
  except AssertionError: pass
  else: raise Exception_expected
  dict_oa = dict_official.deepcopy()
  dict_oa.update(other=dict_a, mode="overlay")
  assert dict_oa["dummy"]["_type"] == "numb"
  assert dict_oa["dummy"]["_enumeration_range"] == "0:1000"
  assert test_cif.validate(dict_oa, out=StringIO()).error_count == 1
  dict_ao = dict_a.deepcopy()
  dict_ao.update(other=dict_official, mode="overlay")
  assert dict_ao["dummy_modified"]["_type"] == "numb"
  assert dict_ao["dummy_modified"]["_enumeration_range"] == "0:"
  assert test_cif.validate(dict_ao).error_count == 0
  dict_ob = dict_official.deepcopy()
  dict_ob.update(other=dict_b, mode="overlay")
  assert dict_ob["dummy"]["_type"] == "numb"
  assert dict_ob["dummy"]["_type_extended"] == "integer"
  assert test_cif.validate(dict_ob).error_count == 0
  dict_ob = dict_official.deepcopy()
  dict_ob.update(other=dict_b, mode="replace")
  assert "_type" not in dict_ob["dummy"]
  assert dict_ob["dummy"]["_type_extended"] == "integer"
  assert test_cif.validate(dict_ob).error_count == 0
  dict_oc = dict_official.deepcopy()
  dict_oc.update(other=dict_c, mode="replace")
  assert dict_oc["dummy"]["_type"] == "char"
  assert test_cif.validate(dict_oc).error_count == 0
  dict_oc = dict_official.deepcopy()
  dict_oc.update(other=dict_c, mode="overlay")
  errors = test_cif.validate(dict_oc)
  #
  # DDL2 merging
  #
  def cif_dic_from_str(string):
    header = """\
data_test.dic
    _dictionary.title           test.dic
    _dictionary.version         1

    loop_
    _item_type_list.code
    _item_type_list.primitive_code
    _item_type_list.construct
    _item_type_list.detail
               code      char
               '[_,.;:"&<>()/\\{}'`~!@#$%A-Za-z0-9*|+-]*'
;              code item types/single words ...
;
"""
    return validation.dictionary(
      cif.reader(input_string=header+string).model())
  dic_a = cif_dic_from_str(
    """
save_fred
    _category.description       'a description'
    _category.id                  fred
    _category.mandatory_code      no
    _category_key.name          'fred.id'
     save_
    """)
  dic_b = cif_dic_from_str(
    """
save_fred
    _category.id                  fred
    _category.mandatory_code      yes
    _category_key.name          'fred.id'
    loop_
    _category_group.id           'inclusive_group'
                                 'atom_group'
     save_
""")
  dic_c = cif_dic_from_str(
    """
save_bob
    _category.id                  bob
    _category.mandatory_code      yes
    _category_key.name          'bob.id'
     save_
""")
  assert dic_a.deepcopy() == dic_a
  assert dic_a.copy() == dic_a
  try: dic_a.deepcopy().update(dic_b, mode="strict")
  except AssertionError: pass
  else: raise Exception_expected
  dic_ab = dic_a.deepcopy()
  dic_ab.update(dic_b, mode="replace")
  assert dic_ab == dic_b
  dic_ab = dic_a.deepcopy()
  dic_ab.update(dic_b, mode="overlay")
  assert dic_ab['test.dic']['fred']['_category.mandatory_code'] == 'yes'
  assert '_category.description' in dic_ab['test.dic']['fred']
  assert '_category_group.id' in dic_ab['test.dic']['fred']
  for mode in ("strict", "replace", "overlay"):
    dic_ac = dic_a.deepcopy()
    dic_ac.update(dic_c, mode=mode)
    assert 'fred' in dic_ac['test.dic']
    assert 'bob' in dic_ac['test.dic']


cif_invalid = """data_1
_made_up_name a                            # warning 1001
_space_group_IT_number b                   # error 2001
_diffrn_reflns_number 2000(1)              # error 2002
_refine_ls_abs_structure_Flack -0.3        # error 2101
_diffrn_radiation_probe rubbish            # error 2102
_symmetry_cell_setting Monoclinic          # warning 1002

loop_
_cell_length_a 10 10                       # error 2501

loop_
_atom_site_label
_atom_site_chemical_conn_number            # error 2504
_atom_site_refinement_flags                # warning 1003
O1 1 P

loop_                                      # error 2503
_atom_site_aniso_label
N1
N2

loop_                                      # error 2505
_space_group_symop_operation_xyz
x,y,z
-x,-y,-z

_atom_site_adp_type Uani                   # error 2506
"""

cif_valid = """data_1
_space_group_IT_number 2
_diffrn_reflns_number 2000
_refine_ls_abs_structure_Flack 0.3
_diffrn_radiation_probe x-ray
_cell_length_a 10
_space_group_crystal_system monoclinic

loop_
_atom_site_label
_atom_site_chemical_conn_number
_atom_site_adp_type
O1 1 Uani
N1 2 Uani
N2 3 Uani

loop_
_chemical_conn_atom_number
_chemical_conn_atom_type_symbol
1 O
2 N
3 N

loop_
_atom_site_aniso_label
N1
N2

loop_
_space_group_symop_id
_space_group_symop_operation_xyz
1 x,y,z
2 -x,-y,-z
"""

cif_invalid_2 = """data_2
_made_up.name a                            # warning 1001
_space_group.IT_number b                   # error 2001
_diffrn_reflns_number 200.32               # error 2001
_refine.ls_abs_structure_Flack -0.3        # error 2101
_diffrn_radiation.probe rubbish            # error 2102
_symmetry.cell_setting Monoclinic          # warning 1002

loop_
_cell.length_a 10 10                       # error 2203, 2301

loop_
_atom_site.id
_atom_site.chemical_conn_number            # error 2504
O1 1

loop_                                      # error 2503
_atom_site_anisotrop.id
_atom_site_anisotrop.U[1][1]               # error 2301
_atom_site_anisotrop.B[1][1]               # error 2201
_atom_site_anisotrop.U[1][2]_esd           # error 2202
N1 1
N2 2

loop_                                      # error 2203
_space_group_symop.operation_xyz
x,y,z
-x,-y,-z
"""

if __name__ == "__main__":
  exercise(sys.argv[1:])
  print("OK")


 *******************************************************************************


 *******************************************************************************
iotbx/cif/validation.py
from __future__ import absolute_import, division, print_function
from cctbx.array_family import flex
from iotbx.cif import builders, model, errors
import libtbx.load_env
from libtbx import smart_open
import copy
import os
import shutil
import re
import sys
from six import string_types
from six.moves.urllib.request import urlopen
from six.moves import zip
import six


class ErrorHandler:
  """An error handler for the validator. This class can be subclassed by clients
  that want to use their own error handlers"""

  def __init__(self):
    self.reset()

  def warning(self, w):
    self._add_warning(w)

  def error(self, e):
    self._add_error(e)

  def reset(self):
    self.warning_count = 0
    self.error_count = 0
    self.errors = {}
    self.warnings = {}

  def _add_warning(self, w):
    self.warning_count += 1
    if w.code in self.warnings:
      self.warnings[w.code].append(w)
    else:
      self.warnings.setdefault(w.code, [w])

  def _add_error(self, e):
    self.error_count += 1
    if e.code in self.errors:
      self.errors[e.code].append(e)
    else:
      self.errors.setdefault(e.code, [e])

  def show(self, show_warnings=True, out=None):
    if out is None:
      out = sys.stdout
    codes = list(self.errors.keys())
    errors = list(self.errors.values())
    if show_warnings:
      codes.extend(list(self.warnings.keys()))
      errors.extend(list(self.warnings.values()))
    for code, errs in zip(codes, errors):
      printed_messages = set()
      for e in errs:
        if str(e) not in printed_messages: # avoid printing duplicates
          printed_messages.add(str(e))
          print(e, file=out)


class ValidationError(Exception):
  def __init__(self, code, format_string, **kwds):
    self.code = code
    self.format_string = format_string
    self.kwds = kwds

  def __str__(self):
    return self.format_string %self.kwds



cifdic_register_url = "ftp://ftp.iucr.org/pub/cifdics/cifdic.register"

def smart_load_dictionary(name=None, file_path=None, url=None,
                          registry_location=cifdic_register_url,
                          save_local=False, store_dir=None):
  from iotbx import cif
  assert [name, file_path, url].count(None) < 3
  cif_dic = None
  if store_dir is None:
    store_dir = libtbx.env.under_dist(
      module_name='iotbx', path='cif/dictionaries')
  if name is not None and [file_path, url].count(None) == 2:
    if file_path is None:
      if os.path.isfile(name):
        file_path = name
      else:
        file_path = os.path.join(store_dir, name)
      if not os.path.isfile(file_path):
        gzip_path = file_path + '.gz'
        if os.path.isfile(gzip_path):
          if save_local:
            gz = smart_open.for_reading(gzip_path)
            f = smart_open.for_writing(file_path)
            shutil.copyfileobj(gz, f)
            gz.close()
            f.close()
          else:
            file_path = gzip_path
  if file_path is not None and os.path.isfile(file_path):
    file_object = smart_open.for_reading(file_path)
    cif_dic = dictionary(cif.reader(file_object=file_object).model())
    file_object.close()
  else:
    if url is None:
      url = locate_dictionary(name, registry_location=registry_location)
    file_object = urlopen(url)
    if save_local:
      if name is None:
        name = os.path.basename(url)
      f = open(os.path.join(store_dir, name), 'wb')
      shutil.copyfileobj(file_object, f)
      f.close()
      cif_dic = dictionary(cif.reader(
        file_path=os.path.join(store_dir, name)).model())
    else:
      cif_dic = dictionary(cif.reader(
        file_object=file_object).model())
  assert cif_dic is not None
  return cif_dic

def locate_dictionary(name, version=None, registry_location=cifdic_register_url):
  from iotbx import cif
  cm = cif.reader(file_object=urlopen(registry_location)).model()
  if version is None: version = '.'
  reg = cm["validation_dictionaries"]
  for n, v, url in zip(reg['_cifdic_dictionary.name'],
                       reg['_cifdic_dictionary.version'],
                       reg['_cifdic_dictionary.URL']):
    if n == name and v == str(version):
      return url


class dictionary(model.cif):

  def __init__(self, other):
    model.cif.__init__(self, other.blocks)
    self.item_type_list = {}
    self.child_parent_relations = {}
    self.look_up_table = {} # cached definitions for each data name
    if 'on_this_dictionary' in self:
      self.DDL_version = 1
      for key, value in six.iteritems(self.blocks):
        self[key] = DDL1_definition(value)
      on_this_dict = self['on_this_dictionary']
      self.name = on_this_dict['_dictionary_name']
      self.version = on_this_dict['_dictionary_version']
    else:
      self.DDL_version = 2
      master_block = list(self.values())[0]
      self.name = master_block['_dictionary.title']
      self.version = master_block['_dictionary.version']
      type_codes = master_block.get('_item_type_list.code')
      type_constructs = master_block.get('_item_type_list.construct')
      for code, construct in zip(type_codes, type_constructs):
        self.item_type_list.setdefault(code, re.compile(construct))
      for key, save in six.iteritems(master_block.saves):
        master_block[key] = DDL2_definition(save)
        children = save.get('_item_linked.child_name')
        parents = save.get('_item_linked.parent_name')
        if parents is not None and children is not None:
          if not isinstance(parents, string_types):
            for child, parent in zip(children, parents):
              self.child_parent_relations.setdefault(child, parent)
    self.err = ErrorHandler()
    language = "en"
    self.errors = errors.error_dicts[language]

  def set_error_handler(self, handler):
    self.err = handler

  def report_error(self, number, **kwds):
    message = self.errors[number]
    if number < 2000:
      self.err.warning(ValidationError(number, message, **kwds))
    elif number < 3000:
      self.err.error(ValidationError(number, message, **kwds))

  def find_definition(self, key):
    """Returns the name of the data block containing the definition for the
       given key.  Raises a KeyError if item not found."""
    if self.DDL_version == 1:
      if key in self.look_up_table:
        return self.look_up_table[key]
      key_ = key.lstrip("_")
      data = self.get(key_) # try simplest first
      # then try shortening key
      while data is None:
        new_key = key_[:key_.rfind("_", 0, -1)+1]
        if new_key == key_: break
        data = self.get(new_key)
        if data is not None and key not in data['_name']:
          data = None
        key_ = new_key
      if data is not None:
        self.look_up_table.setdefault(key, key_)
        return key_
      # otherwise we have to check every block in turn
      else:
        for k, v in six.iteritems(self):
          if k == 'on_this_dictionary': continue
          elif isinstance(v['_name'], string_types):
            if v['_name'] == key:
              self.look_up_table.setdefault(key, key_)
              return k
          elif key in v['_name']:
            self.look_up_table.setdefault(key, key_)
            return k
        self.report_error(1001, key=key) # item not in dictionary
        raise KeyError(key)
    else:
      if key not in list(self.values())[0]:
        self.report_error(1001, key=key) # item not in dictionary
        raise KeyError(key)
      else:
        return key

  def get_definition(self, key):
    if self.DDL_version == 1:
      return self[self.find_definition(key)]
    elif self.DDL_version == 2:
      return list(self.values())[0][self.find_definition(key)]

  def validate_single_item(self, key, value, block):
    try:
      definition = self.get_definition(key)
    except KeyError: return
    self.validate_type(key, value, definition)
    self.validate_enumeration(key, value, definition)
    self.validate_related(key, block, definition)
    self.validate_dependent(key, block, definition)
    _list = definition.get("_list")
    if _list == 'yes':
      self.report_error(2506, key=key) # must be in looped list

  def validate_type(self, key, value, definition):
    if value in ('?', '.'): return
    item_type = definition.type
    if item_type in self.item_type_list:
      match = re.match(self.item_type_list[item_type], value)
      if match is None:
        self.report_error(2001, key=key, value=value, item_type=item_type)
    elif item_type == 'numb':
      # only for DDL1
      try:
        builders.float_from_string(value)
      except Exception as e:
        # can't interpret as numb
        self.report_error(2001, key=key, value=value, item_type=definition.type)
      else:
        # check any type conditions
        type_condition = definition.type_conditions
        if type_condition not in ('esd', 'su'):
          try:
            float(value)
          except Exception as e:
            # if we have got here, then from the data type checking we can assume
            # that the value is given with an esd, which causes it to be invalid.
            self.report_error(2002, key=key)

  def validate_dependent(self, key, block, definition):
    dependents = definition.dependent
    if dependents is None: return
    elif isinstance(dependents, string_types):
      dependents = [dependents]
    for dependent in dependents:
      if dependent not in block:
        self.report_error(2301, dependent=dependent, key=key)

  def validate_enumeration(self, key, value, definition):
    if isinstance(value, string_types):
      values = [value]
    else:
      values = value
    enum_values = definition.enumeration
    enum_min, enum_max = definition.get_min_max()
    if enum_values is None and enum_max is None and enum_min is None:
      return # nothing to check
    for value in values:
      if value in ('.', '?'): continue
      elif enum_values is not None and value not in enum_values:
        enum_lower = [v.lower() for v in enum_values]
        if value.lower() in enum_lower:
          self.report_error(1002, key=key, value=value) # case sensitive match failure
        else:
          # invalid choice for enumeration
          self.report_error(2102, key=key, value=value, enum=tuple(enum_values))
      if definition.type in ('numb', 'float', 'int'):
        try:
          v = builders.float_from_string(value)
        except Exception: return # this error is handled with elsewhere
        # DDL1 range is inclusive, DDL2 is exclusive
        if self.DDL_version == 1:
          if not ((enum_min is None or v >= float(enum_min)) and
                  (enum_max is None or v <= float(enum_max))):
            self.report_error(
              2101, key=key, value=value, enum="%s:%s" %(enum_min, enum_max))
        else:
          if enum_min is None and enum_max is None: return
          elif enum_min is None:
            enum_min = '.'*len(enum_max)
          elif enum_max is None:
            enum_max = '.'*len(enum_min)
          for min, max in zip(enum_min, enum_max):
            if ((min == '.' or v > float(min)) and
                (max == '.' or v < float(max))):
              return # at least one condition was met, so value is inside range
            elif (min == max and v == float(min)):
              return # matched boundary value
          # else value out of range
          self.report_error(2101, key=key, value=value, enum="%s:%s" %(min, max))

  def validate_related(self, key, block, definition):
    related_items = definition.related
    related_functions = definition.related_function
    if related_items is not None and related_functions is not None:
      if (isinstance(related_items, string_types) and
          isinstance(related_functions, string_types)):
        related_items = [related_items]
        related_functions = [related_functions]
      for related_item, related_function in zip(related_items, related_functions):
        if related_function == 'replace':
          if block.get(related_item) is not None:
            self.report_error(2201, key=key, related_item=related_item)
          else: # obsolete definition warning
            self.report_error(1003, key=key, related_item=related_item)
        elif (related_function == 'alternate_exclusive' and
              related_item in block):
          self.report_error(2201, key=key, related_item=related_item)
        elif related_function == 'replacedby': # obsolete definition warning
          self.report_error(1003, key=key, related_item=related_item)
        elif (related_function == 'associated_value' and
              related_item not in block): # missing associated value
          self.report_error(2202, key=key, related_item=related_item)

  def validate_loop(self, loop, block):
    list_category = None
    for key, value in six.iteritems(loop):
      try:
        definition = self.get_definition(key)
      except KeyError: continue
      self.validate_enumeration(key, value, definition)
      self.validate_dependent(key, block, definition)
      self.validate_related(key, block, definition)
      _list = definition.get("_list")
      if self.DDL_version == 1 and _list in ('no', None):
        self.report_error(2501, key=key) # not allowed in list
      definition_category = definition.category
      if (definition_category is not None and
          not isinstance(definition_category, string_types)):
        definition_name = definition.name
        i = flex.first_index(definition_name, key)
        definition_category = definition_category[i]
      if list_category is None:
        list_category = definition_category
      elif (isinstance(list_category, string_types)
            and definition_category is not None
            and list_category != definition_category):
        print(list_category, list(definition_category))
        self.report_error(2502, key=key) # multiple categories in loop
      mandatory = definition.mandatory == 'yes'
      references = definition.get('_list_reference')
      if references is not None:
        if isinstance(references, string_types):
          references = [references]
        for reference in references:
          try:
            ref_data = self.get_definition(reference)
          except KeyError:
            ref_data = self.get_definition(key)
          ref_names = ref_data['_name']
          if isinstance(ref_names, string_types):
            ref_names = [ref_names]
          for name in ref_names:
            if name not in loop:
              self.report_error(2505, key=key, reference=name) # missing _list_reference
      elif (self.DDL_version == 2
            and isinstance(definition.category, string_types)):
        category_def = self.get_definition(definition.category)
        if category_def.category_key is not None:
          category_keys = category_def.category_key
          if isinstance(category_keys, string_types):
            category_keys = [category_keys]
          for cat_key in category_keys:
            cat_key_def = self.get_definition(cat_key)
          if (cat_key_def.mandatory == 'yes'
              and isinstance(cat_key_def.mandatory, string_types)
              and cat_key_def.name not in block):
            self.report_error(
              2203, key=cat_key_def.name, category=definition.category)
      #
      link_parent = definition.get(
        '_list_link_parent', self.child_parent_relations.get(key))
      if link_parent is not None:
        parent_values = loop.get(link_parent, block.get(link_parent))
        if parent_values is not None:
          for v in loop[key]:
            if v != '.' and v not in parent_values:
              # missing parent value
              self.report_error(2503, value=v, child=key, parent=link_parent)
        else:
          self.report_error(2504, child=key, parent=link_parent) # missing parent

  def update(self, other, mode="strict"):
    assert mode in ("strict", "replace", "overlay")
    assert self.DDL_version == other.DDL_version
    if self.DDL_version == 1:
      for k, v in six.iteritems(other):
        if k == "on_this_dictionary": continue
        name = v.name
        try:
          block_name_self = self.find_definition(name)
        except KeyError:
          block_name_self = None
        if mode == "strict":
          assert block_name_self is None and k not in v
          self[k] = v
        elif mode == "replace":
          if block_name_self is not None:
            self[block_name_self] = v
          else:
            self[k] = v
        elif mode == "overlay":
          if block_name_self is not None:
            self[block_name_self].update(v)
          else:
            self[k] = v
    elif self.DDL_version == 2:
      master_block = list(self.values())[0]
      for k, v in six.iteritems(list(other.values())[0].saves):
        #name = v["_item.name"]
        name = k
        try:
          save_name_self = self.find_definition(name)
        except KeyError:
          save_name_self = None
        if mode == "strict":
          assert save_name_self is None and k not in v
          master_block[k] = v
        elif mode == "replace":
          if save_name_self is not None:
            master_block[save_name_self] = v
          else:
            master_block[k] = v
        elif mode == "overlay":
          if save_name_self is not None:
            master_block[save_name_self].update(v)
          else:
            master_block[k] = v
  def __copy__(self):
    return dictionary(model.cif.copy(self))

  copy = __copy__

  def __deepcopy__(self, memo):
    return dictionary(model.cif.__deepcopy__(self, memo))

class definition_base:

  def name(self):
    return self.get(self.aliases['name'])

  def type(self):
    return self.get(self.aliases['type'])

  def type_conditions(self):
    return self.get(self.aliases['type_conditions'])

  def category(self):
    return self.get(self.aliases['category'])

  def category_key(self):
    return self.get(self.aliases['category_key'])

  def mandatory(self):
    return self.get(self.aliases['mandatory'])

  def enumeration(self):
    return self.get(self.aliases['enumeration'])

  def dependent(self):
    return self.get(self.aliases['dependent'])

  def related(self):
    return self.get(self.aliases['related'])

  def related_function(self):
    return self.get(self.aliases['related_function'])

  name = property(name)
  type = property(type)
  type_conditions = property(type_conditions)
  category = property(category)
  category_key = property(category_key)
  mandatory = property(mandatory)
  enumeration = property(enumeration)
  dependent = property(dependent)
  related = property(related)
  related_function = property(related_function)

class DDL1_definition(model.block, definition_base):

  aliases = {
  'name': '_name',
  'type': '_type',
  'type_conditions': '_type_conditions',
  'category': '_category',
  'category_key': 'XXX',
  'mandatory': '_list_mandatory',
  'enumeration': '_enumeration',
  'related': '_related_item',
  'related_function': '_related_function',
  }

  def __init__(self, other=None):
    model.block.__init__(self)
    if other is not None:
      self._items = other._items
      self.loops = other.loops
      self.saves = other.saves
      self._set = other._set
      self.keys_lower = other.keys_lower

  def dependent(self):
    return None
  dependent = property(dependent)

  def get_min_max(self):
    enum_range = self.get('_enumeration_range')
    if enum_range is not None:
      enum_min, enum_max = enum_range.split(':')
      if enum_min == '': enum_min = None
      if enum_max == '': enum_max = None
      return (enum_min, enum_max)
    else:
      return (None, None)

class DDL2_definition(model.save, definition_base):

  aliases = {
  'name': '_item.name',
  'type': '_item_type.code',
  'type_conditions': '_item_type_conditions.code',
  'category': '_item.category_id',
  'category_key': '_category_key.name',
  'mandatory': '_item.mandatory_code',
  'enumeration': '_item_enumeration.value',
  'dependent': '_item_dependent.dependent_name',
  'related': '_item_related.related_name',
  'related_function': '_item_related.function_code',
  }

  def __init__(self, other=None):
    model.save.__init__(self)
    if other is not None:
      self._items = other._items
      self.loops = other.loops
      self._set = other._set
      self.keys_lower = other.keys_lower

  def get_min_max(self):
    return (self.get('_item_range.minimum'), self.get('_item_range.maximum'))


 *******************************************************************************
