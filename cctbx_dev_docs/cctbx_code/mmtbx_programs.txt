

 *******************************************************************************
mmtbx/programs/__init__.py


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/arginine_geometry.py
from __future__ import absolute_import, division, print_function

from libtbx.program_template import ProgramTemplate
from cctbx import geometry_restraints

from cctbx.array_family import flex
from libtbx.utils import null_out

limits = {
  ('CD', 'NE', 'CZ', 'NH1')  : 10,
  ('CD', 'NE', 'CZ', 'NH2')  : 10,
  ('NE', 'CZ', 'NH1', 'NH2') : 2,
  ('NE', 'CZ', 'NH1', 'HH11'): 1,
  ('NE', 'CZ', 'NH1', 'HH12'): 1,
  ('NE', 'CZ', 'NH2', 'HH21'): 1,
  ('NE', 'CZ', 'NH2', 'HH22'): 1,
  #
  ('CD', 'NE', 'CZ', 'NH?')  : 10,
  ('NE', 'CZ', 'NHn', 'HHn?'): 1,
  }

def get_torsion_deviations(v):
  if v<-90: v+=360
  if v>90: v-=180
  return v

def get_atoms_key(atoms):
  if atoms[3].find('HH')>-1: return ('NE', 'CZ', 'NHn', 'HHn?')
  if atoms[0]=='CD': return ('CD', 'NE', 'CZ', 'NH?')
  return atoms

def format_atoms(t):
  outl = ''
  for atom in t:
    outl += '%4s -' % atom
  return outl[:-1]

def format_values(v):
  outl = ''
  for attr, value in zip(['mean', 'min', 'max'], v):
    outl += ' %s: %4.1f' % (attr, value)
  return outl

def format_annotation(values):
  limit = limits.get(atoms, 1e9)
  ann = ''
  if abs(values[1])>limit: ann+='<'
  if values[2]>limit: ann+='>'
  return ann

class arginine_deviations(dict):
  def __repr__(self):
    outl = 'ARG devs\n'
    outl += '  Number of ARG : %s\n' % len(self)
    current = getattr(self, 'atoms',{})
    if current: outl += '  Stats\n'
    for atoms, values in current.items():
      outl += '  %s ~> %s %s\n' % (
        format_atoms(atoms),
        format_values(values),
        format_annotation(values),
        )
    return outl

  def process(self):
    self.data = {}
    for residue, chis in self.items():
      for atoms, chi in chis.items():
        key = get_atoms_key(atoms)
        self.data.setdefault(key, flex.float())
        self.data[key].append(get_torsion_deviations(chi))
    self.atoms = {}
    for atoms, chis in self.data.items():
      self.atoms[atoms]=[flex.mean(chis), flex.min(chis), flex.max(chis)]

class plane_torsion_deviations(arginine_deviations):
  def __init__(self, print_torsion_limit=1., print_torsion_number=10):
    self.print_torsion_limit=print_torsion_limit
    self.print_torsion_number=print_torsion_number

  def __repr__(self):
    tmp = dict(sorted(self.items(), reverse=True, key=lambda item: abs(item[1][0])))
    outl = 'Plane Torsion Deviations\n'
    outl += '  Number : %s\n' % len(self)
    i=0
    for key, item in tmp.items():
      if abs(item[0])<self.print_torsion_limit: continue
      i+=1
      outl += '    %s : %5.1f %s\n' % (key, item[0], '*' if item[1] else '')
      if i>= self.print_torsion_number: break
    return outl

  def is_possible_reduce(self):
    rc=0
    for key, item in self.items():
      if not item[1]: continue
      if abs(item[0])>1.:
        rc+=1
    return rc

class Program(ProgramTemplate):

  description = '''
mmtbx.arginine_geometry:

Usage examples:
  mmtbx.arginine_geometry model.pdb
  '''

  datatypes = ['model', 'phil']

  master_phil_str = """
  arginine {
    selection = None
      .type = atom_selection
      .help = what to select
      .multiple = True
    exclude_hydrogen = False
      .type = bool
    print_torsion_limit = 1.
      .type = float
    print_torsion_number = 10
      .type = int
  }
"""

  # ---------------------------------------------------------------------------
  def validate(self):
    # print('Validating inputs', file=self.logger)
    pass

  def arginine_simple(self):
    model = self.data_manager.get_model()
    hierarchy = model.get_hierarchy()
    for residue_group in hierarchy.residue_groups():
      if len(residue_group.atom_groups())>1: continue
      atom_group = residue_group.atom_groups()[0]
      if atom_group.resname!='ARG': continue
      current = self.results.setdefault(atom_group.id_str(), {})
      for torsion_atom_names in limits:
        torsion_xyzs = []
        for atom in torsion_atom_names:
          ta = atom_group.get_atom(atom)
          if ta is None:
            torsion_xyzs=[]
            break
          torsion_xyzs.append(ta.xyz)
        if not torsion_xyzs: continue
        v = geometry_restraints.dihedral(sites=torsion_xyzs, angle_ideal=0, weight=1).angle_model
        current[tuple(torsion_atom_names)]=v
    self.results.process()

  def torsions_in_planes(self, exclude_hydrogen=False):
    model = self.data_manager.get_model()
    model.set_log(null_out())
    model.process(make_restraints=True)
    grm = model.get_restraints_manager()
    atoms = model.get_hierarchy().atoms()
    plane_i_seqs = []
    remove = []
    for i, plane in enumerate(grm.geometry.planarity_proxies):
      plane_i_seqs.append(set(plane.i_seqs))
      torsion_xyzs = []
      torsion_quotes = []
      for i_seq in plane.i_seqs:
        torsion_xyzs.append(atoms[i_seq].xyz)
        torsion_quotes.append(atoms[i_seq].quote()[8:])
        if len(torsion_xyzs)==4:
          v = geometry_restraints.dihedral(sites=torsion_xyzs, angle_ideal=0, weight=1).angle_model
          v=get_torsion_deviations(v)
          if abs(v)>1: break
          del torsion_xyzs[0]
          del torsion_quotes[0]
      else:
        remove.append(i)
    if remove:
      remove.reverse()
      for r in remove:
        del plane_i_seqs[r]
    data = {}
    for torsion in grm.geometry.dihedral_proxies:
      for plane in plane_i_seqs:
        if len(plane.intersection(set(torsion.i_seqs)))==4:
          torsion_xyzs = []
          torsion_strs = ''
          h_atom = False
          for i_seq in torsion.i_seqs:
            atom = atoms[i_seq]
            if atom.element_is_hydrogen(): h_atom=True
            torsion_xyzs.append(atom.xyz)
            torsion_strs += '%s - ' % (atom.id_str()[4:])
          if exclude_hydrogen and h_atom: continue
          v = geometry_restraints.dihedral(sites=torsion_xyzs, angle_ideal=0, weight=1).angle_model
          v = get_torsion_deviations(v)
          self.results[torsion_strs[:-2]]=[v, h_atom]

  # ---------------------------------------------------------------------------
  def run(self, log=None):
    # self.results = arginine_deviations()
    # self.arginine_simple()
    self.results = plane_torsion_deviations(self.params.arginine.print_torsion_limit,
                                            self.params.arginine.print_torsion_number)
    self.torsions_in_planes(self.params.arginine.exclude_hydrogen)
    print('\n%s' % self.results, file=log)
    reduce_H_atoms = self.results.is_possible_reduce()
    print('  Has reduce-like H atoms : %s\n' % reduce_H_atoms if reduce_H_atoms else '', file=log)

  # ---------------------------------------------------------------------------
  def get_results(self):
    return self.results


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/atom_selection.py
from __future__ import absolute_import, division, print_function

from libtbx.program_template import ProgramTemplate
from libtbx.utils import plural_s
from cctbx.array_family import flex
from cctbx import crystal, uctbx, xray
from libtbx.utils import Sorry
from cctbx.maptbx.box import shift_and_box_model

class Program(ProgramTemplate):

  description = '''
phenix.pdb_atom_selection: tool for selecting some atoms and optionally
  write out them as a PDB file

Usage examples:
  phenix.pdb_atom_selection model.pdb "chain A"
  phenix.pdb_atom_selection model.pdb "chain A" --write-pdb-file=sel.pdb
  '''

  datatypes = ['model', 'phil']

  master_phil_str = """
  atom_selection_program {
    inselection = None
      .type = atom_selection
      .help = what to select
      .multiple = True
    cryst1_replacement_buffer_layer = None
      .type = float
      .help = replace original symmetry with P1 and size that is sufficient to \
        place molecule and surround it with this amount of empty space
    write_pdb_file = None
      .type = path
  }
"""

  # ---------------------------------------------------------------------------
  def validate(self):
    print('Validating inputs', file=self.logger)
    self.data_manager.has_models(raise_sorry=True)
    if (self.params.atom_selection_program.inselection is None or
        len(self.params.atom_selection_program.inselection) == 0):
      raise Sorry("Need selections")

  # ---------------------------------------------------------------------------
  def run(self):
    # I'm guessing self.data_manager, self.params and self.logger
    # are already defined here...

    # this must be mmtbx.model.manager?
    model = self.data_manager.get_model()
    atoms = model.get_atoms()
    all_bsel = flex.bool(atoms.size(), False)
    for selection_string in self.params.atom_selection_program.inselection:
      print("Selecting '%s'" % selection_string, file=self.logger)
      isel = model.iselection(string=selection_string)
      all_bsel.set_selected(isel, True)
      if self.params.atom_selection_program.write_pdb_file is None:
        print("  %d atom%s selected" % plural_s(isel.size()), file=self.logger)
        for atom in atoms.select(isel):
          print ("    %s" % atom.format_atom_record(), file=self.logger)
    print("", file=self.logger)
    if self.params.atom_selection_program.write_pdb_file is not None:
      ss_ann = model.get_ss_annotation()
      if not model.crystal_symmetry() or \
        (not model.crystal_symmetry().unit_cell()):
        model = shift_and_box_model(model, shift_model=False)
      selected_model = model.select(all_bsel)
      if(ss_ann is not None):
        selected_model.set_ss_annotation(ss_ann.\
            filter_annotation(
                hierarchy=selected_model.get_hierarchy(),
                asc=selected_model.get_atom_selection_cache(),
                remove_short_annotations=False,
                remove_3_10_helices=False,
                remove_empty_annotations=True,
                concatenate_consecutive_helices=False,
                split_helices_with_prolines=False,
                filter_sheets_with_long_hbonds=False))
      if self.params.atom_selection_program.cryst1_replacement_buffer_layer is not None:
        box = uctbx.non_crystallographic_unit_cell_with_the_sites_in_its_center(
            sites_cart=selected_model.get_atoms().extract_xyz(),
            buffer_layer=self.params.atom_selection_program.cryst1_replacement_buffer_layer)
        sp = crystal.special_position_settings(box.crystal_symmetry())
        sites_frac = box.sites_frac()
        xrs_box = selected_model.get_xray_structure().replace_sites_frac(box.sites_frac())
        xray_structure_box = xray.structure(sp, xrs_box.scatterers())
        selected_model.set_xray_structure(xray_structure_box)
      written_fname = self.data_manager.write_model_file(
          model_str=selected_model,
          filename=self.params.atom_selection_program.write_pdb_file)
      print("Wrote file: %s" % written_fname, file=self.logger)
      print("", file=self.logger)

  # ---------------------------------------------------------------------------
  def get_results(self):
    return None


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/barbed_wire_analysis.py
from __future__ import absolute_import, division, print_function
import sys
from libtbx.program_template import ProgramTemplate

from mmtbx.validation import barbed_wire_analysis

version = "1.0.0"

master_phil_str = '''
profile = False
  .type = bool
  .short_caption = Profile the run
  .help = Profile the performance of the entire run

output
  .style = menu_item auto_align
{
  type = *text kin selection_string selection_file json
    .type = choice
    .help = """choose output type"""
  file_name = None
    .type = str
    .short_caption = Output file name
    .help = Output file name
  filename = None
    .type = str
    .short_caption = Output file name
    .help = Output file name, optional spelling
  modes = *1 2 *3 4 5 6
    .type = choice(multi=True)
    .short_caption = Choose modes for selection string or file
    .help = Choose modes for selection string or file, subset of 123456, joined by +, eg 1+3
}
''' #+ Helpers.probe_phil_parameters

class Program(ProgramTemplate):
  description = '''
barbed_wire_analysis

This is a tool for identifying barbed wire, near-folded, and other behaviors within AlphaFold2 predicted models

output.type = *text kin selection_string selection_file json
output.file_name= (optional, prints to sys.stdout by default)

pdb or mmcif of residues matching selected behaviors can be printed with output.type=selection_file
output.modes = may be used to choose the printed behaviors with a string of numbers joined by +
1 = Predictive
2 = Unpacked high pLDDT
3 = Near-predictive
4 = Pseudostructure
5 = Barbed wire
6 = Unphysical
output.modes=1+3 is the default, and prints predictive + near-predictive

Examples:
phenix.barbed_wire_analysis your_prediction.pdb
phenix.barbed_wire_analysis your_prediction.pdb output.type=json output.filename=your_prediction_annotation.json
phenix.barbed_wire_analysis your_prediction.pdb output.type=kin output.file_name=your_prediction_markup.kin
phenix.barbed_wire_analysis your_prediction.pdb output.type=selection_file output.file_name=your_prediction_useful_parts.pdb
phenix.barbed_wire_analysis your_prediction.pdb output.type=selection_file modes=4+5+6 output.file_name=your_prediction_nonpredictive_only.pdb
'''
  datatypes = ['model', 'restraint', 'phil']
  master_phil_str = master_phil_str
  data_manager_options = ['model_skip_expand_with_mtrix',
                          'model_skip_ss_annotations']
  def validate(self):
    self.data_manager.has_models(raise_sorry=True)

  def run(self):
    model = self.data_manager.get_model()
    bwa = barbed_wire_analysis.barbed_wire_analysis(model)
    if self.params.output.file_name:
      out = open(self.params.output.file_name, "w")
    elif self.params.output.filename:
      out = open(self.params.output.filename, "w")
    else:
      out = sys.stdout
    if self.params.output.type == "text":
      bwa.as_text_chunks(out)
    elif self.params.output.type == "json":
      bwa.as_json(out)
    elif self.params.output.type == "kin":
      bwa.as_kinemage(out)
    elif self.params.output.type == "selection_string":
      print(bwa.as_selection_string(modes=self.params.output.modes), file=out)
    elif self.params.output.type == "selection_file":
      import os
      #Extension detection taken from mmtbx.pdbtools - output matches input
      input_file_name_base = os.path.basename(
        self.data_manager.get_default_model_name())[:-4]
      if(  model.input_model_format_cif()) or (
         not model.can_be_output_as_pdb()):
            extension = ".cif"
      elif(model.input_model_format_pdb()): extension = ".pdb"
      else:
        assert model.input_model_format_pdb() or \
          model.input_model_format_cif()
      bwa.as_selection_file(model, out, modes=self.params.output.modes, extension=extension)


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/cablam.py
from __future__ import absolute_import, division, print_function

import os
from mmtbx.validation.cablam import cablamalyze
from datetime import datetime
from libtbx.program_template import ProgramTemplate
try:
  from phenix.program_template import ProgramTemplate
except ImportError:
  pass
#from libtbx.utils import Sorry

class Program(ProgramTemplate):
  prog = os.getenv('LIBTBX_DISPATCHER_NAME')
  description="""
  %(prog)s file.pdb [options ...]

Options:

  output=          text : default output.  Prints machine-readable
                          columnated and colon-separated validation text to
                          screen.
                        json : prints results as JSON compatible dictionary
                        kin : prints kinemage markup for validation to screen
                        full_kin : prints kinemage markup and struture kinamge
                          to screen
                        points_kin : prints point cloud of residues in cablam
                          space in kinemage format
                        records : prints pdb-style HELIX and SHEET records to
                          screen, based on CaBLAM's identification of secondary
                          structure
                        records_and_pdb : prints pdb-style HELIX and SHEET
                          records to screen, followed by PDB file formatted
                          coordinates for the input structure
                        oneline : prints single-line summary of CaBLAM
                          validation statistics

  outliers_only=False   compresses certain outputs (text) to show only outlier
                          residues



Example:

  %(prog)s model=1ubq.pdb outliers_only=True
""" % locals()

  master_phil_str = """
  include scope mmtbx.validation.molprobity_cmdline_phil_str
  json = False
    .type = bool
    .help = "Prints results as JSON format dictionary"
  pdb_infile = None
    .type = path
    .help = input PDB file
  output_type = *text kin full_kin points_kin records records_and_pdb oneline
    .type = choice
    .help = choose output type: \
     =text for default colon-separated residue-by-residue validation \
     =kin for outlier markup in kinemage format \
     =full_kin for outlier markup appended to structure - opens in KiNG \
     =points_kin for pointcloud in cablam space \
     =records for PDB-style HELIX/SHEET records \
     =records_and_pdb for PDB-style HELIX/SHEET records attached to a PDB file \
     =oneline for a one-line structure summary
"""
  datatypes = ['model','phil']
  data_manager_options = ['model_skip_expand_with_mtrix']
  known_article_ids = ['molprobity']

#TODO: get cablam.interpretation() to print again

  def validate(self):
    self.data_manager.has_models(raise_sorry=True)

  def run(self):
    hierarchy = self.data_manager.get_model().get_hierarchy()
    self.info_json = {"model_name":self.data_manager.get_default_model_name(),
                      "time_analyzed": str(datetime.now())}
    self.cablam = cablamalyze(
      pdb_hierarchy=hierarchy,
      outliers_only=self.params.outliers_only,
      out=self.logger,
      quiet=False)

    #output_type = *text kin full_kin points_kin records records_and_pdb oneline
    if self.params.json:
      print(self.get_results_as_JSON())
    elif self.params.output_type=='oneline':
      pdb_file_str = os.path.basename(self.data_manager.get_model_names()[0])
      self.cablam.as_oneline(pdbid=pdb_file_str)
    elif self.params.output_type=='kin':
      self.cablam.as_kinemage()
    elif self.params.output_type=='full_kin':
      self.cablam.as_full_kinemage(pdbid=pdbid)
    elif self.params.output_type=='points_kin':
      self.cablam.as_pointcloud_kinemage()
    elif self.params.output_type=='records':
      self.cablam.as_records()
    elif self.params.output_type=='records_and_pdb':
      self.cablam.as_records_and_pdb()
    else: #default text output
      self.cablam.as_text(outliers_only=self.params.outliers_only)

  def get_results(self):
    return self.cablam

  def get_results_as_JSON(self):
    return self.cablam.as_JSON(self.info_json)


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/cablam_idealization.py
# -*- coding: utf-8 -*-
from __future__ import absolute_import, division, print_function

from libtbx.program_template import ProgramTemplate

from mmtbx.building import cablam_idealization

import os

# =============================================================================

class Program(ProgramTemplate):

  description = '''
phenix.cablam_idealization: tool for sampling different conformations in attempt to
  fix Cablam outliers.

Usage examples:
  phenix.cablam_idealization model.pdb
  phenix.cablam_idealization model.cif
  '''

  datatypes = ['model', 'phil']

  master_phil_str = """
include scope mmtbx.building.cablam_idealization.master_phil_str
output {
  suffix = _cablam_fixed
    .type = str
}
  """

  # ---------------------------------------------------------------------------
  def validate(self):
    print('Validating inputs', file=self.logger)
    self.data_manager.has_models(raise_sorry=True)

  # ---------------------------------------------------------------------------
  def run(self):
    # I'm guessing self.data_manager, self.params and self.logger
    # are already defined here...
    print('Using model: %s' % self.data_manager.get_default_model_name(), file=self.logger)

    # this must be mmtbx.model.manager?
    model = self.data_manager.get_model()

    self.output_fname_base = os.path.splitext(
        self.data_manager.get_default_model_name())[0] + self.params.output.suffix
    fo = open(self.output_fname_base+'.log', 'w')
    self.logger.register(label='logfile', file_object=fo)

    self.cablam_id = cablam_idealization.cablam_idealization(
        model=model,
        params = self.params.cablam_idealization,
        log = self.logger)

    results = self.cablam_id.get_results()
    print("Total number of tried outliers: %d" % results.n_tried_residues, file=self.logger)
    print("Number of rotated outliers: %d" % results.n_rotated_residues, file=self.logger)
    # I believe this should go to data_manager. Also not clear how output of
    # two files would affect data_manager.
    for m, fname_base in [
        (results.model, self.output_fname_base),
        (results.model_minimized, self.output_fname_base+"_minimized")]:
      if m is not None:
        self.final_file_name = self.data_manager.write_model_file(
            m, fname_base)
        print("Model written to '%s'" % self.final_file_name)

  # ---------------------------------------------------------------------------
  def get_results(self):
    return self.cablam_id.get_results()

# =============================================================================
# end


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/cbetadev.py
from __future__ import absolute_import, division, print_function

import os
from mmtbx.validation.cbetadev import cbetadev
from libtbx.program_template import ProgramTemplate
#from libtbx.utils import Sorry
from datetime import datetime

class Program(ProgramTemplate):
  prog = os.getenv('LIBTBX_DISPATCHER_NAME')
  description="""
  %(prog)s file.pdb [params.eff] [options ...]

Calculates ideal CB atom position based on mainchain geometry,
then displays deviation of modeled CB from that ideal positon.
Deviations of >= 0.25A are considered outliers

Options:

  model=input_file      input PDB file
  output=text, kin, or bullseye    select type of output
  json=False            Outputs results as JSON compatible dictionary
  outliers_only=False   suppress non-outlier results

Example:

  %(prog)s model=1ubq.pdb
""" % locals()

  master_phil_str = """
  include scope mmtbx.validation.molprobity_cmdline_phil_str
    json = False
      .type = bool
      .help = "Prints results as JSON format dictionary"
    cbetadev {
      output = *text kin bullseye
        .type = choice
        .help = '''choose output type'''
      apply_phi_psi_correction = False
        .type = bool
        .help = XXX
      display_phi_psi_correction = False
        .type = bool
        .help = XXX
      exclude_d_peptides = False
        .type = bool
        .style = hidden
        .help = Attempts to exclude D-peptide using the large CBD
      }
"""
  datatypes = ['model','phil']
  data_manager_options = ['model_skip_expand_with_mtrix']
  known_article_ids = ['molprobity']

  def validate(self):
    self.data_manager.has_models(raise_sorry=True)

  def get_results(self):
    return self.results

  def get_results_as_JSON(self):
    return self.results.as_JSON(self.info_json)

  def run(self):
    hierarchy = self.data_manager.get_model().get_hierarchy()
    self.info_json = {"model_name":self.data_manager.get_default_model_name(),
                      "time_analyzed": str(datetime.now())}
    self.results = cbetadev(
      pdb_hierarchy=hierarchy,
      outliers_only=self.params.outliers_only,
      apply_phi_psi_correction=self.params.cbetadev.apply_phi_psi_correction,
      display_phi_psi_correction=self.params.cbetadev.display_phi_psi_correction,
      exclude_d_peptides=self.params.cbetadev.exclude_d_peptides,
      out=self.logger,
      quiet=False)
    if self.params.cbetadev.output == "kin":
      self.logger.write(self.results.as_kinemage())
    elif self.params.cbetadev.output == "bullseye":
      filebase = os.path.basename(self.data_manager.get_model_names()[0])
      self.logger.write(self.results.as_bullseye_kinemage(pdbid=filebase))
    elif self.params.json:
      print(self.get_results_as_JSON())
    elif self.params.verbose:
      #pdb_file_str = os.path.basename(self.params.model)[:-4]
      #get input file name from data manager, strip file extension
      pdb_file_str = os.path.basename(self.data_manager.get_model_names()[0])[:-4]
      self.results.show_old_output(out=self.logger, prefix=pdb_file_str, verbose=True)


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/chiral_validation.py
from __future__ import absolute_import, division, print_function

import os
from mmtbx.validation.restraints import chiralities
from mmtbx.model import manager
from libtbx.program_template import ProgramTemplate
from libtbx.utils import Sorry
from libtbx.utils import null_out
from datetime import datetime

class Program(ProgramTemplate):
  prog = os.getenv('LIBTBX_DISPATCHER_NAME')
  description="""
%(prog)s file.pdb [params.eff] [options ...]

Options:

  model=input_file      input PDB or mmCIF file
  outliers_only=True    Only return chiral outliers
  kinemage=False        Create kinemage markup (overrides text output)
  json=False            Outputs results as JSON compatible dictionary
  help=False          Prints this help message if true

  counts of various chiral volume outlier classes, including the following:
    tetrahedral geometry outliers (e.g. flattened geometry)
    chiral identity swaps (e.g. L vs D amino acids)
    pseudochiral naming issues (e.g. swapped chemically identical atoms with distinct names)

Example:

  %(prog)s model=1ubq.pdb kinemage=True
""" % locals()

  master_phil_str = """
    outliers_only = True
      .type = bool
      .help = "Only show outliers"
    kinemage = False
      .type = bool
      .help = "Prints kinemage markup for chiral volume outliers"
    json = False
      .type = bool
      .help = "Prints results as JSON format dictionary"
    result_file = None
      .type = path
      .help = "Path for output file"
"""
  datatypes = ['model','phil']
  data_manager_options = ['model_skip_expand_with_mtrix']

  def validate(self):
    self.data_manager.has_models(raise_sorry=True)

  def run(self):
    f = None
    if self.params.result_file is not None:
      try:
        f = open(self.params.result_file, 'w')
        self.logger.register('file', f)
      except IOError:
        raise Sorry("The output file could not be opened")
    model = self.data_manager.get_model()
    model.set_stop_for_unknowns(False)
    p = manager.get_default_pdb_interpretation_params()
    ##print(dir(p.pdb_interpretation))
    p.pdb_interpretation.allow_polymer_cross_special_position=True
    p.pdb_interpretation.flip_symmetric_amino_acids=False
    p.pdb_interpretation.clash_guard.nonbonded_distance_threshold = None
    model.set_log(log = null_out())
    model.process(make_restraints=True, pdb_interpretation_params=p)
    geometry_restraints_manager = model.get_restraints_manager().geometry
    pdb_hierarchy = model.get_hierarchy()
    self.info_json = {"model_name":self.data_manager.get_default_model_name(),
                      "time_analyzed": str(datetime.now())}
    pdb_hierarchy.atoms().reset_i_seq()
    xray_structure = model.get_xray_structure()
    from mmtbx import restraints
    restraints_manager = restraints.manager(
      geometry=geometry_restraints_manager)
    sites_cart = xray_structure.sites_cart()
    hd_selection = xray_structure.hd_selection()
    pdb_atoms = pdb_hierarchy.atoms()
    energies_sites = restraints_manager.energies_sites(
      sites_cart=sites_cart,
      compute_gradients=False).geometry
    restraint_proxies = getattr(restraints_manager.geometry, "chirality_proxies")
    self.results = chiralities(
        pdb_atoms=pdb_atoms,
        sites_cart=sites_cart,
        energies_sites=energies_sites,
        restraint_proxies=restraint_proxies,
        unit_cell=xray_structure.unit_cell(),
        ignore_hd=True,
        sigma_cutoff=4.0,
        outliers_only=self.params.outliers_only,
        use_segids_in_place_of_chainids=False)

    if self.params.kinemage:
      print(self.results.as_kinemage(), file=self.logger)
    elif self.params.json:
      print(self.results.as_JSON(self.info_json), file=self.logger)
    else:
      self.results.show(out=self.logger, verbose=True)
    if f:
      try:
        f.close()
      except Exception:
        raise Sorry("Could not close output file")

  def get_results(self):
    return self.results

  def get_results_as_JSON(self):
    return self.results.as_JSON(self.info_json)


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/clashscore.py
from __future__ import absolute_import, division, print_function

import os
from mmtbx.validation.clashscore import clashscore
from libtbx.program_template import ProgramTemplate
from datetime import datetime

try:
  from phenix.program_template import ProgramTemplate
except ImportError:
  pass
#from libtbx.utils import Sorry

class Program(ProgramTemplate):
  prog = os.getenv('LIBTBX_DISPATCHER_NAME')
  description="""
%(prog)s file.pdb [params.eff] [options ...]

Options:

  model=input_file          input PDB file
  fast = False              Produce only clashscore number, without anything else
  condensed_probe=False     Run probe with -CON parameter
  keep_hydrogens=False      keep input hydrogen atoms if True, regenerate if False
  nuclear=False             use nuclear x-H distances and vdW radii
  json=False                Outputs results as JSON compatible dictionary
  verbose=True              verbose text output
  b_factor_cutoff=40        B factor cutoff for clash analysis
  do_flips=False            Do flips when adding Hs, overides keep_hydrogens

Example:

  %(prog)s model=1ubq.pdb keep_hydrogens=True
""" % locals()

  master_phil_str = """
    model = None
    .type = path
    .optional = False
    .help = '''input PDB file'''

  fast = False
    .type = bool
    .help = ''' Produce only clashscore number, without anything else'''

  condensed_probe = False
    .type = bool
    .help = ''' Run probe with -CON parameter '''

  json = False
    .type = bool
    .help = "Prints results as JSON format dictionary"

  verbose = True
    .type = bool

  keep_hydrogens = False
    .type = bool
    .help = '''Keep hydrogens in input file'''

  do_flips = False
    .type = bool
    .help = '''Do flips when adding Hsi, overides keep_hydrogens=True'''

  nuclear = False
    .type = bool
    .help = '''Use nuclear hydrogen positions'''

  time_limit = 120
    .type = int
    .help = '''Time limit (sec) for Reduce optimization'''

  b_factor_cutoff = None
    .type = int
    .help = '''B factor cutoff for use with MolProbity'''

  clash_cutoff = -0.4
    .type = float
    .help = '''dummy variable for MolProbity, will be removed after MP update'''
"""
  datatypes = ['model','phil']
  data_manager_options = ['model_skip_expand_with_mtrix']
  known_article_ids = ['molprobity']

  def validate(self):
    self.data_manager.has_models(raise_sorry=True)

  #def get_results_as_JSON(self):
  #  if self.params.do_flips : self.params.keep_hydrogens = False
  #  hierarchy = self.data_manager.get_model().get_hierarchy()

  #  result = clashscore(
  #    pdb_hierarchy=hierarchy,
  #    fast = self.params.fast,
  #    condensed_probe = self.params.condensed_probe,
  #    keep_hydrogens=self.params.keep_hydrogens,
  #    nuclear=self.params.nuclear,
  #    out=self.logger,
  #    verbose=self.params.verbose and not quiet,
  #    b_factor_cutoff=self.params.b_factor_cutoff,
  #    do_flips=self.params.do_flips)
  #  return result.as_JSON()

  def run(self, quiet=None): #preserved how quiet was passed to the old run, not sure why
    """
  Calculates nonbonded clashscore using MolProbity (PROBE)

  Returns:
    When verbose=True the function print detailed results to log
    When verbose=False it will print clashscore
  """
    # if do_flips, make keep_hydrogens false
    if self.params.do_flips : self.params.keep_hydrogens = False
    hierarchy = self.data_manager.get_model().get_hierarchy()
    self.info_json = {"model_name":self.data_manager.get_default_model_name(),
                      "time_analyzed": str(datetime.now()),
                      "params": {"fast":self.params.fast,
                                 "condensed_probe":self.params.condensed_probe,
                                 "keep_hydrogens":self.params.keep_hydrogens,
                                 "nuclear":self.params.nuclear,
                                 "b_factor_cutoff":self.params.b_factor_cutoff,
                                 "do_flips":self.params.do_flips}}
    self.results = clashscore(
      pdb_hierarchy=hierarchy,
      fast = self.params.fast,
      condensed_probe = self.params.condensed_probe,
      keep_hydrogens=self.params.keep_hydrogens,
      nuclear=self.params.nuclear,
      out=self.logger,
      verbose=self.params.verbose and not quiet,
      b_factor_cutoff=self.params.b_factor_cutoff,
      do_flips=self.params.do_flips)
    if self.params.json:
      print(self.results.as_JSON())
    elif self.params.verbose:
      self.results.show_old_output(out=self.logger)
    else:
      print(round(self.results.get_clashscore(),2), file=self.logger)

  def get_results(self):
    return self.results

  def get_results_as_JSON(self):
    return self.results.as_JSON(self.info_json)


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/clashscore2.py
"""
All-atom contact analysis.
This is a rewrite of the original clashscore.  This version uses mmtbx.reduce and
mmtbx.probe to generate the contact information rather than stand-alone programs.
It take the same parameters as the original clashscore (except for time_limit)
and it also takes mmtbx.probe parameters.
"""

from __future__ import absolute_import, division, print_function

import os
from mmtbx.validation.clashscore2 import clashscore2
from libtbx.program_template import ProgramTemplate
from datetime import datetime
from mmtbx.probe import Helpers

try:
  from phenix.program_template import ProgramTemplate
except ImportError:
  pass
#from libtbx.utils import Sorry

class Program(ProgramTemplate):
  prog = os.getenv('LIBTBX_DISPATCHER_NAME')
  description="""
%(prog)s file.pdb [params.eff] [options ...]

Options:

  model=input_file          input PDB file
  fast = False              Produce only clashscore number, without anything else
  condensed_probe=False     Run probe with -CON parameter
  keep_hydrogens=False      keep input hydrogen atoms if True, regenerate if False
  nuclear=False             use nuclear x-H distances and vdW radii
  json=False                Outputs results as JSON compatible dictionary
  verbose=True              verbose text output
  b_factor_cutoff=40        B factor cutoff for clash analysis
  do_flips=False            Do flips when adding Hs, overides keep_hydrogens

Example:

  %(prog)s model=1ubq.pdb keep_hydrogens=True
""" % locals()

  master_phil_str = """
    model = None
    .type = path
    .optional = False
    .help = '''input PDB file'''

  fast = False
    .type = bool
    .help = ''' Produce only clashscore number, without anything else'''

  condensed_probe = False
    .type = bool
    .help = ''' Run probe with -CON parameter '''

  json = False
    .type = bool
    .help = "Prints results as JSON format dictionary"

  verbose = True
    .type = bool

  keep_hydrogens = False
    .type = bool
    .help = '''Keep hydrogens in input file'''

  do_flips = False
    .type = bool
    .help = '''Do flips when adding Hsi, overides keep_hydrogens=True'''

  nuclear = False
    .type = bool
    .help = '''Use nuclear hydrogen positions'''

  b_factor_cutoff = None
    .type = int
    .help = '''B factor cutoff for use with MolProbity'''

  clash_cutoff = -0.4
    .type = float
    .help = '''dummy variable for MolProbity, will be removed after MP update'''
""" + Helpers.probe_phil_parameters

# Removed time_limit from the phil parameters
#  time_limit = 120
#    .type = int
#    .help = '''Time limit (sec) for Reduce optimization'''

  datatypes = ['model','phil']
  data_manager_options = ['model_skip_expand_with_mtrix']
  known_article_ids = ['molprobity']

  def validate(self):
    self.data_manager.has_models(raise_sorry=True)

  def run(self, quiet=None): #preserved how quiet was passed to the old run, not sure why
    """
  Calculates nonbonded clashscore using MolProbity (PROBE)

  Returns:
    When verbose=True the function print detailed results to log
    When verbose=False it will print clashscore
  """
    # if do_flips, make keep_hydrogens false
    if self.params.do_flips : self.params.keep_hydrogens = False
    self.info_json = {"model_name":self.data_manager.get_default_model_name(),
                      "time_analyzed": str(datetime.now())}
    self.results = clashscore2(
      self.params.probe,
      data_manager=self.data_manager,
      fast = self.params.fast,
      condensed_probe = self.params.condensed_probe,
      keep_hydrogens=self.params.keep_hydrogens,
      nuclear=self.params.nuclear,
      out=self.logger,
      verbose=self.params.verbose and not quiet,
      b_factor_cutoff=self.params.b_factor_cutoff,
      do_flips=self.params.do_flips)
    if self.params.json:
      print(self.results.as_JSON())
    elif self.params.verbose:
      self.results.show_old_output(out=self.logger)
    else:
      print(round(self.results.get_clashscore(),2), file=self.logger)

  def get_results(self):
    return self.results

  def get_results_as_JSON(self):
    return self.results.as_JSON(self.info_json)


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/comparama.py
# -*- coding: utf-8 -*-
from __future__ import absolute_import, division, print_function

from libtbx.program_template import ProgramTemplate

from scitbx.array_family import flex

from mmtbx.validation import comparama
from mmtbx.validation.ramalyze import res_type_labels

from matplotlib.backends.backend_pdf import PdfPages

import os
import six

# =============================================================================

class Program(ProgramTemplate):

  description = '''
phenix.comparama: tool for compare Ramachandran plots, e.g. before-after
  refinement.

Usage examples:
  phenix.comparama model1.pdb model2.pdb
  phenix.comparama model1.cif model2.cif
  '''

  datatypes = ['model', 'phil']

  master_phil_str = """\
    include scope mmtbx.validation.comparama.master_phil_str
    output
    {
      individual_residues = True
        .type = bool
      sorted_individual_residues = False
        .type = bool
      counts = True
        .type = bool
      prefix = kleywegt
        .type = str
      plots = False
        .type = bool
        .help = output Kleywegt plots - arrows on Rama plot showing where \
          residues moved.
      pdf = True
        .type = bool
        .help = save the same plots as one pdf file
      wrap_arrows = True
        .type = bool
        .help = wrap long arrows around the edges of plot
    }
"""

  # ---------------------------------------------------------------------------
  def validate(self):
    print('Validating inputs', file=self.logger)
    self.data_manager.has_models(expected_n=2, exact_count=True, raise_sorry=True)
    model_1, model_2 = self._get_models()
    model_1.add_crystal_symmetry_if_necessary()
    model_2.add_crystal_symmetry_if_necessary()
    # Filter out what you are not interested in
    s1 = model_1.selection(string="protein")
    s2 = model_2.selection(string="protein")
    model_1 = model_1.select(selection = s1)
    model_2 = model_2.select(selection = s2)
    #
    # assert model_1.get_hierarchy().is_similar_hierarchy(model_2.get_hierarchy())
    for m in [model_1, model_2]:
      assert m.get_hierarchy().models_size() == 1

  # ---------------------------------------------------------------------------
  def run(self):
    # I'm guessing self.data_manager, self.params and self.logger
    # are already defined here...
    # print('Using model: %s' % self.data_manager.get_default_model_name(), file=self.logger)

    # this must be mmtbx.model.manager?
    model_1, model_2 = self._get_models()
    # Filter out what you are not interested in
    s1 = model_1.selection(string="protein")
    s2 = model_2.selection(string="protein")
    model_1 = model_1.select(selection = s1)
    model_2 = model_2.select(selection = s2)

    self.rama_comp = comparama.rcompare(
        model1 = model_1,
        model2 = model_2,
        params = self.params.comparama,
        log = self.logger)

    # outputting results
    results = self.rama_comp.get_results()
    if len(results) == 0:
      print("No ramachandran residues found!")
      return
    if self.params.output.individual_residues:
      for r in results:
        self.show_single_result(r)
      print("="*80, file=self.logger)
    if self.params.output.sorted_individual_residues:
      sorted_res = sorted(results, key=lambda tup: tup[1])
      for r in sorted_res:
        self.show_single_result(r)
      print("="*80, file=self.logger)

    skip1, skip2 = self.rama_comp.get_skipped()
    for s in skip1:
      print("WARNING! No match for '%s' in the second model" % s.id_str(), file=self.logger)
    for s in skip2:
      print("WARNING! No match for '%s' in the first model" % s.id_str(), file=self.logger)
    if len(skip1) + len(skip2) > 0:
      print("="*80, file=self.logger)

    nr = self.rama_comp.get_number_results()
    print ("mean: %.3f std: %.3f" % (nr.mean_diff, nr.std_diff), file=self.logger)
    print("Sum of rama scores: \t\t\t %.3f -> %.3f" % (nr.sum_1, nr.sum_2) , file=self.logger)
    print("Sum of rama scores/n_residues:\t\t %.4f -> %.4f (%d residues)" % \
        (nr.sum_1/nr.n_res, nr.sum_2/nr.n_res, nr.n_res), file=self.logger)
    print("Sum of rama scores scaled:\t\t %.3f -> %.3f" % \
        (nr.scaled_sum_1, nr.scaled_sum_2) , file=self.logger)
    print("Sum of rama scores/n_residues scaled:\t %.4f -> %.4f (%d residues)" % \
        (nr.scaled_sum_1/nr.n_res, nr.scaled_sum_2/nr.n_res, nr.n_res), file=self.logger)
    print("Sum of rama scores reverse scaled:\t\t %.3f -> %.3f" % \
        (nr.rev_scaled_sum_1, nr.rev_scaled_sum_2) , file=self.logger)
    print("Sum of rama scores/n_residues reverse scaled:\t %.4f -> %.4f (%d residues)" % \
        (nr.rev_scaled_sum_1/nr.n_res, nr.rev_scaled_sum_2/nr.n_res, nr.n_res), file=self.logger)

    if self.params.output.counts:
      for k, v in six.iteritems(nr.counts):
        print("%-20s: %d" % (k,v), file=self.logger)

    # Pavel's numbers
    s1, s2 = self.rama_comp.get_results_as_vec3()
    pnumber = flex.mean(flex.sqrt((s1-s2).dot()))
    # compare these with log output:
    #  A   2  ASN 25.13, (-60.6:141.2), (-78.7:158.6), Favored, Score: 0.5693 -> 0.2831
    #                      phi1  psi1     phi2  psi2
    # print (list(s1))
    # print (list(s2))
    print ("Pavel's test number: %.4f" % pnumber)

    name1 = os.path.basename(self.data_manager.get_model_names()[0]).split('.')[0]
    name2 = os.path.basename(self.data_manager.get_model_names()[1]).split('.')[0]
    base_fname = "%s--%s" % (name1, name2)
    if self.params.output.plots:
      for pos, plot in six.iteritems(self.rama_comp.get_plots(wrap_arrows=self.params.output.wrap_arrows)):
        file_label = res_type_labels[pos].replace("/", "_")
        plot_file_name = "%s_%s_%s_plot.png" % (
            base_fname, self.params.output.prefix, file_label)
        print("saving: '%s'" % plot_file_name)
        plot.save_image(plot_file_name, dpi=300)

    if self.params.output.pdf:
      pdf_fname = "%s_%s.pdf" % (base_fname, self.params.output.prefix)
      pdfp = PdfPages(pdf_fname)
      for pos, plot in six.iteritems(self.rama_comp.get_plots(wrap_arrows=self.params.output.wrap_arrows)):
        pdfp.savefig(plot.figure)
      print("saving: '%s'" % pdf_fname)
      pdfp.close()

  def show_single_result(self, r):
    print("%s %.2f, (%.1f:%.1f), (%.1f:%.1f), %s, Score: %.4f -> %.4f" % \
        (r[0], r[1], r[2], r[3], r[4], r[5], r[6], r[8], r[9]),
        file=self.logger)

  # ---------------------------------------------------------------------------
  def get_results(self):
    return self.rama_comp.get_results()

  def _get_models(self):
    m_names = self.data_manager.get_model_names()
    model_1 = self.data_manager.get_model(filename=m_names[0])
    model_2 = self.data_manager.get_model(filename=m_names[1])
    return model_1, model_2


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/emringer.py
from __future__ import absolute_import, division, print_function
try:
  from phenix.program_template import ProgramTemplate
except ImportError:
  from libtbx.program_template import ProgramTemplate
import os
import libtbx.phil
from libtbx.utils import Sorry
from libtbx import easy_pickle
import mmtbx.ringer.emringer

# =============================================================================

program_citations = libtbx.phil.parse('''
citation {
  article_id = emringer1
  authors = Barad BA, Echols N, Wang RY, Cheng Y, DiMaio F, Adams PD, Fraser JS
  title = Side-chain-directed model and map validation for 3D Electron Cryomicroscopy.
  journal = Nature Methods
  volume = 10
  pages = 943-46
  year = 2015
  doi_id = "10.1038/nmeth.3541"
  pmid = 26280328
  external = True
}

citation {
  article_id = emringer2
  authors = Lang PT, Ng HL, Fraser JS, Corn JE, Echols N, Sales M, Holton JM, Alber T
  title = Automated electron-density sampling reveals widespread conformational polymorphism in proteins.
  journal = Protein Sci.
  volume = 7
  pages = 1420-31
  year = 2010
  doi_id = ""
  pmid = 20499387
  external = True
}
''')

# =============================================================================

master_phil_str = '''
include scope libtbx.phil.interface.tracking_params
include scope mmtbx.ringer.emringer.master_params
map_label = 2FOFCWT,PH2FOFCWT
  .type = str
  .input_size = 200
  .short_caption = 2Fo-FC map labels
  .help = Labels for 2Fo-Fc map coefficients
show_gui = False
  .type = bool
output_base = None
  .type = str
output_dir = None
  .type = path
  .short_caption = Output directory
quiet = False
  .type = bool
  .short_caption = no graphs
  .help = Don't output files or graphs
'''

# =============================================================================

class Program(ProgramTemplate):

  description = '''
Program for calculating the EMRinger score.\n

Minimum required inputs:
  Model file
  Map file (or file with map coefficients)

How to run:
  phenix.emringer model.pdb map.ccp4
'''

  datatypes = ['model', 'real_map', 'phil', 'map_coefficients']

  citations = program_citations
  master_phil_str = master_phil_str


  # ---------------------------------------------------------------------------
  def validate(self):
    print('Validating inputs', file=self.logger)
    self.data_manager.has_models(raise_sorry=True)
    if not (self.data_manager.has_real_maps() or
        self.data_manager.has_map_coefficients()):
      raise Sorry("Supply a map file or a file with map coefficients.")
    elif (self.data_manager.has_real_maps() and
        self.data_manager.has_map_coefficients()):
      raise Sorry("Supply either a map file or a file with map coefficients.")

  # ---------------------------------------------------------------------------
  def run(self):
    map_inp = None
    miller_array = None

    print('Using model: %s' % self.data_manager.get_default_model_name(),
      file=self.logger)
    model = self.data_manager.get_model()

    if self.data_manager.has_map_coefficients():
      miller_arrays = self.data_manager.get_miller_arrays()
      miller_array = self.find_label(miller_arrays = miller_arrays)
      print('Using miller array: %s' % miller_array.info().label_string(),
        file=self.logger)
    elif self.data_manager.has_real_maps():
      print('Using map: %s' % self.data_manager.get_default_real_map_name(),
        file=self.logger)
      map_inp = self.data_manager.get_real_map()
      print("CCP4 map statistics:", file=self.logger)
      map_inp.show_summary(out=self.logger, prefix="  ")

    if (self.params.output_base is None):
      pdb_base = os.path.basename(self.data_manager.get_default_model_name())
      self.params.output_base = os.path.splitext(pdb_base)[0] + "_emringer"

    if not self.params.quiet:
      plots_dir = self.params.output_base + "_plots"
      if (not os.path.isdir(plots_dir)):
        os.makedirs(plots_dir)

    task_obj = mmtbx.ringer.emringer.emringer(
      model        = model,
      miller_array = miller_array,
      map_inp      = map_inp,
      params       = self.params,
      out          = self.logger)
    task_obj.validate()
    task_obj.run()
    self.results = task_obj.get_results()

    ringer_result = self.results.ringer_result

    if not self.params.quiet:
      # save as pickle
      easy_pickle.dump("%s.pkl" % self.params.output_base, ringer_result)
      print ('Wrote %s.pkl' % self.params.output_base, file=self.logger)
      # save as CSV
      csv = "\n".join([ r.format_csv() for r in ringer_result])
      open("%s.csv" % self.params.output_base, "w").write(csv)
      print ('Wrote %s.csv' % self.params.output_base, file=self.logger)

    scoring_result = self.results.scoring_result
    scoring_result.show_summary(out = self.logger)

    #rolling_result = self.results.rolling_result

  # It would be good to have central code for this
  # ---------------------------------------------------------------------------
  def find_label(self, miller_arrays):
    best_guess = None
    best_labels = []
    all_labels = []
    miller_array = None
    for array in miller_arrays:
      label = array.info().label_string().replace(" ", "")
      if (self.params.map_label is not None):
        if (label == self.params.map_label.replace(" ", "")):
          miller_array = array
          return miller_array
      elif (self.params.map_label is None):
        if (array.is_complex_array()):
          all_labels.append(label)
          if (label.startswith("2FOFCWT") or label.startswith("2mFoDFc") or
              label.startswith("FWT")):
            best_guess = array
            best_labels.append(label)
    if (miller_array is None):
      if (len(all_labels) == 0):
        raise Sorry("No valid (pre-weighted) map coefficients found in file.")
      elif (len(best_labels) == 0):
        raise Sorry("Couldn't automatically determine appropriate map labels. "+
          "Choices:\n  %s" % "  \n".join(all_labels))
      elif (len(best_labels) > 1):
        raise Sorry("Multiple appropriate map coefficients found in file. "+
          "Choices:\n  %s" % "\n  ".join(best_labels))
      elif (len(best_labels) == 1):
        miller_array = best_guess
        print("  Guessing %s for input map coefficients"% best_labels[0], file=self.logger)
        return miller_array

  # ---------------------------------------------------------------------------
  def get_results(self):
    return self.results



 *******************************************************************************


 *******************************************************************************
mmtbx/programs/fetch.py
from __future__ import absolute_import, division, print_function

from libtbx.program_template import ProgramTemplate
from libtbx import easy_run
from libtbx.utils import Sorry
from iotbx.pdb.fetch import valid_pdb_id, fetch_and_write
from mmtbx.wwpdb import rcsb_web_services
import os

master_phil_str = """
fetch
  .caption = Automatically retrieve data from the PDB via the RCSB \
    web server.  If you intend to re-refine or re-build the structure we \
    recommend creating a new project, but this is not required.  Note that \
    you may also use this tool to generate an MTZ file from the mmCIF \
    structure factors (if available), but the options \
    are more limited than what is available in the phenix.cif_as_mtz.
  .style = auto_align caption_img:icons/custom/pdb_import64.png \
    caption_width:400
{
  pdb_ids = None
    .type = strings
    .short_caption = PDB ID(s)
    .input_size = 400
    .style = bold
  action = *model data sequence half_maps all
    .type = choice(multi=True)
    .caption = model_file(s) data_file(s) sequence half_maps
  convert_to_mtz = False
    .type = bool
    .caption = Try to convert X-ray data to mtz format
  mirror = *rcsb pdbe pdbj
    .type = choice
    .caption = RCSB PDBe PDBj
    .short_caption = Mirror site
    .style = bold
}
"""

class Program(ProgramTemplate):
  description = """
  Fetch model, data, sequence files. Optionally convert to sf data to mtz format.
  Usage:
  Get only model:
    iotbx.fetch_pdb 1yjp
  Get model and data(xray or cryo-em):
    iotbx.fetch_pdb 1yjp action=model+data
  Get everything:
    iotbx.fetch_pdb 1yjp action=all
"""
  datatypes = ['phil']
  master_phil_str = master_phil_str

  def custom_init(self):
    # store output filenames and error messages
    self.output_filenames = []
    self.errors = []

  def validate(self):
    print('Validating inputs:\n', file=self.logger)
    if self.params.fetch.pdb_ids is  None:
      raise Sorry("Provide pdb id for fetching")
    for pdb_id in self.params.fetch.pdb_ids:
      if not valid_pdb_id(pdb_id):
        raise Sorry("Invalid PDB code: %s" % pdb_id)
    for a in self.params.fetch.action:
      if a not in ['model', 'data', 'sequence', 'half_maps', 'all']:
        raise Sorry("Unsupported action %s" % a)

  def define_entities_to_fetch(self, emdb_number):
    entities_to_fetch = []
    if 'model' in self.params.fetch.action:
      entities_to_fetch += ['model_pdb', 'model_cif']
    if 'data' in self.params.fetch.action:
      if emdb_number is None:
        entities_to_fetch += ['sf']
      else:
        entities_to_fetch += ['em_map']
    if 'sequence' in self.params.fetch.action:
      entities_to_fetch += ['sequence']
    if 'half_maps' in self.params.fetch.action and emdb_number:
      entities_to_fetch += ['em_half_map_1', 'em_half_map_2']

    if 'all' in self.params.fetch.action:
      entities_to_fetch = ['model_pdb', 'model_cif', 'sequence']
      if emdb_number is not None:
        entities_to_fetch += ['em_map','em_half_map_1', 'em_half_map_2']
      else:
        entities_to_fetch += ['sf']
    return entities_to_fetch

  def run(self):
    for pdb_id in self.params.fetch.pdb_ids:
      emdb_number = None
      emdb_ids = rcsb_web_services.get_emdb_id_for_pdb_id(pdb_id)
      if emdb_ids is not None:
        emdb_number = int(emdb_ids[0].split('-')[1])
      print("Fetching: PDB ID: %s, EMDB ID: %s" % (pdb_id, emdb_number), file=self.logger)
      entities_to_fetch = self.define_entities_to_fetch(emdb_number)
      for e in entities_to_fetch:
        fn = fetch_and_write(
            id=pdb_id,
            entity=e,
            mirror=self.params.fetch.mirror,
            emdb_number=emdb_number,
            log=self.logger)
        if e == 'sf' and fn is not None and self.params.fetch.convert_to_mtz:
          # here we have successfully have structure factor file and
          # need to convert it to mtz.
          cmd = "phenix.cif_as_mtz %s --merge --map_to_asu --extend_flags --ignore_bad_sigmas" % fn
          easy_run.call(cmd)
          if os.path.isfile("%s-sf.mtz" % pdb_id):
            new_filename = "%s.mtz" % pdb_id
            os.rename("%s-sf.mtz" % pdb_id, new_filename)
            print("Converted structure factors saved to %s.mtz" % pdb_id, file=self.logger)
            self.output_filenames.append(new_filename)
          if (not os.path.isfile("%s.mtz" % pdb_id)):
            error_msg = "MTZ conversion failed - try running phenix.cif_as_mtz " \
              + "manually (and check %s-sf.cif for format errors)." % pdb_id
            print(error_msg, file=self.logger)
            self.errors.append(error_msg)
        elif fn is not None:
          self.output_filenames.append(fn)

  def get_results(self):
    return self.output_filenames, self.errors


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/fmodel.py
from __future__ import absolute_import, division, print_function
try:
  from phenix.program_template import ProgramTemplate
except ImportError:
  from libtbx.program_template import ProgramTemplate
import os
import mmtbx.utils
import iotbx.phil
import iotbx.pdb
import random
from libtbx.utils import Sorry
from cctbx.array_family import flex
from libtbx import group_args

fmodel_from_xray_structure_params_str = """\
fmodel
  .short_caption = F(model) options
  .expert_level = 1
  .style = auto_align box
{
  k_sol = 0.0
    .type = float
    .help = Bulk solvent k_sol values
    .short_caption=Bulk solvent K_sol value
  b_sol = 0.0
    .type = float
    .help = Bulk solvent b_sol values
    .short_caption=Bulk solvent B_sol value
  b_cart = 0 0 0 0 0 0
    .type = floats(6)
    .help = Anisotropic scale matrix
    .input_size = 200
    .short_caption = Anisotropic scale matrix
  scale = 1.0
    .type = float
    .help = Overall scale factor
}
structure_factors_accuracy
  .short_caption = Structure factors accuracy
  .style = auto_align box
{
  include scope mmtbx.f_model.sf_and_grads_accuracy_master_params
}
mask
  .short_caption = Bulk solvent mask
  .style = auto_align box
{
  include scope mmtbx.masks.mask_master_params
}
"""

master_phil_str = '''
include scope libtbx.phil.interface.tracking_params

high_resolution = None
  .type = float
  .expert_level=1
  .style = noauto bold
low_resolution = None
  .type = float
  .expert_level=1
  .style = noauto
r_free_flags_fraction = None
  .type = float
  .expert_level=1
  .style = noauto
add_sigmas = False
  .type = bool
  .expert_level=1
  .help = Adds calculated Sigma(F) column to output file.
  .style = noauto
add_random_error_to_amplitudes_percent = None
  .type = float
  .short_caption = Add random error (percent)
  .style = noauto
scattering_table = wk1995  it1992  *n_gaussian  neutron electron
  .type = choice
  .help = Choices of scattering table for structure factors calculations.  \
    n_gaussian is the standard set of X-ray scattering factors.
  .expert_level=1
  .style = noauto
custom_scattering_factors = None
  .type = path
  .help = Use custom scattering factors and replaces default values entirely
%s
random_seed=None
  .type = int
  .help = Random seed
  .expert_level=2
twin_law = None
  .type = str
  .help = Optional twin law if we want to generate a twinned dataset
  .input_size = 120
  .style = noauto
twin_fraction = None
  .type = float
  .help = Twin fraction, ignored if twin_law is not specified
  .style = noauto
wavelength = None
  .type = float
  .input_size = 80
  .help = Wavelength, sets all atoms to anomalous
  .style = noauto
generate_fake_p1_symmetry = False
  .type = bool
  .short_caption = Generate fake symmetry if necessary
  .help = Allows use of PDB files without CRYST1 records as input.  The \
    crystal symmetry will be assumed to be a P1 box.
output
  .short_caption = Reflection output
  .expert_level=0
  .style = noauto
{
  format = *mtz cns
    .type = choice
    .short_caption = File format
    .input_size = 100
  label = FMODEL
    .type = str
    .short_caption = Data label
    .input_size = 100
  type = real *complex
    .type = choice
    .short_caption = Output data type
    .help = Numeric type of output data.  'real' is amplitudes only, \
      'complex' is complete structure factors as complex numbers.
    .expert_level=1
    .style = bold
  obs_type = *amplitudes intensities
    .type = choice
    .help = Experimental observation type to output.  Certain restrictions \
      apply if intensities are selected.
    .expert_level = 2
  file_name = None
    .type = path
    .short_caption = Output file
    .style = bold noauto new_file
  include scope libtbx.phil.interface.tracking_params
}
anomalous_scatterers
  .short_caption = Anomalous sites
  .style = menu_item noauto
{
  group
    .optional = True
    .multiple = True
    .short_caption = Anomalous scatterer group
    .style = auto_align
  {
    selection = None
      .type = atom_selection
      .short_caption = Atom selection
      .input_size = 400
    f_prime = 0
      .type = float
      .short_caption = f'
    f_double_prime = 0
      .type = float
      .short_caption = f''
  }
}
gui
  .help = "GUI-specific parameter required for output directory"
{
  output_dir = None
  .type = path
  .style = output_dir

  data_column_label = None
  .type = str
  .style = noauto renderer:draw_any_label_widget
  .input_size = 300
}
'''%fmodel_from_xray_structure_params_str

fmodel_from_xray_structure_params = iotbx.phil.parse(
  fmodel_from_xray_structure_params_str, process_includes=True)

master_phil = iotbx.phil.parse(master_phil_str, process_includes = True)


def set_fp_fdp_for_anomalous_scatterers(pdb_hierarchy, xray_structure,
  anomalous_scatterer_groups):
  scatterers = xray_structure.scatterers()
  for group in anomalous_scatterer_groups:
    iselection = pdb_hierarchy.atom_selection_cache().selection(
      string = group.selection).iselection()
    if(iselection.size() == 0):
      raise Sorry(
        "Empty selection: selection string '%s' does not select any atom."%
        group.selection)
    for i_seq in iselection:
      scatterers[i_seq].fp = group.f_prime
      scatterers[i_seq].fdp = group.f_double_prime

# =============================================================================

class Program(ProgramTemplate):

  description = '''
phenix.fmodel: a tool to compute structure factors, Fmodel:

  Fmodel = scale * exp(AnisoScale) * (Fcalc + k_sol * exp(-b_sol*s^2/4) * Fmask)

  where:

  - Fmodel - total model structure factor (complex value)
  - AnisoScale = -ht*A(-1)*b_cart*A(-1)th/4
  - h - column vector with Miller indices
  - A - orthogonalization matrix
  - b_cart - anisotropic scale matrix
  - t and (-1) denotes transposition and inversion operations
  - scale - overall scale factor
  - Fcalc - structure factors calculated from atomic model
  - k_sol and b_sol - Flat Bulk solvent model parameters
  - Fmask - structure factors calculated from bulk solvent mask

Usage examples:

  1) phenix.fmodel model.pdb high_resolution=1.5

     will result in a file containing complete set of Fmodel = Fcalc computed
     from atomic model up to 1.5A resolution.

  2) phenix.fmodel model.pdb scale=2 k_sol=0.35 b_sol=50 b_cart="1 2 3 0 4 7" high_res=1.5 low_res=10

     will result in a file containing complete set of Fmodel computed using the
     above formula in resolution range 1.5-20.0A.

  3) phenix.fmodel model.pdb high_resolution=1.5 algorithm=direct

     is similar to "1)" but the Fcalc are computed using direct summation algorithm.

  4) phenix.fmodel model.pdb high_res=1.5 format=cns label=FOBS type=real r_free=0.1

     will result in CNS formatted file containing complete set of amplitudes of
     Fmodel = Fcalc computed up to 1.5A resolution, labelled as FOBS, and free-R
     flags with 10% of test reflections. This is a typical command to simulate Fobs.

  5) phenix.fmodel model.pdb high_res=1.5 scattering_table=neutron

     will result in a file containing complete set of Fmodel = Fcalc computed
     from atomic model up to 1.5A resolution using neutron scattering table.

  6) phenix.fmodel model.pdb parameters.txt

     will result in a structure factor file, where Fmodel were computed using
     parameters defined in parameters.txt file. The parameters.txt file can
     contain all or any subset of parameters listed below. Note, that each {
     must have a matching one }.

  7) phenix.fmodel model.pdb reflection_data.mtz

     will result in a file containing a set of Fmodel = Fcalc that will match
     the set of Miller indices of the data in reflection_data.mtz file.

  8) phenix.fmodel model.pdb reflection_data.mtz data_column_label="FOBS,SIGMA"

     similar to "7)", where the specific data array is selected.

  9) phenix.fmodel model.pdb reflection_data.mtz twin_law="l,-k,h" twin_fraction=0.3

     generates twin data set (real type) with given twin law and fraction.

See below for complete list of available parameters.
'''

  datatypes = ['model', 'phil', 'miller_array']

  master_phil_str = master_phil_str

#  show_data_manager_scope_by_default = True

  # ---------------------------------------------------------------------------

  def validate(self):
    print('Validating inputs:\n', file=self.logger)
    self.data_manager.has_models(
      raise_sorry = True,
      expected_n  = 1,
      exact_count = True)
    if len(self.data_manager.get_miller_array_names()) > 1:
      raise Sorry('Please supply at most one reflection file.')
    if self.data_manager.has_miller_arrays():
      if([self.params.high_resolution, self.params.low_resolution].count(None) != 2):
        raise Sorry("high_resolution and low_resolution must be undefined "+
                    "if reflection data file is given.")
      if len(self.data_manager.get_miller_array_user_selected_labels()) > 1:
        raise Sorry('Supply not more than one label name.')
    else:
      if (self.params.high_resolution is None):
        raise Sorry("Input data file or high_resolution has to be provided.")

    if (self.params.output.type == "complex") and (self.params.add_sigmas):
      raise Sorry("Sigma values only supported when the output type is 'real'.")
    if (self.params.low_resolution is not None
        and self.params.high_resolution is not None):
      if self.params.low_resolution < self.params.high_resolution :
        raise Sorry("Low-resolution cutoff must be larger than the high-"+
          "resolution cutoff.")
    if (self.params.output.obs_type == "intensities"):
      if (self.params.output.type == "complex"):
        raise Sorry("Output type must be 'real' when intensities specified "+
          "for obs_type.")
      if (not self.params.output.label.upper().startswith("I")):
        raise Sorry("Output label must start with 'I' (any case) when "+
          "intensities specified for obs_type (was: %s)." % self.params.output.label)
      if (self.params.output.format != "mtz"):
        raise Sorry("Output format must be 'mtz' when intensities specified.")
    if (self.params.wavelength is not None):
      if (self.params.scattering_table == "neutron"):
        raise Sorry("Wavelength parameter not supported when the neutron "+
          "scattering table is used.")

# For GUI
#def validate_params(params, callback=None):
#  if len(params.pdb_file) == 0 :
#    raise Sorry("You must provide at least one model file to use for "+
#      "F(model) calculations.")
#  if (params.high_resolution is None):
#    if (params.reference_file is None):
#      raise Sorry("Please specify a high-resolution cutoff.")
#  elif (params.reference_file is not None):
#    if (params.data_column_label is None):
#      raise Sorry("Please select a column label to use in the reference "+
#        "data file.")
#    elif ([params.high_resolution, params.low_resolution].count(None) != 2):
#      raise Sorry("High resolution and low resolution must be undefined "+
#                  "if reflection data file is given.")
#  if (params.output.file_name is None):
#    raise Sorry("Please specify an output file.")
#  validate_params_command_line(params)


  # ---------------------------------------------------------------------------

  def run(self):

    print('Parameters to compute Fmodel:', file=self.logger)
    # TODO print processed non defaults from phil

    print('Using model file:', self.data_manager.get_default_model_name(),
      file=self.logger)

    mo = self.data_manager.get_model()
    cs = mo.crystal_symmetry()

    miller_array = None
    if self.data_manager.has_miller_arrays():
      print('Using reflection file:',
        self.data_manager.get_default_miller_array_name(),
        file=self.logger)
      user_selected_labels = self.data_manager.get_miller_array_user_selected_labels()
      if not user_selected_labels: user_selected_labels = None
      miller_arrays = self.data_manager.get_miller_arrays(
        labels=user_selected_labels)
      data_sizes = flex.int([ma.data().size() for ma in miller_arrays])
      if(data_sizes.all_eq(data_sizes[0])): miller_array = miller_arrays[0]
      else:
        raise Sorry('Reflection file contains arrays of different lengths. \
                    Please select one using "labels.name=" keyword.')
      miller_array = miller_arrays[0]
      assert(miller_array is not None)
      miller_array.show_comprehensive_summary(f = self.logger, prefix="  ")
      miller_array = miller_array.map_to_asu().customized_copy(
        data = flex.double(miller_array.data().size(), 1))
      cs_from_ma = miller_array.crystal_symmetry()
      if (self.params.generate_fake_p1_symmetry and cs_from_ma is not None):
        raise Sorry("The reflection data already define crystal symmetry; "+
          "you may not use this in combination with the option "+
          "generate_fake_p1_symmetry=True.")
      if cs is None:
        cs = cs_from_ma

    if not self.params.generate_fake_p1_symmetry:
      msg = '''Symmetry information in model file is incomplete or missing.
If you want the program to generate P1 symmetry automatically, set
generate_fake_p1_symmetry=True.'''
      if not cs: raise Sorry(msg)
      elif cs.is_incomplete(): raise Sorry(msg)
    else:
      print('\nGenerating fake P1 symmetry', file=self.logger)

    pdb_hierarchy = mo.get_hierarchy()
    # need to preserve the order in the hierarchy in case we have to perform an
    # atom selection later
    # if cs is None, this will create a fake box, not sure how to get the same
    # box via model obj directly
    xray_structure = pdb_hierarchy.extract_xray_structure(crystal_symmetry = cs)
    if (cs is None): cs = xray_structure.crystal_symmetry()
    print('\nCrystal symmetry used: ', file=self.logger)
    cs.show_summary(f=self.logger)

    if (miller_array is not None):
      if (miller_array.crystal_symmetry() is None):
        miller_array = miller_array.customized_copy(crystal_symmetry=cs)
    xray_structure.show_summary(f = self.logger, prefix='  ')
    if(len(self.params.anomalous_scatterers.group) != 0):
      pdb_atoms = pdb_hierarchy.atoms()
      pdb_atoms.reset_i_seq()
      set_fp_fdp_for_anomalous_scatterers(
        pdb_hierarchy              = pdb_hierarchy,
        xray_structure             = xray_structure,
        anomalous_scatterer_groups = self.params.anomalous_scatterers.group)
    elif (self.params.wavelength is not None):
      print("Setting inelastic form factors for wavelength = %g" % \
        self.params.wavelength, file=self.logger)
      xray_structure.set_inelastic_form_factors(
        photon=self.params.wavelength,
        table="sasaki")

    if(self.params.random_seed is not None):
      random.seed(self.params.random_seed)
      flex.set_random_seed(self.params.random_seed)

    print("-"*79, file=self.logger)
    print("Computing model structure factors, Fmodel:", file=self.logger)
    if(self.params.output.format == "cns"): extension = ".hkl"
    elif(self.params.output.format == "mtz"): extension = ".mtz"
    ofn = self.params.output.file_name
    if(ofn is None):
      ofn = os.path.basename(self.data_manager.get_default_model_name())
      ofn = ofn + extension

    use_custom_scattering_dictionary = False
    if self.params.custom_scattering_factors:
      use_custom_scattering_dictionary = True
    mmtbx.utils.fmodel_from_xray_structure(
      xray_structure = xray_structure,
      f_obs          = miller_array,
      add_sigmas     = self.params.add_sigmas,
      params         = self.params,
      twin_law       = self.params.twin_law,
      twin_fraction  = self.params.twin_fraction,
      use_custom_scattering_dictionary = use_custom_scattering_dictionary,
      out            = self.logger).write_to_file(file_name = ofn,
        obs_type=self.params.output.obs_type)
    print("Output file name:", ofn, file=self.logger)
    print("All done.", file=self.logger)
    print("-"*79, file=self.logger)
    self.output_file = ofn

  def get_results(self):
    return group_args(
     output_file=self.output_file,
     model=self.data_manager.get_default_model_name())



 *******************************************************************************


 *******************************************************************************
mmtbx/programs/hbond.py
from __future__ import division, print_function
from libtbx.program_template import ProgramTemplate
import mmtbx.nci.hbond
import mmtbx.nci.skew_kurt_plot
from libtbx.utils import null_out
import os

# =============================================================================

class Program(ProgramTemplate):

  description = '''
phenix.hbond: tool to find H bonds in an atomic model

Usage example:
  phenix.hbond model.pdb
  '''

  datatypes = ['model', 'phil', 'restraint']


  master_phil_str = '''
  include scope mmtbx.nci.hbond.master_phil_str

  output_skew_kurtosis_plot = False
    .type = bool
    .short_caption = Output skew-kurtosis plot with result in png format
  plot_colorblind_friendly = True
    .type = bool
    .short_caption = Use colorblind friendly palette for skew-kurtosis plot
  do_rotate_translate = False
    .type = bool
    .style = hidden
  do_y_log = False
    .type = bool
    .style = hidden
  output_sk_coordinates = False
    .type = bool
  plot_parameters_override
    .help = These parameters will override preset values in plots. The values \
      will be passed directly to matplotlib functions, so should be valid \
      matplotlib color names.
  {
    colormap = None
      .type = str
    contour_left = None
      .type = str
    contour_right = None
      .type = str
    contour_thick_left = None
      .type = float(value_min=0.1, value_max=10)
    contour_thick_right = None
      .type = float(value_min=0.1, value_max=10)
    theta_color = None
      .type = str
    theta_contour = None
      .type = str
    Rha_color = None
      .type = str
    Rha_contour = None
      .type = str
  }
  '''
  # % mmtbx.nci.hbond.master_phil_str

  # ---------------------------------------------------------------------------
  def validate(self):
    self._print('Validating inputs')
    self.data_manager.has_models(raise_sorry=True)

  # ---------------------------------------------------------------------------
  def run(self):
    print('Using model: %s' % self.data_manager.get_default_model_name(),
      file=self.logger)
    inp_models = []
    for model_name in self.data_manager.get_model_names():
      inp_models.append((model_name, self.data_manager.get_model(model_name)))
    theta1_data = []
    Rha_data = []
    if self.params.output_sk_coordinates:
      file_names = []
    for m_name, model in inp_models:
      model.set_log(log = null_out())
      if self.params.hbond.add_hydrogens_if_absent and not model.has_hd():
        from elbow.command_line.ready_set import model_interface as ready_set_model_interface
        model = ready_set_model_interface(
            model=model,
            params=["add_h_to_water=False",
                    "optimise_final_geometry_of_hydrogens=False"],
            )
      model.process(make_restraints=True)
      self.results = mmtbx.nci.hbond.find(model = model)
      if self.params.hbond.show_hbonds:
        self.results.show(log = self.logger)
      self._print("-"*79)
      #self.results.show_summary(log = self.logger)
      prefix=self.params.output.prefix
      if not prefix:
        prefix='%s_hbond' % os.path.basename(m_name).split('.')[0]
      if self.params.hbond.output_pymol_file:
        self.results.as_pymol(prefix=prefix)
      if self.params.hbond.output_restraint_file:
        self.results.as_restraints(file_name='%s.eff' % prefix)
      #
      stats = mmtbx.nci.hbond.stats(model = model, prefix="%s_stats" % prefix,
        output_stats_pdf = self.params.hbond.output_stats_pdf)
      if stats is None:
        self._print('\n\tLimited number of H-bonds so statistics are not calculated.')
        return
      min_data_size=self.params.hbond.min_data_size
      # These are the values to be used for the plot!
      stats.all.show_summary(log = self.logger)
      if stats.all.get_counts(min_data_size=min_data_size):
        theta1_data.append(stats.all.get_counts(min_data_size=min_data_size).theta_1)
        Rha_data.append(   stats.all.get_counts(min_data_size=min_data_size).d_HA)
        if self.params.output_sk_coordinates:
          file_names.append(m_name)

    if self.params.output_skew_kurtosis_plot and len(theta1_data) > 0 and len(Rha_data) > 0:
      # To use other than 'all' type, nci.hbond.find needs to be called with selected model again,
      # like in stats().
      fn = '%s_skew_kurtosis' % prefix
      if self.params.plot_colorblind_friendly:
        fn += "_cbf"
      theta1_c = [(x.skew, x.kurtosis) for x in theta1_data]
      Rha_c = [(x.skew, x.kurtosis) for x in Rha_data]

      op = {}
      for param_name in dir(self.params.plot_parameters_override):
        if not param_name.startswith('__'):
          param_value = getattr(self.params.plot_parameters_override, param_name)
          if param_value != None:
            op[param_name] = param_value

      if self.params.output_sk_coordinates:
        from libtbx import group_args
        from libtbx import easy_pickle
        o = group_args(
          file_names    = file_names,
          theta1_coords = theta1_c,
          Rha_coords    = Rha_c)
        easy_pickle.dump(file_name="%s_coords.pkl"%prefix, obj = o)

      mmtbx.nci.skew_kurt_plot.make_figure(
          file_name=fn,
          theta1_coords=theta1_c,
          Rha_coords=Rha_c,
          dot_size = self.params.hbond.dot_size,
          type='all',
          override_palette = op,
          colorblind_friendly=self.params.plot_colorblind_friendly,
          do_rotate=self.params.do_rotate_translate,
          do_y_log=self.params.do_y_log,
          )
      self._print("\nOutputted plot as %s.png" % fn)

  # ---------------------------------------------------------------------------
  def get_results(self):
    return self.results

# =============================================================================
# end


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/holton_geometry_validation.py
"""
Holton geometry validation score calculation.  Based on a
script by James Holton (untangle_score.csh).  See details in
mmtbx/validation/holton_geometry_validation.py
"""

from __future__ import absolute_import, division, print_function

import os
from mmtbx.validation.holton_geometry_validation import \
    holton_geometry_validation
from libtbx.program_template import ProgramTemplate

try:
  from phenix.program_template import ProgramTemplate
except ImportError:
  pass

class Program(ProgramTemplate):
  prog = os.getenv('LIBTBX_DISPATCHER_NAME')
  description="""
%(prog)s file.pdb [params.eff] [options ...]

Options:

  model=input_file          input PDB file

Example:

  %(prog)s model=1ubq.pdb
""" % locals()


  master_phil_str = """
    model = None
      .type = path
      .optional = False
      .help = '''input PDB file'''

    other_models = None
      .type = path
      .help = "Models to compare with model"
      .multiple = True

    get_individual_residue_scores = None
      .type = bool
      .short_caption = Residue scores
      .help = Calculate individual residue scores in addition to overall score

    round_numbers = True
      .type = bool
      .short_caption = Round numbers
      .help = Round numbers before calculation

    worst_clash_is_one_plus_n_times_worst_clash = True
      .type = bool
      .short_caption = Scale clashes
      .help = Scale worst clash score by (1 + n) where n is total clashes

    clash_energy_add_n = True
      .type = bool
      .short_caption = Add N to clash energy
      .help = Add number of clashes to clash energy score

    minimum_nonbond_score_to_be_worst = -0.1
      .type = float
      .short_caption = Minimum worst nonbond_score
      .help = Only include worst nonbond score if it is at least this value

    minimum_nonbond_score_to_be_included_in_average = 0
      .type = float
      .short_caption = Minimum nonbond_score
      .help = Only include nonbond score in average if it is at least this value

    include_full_nonbond_score = True
      .type = bool
      .short_caption = Include full nonbond score
      .help = If set, add additional scoring term in which all nonbond \
              values (even those less than the minimums) are included

    keep_hydrogens = True
      .type = bool
      .short_caption = Keep hydrogens
      .help = If set, keep input hydrogens, but add any necessary riding H.

    ignore_cis_peptides = False
      .type = bool
      .short_caption = Ignore cis peptides
      .help = If set, ignore cis peptides. Otherwise (if False), penalize them.

    ignore_h_except_in_nonbond = True
      .type = bool
      .short_caption = Ignore H except in nonbond
      .help = If set, ignore H atoms except in nonbond term

    ignore_arg_h_nonbond = True
      .type = bool
      .short_caption = Ignore H in Arg
      .help = If set, ignore H atoms in Arginine

    ignore_bond_lengths_with_h = False
      .type = bool
      .short_caption = Ignore bond lengths with H
      .help = If set, ignore bond lengths involving H atoms

    ignore_water_h_bonds = False
      .type = bool
      .short_caption = Ignore water H bonds
      .help = If set, ignore nonbonded contacts with water hydrogens

    rotalyze_ramalyze_max_energy = 99
      .type = float
      .short_caption = Maximum ramalyze/rotalyze energy
      .help = Maximum value of energy for a bad rotamer or phi-psi combination

    overall_max_energy = None
      .type = float
      .short_caption = Maximum overall energy
      .help = Maximum value of energy

    omega_angle_sigma = 4
      .type = float
      .short_caption = Omega angle sigma
      .help = Sigma for omega angle
    cbetadev_sigma = 0.05
      .type = float
      .short_caption = CB position sigma
      .help = Sigma for CB position

    clashscore_ideal_dist = 3
      .type = float
      .short_caption = Clashscore ideal distance
      .help = Ideal distance in Lennard-Jones potential for clashscore result

    lj_dist_that_yields_zero = 6 # Distance for modified LJ to cross zero
      .type = float
      .short_caption = LJ distance yielding zero
      .help = Distance at which modified Lennard-Jones potential crosses zero

    const_shrink_donor_acceptor = 0
      .type = float
      .help = Allow contacts closer by const_shrink_donor_acceptor from \
                normal target for H-bonding atoms. NOTE: matches \
                behavior of Phenix pre-2024.
      .short_caption = Shrink donor acceptor distance

    remove_waters = None
      .type = bool
      .help = Remove waters before analysis
      .short_caption = Remove waters

    score_this_altloc_only = None
      .type = str
      .help = Score only this altloc if specified
      .short_caption = Score this altloc only

    softPnna_params {
      y0 = 1
      .type = float
      .help = Parameter y0 for softPnna calculation
      a2 = -0.0192266
      .type = float
      .help = Parameter a2 for softPnna calculation
      a1 = 0.751694
      .type = float
      .help = Parameter a1 for softPnna calculation
      a0 = 1.12482
      .type = float
      .help = Parameter a0 for softPnna calculation
      mx = 0.21805
      .type = float
      .help = Parameter mx for softPnna calculation
      my = 0.736621
      .type = float
      .help = Parameter my for softPnna calculation
     }


    include_random = True
      .type = bool
      .help = Estimate expected value for structure with normal errors
      .short_caption = Estimate expected value

    n_random = 20
      .type = int
      .help = Number of samples for estimation of expected values
      .short_caption = Number of samples for estimates

    random_seed = 171927
      .type = int
      .help = Random seed
      .short_caption = Random seed

    variable_params {
      clashscore_ideal_dist_values = 2.5 3 3 3 3.5
         .type = floats
         .help = Values to try for variables that are uncertain in comparison \
               between models
      lj_dist_that_yields_zero_values = 5 6 6 6 7
         .type = floats
      omega_angle_sigma_values = 4 5 6 7 8 9 10
         .type = floats
      cbetadev_sigma_values = .04  .05  .06
         .type = floats
      worst_clash_is_one_plus_n_times_worst_clash_values = 0 1
          .type = floats
      clash_energy_add_n_values = 0 1
          .type = floats
      minimum_nonbond_score_to_be_worst_values = -0.1  0.0
         .type = floats
      minimum_nonbond_score_to_be_included_in_average_values = 0 0 0 0  -1.1
         .type = floats
      include_full_nonbond_score_values = 0 1
         .type = floats
      ignore_arg_h_nonbond_values = 0 1
         .type = floats
      rotalyze_ramalyze_max_energy_values = 20  99 99 99  1000
         .type = floats
    }

"""


  datatypes = ['model','phil']

  def validate(self):
    self.set_defaults()
    self.data_manager.has_models(raise_sorry=True)

  def set_defaults(self):

    if not self.params.model:
      self.data_manager.has_models(raise_sorry=True)
      self.params.model = self.data_manager.get_default_model_name()
    self.model = self.data_manager.get_model(self.params.model)
    print("\nModel read from %s" %(self.params.model), file = self.logger)

    # decide if there are other models
    if not self.params.other_models:
      self.params.other_models = []
      for fn in self.data_manager.get_model_names():
        if fn != self.params.model:
          self.params.other_models.append(fn)
    if self.params.other_models:
      print("Other models to compare: %s" %(" ".join(self.params.other_models)),
        file = self.logger)

  def run(self):
    if self.params.other_models:  # Run comparison analysis
      return self.run_comparison()

    self.results = holton_geometry_validation(
      dm = self.data_manager,
     model = self.model,
     get_individual_residue_scores = self.params.get_individual_residue_scores,
     round_numbers = self.params.round_numbers,
     worst_clash_is_one_plus_n_times_worst_clash =
       self.params.worst_clash_is_one_plus_n_times_worst_clash,
     clash_energy_add_n = self.params.clash_energy_add_n,
     minimum_nonbond_score_to_be_worst =
         self.params.minimum_nonbond_score_to_be_worst,
     minimum_nonbond_score_to_be_included_in_average =
        self.params.minimum_nonbond_score_to_be_included_in_average,
     include_full_nonbond_score = self.params.include_full_nonbond_score,
     keep_hydrogens = self.params.keep_hydrogens,
     ignore_cis_peptides = self.params.ignore_cis_peptides,
     ignore_h_except_in_nonbond = self.params.ignore_h_except_in_nonbond,
     ignore_arg_h_nonbond = self.params.ignore_arg_h_nonbond,
     ignore_bond_lengths_with_h = self.params.ignore_bond_lengths_with_h,
     ignore_water_h_bonds = self.params.ignore_water_h_bonds,
     rotalyze_ramalyze_max_energy = self.params.rotalyze_ramalyze_max_energy,
     overall_max_energy = self.params.overall_max_energy,
     omega_angle_sigma = self.params.omega_angle_sigma,
     cbetadev_sigma = self.params.cbetadev_sigma,
     clashscore_ideal_dist = self.params.clashscore_ideal_dist,
     lj_dist_that_yields_zero = self.params.lj_dist_that_yields_zero,
     const_shrink_donor_acceptor = self.params.const_shrink_donor_acceptor,
     remove_waters = self.params.remove_waters,
     score_this_altloc_only = self.params.score_this_altloc_only,
     softPnna_params = self.params.softPnna_params,
     include_random = self.params.include_random,
     n_random = self.params.n_random,
      log =self.logger)

  def get_results(self):
    return self.results

  def get_results_as_JSON(self):
    return self.results.as_JSON(self.info_json)

  def run_comparison(self):
    """ Analyze model and other models with various values of parameters and
     determine which are convincingly better"""

    all_model_list = [self.model]
    for fn in self.params.other_models:
      all_model_list.append(self.data_manager.get_model(fn))
    self.params.other_models = []
    from copy import deepcopy
    base_params = deepcopy(self.params)

    base_params.include_random = False # skip this

    variable_params = {}
    for x in dir(self.params.variable_params):
      if x.startswith("__"): continue
      xx = x.replace("_values","")
      current_value = getattr(self.params,xx, None)
      value_list = getattr(self.params.variable_params, x)
      if current_value is None: continue
      elif current_value in [True, False]: # bool
        new_value_list = []
        for v in value_list:
          new_value_list.append(True if v==1 else False)
        value_list = new_value_list
      variable_params[xx] = value_list

    import random
    random.seed(self.params.random_seed)
    next_seed = random.randint(0,10000000)
    all_result_dict = {}
    for i in range(self.params.n_random):
      random.seed(next_seed)
      self.params = deepcopy(base_params)
      for key in list(variable_params.keys()):
        value_list = variable_params[key]
        n = len(value_list)
        k = random.randint(0,n-1)
        value = value_list[k]
        setattr(self.params,key,value)
      next_seed = random.randint(0,10000000)
      self.params.random_seed = next_seed
      next_seed = random.randint(0,10000000)

      # Ready to run on all the models
      all_result_dict[i] = []
      for model in all_model_list:
        self.model = model
        self.run()
        r = self.get_results()
        all_result_dict[i].append(r)
        print("RESULT:",self.params.omega_angle_sigma,r.sum_energy,model.info().file_name)
    value_list_dict = {}
    from scitbx.array_family import flex
    for k in range(len(all_model_list)):
      value_list = flex.double()
      for i in range(self.params.n_random):
        value_list.append(all_result_dict[i][k].sum_energy)
      value_list_dict[k] = value_list
      delta_list = value_list - value_list_dict[0]
      mean_delta = delta_list.min_max_mean().mean
      sd_delta = delta_list.standard_deviation_of_the_sample()
      print("Model %s:  delta: %.2f  SD %.2f" %(
        all_model_list[k].info().file_name, mean_delta, sd_delta),
         file = self.logger)

# =============================================================================
# for reference documentation keywords
master_phil_str = Program.master_phil_str


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/hydrogenate.py
from __future__ import absolute_import, division, print_function
import os, time
from libtbx.program_template import ProgramTemplate
#from libtbx.utils import null_out
from libtbx import group_args
from libtbx.str_utils import make_sub_header
from mmtbx.hydrogens import reduce_hydrogen

master_phil_str = '''
use_neutron_distances = False
  .type = bool
  .help = Use neutron distances

keep_existing_H = False
  .type = bool
  .help = Keep existing H atoms in the model

n_terminal_charge = *residue_one first_in_chain no_charge
  .type = choice(multi=False)
  .help = Mode for placing H3 at terminal nitrogen.

add_h_to_water = False
  .type = bool

add_d_to_water = False
  .type = bool

print_time = False
  .type = bool
'''

# ------------------------------------------------------------------------------

class Program(ProgramTemplate):
  description = '''
Add hydrogens.

Inputs:
  PDB or mmCIF file containing atomic model
  Ligand CIF file, if needed
'''
  datatypes = ['model', 'restraint', 'phil']
  master_phil_str = master_phil_str
  data_manager_options = ['model_skip_expand_with_mtrix',
                          'model_skip_ss_annotations']

  # ----------------------------------------------------------------------------

  def validate(self):
    self.data_manager.has_models(
      raise_sorry = True,
      expected_n  = 1,
      exact_count = True)

  # ----------------------------------------------------------------------------

  def run(self):
    t0 = time.time()
    self.model = self.data_manager.get_model()
    if self.data_manager.has_restraints():
      self.model.set_stop_for_unknowns(False)
      self.model.process(make_restraints=False)
    time_get_model = round(time.time()-t0, 2)

    make_sub_header('Add H atoms', out=self.logger)
    hydrogenate_obj = reduce_hydrogen.place_hydrogens(
      model                 = self.model,
      use_neutron_distances = self.params.use_neutron_distances,
      n_terminal_charge     = self.params.n_terminal_charge,
      print_time            = self.params.print_time)
    #import line_profiler
    #lp = line_profiler.LineProfiler(reduce_add_h_obj.run)
    #lp.enable()
    hydrogenate_obj.run()
    #lp.disable()
    #lp.print_stats()
    self.model = hydrogenate_obj.get_model()
    hydrogenate_obj.show(log = self.logger)

    if self.params.print_time:
      print("Get model obj in program template:", time_get_model)
      hydrogenate_obj.print_times()

    # Why is this done here and in the class?
    if self.params.add_h_to_water:
      self.model.add_hydrogens(1., occupancy=1.)
    elif self.params.add_d_to_water:
      self.model.add_hydrogens(1., element="D", occupancy=1.)

    if self.params.output.prefix is None:
      self.params.output.prefix = os.path.split(os.path.splitext(
        self.data_manager.get_default_model_name())[0])[1]

    if self.data_manager.get_model().input_model_format_cif():
      self.output_file_name = self.params.output.prefix+"_hydrogenate.cif"
      self.data_manager.write_model_file(
        model_str = self.model.model_as_mmcif(),
        filename  = self.output_file_name)
    else:
      self.output_file_name = self.params.output.prefix+"_hydrogenate.pdb"
      self.data_manager.write_model_file(
        model_str = self.model.model_as_pdb(),
        filename  = self.output_file_name)

    print("Wrote file: %s" % self.output_file_name, file=self.logger)

  # ----------------------------------------------------------------------------

  def get_results(self):
    return group_args(
     output_file_name=self.output_file_name)


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/ligand_restraints_validation.py
from __future__ import absolute_import, division, print_function

from libtbx.program_template import ProgramTemplate

# from cctbx.maptbx.box import shift_and_box_model

class Program(ProgramTemplate):

  description = '''
mmtbx.ligand_restraints_validation:

Usage examples:
  mmtbx.ligand_restraints_validation ligand.cif
  '''

  datatypes = ['phil', 'restraint']

  master_phil_str = """
  ligand_restraints_validation {
    input {
      restraints = None
        .type = path
      }
    action {
      use_hydrogens = True
        .type = bool
    }
    output {
      write_pdb = None
        .type = path
      write_geo = None
        .type = path
      write_input_pdb = None
        .type = path
    }
  }
"""

  # ---------------------------------------------------------------------------
  def validate(self):
    pass

  # ---------------------------------------------------------------------------
  def get_energies_sites(self, model, use_hydrogens=False):
    assert model.restraints_manager is not None
    if(use_hydrogens):
      rm = model.restraints_manager
      sc = model.get_sites_cart()
    else:
      hd_sel = model.get_xray_structure().hd_selection()
      rm = model.restraints_manager.select(~hd_sel)
      sc = model.get_sites_cart().select(~hd_sel)
    energies_sites = \
      rm.geometry.energies_sites(
        sites_cart        = sc,
        compute_gradients = False)
    return energies_sites #.bond_deviations()[2]

  def processed_ligand_restaints(self, filename):
    from mmtbx.monomer_library.geostd_utils import get_as_hierarchy
    from mmtbx.monomer_library.geostd_utils import as_cif_object
    hierarchy=get_as_hierarchy(filename)
    hierarchy.sort_atoms_in_place()
    # hierarchy.show()
    starting_atoms=hierarchy.atoms()
    starting_xyz=starting_atoms.extract_xyz()
    params = self.params.ligand_restraints_validation
    if params.output.write_input_pdb:
      hierarchy.write_pdb_file(params.output.write_input_pdb)
    #
    from mmtbx.model.model import manager
    m = manager(pdb_hierarchy=hierarchy,
                restraint_objects=[(filename, as_cif_object(filename))],
                )
    # m = shift_and_box_model(model = m, box_cushion = 5.)
    # for atom in m.get_hierarchy().atoms(): print(atom.format_atom_record())
    #
    # geom min
    #
    from mmtbx.refinement import geometry_minimization
    from six.moves import StringIO
    sio=StringIO()
    m.process(make_restraints=True)
    geometry_minimization.run2(
      restraints_manager = m.get_restraints_manager(),
      pdb_hierarchy = m.get_hierarchy(),
      correct_special_position_tolerance = 1.,
      bond        = True,
      nonbonded   = True,
      angle       = True,
      dihedral    = True,
      chirality   = True,
      planarity   = True,
      parallelity = True,
      log         = sio,
      )
    # m.set_sites_cart_from_hierarchy()
    # for atom in m.get_hierarchy().atoms(): print(atom.format_atom_record())
    h=m.get_hierarchy()
    if 0: h.write_pdb_file('test.pdb')
    if params.output.write_pdb:
      h.write_pdb_file(params.output.write_pdb)
    ending_xyz=h.atoms().extract_xyz()

    result={}
    rc = starting_xyz.rms_difference(ending_xyz)
    print('\n  RMSD of starting and ending coordinates : %5.2f' % rc, file=self.logger)
    result['RMSD']=rc
    result['atoms']=len(ending_xyz)
    es = self.get_energies_sites(m, use_hydrogens=params.action.use_hydrogens)
    # es.show()
    result['energies_sites']=es
    print('\nGeometry Min. result')
    es.show(f=self.logger)
    if params.output.write_geo:
      gs = m.restraints_as_geo()
      f=open(params.output.write_geo, 'w')
      f.write(gs)
      del f
    return result

  def run(self, log=None):
    self.results={}
    for filename in self.data_manager.get_restraint_names():
      rc = self.processed_ligand_restaints(filename)
      self.results[filename]=rc

  # ---------------------------------------------------------------------------
  def get_results(self):
    return self.results


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/mask.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.mask
from libtbx.program_template import ProgramTemplate
import iotbx.pdb
from cctbx import maptbx
from mmtbx.maps import fem
from mmtbx import masks

master_phil_str = '''
resolution=1.0
  .type=float
resolution_factor=1./4
  .type=float
'''

# ------------------------------------------------------------------------------

class Program(ProgramTemplate):
  description = '''
phenix.mask: Given PDB file calculate bulk-solvent mask

How to run:
  phenix.mask model.pdb
'''
  datatypes = ['model', 'phil']
  master_phil_str = master_phil_str

# ------------------------------------------------------------------------------

  def validate(self):
    self.data_manager.has_models(raise_sorry=True)

# ------------------------------------------------------------------------------

  def run(self):
    model = self.data_manager.get_model()
    xrs = model.get_xray_structure()
    crystal_gridding = maptbx.crystal_gridding(
      unit_cell         = xrs.unit_cell(),
      d_min             = self.params.resolution,
      resolution_factor = self.params.resolution_factor,
      symmetry_flags    = maptbx.use_space_group_symmetry,
      space_group_info  = xrs.space_group().info())
    mp = masks.mask_master_params.extract()
    mp.n_real = crystal_gridding.n_real()
    mp.step = None
    mmtbx_masks_asu_mask_obj = masks.asu_mask(
      xray_structure = xrs.expand_to_p1(sites_mod_positive=True),
      mask_params    = mp)
    bulk_solvent_mask = mmtbx_masks_asu_mask_obj.mask_data_whole_uc()
    #
    fem.ccp4_map(
      cg        = crystal_gridding,
      file_name = "mask.ccp4",
      map_data  = bulk_solvent_mask)


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/matthews.py
from __future__ import absolute_import, division, print_function
try:
  from phenix.program_template import ProgramTemplate
except ImportError:
  from libtbx.program_template import ProgramTemplate
from iotbx import crystal_symmetry_from_any
import iotbx.bioinformatics
from cctbx import crystal
from libtbx.utils import Sorry

master_phil_str = """
space_group = None
  .type = space_group
unit_cell = None
  .type = unit_cell
n_residues = None
  .type = int(value_min=1)
  .optional = True
n_bases = None
  .type = int(value_min=1)
  .optional = True
"""

# =============================================================================

class Program(ProgramTemplate):

  description = '''
Calculate the expected Matthews coefficient given the crystal symmetry and
crystallized molecule(s).

phenix.matthews [data.hkl] [space_group] [unit_cel] [sequence] [n_residues] ...
'''

  datatypes = ['model', 'phil', 'miller_array', 'sequence']

  master_phil_str = master_phil_str

  # ---------------------------------------------------------------------------

  def validate(self):
    '''
    Make sure there is correct amount of inputs
    '''
    print('Validating inputs...\n', file=self.logger)
    #
    # number of files
    if len(self.data_manager.get_miller_array_names()) > 1:
      raise Sorry('Supply at most one reflection file.')
    if len(self.data_manager.get_model_names()) > 1:
      raise Sorry('Supply at most one model file.')
    if len(self.data_manager.get_sequence_names()) > 1:
      raise Sorry('Supply at most one model file.')
    # Space group & unit cell - either from data file or from command line
    if (self.params.space_group is None) and (self.params.unit_cell is None):
      if not self.data_manager.has_miller_arrays():
        raise Sorry('You must supply both a space group and a unit cell, ' +
          'either via the command line or a data file).')
    elif (self.params.space_group is None) or (self.params.unit_cell is None):
        raise Sorry('Supply the space group and a unit cell either via the '+
          'command line or a data file.')
    else:
      if self.data_manager.has_miller_arrays():
        raise Sorry('No need to use a data file if space group and unit cell '+
          'are supplied.')
    # composition: either from sequence, model or command line
    if self.data_manager.has_models() and self.data_manager.has_sequences():
      raise Sorry('Supply either a model file or a sequence.')
    if not self.data_manager.has_sequences() and not self.data_manager.has_models():
      if (self.params.n_residues is None) and (self.params.n_bases is None):
        raise Sorry('You must specify the composition of the crystallized '+
          'entity - either a sequence, a partial model, or the number of '+
          'protein residues or nucleic acid bases.')
    else :
      if (self.params.n_residues is not None) or (self.params.n_bases is not None):
        raise Sorry('You may only specify a sequence file OR a partial model '+
          'OR the numbers of residues and/or bases.')

  # ---------------------------------------------------------------------------

  def run(self):
    '''
    Calculate Matthews coefficient and print the results
    '''
    # space group
    print('Space group and unit cell:', file=self.logger)
    if (self.params.space_group is None) and (self.params.unit_cell is None):
      data_fn = self.data_manager.get_miller_array_names()[0]
      print('From data file ', data_fn, file=self.logger)
      cs = crystal_symmetry_from_any.extract_from(file_name=data_fn)
      if cs is not None:
        sg_from_file = cs.space_group_info()
        if sg_from_file is not None:
          self.params.space_group = cs.space_group_info()
        uc_from_file = cs.unit_cell()
        if uc_from_file is not None:
          self.params.unit_cell = uc_from_file
    else:
      print('From command line inputs', file=self.logger)
    print('Space group:', self.params.space_group, file=self.logger)
    print('Unit cell:', self.params.unit_cell, file=self.logger)

    print('\nComposition:', file=self.logger)

    # composition from sequence
    if self.data_manager.has_sequences():
      print('Using sequence file ',
        self.data_manager.get_default_sequence_name(), file=self.logger)
      assert (self.params.n_residues == self.params.n_bases == None)
      seq_object = self.data_manager.get_sequence()[0]
      n_residues, n_bases = iotbx.bioinformatics.composition_from_sequence(
        sequence=seq_object.sequence)
      self.params.n_residues = n_residues
      self.params.n_bases = n_bases
    #else :
    #  raise Sorry("No composition information could be obtained from the "+
    #    "sequence file.")

    # composition from model file
    if self.data_manager.has_models():
      print('Using model file ',
        self.data_manager.get_default_model_name(), file=self.logger)
      assert (self.params.n_residues == self.params.n_bases == None)
      model = self.data_manager.get_model()
      self.params.n_residues = 0
      self.params.n_bases = 0
      hierarchy = model.get_hierarchy()
      comp = hierarchy.composition()
      self.params.n_residues = comp.n_protein
      self.params.n_bases = comp.n_nucleotide
    if (self.params.n_residues):
        print('Number of residues: %d' % self.params.n_residues, file=self.logger)
    if (self.params.n_bases):
        print('Number of bases: %d' % self.params.n_bases, file=self.logger)

    symm = crystal.symmetry(
      space_group_info=self.params.space_group,
      unit_cell=self.params.unit_cell)
    from mmtbx.scaling import matthews
    result = matthews.matthews_rupp(
      crystal_symmetry=symm,
      n_residues=self.params.n_residues,
      n_bases=self.params.n_bases)
    result.show(out=self.logger)
    return result


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/mp_validate_bonds.py
from __future__ import absolute_import, division, print_function

import os
from mmtbx.model import manager
from libtbx.program_template import ProgramTemplate
from libtbx.utils import null_out
import json
from mmtbx.validation.mp_validate_bonds import mp_validate_bonds
from datetime import datetime

class Program(ProgramTemplate):
  prog = os.getenv('LIBTBX_DISPATCHER_NAME')
  description="""\
%(prog)s file.pdb [params.eff] [options ...]

Options:

  model=input_file        input PDB file
  outliers_only=False   only print outliers
  json=False            Outputs results as JSON compatible dictionary
  use_cdl=True          Use the Conformational Dependent Library (cdl) for reference values
  verbose=False         verbose text output

Example:

  %(prog)s model=1ubq.pdb outliers_only=True
""" % locals()

  master_phil_str = """
  include scope mmtbx.validation.molprobity_cmdline_phil_str
  show_errors = False
    .type = bool
    .help = '''Print out errors'''
  json = False
    .type = bool
    .help = "Prints results as JSON format dictionary"
  use_cdl = True
    .type = bool
    .help = "Use conformational dependent library for reference values"
  use_parent = False
    .type = bool
  """
  datatypes = ['model','phil']
  data_manager_options = ['model_skip_expand_with_mtrix']
  known_article_ids = ['molprobity']

  def validate(self):
    self.data_manager.has_models(raise_sorry=True)

  def run(self):
    model = self.data_manager.get_model()
    model.set_stop_for_unknowns(False)
    hierarchy = model.get_hierarchy()
    self.info_json = {"model_name":self.data_manager.get_default_model_name(),
                      "time_analyzed": str(datetime.now()),
                      "params": {"use_cdl":self.params.use_cdl,
                                 "outliers_only":self.params.outliers_only,
                                 }}
    p = manager.get_default_pdb_interpretation_params()
    ##print(dir(p.pdb_interpretation))
    p.pdb_interpretation.allow_polymer_cross_special_position=True
    p.pdb_interpretation.flip_symmetric_amino_acids=False
    p.pdb_interpretation.clash_guard.nonbonded_distance_threshold = None
    p.pdb_interpretation.restraints_library.cdl=self.params.use_cdl
    model.set_log(log = null_out())
    model.process(make_restraints=True, pdb_interpretation_params=p)
    geometry = model.get_restraints_manager().geometry
    atoms = hierarchy.atoms()
    self.results = mp_validate_bonds(
      pdb_hierarchy=hierarchy,
      geometry_restraints_manager=geometry,
      outliers_only=self.params.outliers_only)
    if self.params.json:
      print(self.results.as_JSON(addon_json=self.info_json), file=self.logger)
    elif self.params.verbose:
      self.results.show(out=self.logger, verbose=True)

  def get_results(self):
    return self.results

  def get_results_as_JSON(self):
    return self.results.as_JSON(self.info_json)


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/nonbonded_overlaps.py
from __future__ import division, print_function
try:
  from phenix.program_template import ProgramTemplate
except ImportError:
  from libtbx.program_template import ProgramTemplate
import libtbx.load_env
#import time
import cctbx.geometry_restraints.nonbonded_overlaps as nbo
import cctbx.geometry_restraints.process_nonbonded_proxies as pnp
from elbow.command_line.ready_set import model_interface as ready_set_model_interface


master_phil_str = """

  keep_temp = False
    .type = bool
    .help = '''Keep temporary readyset folder'''

  add_hydrogen = True
    .type = bool
    .help = '''Add H atoms to input model.'''

  nuclear = False
    .type = bool
    .help = '''Use nuclear hydrogen positions'''
"""

# =============================================================================

class Program(ProgramTemplate):

  description = '''
phenix.nonbonded_overlaps file.pdb [params.eff] [options ...]

Options:

  add_hydrogen=True         Place H atoms with ready_set (recommended!)
  nuclear=False             Use nuclear X-H distances and vdW radii
  keep_temp=False           Keep temporary readyset folder

Example:

>>> mmtbx.nonbonded_overlaps xxxx.pdb keep_temp=True

>>> mmtbx.nonbonded_overlaps xxxx.pdb add_hydrogen=False

>>> mmtbx.nonbonded_overlaps xxxx.pdb yyyyy.cif add_hydrogen=False
'''

  datatypes = ['model', 'phil', 'restraint']

  master_phil_str = master_phil_str


  def validate(self):
    print('Validating inputs:\n', file=self.logger)
    self.data_manager.has_models(
      raise_sorry = True,
      expected_n  = 1,
      exact_count = True)


  def run(self):
    pdb_fn = self.data_manager.get_default_model_name()
    print('Using model file:', pdb_fn, file=self.logger)
    restraint_objects = list()
    if self.data_manager.has_restraints():
      print('Using restraints files', self.data_manager.get_restraint_names(),
        file=self.logger)
      for filename in self.data_manager.get_restraint_names():
        restraint_objects.append((filename, self.data_manager.get_restraint(filename)))

    model = self.data_manager.get_model()

    pi_params = model.get_default_pdb_interpretation_params()
    pi_params.pdb_interpretation.clash_guard.nonbonded_distance_threshold = None

    if self.params.nuclear:
      params.pdb_interpretation.use_neutron_distances = True

    # TODO: below are some non-defaults for pdb_interpretation,
    # but they cannot be changed
    # Do we need the non-defaults?
    # assume_hydrogens_all_missing --> default is False, but becomes True if H are present
    # hard_minimum_nonbonded_distance --> default is 0.001 but is 0 in NBO
    # substitute_non_crystallographic_unit_cell_if_necessary --> not necessary

    # add H atoms with readyset
    if self.params.add_hydrogen:
      params=["add_h_to_water=False",
              "optimise_final_geometry_of_hydrogens=False"]
      assert (libtbx.env.has_module(name="reduce"))
      assert (libtbx.env.has_module(name="elbow"))
      readyset_model = ready_set_model_interface(
            model  = model,
            params = params,
            keep_temp = self.params.keep_temp)
    else:
      readyset_model = model

    readyset_model.set_restraint_objects(restraint_objects)
    readyset_model.process(make_restraints=True,
      pdb_interpretation_params = pi_params)

    # TODO: do we need macro_mol_sel, do we care?
    # If we use model.select(), we don't need it.
    macro_mol_sel = readyset_model.selection(
      string = 'protein or dna or rna')

    #t0 = time.time()
    nb_overlaps = nbo.info(
      model = readyset_model,
      macro_molecule_selection=macro_mol_sel)
    #t1 = time.time()

    nb_overlaps.show(
      log=self.logger,
      nbo_type='all',
      normalized_nbo=True)

    #t2 = time.time()
    processed_nbps = pnp.manager(model = readyset_model)
    clashes = processed_nbps.get_clashes()
    #t3 = time.time()
    clashes.show(log=self.logger)

    hbonds = processed_nbps.get_hbonds()
    hbonds.show(log=self.logger)

    #print("OLD time: %8.3f"%(t1-t0))
    #print("NEW time: %8.3f"%(t3-t2))


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/omegalyze.py
from __future__ import absolute_import, division, print_function

import os
from mmtbx.validation.omegalyze import omegalyze
from libtbx.program_template import ProgramTemplate
from libtbx.utils import Sorry
from datetime import datetime

class Program(ProgramTemplate):
  prog = os.getenv('LIBTBX_DISPATCHER_NAME')
  description="""
%(prog)s file.pdb [params.eff] [options ...]

Options:

  model=input_file      input PDB or mmCIF file
  nontrans_only=True    only print nontrans residues (does not affect kinemage)
  text=True          verbose colon-delimited text output (default)
  kinemage=False        Create kinemage markup (overrides text output)
  json=False            Outputs results as JSON compatible dictionary
  help = False          Prints this help message if true

  text output is colon-delimited and follows the format:
    residue:type:omega:conformation
      'residue' is a unique residue identifier
      'type' is either proline or general case
      'omega' is the calculated omega dihedral for the peptide between this
        residue and the preceeding residue
      'conformation' is: cis for omega within 30 degrees of planar cis
                         trans for omega within 30 degrees of planar trans
                         twisted for omega not within 30 degrees of planar

  SUMMARY statistics provide:
    counts of cis prolines and twisted prolines relative to total prolines with
      measurable omega dihedrals across all chains
    counts of non-proline cis and twisted peptides relative to total non-proline
      peptides with measurable omega dihedrals across all chains

  Cis Prolines occur in ~5%% of prolines (1 in 20) at high resolution
  Non-Proline Cis residues occur in ~0.05%% of residues (1 in 2000) and require
    clear support from experimental data or homology.
  Twisted peptides are even less frequent and are highly suspect without
    high-resolution data.

Example:

  %(prog)s model=1ubq.pdb kinemage=True
""" % locals()

  master_phil_str = """
    nontrans_only = True
      .type = bool
      .help = "Controls whether trans peptides are stored and printed"
    text = True
      .type = bool
      .help = "Prints verbose, colon-delimited text output and summary"
    kinemage = False
      .type = bool
      .help = "Prints kinemage markup for cis-peptides"
    json = False
      .type = bool
      .help = "Prints results as JSON format dictionary"
    oneline = False
      .type = bool
      .help = "Prints oneline-style summary statistics"
    result_file = None
      .type = path
      .help = "Path for output file"
"""
  datatypes = ['model','phil']
  data_manager_options = ['model_skip_expand_with_mtrix']

  def validate(self):
    self.data_manager.has_models(raise_sorry=True)

  def run(self):
    f = None
    if self.params.result_file is not None:
      try:
        f = open(self.params.result_file, 'w')
        self.logger.register('file', f)
      except IOError:
        raise Sorry("The output file could not be opened")
    hierarchy = self.data_manager.get_model().get_hierarchy()
    self.info_json = {"model_name":self.data_manager.get_default_model_name(),
                      "time_analyzed": str(datetime.now())}

    self.results = omegalyze(
      pdb_hierarchy=hierarchy,
      nontrans_only=self.params.nontrans_only,
      out=self.logger,
      quiet=False)
    if self.params.kinemage:
      print(self.results.as_kinemage(), file=self.logger)
    elif self.params.oneline:
      self.results.summary_only(out=self.logger, pdbid=self.data_manager.get_default_model_name())#params.model)
    elif self.params.json:
      print(self.results.as_JSON(addon_json=self.info_json), file=self.logger)
    elif self.params.text:
      self.results.show_old_output(out=self.logger, verbose=True)
    if f:
      try:
        f.close()
      except Exception:
        raise Sorry("Could not close output file")

  def get_results(self):
    return self.results

  def get_results_as_JSON(self):
    return self.results.as_JSON(self.info_json)


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/pdb_as_cif.py

from __future__ import absolute_import, division, print_function
try:
  from phenix.program_template import ProgramTemplate
except ImportError:
  from libtbx.program_template import ProgramTemplate
import os

master_phil_str = '''
model_file_name = None
  .type = path
  .short_caption = Model file
  .multiple = False
  .help = Model file name
  .style = file_type:pdb bold input_file
'''

class Program(ProgramTemplate):
  datatypes = ['model', 'phil', 'restraint']
  master_phil_str = master_phil_str

  def validate(self):
    model = self.data_manager.get_model()
    hierarchy = model.get_hierarchy()
    pdb_atoms = hierarchy.atoms()
    pdb_atoms.set_chemical_element_simple_if_necessary()
    elements = pdb_atoms.extract_element().strip()
    if (not elements.all_ne("")):
      n_missing = elements.count("")
      raise RuntimeError("Missing element symbol for %d atoms." % n_missing)

  def run(self):
    file_name = self.data_manager.get_model_names()[0]
    print("Converting %s to mmCIF format." %file_name)
    basename = os.path.splitext(os.path.basename(file_name))[0]
    model = self.data_manager.get_model()
    txt = model.model_as_mmcif()
    print(txt)
    with open(basename+".cif", 'w') as f:
      f.write(txt)
    print("  wrote %s.cif" % basename)



 *******************************************************************************


 *******************************************************************************
mmtbx/programs/pdbtools.py
# -*- coding: utf-8 -*-
from __future__ import absolute_import, division, print_function
from libtbx.program_template import ProgramTemplate
from mmtbx import pdbtools
from libtbx import Auto
import os
import mmtbx.pdbtools
from cctbx import uctbx

class Program(ProgramTemplate):

  description = '''
phenix.pdbtools tools for PDB model manipulations.

Usage examples:
  phenix.pdbtools model.pdb sites.shake=0.4
  phenix.pdbtools model.cif remove="element H"
  '''

  datatypes = ['model', 'phil']

  master_phil_str = """\
include scope mmtbx.pdbtools.master_params

output {
  prefix = None
    .type = str
  suffix = _modified
    .type = str
  serial = None
    .type = int
  overwrite = True
    .type = bool
}
# temporary GUI PHIL
include scope libtbx.phil.interface.tracking_params
gui
  .help = "GUI-specific parameter required for output directory"
{
  output_dir = None
  .type = path
  .style = output_dir
}
"""

  def validate(self):
    print('Validating inputs', file=self.logger)
    self.data_manager.has_models(
      raise_sorry = True,
      expected_n  = 1,
      exact_count = True)

  def run(self):
    self.model = self.data_manager.get_model()
    cs = self.model.crystal_symmetry()
    if(cs is None or cs.is_empty() or cs.is_nonsense()):
      print("Crystal symmetry undefined, creating fake P1 box.")
      box_crystal_symmetry = \
        uctbx.non_crystallographic_unit_cell_with_the_sites_in_its_center(
          sites_cart   = self.model.get_sites_cart(),
          buffer_layer = 5).crystal_symmetry()
      self.model.set_crystal_symmetry(crystal_symmetry = box_crystal_symmetry)
    print('Performing manipulations', file=self.logger)
    self.model = mmtbx.pdbtools.modify(
      model  = self.model,
      params = self.params.modify,
      log    = self.logger).get_results().model
    # Write output model file
    input_file_name_base = os.path.basename(
      self.data_manager.get_default_model_name())[:-4]
    if(  self.model.input_model_format_cif()) or (
       not self.model.can_be_output_as_pdb()):
          extension = ".cif"
    elif(self.model.input_model_format_pdb()): extension = ".pdb"
    else:
      assert self.model.input_model_format_pdb() or \
        self.model.input_model_format_cif()
    if(self.params.output.prefix is not None):
      output_file_name = self.params.output.prefix
      if(self.params.output.suffix is not None):
        output_file_name = output_file_name + self.params.output.suffix
    else:
      output_file_name = input_file_name_base + self.params.output.suffix
    output_file_name = output_file_name + extension
    ofn = self.get_default_output_filename(
      prefix=output_file_name,
      suffix=None,
      serial=Auto)
    print('Writing output model to %s' %ofn, file=self.logger)
    output_cs=True
    if(cs is None): output_cs = False

    self.data_manager.write_model_file(self.model, ofn, output_cs=output_cs)
    self.result = ofn

  def get_results(self):
    return self.result

# So master_phil_str can be called
master_phil_str = Program.master_phil_str


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/polder.py
from __future__ import absolute_import, division, print_function
from six.moves import zip
try:
  from phenix.program_template import ProgramTemplate
except ImportError:
  from libtbx.program_template import ProgramTemplate
import os
from libtbx.utils import Sorry
import mmtbx.maps.polder
from iotbx import crystal_symmetry_from_any
from iotbx import mrcfile
from libtbx import group_args
from cctbx.array_family import flex

master_phil_str = '''
include scope libtbx.phil.interface.tracking_params
include scope mmtbx.maps.polder.master_params
solvent_exclusion_mask_selection = None
  .type = str
  .short_caption = Omit selection
  .help = Atoms around which bulk solvent mask is set to zero
  .input_size = 400
scattering_table = *n_gaussian wk1995 it1992 neutron electron
  .type = choice
  .short_caption = Scattering table
  .help = Scattering table for structure factors calculations
output_file_name_prefix = None
  .type = str
  .short_caption = Output prefix
  .help = Prefix for output filename
mask_output = False
  .type = bool
  .short_caption = Output masks
  .help = Additional output: ccp4 maps containing the solvent mask for inital \
   model (mask_all.ccp4), when ligand is omitted (mask_omit.ccp4) and the mask \
   used for polder (mask_polder.ccp4)
debug = False
  .type = bool
  .expert_level = 3
  .short_caption = Output biased map
  .help = Additional output: biased omit map (ligand used for mask calculation \
   but omitted from model)
gui
  .help = "GUI-specific parameter required for output directory"
{
  output_dir = None
  .type = path
  .style = output_dir

  data_column_label = None
  .type = str
  .style = noauto renderer:draw_any_label_widget
  .input_size = 200

  free_column_label = None
  .type = str
  .style = noauto renderer:draw_any_label_widget
  .input_size = 200
}
'''

# =============================================================================

class Program(ProgramTemplate):

  description = '''

Computes omit maps by excluding the bulk solvent in the area around a
selection. An example of application are ligand omit maps. Polder omit maps
can be helpful if the ligand density is weak and obscured by bulk solvent
in conventional omit maps (where the ligand is deleted from the model).

Inputs:
  - Reflection file: It can be in most of known formats and data can be
    spread across multiple files (Fobs in one file, Rfree in another)
  - Model file
  - Omit selection (such as for a ligand)
  - optional: label(s) for data arrays to be used

Usage examples:
  1. phenix.polder model.cif data.mtz selection="chain A and resseq 1"
  2. phenix.polder model.pdb data.hkl data_labels="FP" selection="chain A"
  3. phenix.polder a.hkl b.hkl model.pdb selection="resseq 435"

Output:
  MTZ file with map coefficients for:
  Polder map:
  - mFo-DFc_polder    : polder difference map coefficients
  - PHImFo-DFc_polder : corresponding phases
  Omit map:
  For this map, the OMIT selection is deleted from the model and bulk solvent
  enters the area.
  - mFo-DFc_omit      : omit difference map coefficients
  - PHImFo-DFc_omit   : corresponding phases

Optional output:
  CCP4 files with mask data:
  - mask_all.ccp4    : mask of original model
  - mask_omit.ccp4   : mask when ligand is omitted
  - mask_polder.ccp4 : mask obtained by polder procedure

'''

  datatypes = ['model', 'phil', 'miller_array']

  master_phil_str = master_phil_str
  known_article_ids = ['phenix.polder']
  use_scattering_table_for_default_type = 'scattering_table'

  # ---------------------------------------------------------------------------

  def validate(self):
    print('Validating inputs:\n', file=self.logger)
    self.data_manager.has_models(
      raise_sorry = True,
      expected_n  = 1,
      exact_count = True)
    self.data_manager.has_miller_arrays(raise_sorry=True)
    if (len(self.data_manager.get_miller_array_names()) > 2):
      raise Sorry('Dont input more than 2 reflection files.')

    if (self.params.solvent_exclusion_mask_selection is None):
      raise Sorry('''Selection for atoms to be omitted is required.

  Try something like

    solvent_exclusion_mask_selection="resname LIG"
  ''')
    if (self.params.polder.sphere_radius < 3):
      raise Sorry("Sphere radius out of range: must be larger than 3 A")
    if (self.params.polder.box_buffer is not None and
      (self.params.polder.box_buffer < 0 or self.params.polder.box_buffer > 5)):
      raise Sorry("Box buffer out of range: must be between 0 and 5")

    if (self.params.polder.resolution_factor < 0.0):
      raise Sorry('Use a positive value for the resolution gridding factor.')

    self.fmodel = None
    try:
      self.fmodel = self.data_manager.get_fmodel(
        scattering_table = self.params.scattering_table)
    except Sorry as s:
      if 'previously used R-free flags are available run this command again' in str(s):
        #TODO print stuff here to informa that there is no Rfree flag
        fmodel_params = self.data_manager.get_fmodel_params()
        fmodel_params.xray_data.r_free_flags.required = False
        fmodel_params.xray_data.r_free_flags.ignore_r_free_flags = True
        self.data_manager.set_fmodel_params(fmodel_params)
        self.fmodel = self.data_manager.get_fmodel(
          scattering_table = self.params.scattering_table)
    if self.fmodel is None:
      raise Sorry('Failed to create fmodel. Please submit a bug report.')

  # ---------------------------------------------------------------------------

  def get_crystal_symmetry(self):
    crystal_symmetries = []
    files = self.data_manager.get_model_names() + \
      self.data_manager.get_miller_array_names()
    for f in files:
      cs = crystal_symmetry_from_any.extract_from(f)
      if (cs is not None):
        crystal_symmetries.append(cs)

    if (len(crystal_symmetries) == 1): crystal_symmetry = crystal_symmetries[0]
    elif (len(crystal_symmetries) == 0):
     raise Sorry("No crystal symmetry found.")
    else:
      if (not crystal_symmetries[0].is_similar_symmetry(crystal_symmetries[1])):
        raise Sorry("Crystal symmetry mismatch between different files.")
        # TODO what if 3 symmetries?
      crystal_symmetry = crystal_symmetries[0]
    return crystal_symmetry

  # ---------------------------------------------------------------------------

  def prepare_f_obs_and_flags_if_anomalous(self, f_obs, r_free_flags):
    sel = f_obs.data()>0
    f_obs = f_obs.select(sel)
    merged = f_obs.as_non_anomalous_array().merge_equivalents()
    f_obs = merged.array().set_observation_type(f_obs)
    if r_free_flags:
      r_free_flags = r_free_flags.select(sel)
      merged_free = r_free_flags.as_non_anomalous_array().merge_equivalents()
      r_free_flags = merged_free.array().set_observation_type(r_free_flags)
      f_obs, r_free_flags = f_obs.common_sets(r_free_flags)
    return f_obs, r_free_flags

  # ---------------------------------------------------------------------------

  def check_selection(self, pdb_hierarchy):
    print("*"*79, file=self.logger)
    print('Selecting atoms...\n', file=self.logger)
    print('Selection string:', self.params.solvent_exclusion_mask_selection,
      file=self.logger)

    selection_bool = pdb_hierarchy.atom_selection_cache().selection(
      string = self.params.solvent_exclusion_mask_selection)
    n_selected = selection_bool.count(True)
    n_selected_all = pdb_hierarchy.atom_selection_cache().selection(
      string = 'all').count(True)
    if(n_selected == 0):
      raise Sorry("No atoms where selected. Check selection syntax again.")
    if (n_selected/n_selected_all > 0.5):
      raise Sorry("""More than half of total number of atoms selected. Omit
        selection should be smaller, such as one ligand or a few residues.""")

    print('Number of atoms selected:', n_selected, file=self.logger)
    pdb_hierarchy_selected = pdb_hierarchy.select(selection_bool)
    ligand_str = pdb_hierarchy_selected.as_pdb_or_mmcif_string(target_format='pdb')
    print(ligand_str, file=self.logger)
    print("*"*79, file=self.logger)

    return selection_bool

  # ---------------------------------------------------------------------------

  def broadcast_rfactors(self, r_work, r_free):
    print('R_work = %6.4f R_free = %6.4f' % (r_work, r_free), file=self.logger)
    print ('*'*79, file=self.logger)

  # ---------------------------------------------------------------------------

  def print_rfactors(self):
    print ('*'*79, file=self.logger)
    fmodel_input  = self.results.fmodel_input
    fmodel_biased = self.results.fmodel_biased
    fmodel_omit   = self.results.fmodel_omit
    fmodel_polder = self.results.fmodel_polder
    print('R factors for unmodified input model and data:', file=self.logger)
    self.broadcast_rfactors(fmodel_input.r_work(), fmodel_input.r_free())
    if (self.params.debug):
      print('R factor when ligand is used for mask calculation (biased map):',
        file=self.logger)
      self.broadcast_rfactors(fmodel_biased.r_work(), fmodel_biased.r_free())
    print('R factor for polder map', file=self.logger)
    self.broadcast_rfactors(fmodel_polder.r_work(), fmodel_polder.r_free())
    print('R factor for OMIT map (ligand is excluded for mask calculation):',
      file=self.logger)
    self.broadcast_rfactors(fmodel_omit.r_work(), fmodel_omit.r_free())

  # ---------------------------------------------------------------------------

  def write_files(self, f_obs):
    if (self.params.mask_output):
      masks = [self.results.mask_data_all,
               self.results.mask_data_omit,
               self.results.mask_data_polder]
      filenames = ["all", "omit", "polder"]
      for mask_data, filename in zip(masks, filenames):
        mrcfile.write_ccp4_map(
          file_name   = "mask_" + filename + ".ccp4",
          unit_cell   = f_obs.unit_cell(),
          space_group = f_obs.space_group(),
          map_data    = mask_data,
          labels      = flex.std_string([""]))
    mtz_dataset = self.results.mc_polder.as_mtz_dataset(
      column_root_label = "mFo-DFc_polder")
    mtz_dataset.add_miller_array(
      miller_array      = self.results.mc_omit,
      column_root_label = "mFo-DFc_omit")
    if (self.params.debug):
      mtz_dataset.add_miller_array(
        miller_array      = self.results.mc_biased,
        column_root_label = "mFo-DFc_bias_omit")
    mtz_object = mtz_dataset.mtz_object()
    polder_file_name = "polder_map_coeffs.mtz"
    if (self.params.output_file_name_prefix is not None):
      polder_file_name = self.params.output_file_name_prefix + "_" + polder_file_name
    mtz_object.write(file_name = polder_file_name)
    self.output_file_name = polder_file_name
    print('File %s was written.' % polder_file_name, file=self.logger)

  # ---------------------------------------------------------------------------

  def print_validation(self):
    vr = self.results.validation_results
    if vr is None:
      return ''
    print('Map 1: calculated Fobs with ligand', file=self.logger)
    print('Map 2: calculated Fobs without ligand', file=self.logger)
    print('Map 3: real Fobs data', file=self.logger)
    print('CC(1,2): %6.4f' % vr.cc12, file=self.logger)
    print('CC(1,3): %6.4f' % vr.cc13, file=self.logger)
    print('CC(2,3): %6.4f' % vr.cc23, file=self.logger)
    print('Peak CC:', file=self.logger)
    print('CC(1,2): %6.4f' % vr.cc12_peak, file=self.logger)
    print('CC(1,3): %6.4f' % vr.cc13_peak, file=self.logger)
    print('CC(2,3): %6.4f' % vr.cc23_peak, file=self.logger)
    print('q    D(1,2) D(1,3) D(2,3)', file=self.logger)
    for c,d12_,d13_,d23_ in zip(vr.cutoffs,vr.d12,vr.d13,vr.d23):
      print('%4.2f %6.4f %6.4f %6.4f'%(c,d12_,d13_,d23_), file=self.logger)
    ###
    if(self.params.debug):
      self.write_map_box(
        box      = vr.box_1,
        filename = "box_1_polder.ccp4")
      self.write_map_box(
        box      = vr.box_2,
        filename = "box_2_polder.ccp4")
      self.write_map_box(
        box      = vr.box_3,
        filename = "box_3_polder.ccp4")
      vr.ph_selected.write_pdb_or_mmcif_file(target_filename="box_polder.pdb",
        target_format = 'pdb')
      #crystal_symmetry=vr.box_1.model().crystal_symmetry()
    #
    print ('*'*79, file=self.logger)
    message = self.result_message(cc12 = vr.cc12, cc13 = vr.cc13, cc23 = vr.cc23)
    if self.params.scattering_table=='electron':
      message=''
    print(message, file=self.logger)
    return message

  # ---------------------------------------------------------------------------

  def write_map_box(self, box, filename):
      box.map_manager().write_map(filename)

  # ---------------------------------------------------------------------------

  def result_message(self, cc12, cc13, cc23):
    if (cc13 < 0.7 or
        (cc23 > cc12 and cc23 > cc13) or (cc13 < cc12 and cc13 < cc23)):
      msg = """The polder map is very likely to show bulk-solvent or noise."""
    elif (cc13 >= 0.8):
      msg = 'The polder map is likely to show the omitted atoms.'
    elif (cc13 >= 0.7 and cc13 < 0.8):
      if (cc23 < 0.7*cc13):
        msg = """\
The polder map is more likely to show the omitted atoms than bulk solvent.
It is recommended to carefully inspect the maps to confirm."""
      else:
        msg = """\
The polder map is more likely to show bulk-solvent or noise instead of the
omitted atoms. But it is recommended to inspect the maps to confirm."""
    return msg

  # ---------------------------------------------------------------------------

  def run(self):

    print('Using model file:', self.data_manager.get_default_model_name(),
      file=self.logger)
    print('Using reflection file(s):', self.data_manager.get_miller_array_names(),
      file=self.logger)

    cs = self.get_crystal_symmetry()

    model = self.data_manager.get_model()
    ph = model.get_hierarchy()
    xrs = model.get_xray_structure()
    selection_bool = self.check_selection(pdb_hierarchy = ph)

    f_obs, r_free_flags = self.fmodel.f_obs(), self.fmodel.r_free_flags()

    print('Input data...', file=self.logger)
    print('  Reflection data:', f_obs.info().labels, file=self.logger)
    if (r_free_flags.info() is not None):
      print('  Free-R flags:', r_free_flags.info().labels, file=self.logger)
    else:
      print('  Free-R flags: not present or not found', file=self.logger)
    print('\nWorking crystal symmetry after inspecting all inputs:', file=self.logger)
    cs.show_summary(f=self.logger)

    if (f_obs.anomalous_flag()):
      f_obs, r_free_flags = self.prepare_f_obs_and_flags_if_anomalous(
        f_obs        = f_obs,
        r_free_flags = r_free_flags)

    model_basename = os.path.basename(
      self.data_manager.get_default_model_name().split(".")[0])
    if (len(model_basename) > 0 and self.params.output_file_name_prefix is None):
      self.params.output_file_name_prefix = model_basename

    polder_object = mmtbx.maps.polder.compute_polder_map(
      f_obs            = f_obs,
      r_free_flags     = r_free_flags,
      model            = model,
      params           = self.params.polder,
      selection_string = self.params.solvent_exclusion_mask_selection)

    polder_object.validate()
    polder_object.run()
    self.results = polder_object.get_results()

    self.print_rfactors()
    self.write_files(f_obs = f_obs)
    self.message = None
    if (not self.params.polder.compute_box):
      self.message = self.print_validation()

    print ('*'*79, file=self.logger)
    print ('Finished', file=self.logger)


  def get_results(self):
    # results object not returned because it contains maps
    return group_args(
      message     = self.message,
      output_file = self.output_file_name,
      model       = self.data_manager.get_default_model_name())


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/prepare_pdb_deposition.py
from __future__ import absolute_import, division, print_function

import os

from six.moves import cStringIO as StringIO

from libtbx import group_args
from libtbx.program_template import ProgramTemplate
from libtbx.utils import Sorry

# =============================================================================
class Program(ProgramTemplate):

  description = '''
Program for preparing model and data files for depostion into the Protein
Data Bank.

Minimum required data:
  Model file
  Sequence file

The sequence file should have a sequence for each chain in the model file.

Currently, this program only combines the model and sequence into a single
mmCIF file. If the input model is in mmCIF format, extra loops in the
file that are not modified will be kept.

Adding sequences will populate the entity_poly, entity_poly_seq,
struct_ref, and struct_ref_seq loops. The struct_ref and struct_ref_seq
loops are works in progress and will require external information. Also,
the canonical sequence containing all residues for the structure should
be provided. If there are non-standard residues in the model, they will
be automatically changed to the 3 letter residue name surrounded by
parentheses.

More functionality is planned.
'''

  datatypes = ['model', 'phil', 'restraint', 'sequence']

  master_phil_str = '''
mmtbx.validation.sequence.sequence_alignment {
  include scope mmtbx.validation.sequence.master_phil
}
custom_residues = None
  .type = strings
  .help = Space-separated list of three letter codes to be included in \
    the entity_poly.pdbx_one_letter_code mmCIF loop \
    (e.g. custom_residues='SUI PYL')
keep_original_loops = True
  .type = bool
  .help = Preserves mmCIF data from the input model file (if available) that \
    is not overwritten by other input
align_columns = False
  .type = bool
  .help = When set to True, the columns are aligned. This will take longer \
    because the column widths need to be deteremined before outputting.
include scope mmtbx.monomer_library.pdb_interpretation.grand_master_phil_str
include scope mmtbx.geometry_restraints.torsion_restraints.reference_model.reference_model_str
include scope mmtbx.geometry_restraints.external.external_energy_params_str
output {
  suffix = '.deposit'
    .type = str
    .help = Suffix string added to automatically generated output filenames
}

# PHIL parameters for current GUI
include scope libtbx.phil.interface.tracking_params
gui
  .help = "GUI-specific parameter required for output directory"
{
  output_dir = None
  .type = path
  .style = output_dir
}
'''
  # ---------------------------------------------------------------------------
  def custom_init(self):
    self.output_file = None

  # ---------------------------------------------------------------------------
  def validate(self):
    self.data_manager.has_models(expected_n=1, exact_count=True, raise_sorry=True)
    self.data_manager.has_sequences(raise_sorry=True)
    model = self.data_manager.get_model()
    if not model.input_model_format_cif():
      raise Sorry('Your input model must already be in mmCIF.')

  # ---------------------------------------------------------------------------
  def run(self):
    print('Using model: {model_name}'.format(
      model_name=self.data_manager.get_default_model_name()))
    print('Using sequence(s): {sequence_names}'.format(
      sequence_names=', '.join(self.data_manager.get_sequence_names())))

    # get model
    model = self.data_manager.get_model()
    model.set_log(self.logger)

    # add sequences
    sequences = list()
    for sequence_name in self.data_manager.get_sequence_names():
      sequences.extend(self.data_manager.get_sequence(sequence_name))

    # match input sequences with model chains
    print(file=self.logger)
    print('Matching sequences to chains', file=self.logger)
    print('----------------------------', file=self.logger)
    # No error trapping
    model.set_sequences(
      sequences,
      custom_residues=self.params.custom_residues,
      similarity_matrix=self.params.mmtbx.validation.sequence.sequence_alignment.similarity_matrix,
      min_allowable_identity=self.params.mmtbx.validation.sequence.sequence_alignment.min_allowable_identity)

    # When the input is already in mmCIF, just add sequence information
    found_cif_block = False
    if hasattr(model._model_input, 'cif_model'):
      for cif_block in model._model_input.cif_model.values():
        if '_atom_site' in cif_block:
          cif_block.update(model._sequence_validation.sequence_as_cif_block())
          out = StringIO()
          model._model_input.cif_model.show(
            out=out, align_columns=self.params.align_columns)
          self.cif_model = out.getvalue()
          found_cif_block = True
          break
    # otherwise, generate mmCIF
    if not found_cif_block:
      model.get_restraints_manager()
      self.cif_model = model.model_as_mmcif(
        align_columns=self.params.align_columns,
        keep_original_loops=self.params.keep_original_loops)

    # show sequence alignment
    model._sequence_validation.show(out=self.logger)
    print(file=self.logger)

    # write output file to current directory
    if self.params.output.prefix is None:
      self.params.output.prefix = os.path.split(os.path.splitext(
        self.data_manager.get_default_model_name())[0])[1]
    self.data_manager.set_default_output_filename(
      self.get_default_output_filename())
    self.output_file = self.data_manager.get_default_output_model_filename()
    print('Writing mmCIF', file=self.logger)
    print('-------------', file=self.logger)
    print ('  Output file = %s' % self.output_file, file=self.logger)
    self.data_manager.write_model_file(self.cif_model)

  # ---------------------------------------------------------------------------
  def get_results(self):
    return group_args(output_file=self.output_file,
                      cif_model=self.cif_model)

# =============================================================================
# end


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/probe2.py
##################################################################################
# Copyright(c) 2021-2023, Richardson Lab at Duke
# Licensed under the Apache 2 license
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import absolute_import, division, print_function
import sys
import math
from datetime import datetime
from pathlib import Path
from libtbx.program_template import ProgramTemplate
from libtbx import group_args, phil
from libtbx.str_utils import make_sub_header
from libtbx.utils import Sorry
import mmtbx
import mmtbx_probe_ext as probeExt
from mmtbx.probe import Helpers
from iotbx import pdb
from iotbx.pdb import common_residue_names_get_class

version = "4.11.0"

master_phil_str = '''
profile = False
  .type = bool
  .short_caption = Profile the run
  .help = Profile the performance of the entire run

source_selection = "occupancy > 0.33"
  .type = atom_selection
  .short_caption = Source selection
  .help = Source selection description

target_selection = None
  .type = atom_selection
  .short_caption = Target selection
  .help = Target selection description ('=' means same as source)

use_neutron_distances = False
  .type = bool
  .short_caption = Use neutron distances
  .help = Use neutron distances (-nuclear in probe)

approach = *self both once surface count_atoms
  .type = choice
  .short_caption = What to count
  .help = self (src -> src) both (src <=> targ) once (src -> targ) surface (VdW surface) count_atoms (count atoms)

excluded_bond_chain_length = 4
  .type = int
  .short_caption = Excluded bond chain length
  .help = Exclude chain of atoms bonded to source for this many hops (-4H, -3, -2 , -1 in probe).  When set to 4, an atom chain longer than 3 is only excluded when either the first or the last atom in the chain is a Hydrogen.

minimum_water_hydrogen_occupancy = 0.25
  .type = float
  .short_caption = Minimum water hydrogen occupancy
  .help = Minimum occupancy for polar hydrogens (0.66 in original Reduce)

maximum_water_hydrogen_b = 80.0
  .type = float
  .short_caption = Maximum water hydrogen B factor
  .help = Minimum b-factor for polar hydrogens (40.0 in original Reduce)

include_mainchain_mainchain = True
  .type = bool
  .short_caption = Include mainchain-mainchain interactions
  .help = Include mainchain -> mainchain interactions (-mc in probe)

include_water_water = False
  .type = bool
  .short_caption = Include water-water interactions
  .help = Include water-to-water interactions (-wat2wat in probe)

keep_unselected_atoms = True
  .type = bool
  .short_caption = Unselected atoms block dots
  .help = Include atoms that are not selected in the collision neighbor lists (-keep, -drop, -scsurface, -exposed, -asurface, -access in probe)

atom_radius_scale = 1.0
  .type = float
  .short_caption = Scale applied to atom radii
  .help = Atom radius = (r*atom_radius_scale)+atom_radius_offset (-scalevds, -vswscale in probe)

atom_radius_offset = 0.0
  .type = float
  .short_caption = Offset applied to atom radii
  .help = Atom radius = (r*atom_radius_scale)+atom_radius_offset (-addvdw in probe)

minimum_occupancy = 0.02
  .type = float
  .short_caption = Minimum occupancy
  .help = Minimum occupancy for a source atom (-minoccupancy in probe)

overlap_scale_factor = 0.5
  .type = float
  .short_caption = Overlap scale factor
  .help = Fraction of overlap assigned to each atom (-spike in probe)

ignore_lack_of_explicit_hydrogens = False
  .type = bool
  .short_caption = Ignore lack of explicit hydrogens
  .help = For an explicit-hydrogen model, ignore lack of hydrogens (probe behaved this way)

output
  .style = menu_item auto_align
{
  write_files = True
    .type = bool
    .short_caption = Write the output files
    .help = Write the output files(s) when this is True (default). Set to False when harnessing the program.

  file_name = None
    .type = str
    .short_caption = Output file name
    .help = Output file name

  dump_file_name = None
    .type = str
    .short_caption = Dump file name
    .help = Dump file name for regression testing atom characteristics (-DUMPATOMS in probe)

  format = *kinemage raw oneline json
    .type = choice
    .short_caption = Output format
    .help = Type of output to write (-oneline -unformated -kinemage in probe)

  contact_summary = False
    .type = bool
    .short_caption = Summarize contacts
    .help = Report summary of contacts (-oneline, -summary in probe)

  condensed = False
    .type = bool
    .short_caption = Condensed output
    .help = Condensed output format (-condense, -kinemage in probe)

  count_dots = False
    .type = bool
    .short_caption = Count dots, don't list
    .help = Count dots rather than listing all contacts (-countdots in probe)

  record_added_hydrogens = False
    .type = bool
    .short_caption = Record Phantom Hydrogens
    .help = Output hydrogen-bond contacts (-dumph2o in probe)

  report_hydrogen_bonds = True
    .type = bool
    .short_caption = Report hydrogen bonds
    .help = Report hydrogen bonds (-nohbout in probe)

  report_clashes = True
    .type = bool
    .short_caption = Report clashes
    .help = Report clashes (-noclashout in probe)

  report_vdws = True
    .type = bool
    .short_caption = report VdW contacts
    .help = Report van der Waals contects (-novdwout in probe)

  separate_worse_clashes = False
    .type = bool
    .short_caption = Separately report worse clashes
    .help = Separately report worse clashes (-sepworse in probe)

  group_name = ""
    .type = str
    .short_caption = Group name to use
    .help = Specify the group name (-name in probe)

  add_group_name_master_line = False
    .type = bool
    .short_caption = Add group master line
    .help = Add a master=name line on lists (-dotmaster in probe)

  add_group_line = True
    .type = bool
    .short_caption = Add group line
    .help = Add a group line on kinemage output (-nogroup in probe)

  add_kinemage_keyword = False
    .type = bool
    .short_caption = Add kinemage keyword
    .help = Add kinemage 1 to beginning of kin file (-kinemage in probe)

  add_lens_keyword = False
    .type = bool
    .short_caption = Add lens keyword
    .help = Add lens keywoard to kin file (-lens, -nolens in probe)

  color_by_na_base = False
    .type = bool
    .short_caption = Color by nucleic acid base
    .help = Color by nucleic acid base (-basecolor, -colorbase in probe)

  color_by_gap = True
    .type = bool
    .short_caption = Color by gap
    .help = Assign a color to reported gaps (-atomcolor, -gapcolor, -basecolor in probe)

  group_label = ""
    .type = str
    .short_caption = Surface-dots group label
    .help = Label for the surface-dots group (-name, -scsurface, -exposed, -asurface, -access in probe)

  bin_gaps = False
    .type = bool
    .short_caption = Bin the gaps
    .help = Bin the gaps (-gapbins in probe)

  merge_contacts = True
    .type = bool
    .short_caption = Combine wide and close contacts
    .help = Combine wide and close contacts (True in probe)

  only_report_bad_clashes = False
    .type = bool
    .help = Only report bad clashes (-onlybadout in probe)

  atoms_are_masters = False
    .type = bool
    .short_caption = Atoms are masters
    .help = Atoms are listed as masters (-element in probe)

  default_point_color = "gray"
    .type = str
    .short_caption = Default color for points
    .help = Default color for output points (-outcolor in probe)

  compute_scores = True
    .type = bool
    .short_caption = Compute scores rather than counting
    .help = Compute scores rather than just counting dots (-spike, -nospike in probe)

   altid_as_pointmaster = True
    .type = bool
    .short_caption = Add alternate IDs as point masters for atoms that are in alternate conformations
    .help = Add alternate IDs as point masters for atoms that are in alternate conformations
}
''' + Helpers.probe_phil_parameters

program_citations = phil.parse('''
citation {
  authors = Word, et. al.
  journal = J. Mol. Biol.
  volume = 285
  pages = 1711-1733
  year = 1999
  external = True
}
''')

################################################################################
# List of all of the keys for atom classes, including all elements and all
# nucleic acid types.  These are in the order that the original Probe reported
# them.  Based on atomprops.h:INIT_ATOM_TABLE from original probe.
_allAtomClasses = ['ignore',
                      'H','C','N','O','P','S','As','Se','F','Cl','Br','I',
                      'Li','Na','Al','K','Mg','Ca','Mn','Fe','Co','Ni','Cu','Zn',
                      'Rb','Sr','Mo','Ag','Cd','In','Cs','Ba','Au','Hg','Tl','Pb',
                      'V','Cr','Te','Sm','Gd','Yb','W','Pt','U',
                      'He','Be','B','Ne','Se','Ar','Sc','Ti','Ga','Ge','Kr','Y','Zr',
                      'Sn','Sb','Xe','La','Ce','Fr','Ra','Th',
                      'Nb','Tc','Ru','Rh','Pd','Pr','Nd','Pm','Eu','Tb','Dy','Ho','Er',
                      'Tm','Lu','Hf','Ta','Re','Os','Ir','Bi','Po','At','Rn','Ac','Pa',
                      'Np','Pu','Am','Cm','Bk','Cf','Es','Fm','Md','No',
                      'a','c','t/u','g','other na','nonbase']

################################################################################
# Dictionary of dictionaries of lists structure holding lists of DotInfo class objects,
# indexed by atom class and then by interaction type.  Fill in empty lists for all of
# the possible classes and types.
_interactionTypes = [
    probeExt.InteractionType.WideContact,
    probeExt.InteractionType.CloseContact,
    probeExt.InteractionType.WeakHydrogenBond,
    probeExt.InteractionType.SmallOverlap,
    probeExt.InteractionType.Bump,
    probeExt.InteractionType.BadBump,
    probeExt.InteractionType.StandardHydrogenBond
  ]

# ------------------------------------------------------------------------------

def _color_for_gap(gap, interactionType):
  '''
    Report the color associated with a gap (and interaction type).
    :param gap: Size of the gap in Angstroms.
    :param interactionType: InteractionType of the dot.
    :return: Kinemage name of the color associated with the class.
  '''

  if interactionType == probeExt.InteractionType.StandardHydrogenBond:
    return "greentint "
  elif gap > 0.35:
    return "blue "
  elif gap > 0.25:
    return "sky "
  elif gap > 0.15:
    return "sea "
  elif gap > 0.0:
    return "green "
  elif gap > -0.1:
    return "yellowtint "
  elif gap > -0.2:
    return "yellow "
  elif gap > -0.3:
    return "orange "
  elif gap > -0.4:
    return "red "
  else:
    return "hotpink "

# ------------------------------------------------------------------------------

def _color_for_atom_class(c):
  '''
    Report the color associated with an atom class.
    Based on atomprops.h:INIT_ATOM_TABLE from original probe.
    :param c: Class of the atom.
    :return: Kinemage name of the color associated with the class.
  '''

  # Make sure the atom class is one that we know about
  if not c in _allAtomClasses:
    return 'magenta'

  # Check to see if this atom belongs to one of the special colors.
  if c in ['C','Ag','other na']:
    return 'white'
  elif c in ['N','He','t/u']:
    return 'sky'
  elif c in ['O']:
    return 'red'
  elif c in ['P','Ne','a']:
    return 'pink'
  elif c in ['S','c']:
    return 'yellow'
  elif c in ['Se','F','Cl']:
    return 'green'
  elif c in ['Br','I']:
    return 'brown'
  elif c in ['Co']:
    return 'blue'
  elif c in ['Cu','Ar']:
    return 'orange'
  elif c in ['Au']:
    return 'gold'
  elif c in ['Kr']:
    return 'greentint'
  elif c in ['Xe']:
    return 'magenta'
  elif c in ['Rn']:
    return 'pinktint'
  elif c in ['g']:
    return 'sea'

  # Most atom types, the default.
  return 'grey'

# ------------------------------------------------------------------------------

def _condense(dotInfoList, condense):
  '''
    Condensing the list of dots for use in raw or JSON output, sorting and removing
    duplicates.
    :param dotInfoList: List of DotInfo structures to sort and perhaps condense.
    :param condense: Boolean telling whether to condense the output, removing duplicates.
    :return: Condensed dotlist.
  '''

  ret = []

  # Handle all of the dots associated with each source atom as a group.
  # This will be from curAtomIndex to curAtomEndIndex.
  curAtomIndex = 0
  while curAtomIndex < len(dotInfoList):

    # Find the last dot in the current atom, which may be at the end of the list.
    curAtomEndIndex = len(dotInfoList) - 1
    for curAtomEndIndex in range(curAtomIndex+1, len(dotInfoList)):
      if dotInfoList[curAtomIndex].src != dotInfoList[curAtomEndIndex].src:
        curAtomEndIndex -= 1
        break

    # Sort the dots for the same source atom based on characteristics of their target atom.
    # We include the XYZ position in the sort so that we get the same order and grouping each
    # time even though the phantom H? atoms are otherwise identical.
    thisAtom = sorted(dotInfoList[curAtomIndex:curAtomEndIndex+1])

    # Remove duplicates (same target atom) if we've been asked to.
    # We do this by scanning through and accumulating counts as long as the target
    # atom is the same and by appending a new entry when the target atom is different.
    # The result is a single entry for each target atom with a count of the number of
    # dots that were associated with it in the resulting entry.
    if condense and len(thisAtom) > 0:
      thisAtom[0].dotCount = 1
      condensed = [ thisAtom[0] ]
      for i in range(1,len(thisAtom)):
        if thisAtom[i-1].target.memory_id() == thisAtom[i].target.memory_id():
          condensed[-1].dotCount += 1
        else:
          thisAtom[i].dotCount = 1
          condensed.append(thisAtom[i])
      thisAtom = condensed

    # Append the sorted and potentially condensed list to the return list
    ret.extend(thisAtom)

    # Handle the chunk of dots on the next atom
    curAtomIndex = curAtomEndIndex + 1

  return ret

# ------------------------------------------------------------------------------

def _totalInteractionCount(chainCounts):
  '''
    Find the total count of interactions of any type for the specified chain-pair type.
    :param chainCounts: One of the structures that hold the counts of interaction
    types for a given pair of chain types: _MCMCCount, _SCSCCount, _MCSCCount, _otherCount,
    or _sumCount.
    :return: Sum of results across all interaction types.
  '''
  ret = 0
  for v in chainCounts.values():
    ret += v
  return ret

# ------------------------------------------------------------------------------

class DotInfo:
  # Dot class storing information about an individual dot.
  def __init__(self, src, target, loc, spike, overlapType, gap, ptmaster, angle):
    self.src = src                  # Source atom for the interaction
    self.target = target            # Target atom for the interactions
    self.loc = loc                  # Location of the dot start
    self.spike = spike              # Location of the dot end
    self.overlapType = overlapType  # Type of overlap the interaction represents
    self.gap = gap                  # Gap between the atoms
    self.ptmaster = ptmaster        # Main/side chain interaction type
    self.angle = angle              # Angle associated with the bump
    self.dotCount = 1               # Used by _condense and raw/JSON output to count dots on the same source + target

  def _makeName(self, atom):
      # Make the name for an atom, which includes its chain and residue information
      # along with other atom data, and also includes its location to distinguish
      # among H? atoms that are otherwise identical.
      return "{}{:4.4s}{}{} {}{:1s} {:.3f} {:.3f} {:.3f}".format(
        atom.parent().parent().parent().id, # chain
        str(atom.parent().parent().resseq_as_int()), # residue number
        atom.parent().parent().icode, # insertion code
        atom.parent().resname, # residue name
        atom.name, # atom name
        atom.parent().altloc, # alternate location
        atom.xyz[0], atom.xyz[1], atom.xyz[2])

  def __lt__(self, other):
      # Sort dots based on characteristics of their source and target atoms, then their gap
      # (smallest/most negative gap to largest).
      # We include the XYZ position in the sort so that we get the same order and grouping each
      # time even though the phantom H? atoms are otherwise identical.
      # There may be no target atoms specified (may be Python None value), which will
      # be treated as the empty string.

      selfName = self._makeName(self.src)
      if self.target is not None:
        selfName += self._makeName(self.target)
      otherName = other._makeName(other.src)
      if other.target is not None:
        otherName += other._makeName(other.target)

      return (selfName < otherName) or (
        (selfName == otherName) and (self.gap < other.gap)
      )

# ------------------------------------------------------------------------------

def Test():
  '''
    Run tests on the functions that are not part of the program class.
    Throw an assertion error if there is a problem with one of them.
  '''

  #=====================================================================================
  # Test the _condense() method.

  atoms = [ # Different atoms for different indices
    pdb.hierarchy.atom(), pdb.hierarchy.atom(), pdb.hierarchy.atom(), pdb.hierarchy.atom()
  ]
  # Name the atoms distinctly so that they will sort in order.
  for i,a in enumerate(atoms):
    a.name = str(i)
  ag1 = pdb.hierarchy.atom_group()
  for a in atoms:
    ag1.append_atom(a)
  rg1 = pdb.hierarchy.residue_group()
  rg1.append_atom_group(ag1)
  rg1.resseq = 1
  c1 = pdb.hierarchy.chain()
  c1.append_residue_group(rg1)

  sourceTarget = [  # Index of source atom, target atom pairs to add into the dots list
    (1,1), (1,2), (1,1), (1,2),
    (2,1),
    (3,1), (3,1), (3,1), (3,2), (3,2), (3,2)
  ]
  dots = [  # Construct a test dots list based on the sourceTarget tuples.
    DotInfo(atoms[src],atoms[trg],(0,0,0), (0,0,0), probeExt.OverlapType.Ignore, 0.0, ' ', 0.0)
      for (src,trg) in sourceTarget
  ]

  # Test when only sorting
  inorder = _condense(dots, False)
  assert len(inorder) == len(dots), "probe2:Test(): Unexpected length from _condense when not condensing"
  assert inorder[0].target == inorder[1].target, "probe2:Test(): Unexpected sorted value from _condense when not condensing"
  assert inorder[1].target != inorder[2].target, "probe2:Test(): Unexpected sorted value from _condense when not condensing"

  # Test when also condensing
  inorder = _condense(dots, True)
  assert len(inorder) == 5, "probe2:Test(): Unexpected length from _condense when condensing"
  assert inorder[0].target != inorder[1].target, "probe2:Test(): Unexpected sorted value from _condense when condensing"
  assert inorder[-1].dotCount == 3, "probe2:Test(): Unexpected dot count value from _condense when condensing"

  #=====================================================================================
  # Test the _totalInteractionCount() method.  We make stand-in dictionaries using a stand-in
  # list.
  interactionTypes = [0, 1, 2, 3, 4, 5, 6]
  MCMCCount = {}
  for t in interactionTypes:
    MCMCCount[t] = 1

  assert _totalInteractionCount(MCMCCount) == len(interactionTypes), "probe2:Test(): _totalInteractionCount(MCMCCount) failed"

  #=====================================================================================
  # Test the _color_for_gap() method.
  table = [ [0.3, "sky "], [0.1, "green "], [-0.5, "hotpink "]]
  hydro = "greentint "
  for t in table:
    assert _color_for_gap(t[0], probeExt.InteractionType.CloseContact) == t[1], "probe2:Test(): _color_for_gap("+str(t[0])+") failed to return "+t[1]
    assert _color_for_gap(t[0], probeExt.InteractionType.StandardHydrogenBond) == hydro, "probe2:Test(): _color_for_gap() for a hydrogen bond failed to return "+hydro

  #=====================================================================================
  # Test the _color_for_atom_class() method.
  table = [ ["Bob", "magenta"], ["Ag", "white"], ["Cu", "orange"], ["Rn","pinktint"] ]
  for t in table:
    assert _color_for_atom_class(t[0]) == t[1], "probe2:Test(): _color_for_atom_class("+str(t[0])+") failed to return "+t[1]

  print('Success!')

# ------------------------------------------------------------------------------

class Program(ProgramTemplate):
  description = '''
probe2 version {}

This program replaces the original "probe" program from the Richarson lab
at Duke University and was developed by them as part of a supplemental award.

It computes the MolProbity Probe score for a file, or a subset of the file,
producing summaries or lists of all contacts, in Kinemage/raw/JSON format, depending
on the Phil parameters.

By default, it compares all atoms in all alternates that meet an occupancy
criterion against themselves and produces a Kinemage-format file showing all of
the dot interactions.  See below for the Phil parameter equivalents to some
original probe command-line arguments.  (Note that the original probe selected
only the a alternate by default, but version 4 of probe2 selects all alternates by default
because it also adds point masters for all alternates.)

Inputs:
  PDB or mmCIF file containing atomic model
  Ligand CIF file, if needed

Output:
  Kinemage or text file describing the score and other information,
  depending on the parameters.

  If neither output.file_name nor output.filename is specified, it will write
  to a file with the same name as the input model file name but with the
  extension replaced with with '.kin', '.txt', or '.json' depending on the
  parameters (.kin when output.format == kinemage and output.count_dots == False).

  In addition to writing files, this is derived from the Program Template object
  and the run() method returns a dictionary whose key values are atom classes
  (atom names, NA bases, other na and nonbase depending on how the program
  was run).  Each value is a dictionary of dot interaction types (wide contact,
  close contact, weak hydrogen bonds, small overlap, bump, bad bump, hydrogen
  bond) where not all types will be filled in based on the way the program was
  run.  The value for each interaction type entry is an array of DotInfo objects
  that describe all dots of that type found by the run.

Note:
  Some approaches require the target_selection parameter.  Setting the
  target_selection to "=" will re-use the source for the target.  In all
  other cases, the string passed in will be used as a CCTBX selection on
  the model to select a subset of its atoms.

  The original Probe program had two ways to specify whether HET atoms were included
  and whether water atoms were include, in the selection description and as separate
  command-line arguments.  The command-line arguments are not present in Probe2, they
  must be specified as part of the selection criteria.  Also Probe2 does not break out
  aromatic Carbons as Car in a separate category when counting dots, they are treated
  as C for reporting purposes.

  The most simple dotkin:
    mmtbx.probe2 approach=self source_selection="all" output.file_name=out.kin input.pdb

  The probe2 command line to test a ligand named TMP against everything else:
    mmtbx.probe2 approach=both source_selection="resname TMP" target_selection="not resname TMP" PDBfilename

  Equivalent PHIL arguments for original Probe command-line options:
    -defaults:
      source_selection="(altid a or altid '' or altid ' ') and occupancy > 0.33"
      approach=self
      excluded_bond_chain_length=4
      include_mainchain_mainchain=True
    -kinemage:
      output.add_kinemage_keyword=True
      output.count_dots=False
      output.format=kinemage
      output.condensed=False
    -scsurface:
      approach=surface
      source_selection="not water"
      keep_unselected_atoms=False
      probe.radius=1.4
      group_name="SCS"
    -exposed:
      approach=surface
      source_selection="(altid a or altid '' or altid ' ') and occupancy > 0.33"
      keep_unselected_atoms=False
      probe.radius=1.4
      group_name="SCS"
    -asurface:
      approach=surface
      source_selection="not water"
      keep_unselected_atoms=False
      probe.radius=0.0
      group_name="AS"
    -access:
      approach=surface
      source_selection="not water"
      keep_unselected_atoms=False
      atom_radius_offset=1.4
      probe.radius=0.0
      group_name="AS"
    -scan0:
      source_selection="(altid a or altid '' or altid ' ') and bfactor < 40 occupancy > 0.33"
      approach=self
      excluded_bond_chain_length=4
      include_mainchain_mainchain=True
    -scan1:
      approach=once
      excluded_bond_chain_length=4
      source_selection="(altid a or altid '' or altid ' ') and bfactor < 40 and occupancy > 0.33"
      target_selection="((altid a or altid '' or altid ' ') and bfactor < 40 and occupancy > 0.65) or (not water and occupancy > 0.33)"
'''.format(version)
  datatypes = ['model', 'restraint', 'phil']
  master_phil_str = master_phil_str
  data_manager_options = ['model_skip_expand_with_mtrix',
                          'model_skip_ss_annotations']
  citations = program_citations
  epilog = '''
  For additional information and help, see http://kinemage.biochem.duke.edu/software/probe
  and http://molprobity.biochem.duke.edu
  '''

# ------------------------------------------------------------------------------

  def _scaled_atom_radius(self, a):
    '''
      Find the scaled and offset radius for the specified atom.  This will be called on each
      atom after their extra information has been loaded to determine the scaled and offset
      value to use for the remainder of the program.
      :param a: Atom whose radius is to be scaled
      :return: Scaled and offset radius of the atom.
    '''
    rad = self._extraAtomInfo.getMappingFor(a).vdwRadius
    if rad <= 0:
      alt = a.parent().altloc
      if alt == "":
        alt = " "
      resName = a.parent().resname.strip().upper()
      resID = str(a.parent().parent().resseq_as_int())
      chainID = a.parent().parent().parent().id
      myFullName = "chain "+str(chainID)+" "+resName+" "+resID+" "+a.name+" "+alt
      raise Sorry("Invalid radius for atom look-up: "+myFullName+"; rad = "+str(rad))
    return self.params.atom_radius_offset + (rad * self.params.atom_radius_scale)


  def _describe_atom_for_debug(self, a):
      resName = a.parent().resname.strip().upper()
      resID = str(a.parent().parent().resseq_as_int())
      chainID = a.parent().parent().parent().id
      iCode = a.parent().parent().icode
      alt = a.parent().altloc
      return "{:>2s}{:>4s}{}{} {}{:1s}".format(chainID, resID, iCode, resName, a.name, alt)

# ------------------------------------------------------------------------------

  def _atom_class_for(self, a):
    '''
      Assign the atom class for a specified atom.
      :param a: Atom whose class is to be specified
      :return: If our parameters have been set to color and sort by NA base,
      then it returns the appropriate base name.  Otherwise, it returns the
      element of the atom with any second letter in the element name lower-case
      to match the values in the _allAtomClasses list.
    '''
    if not self.params.output.color_by_na_base:
      val = a.element
      if len(val) > 1:
        val = val[0] + val[1:].lower()
      return val
    else:
      resName = a.parent().resname
      cl = common_residue_names_get_class(name = resName)
      if cl == "common_rna_dna" or cl == "modified_rna_dna":
        cleanName = resName.upper().strip()
        if cleanName in ['U','URA','UTP','UDP','UMP','UR',
                         'T','THY','TTP','TDP','TMP','5MU','DT','TR']:
          return 't/u'
        elif cleanName in ['A','ADE','ATP','ADP','AMP','1MA','RIA','T6A','DA','AR']:
          return 'a'
        elif cleanName in ['C','CYT','CTP','CDP','CMP','5MC','OMC','DC','CR']:
          return 'c'
        elif cleanName in ['G','GUA','GTP','GDP','GMP','GSP','1MG','2MG','M2G','7MG','OMG','DG','GR']:
          return 'g'
        return 'other na'
      else:
        return "nonbase"

# ------------------------------------------------------------------------------

  def _save_dot(self, src, target, atomClass, loc, spike, overlapType, gap, ptmaster, angle):
    '''
      Generate and store a DotInfo entry with the specified parameters.  It will be stored
      into the self._results data structure.
      :param src: Source atom for the dot.
      :param target: Target atom for the dot, if any.
      :param atomClass: Atom class of this dot, indicates where to store.
      :param loc: Location of the dot start.
      :param spike: Location of the dot end.
      :param overlapType: Type of overlap for the dot.
      :param gap: Gap spacing for the dot.
      :param ptmaster: ptmaster entry for the dot.
      :param angle: angle for the dot.
      :return: As a side effect, this will add a new entry into one of the lists in the
      self._results data structure.
    '''
    self._results[atomClass][self._dotScorer.interaction_type(
        overlapType,gap, self.params.output.separate_worse_clashes)].append(
      DotInfo(src, target, loc, spike, overlapType, gap, ptmaster, angle)
    )

# ------------------------------------------------------------------------------

  def _generate_interaction_dots(self, sourceAtoms, targetSet, spatialQuery, phantomsQuery, bondedNeighborLists):
    '''
      Find all interaction dots for the specified atoms.
      This does not include locations where the probe is inside a bonded neighbor.
      :param sourceAtoms: Sorted list of atoms that can be the source of an interaction.
      :param targetSet: Set of atoms that are targets; others will block dots but not interact
      (can be the same as sourceAtoms for some approaches).
      :param spatialQuery: Spatial-query structure that can be used to look up nearby atoms
      (all atoms, whether or not they are targets).
      :param phantomsQuery: Spatial-query structure that can be used to look up nearby Phantom
      Hydrogens (whether or not they are in the source or target atoms).
      :param bondedNeighborLists: List of bonded neighbors for atoms in sourceAtoms.
      :return: Side effect: Add dots to the self._results data structure by
      atomclass and dot type.
    '''

    # Store constants used frequently
    probeRadius = self.params.probe.probe_radius
    include_mainchain_mainchain = self.params.include_mainchain_mainchain
    minimum_occupancy = self.params.minimum_occupancy
    include_water_water = self.params.include_water_water
    excluded_bond_chain_length = self.params.excluded_bond_chain_length
    maxRadius = 2*self._maximumVDWRadius + 2 * self.params.probe.probe_radius

    for src in sourceAtoms:
      # Find out what class of dot we should place for this atom.
      atomClass = self._atomClasses[src]

      # Generate no dots for ignored atoms.
      if atomClass == 'ignore':
        continue

      # Generate no dots for atoms with too-low occupancy
      if src.occ < minimum_occupancy:
        continue

      # Find atoms that are close enough that they might touch.
      nearby = spatialQuery.neighbors(src.xyz, 0.00001, maxRadius)

      # Find our characteristics
      srcMainChain = self._inMainChain[src]
      srcSideChain = self._inSideChain[src]
      srcHet = self._inHet[src]
      srcInWater = self._inWater[src]
      srcExtra = self._extraAtomInfo.getMappingFor(src)
      srcModel = src.parent().parent().parent().parent().id

      # Select those that are actually within the contact distance based on their
      # particular radius (this query includes only target atoms, so we don't need to check separately for that).
      # Also verify that the potential target atoms meet our criteria based on parameters.
      # Keep a list of nearby Phantom Hydrogens in case we need to exclude them.
      atomSet = set()
      for n in nearby:
        nMainChain = self._inMainChain[n]
        nHet = self._inHet[n]
        nInWater = self._inWater[n]
        nExtra = self._extraAtomInfo.getMappingFor(n)
        nModel = n.parent().parent().parent().parent().id

        d = (Helpers.rvec3(n.xyz) - Helpers.rvec3(src.xyz)).length()
        if (d <= nExtra.vdwRadius + srcExtra.vdwRadius + 2*probeRadius):

          # if both atoms are in the same non-HET chain and on the main chain, then skip
          # if we're not allowing mainchain-mainchain interactions.
          # The atoms must be on the same chain to be skipped.
          if not include_mainchain_mainchain and (
                (srcMainChain and nMainChain) and not (srcHet or nHet) and
                (src.parent().parent().parent().id == n.parent().parent().parent().id) # Same chain
              ):
            continue
          # Skip atoms that are marked to be ignored
          if self._atomClasses[n] == 'ignore':
            continue
          # Skip atoms with too low occupancy
          elif n.occ < minimum_occupancy:
            continue
          # Check for water-water interactions
          elif srcInWater and nInWater:
            # Skip water-water interactions unless they are allowed
            if (not include_water_water):
              continue
            # Ensure that we're not from the same water; we don't interact with ourself
            elif src.parent() == n.parent():
              continue
          # Skip atoms that are in non-compatible alternate conformations
          elif not Helpers.compatibleConformations(src, n):
            continue
          # Skip atoms that are in different models.
          elif srcModel != nModel:
            continue
          atomSet.add(n)

      # Check the atoms for interactions
      if len(atomSet) > 0:
        # Find the atoms that are bonded to the source atom within the specified hop
        # count.  Limit the length of the chain to 3 if neither the source nor the final
        # atom is a Hydrogen.
        excluded = Helpers.getAtomsWithinNBonds(src, bondedNeighborLists, self._extraAtomInfo, probeRadius,
          excluded_bond_chain_length, 3)

        # For Phantom Hydrogens, add any non-Acceptor atom in the atom list into the
        # excluded list and also add nearby Phantom Hydrogens into the excluded list.
        # @todo Consider whether we'd rather handle this by making bonds between the
        # Phantoms and their water Oxygens (both directions), which will shield their
        # contacts from one another and (1) avoid removing sections of hydrogen bond patterns
        # that fall inside atoms that are covalently bonded to acceptors, and (2) remove
        # the inner collision of the water Oxygen with the acceptor that also makes
        # a Hydrogen bond with the Phantom Hydrogen.
        if srcExtra.isDummyHydrogen:
          nearbyPhantomHydrogens = set(phantomsQuery.neighbors(src.xyz, 0.00001, maxRadius))
          newExclusions = set()
          for a in atomSet:
            if not self._extraAtomInfo.getMappingFor(a).isAcceptor:
              newExclusions.add(a)
          excluded = list(set(excluded).union(newExclusions).union(nearbyPhantomHydrogens))

        # Remove all of the excluded atoms from the interaction set so we don't
        # put spurious dots on them.
        for e in excluded:
          atomSet.discard(e)

        # Check each dot to see if it interacts with non-bonded nearby target atoms.
        srcDots = self._dots[src]
        scale = self.params.overlap_scale_factor
        for dotvect in srcDots:

          # Find out if there is an interaction
          res = self._dotScorer.check_dot(src, dotvect, probeRadius, list(atomSet), excluded, scale)

          # Classify the interaction and store appropriate results unless we should
          # ignore the result because there was not valid overlap.
          overlapType = res.overlapType

          # If the overlap type is NoOverlap, check dot to make sure it is not annular.
          # This excludes dots that are further from the contact than dots could be at
          # the ideal just-touched contact.
          if overlapType == probeExt.OverlapType.NoOverlap and res.annular:
            continue

          # Handle any dots that should not be ignored.
          if overlapType != probeExt.OverlapType.Ignore:

            # If the cause of the dot is not in the target set, we ignore the dot.
            if not res.cause in targetSet:
              continue

            # If the overlap type is not a Hydrogen bond, then check the occupancy of atoms where
            # at least one of the pair is on the "" or " " alternate conformation to make sure the
            # sum of their occupancies is greater than 1.
            if overlapType != probeExt.OverlapType.HydrogenBond:
              if (src.parent().altloc in ['',' ']) or (res.cause.parent().altloc in ['',' ']):
                if src.occ + res.cause.occ <= 1:
                  continue

            # See whether this dot is allowed based on our parameters.
            spo = self.params.output
            show = False
            interactionType = self._dotScorer.interaction_type(overlapType,res.gap, self.params.output.separate_worse_clashes)
            if interactionType == probeExt.InteractionType.Invalid:
              print('Warning: Invalid interaction type encountered (internal error)', file=self.logger)
              continue

            # Main branch if we're reporting other than bad clashes
            if (not spo.only_report_bad_clashes):
              # We are reporting other than bad clashes, see if our type is being reported
              if spo.report_hydrogen_bonds and (overlapType == probeExt.OverlapType.HydrogenBond):
                show = True
              elif spo.report_clashes and (overlapType == probeExt.OverlapType.Clash):
                show = True
              elif spo.report_vdws and (overlapType == probeExt.OverlapType.NoOverlap):
                show = True
            else:
              # We are only reporting bad clashes.  See if we're reporting clashes and this is
              # a bad one.
              if (spo.report_clashes and interactionType in [
                    probeExt.InteractionType.Bump, probeExt.InteractionType.BadBump]):
                show = True

            # If we're not showing this one, skip to the next
            if not show:
              continue

            # Determine the ptmaster (main/side chain interaction type) and keep track of
            # counts for each type.
            causeMainChain = self._inMainChain[res.cause]
            causeSideChain = self._inSideChain[res.cause]
            causeHet = self._inHet[res.cause]
            ptmaster = ' '
            if srcMainChain and causeMainChain:
              if (not srcHet) and (not causeHet): # This may be a redundant check
                ptmaster = 'M'
                self._MCMCCount[interactionType] += 1
            elif srcSideChain and causeSideChain:
              if (not srcHet) and (not causeHet): # This may be a redundant check
                ptmaster = 'S'
                self._SCSCCount[interactionType] += 1
            elif ( (srcMainChain and causeSideChain) or (srcSideChain and causeMainChain) ):
              if (not srcHet) and (not causeHet): # This may be a redundant check
                ptmaster = 'P'
                self._MCSCCount[interactionType] += 1
            else:
              ptmaster = 'O'
              self._otherCount[interactionType] += 1

            # Find the locations of the dot and spike by scaling the dot vector by the atom radius and
            # the (negative because it is magnitude) overlap.
            loc = Helpers.rvec3(src.xyz) + Helpers.rvec3(dotvect)
            spikeloc = ( Helpers.rvec3(src.xyz) + Helpers.rvec3(dotvect).normalize() *
                         (self._extraAtomInfo.getMappingFor(src).vdwRadius - res.overlap) )

            # Save the dot
            self._save_dot(src, res.cause, atomClass, loc, spikeloc, overlapType, res.gap, ptmaster, 0)

# ------------------------------------------------------------------------------

  def _generate_surface_dots_for(self, src, nearby):
    '''
      Find all surface dots for the specified atom.
      This does not include locations where the probe is interacting with
      a nearby atom, so it is a subset of the skin dots (for which only the
      dots themselves are outside of the nearby atoms).
      :param src: Atom whose surface dots are to be found.
      :param nearby: Atoms that are nearby to src and might block surface dots.
      :return: Side effect: Add dots on the surface of the atom to the
              self._results data structure by atomclass and dot type.
    '''

    # Generate no dots for ignored atoms.
    if self._atomClasses[src] == 'ignore':
      return

    # Check all of the dots for the atom and see if they should be
    # added to the list.
    srcInWater = self._inWater[src]
    r = self._extraAtomInfo.getMappingFor(src).vdwRadius
    pr = self.params.probe.probe_radius
    srcDots = self._dots[src]
    for dotvect in srcDots:
      # Dot on the surface of the atom, at its radius; both dotloc and spikeloc from original code.
      # This is where the probe touches the surface.
      dotloc = Helpers.rvec3(src.xyz) + Helpers.rvec3(dotvect)
      # Dot that is one probe radius past the surface of the atom, exploring for contact with nearby
      # atoms.  This is the location of the center of the probe.
      exploc = Helpers.rvec3(src.xyz) + Helpers.rvec3(dotvect).normalize() * (r + pr)

      # If the exploring dot is within a probe radius + vdW radius of a nearby atom,
      # we don't add a dot.
      okay = True
      for b in nearby:
        bInWater = self._inWater[b]
        # If we should ignore the nearby atom, we don't check it.
        if self._atomClasses[b] == 'ignore':
          continue
        # If we're ignoring water-water interactions and both src and
        # nearby are in a water, we should ignore this as well (unless
        # both are hydrogens from the same water, in which case we
        # continue on to check.)
        elif ((not self.params.include_water_water) and srcInWater and bInWater
              and src.parent() != b.parent() ):
          continue

        # The nearby atom is one that we should check interaction with, see if
        # we're in range.  If so, mark this dot as not okay because it is inside a
        # nearby atom.
        if ( (Helpers.rvec3(b.xyz) - exploc).length() <=
            pr + self._extraAtomInfo.getMappingFor(b).vdwRadius ):
          okay = False

      # If this dot is okay, add it to the internal data structure based on its
      # atom class and overlap type.
      if okay:
        self._save_dot(src, None, self._atomClasses[src], dotloc, dotloc,
                       probeExt.OverlapType.NoOverlap, 0.0, ' ', 0.0)

# ------------------------------------------------------------------------------

  def _count_skin_dots_for(self, src, bonded):
    '''
      Count all skin dots for the specified atom.
      :param src: Atom whose surface dots are to be found.
      :param bonded: Atoms that are bonded to src by one or more hops.
      :return: Side effect: Add dots on the surface of the atom to the
              self._results data structure by atomclass and dot type.
    '''

    # No dots yet...
    ret = 0

    # Generate no dots for ignored atoms or for phantom hydrogens
    if self._atomClasses[src] == 'ignore' or self._extraAtomInfo.getMappingFor(src).isDummyHydrogen:
      return 0

    # If we should ignore the bonded element, we don't check it.
    # Remove any ignored atoms from the list of bonded atoms to pull this check out of
    # the inner loop.
    srcDots = self._dots[src]
    realBonded = []
    for b in bonded:
      if self._atomClasses[b] != 'ignore':
        realBonded.append(b)

    # Check all of the dots for the atom and see if they should be
    # added to the list.
    return self._dotScorer.count_surface_dots(src, srcDots, realBonded)

# ------------------------------------------------------------------------------

  def _count_skin_dots(self, atoms, bondedNeighborLists):
    '''
      Count all skin dots for the atoms passed in.
      :param atoms: Atoms to check.
      :param bondedNeighborLists: Neighbor list including these atoms.
      This is used to normalize output scores.
      :return: Number of skin dots on any of the atoms in the source selection.
    '''

    ret = 0

    # Store parameters that are used in the inner loop
    excluded_bond_chain_length = self.params.excluded_bond_chain_length

    for src in atoms:
      # Find the atoms that are bonded to the source atom within the specified hop
      # count.  Limit the length of the chain to 3 if neither the source nor the final
      # atom is a Hydrogen.
      # We check only out to a probe radius of 0 (atoms actually overlapping)
      neighbors = Helpers.getAtomsWithinNBonds(src, bondedNeighborLists, self._extraAtomInfo, 0.0,
        excluded_bond_chain_length, 3)

      # Count the skin dots for this atom.
      ret += self._count_skin_dots_for(src, neighbors)

    # Return the total count
    return ret

# ------------------------------------------------------------------------------

  def _writeRawOutput(self, groupName, masterName, writeJSON = False):
    '''
      Describe raw summary counts for data of various kinds.
      :param groupName: Name to give to the group.
      :param masterName: Name for the beginning of each line.
      :param writeJSON: If True, write the output in JSON format.  Otherwise, write one raw entry per line.
      :return: String to be added to the output.
    '''

    if writeJSON:
      ret = '{ "flat_results" : ['
    else:
      ret = ''

    # Provide a short name for each interaction type
    mast = {}
    for t in _interactionTypes:
      mast[t] = probeExt.DotScorer.interaction_type_short_name(t)

    # Store values that we will need often
    density = self.params.probe.density
    gap_weight = self.params.probe.gap_weight
    bump_weight = self.params.probe.bump_weight
    hydrogen_bond_weight = self.params.probe.hydrogen_bond_weight

    # Go through all atom types and contact types and report the contacts.
    first_line = True
    for atomClass in _allAtomClasses:
      for interactionType in _interactionTypes:

        # Condensed report all of the dots of this type.
        condensed = _condense(self._results[atomClass][interactionType], self.params.output.condensed)
        for node in condensed:

          if writeJSON:
            if first_line:
              first_line = False
            else:
              ret += ','
            ret += '\n'
            ret += '{{"master": "{}", "group": "{}", "type": "{}"'.format(masterName, groupName, mast[interactionType])
          else:
            ret += "{}:{}:{}:".format(masterName, groupName, mast[interactionType])

          # Describe the source atom
          a = node.src
          resName = a.parent().resname.strip().upper()
          resID = str(a.parent().parent().resseq_as_int())
          chainID = a.parent().parent().parent().id
          iCode = a.parent().parent().icode
          if iCode == "":
            iCode = " "
          alt = a.parent().altloc
          if writeJSON:
            ret += ', "src": {{"chainID": "{}", "resID": {}, "iCode": "{}", "resName": "{}", "atomName": "{}", "alt": "{}"}}'.format(
              chainID, resID, iCode.strip(), resName, a.name, alt.strip())
          else:
            ret += "{:>2s}{:>4s}{}{} {}{:1s}:".format(chainID, resID, iCode, resName.strip(), a.name, alt)

          # Describe the target atom, if it exists
          t = node.target
          if t is None:
            if not writeJSON:
              ret += ":::::::"
          else:
            resName = t.parent().resname.strip().upper()
            resID = str(t.parent().parent().resseq_as_int())
            chainID = t.parent().parent().parent().id
            iCode = t.parent().parent().icode
            if iCode == "":
              iCode = " "
            alt = t.parent().altloc
            if writeJSON:
              ret += ', "target": {{"chainID": "{}", "resID": {}, "iCode": "{}", "resName": "{}", "atomName": "{}", "alt": "{}"}}'.format(
                chainID, resID, iCode.strip(), resName, t.name, alt.strip())
            else:
              ret += "{:>2s}{:>4s}{}{} {:<3s}{:1s}:".format(chainID, resID, iCode, resName.strip(), t.name, alt)

            r1 = self._extraAtomInfo.getMappingFor(a).vdwRadius
            r2 = self._extraAtomInfo.getMappingFor(t).vdwRadius
            sl = (node.loc-node.spike).length()
            gap = (Helpers.rvec3(a.xyz)-Helpers.rvec3(t.xyz)).length() - (r1 + r2)
            dtgp = node.gap
            score = 0.0

            if interactionType in [probeExt.InteractionType.WideContact, probeExt.InteractionType.WideContact]:
              scaledGap = dtgp / gap_weight
              score = math.exp(-scaledGap*scaledGap)
            elif interactionType in [
              probeExt.InteractionType.WeakHydrogenBond,  # don't know what to do here, because they can be both wc and cc, so will have to check
              probeExt.InteractionType.SmallOverlap,      # small overlap, doing nothing, as before
              probeExt.InteractionType.Bump,
              probeExt.InteractionType.BadBump]:          # worse overlap, same as bad overlap
                score = score = - bump_weight * sl
            else: # Hydrogen bond
              score = hydrogen_bond_weight * sl

            if self.params.output.condensed:
              if writeJSON:
                ret += ', "dotCount": {}'.format(node.dotCount)
              else:
                ret += "{}:".format(node.dotCount)

            if writeJSON:
              if self.params.output.condensed:
                # Don't write elements that are not needed for condensed output
                ret += ', "gap": {:.3f}'.format(gap)
              else:
                ret += ', "gap": {:.3f}, "dotGap": {:.3f}, "spike": [{:.3f},{:.3f},{:.3f}], "spikeLen": {:.3f}, "scoreOverDensity": {:.4f}'.format(
                  gap, dtgp, node.spike[0], node.spike[1], node.spike[2], sl, score/density)
            else:
              ret += "{:.3f}:{:.3f}:{:.3f}:{:.3f}:{:.3f}:{:.3f}:{:.4f}".format(gap, dtgp,
                node.spike[0], node.spike[1], node.spike[2], sl, score/density)

          try:
            tName = self._atomClasses[t]
            tBVal = "{:.2f}".format(t.b)
          except Exception:
            tName = ""
            tBVal = ""

          if writeJSON:
            if self.params.output.condensed:
              # Don't write elements that are not needed for condensed output
              ret += ', "srcClass": "{}", "targetClass": "{}"'.format(self._atomClasses[a], tName)
            else:
              ret += ', "srcClass": "{}", "targetClass": "{}", "loc": [{:.3f},{:.3f},{:.3f}]'.format(
                self._atomClasses[a], tName, node.loc[0], node.loc[1], node.loc[2])
          else:
            ret += ":{}:{}:{:.3f}:{:.3f}:{:.3f}".format(self._atomClasses[a], tName,
              node.loc[0], node.loc[1], node.loc[2])

          if writeJSON:
            ret += ', "srcBFactor": {:.2f}, "targetBFactor": {}}}'.format(a.b, tBVal)
          else:
            ret += ":{:.2f}:{}\n".format(a.b, tBVal)

    if writeJSON:
      ret += '\n] }\n'
    return ret

# ------------------------------------------------------------------------------

  def _writeOutput(self, groupName, masterName):
    '''
      Describe contacts for data of various kinds.
      :param groupName: Name to give to the group.
      :param masterName: Name for the master command.
      :return: String to be added to the output.
    '''

    ret = ''

    ptm = ' '
    color = ''
    mast = {}
    for t in _interactionTypes:
      # Probe uses spaces in these names for this function but underscores for others, so we replace
      # underscores with spaces here.
      mast[t] = probeExt.DotScorer.interaction_type_name(t).replace("_"," ")
    extraMaster = ''
    pointid = ''
    ptmast = ''
    gapNames = ['z','y','x','w','v','u','t','g','r','q','f','F','Q','R','G','T','U','V','W','X','Y','Z']
    # std gapbins scope at least -.5 to +.5, wider if probeRad > 0.25 standard
    gaplimit = int(math.floor(((2*(max(self.params.probe.probe_radius,0.25))+0.5)/0.05)+2))
    gapcounts = [0] * gaplimit
    maxgapcounts = 0
    strcName = ''

    # Rename contacts as needed
    if self.params.output.merge_contacts:
      mast[probeExt.InteractionType.WideContact] = mast[probeExt.InteractionType.CloseContact] = 'vdw contact'
    if self.params.approach == 'surface':
      mast[probeExt.InteractionType.CloseContact] = 'surface'

    if self.params.output.add_group_name_master_line:
      extraMaster = ' master={{{}}}'.format(masterName)

    ret += "@subgroup dominant {{{}}}\n".format(groupName)

    if self.params.approach == 'surface':
      ret += "@master {{{}}}\n".format(mast[1])
    else:
      if self.params.output.report_vdws and not self.params.output.only_report_bad_clashes:
        ret += "@master {{{}}}\n".format(mast[probeExt.InteractionType.WideContact])
        if not self.params.output.merge_contacts:
          ret += "@master {{{}}}\n".format(mast[probeExt.InteractionType.CloseContact])
      if self.params.output.report_clashes or self.params.output.only_report_bad_clashes:
        if not self.params.output.only_report_bad_clashes:
          ret += "@master {{{}}}\n".format(mast[probeExt.InteractionType.SmallOverlap])
        ret += "@master {{{}}}\n".format(mast[probeExt.InteractionType.Bump])
        if self.params.output.separate_worse_clashes:
          ret += "@master {{{}}}\n".format(mast[probeExt.InteractionType.BadBump])
      if self.params.output.report_hydrogen_bonds and not self.params.output.only_report_bad_clashes:
        ret += "@master {{{}}}\n".format(mast[probeExt.InteractionType.StandardHydrogenBond])
        if self.params.probe.allow_weak_hydrogen_bonds:
          ret += "@master {{{}}}\n".format(mast[probeExt.InteractionType.WeakHydrogenBond])

    # Report count legend if any counts are nonzero.
    if _totalInteractionCount(self._MCMCCount) > 0:
      ret += "@pointmaster 'M' {McMc contacts}\n"
    if _totalInteractionCount(self._SCSCCount) > 0:
      ret += "@pointmaster 'S' {ScSc contacts}\n"
    if _totalInteractionCount(self._MCSCCount) > 0:
      ret += "@pointmaster 'P' {McSc contacts}\n"
    if _totalInteractionCount(self._otherCount) > 0:
      ret += "@pointmaster 'O' {Hets contacts}\n"

    # Report binned gap legend if we're binning gaps
    if self.params.output.bin_gaps:
      for i in range(gaplimit):
        ret += "@pointmaster '{}' {{gap {:3.2f}}}\n".format(gapNames[i],((i-11.0)/20.0)+0.05)

    # Go through all atom types and contact types and report the contacts.
    for atomClass in _allAtomClasses:
      for interactionType in _interactionTypes:
        # When we switch point types, we need to repeat the point ID.
        lastPointID = ''

        # Write list headers for types that have entries.  Do not write one for weak Hydrogen
        # bonds unless we're separating them out.
        if (len(self._results[atomClass][interactionType]) > 0 and
              (self.params.probe.allow_weak_hydrogen_bonds or
                  interactionType != probeExt.InteractionType.WeakHydrogenBond
              )
            ):
          # The formatting of the header depends on the type
          # of dot it is and whether atoms are masters.  There is a basic line for each, with addition of
          # a lens string for some cases.  Some entries are dots and others are vectors.
          lensDots = ""
          listType = '@dotlist'
          if interactionType in [probeExt.InteractionType.WideContact, probeExt.InteractionType.CloseContact]:
            if self.params.output.add_lens_keyword:
              lensDots = " lens"
          elif interactionType in [probeExt.InteractionType.SmallOverlap, probeExt.InteractionType.Bump,
              probeExt.InteractionType.BadBump]:
            listType = '@vectorlist'
          elif interactionType == probeExt.InteractionType.StandardHydrogenBond:
            # Nothing special
            pass

          # Write the header based on the settings above and whether atoms are masters.
          if self.params.output.atoms_are_masters:
            ret += "{} {{x}} color={} master={{{} dots}} master={{{}}}{}{}\n".format(
                    listType,
                    _color_for_atom_class(atomClass), atomClass, mast[interactionType], extraMaster,
                    lensDots
                   )
          else:
            ret += "{} {{x}} color={} master={{{}}}{}{}\n".format(
                      listType,
                      _color_for_atom_class(atomClass), mast[interactionType], extraMaster,
                      lensDots
                    )

        # Report all of the dots of this type.
        for node in self._results[atomClass][interactionType]:
          a = node.src
          t = node.target
          if self.params.output.bin_gaps:
            # Include trailing space for a gapbin character (second point master)
            ptmast = " '{} ' ".format(node.ptmaster)
          elif node.ptmaster == " ":
            # Blank means no point master
            ptmast = ""
          else:
            ptmast = " '{}' ".format(node.ptmaster)

          pointid = "{}{:1s}{:>3s} {:>3d} {:1s}{}".format(a.name, a.parent().altloc, a.parent().resname,
            a.parent().parent().resseq_as_int(), a.parent().parent().icode,
            a.parent().parent().parent().id)
          if pointid != lastPointID:
            lastPointID = pointid
            ret += '{{{}}}'.format(pointid)
          else:
            ret += '{"}'

          if self.params.output.color_by_gap:
            if t is not None:
              color = _color_for_gap(node.gap, interactionType)
              ret += "{}".format(color)
            else:
              ret += "{} ".format(self.params.output.default_point_color)

          # Handle gap binning if we're doing it
          if self.params.output.bin_gaps:
            Lgotgapbin = False    # until identify which gapbin
            for k in range(gaplimit):
              # pt master intervals of 0.05 from -0.5 to +0.5
              if node.gap < ((k-11.0)/20.0)+0.05:
                # Replace the fourth character of ptmast with the appropriate gap name
                ptmast = ptmast[:3]+gapNames[k]+ptmast[4:]
                gapcounts[k] += 1
                maxgapcounts = max(gapcounts[k], maxgapcounts)
                if k < gaplimit:
                  Lgotgapbin = True
                  break
            if not Lgotgapbin:
              # assign this node, aka dot, to overflow gapbin
              ptmast = ptmast[:3]+gapNames[-1]+ptmast[4:]
              gapcounts[-1] += 1

          # Add alternate conformation masters to the pointmaster unless we've been told not to
          if self.params.output.altid_as_pointmaster:
            alt = ''
            if (not a.parent().altloc in [' ', '']):
              alt = a.parent().altloc
            if (not t is None) and (not t.parent().altloc in [' ', '']):
              alt += t.parent().altloc
            if alt != '':
              # Find the index of the second single quote in the ptmaster string

              idx = ptmast.rfind("'")
              # Insert the alternate conformation into the ptmaster string at this index,
              # using the lower-case version of the alternate conformation character.
              ptmast = ptmast[:idx] + alt.lower() + ptmast[idx:]

          if interactionType in [probeExt.InteractionType.SmallOverlap, probeExt.InteractionType.Bump,
              probeExt.InteractionType.BadBump]:
            ret += 'P {}{:.3f},{:.3f},{:.3f} {{"}}{} {}{:.3f},{:.3f},{:.3f}\n'.format(
                      ptmast, node.loc[0], node.loc[1], node.loc[2],
                      color,
                      ptmast, node.spike[0], node.spike[1], node.spike[2]
                    )
          else: # Contact or H bond
            ret += "{}{:.3f},{:.3f},{:.3f}\n".format(
                      ptmast, node.loc[0], node.loc[1], node.loc[2]
                   )

    # Print the gap bins if we have computed them.
    if self.params.output.bin_gaps:
      ret += "@text\n"
      for k in range(gaplimit):
        ret += "{{{:5.2f}, {:8d} }}\n".format(
                (((k-11.0)/20.0)+0.05),gapcounts[k]
                )

      # kinemage 2
      ret += "@kinemage 2\n"
      ret += "@group {{gapbins}} dominant\n"
      ret += "@vectorlist {gapbins}\n"
      for k in range(gaplimit-1):
        ret += "{{{:5.2f}, {:8d} }} {:5.2f}, {:8f}, 0.00\n".format(
                 (((k-11.0)/20.0)+0.05), gapcounts[k],
                 (((k-11.0)/20.0)+0.05)*maxgapcounts, gapcounts[k]
               )
      ret += "@labellist {gapbins}\n"
      ret += "{0} 0.0, -1.0, 0.0\n"

      # LXHvector output in probe had to do with -oneDotEach, so we don't include it here.

    return ret

# ------------------------------------------------------------------------------

  def _doEnumeration(self, reportSubScores, isSurface, numSkinDots):
    '''
      Compute summary counts for data of various kinds.  Called by _rawEnumerate() and
      _enumerate() to do the shared work.
      :param reportSubScores: Provide reports on different contact subscores.
      :param isSurface: Are these all surface dots?
      :param numSkinDots: The number of dots on atom skins. This is used to normalize output scores.
      :return: Tuple of values: (string_to_output, tgs, ths, thslen, tbs, tbslen, tsas,
              tGscore, tHscore, tBscore, tscore)
    '''
    retString = ''

    # Store values that we will need often
    approach = self.params.approach
    density = self.params.probe.density
    gap_weight = self.params.probe.gap_weight
    bump_weight = self.params.probe.bump_weight
    hydrogen_bond_weight = self.params.probe.hydrogen_bond_weight

    # Compute the counts
    tgs = ths = thslen = tbs = tbslen = tsas = 0
    tGscore = tHscore = tBscore = tscore = 0
    for c in _allAtomClasses:
      for t in _interactionTypes:
        res = self._results[c][t]
        if len(res) > 0:

          # gs stores all of the values unless reportSubScores is True
          gs = hs = hslen = bs = bslen = score = psas = 0

          # Print a line describing the atom class and interaction type.
          label = "external_dots "
          if not isSurface:
            label = probeExt.DotScorer.interaction_type_name(t)
          retString += "{:>3s} {:14s} ".format(c, label)

          for node in self._results[c][t]:
            if reportSubScores:
              if t in [probeExt.InteractionType.WideContact, probeExt.InteractionType.CloseContact,
                  probeExt.InteractionType.WeakHydrogenBond]:
                gs += 1
                dtgp = node.gap
                scaledGap = dtgp/gap_weight
                scoreValue = math.exp(-scaledGap*scaledGap)
                score   += scoreValue
                tGscore += scoreValue
              elif t in [probeExt.InteractionType.SmallOverlap, probeExt.InteractionType.Bump,
                  probeExt.InteractionType.BadBump]:
                bs += 1
                slen = 0.5*abs(node.gap);
                bslen += slen
                scoreValue = - bump_weight * slen
                score   += scoreValue
                tBscore += scoreValue
              else: # Hydrogen bond
                hs += 1
                slen = 0.5*abs(node.gap)
                hslen += slen
                scoreValue = hydrogen_bond_weight * slen
                score   += scoreValue
                tHscore += scoreValue
            else:
              gs += 1

            if approach == 'surface':
              p_radius = self.params.probe.probe_radius
              a_radius = self._extraAtomInfo.getMappingFor(node.src).vdwRadius
              psas += (a_radius + p_radius)*(a_radius + p_radius)/(a_radius * a_radius)

          # Finish reporting by atom class and interaction type
          if reportSubScores:
            if t in [probeExt.InteractionType.WideContact, probeExt.InteractionType.CloseContact,
                probeExt.InteractionType.WeakHydrogenBond]:
              retString += "{:7d} {:5.1f}% {:9.1f} {:9.2f}\n".format(gs, 100.0*gs/numSkinDots, score/density,
                                1000.0*score/numSkinDots)
            elif t in [probeExt.InteractionType.SmallOverlap, probeExt.InteractionType.Bump,
                probeExt.InteractionType.BadBump]:
              retString += "{:7d} {:5.1f}% {:9.1f} {:9.2f}\n".format(bs, 100.0*bs/numSkinDots, score/density,
                                1000.0*score/numSkinDots)
            else: # Hydrogen bond
              retString += "{:7d} {:5.1f}% {:9.1f} {:9.2f}\n".format(hs, 100.0*hs/numSkinDots, score/density,
                                1000.0*score/numSkinDots)
          else:
            retString += "{:7d} {:5.1f}%\n".format(gs, 100.0*gs/numSkinDots)

          # Done computing for this category, calculate totals
          tgs += gs
          ths += hs
          thslen += hslen
          tbs += bs
          tbslen += bslen
          tscore += score
          if approach == 'surface':
            tsas += psas  # tally the solvent accessible surface

    return (retString, tgs, ths, thslen, tbs, tbslen, tsas, tGscore, tHscore, tBscore, tscore)

# ------------------------------------------------------------------------------

  def _rawEnumerate(self, groupName, numberSelected, reportSubScores, isSurface, numSkinDots, masterName):
    '''
      Describe summary counts for data of various kinds.
      :param groupName: Name to give to the group.
      :param numberSelected: Number of atoms in the selection.
      :param reportSubScores: Provide reports on different contact subscores.
      :param isSurface: Are these all surface dots?
      :param numSkinDots: The number of dots on atom skins. This is used to normalize output scores.
      :param masterName: Name for the beginning of each line.
      :return: String to be added to the output.
    '''
    # The C code has a rawName parameter, but it was only nonempty for autobondrot/movingDoCommand
    # The C code has a scoreBias parameter, but it was only nonzero for autobondrot/movingDoCommand

    ret = ""

    # If we have an empty selection, report zero.
    if numberSelected <= 0 or numSkinDots <= 0:
      ret += "{:9.3f}".format(0.0)

    else:
      # Compute and report the score.  Discard anything from the return string in the count
      # routine -- we don't want to print it.
      (retString, tgs, ths, thslen, tbs, tbslen, tsas, tGscore, tHscore, tBscore, tscore
        ) = self._doEnumeration(reportSubScores, isSurface, numSkinDots)

      # Output one line of information.
      if isSurface:
        ret += "{:9.3f}".format( (tgs+tbs+ths)/self.params.probe.density )
      elif reportSubScores:
        ret += "{:9.3f}".format( tscore/self.params.probe.density )
      else:
        ret += "{:9.3f}".format( tgs )

    # Report the same information at the end of the line whether or not we counted the scores.
    if len(groupName) > 0 or len(masterName) > 0:
      ret += "#"
    if len(masterName) > 0:
      ret += " {}".format(masterName)
    if len(groupName) > 0:
      ret += " {}".format(groupName)
    ret += "\n"
    return ret

# ------------------------------------------------------------------------------

  def _count_summary(self, modeName, completed = True):
    '''
      Describe summary counts for chain-vs.-chain counts.
      :param modeName: Description of the mode of operation to report.
      :param completed: This is the last iteration, so print the accumulated values.
      :return: String to be added to the output.
    '''

    ret = ''

    # Keep a running total of values for each chain-vs.-chain list.
    # The first time we're run, fill the values with 0.
    # Clear the global counts once they have been added to the running total so we can run a new count.
    if not hasattr(self,'_MCMCTotal'):
      self._MCMCTotal = {}
      self._SCSCTotal = {}
      self._MCSCTotal = {}
      self._otherTotal = {}
      for t in _interactionTypes:
        self._MCMCTotal[t] = 0
        self._SCSCTotal[t] = 0
        self._MCSCTotal[t] = 0
        self._otherTotal[t] = 0
    for t in _interactionTypes:
      self._MCMCTotal[t] += self._MCMCCount[t]
      self._MCMCCount[t] = 0
      self._SCSCTotal[t] += self._SCSCCount[t]
      self._SCSCCount[t] = 0
      self._MCSCTotal[t] += self._MCSCCount[t]
      self._MCSCCount[t] = 0
      self._otherTotal[t] += self._otherCount[t]
      self._otherCount[t] = 0

    # Compute the sum of all subtypes per interaction type.
    sumTotal = {}
    for t in _interactionTypes:
      sumTotal[t] = self._MCMCTotal[t] + self._SCSCTotal[t] + self._MCSCTotal[t] + self._otherTotal[t]

    # If we're at the last pass, fill in our return string.
    if completed:
      if self.params.output.format == 'oneline':
        # Report the file name that was read along with its summary data on one line
        ret += ": {} ".format(self.data_manager.get_model_names()[0])
        for c in [self._MCMCTotal, self._SCSCTotal, self._MCSCTotal, self._otherTotal]:
          for t in _interactionTypes:
            ret += ":{:9d} ".format(c[t])
        ret += ":\n"
      else:
        ret += "@text\n"
        ret += "probe: {}\n".format(modeName)
        ret += "{}\n".format(self.data_manager.get_model_names()[0])
        ret += ":CONTACT:   WIDE   :  CLOSE   :  weak H-bonds  : SMALL   :   BAD    :  WORSE  :  H-BOND  :\n"
        for (c,name) in [(self._MCMCTotal, "MCMC"), (self._SCSCTotal, "SCSC"),
                         (self._MCSCTotal, "MCSC"), (self._otherTotal, "OTHER"),
                         (sumTotal, "SUM")]:
          ret += ":{:7s}".format(name)
          for t in _interactionTypes:
            ret += ":{:9d} ".format(c[t])
          ret += ":\n"

    return ret

# ------------------------------------------------------------------------------

  def _enumerate(self, groupName, numberSelected, reportSubScores, isSurface, numSkinDots):
    '''
      Describe summary counts for data of various kinds.
      :param groupName: Name to give to the group.
      :param numberSelected: Number of atoms in the selection.
      :param reportSubScores: Provide reports on different contact subscores.
      :param isSurface: Are these all surface dots?
      :param numSkinDots: The number of dots on atom skins. This is used to normalize output scores.
      :return: String to be added to the output.
    '''

    ret = ''

    # Store values that we will need often
    density = self.params.probe.density

    ret += "        \nsubgroup: {}\n".format(groupName)
    ret += "atoms selected: {}\npotential dots: {}\npotential area: {:.1f} A^2\n".format(
      numberSelected, numSkinDots, numSkinDots/density)
    if numberSelected <=0 or numSkinDots <= 0:
      ret += "empty selection\n"
      return

    if reportSubScores:
      ret += "  type                 #      %       score score/A^2 x 1000\n"
    else:
      ret += "  type                 #      %\n"

    # Compute the counts
    (retString, tgs, ths, thslen, tbs, tbslen, tsas, tGscore, tHscore, tBscore, tscore
      ) = self._doEnumeration(reportSubScores, isSurface, numSkinDots)
    ret += retString

    # Report the counts
    if reportSubScores:
      ret += "\n     tot contact:  {:7d} {:5.1f}% {:9.1f} {:9.2f}\n".format(
        tgs, 100.0*tgs/numSkinDots, tGscore/density, 1000.0*tGscore/numSkinDots
      )
      ret += "     tot overlap:  {:7d} {:5.1f}% {:9.1f} {:9.2f}\n".format(
        tbs, 100.0*tbs/numSkinDots, tBscore/density, 1000.0*tBscore/numSkinDots
      )
      ret += "     tot  H-bond:  {:7d} {:5.1f}% {:9.1f} {:9.2f}\n".format(
        ths, 100.0*ths/numSkinDots, tHscore/density, 1000.0*tHscore/numSkinDots
      )

      ret += "\n       grand tot:  {:7d} {:5.1f}% {:9.1f} {:9.2f}\n".format(
        (tgs+tbs+ths), 100.0*(tgs+tbs+ths)/numSkinDots, tscore/density, 1000.0*tscore/numSkinDots
      )
      ret += "\ncontact surface area: {:.1f} A^2\n".format((tgs+tbs+ths)/density)
    else:
      ret += "             tot:  {:7d} {:5.1f}%\n\n".format(tgs, 100.0*tgs/numSkinDots)
      ret += "   contact surface area: {:.1f} A^2\n".format(tgs/density)
      if self.params.approach == 'surface':
        ret += "accessible surface area: {:.1f} A^2\n\n".format(tsas/density)

    return ret


# ------------------------------------------------------------------------------

  def _describe_selection_and_parameters(self, groupLabel, selectionName):
    '''
      Describe the selection type and other parameters for a run.  Called by various run types.
      :param groupLabel: Name to give to the group.
      :param selectionName: Name of the selection mode: 'self', 'once'.
      :return: String to be added to the output.
    '''

    ret = ''
    ret += "selection: {}\nname: {}\n".format(selectionName, groupLabel)
    ret += "density: {:.1f} dots per A^2\nprobeRad: {:.3f} A\nVDWrad: (r * {:.3f}) + {:.3f} A\n".format(
      self.params.probe.density, self.params.probe.probe_radius, self.params.atom_radius_scale,
      self.params.atom_radius_offset)
    ret += "score weights: gapWt={:0g}, bumpWt={:0g}, HBWt={:0g}\n".format(
      self.params.probe.gap_weight, self.params.probe.bump_weight, self.params.probe.hydrogen_bond_weight)
    return ret

# ------------------------------------------------------------------------------

  def _report_single_interaction(self, groupLabel, selectionName, comparisonString, intersectionName,
      numModels, modelIndex, bondedNeighborLists):
    '''
      Print information about a single interaction, either self interaction or once interaction.
      :param groupLabel: Name to give to the group.
      :param selectionName: Name of the selection mode: 'self', 'once'.
      :param comparisonString: String decribing the comparison: '1->1', '1->2'.
      :param intersectionName: Name of the intersection being done: 'SelfIntersect', 'IntersectOnce'.
      :param numModels: Number of models we are running over.
      :param modelIndex: Current model we are running.
      :param bondedNeighborLists: List of bonded neighbors for atoms in sourceAtoms.
      :return: String to be added to the output.
    '''

    ret = ''
    # Count the dots if we've been asked to do so.
    if self.params.output.count_dots:
      numSkinDots = self._count_skin_dots(self._source_atoms_sorted, bondedNeighborLists)
      if self.params.output.format != 'raw':
        ret += self._describe_run("program:","command:")
        ret += self._describe_selection_and_parameters(groupLabel, selectionName)

      nsel = len(self._source_atoms_sorted)
      if self.params.output.format == 'raw':
        ret += self._rawEnumerate("", nsel, self.params.output.compute_scores, False, numSkinDots, groupLabel)
      else:
        ret += self._enumerate("{} dots".format(selectionName), nsel, self.params.output.compute_scores, False, numSkinDots)

    else: # Not counting the dots

      # Check for various output format types.
      # We're not implementing O format or XV format, but we still allow raw and oneline
      if self.params.output.format == 'raw':
        ret += self._writeRawOutput(comparisonString,groupLabel, False)

      elif self.params.output.format == 'json':
        ret += self._writeRawOutput(comparisonString,groupLabel, True)

      elif self.params.output.format == 'oneline':
        ret += self._count_summary(intersectionName)

      elif self.params.output.format == 'kinemage': # Kinemage format
        ret += self._describe_run("@caption"," command:")
        if self.params.output.contact_summary:
          ret += self._count_summary(intersectionName)

        if self.params.output.add_group_line:
          if numModels > 1:
            # doing one of multiple models of an ensemble
            ret += "@group dominant {{{} M{}}} animate\n".format(groupLabel,modelIndex+1)
          else:
            ret += "@group dominant {{{}}}\n".format(groupLabel)

        ret += self._writeOutput("{} dots".format(selectionName), groupLabel)
        # Put the water after so they end up in the right group
        ret += self._phantomHydrogenOutput

      else:
        raise ValueError("Unrecognized output format: "+self.params.output.format+" (internal error)")

    return ret

# ------------------------------------------------------------------------------

  def _clear_results(self):
    # Initialize the results to empty.
    self._results = {}
    for c in _allAtomClasses:
      interactionTypeDicts = {}
      for i in _interactionTypes:
        interactionTypeDicts[i] = []
      self._results[c] = interactionTypeDicts

# ------------------------------------------------------------------------------

  def _describe_run(self, header1, header2):
    '''
      Describe the command-line and other Phil options used for this run so that
      it could be reproduced.
      :param header1: Header for the first output line (the version/time line).
      :param header2: Header for the second output line (the command and its arguments).
      :return: String to be added to the output.
    '''

    global version
    ret = '{} probe2 v.{}, run {}\n'.format(header1, version, datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    ret += header2
    for a in sys.argv:
      ret += ' {}'.format(a)
    ret += '\n'

    return ret

# ------------------------------------------------------------------------------

  def validate(self):
    self.data_manager.has_models(raise_sorry=True)
    if self.params.output.filename is None:
      # If the output file name is not specified, use the same root as the
      # input file and replace the suffix with .kin for Kinemage output or
      # .txt for raw or .json for JSON.
      suffix = '.kin'
      if self.params.output.format == 'json':
        suffix = '.json'
      elif self.params.output.format != 'kinemage' or self.params.output.count_dots:
        suffix = '.txt'
      inName = self.data_manager.get_default_model_name()
      p = Path(inName)
      self.params.output.filename = str(p.with_suffix(suffix))
      print('Setting output.filename Phil parameter to',self.params.output.filename)
    if self.params.source_selection is None:
      raise Sorry("Must specify a source parameter for approach "+self.params.approach)
    if self.params.approach in ['once','both'] and self.params.target_selection is None:
      raise Sorry("Must specify a target parameter for approach "+self.params.approach)
    aScale = self.params.atom_radius_scale
    if aScale < 0.0001 or aScale > 1000:
      raise Sorry("Invalid atom_radius_scale value: {:0g}".format(aScale))
    ao = self.params.atom_radius_offset
    if ao < -10 or ao > 1000:
      raise Sorry("Invalid atom_radius_offset value: {:0g}".format(ao))

    # Ensure consistency among parameters
    if self.params.probe.contact_cutoff < self.params.probe.probe_radius:
      self.params.probe.contact_cutoff = self.params.probe.probe_radius

    # Turn on profiling if we've been asked to in the Phil parameters
    if self.params.profile:
      import cProfile
      self._pr = cProfile.Profile()
      self._pr.enable()

# ------------------------------------------------------------------------------

  def overrideModel(self, model):
    '''This is a hack to let another program harness probe2 without having to write a
    new model file for it to read. After initializing probe2, but before calling
    run(), call this function to override the model that it should use.
    '''
    self.model = model

# ------------------------------------------------------------------------------

  def run(self):
    # String that will be output to the specified file.
    outString = ''

    if (self.params.output.add_kinemage_keyword and not self.params.output.count_dots
        and self.params.output.format == 'kinemage'):
      outString += '@kinemage 1\n'

    make_sub_header('Interpret Model', out=self.logger)

    # Allow the model to be overridden using the overrideModel() method.
    if not hasattr(self, 'model'):
      # Get our model.
      self.model = self.data_manager.get_model()

    ################################################################################
    # Get the bonding information we'll need to exclude our bonded neighbors.
    allAtoms = self.model.get_atoms()
    make_sub_header('Compute neighbor lists', out=self.logger)

    self.model.set_stop_for_unknowns(False)
    p = mmtbx.model.manager.get_default_pdb_interpretation_params()
    p.pdb_interpretation.use_neutron_distances = self.params.use_neutron_distances
    p.pdb_interpretation.allow_polymer_cross_special_position=True
    p.pdb_interpretation.clash_guard.nonbonded_distance_threshold=None
    p.pdb_interpretation.proceed_with_excessive_length_bonds=True
    p.pdb_interpretation.disable_uc_volume_vs_n_atoms_check=True
    # We need to turn this on because without it the interpretation is
    # renaming atoms to be more correct.  Unfortunately, this causes the
    # dot names to no longer match the input file.
    p.pdb_interpretation.flip_symmetric_amino_acids=False
    try:
      self.model.process(make_restraints=True, pdb_interpretation_params=p) # make restraints
      geometry = self.model.get_restraints_manager().geometry
      sites_cart = self.model.get_sites_cart() # cartesian coordinates
      bondProxies, asu = \
          geometry.get_all_bond_proxies(sites_cart = sites_cart)
    except Exception as e:
      try:
        # Fix up bogus unit cell when it occurs by checking crystal symmetry.
        self.model.add_crystal_symmetry_if_necessary()

        # Retry with the adjusted model
        self.model.process(make_restraints=True, pdb_interpretation_params=p) # make restraints
        geometry = self.model.get_restraints_manager().geometry
        sites_cart = self.model.get_sites_cart() # cartesian coordinates
        bondProxies, asu = \
            geometry.get_all_bond_proxies(sites_cart = sites_cart)

      except Exception as e:
        raise Sorry("Could not get bonding information for input file: " + str(e))

    ################################################################################
    # Get the bonding information we'll need to exclude our bonded neighbors.
    self._allBondedNeighborLists = Helpers.getBondedNeighborLists(allAtoms, bondProxies)

    ################################################################################
    # Get the extra atom information needed to score all of the atoms in the model.
    make_sub_header('Compute extra atom information', out=self.logger)
    ret = Helpers.getExtraAtomInfo(model = self.model,
      bondedNeighborLists = self._allBondedNeighborLists,
      useNeutronDistances = self.params.use_neutron_distances,
      probePhil = self.params.probe)
    self._extraAtomInfo = ret.extraAtomInfo
    if len(ret.warnings) > 0:
      print('Warnings returned by getExtraAtomInfo():\n'+ret.warnings, file=self.logger)

    # Scale and offset the radius values for all atoms based on our command-line arguments.
    for a in allAtoms:
      ei = self._extraAtomInfo.getMappingFor(a)
      ei.vdwRadius = self._scaled_atom_radius(a)
      self._extraAtomInfo.setMappingFor(a, ei)

    ################################################################################
    # Find the maximum VDW radius of any of our atoms, used to limit searches for nearby
    # atoms.
    self._maximumVDWRadius = 1
    for a in allAtoms:
      self._maximumVDWRadius = max(self._maximumVDWRadius, self._extraAtomInfo.getMappingFor(a).vdwRadius)

    ################################################################################
    # Get the extra atom information needed to sort all of the atoms in the model
    # into proper classes for reporting.  These classes may be atom names, when we're
    # sorting by atoms and it can be nucleic acid base names when we're sorting by that.
    # Comes from newAtom() and dotType() functions in probe.c.
    # Rather than a table indexed by type, we directly write the result.
    # Handle all atoms, not only selected atoms.
    self._atomClasses = {}
    for a in allAtoms:
      if not a.element_is_hydrogen():
        # All elements except hydrogen use their own names.
        self._atomClasses[a] = self._atom_class_for(a)
      else:
        # For hydrogen, assign based on what it is bonded to.
        if len(self._allBondedNeighborLists[a]) < 1:
          raise Sorry("Found Hydrogen with no neigbors: " + self._describe_atom_for_debug(a))
        else:
          self._atomClasses[a] = self._atom_class_for(self._allBondedNeighborLists[a][0])

    ################################################################################
    # Get the other characteristics we need to know about each atom to do our work.
    make_sub_header('Getting extra atom characteristics', out=self.logger)
    self._inWater = {}
    self._inHet = {}
    self._inMainChain = {}
    self._inSideChain = {}
    hetatm_sel = self.model.selection("hetatm")
    mainchain_sel = self.model.selection("backbone")  # Will NOT include Hydrogen atoms on the main chain
    sidechain_sel = self.model.selection("sidechain") # Will include Hydrogen atoms on the side chain
    for a in allAtoms:
      self._inWater[a] = common_residue_names_get_class(name=a.parent().resname) == "common_water"
      self._inHet[a] = hetatm_sel[a.i_seq]
      if not a.element_is_hydrogen():
        self._inMainChain[a] = mainchain_sel[a.i_seq]
      else:
        # Check our bonded neighbor to see if it is on the mainchain if we are a Hydrogen
        if len(self._allBondedNeighborLists[a]) < 1:
          raise Sorry("Found Hydrogen with no neigbors: " + self._describe_atom_for_debug(a))
        else:
          self._inMainChain[a] = mainchain_sel[self._allBondedNeighborLists[a][0].i_seq]
      self._inSideChain[a] = sidechain_sel[a.i_seq]

    ################################################################################
    # Ensure that the model we've been passed has at least one Hydrogen bonded to a Carbon
    # and at least one polar Hydrogen (bonded to N, O, or S).  Otherwise, raise a Sorry.
    if not self.params.ignore_lack_of_explicit_hydrogens:
      foundCBonded = False
      foundPolar = False
      for a in allAtoms:
        if Helpers.isPolarHydrogen(a, self._allBondedNeighborLists):
          foundPolar = True
        elif a.element_is_hydrogen():
          if len(self._allBondedNeighborLists[a]) < 1:
            raise Sorry("Found Hydrogen with no neigbors: " + self._describe_atom_for_debug(a))
          else:
            neighbor = self._allBondedNeighborLists[a][0]
            if neighbor.element == 'C':
              foundCBonded = True
      if not (foundCBonded and foundPolar):
        raise Sorry("Did not find both polar and non-polar Hydrogens in model.  For proper operation, "+
                    "Probe requires explicit Hydrogens.  Run Reduce2 or another placement "+
                    "program on the model before running Probe, or else add the Phil "+
                    "parameter ignore_lack_of_explicit_hydrogens=True.")

    ################################################################################
    # Get the source selection (and target selection if there is one).  These will be
    # lists of atoms that are in each selection, a subset of the atoms in the model.
    # If there is no model_id in the selection criteria, these may include atoms from
    # multiple models in the hierarchy.
    make_sub_header('Getting atom selections', out=self.logger)
    source_sel = self.model.selection(self.params.source_selection)
    allSourceAtoms = set()
    for a in allAtoms:
      if source_sel[a.i_seq]:
        allSourceAtoms.add(a)

    allTargetAtoms = set()
    if self.params.target_selection is not None:
      # If the target selection is "=", that means that it should be the same as the source selection.
      if self.params.target_selection == "=":
        allTargetAtoms = allSourceAtoms
      else:
        target_sel = self.model.selection(self.params.target_selection)
        for a in allAtoms:
          if target_sel[a.i_seq]:
            allTargetAtoms.add(a)

    ################################################################################
    # We usually have the selection pick a model, but in the case of SELFINTERSECT with one
    # input file and no model specified in the source and target patterns, we loop over all
    # models in the file.
    # We get lists of all atoms present in each hierarchy model that we're running.
    # This is a list of one when only one is selected and it is all of the available ones
    # when no particular one is selected.
    make_sub_header('Getting atom lists', out=self.logger)
    atomLists = [ self.model.get_atoms() ]
    if (self.params.approach == 'self' and
        (self.params.source_selection is None or 'model' not in self.params.source_selection) and
        (self.params.target_selection is None or 'model' not in self.params.target_selection)):
      # Handle the multiple-model case by looping modelID over all models.
      numModels = self.model.get_hierarchy().models_size()
      atomLists = []
      for i in range(numModels):
        atomLists.append( self.model.get_hierarchy().models()[i].atoms() )

    make_sub_header('Processing atom lists', out=self.logger)
    for modelIndex, atoms in enumerate(atomLists):

      ################################################################################
      # Get the subset of the source selection and target selection for this hierarchy
      # model.

      # Make an acceleration structure for determining whether an atom is in the ones we
      # are considering in the current list. This is a set rather than a list to make it
      # rapid to determine membership.
      atomsInThisModel = set(atoms)
      source_atoms = set()
      for a in allSourceAtoms:
        if a in atomsInThisModel:
          source_atoms.add(a)

      target_atoms = set()
      for a in allTargetAtoms:
        if a in atomsInThisModel:
          target_atoms.add(a)

      ###########################
      # Helper utility function to sort atoms consistently from run to run so that we get
      # the same ordering on coarse angles.
      def atomID(a):
        # Return the ID of the atom, which includes its chain, residue name,
        # residue number, atom name, and alternate separated by spaces. This
        # is used to sort the atoms. This must work in the case where we have
        # test atoms that are not completely fleshed out.
        try:
          return ( a.parent().parent().parent().id + a.parent().resname +
            str(a.parent().parent().resseq_as_int()) + a.name + a.parent().altloc )
        except Exception:
          return ""
      #
      ###########################

      ################################################################################
      # Find a list of all of the selected atoms with no duplicates
      # Get the bonded neighbor lists for the atoms that are in this selection.
      # We have to do this so that when keep_unselected_atoms is set to False we don't
      # follow bonds to neighbor atoms that should not exist.
      # Sort the atoms by an ID that is consistent from run to run so that they end up
      # in our data structures in the same order for each run.

      make_sub_header('Sorting atoms', out=self.logger)
      all_selected_atoms = sorted(source_atoms.union(target_atoms), key=lambda x:atomID(x))
      make_sub_header('Getting bonded-neighbor lists', out=self.logger)
      bondedNeighborLists = Helpers.getBondedNeighborLists(all_selected_atoms, bondProxies)

      ################################################################################
      # Build a spatial-query structure that tells which atoms are nearby.
      # Include all atoms in the structure, not just the ones that have been selected,
      # unless we've been asked not to keep them.
      make_sub_header('Make spatial-query accelerator', out=self.logger)
      if self.params.keep_unselected_atoms:
        self._spatialQuery = Helpers.createSpatialQuery(atoms, self.params.probe)
        # Replace the bonded-neighbor list with all bonded neighbors, even ones that
        # are not selected, so that they will block dots that overlap with bonded atoms.
        bondedNeighborLists = self._allBondedNeighborLists
        selectedAtomsIncludingKept = atoms
      else:
        self._spatialQuery = Helpers.createSpatialQuery(all_selected_atoms, self.params.probe)
        selectedAtomsIncludingKept = all_selected_atoms

      ################################################################################
      # Add Phantom hydrogens to waters and mark
      # the water oxygens as not being donors in atoms that are in the source or target selection.
      # Also clear the donor status of all N, O, S atoms because we have explicit hydrogen donors.
      self._phantomHydrogenOutput = ""
      phantomHydrogens = []
      make_sub_header('Adjusting for explicit hydrogens', out=self.logger)
      if self.params.output.record_added_hydrogens:
        self._phantomHydrogenOutput += "@master {water H?}\n"
        self._phantomHydrogenOutput += '@vectorlist {water H?} color= gray master={water H?}\n'

      # @todo Look up the radius of a water Hydrogen.  This may require constructing a model with
      # a single water in it and asking about the hydrogen radius.  This could also become a
      # Phil parameter.  Also look up the OH bond distance rather than hard-coding it here.
      phantomHydrogenRadius = 1.05
      placedHydrogenDistance = 0.84
      if self.params.use_neutron_distances:
        phantomHydrogenRadius = 1.0
        placedHydrogenDistance = 0.98

      adjustedHydrogenRadius = self.params.atom_radius_offset + (phantomHydrogenRadius * self.params.atom_radius_scale)

      # Check all selected atoms to see if we need to add Phantom Hydrogens to them.
      # Don't add Phantom Hydrogens to atoms that are not selected, even if they are kept.
      maxISeq = Helpers.getMaxISeq(self.model)
      for a in all_selected_atoms:

        # Ignore Hydrogens whose parameters are out of bounds.
        if a.element_is_hydrogen():
          # In the original code, this looks at H atoms with parent N,O,S atoms
          # and marks them as donors.  This is handled for us below in the call
          # to Helpers.fixupExplicitDonors().

          # If we are in a water, make sure our occupancy and temperature (b) factor are acceptable.
          # If they are not, set the class for the atom to 'ignore'.
          # This handles the case where there were explicit Hydrogens on waters and so
          # we won't add Phantom Hydrogens.
          if self._inWater[a] and (a.occ < self.params.minimum_water_hydrogen_occupancy or
              a.b > self.params.maximum_water_hydrogen_b):
            self._atomClasses[a] = 'ignore'

        # If we are the Oxygen in a water, then add phantom hydrogens pointing towards nearby acceptors
        elif self._inWater[a] and a.element == 'O':
          # We're an acceptor and not a donor.
          # @todo Original Probe code only cleared the donor status if it found a bonded
          # Hydrogen in the same conformation whose occupancy was > 0.1.  Here, we're turning
          # it off regardless of the occupancy.
          ei = self._extraAtomInfo.getMappingFor(a)
          ei.isDonor = False
          ei.isAcceptor = True
          self._extraAtomInfo.setMappingFor(a, ei)

          # If we don't yet have Hydrogens attached, add phantom hydrogen(s)
          if len(bondedNeighborLists[a]) == 0:
            # NOTE: The Phantoms have i_seq numbers that are sequential and that are higher than
            # all other atoms in the model.  Each one has a unique i_seq.
            newPhantoms = Helpers.getPhantomHydrogensFor(maxISeq, a, self._spatialQuery, self._extraAtomInfo,
                            0.0, True, adjustedHydrogenRadius, placedHydrogenDistance)
            maxISeq += len(newPhantoms)
            for p in newPhantoms:

              # Put in our list of Phantom Hydrogens
              phantomHydrogens.append(p)

              # Add the atom to the general spatial-query data structure
              self._spatialQuery.add(p)

              # Set the extra atom information for this atom
              ei = probeExt.ExtraAtomInfo(adjustedHydrogenRadius, False, True, True)
              self._extraAtomInfo.setMappingFor(p, ei)

              # Set the atomClass and other data based on the parent Oxygen.
              self._atomClasses[p] = self._atom_class_for(a)
              self._inWater[p] = self._inWater[a]
              self._inMainChain[p] = self._inMainChain[a]
              self._inSideChain[p] = self._inSideChain[a]
              self._inHet[p] = self._inHet[a]

              # Mark the Phantom Hydrogens as being bonded to their Oxygen so that
              # dots on a Phantom Hydrogen within its Oxygen will be excluded.
              bondedNeighborLists[p] = [a]

              # It was thought that in the future, we may add these bonds, but that will cause the
              # Phantom Hydrogens to mask their water Oxygens from close contacts or
              # clashes with the acceptors, which is a change in behavior from the
              # original Probe and would have the undesirable effect of a potential
              # Hydrogen hiding a true collision.
              # Not marking these as bonded requires special-case handling
              # of Phantom Hydrogen interactions in the dot-scoring code.
              # This means that we have a one-way bond, which is unusual but suits our
              # purposes.
              # Not done: bondedNeighborLists[a].append(p)

              # Add the new atom to any selections that the old atom was in.
              if a in source_atoms:
                source_atoms.add(p)
              if a in target_atoms:
                target_atoms.add(p)

              # Report on the creation if we've been asked to
              if self.params.output.record_added_hydrogens:

                resName = a.parent().resname.strip().upper()
                resID = str(a.parent().parent().resseq_as_int())
                chainID = a.parent().parent().parent().id
                iCode = a.parent().parent().icode
                alt = a.parent().altloc
                self._phantomHydrogenOutput += '{{{:4.4s}{:1s}{:>3s}{:>2s}{:>4s}{:1s}}}P {:8.3f}{:8.3f}{:8.3f}\n'.format(
                  a.name, alt, resName, chainID, resID, iCode,
                  a.xyz[0], a.xyz[1], a.xyz[2])

                resName = p.parent().resname.strip().upper()
                resID = str(p.parent().parent().resseq_as_int())
                chainID = p.parent().parent().parent().id
                iCode = p.parent().parent().icode
                alt = p.parent().altloc
                self._phantomHydrogenOutput += '{{{:4.4s}{:1s}{:>3s}{:>2s}{:>4s}{:1s}}}L {:8.3f}{:8.3f}{:8.3f}\n'.format(
                  p.name, alt, resName, chainID, resID, iCode,
                  p.xyz[0], p.xyz[1], p.xyz[2])

      # Fix up the donor status for all of the atoms now that we've added the final explicit
      # Phantom Hydrogens.
      Helpers.fixupExplicitDonors(selectedAtomsIncludingKept, bondedNeighborLists, self._extraAtomInfo)

      ################################################################################
      # Add ionic bonds to the bonded-neighbor list so that we won't count interactions
      # between two atoms that are both bonded to the same ion (such as Nitrogens on
      # Histidine rings around Cu or Zn).  Do this after we've added the Phantom Hydrogens
      # so that we don't see ionic bonds in the Phantom-Hydrogen addition code checks.
      Helpers.addIonicBonds(bondedNeighborLists, selectedAtomsIncludingKept, self._spatialQuery, self._extraAtomInfo)

      # Make a query structure to return the Phantom Hydrogens (if there are any)
      self._phantomHydrogensSpatialQuery = Helpers.createSpatialQuery(phantomHydrogens, self.params.probe)

      ################################################################################
      # Re-fill all_selected_atoms
      all_selected_atoms = sorted(source_atoms.union(target_atoms), key=lambda x:atomID(x))

      ################################################################################
      # Get the dot sets we will need for each atom.  This is the set of offsets from the
      # atom center where dots should be placed.  We use a cache to reduce the calculation
      # time by returning the same answer for atoms that have the same radius.
      # This must be done after we've added all Phantom Hydrogens and adjusted all of
      # the ExtraAtomInfo.
      dotCache = Helpers.createDotSphereCache(self.params.probe)
      self._dots = {}
      for a in all_selected_atoms:
        self._dots[a] = dotCache.get_sphere(self._extraAtomInfo.getMappingFor(a).vdwRadius).dots()

      ################################################################################
      # Construct a DotScorer object.  This must be done after we've added all Phantom
      # Hydrogens and adjusted all of the ExtraAtomInfo.
      make_sub_header('Make dot scorer', out=self.logger)
      self._dotScorer = Helpers.createDotScorer(self._extraAtomInfo, self.params.probe)

      ################################################################################
      # Sums of interaction types of dots based on whether their source and/or target
      # were mainchain, sidechain, both, or neither.  There is another place to store
      # the sum of multiple passes.
      # Each contains an entry for each InteractionType and for the total.
      self._clear_results();
      self._MCMCCount = {}
      self._SCSCCount = {}
      self._MCSCCount = {}
      self._otherCount = {}
      for t in _interactionTypes:
        self._MCMCCount[t] = 0
        self._SCSCCount[t] = 0
        self._MCSCCount[t] = 0
        self._otherCount[t] = 0

      ################################################################################
      # Generate sorted lists of the selected atoms, so that we run them in the same order
      # they appear in the model file.  This will group phantom hydrogens with the oxygens
      # they are associated with because they share the same sequence ID.
      # We add the location to the sorting criteria because the phantom hydrogens have the
      # same sequence ID as their parent O and as each other.
      self._source_atoms_sorted = sorted(source_atoms, key=lambda atom: "{} {:.3f} {:.3f} {:.3f}".format(
        atom.i_seq, atom.xyz[0], atom.xyz[1], atom.xyz[2]))
      self._target_atoms_sorted = sorted(target_atoms, key=lambda atom:  "{} {:.3f} {:.3f} {:.3f}".format(
        atom.i_seq, atom.xyz[0], atom.xyz[1], atom.xyz[2]))

      ################################################################################
      # Find our group label
      if self.params.output.format in ['raw','json']:
        groupLabel = ""
      else:
        groupLabel = "dots"
      if len(self.params.output.group_label) > 0:
        groupLabel = self.params.output.group_label

      ################################################################################
      # Do the calculations; which one depends on the approach and other phil parameters.
      # Append the information to the string that will be written to file.

      if self.params.approach == 'count_atoms':
        make_sub_header('Counting atoms', out=self.logger)
        # Report the number of atoms in the source selection
        outString += 'atoms selected: '+str(len(self._source_atoms_sorted))+'\n'

      elif self.params.approach == 'surface':
        make_sub_header('Find surface dots', out=self.logger)

        # Store constants used frequently
        minimum_occupancy = self.params.minimum_occupancy
        include_water_water = self.params.include_water_water

        # Produce dots on the surfaces of the selected atoms.
        maxRadius = 2*self._maximumVDWRadius + 2 * self.params.probe.probe_radius
        for src in self._source_atoms_sorted:
          srcInWater = self._inWater[src]
          srcModel = src.parent().parent().parent().parent().id

          # Find nearby atoms that might come into contact.  This greatly speeds up the
          # search for touching atoms.
          maxRadius = (self._extraAtomInfo.getMappingFor(src).vdwRadius + self._maximumVDWRadius +
            2 * self.params.probe.probe_radius)
          nearby = self._spatialQuery.neighbors(src.xyz, 0.00001, maxRadius)

          # Select those that are actually within the contact distance based on their
          # particular radius.  Only accept atoms that are in compatible conformations.
          atomList = []
          for n in nearby:
            nInWater = self._inWater[n]
            nModel = n.parent().parent().parent().parent().id

            # Skip atoms that are marked to be ignored
            if self._atomClasses[n] == 'ignore':
              continue
            # Skip water-water interactions unless they are between atoms in the same residue
            elif (not include_water_water) and srcInWater and nInWater and (src.parent() != n.parent()):
              continue
            # Skip atoms that are in non-compatible alternate conformations
            elif not Helpers.compatibleConformations(src, n):
              continue
            # Skip atoms that are in different models.
            elif srcModel != nModel:
              continue
            d = (Helpers.rvec3(n.xyz) - Helpers.rvec3(src.xyz)).length()
            if (d <= self._extraAtomInfo.getMappingFor(n).vdwRadius +
                self._extraAtomInfo.getMappingFor(src).vdwRadius + 2*self.params.probe.probe_radius):
              atomList.append(n)

          # Find out what class of dot we should place for this atom.
          atomClass = self._atomClasses[src]

          # Generate all of the dots for this atom.
          self._generate_surface_dots_for(src, atomList)

        # Count the dots if we've been asked to do so.
        if self.params.output.count_dots:
          numSkinDots = self._count_skin_dots(self._source_atoms_sorted, bondedNeighborLists)
          if self.params.output.format != 'raw':
            outString += self._describe_selection_and_parameters(groupLabel, "external")

          nsel = len(self._source_atoms_sorted)
          if self.params.output.format == 'raw':
            outString += self._rawEnumerate("", nsel, False, True, numSkinDots, groupLabel)
          else:
            outString += self._describe_run("program:","command:")
            outString += self._enumerate("extern dots", nsel, False, True, numSkinDots)

        # Otherwise, produce the dots as output
        else:
          # Check for various output format types other than Kinemage.
          # We're not implementing O format or XV format, but we still allow raw and oneline
          if self.params.output.format == 'raw':
            outString += self._writeRawOutput("1->none",groupLabel)

          elif self.params.output.format == 'oneline':
            # Do nothing for this mode when computing the surface
            pass

          elif self.params.output.format == 'kinemage': # Kinemage format
            outString += self._describe_run("@caption"," command:")
            masterName = "dots"
            if len(self.params.output.group_name) > 0:
              masterName = self.params.output.group_name

            if self.params.output.add_group_line:
              outString += "@group dominant {{{}}}\n".format(masterName)

            outString += self._writeOutput("extern dots", masterName)

          else:
            raise ValueError("Unrecognized output format: "+self.params.output.format+" (internal error)")

      elif self.params.approach == 'self':
        make_sub_header('Find self-intersection dots', out=self.logger)

        # Generate dots for the source atom set against itself.
        self._generate_interaction_dots(self._source_atoms_sorted, source_atoms,
          self._spatialQuery, self._phantomHydrogensSpatialQuery, bondedNeighborLists)

        # Generate our report
        outString += self._report_single_interaction(groupLabel, "self", "1->1", "SelfIntersect",
            len(atomLists), modelIndex, bondedNeighborLists)

      elif self.params.approach == 'once':
        make_sub_header('Find single-direction intersection dots', out=self.logger)

        # Generate dots for the source atom set against the target atom set.
        self._generate_interaction_dots(self._source_atoms_sorted, target_atoms,
          self._spatialQuery, self._phantomHydrogensSpatialQuery, bondedNeighborLists)

        # Generate our report
        outString += self._report_single_interaction(groupLabel, "once", "1->2", "IntersectOnce",
            len(atomLists), modelIndex, bondedNeighborLists)

      elif self.params.approach == 'both':
        make_sub_header('Find both-directions intersection dots', out=self.logger)

        # @todo The code below here is similar to -once but is repeated twice and has different string values.
        # It is also somewhat re-ordered in terms of where the selection is printed.  This keeps us from
        # re-using _report_single_interaction() directly without generalizing it.

        # Preliminary information before running both intersections.
        if self.params.output.count_dots:
          if self.params.output.format != 'raw':
            outString += self._describe_run("program:","command:")
            outString += self._describe_selection_and_parameters(groupLabel, "once")
        else: # Not counting the dots
          if self.params.output.format == 'raw':
            pass
          elif self.params.output.format == 'kinemage':
            outString += self._describe_run("@caption"," command:")
            if self.params.output.add_group_line:
              outString += "@group {{{}}}\n".format(groupLabel)

        # =================== First direction ========================

        # Generate dots for the source atom set against the target atom set.
        self._generate_interaction_dots(self._source_atoms_sorted, target_atoms,
          self._spatialQuery, self._phantomHydrogensSpatialQuery, bondedNeighborLists)

        # Count the dots if we've been asked to do so.
        if self.params.output.count_dots:
          numSkinDots = self._count_skin_dots(self._source_atoms_sorted, bondedNeighborLists)
          nsel = len(self._source_atoms_sorted)
          if self.params.output.format == 'raw':
            outString += self._rawEnumerate("1->2", nsel, self.params.output.compute_scores, False, numSkinDots, groupLabel)
          else:
            outString += self._enumerate("1->2", nsel, self.params.output.compute_scores, False, numSkinDots)

        else: # Not counting the dots

          # Check for various output format types.
          # We're not implementing O format or XV format, but we still allow raw and oneline
          if self.params.output.format == 'raw':
            outString += self._writeRawOutput("1->2",groupLabel)

          elif self.params.output.format == 'oneline':
            # Acculumlate but do not report results
            outString += self._count_summary("IntersectBothWays 1->2", False)

          elif self.params.output.format == 'kinemage': # Kinemage format
            outString += self._writeOutput("1->2", groupLabel)
            if self.params.output.contact_summary:
              # Acculumlate but do not report results
              outString += self._count_summary("IntersectBothWays 1->2", False)

        # =================== Second direction ========================

        # Clear the results before running interactions the other direction.
        self._clear_results();

        # Generate dots for the target atom set against the source atom set.
        self._generate_interaction_dots(self._target_atoms_sorted, source_atoms,
          self._spatialQuery, self._phantomHydrogensSpatialQuery, bondedNeighborLists)

        # Count the dots if we've been asked to do so.
        if self.params.output.count_dots:
          numSkinDots = self._count_skin_dots(self._target_atoms_sorted, bondedNeighborLists)
          nsel = len(self._target_atoms_sorted)
          if self.params.output.format == 'raw':
            outString += self._rawEnumerate("2->1", nsel, self.params.output.compute_scores, False, numSkinDots, groupLabel)
          else:
            outString += self._enumerate("2->1", nsel, self.params.output.compute_scores, False, numSkinDots)

        else: # Not counting the dots

          # Check for various output format types.
          # We're not implementing O format or XV format, but we still allow raw and oneline
          if self.params.output.format == 'raw':
            outString += self._writeRawOutput("2->1",groupLabel)

          elif self.params.output.format == 'oneline':
            # Accumulate and report results
            outString += self._count_summary("IntersectBothWays 2->1", True)

          elif self.params.output.format == 'kinemage': # Kinemage format
            outString += self._writeOutput("2->1", groupLabel)
            if self.params.output.contact_summary:
              # Accumulate and report results
              outString += self._count_summary("IntersectBothWays 2->1", True)

          else:
            raise ValueError("Unrecognized output format: "+self.params.output.format+" (internal error)")

    # Write the output to the specified file.
    if self.params.output.write_files:
      self.data_manager._write_text("Text", outString, self.params.output.filename)

    # If we have a dump file specified, write the atom information into it.
    # We write it at the end because the extra atom info may have been adjusted
    # during the code that handles hydrogen adjustements.
    if self.params.output.write_files and self.params.output.dump_file_name is not None:
      atomDump = Helpers.writeAtomInfoToString(allAtoms, self._extraAtomInfo)
      with open(self.params.output.dump_file_name,"w") as df:
        df.write(atomDump)

    # Report profiling info if we've been asked to in the Phil parameters
    if self.params.profile:
      print('Profile results:')
      import pstats
      profile_params = {'sort_by': 'time', 'num_entries': 20}
      self._pr.disable()
      ps = pstats.Stats(self._pr).sort_stats(profile_params['sort_by'])
      ps.print_stats(profile_params['num_entries'])

    # Return the results object that has all of the dots and the output string.
    return self._results, outString

# ------------------------------------------------------------------------------

  #def get_results(self):
  #  return group_args(model = self.model)



 *******************************************************************************
