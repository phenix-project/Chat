

 *******************************************************************************
iotbx/command_line/__init__.py
"""Command-line tools for reading, writing and analyzing files.
"""
from __future__ import division


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/biomt_reconstruction.py
"""
  Apply BIOMT records of PDB or equivalent records of mmCIF.
"""

from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.pdb.biomt_reconstruction

import sys, os
import iotbx.pdb
import mmtbx.model

def run(args):
  """
  Apply BIOMT records of PDB or equivalent records of mmCIF.
  Example:
    phenix.pdb.biomt_reconstruction model.pdb
    phenix.pdb.biomt_reconstruction model.cif
  """
  if(len(args)==0 or "--help" in args or "-h" in args):
    print(run.__doc__)
    return
  file_name = args[0]
  pdb_inp = iotbx.pdb.input(file_name=file_name)
  m = mmtbx.model.manager(model_input = pdb_inp, expand_with_mtrix=False)
  m.expand_with_BIOMT_records()
  ofn = "%s_BIOMT_expanded" % (os.path.splitext(os.path.basename(file_name))[0])
  if m.input_model_format_cif():
    ofn += ".cif"
    text_to_write = m.model_as_mmcif()
  else:
    ofn += ".pdb"
    text_to_write = m.model_as_pdb()
  print("Writing result to %s file."%ofn)
  with open(ofn, 'w') as f:
    f.write(text_to_write)
if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/blast_pdb.py
""" Run a BLAST search on the NCBI's web servers."""
from __future__ import absolute_import, division, print_function

import libtbx.phil
from libtbx.utils import Sorry
import os
import sys

master_phil = libtbx.phil.parse("""
blast_pdb
  .caption = This program will run a BLAST search on the NCBI's web servers. \
    You may use any format sequence file, but only a single sequence may be \
    searched at a time.  (Please limit your use of this service, as it is a \
    shared public resource!)
  .short_caption = NCBI BLAST search of PDB
  .style = box auto_align caption_img:icons/custom/pdb_import.png
{
  file_name = None
    .type = path
    .style = bold input_file file_type:seq
  output_file = None
    .type = path
    .style = bold new_file
  blast_type = *blastp blastn
    .type = choice
    .caption = Protein_(blastp) Nucleotide_(blastn)
    .short_caption = Search type
  expect = 0.01
    .type = float
    .short_caption = E-value cutoff
}""")

def run(args=(), params=None, out=None):
  if (out is None):
    out = sys.stdout
  if (params is None):
    import iotbx.phil
    cmdline = iotbx.phil.process_command_line_with_files(
      args=args,
      master_phil=master_phil,
      seq_file_def="blast_pdb.file_name")
    params = cmdline.work.extract()
  validate_params(params)
  params = params.blast_pdb
  from iotbx.bioinformatics.structure import get_ncbi_pdb_blast, \
    summarize_blast_output
  from iotbx.file_reader import any_file
  seq_file = any_file(params.file_name,
    force_type="seq",
    raise_sorry_if_not_expected_format=True,
    raise_sorry_if_errors=True)
  seq_file.check_file_type("seq")
  seq_objects = seq_file.file_object
  if (len(seq_objects) == 0):
    raise Sorry("Empty sequence file!")
  elif (len(seq_objects) > 1):
    print("WARNING: multiple sequences provided; searching only the 1st", file=out)
  sequence = seq_objects[0].sequence
  if (len(sequence) == 0):
    raise Sorry("No data in sequence file.")
  elif (len(sequence) < 6):
    raise Sorry("Sequence must be at least six residues.")
  if (params.output_file is None):
    params.output_file = "blast.xml"
  blast_out = get_ncbi_pdb_blast(sequence,
    file_name=params.output_file,
    blast_type=params.blast_type,
    expect=params.expect)
  print("Wrote results to %s" % params.output_file, file=out)
  results = summarize_blast_output(blast_out)
  if (len(args) != 0) : # command-line mode
    print("", file=out)
    print("%d matching structures" % len(results), file=out)
    print("", file=out)
    print("ID    Chain     evalue  length  %ident    %pos  #structures", file=out)
    print("-" * 59, file=out)
    for result in results :
      result.show(out)
  if (len(results) > 0):
    return sequence, os.path.abspath(params.output_file)
  else :
    return sequence, None

def validate_params(params):
  if (params.blast_pdb.file_name is None):
    raise Sorry("A sequence file is required as input.")
  elif (not os.path.isfile(params.blast_pdb.file_name)):
    raise Sorry("%s is not a file." % params.blast_pdb.file_name)
  return True

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/build_phil_cache.py
"""Create master parameters from a Phil file"""
from __future__ import absolute_import, division, print_function

import libtbx.load_env
from libtbx import phil
from libtbx.utils import import_python_object
import os
import sys

def run(args):
  phil_path = args[-1]
  phil_inp = import_python_object(
    import_path=phil_path,
    error_prefix="",
    target_must_be="",
    where_str="").object
  if (isinstance(phil_inp, str)):
    phil_object = phil.parse(phil_inp)
  elif (hasattr(phil_inp, "__call__")):
    phil_object = phil_inp()
  else :
    assert isinstance(phil_inp, phil.scope)
    phil_object = phil_inp
  cache_dir = os.path.join(libtbx.env.build_path, "phil_cache")
  if (not os.path.isdir(cache_dir)):
    os.mkdir(cache_dir)
  full_path = os.path.join(cache_dir, phil_path)
  f = open("%s.phil" % full_path, "w")
  phil_object.show(out=f, attributes_level=3)
  f.close()
  print("Wrote master parameters to %s.phil" % full_path)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/cbf_read.py
"""Read a CBF file"""

from __future__ import absolute_import, division, print_function
import iotbx.cif
import iotbx.cif.validation
import libtbx.load_env
import sys, os
import six
op = os.path

def run(args):
  dic_path = libtbx.env.find_in_repositories(
    relative_path="cbflib/doc/cif_img_1.5.4_28Jul07.dic",
    test=op.isfile)
  if (dic_path is not None):
    cif_dic = iotbx.cif.validation.smart_load_dictionary(file_path=dic_path)
  else:
    cif_dic = None
  for file_name in args:
    raw = open(file_name, "rb").read()
    pattern = "--CIF-BINARY-FORMAT-SECTION--"
    i = raw.find(pattern)
    if (i >= 0):
      j = raw.rfind(pattern+"--")
    sliced = raw[:i] + "\n" + raw[j:]
    cif = iotbx.cif.fast_reader(input_string=sliced)
    model = cif.model()
    for k, v in six.iteritems(model):
      print(v["_array_data.data"])
    if (cif_dic is not None):
      model.validate(cif_dic)

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/cif.as_miller_arrays.py
"""Read a reflection file and get miller arrays and dump as pickle"""
from __future__ import absolute_import, division, print_function
import iotbx.cif
from libtbx import easy_pickle, smart_open
from libtbx.str_utils import show_string
import sys, os
op = os.path

def run(args):
  for f in args:
    try:
      file_object = smart_open.for_reading(file_name=f)
      miller_arrays = iotbx.cif.reader(file_object=file_object).as_miller_arrays()
    except KeyboardInterrupt:
      raise
    except Exception as e:
      print("Error extracting miller arrays from file: %s:" % (
        show_string(f)))
      print(" ", str(e))
      continue
    for miller_array in miller_arrays:
      miller_array.show_comprehensive_summary()
      print()
    r, _ = op.splitext(op.basename(f))
    easy_pickle.dump(file_name=r+'_miller_arrays.pickle', obj=miller_arrays)

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/cif.as_xray_structure.py
"""Read xray structure from mmCIF file and dump as pickle"""

from __future__ import absolute_import, division, print_function
from cctbx import xray
from libtbx import easy_pickle
from libtbx.str_utils import show_string
import sys, os
op = os.path

def run(args):
  for f in args:
    try:
      xray_structures = xray.structure.from_cif(file_path=f)
    except KeyboardInterrupt:
      raise
    except Exception as e:
      print("Error extracting xray structure from file: %s:" % (
        show_string(f)))
      print(" ", str(e))
      continue
    basename, _ = op.splitext(op.basename(f))
    for key, xs in xray_structures.items():
      xs.show_summary()
      r = basename
      if key != r:
        r += '_'+key
      easy_pickle.dump(file_name=r+'_xray_structure.pickle', obj=xs)

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/cif.validate.py
"""Validate an mmCIF file"""

from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME iotbx.cif.validate

import glob, os, sys
from six.moves import urllib
from six.moves import cStringIO as StringIO

from iotbx import cif
from iotbx.cif import validation
from iotbx.option_parser import option_parser
from libtbx.utils import time_log
import libtbx.load_env

def run(args, out=sys.stdout):
  if len(args) == 0: args = ["--help"]
  command_line = (option_parser(
                  usage="iotbx.cif.validate filepath|directory [options]")
                  .option(None, "--file_ext",
                          action="store",
                          default="cif")
                  .option(None, "--dic",
                          action="append",
                          dest="dictionaries")
                  .option(None, "--show_warnings",
                          action="store_true")
                  .option(None, "--show_timings",
                          action="store_true")
                  .option(None, "--strict",
                          action="store",
                          type="bool",
                          default="true")).process(args=args)
  if len(command_line.args) != 1:
    command_line.parser.show_help()
    return
  total_timer = time_log("total").start()
  filepath = command_line.args[0]
  if not os.path.isabs(filepath):
    abs_path = libtbx.env.find_in_repositories(relative_path=filepath)
    if abs_path is None:
      abs_path = libtbx.env.find_in_repositories(
        relative_path=filepath, test=os.path.isfile)
    if abs_path is not None: filepath = abs_path
  cif_dics = command_line.options.dictionaries
  if cif_dics is None:
    cif_dics = ["cif_core.dic"]
  cif_dic = validation.smart_load_dictionary(name=cif_dics[0])
  if len(cif_dics) > 1:
    [cif_dic.update(
      validation.smart_load_dictionary(name=d)) for d in cif_dics[1:]]
  show_warnings = command_line.options.show_warnings == True
  show_timings = command_line.options.show_timings == True
  strict = command_line.options.strict
  if os.path.isdir(filepath):
    file_ext = command_line.options.file_ext
    crawl(filepath, file_ext=file_ext,
          cif_dic=cif_dic, show_warnings=show_warnings,
          show_timings=show_timings, strict=strict)
  elif os.path.isfile(filepath):
    cm = cif.reader(file_path=filepath, strict=strict).model()
    cm.validate(cif_dic, show_warnings=show_warnings)
  else:
    try:
      file_object = urllib.request.urlopen(filepath)
    except urllib.error.URLError as e:
      pass
    else:
      cm = cif.reader(file_object=file_object, strict=strict).model()
      cm.validate(cif_dic, show_warnings=show_warnings)
  if show_timings:
    total_timer.stop()
    print(total_timer.report())

def crawl(directory, file_ext, cif_dic, show_warnings, show_timings, strict):
  timer = time_log("parsing")
  validate_timer = time_log("validate")
  for root, dirs, files in os.walk(directory):
    cif_g = glob.glob(os.path.join(root, "*.%s" %file_ext))
    files_to_read = cif_g
    for path in files_to_read:
      timer.start()
      try:
        cm = cif.reader(file_path=path, strict=strict).model()
      except AssertionError:
        continue
      timer.stop()
      s = StringIO()
      validate_timer.start()
      cm.validate(cif_dic, show_warnings=show_warnings, out=s)
      validate_timer.stop()
      if s.getvalue():
        print(path)
        print(s.getvalue())
  if show_timings:
    print(timer.legend)
    print(timer.report())
    print(validate_timer.report())

if __name__ == '__main__':
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/cif_as_pdb.py
"""Try to convert an mmCIF formatted model file to PDB format"""

from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.cif_as_pdb
# LIBTBX_SET_DISPATCHER_NAME iotbx.cif_as_pdb
import os
import iotbx.pdb
import iotbx.pdb.mmcif
import mmtbx.model


def check_args(args):
  #  Look for "force_pdb_format=True" in args and set force_pdb_format if so
  force_pdb_format = False
  for arg in args:
    if arg.lower() == "force_pdb_format=true":
       force_pdb_format = True
       args.remove(arg)
  return args, force_pdb_format

def run(args):
  args, force_pdb_format = check_args(args)
  for file_name in args:
    try:
      assert os.path.exists(file_name)
      print("Converting %s to PDB format." %file_name)
      cif_input = iotbx.pdb.mmcif.cif_input(file_name=file_name)
      m = mmtbx.model.manager(model_input=cif_input)
      basename = os.path.splitext(os.path.basename(file_name))[0]
      if (not m.can_be_output_as_pdb()):
        if not force_pdb_format:
           from libtbx.utils import Sorry
           raise Sorry(
             "The file %s cannot be converted to standard PDB format." %(
             file_name) + "\n\nUse 'force_pdb_format=True' to convert using"+
             " forward-compatible PDB \nwith 2-character chain IDs and " +
             "3-character residue names")
        else: # go ahead
          # Convert the hierarchy to forward_compatible:
          from iotbx.pdb.forward_compatible_pdb_cif_conversion import \
             hierarchy_as_forward_compatible_pdb_string
          pdb_text =  \
              hierarchy_as_forward_compatible_pdb_string(m.get_hierarchy())
          print(
           "\n***Warning: the file %s does not fit in standard PDB format." %(
           file_name) + \
           "\nConverting to forward_compatible PDB %s, with" %(
             basename+".pdb") +\
            "\n2-character chain ID and 3-character residue names.\n")
      else:
        pdb_text = m.model_as_pdb()
      print("Writing %s" % (basename+".pdb"))
      with open(basename+".pdb", 'w') as f:
        f.write(pdb_text)
    except Exception as e:
      print("Error converting %s to PDB format:" %file_name)
      print(" ", str(e))
      continue

if __name__ == '__main__':
  import sys
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/cns.reflection_reader.py
"""Read a CNS reflection file"""
from __future__ import absolute_import, division, print_function
from iotbx.cns import reflection_reader
import sys
if (__name__ == "__main__"):
  reflection_reader.run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/cns.sdb_reader.py
"""Read a CNS SDB file"""
from __future__ import absolute_import, division, print_function
from iotbx.cns import sdb_reader
import sys
if (__name__ == "__main__"):
  sdb_reader.run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/cns.transfer_crystal_symmetry.py
"""Transfer crystal symmetry to a cns file"""
from __future__ import absolute_import, division, print_function
from iotbx import cns
import iotbx.cns.space_group_symbols
from iotbx import crystal_symmetry_from_any
from libtbx.str_utils import show_string
from libtbx.utils import Sorry, Usage, plural_s, detect_binary_file
import sys, os
from six.moves import zip

def run(args):
  if (len(args) != 2):
    raise Usage("""\
iotbx.cns.transfer_crystal_symmetry any_symmetry_source_file cns_input_file
  *********************************************
  NOTE: the cns_input_file is changed in place.
  *********************************************""")
  #
  for file_name in args:
    if (not os.path.exists(file_name)):
      raise Sorry("No such file: %s" % show_string(file_name))
  source, target = args
  crystal_symmetry = crystal_symmetry_from_any.extract_from(source)
  if (crystal_symmetry is None):
    raise Sorry(
      "Unknown file format or unit cell and/or space group"
      " missing from file: " + show_string(source))
  cns_space_group_symbol = cns.space_group_symbols.cns_format(
    space_group_info=crystal_symmetry.space_group_info())
  if (cns_space_group_symbol is None):
    raise Sorry("Space group not available in CNS: %s" %
      show_string(str(crystal_symmetry.space_group_info())))
  sg = '"%s"' % cns_space_group_symbol
  a,b,c,alpha,beta,gamma = ["%.6g" % p
    for p in crystal_symmetry.unit_cell().parameters()]
  parameter_names = ["sg", "a", "b", "c", "alpha", "beta", "gamma"]
  parameters_found = dict(zip(parameter_names, [0]*len(parameter_names)))
  parameters_changed = []
  lines_out = []
  detect_binary = detect_binary_file(monitor_initial=100)
  try: cns_inp = open(target).read().splitlines()
  except IOError as e:
    raise Sorry("Error reading file %s (%s)" % (show_string(target), str(e)))
  end_block_parameter_definition = False
  for line in cns_inp:
    if (detect_binary is not None):
      is_binary = detect_binary.is_binary_file(block=line)
      if (is_binary is not None):
        if (is_binary):
          raise Sorry("%s appears to be a binary file." % show_string(target))
        detect_binary = None
    if (end_block_parameter_definition):
      lines_out.append(line)
    else:
      l = line.strip().replace(" ","")
      if (l == "){-endblockparameterdefinition-}"):
        lines_out.append(line)
        end_block_parameter_definition = True
      else:
        line_out = line
        for p in parameter_names:
          if (l.startswith("{===>}%s=" % p) and l.endswith(";")):
            parameters_found[p] += 1
            line_out = '{===>} %s=%s;' % (p, vars()[p])
            if (line_out != line): parameters_changed.append(p)
            break
        lines_out.append(line_out)
  if (list(parameters_found.values()).count(1) != 7):
    raise Sorry("Unexpected set of variable names in %s:\n  counts: %s" % (
      show_string(target), str(parameters_found)))
  elif (len(parameters_changed) == 0):
    print("Info: no changes, %s was not modified." % show_string(target))
  else:
    string_out = "\n".join(lines_out)
    print("Info: %d change%s" % plural_s(len(parameters_changed)), \
      "(%s)," % ", ".join(parameters_changed), \
      "writing modified file %s." % show_string(target))
    try: print(string_out, file=open(target, "w"))
    except IOError as e:
      raise Sorry("Error writing file %s (%s)" % (show_string(target), str(e)))

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/cns_as_mtz.py
"""Convert CNS to MTZ format"""
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.cns_as_mtz

import iotbx.cns.reflection_reader
from iotbx.option_parser import option_parser
import sys, os
from iotbx import mtz

def run(args, command_name="phenix.cns_as_mtz"):
  if (len(args) == 0): args = ["--help"]
  command_line = (option_parser(
    usage="%s [options] cns_file" % command_name,
    description="Example: %s scale.hkl" % command_name)
    .enable_symmetry_comprehensive()
    .option("-q", "--quiet",
      action="store_true",
      default=False,
      help="suppress output")
  ).process(args=args)
  if (len(command_line.args) != 1):
    command_line.parser.show_help()
    return
  cns_file_name = command_line.args[0]
  crystal_symmetry = command_line.symmetry
  if (crystal_symmetry.unit_cell() is None):
    print()
    print("*" * 79)
    print("Unknown unit cell parameters.")
    print("Use --symmetry or --unit_cell to define unit cell:")
    print("*" * 79)
    print()
    command_line.parser.show_help()
    return
  if (crystal_symmetry.space_group_info() is None):
    print()
    print("*" * 79)
    print("Unknown space group.")
    print("Use --symmetry or --space_group to define space group:")
    print("*" * 79)
    print()
    command_line.parser.show_help()
    return
  if (not command_line.options.quiet):
    print("CNS file name:", cns_file_name)
    print("Crystal symmetry:")
    crystal_symmetry.show_summary(prefix="  ")
  reflection_file = iotbx.cns.reflection_reader.cns_reflection_file(
    file_handle=open(cns_file_name, "r"))
  if (not command_line.options.quiet):
    reflection_file.show_summary()
  miller_arrays = reflection_file.as_miller_arrays(
                                             crystal_symmetry=crystal_symmetry)
  mtz_dataset = None
  for miller_array in miller_arrays:
    if (mtz_dataset is None):
      mtz_dataset = miller_array.as_mtz_dataset(
        column_root_label=miller_array.info().labels[0])
    else:
      mtz_dataset.add_miller_array(
        miller_array=miller_array,
        column_root_label=miller_array.info().labels[0])
  mtz_object = mtz_dataset.mtz_object()
  for column in mtz_object.columns():
    column_type = {
      "FOM": "W",
      "PHASE": "P"}.get(column.label())
    if (column_type is not None):
      column.set_type(new_type=column_type)
  mtz_object.show_summary()
  mtz_file_name = os.path.basename(cns_file_name)
  if (mtz_file_name.count(".") == 1):
     mtz_file_name = mtz_file_name[:mtz_file_name.index(".")]
  mtz_file_name += ".mtz"
  print("Writing MTZ file:", mtz_file_name)
  mtz_object.write(mtz_file_name)

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/crystal_symmetry_from_any.py
"""Extract crystal_symmetry from any suitable file"""
from __future__ import absolute_import, division, print_function
from iotbx import crystal_symmetry_from_any
from iotbx.pdb import format_cryst1_and_scale_records
from iotbx.cns.crystal_symmetry_utils import crystal_symmetry_as_cns_inp_defines
from iotbx import format
from libtbx.option_parser import option_parser
import libtbx.load_env
import sys

def run(args):
  if (len(args) == 0): args = ["--help"]
  command_line = (option_parser(
    usage="%s [OPTIONS] FILE..." % libtbx.env.dispatcher_name)
    .option(None, "--niggli_cell",
      action="store_true")
  ).process(args=args)
  if (len(command_line.args) == 0):
    command_line.parser.show_help()
    return
  co = command_line.options
  for arg in command_line.args:
    crystal_symmetry = crystal_symmetry_from_any.extract_from(arg)
    if (crystal_symmetry is None):
      raise RuntimeError("Unknown file format or unit cell and space group missing from file.")
    if (co.niggli_cell
          and crystal_symmetry.unit_cell() is not None
          and crystal_symmetry.space_group_info() is not None):
      crystal_symmetry = crystal_symmetry.niggli_cell()
    format.crystal_symmetry(crystal_symmetry)
    print()
    print("\n".join(
      crystal_symmetry_as_cns_inp_defines(crystal_symmetry=crystal_symmetry)))
    print()
    print(format_cryst1_and_scale_records(
      crystal_symmetry=crystal_symmetry,
      write_scale_records=True))
    print()

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/csv_as_mtz.py
"""Convert reflection_csv_file to mtz"""
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.csv_as_mtz

import sys, os
from cctbx import miller
from iotbx.option_parser import iotbx_option_parser
from iotbx.pdb import crystal_symmetry_from_pdb
from libtbx.utils import Sorry
from cctbx.array_family import flex

def run(args, command_name = "mmtbx.csv_to_mtz"):
  if (len(args) == 0): args = ["--help"]
  try:
    command_line = (iotbx_option_parser(
      usage="%s [reflection_csv_file] [options]" % command_name,
      description='Example: %s 1m5u-sf.csv --use_model=1m5u.pdb'%command_name)
      .enable_symmetry_comprehensive()
      .option(None, "--output_file",
        action="store",
        default=False,
        type="string",
        help="Output mtz file name.")
      .option(None, "--use_model",
        action="store",
        default=False,
        type="string",
        help="Use PDB model to make better guess about reflection data type.")
    ).process(args=args)
  except Exception as e:
    if(str(e) != "0"): print(str(e))
    sys.exit(0)
  crystal_symmetry = command_line.symmetry
  if(command_line.symmetry.unit_cell() is None or
     command_line.symmetry.space_group_info() is None):
    if(command_line.options.use_model):
      crystal_symmetry = crystal_symmetry_from_pdb.extract_from(
         file_name=command_line.options.use_model)
  if(crystal_symmetry.unit_cell() is None or
     crystal_symmetry.space_group_info() is None):
    raise Sorry(
      "Crystal symmetry is not defined. Please use the --symmetry option.\n"
      "Type %s without arguments to see more options."%command_name)
  if(len(command_line.args) > 1):
    print("%d arguments are given from the command line:"% \
      len(command_line.args), command_line.args)
    raise Sorry("Please specify one reflection csv file.")
  file_name = command_line.args[0]
  if(not os.path.isfile(file_name)):
    raise Sorry("File is not found: %s"%file_name)
  data = flex.double()
  sigmas = flex.double()
  flags = flex.int()
  column_ids, columns = parse_csv_file(file_name=file_name)
  data_label_root = column_ids[3]
  ms = miller.set(crystal_symmetry, flex.miller_index(columns[0]))
  for d in columns[1]:
    data.append(float(d))
  for sig in columns[2]:
    sigmas.append(float(sig))
  for flag in columns[3]:
    flags.append(int(flag))
  assert len(data) == len(sigmas)
  assert len(flags) == len(data)
  ma = miller.array(ms, data, sigmas)
  if data_label_root.startswith('F'):
    ma.set_observation_type_xray_amplitude()
  elif data_label_root.startswith('I'):
    ma.set_observation_type_xray_intensity()
  else:
    ma.set_observation_type_xray_amplitude()
  flags_ma = miller.set(
      crystal_symmetry = crystal_symmetry,
      indices          = ma.indices()).array(data = flags)
  mtz_dataset = ma.as_mtz_dataset(
    column_root_label = data_label_root)
  mtz_dataset.add_miller_array(
      miller_array      = flags_ma,
      column_root_label = "R-free-flags")
  mtz_object = mtz_dataset.mtz_object()
  mtz_object.write(file_name = command_line.options.output_file)

def parse_csv_file(file_name):
  f = open(file_name)
  column_ids = f.readline().strip().split(',')
  data = []
  for id in column_ids:
    data.append([])
  for line in f.readlines():
    temp = line.strip().split(',')
    for i, value in enumerate(temp):
      if i == 0:
        h = int(value)
      elif i == 1:
        k = int(value)
      elif i == 2:
        l = int(value)
      elif i == 3:
        hkl = (h, k, l)
        data[0].append(hkl)
        data[i-2].append(value)
      else:
        data[i-2].append(value)
  return column_ids, data


if(__name__ == "__main__"):
   run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/dano_as_amplitudes.py
"""Convert DANO values (F+ - F-) to pseudo-amplitudes"""
# TODO tests

from __future__ import absolute_import, division, print_function
from iotbx.reflection_file_utils import reflection_file_server
import iotbx.phil
from libtbx.utils import Sorry
import sys

master_phil_str = """
data = None
  .type = path
labels = None
  .type = strings
symmetry = None
  .type = path
mtz_out = dano_as_fobs.mtz
  .type = path
"""

def run(args):
  cmdline = iotbx.phil.process_command_line_with_files(
    args=args,
    master_phil_string=master_phil_str,
    reflection_file_def="data",
    pdb_file_def="symmetry")
  params = cmdline.work.extract()
  if (params.data is None):
    raise Sorry("Data file not defined")
  hkl_file = cmdline.get_file(params.data)
  crystal_symmetry = None
  if (params.symmetry is not None):
    from iotbx import crystal_symmetry_from_any
    crystal_symmetry = crystal_symmetry_from_any.extract_from(
      file_name=params.symmetry)
  hkl_server = reflection_file_server(
    crystal_symmetry=crystal_symmetry,
    force_symmetry=True,
    reflection_files=[hkl_file.file_object],
    err=sys.stderr)
  data = hkl_server.get_xray_data(
    file_name=params.data,
    labels=params.labels,
    ignore_all_zeros=True,
    parameter_scope="",
    minimum_score=4,
    prefer_anomalous=True)
  if (not data.anomalous_flag()):
    raise Sorry("Must provide anomalous data.")
  if data.is_xray_intensity_array():
    data = data.f_sq_as_f()
  dano = abs(data.anomalous_differences())
  dano.set_observation_type_xray_amplitude()
  dano.as_mtz_dataset(column_root_label="F").mtz_object().write(params.mtz_out)
  print("Wrote DANO to %s" % params.mtz_out)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/detector_image_as_png.py
"""Convert dectector image to png image"""
# LIBTBX_SET_DISPATCHER_NAME labelit.png

from __future__ import absolute_import, division, print_function
from libtbx.utils import Sorry, Usage
from six import BytesIO
import os
import sys

usage_message ="""\
labelit.png file_name [output_file] [bin=1|2]

  Convert an X-ray detector image to PNG format.

  Input file is a detector image (CBF, ADSC, MAR, etc.).  If the name of the
  output file is not specified, it will be identical to the image file but
  with the extension replaced by '.png'.

  bin argument: 1 ( default, same-sized png  as detector )
                2 ( bin detector pixels 2x2 for display )"""

def run(args):
  if (len(args) == 0) or (len(args) > 3) or "-large" in args or "help" in args:
    raise Usage(usage_message)
  graphics_bin = 1
  if len(args)==3 and args[2].find("bin=")==0 and args[2][4]=="2":
    graphics_bin = 2
  img_file = args[0]
  output_file = None
  if (len(args) >= 2):
    output_file = args[1]
  if (output_file is None):
    output_file = os.path.basename(os.path.splitext(img_file)[0]) + ".png"
  C = convert_image(img_file,graphics_bin)
  C.img.show_header()
  open(output_file, "wb").write(C.output().getvalue())
  print("Wrote %s" % output_file)

class convert_image:

 def __init__(self,file_name,graphics_bin=1):#, output_file=None):
  from rstbx.slip_viewer.slip_viewer_image_factory import SlipViewerImageFactory as ImageFactory
  from iotbx.detectors import ImageException
  try :
    from PIL import Image
  except ImportError :
    import Image
  try :
    img = ImageFactory(file_name)
  except ImageException as e :
    raise Sorry(str(e))
  img.read()
  self.img = img
  if (img.vendortype in ["Pilatus-6M","Pilatus-2M","Pilatus-300K"]):
    graphics_bin = 1
  flex_img = img.get_flex_image(binning=graphics_bin, brightness=1)
  flex_img.setWindow(0.0, 0.0, 1)
  flex_img.spot_convention(0)
  flex_img.adjust(color_scheme=0)
  flex_img.prep_string()
  data_string = flex_img.as_bytes()
  try: # fromstring raises Exception in Pillow >= 3.0.0
    self.imageout = Image.fromstring("RGB",
                         (flex_img.ex_size2(), flex_img.ex_size1()),
                         data_string)
  except Exception:
    self.imageout = Image.frombytes("RGB",
                         (flex_img.ex_size2(), flex_img.ex_size1()),
                         data_string)

 def output(self):
  out = BytesIO()
  self.imageout.save(out, "PNG")
  return out

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/distance_least_squares.py
""" Analyze non-bonded contacts in a model in strudat file
"""

from __future__ import absolute_import, division, print_function
def run(args, distance_cutoff=3.5):
  from iotbx.option_parser import option_parser
  command_line = (option_parser(
    usage="iotbx.distance_least_squares [options] studat_file [...]",
    description="Example: iotbx.distance_least_squares strudat --tag=SOD")
    .option(None, "--tag",
      action="store",
      type="string",
      help="tag as it appears in the strudat file")
    .option(None, "--repulsion_function",
      action="store",
      type="choice",
      choices=["gaussian", "cos", "prolsq"],
      default="gaussian",
      help="Nonbonded repulsion function type",
      metavar="gaussian|cos|prolsq")
    .option(None, "--bond_stretch_factor",
      action="store",
      type="float",
      default=0.1,
      help="Bond stretch factor used in max residual calculation"
           " for nonbonded cos or gaussian repulsion function",
      metavar="FLOAT")
    .option(None, "--n_trials",
      action="store",
      type="int",
      default=1,
      help="Number of trial per structure",
      metavar="INT")
    .option(None, "--n_macro_cycles",
      action="store",
      type="int",
      default=1,
      help="Number of macro cycles per trial",
      metavar="INT")
    .option(None, "--dev",
      action="store_true",
      default=False)
  ).process(args=args)
  if (len(command_line.args) == 0):
    command_line.parser.show_help()
    return
  co = command_line.options
  from cctbx.geometry_restraints import distance_least_squares as dls
  from iotbx.kriber import strudat
  for file_name in command_line.args:
    strudat_entries = strudat.read_all_entries(open(file_name))
    for entry in strudat_entries.entries:
      if (co.tag is not None and co.tag != entry.tag):
        continue
      print("strudat tag:", entry.tag)
      print()
      dls.distance_and_repulsion_least_squares(
        si_structure=entry.as_xray_structure(),
        distance_cutoff=distance_cutoff,
        nonbonded_repulsion_function_type=co.repulsion_function,
        nonbonded_max_residual_bond_stretch_factor=co.bond_stretch_factor,
        n_trials=co.n_trials,
        n_macro_cycles=co.n_macro_cycles,
        connectivities=entry.connectivities(all_or_nothing=True),
        dev=co.dev)

if (__name__ == "__main__"):
  import sys
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/dtrek.to_cns.py
"""Convert DTREK to CNS format"""
from __future__ import absolute_import, division, print_function
def iobs_as_fobs(iobs, isigma):
  import math
  if (iobs >= 0):
    fobs = math.sqrt(iobs)
    if (isigma < iobs):
      fsigma = fobs - math.sqrt(iobs - isigma)
    else:
      fsigma = fobs
  else:
    fobs = 0
    fsigma = 0
  return fobs, fsigma

def dtrek_as_cns_hkl(file_object, file_name=None):
  info = []
  reflections = []
  mode = 0
  for line in file_object:
    if (line == ""): break
    if (mode == 0):
      if (line.startswith("CRYSTAL_")):
        info.append(line[:-1])
      if (not line.startswith(" ")): continue
      mode = 1
    flds = line.split()
    iobs = float(flds[3])
    isigma = float(flds[4])
    if (iobs < 0 or isigma < 0): continue
    fobs, sigma = iobs_as_fobs(iobs, isigma)
    reflections.append("INDEX %s %s %s FOBS %.6g SIGMA %.6g" % (
      flds[0], flds[1], flds[2], fobs, sigma))
  if (file_name): print("{ file:", file_name, "}")
  for line in info: print("{", line, "}")
  print("NREFlections=%d" % (len(reflections),))
  print("ANOMalous=FALSe")
  print("DECLare NAME=FOBS  DOMAin=RECIprocal TYPE=REAL END")
  print("DECLare NAME=SIGMA DOMAin=RECIprocal TYPE=REAL END")
  for line in reflections: print(line)

if (__name__ == "__main__"):
  import sys, os.path
  if (len(sys.argv) == 1):
    dtrek_as_cns_hkl(sys.stdin)
  elif (len(sys.argv) == 2):
    f = open(sys.argv[1], "r")
    dtrek_as_cns_hkl(f, os.path.abspath(sys.argv[1]))
    f.close()
  else:
    raise RuntimeError(
      "usage: %s [d*trek_file_name]" % (os.path.basename(sys.argv[0]),))


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/effective_resolution.py
"""Calculate effective resolution of a reflection file"""

from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.resolution

from iotbx import reflection_file_reader
from cctbx import maptbx
from cctbx.array_family import flex
from libtbx.utils import Sorry
import sys, math, time
from scitbx import regular_grid_on_unit_sphere
import six
from six.moves import range

def one_d_image_along_axis(n, step, uc_length):
  rho  = flex.double()
  dist = flex.double()
  r = 0
  while r < uc_length/2:
    rho_ = 0
    for n_key, n_value in six.iteritems(n):
      rho_ += n_value*math.cos(2*math.pi*r*n_key/uc_length)
    dist.append(r)
    rho.append(rho_)
    r+=step
  return dist, rho

def second_derivatives(rho, delta):
  rho_2nd = flex.double()
  for i in range(rho.size()):
    if(i>=1 and i<rho.size()-1): tau = (rho[i+1]+rho[i-1]-2*rho[i])/delta**2
    elif(i==0):                  tau = (rho[i+1]+rho[i+1]-2*rho[i])/delta**2
    else:                        tau = (rho[i+0]+rho[i-1]-2*rho[i])/delta**2
    rho_2nd.append(tau)
  result = flex.double()
  for i in range(rho_2nd.size()):
    rho_ave = 0
    span = [-2,-1,0,1,2]
    #span = [-5,-4,-3,-2,-1,0,1,2, 3,4,5]
    for j in span:
      ij = i+j
      if(ij<0):               ij=0
      if(ij>=rho_2nd.size()): ij=rho_2nd.size()-1
      rho_ave += rho_2nd[ij]
    rho_ave = rho_ave/len(span)
    result.append(rho_ave)
  return result

def compute_d_eff(r, rho_2nd):
  v0 = rho_2nd[0]
  for i in range(rho_2nd.size()):
    if(v0*rho_2nd[i]<0):
      return r[i]*2.5 # formulas (9)-(10)
  return None

def compute(miller_array, step_scale=0.0005):
  miller_array.show_comprehensive_summary(prefix="  ")
  step = miller_array.d_min()*step_scale
  #
  ma_p1 = miller_array.expand_to_p1()
  #
  n_h = {}
  n_k = {}
  n_l = {}
  indices = ma_p1.indices()
  for ind in indices:
    h,k,l = ind
    n_h.setdefault(h, flex.int()).append(1)
    n_k.setdefault(k, flex.int()).append(1)
    n_l.setdefault(l, flex.int()).append(1)
  def count(d):
    for k in d.keys():
      d[k] = d[k].size()
    return d
  n_h = count(n_h)
  n_k = count(n_k)
  n_l = count(n_l)
  # resolutions along axes
  a,b,c = miller_array.unit_cell().parameters()[:3]
  x, rho_x = one_d_image_along_axis(n=n_h, step=step, uc_length=a)
  y, rho_y = one_d_image_along_axis(n=n_k, step=step, uc_length=b)
  z, rho_z = one_d_image_along_axis(n=n_l, step=step, uc_length=c)
  # 2nd derivatives
  r2x = second_derivatives(rho=rho_x, delta=step)
  r2y = second_derivatives(rho=rho_y, delta=step)
  r2z = second_derivatives(rho=rho_z, delta=step)
  # effective resolution along axes
  d_eff_a = compute_d_eff(r=x, rho_2nd=r2x)
  d_eff_b = compute_d_eff(r=y, rho_2nd=r2y)
  d_eff_c = compute_d_eff(r=z, rho_2nd=r2z)
  print("  Effective resolution along axes a,b,c: %6.3f %6.3f %6.3f"%(
    d_eff_a, d_eff_b, d_eff_c))
  # all directions
  l = 0.8 * min(d_eff_a/2.5, d_eff_b/2.5, d_eff_c/2.5)
  r = 1.2 * max(d_eff_a/2.5, d_eff_b/2.5, d_eff_c/2.5)
  us = regular_grid_on_unit_sphere.rosca(m=9, hemisphere=True)
  d_effs = flex.double()
  o = maptbx.ft_analytical_1d_point_scatterer_at_origin(N=100000)
  for i, u in enumerate(us):
    o.compute(
      miller_indices=indices,
      step=step,
      left=l,
      right=r,
      u_frac=miller_array.unit_cell().fractionalize(u))
    dist, rho_ = o.distances(), o.rho()
    rho2 = second_derivatives(rho=rho_, delta=step)
    d_eff = compute_d_eff(r=dist, rho_2nd=rho2)
    d_effs.append(d_eff)
  print("  Effective resolution (min,max): %8.3f%8.3f"%(
    flex.min(d_effs), flex.max(d_effs)))

def run(args):
  if(len(args)!=1):
    raise Sorry("Reflection file expected.")
  reflection_file = reflection_file_reader.any_reflection_file(
    file_name = args[0])
  miller_arrays = reflection_file.as_miller_arrays(
    force_symmetry=True,
    merge_equivalents=False)
  if(miller_arrays is None):
    raise Sorry("Warning: unknown file format:", file_name)
  for ma in miller_arrays:
    if(type(ma.data()) == type(flex.double())):
      print("Processing data array with labels:", ma.info().label_string())
      compute(miller_array=ma)
      print()

if (__name__ == "__main__"):
  t0 = time.time()
  run(args=sys.argv[1:])
  print("Time: %8.3f"%(time.time()-t0))


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/emma.py
"""Match atoms in two models, allowing for origin shifts
and crystallographic relationships"""
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.emma
# LIBTBX_SET_DISPATCHER_NAME iotbx.emma

from iotbx import crystal_symmetry_from_any
import iotbx.pdb
from iotbx.cns import sdb_reader
from iotbx.kriber import strudat
from iotbx.option_parser import option_parser
from cctbx import euclidean_model_matching as emma
import sys, os
import cctbx.xray
from six.moves import zip

class MultipleEntriesError(RuntimeError): pass

def get_emma_model_from_pdb(file_name=None,
                            pdb_records=None,
                            crystal_symmetry=None):
  assert [file_name, pdb_records].count(None) == 1
  if (pdb_records is None):
    pdb_inp = iotbx.pdb.input(file_name=file_name)
  else:
    pdb_inp = iotbx.pdb.input(source_info=None, lines=pdb_records)
  crystal_symmetry = pdb_inp.crystal_symmetry(
    crystal_symmetry=crystal_symmetry,
    weak_symmetry=True)
  if (not crystal_symmetry or crystal_symmetry.unit_cell() is None):
    raise RuntimeError("Unit cell parameters unknown for model %s." %(
        file_name))
  if (crystal_symmetry.space_group_info() is None):
    raise RuntimeError("Space group unknown.")
  positions = []
  for atom in pdb_inp.atoms_with_labels():
    positions.append(emma.position(
      ":".join([str(len(positions)+1),
                atom.name, atom.resname, atom.chain_id]),
      crystal_symmetry.unit_cell().fractionalize(atom.xyz)))
  assert len(positions) > 0
  result = emma.model(
    crystal_symmetry.special_position_settings(),
    positions)
  if (file_name is not None):
    result.label = file_name
  return result

def get_emma_model_from_sdb(file_name, crystal_symmetry):
  sdb_files = sdb_reader.multi_sdb_parser(open(file_name))
  if (len(sdb_files) > 1):
    raise MultipleEntriesError(
      "SDB file %s may contain only one structure." % file_name)
  assert len(sdb_files) == 1
  sdb_file = sdb_files[0]
  crystal_symmetry = crystal_symmetry.join_symmetry(
    other_symmetry=sdb_file.crystal_symmetry(),
    force=True)
  positions = []
  for i,site in enumerate(sdb_file.sites):
    if (crystal_symmetry.unit_cell() is None):
      raise RuntimeError("Unit cell parameters unknown.")
    positions.append(emma.position(
      ":".join((str(i+1), site.segid, site.type)),
      crystal_symmetry.unit_cell().fractionalize((site.x, site.y, site.z))))
  assert len(positions) > 0
  result = emma.model(
    crystal_symmetry.special_position_settings(),
    positions)
  result.label = sdb_file.file_name
  return result

def get_emma_model_from_solve(file_name, crystal_symmetry):
  positions = []
  for line in open(file_name):
    flds = line.split()
    if (len(flds) < 4 or flds[0].lower() != "xyz"): continue
    site = [float(x) for x in flds[1:4]]
    positions.append(emma.position("site"+str(len(positions)+1), site))
  assert len(positions) > 0
  result = emma.model(
    crystal_symmetry.special_position_settings(),
    positions)
  result.label = file_name
  return result

def get_emma_model_from_ins(file_name):
  return cctbx.xray.structure.from_shelx(file=open(file_name)).as_emma_model()

def get_emma_model_from_strudat(file_name):
  strudat_entries = strudat.read_all_entries(open(file_name))
  if (len(strudat_entries.entries) > 1):
    raise MultipleEntriesError(
      "strudat file %s may contain only one structure." % file_name)
  assert len(strudat_entries.entries) == 1
  return strudat_entries.entries[0].as_xray_structure().as_emma_model()

def get_emma_model(file_name, crystal_symmetry):
  if (not os.path.isfile(file_name)):
    raise RuntimeError("File not found: %s" % file_name)
  try:
    return get_emma_model_from_pdb(
      file_name=file_name,
      crystal_symmetry=crystal_symmetry)
  except KeyboardInterrupt: raise
  except Exception:
    if (iotbx.pdb.is_pdb_file(file_name)): raise
  try:
    return get_emma_model_from_sdb(
      file_name=file_name,
      crystal_symmetry=crystal_symmetry)
  except MultipleEntriesError:
    raise
  except KeyboardInterrupt: raise
  except Exception:
    pass
  try:
    return get_emma_model_from_solve(
      file_name=file_name,
      crystal_symmetry=crystal_symmetry)
  except KeyboardInterrupt: raise
  except Exception:
    pass
  try:
    return get_emma_model_from_ins(file_name=file_name)
  except KeyboardInterrupt: raise
  except Exception:
    pass
  try:
    return get_emma_model_from_strudat(file_name=file_name)
  except MultipleEntriesError:
    raise
  except KeyboardInterrupt: raise
  except Exception:
    pass
  raise RuntimeError("Coordinate file %s: unknown format." % file_name)

def run(args, command_name="phenix.emma"):
  command_line = (option_parser(
    usage=command_name + " [options]"
         +" reference_coordinates other_coordinates",
    description="Example: %s model1.pdb model2.sdb" % command_name)
    .enable_symmetry_comprehensive()
    .option(None, "--output_pdb",
      action="store",
      type="str",
      default="",
      help="Output pdb: second model transformed to best match first model",
      metavar="STR")
    .option(None, "--tolerance",
      action="store",
      type="float",
      default=3.,
      help="match tolerance",
      metavar="FLOAT")
    .option(None, "--diffraction_index_equivalent",
      action="store_true",
      help="Use only if models are diffraction-index equivalent.")
  ).process(args=args, nargs=2)
  crystal_symmetry = command_line.symmetry
  if (   crystal_symmetry.unit_cell() is None
      or crystal_symmetry.space_group_info() is None):
    for file_name in command_line.args:
      crystal_symmetry = crystal_symmetry.join_symmetry(
        other_symmetry=crystal_symmetry_from_any.extract_from(
          file_name=file_name),
        force=False)
  output_pdb = command_line.options.output_pdb
  if output_pdb:
    print("Output pdb:",output_pdb)
  tolerance = command_line.options.tolerance
  print("Tolerance:", tolerance)
  if (tolerance <= 0.):
    raise ValueError("Tolerance must be greater than zero.")
  print()
  diffraction_index_equivalent = \
    command_line.options.diffraction_index_equivalent
  if (diffraction_index_equivalent):
    print("Models are diffraction index equivalent.")
    print()
  second_model_as_pdb_inp=None
  emma_models = []
  for file_name in command_line.args:
    emma_models.append(get_emma_model(
      file_name=file_name,
      crystal_symmetry=crystal_symmetry))
    if len(emma_models)==2 and os.path.isfile(file_name):
      try:
        second_model_as_pdb_inp=iotbx.pdb.input(
           file_name=file_name)
      except Exception as e:
        pass
  emma_models[0].show("Reference model")
  emma_models[1].show("Other model")
  for model,label in zip(emma_models, ["reference", "other"]):
    if (model.unit_cell() is None):
      raise RuntimeError("Unit cell parameters unknown (%s model)." % label)
    if (model.space_group_info() is None):
      raise RuntimeError("Space group unknown (%s model)." % label)
  model_matches = emma.model_matches(
    model1=emma_models[0],
    model2=emma_models[1],
    tolerance=tolerance,
    models_are_diffraction_index_equivalent=diffraction_index_equivalent)
  if (model_matches.n_matches() == 0):
    print("No matches.")
    print()
  else:
    max_n_pairs = None
    first=True
    for match in model_matches.refined_matches:
      if (max_n_pairs is None or len(match.pairs) > max_n_pairs*0.2):
        print("." * 79)
        print()
        match.show()
        if first and output_pdb: # 2013-01-25 tt
          if second_model_as_pdb_inp:
            match.get_transformed_model2(output_pdb=output_pdb,
              template_pdb_inp=second_model_as_pdb_inp,
              f=sys.stdout)
          else:
            print("No output model as input model was not PDB")
        first=False
      if (max_n_pairs is None):
        max_n_pairs = len(match.pairs)

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/explore_metric_symmetry.py
"""Explore Metric Symmetry. A list of possible unit cells and spacegroups is
given for the given specified unit cell and spacegroup combination. If a
second unit cell is given, linear combinations of the basis vector of one
unit cell are sought that match the other."""

from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.explore_metric_symmetry

from cctbx import sgtbx
from cctbx.sgtbx import pointgroup_tools as pgt
from cctbx.sgtbx import sub_lattice_tools as slt
from cctbx import crystal
from iotbx.option_parser import option_parser
from libtbx import easy_run
from libtbx.utils import Sorry, multi_out
from libtbx.str_utils import show_string
import libtbx.path
from six.moves import cStringIO as StringIO

import sys
from six.moves import zip

def do_pointgroup_tricks(input_uc,
                         input_ls,
                         max_delta,
                         out=None):
  if out is None:
    out = sys.stdout

  sg_explorer = pgt.space_group_graph_from_cell_and_sg(
      input_uc,
      input_ls,
      max_delta)


  print("A summary of the constructed point group graph object is given below", file=out)
  print("====================================================================", file=out)
  print(file=out)
  print("----------------------", file=out)
  print("Input crystal symmetry", file=out)
  print("----------------------", file=out)
  print("Unit cell: ", input_uc.parameters(), file=out)
  print("Unit cell volume: ", input_uc.volume(), file=out)
  print("Space group: ", sgtbx.space_group_info( group=input_ls ), file=out)
  print(file=out)
  print(file=out)
  print("--------------------------", file=out)
  print("Lattice symmetry deduction", file=out)
  print("--------------------------", file=out)
  print("Niggli cell: ", sg_explorer.xs_prim_set.unit_cell().parameters(), file=out)
  print("Niggli cell volume: ", sg_explorer.xs_prim_set.unit_cell().volume(), file=out)
  print("Niggli transformed input symmetry: ", sg_explorer.xs_prim_set.space_group_info(), file=out)
  print("Symmetry of Niggli cell: ", sgtbx.space_group_info( group = sg_explorer.pg_high ), file=out)
  print(file=out)
  print(file=out)
  print("All pointgroups that are both a subgroup of the lattice symmetry and", file=out)
  print("a supergroup of the Niggli transformed input symmetry wil now be listed,", file=out)
  print("as well as their minimal supergroups/maximal subgroups and symmetry", file=out)
  print("operators that generate them.", file=out)
  print("For each pointgroup, a list of compatible spacegroups will be listed.", file=out)
  print("Care is taken that there are no systematic absence violation with the ", file=out)
  print("provided input spacegroup.", file=out)
  print(file=out)
  out.flush()

  sg_explorer.show(out=out)

  # return the object
  return sg_explorer




def make_graph_of_graph(pg_object,
                        file_name,
                        out=None):
  if out is None:
    out = sys.stdout

  dot_path = libtbx.path.full_command_path(command="dot")
  if (dot_path is None):
    raise Sorry("""\
The program "dot" is not on PATH:
  For information about "dot" visit: http://www.graphviz.org/""")

  buffer = StringIO()
  pg_object.graphviz_pg_graph(out=buffer)
  command = "%s -Tpng > %s" % (show_string(dot_path), show_string(file_name))
  # XXX warning - Fontconfig error messages cause raise_if_errors_or_output()
  # to crash even if 'dot' ran successfully.
  rc = easy_run.fully_buffered(
    command=command,
    stdin_lines=buffer.getvalue().splitlines())#.raise_if_errors_or_output()
  if (rc.return_code != 0):
    raise RuntimeError("Fatal error running %s:\n%s" % (dot_path,
      "\n".join(rc.stderr_lines)))
  print("A file named", show_string(file_name), \
    "contains a graphical representation ", file=out)
  print("of the point group relations.", file=out)


def run(args, command_name="phenix.explore_metric_symmetry"):
  command_line = (
    option_parser(
    usage=command_name+" [options]",
    description="""\
Explore Metric Symmetry. A list of possible unit cells and spacegroups is
given for the given specified unit cell and spacegroup combination. If a
second unit cell is given, linear combinations of the basis vector of one
unit cell are sought that match the other.""")

    .enable_symmetry_comprehensive()

    .option(None, "--max_delta",
            action = "store",
            type="float",
            default=5.0,
            dest = "max_delta",
            help = "Maximum delta/obliquity used in determining the lattice symmetry, using a modified Le-Page algorithm. Default is 5.0 degrees",
            metavar="FLOAT")

    .option(None, "--start_from_p1",
            action="store_true",
            dest="niggli",
            default=False,
            help="Reduce to Niggli cell and forget the input spacegroup before higher metric symmetry is sought.")

    .option(None, "--graph",
            action="store",
            default=None,
            help="A graphical representation of the graph will be written out."
                 " Requires Graphviz to be installed and on PATH.")

    .option(None, "--centring_type",
            action="store",
            type="str",
            help="Centring type, choose from P,A,B,C,I,R,F")

    .option(None, "--other_unit_cell",
            action="store",
            type="str",
            help="Other unit cell, for unit cell comparison",
            metavar="10,20,30,90,103.7,90")

    .option(None, "--other_space_group",
            action="store",
            type="str",
            help="space group for other_unit_cell, for unit cell comparison")

    .option(None, "--other_centring_type",
            action="store",
            type="str",
            help="Centring type, choose from P,A,B,C,I,R,F")

    .option(None, "--no_point_group_graph",
            action="store_true",
            dest="pg_graph",
            default=False,
            help="Do not carry out the construction of a point group graph." )

    .option(None, "--relative_length_tolerance",
            action="store",
            type="float",
            help="Tolerance for unit cell lengths to be considered equal-ish.",
            default=0.10,
            metavar="FLOAT",
            dest="rel_length_tol")

    .option(None, "--absolute_angle_tolerance",
            action="store",
            dest="abs_angle_tol",
            type="float",
            default=10.0,
            metavar="FLOAT",
            help="Angular tolerance in unit cell comparison")

     .option(None, "--max_order",
             action="store",
             type="int",
             default=1,
             metavar="INT",
             help="Maximum volume change for target cell" )
    ).process(args=args)

  log = multi_out()
  log.register(label="stdout", file_object=sys.stdout)

  allowed_centring_types={"P":"Primitive",
                          "A":"A centered",
                          "B":"B centered",
                          "C":"C centered",
                          "I":"Body centered",
                          "R":"Rombohedral",
                          "F":"Face centered"}
  if command_line.options.centring_type is not None:
    if command_line.options.centring_type not in allowed_centring_types:
      print("Sorry, the centring type %s is not known."%(command_line.options.centring_type), file=log)
      print("Choose from P,A,B,C,I,R,F ", file=log)
      return

  xs = None
  other_xs = None

  if len(args)==0:
    command_line.parser.show_help()
    return

  if ( command_line.symmetry.unit_cell() == None ):
    print(file=log)
    print("Sorry: Unit cell not specified.", file=log)
    print(file=log)
    command_line.parser.show_help()
    return

  if command_line.options.centring_type is None:
    if ( command_line.symmetry.space_group_info() == None ):
      print(file=log)
      print("Sorry: centring type or space group not specified.", file=log)
      print(file=log)
      command_line.parser.show_help()
      return
  if command_line.symmetry.space_group_info()  is not None:
    if not ( command_line.symmetry.space_group().is_chiral() ):
      print("Sorry, Non chiral space groups not yet supported.", file=log)
      return

  if command_line.options.centring_type is not None:
    xs  = crystal.symmetry(
      unit_cell=command_line.symmetry.unit_cell(),
      space_group_symbol="Hall: %s 1" %( command_line.options.centring_type )
      )
    command_line.symmetry = xs

  if command_line.options.niggli:
    print("*Unit cell will be niggli reduced and P1 will be assumed*", file=log)
    uc = command_line.symmetry.change_basis(
      command_line.symmetry.change_of_basis_op_to_niggli_cell() ).unit_cell()
    command_line.symmetry = crystal.symmetry( uc, "P 1" )

  xs = command_line.symmetry

  ############################################################################
  # ABOVE IS JUST INPUT PARSING, NOW THE ACTUAL STUFF HAPPENS
  ############################################################################


  if not command_line.options.pg_graph:
    ##############################
    #   get a point group graph  #
    ##############################

    pg_object = do_pointgroup_tricks( xs.unit_cell(),
                                      xs.space_group(),
                                      command_line.options.max_delta,
                                      log )

    ################################################
    #  make a graphical representation if desired  #
    ################################################

    if command_line.options.graph is not None:
      make_graph_of_graph(pg_object,
                          command_line.options.graph,
                          log)


  #########################################
  #  Check if other cell has been defined #
  #########################################

  if command_line.options.other_unit_cell is not None:
    print("A second unit cell has been specified. ", file=log)
    other_xs = None

    if command_line.options.other_space_group is None:
      if command_line.options.other_centring_type is None:
        raise Sorry("No space group or centring type for other cell specified.")
      else:
        other_xs = crystal.symmetry( command_line.options.other_unit_cell,
                                     space_group_symbol="Hall: %s 1" %( command_line.options.other_centring_type )
                                   )
    else:
      other_xs = crystal.symmetry( command_line.options.other_unit_cell,
                                   space_group_symbol=command_line.options.other_space_group
                                 )

    # get the graph is desired
    if not command_line.options.pg_graph:
      other_pg_object = do_pointgroup_tricks( other_xs.unit_cell(),
                                              other_xs.space_group(),
                                              command_line.options.max_delta,
                                              log )
    # do the unit cell comparison
    print(file=log)
    print(file=log)
    print("Unit cell comparison", file=log)
    print("--------------------", file=log)
    print(file=log)
    print("The unit cells will be compared. The smallest niggli cell,", file=log)
    print("will be used as a (semi-flexible) lego-block to see if it", file=log)
    print("can construct the larger Niggli cell.", file=log)
    print(file=log)
    print(file=log)

    order = command_line.options.max_order

    if order==1:
      sl_object =  slt.compare_lattice(xs_a=xs,
                                       xs_b=other_xs,
                                       max_delta=command_line.options.max_delta,
                                       out=log,
                                       relative_length_tolerance=command_line.options.rel_length_tol,
                                       absolute_angle_tolerance=command_line.options.abs_angle_tol)
    else:

      tmp_a = xs.change_basis( xs.change_of_basis_op_to_niggli_cell() )
      tmp_b = other_xs.change_basis( other_xs.change_of_basis_op_to_niggli_cell() )
      modified_xs = None
      order = command_line.options.max_order
      lego_block = None
      if ( tmp_a.unit_cell().volume() > tmp_b.unit_cell().volume() ):
        modified_xs = slt.make_list_of_target_xs_up_to_order( xs, order )
        lego_block = other_xs
      else:
        modified_xs = slt.make_list_of_target_xs_up_to_order( other_xs, order )
        lego_block = xs

      print(file=log)
      print("Volume change of largest niggli cell requested via keyword --max_order", file=log)
      print(file=log)
      print("Input crystal symmetry is tranformed to niggli setting using the operator:", file=log)
      print(modified_xs.basic_to_niggli_cb_op.as_xyz(), file=log)
      print(file=log)
      print("Comparisons for various sublattices of the target cell are listed", file=log)
      print(file=log)

      for tmp_xs,cb_op,mat in zip(modified_xs.xs_list,
                                  modified_xs.extra_cb_op,
                                  modified_xs.matrices ):
        mat=mat.as_list_of_lists()
        print("===================================================================", file=log)
        print("Niggli cell is expanded using matrix:", file=log)
        print(file=log)
        print(r"               /%4i %4i %4i  \  "%(mat[0][0],mat[0][1],mat[0][2]), file=log)
        print("          M =  |%4i %4i %4i  |  "%(mat[1][0],mat[1][1],mat[1][2]), file=log)
        print(r"               \%4i %4i %4i  /  "%(mat[2][0],mat[2][1],mat[2][2]), file=log)
        print(file=log)
        print("Change of basis operator to reference setting:", file=log)
        print("    ", cb_op.as_xyz(), file=log)
        print("resulting crystal symmetry:", file=log)
        tmp_xs.show_summary(f=log,prefix="   ")
        print(file=log)
        print(file=log)
        sl_object =  slt.compare_lattice(xs_a=tmp_xs,
                                         xs_b=lego_block,
                                         max_delta=command_line.options.max_delta,
                                         out=log,
                                         relative_length_tolerance=command_line.options.rel_length_tol,
                                         absolute_angle_tolerance=command_line.options.abs_angle_tol)


if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/export_scalepack_unmerged.py
""" Export reflection file as scalepack unmerged"""
from __future__ import absolute_import, division, print_function
from libtbx.utils import Sorry
from libtbx import Auto
import os.path
import sys

master_phil_str = """
file_name = None
  .type = path
data_labels = None
  .type = str
space_group = None
  .type = space_group
ignore_merged = False
  .type = bool
batch_label = None
  .type = str
ignore_batch = False
  .type = bool
output {
  prefix = None
    .type = str
}
"""

def run(args, out=sys.stdout):
  import iotbx.phil
  cmdline = iotbx.phil.process_command_line_with_files(
    args=args,
    master_phil_string=master_phil_str,
    reflection_file_def="file_name",
    space_group_def="space_group")
  params = cmdline.work.extract()
  validate_params(params)
  hkl_in = cmdline.get_file(params.file_name)
  miller_arrays = hkl_in.file_object.as_miller_arrays(
    merge_equivalents=False)
  batch_numbers = None
  if (hkl_in.file_object.file_type() == "scalepack_no_merge_original_index"):
    if (not params.ignore_batch):
      batch_numbers = hkl_in.file_object.file_content().batch_numbers
  outputs = []
  for array in miller_arrays :
    labels = array.info().label_string()
    if (array.space_group() is None):
      if (params.space_group is None):
        raise Sorry("Space group needs to be explicitly specified.")
      else :
        array = array.customized_copy(
          space_group_info=params.space_group).set_info(array.info())
    elif (params.space_group is None):
      params.space_group = array.space_group_info()
    if (array.is_xray_intensity_array() and
        not array.is_unique_set_under_symmetry()):
      if (params.data_labels is None) or (labels == params.data_labels):
        outputs.append(array)
    elif (array.is_integer_array() and batch_numbers is None):
      if (not params.ignore_batch) and (params.batch_label is not None):
        if (labels == params.batch_label):
          batch_numbers = array
        elif (params.batch_label is Auto and
              "BATCH" in array.info().labels_string()):
          batch_numbers = array
  if (len(outputs) == 0):
    raise Sorry("No unmerged intensities found.")
  elif (params.space_group is None):
    raise Sorry("Space group needs to be explicitly specified.")
  for i_obs in outputs :
    print("Using intensities in %s" % i_obs.info().label_string(), file=out)
  if (batch_numbers is not None):
    if (type(batch_numbers).__name__ == "array"):
      print("Batch numbers will be taken from %s" % \
        batch_numbers.info().label_string(), file=out)
    else :
      print("Batch numbers taken from raw input file", file=out)
  if (params.output.prefix is None):
    params.output.prefix = os.path.splitext(
      os.path.basename(params.file_name))[0]
  output_file_names = []
  for i_obs in outputs :
    labels = i_obs.info().labels
    wavelength_id = None
    crystal_id = None
    for label in labels :
      if label.startswith("wavelength_id="):
        label2, w_id_str = label.split("=")
        wavelength_id = int(w_id_str)
      if label.startswith("crystal_id="):
        label2, c_id_str = label.split("=")
        crystal_id = int(c_id_str)
    file_base = params.output.prefix
    if (crystal_id is not None):
      file_base += "_c%d" % crystal_id
    if (wavelength_id is not None):
      file_base += "_w%d" % wavelength_id
    file_name = file_base + "_unmerged.sca"
    n = 1
    while file_name in output_file_names :
      file_name = file_base + "-" + str(n) + "_unmerged.sca"
      n += 1
    output_file_names.append(file_name)
    if (i_obs.space_group() is None):
      i_obs = i_obs.customized_copy(space_group_info=params.space_group)
    tmp_batch_numbers = batch_numbers
    if (batch_numbers is not None):
      mismatch = False
      if (type(batch_numbers).__name__ != "array"):
        if (len(batch_numbers) != len(i_obs.indices())):
          mismatch = True
      elif (batch_numbers.indices().all_eq(i_obs.indices())):
        mismatch = True
      if (mismatch):
        msg = ("The h,k,l indices for the batch number array (%s) " +
          "do not match the h,k,l indices for the intensity array %s.  ") % \
          (batch_numbers.info().label_string(),
           i_obs.info().label_string())
        if (not params.ignore_batch):
          raise Sorry(msg +
            "You can suppress this warning by specifying ignore_batch=True.")
        else :
          print(msg + "The batch numbers will not be output.", file=out)
          tmp_batch_numbers = None
    i_obs.export_as_scalepack_unmerged(
      file_name=file_name,
      batch_numbers=tmp_batch_numbers)
    print("Wrote %s" % file_name, file=out)
  return output_file_names

def validate_params(params):
  if (params.file_name is None):
    raise Sorry("Input file name not specified.")

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/file_reader.py
"""Read any file and check format"""

from __future__ import absolute_import, division, print_function

from iotbx import file_reader
import libtbx.phil
from libtbx.utils import Sorry, Usage
import re
import os
import sys

master_phil = libtbx.phil.parse("""
file_reader
  .short_caption = File format verification
  .caption = This utility will check the format of any file supported as \
    input by Phenix.  Since most of the input methods are designed to be \
    tolerant of errors, it does not provide detailed feedback about \
    parsing issues.
  .style = auto_align box caption_img:icons/crystal_project/32x32/mimetypes/txt.png
{
  file_name = None
    .type = path
    .style = bold
  force_type = *None %s
    .type = choice(multi=False)
    .caption = Any_format %s
}
""" % (" ".join(file_reader.standard_file_types),
       " ".join([ re.sub(" ", "_", file_reader.standard_file_descriptions[ft])
                  for ft in file_reader.standard_file_types ])))

def run(args=(), params=None, out=sys.stdout):
  if (len(args) == 0) and (params is None):
    raise Usage("""
iotbx.file_reader filename [force_type=None]

(where force_type can be optionally set to one of these keywords:
  %s)
""" % ",".join(iotbx.file_reader.standard_file_types))
  user_phil = []
  for arg in args :
    if (os.path.isfile(arg)):
      user_phil.append(libtbx.phil.parse(
        """file_reader.file_name='%s'""" % arg))
    else :
      if (arg.startswith("force_type")):
        arg = "file_reader." + arg
      try :
        user_phil.append(libtbx.phil.parse(arg))
      except RuntimeError as e :
        print(e)
        print("Unrecognized argument '%s'" % arg)
  params = master_phil.fetch(sources=user_phil).extract()
  validate_params(params)
  f = file_reader.any_file(
    file_name=params.file_reader.file_name,
    valid_types=file_reader.standard_file_types,
    force_type=params.file_reader.force_type)
  f.show_summary(out=out)

def validate_params(params):
  if (params.file_reader.file_name is None):
    raise Sorry("No file specified.")

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/flip_symmetric_amino_acids.py
"""Flip symmetric amino acids in a model"""
# LIBTBX_SET_DISPATCHER_NAME iotbx.pdb.flip_symmetric_amino_acids

from __future__ import absolute_import, division, print_function
from libtbx.utils import Usage
import sys
import iotbx.pdb
import mmtbx.model

master_phil_str = """
file_name = None
  .type = path
  .multiple = False
  .optional = False
  .style = hidden
"""

def show_usage():
  help_msg = """\
iotbx.pdb.flip_symmetric_amino_acids model.pdb

"""

  raise Usage(help_msg)

def run(args):
  if len(args) == 0:
    show_usage()
    return
  inp_fn = args[0]
  import time
  t0=time.time()
  pdb_input = iotbx.pdb.input(
      file_name=inp_fn,
      source_info=None,
      raise_sorry_if_format_error=True)
  t0=time.time()
  model = mmtbx.model.manager(
      model_input = pdb_input)
  pdb_h = model.get_hierarchy()
  info = pdb_h.flip_symmetric_amino_acids()
  print(info)
  model.set_sites_cart_from_hierarchy()

  out_fn_prefix = inp_fn
  if inp_fn.endswith(".pdb") or inp_fn.endswith(".cif"):
    out_fn_prefix = inp_fn[:-4]

  if model.input_model_format_cif():
    out_fn = out_fn_prefix + "_iupac.cif"
    txt = model.model_as_mmcif()
  else:
    out_fn = out_fn_prefix + "_iupac.pdb"
    txt = model.model_as_pdb()
  with open(out_fn, 'w') as f:
    f.write(txt)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/french_wilson.py
"""Apply French and Wilson conversion from I to F"""
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.french_wilson
# LIBTBX_SET_DISPATCHER_NAME iotbx.french_wilson

import libtbx.phil
from libtbx import runtime_utils
from libtbx.utils import Sorry, Usage
import os
import sys

master_phil = libtbx.phil.parse("""
french_wilson {
  file_name = None
    .type = path
    .short_caption = Reflections
    .help = '''input intensity data file (mtz)'''
    .style = bold file_type:hkl process_hkl child:iobs:intensity_labels \
      child:rfree:r_free_flags.label input_file
  intensity_labels = None
    .type = strings
    .style = bold renderer:draw_fobs_label_widget
    .input_size = 160
  r_free_flags.label = None
    .type = str
    .short_caption = R-free label
    .style = bold renderer:draw_rfree_label_widget
    .input_size = 160
  output_file = None
    .type = path
    .optional = True
    .help = '''Enter a .mtz output name'''
    .style = bold file_type:hkl new_file
  include scope libtbx.phil.interface.tracking_params
  keep_r_free_flags = True
    .type = bool
    .help = "Keep R-free flag data if present"
    .short_caption = Keep R-free flags if present in input file
  include scope cctbx.french_wilson.master_phil
  sigma_iobs_rejection_criterion = None
    .type=float
    .short_caption = Sigma(Iobs) rejection criterion
  wavelength = None
    .type = float
    .help = Optional, defaults to value defined in input file (if any)
}
""", process_includes=True)

def run(args, out=sys.stdout):
  from cctbx import french_wilson
  from iotbx import file_reader
  hkl_file = None
  sources = []
  interpreter = master_phil.command_line_argument_interpreter()
  for arg in args :
    if os.path.isfile(arg):
      input_file = file_reader.any_file(arg)
      if (input_file.file_type == "hkl"):
        hkl_file = input_file
        sources.append(interpreter.process(arg="file_name=\"%s\"" % arg))
      elif (input_file.file_type == "phil"):
        sources.append(input_file.file_object)
    else :
      arg_phil = interpreter.process(arg=arg)
      sources.append(arg_phil)
  work_phil = master_phil.fetch(sources=sources)
  work_params = work_phil.extract()
  if (work_params.french_wilson.file_name is None):
    if (hkl_file is None):
      raise Usage("phenix.french_wilson data.mtz [params.eff] [options ...]")
    else :
      work_params.french_wilson.file_name = hkl_file.file_name
  elif (hkl_file is None):
    hkl_file = file_reader.any_file(work_params.french_wilson.file_name)
  params = work_params.french_wilson
  xray_data_server = hkl_file.file_server
  crystal_symmetry = xray_data_server.miller_arrays[0].crystal_symmetry()
  if (crystal_symmetry is None):
    raise Sorry("No crystal symmetry found.  This program requires an input "+
      "format with complete symmetry information.")
  unit_cell = xray_data_server.miller_arrays[0].unit_cell()
  if (unit_cell is None):
    raise Sorry("No unit cell found.  This program requires an input "+
      "format with complete unit cell information.")
  i_obs = None
  i_obs = xray_data_server.get_xray_data(
    file_name = params.file_name,
    labels = params.intensity_labels,
    ignore_all_zeros = True,
    parameter_scope = 'french_wilson',
    parameter_name = 'intensity_labels')
  from six.moves import cStringIO as StringIO
  xray_data_server.err = StringIO()
  try :
    r_free_flags, test_flag_value = xray_data_server.get_r_free_flags(
      file_name = params.file_name,
      label = params.r_free_flags.label,
      test_flag_value = None,
      disable_suitability_test = False,
      parameter_scope = "french_wilson.r_free_flags")
  except Sorry as e :
    r_free_flags = None
  if (i_obs is None):
    raise Sorry("Couldn't find intensities!")
  wavelength = params.wavelength
  if (wavelength is None):
    info = i_obs.info()
    if (info is not None):
      wavelength = info.wavelength
      if (wavelength is not None):
        print("Using wavelength=%g from input file" % wavelength, file=out)
  sigma_iobs_rejection_criterion = work_params.french_wilson.\
    sigma_iobs_rejection_criterion
  if (not i_obs.is_unique_set_under_symmetry()):
    print("Merging symmetry-equivalent reflections", file=out)
    i_obs = i_obs.merge_equivalents().array()
  f_obs = french_wilson.french_wilson_scale(miller_array=i_obs,
    params=params,
    sigma_iobs_rejection_criterion=sigma_iobs_rejection_criterion,
    log=out)
  if f_obs is None:
    raise Sorry("Not enough data to accurately apply the French-Wilson method."+\
                " Exiting.")
  if params.output_file == None:
    output_file = "french_wilson.mtz"
  else:
    output_file = params.output_file
  mtz_dataset = i_obs.as_mtz_dataset(
    column_root_label = "I",
    wavelength = wavelength)
  mtz_dataset.add_miller_array(
    miller_array      = f_obs,
    column_root_label = "F")
  if (r_free_flags is not None) and (params.keep_r_free_flags):
    mtz_dataset.add_miller_array(
      miller_array      = r_free_flags,
      column_root_label = "R-free-flags")
  mtz_object = mtz_dataset.mtz_object()
  mtz_object.write(file_name = output_file)
  print("Wrote %s" % output_file, file=out)
  return output_file

class launcher(runtime_utils.target_with_save_result):
  def run(self):
    return run(args=list(self.args), out=sys.stdout)

def validate_params(params):
  if (params.french_wilson.file_name is None):
    raise Sorry("Please specify a reflections file.")
  elif (params.french_wilson.intensity_labels is None):
    raise Sorry("No intensity labels selected; are you sure the input file "+
      "contains appropriate data?")
  return True

def finish_job(result):
  output_files = []
  if (result is not None):
    output_files.append((result, "Corrected amplitudes"))
  return (output_files, [])

if(__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/get_pubmed_citation.py
"""Fetch a citation for a PubMed article, output in either the format used
internally in Phenix, or BibText"""

from __future__ import absolute_import, division, print_function
from iotbx.bioinformatics import pubmed
import iotbx.phil
import sys

master_phil = """
pmid = None
  .type = int
  .multiple = True
bibtex = False
  .type = bool
"""

def run(args, out=sys.stdout):
  cmdline = iotbx.phil.process_command_line_with_files(
    args=args,
    master_phil_string=master_phil,
    integer_def="pmid",
    usage_string="""\
iotbx.get_pubmed_citation PMID

Fetch a citation for a PubMed article, output in either the format used
internally in Phenix, or BibText (if bibtex=True or --bibtext specified).
""")
  params = cmdline.work.extract()
  assert (params.pmid is not None) and (len(params.pmid) > 0)
  for pmid in params.pmid :
    article = pubmed.get_pubmed_xml(pmid)
    if (params.bibtex):
      print(article.as_bibtex_citation(), file=out)
    else :
      print(article.as_phenix_citation(), file=out)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/lattice_symmetry.py
"""Analyze lattice symmetry"""

from __future__ import absolute_import, division, print_function
# Comments by Phil Evans, MRC-LMB, Cambridge, U.K.

from cctbx import crystal
from cctbx.sgtbx.lattice_symmetry import metric_subgroups
from iotbx.option_parser import option_parser
import sys

def run(args):
  command_line = (option_parser(
    usage="iotbx.lattice_symmetry [options] [centring_type_symbol]",
    description="Example: iotbx.lattice_symmetry"
               +" --unit_cell=12,12,12.1,89,90,92 F")
    .enable_symmetry_comprehensive()
    .option(None, "--delta",
      action="store",
      type="float",
      default=3.,
      help="angular tolerance in degrees")
  ).process(args=args, max_nargs=1)
  # Pick up symmetry object
  input_symmetry = command_line.symmetry
  # Check that we have what we need
  if (input_symmetry.unit_cell() is None):
    print()
    print("***********************************")
    print("Please specify unit cell parameters")
    print("***********************************")
    print()
    command_line.parser.show_help()
    return
  if (len(command_line.args) > 0):
    input_symmetry = crystal.symmetry(
      unit_cell=input_symmetry.unit_cell(),
      space_group_symbol="Hall: %s 1" % command_line.args[0])
  elif (input_symmetry.space_group_info() is None):
    input_symmetry = crystal.symmetry(
      unit_cell=input_symmetry.unit_cell(),
      space_group_symbol="P 1")
  # Do it
  groups = metric_subgroups(input_symmetry, command_line.options.delta,
    enforce_max_delta_for_generated_two_folds=True)
  groups.show()

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/merging_statistics.py
"""Analyze merging statistics for a reflection file"""
# LIBTBX_SET_DISPATCHER_NAME phenix.merging_statistics
# LIBTBX_SET_DISPATCHER_NAME iotbx.merging_statistics

from __future__ import absolute_import, division, print_function
import iotbx.merging_statistics
import iotbx.phil
from libtbx.str_utils import format_value
from libtbx.utils import Sorry
from libtbx import runtime_utils
import sys

citations_str = iotbx.merging_statistics.citations_str

master_phil = """
file_name = None
  .type = path
  .short_caption = Unmerged data
  .style = file_type:hkl OnChange:extract_unmerged_intensities bold
labels = None
  .type = str
  .input_size = 200
  .style = renderer:draw_unmerged_intensities_widget
space_group = None
  .type = space_group
  .input_size = 120
unit_cell = None
  .type = unit_cell
symmetry_file = None
  .type = path
  .style = file_type:pdb,hkl OnChange:extract_symmetry
%s
debug = False
  .type = bool
loggraph = False
  .type = bool
estimate_cutoffs = False
  .type = bool
include scope libtbx.phil.interface.tracking_params
json {
  file_name = None
    .type = path
  indent = None
    .type = int(value_min=0)
}
mmcif {
  file_name = None
    .type = path
  data_name = data
    .type = str
}
""" % iotbx.merging_statistics.merging_params_str

# Hack for handling SHELX files
class cmdline_processor(iotbx.phil.process_command_line_with_files):
  def process_other(self, arg):
    if ("=" in arg):
      fields = arg.split("=")
      if (len(fields) == 2) and (fields[1] in ["amplitudes", "intensities",
          "hklf3", "hklf4"]):
        from iotbx import reflection_file_reader
        hkl_in = reflection_file_reader.any_reflection_file(arg)
        if (hkl_in.file_type() is not None):
          return iotbx.phil.parse("%s=%s" % (self.reflection_file_def,
            arg))
    return False

def run(args, out=None, master_params=None,
    assume_shelx_observation_type_is="intensities"):
  if (out is None) : out = sys.stdout
  import iotbx.phil
  if (master_params is None):
    master_params = iotbx.phil.parse(master_phil, process_includes=True)
  cmdline = cmdline_processor(
    args=args,
    master_phil=master_params,
    reflection_file_def="file_name",
    pdb_file_def="symmetry_file",
    space_group_def="space_group",
    unit_cell_def="unit_cell",
    usage_string="""\
phenix.merging_statistics [data_file] [options...]

Calculate merging statistics for non-unique data, including R-merge, R-meas,
R-pim, and redundancy.  Any format supported by Phenix is allowed, including
MTZ, unmerged Scalepack, or XDS/XSCALE (and possibly others).  Data should
already be on a common scale, but with individual observations unmerged.
%s
""" % citations_str)
  params = cmdline.work.extract()
  i_obs = iotbx.merging_statistics.select_data(
    file_name=params.file_name,
    data_labels=params.labels,
    log=out,
    assume_shelx_observation_type_is=assume_shelx_observation_type_is,
    anomalous=params.anomalous,
  )
  params.labels = i_obs.info().label_string()
  validate_params(params)
  symm = sg = uc = None
  if (params.symmetry_file is not None):
    from iotbx import crystal_symmetry_from_any
    symm = crystal_symmetry_from_any.extract_from(
      file_name=params.symmetry_file)
    if (symm is None):
      raise Sorry("No symmetry records found in %s." % params.symmetry_file)
  else :
    sg = i_obs.space_group()
    if (params.space_group is not None):
      sg = params.space_group.group()
    elif (sg is None):
      raise Sorry("Missing space group information.")
    uc = i_obs.unit_cell()
    if (params.unit_cell is not None):
      uc = params.unit_cell
    elif (uc is None):
      raise Sorry("Missing unit cell information.")
    from cctbx import crystal
    symm = crystal.symmetry(
      space_group=sg,
      unit_cell=uc)
  if (i_obs.sigmas() is None):
    raise Sorry("Sigma(I) values required for this application.")
  result = iotbx.merging_statistics.dataset_statistics(
    i_obs=i_obs,
    crystal_symmetry=symm,
    d_min=params.high_resolution,
    d_max=params.low_resolution,
    n_bins=params.n_bins,
    reflections_per_bin=params.reflections_per_bin,
    binning_method=params.binning_method,
    anomalous=params.anomalous,
    debug=params.debug,
    file_name=params.file_name,
    sigma_filtering=params.sigma_filtering,
    use_internal_variance=params.use_internal_variance,
    eliminate_sys_absent=params.eliminate_sys_absent,
    extend_d_max_min=params.extend_d_max_min,
    cc_one_half_significance_level=params.cc_one_half_significance_level,
    cc_one_half_method=params.cc_one_half_method,
    log=out)
  result.show(out=out)
  if (getattr(params, "loggraph", False)):
    result.show_loggraph(out=out)
  if (params.estimate_cutoffs):
    result.show_estimated_cutoffs(out=out)
  if params.json.file_name is not None:
    result.as_json(file_name=params.json.file_name, indent=params.json.indent)
  if params.mmcif.file_name is not None:
    import iotbx.cif.model
    cif = iotbx.cif.model.cif()
    cif[params.mmcif.data_name] = result.as_cif_block()
    with open(params.mmcif.file_name, 'w') as f:
      print(cif, file=f)
  print("", file=out)
  print("References:", file=out)
  print(citations_str, file=out)
  print("", file=out)
  return result

#-----------------------------------------------------------------------
# Phenix GUI stuff
def validate_params(params):
  if (params.file_name is None):
    raise Sorry("No data file specified!")
  elif (params.labels is None):
    raise Sorry("No data labels selected!")
  if (not None in [params.high_resolution, params.low_resolution]):
    if (params.low_resolution < params.high_resolution):
      raise Sorry("Resolution limits flipped - high resolution must be a "+
        "smaller number than low resolution.")
  elif (params.extend_d_max_min):
    raise Sorry("High and low resolution limits must be explicitly given "+
      "when calculating statistics relative to user-defined resolution "+
      "range (extend_d_max_min=True).")
  return True

class launcher(runtime_utils.target_with_save_result):
  def run(self):
    return run(args=list(self.args),
               out=sys.stdout,
               assume_shelx_observation_type_is="intensities")

def finish_job(result):
  stats = []
  if (result is not None):
    stats = [
      ("High resolution", format_value("%.3g", result.overall.d_min)),
      ("Redundancy", format_value("%.1f", result.overall.mean_redundancy)),
      ("R-meas", format_value("%.3g", result.overall.r_meas)),
      ("R-meas (high-res)", format_value("%.3g", result.bins[-1].r_meas)),
      ("<I/sigma>", format_value("%.2g", result.overall.i_over_sigma_mean)),
      ("<I/sigma> (high-res)", format_value("%.2g",
        result.bins[-1].i_over_sigma_mean)),
      ("Completeness", format_value("%.1f%%", result.overall.completeness*100)),
      ("Completeness (high-res)", format_value("%.1f%%",
        result.bins[-1].completeness*100)),
    ]
  return ([], stats)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/mtrix_reconstruction.py
"""Apply MTRIX records of PDB or equivalent records of mmCIF"""
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.pdb.mtrix_reconstruction

import sys, os
import iotbx.pdb
import iotbx.cif
import mmtbx.model

def run(args):
  """
  Apply MTRIX records of PDB or equivalent records of mmCIF.
  Example:
    phenix.pdb.mtrix_reconstruction model.pdb
    phenix.pdb.mtrix_reconstruction model.cif
  """
  if(len(args)==0 or "--help" in args or "-h" in args):
    print(run.__doc__)
    return
  file_name = args[0]
  pdb_inp = iotbx.pdb.input(file_name=file_name)
  model = mmtbx.model.manager(
      model_input=pdb_inp)
  if model.input_model_format_cif():
    out_text = model.model_as_mmcif()
    ext = ".cif"
  else:
    out_text = model.model_as_pdb()
    ext = ".pdb"
  ofn = "%s_MTRIX_expanded%s"%(
    os.path.splitext(os.path.basename(file_name))[0], ext)
  print("Writing result to %s file."%ofn)
  with open(ofn, 'w') as f:
    f.write(out_text)

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/mtz.dump.py
"""Summarize contents of a reflection file or show each reflection"""
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.mtz.dump
# LIBTBX_SET_DISPATCHER_NAME iotbx.mtz.dump

from iotbx import mtz
from iotbx.option_parser import option_parser
import sys, os

def process(file_name, show_column_data, column_data_format, show_batches):
  if (show_column_data):
    column_data_format = mtz.tidy_show_column_data_format_keyword(
      input=column_data_format)
  else:
    column_data_format = ""
  if (column_data_format != "spreadsheet"):
    print("Processing:", file_name)
  mtz_object = mtz.object(file_name=file_name)
  if (column_data_format != "spreadsheet"):
    mtz_object.show_summary()
    print()
  if (show_column_data):
    mtz_object.show_column_data(format=column_data_format)
    if (column_data_format != "spreadsheet"):
      print()
  if (show_batches):
    for batch in mtz_object.batches():
      batch.show()
      print("-" * 79)
    print()
  sys.stdout.flush()

def walk_callback(arg, top, names):
  for name in names:
    if (not name.lower().endswith(".mtz")): continue
    file_name = os.path.normpath(os.path.join(top, name))
    process(
      file_name=file_name,
      show_column_data=arg.show_column_data,
      show_batches=arg.show_batches)

def run(args, command_name="phenix.mtz.dump"):
  if (len(args) == 0): args = ["--help"]
  command_line = (option_parser(
    usage=command_name+" [options] file_name [...]")
    .option("-v", "--verbose",
      action="store_true",
      default=False,
      help="Enable CMTZ library messages.")
    .option("-c", "--show_column_data",
      action="store_true")
    .option("-f", "--column_data_format",
      action="store",
      type="string",
      metavar="KEYWORD",
      help="Valid keywords are: %s."
             % ", ".join(mtz.show_column_data_format_keywords)
          +" Human readable is the default. The format keywords can be"
          +" abbreviated (e.g. -f s).")
    .option("-b", "--show_batches",
      action="store_true")
    .option(None, "--walk",
      action="store",
      type="string",
      metavar="ROOT_DIR",
      help="Find and process all MTZ files under ROOT_DIR")
  ).process(args=args)
  if (len(command_line.args) == 0):
    print(command_line.parser.format_help())
    return
  if (command_line.options.verbose):
    mtz.ccp4_liberr_verbosity(1)
  for file_name in command_line.args:
    process(
      file_name=file_name,
      show_column_data=command_line.options.show_column_data,
      column_data_format=command_line.options.column_data_format,
      show_batches=command_line.options.show_batches)
  if (command_line.options.walk is not None):
    os.path.walk(
      top=command_line.options.walk,
      func=walk_callback,
      arg=command_line.options)

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/mtz_as_cif.py
"""Convert MTZ reflection file to mmCIF"""

from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.mtz_as_cif

import os
import sys
from cctbx.array_family import flex
from libtbx.utils import plural_s
import iotbx.phil
import iotbx.cif.model
from iotbx import reflection_file_utils

from iotbx.cif_mtz_data_labels import phenix_to_cif_labels_dict,\
  ccp4_to_cif_labels_dict
from six.moves import zip
# Probably we can align with what PDB choose to use
# http://mmcif.wwpdb.org/dictionaries/mmcif_pdbx_v40.dic/Categories/refln.html
# comply with newer version:
# http://mmcif.wwpdb.org/dictionaries/mmcif_pdbx_v50.dic/Categories/refln.html
# http://www.ccp4.ac.uk/html/cif2mtz.html

def mtz_to_cif_label(mtz_to_cif_label_dict, mtz_label):
  if mtz_label.endswith("xray"):
    mtz_label = mtz_label[:-5]
  elif mtz_label.endswith("neutron"):
    mtz_label = mtz_label[:-8]
  elif mtz_label.endswith(("_X", "_N")):
    mtz_label = mtz_label[:-2]
  cif_label = mtz_to_cif_label_dict.get(mtz_label)
  if cif_label is None:
    # to catch e.g. IOBS_N(+), SIGIOBS_N(+), IOBS_N(-), SIGIOBS_N(-)
    mtz_label = mtz_label.replace("_N", "").replace("_X", "")
    cif_label = mtz_to_cif_label_dict.get(mtz_label)
  return cif_label

master_phil = iotbx.phil.parse("""
mtz_as_cif
  .short_caption = MTZ as mmCIF
  .caption = This program will convert reflections in MTZ format to mmCIF, \
    suitable for PDB deposition.  Note that phenix.refine can also write \
    mmCIF files directly if desired.
  .style = auto_align box \
    caption_img:icons/custom/phenix.reflection_file_editor.png
{
mtz_file = None
  .type = path
  .multiple = True
  .short_caption = MTZ file
  .style = file_type:mtz input_file bold
output_file = None
  .type = path
  .help = Optional output file name to override default
  .optional = True
  .help = 'Enter a .cif output name'
  .style = file_type:cif bold new_file
mtz_labels = None
  .help = Custom input labels for unknown MTZ columns
  .short_caption = Custom input labels
  .type = strings
cif_labels = None
  .help = Custom output labels for unknown mmCIF columns
  .short_caption = Custom output labels
  .type = strings
}
""")

def format_usage_message(log=sys.stdout):
  print("-"*79, file=log)
  msg = """\
phenix.mtz_as_cif: Convert mtz to CIF format.
The tool will automatically recognize most of the labels from Phenix and CCP4
and convert them to appropriate mmCIF format. If some labels are not recognized,
or another mmCIF labels are needed for them, one may use mtz_labels and
cif_labels parameters to provide pairs of mtz and cif labels. Note that provided
cif_labels must comply with mmCIF format. Number of mtz_labels should be equal
to number of cif_labels.

Usage: phenix.mtz_as_cif data.mtz [params.eff] [options ...]

Usage examples:
  phenix.mtz_as_cif data.mtz
  phenix.mtz_as_cif data.mtz output_file=custom.cif mtz_labels="FOBS SIGFOBS"
      cif_labels="_refln.custom1 _refln.custom2"
"""
  print(msg, file=log)
  print("-"*79, file=log)
  print(master_phil.show(), file=log)

def run(args, params=None, out=sys.stdout):
  from iotbx import file_reader
  work_params = params
  if (work_params is None):
    cmdline = iotbx.phil.process_command_line_with_files(
      args=args,
      master_phil=master_phil,
      reflection_file_def="mtz_as_cif.mtz_file")
    work_params = cmdline.work.extract()
  if (len(work_params.mtz_as_cif.mtz_file) == 0):
    format_usage_message(log = out)
    return
  work_params = work_params.mtz_as_cif
  mtz_objects = []
  for file_name in work_params.mtz_file :
    input_file = file_reader.any_file(file_name)
    input_file.check_file_type("hkl")
    if (input_file.file_object.file_type() != 'ccp4_mtz'):
      raise Sorry("Error reading '%s' - only MTZ files may be used as input."
        % file_name)
    mtz_objects.append(input_file.file_object.file_content())
  assert (len(mtz_objects) != 0)
  custom_cif_labels_dict = {}
  if work_params.mtz_labels is not None and work_params.cif_labels is not None:
    assert len(work_params.mtz_labels) == len(work_params.cif_labels)
    for mtz_label, cif_label in zip(work_params.mtz_labels, work_params.cif_labels):
      custom_cif_labels_dict.setdefault(mtz_label, cif_label)
  output_files = []
  for mtz_file_name, mtz_object in zip(work_params.mtz_file, mtz_objects):
    print("Converting %s" %mtz_file_name, file=out)
    cif_blocks = mtz_as_cif_blocks(
      mtz_object, custom_cif_labels_dict=custom_cif_labels_dict).cif_blocks

    prefix = os.path.splitext(os.path.basename(mtz_file_name))[0]
    output_file = work_params.output_file
    if output_file is None:
      output_file = prefix + ".reflections.cif"
    cif_model = iotbx.cif.model.cif()
    # This is gross... refactor some time the whole thing.
    for key in cif_blocks.keys():
      print(key)
      if key == "xray" and cif_blocks["xray"] is not None:
        cif_model[prefix] = cif_blocks["xray"].cif_block

      elif key == "neutron" and cif_blocks["neutron"] is not None:
        cif_model[prefix+"_neutron"] = cif_blocks["neutron"].cif_block

      elif cif_blocks[key] is not None:
        cif_model[prefix+"_"+key] = cif_blocks[key].cif_block
    with open(output_file, "w") as f:
      print("Writing data and map coefficients to CIF file:\n  %s" % \
        (f.name), file=out)
      print(cif_model, file=f)
      output_files.append(output_file)
  return output_files

class mtz_as_cif_blocks(object):

  def __init__(self, mtz_object, custom_cif_labels_dict=None, log=None,
      test_flag_value=None):

    self.cif_blocks = {
      'xray': None,
      'neutron': None
    }

    if log is None: log = sys.stdout

    miller_arrays = mtz_object.as_miller_arrays()

    miller_arrays_as_cif_block = None

    input_observations_xray = None
    input_observations_neutron = None
    r_free_xray = None
    r_free_neutron = None
    f_obs_filtered_xray = None
    f_obs_filtered_neutron = None

    mtz_to_cif_labels_dict = {}
    mtz_to_cif_labels_dict.update(phenix_to_cif_labels_dict)
    mtz_to_cif_labels_dict.update(ccp4_to_cif_labels_dict)
    if custom_cif_labels_dict is not None:
      mtz_to_cif_labels_dict.update(custom_cif_labels_dict)

    unknown_mtz_labels = []

    for array in miller_arrays:
      labels = array.info().labels
      label = labels[0]
      if reflection_file_utils.looks_like_r_free_flags_info(array.info()):
        if "(+)" in label:
          array = array.average_bijvoet_mates()
          labels = [label.replace("(+)", "")]
        if label.endswith(("neutron", "_N")):
          r_free_neutron = array
        else:
          r_free_xray = array
        continue # deal with these later
      elif label.startswith("F-obs-filtered"):
        if label.endswith(("neutron", "_N")):
          f_obs_filtered_neutron = array
        else:
          f_obs_filtered_xray = array
      elif label.startswith("F-obs") or label.startswith("I-obs"):
        if label.strip("(+)").endswith(("neutron", "_N")):
          input_observations_neutron = array
        else:
          input_observations_xray = array
      #elif label.startswith("R-free-flags"):
      column_names = []
      for mtz_label in labels:
        cif_label = mtz_to_cif_label(mtz_to_cif_labels_dict, mtz_label)
        column_names.append(cif_label)

      column_names = self.check_for_dano_and_convert(column_names, labels, array)
      if column_names.count(None) > 0:
        # I don't know what to do with this array
        for i, mtz_label in enumerate(labels):
          if column_names[i] is None:
            unknown_mtz_labels.append(mtz_label)
        continue
      assert column_names.count(None) == 0
      if labels[0].strip("(+)").endswith(("neutron", "_N")):
        data_type = "neutron"
      else:
        data_type = "xray"
      if column_names[0].startswith(("_refln.F_meas",
                                     "_refln.F_squared_meas",
                                     "_refln.pdbx_F_",
                                     "_refln.pdbx_I_")):
        if data_type == "neutron":
          input_observations_neutron = array
        else:
          input_observations_xray = array

      if self.cif_blocks.get(data_type) is None:
        self.cif_blocks[data_type] = iotbx.cif.miller_arrays_as_cif_block(
          array=array, column_names=column_names, format="mmcif")
      else:
        # check if it is taken already
        present = False
        for ln in column_names:
          if ln in self.cif_blocks[data_type].refln_loop.keys():
            present = True

        if present:
          labels_string = "_"
          for l in labels:
            labels_string += l+" "
          labels_string = labels_string.strip().replace(" ", "_")
          self.cif_blocks[data_type+labels_string] = iotbx.cif.miller_arrays_as_cif_block(
              array=array, column_names=column_names, format="mmcif")
        else:
          self.cif_blocks[data_type].add_miller_array(array, column_names=column_names)

    if len(unknown_mtz_labels):
      print("Warning: Unknown mtz label%s: %s" %(
        plural_s(len(unknown_mtz_labels))[1], ", ".join(unknown_mtz_labels)), file=log)
      print("  Use mtz_labels and cif_labels keywords to provide translation for custom labels.", file=log)

    data_types = ["xray"]
    if self.cif_blocks['neutron'] is not None:
      data_types.append("neutron")

    if input_observations_xray is None and f_obs_filtered_xray is not None:
      self.cif_blocks["xray"].add_miller_array(
        array=f_obs_filtered_xray,
        column_names=('_refln.F_meas_au','_refln.F_meas_sigma_au'))
    if input_observations_neutron is None and f_obs_filtered_neutron is not None:
      self.cif_blocks["neutron"].add_miller_array(
        array=f_obs_filtered_neutron,
        column_names=('_refln.F_meas_au','_refln.F_meas_sigma_au'))

    for data_type in data_types:
      if data_type == "xray":
        r_free = r_free_xray
        input_obs = input_observations_xray
        f_obs_filtered = f_obs_filtered_xray
        if (self.cif_blocks["xray"] is None and r_free_xray is not None and
            self.cif_blocks["neutron"] is not None and r_free_neutron is None):
          r_free_neutron = r_free_xray
      elif data_type == "neutron":
        r_free = r_free_neutron
        input_obs = input_observations_neutron
        f_obs_filtered = f_obs_filtered_neutron
      if self.cif_blocks[data_type] is not None and r_free is not None:
        self.cif_blocks[data_type].add_miller_array(
          array=r_free, column_name='_refln.pdbx_r_free_flag')

      if input_obs is None or r_free is None: continue
      # it may happen that there is an Rfree array but the values are all identical
      if (r_free.data().all_eq(r_free.data()[0])):
        refln_status = r_free.array(data=flex.std_string(r_free.size(), "o"))
        self.cif_blocks[data_type].add_miller_array(
          array=refln_status, column_name="_refln.status")
        continue
      if (test_flag_value is None):
        test_flag_value = reflection_file_utils.guess_r_free_flag_value(
          miller_array=r_free)
      assert (test_flag_value is not None)
      refln_status = r_free.array(data=flex.std_string(r_free.size(), "."))
      input_obs_non_anom = input_obs.average_bijvoet_mates()
      match = r_free.match_indices(input_obs_non_anom)
      refln_status.data().set_selected(match.pair_selection(0), "o")
      refln_status.data().set_selected(r_free.data() == test_flag_value, "f")
      if f_obs_filtered is not None:
        f_obs_filtered_non_anom = f_obs_filtered.average_bijvoet_mates()
        match = r_free.match_indices(f_obs_filtered_non_anom)
        refln_status.data().set_selected(match.single_selection(0), "<") # XXX
      self.cif_blocks[data_type].add_miller_array(
        array=refln_status, column_name="_refln.status")

  def check_for_dano_and_convert(self, column_names, labels, array):
    need_to_convert = False
    for l in labels:
      if l.lower().find("dano") >= 0:
        need_to_convert = True
        break
    if not need_to_convert:
      return column_names
    else:
      result = []
      #  assert array.anomalous_flag()  # No it is not anomalous (only one
      #    number per reflection...it is anomalous data though
      result = ["_refln.pdbx_anom_difference",
                "_refln.pdbx_anom_difference_sigma",]

      if labels[0].lower().find('i-obs') >= 0:
        raise Sorry("Cannot convert anomalous differences on intensity to CIF")
      return result


def validate_params(params):
  if (len(params.mtz_as_cif.mtz_file) == 0):
    raise Sorry("No MTZ file(s) specified!")
  return True

if __name__ == '__main__':
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/patterson_map.py
"""Calculate Patterson map"""
# LIBTBX_SET_DISPATCHER_NAME cctbx.patterson_map

from __future__ import absolute_import, division, print_function
from libtbx.utils import Sorry, Usage, show_development_warning
import libtbx.phil
import math
import os
import sys

patterson_map_phil_str = """
scaling = *sigma volume
  .type = choice
resolution_factor = 1/4.
  .type = float
  .optional = False
high_resolution = None
  .type = float
sharpening = False
  .type = bool
min_sigma_ratio = 3.0
  .type = float
  .optional = False
remove_origin_peak = False
  .type = bool
mandatory_factors = None
  .type = ints
"""

master_phil = libtbx.phil.parse("""
data = None
  .type = path
labels = None
  .type = str
map_type = *auto anom native
  .type = choice
diff_limit = None
  .type = float
%s
map_file_name = None
  .type = path
""" % patterson_map_phil_str)

def prepare_f_obs(f_obs, params):
  if (f_obs.is_xray_intensity_array()):
    f_obs = f_obs.f_sq_as_f()
  f_obs = f_obs.map_to_asu()
  if (not f_obs.is_unique_set_under_symmetry()):
    f_obs = f_obs.merge_equivalents().array()
  if (f_obs.sigmas() is not None):
    f_obs = f_obs.select(f_obs.sigmas() > 0)
    f_obs = f_obs.select((f_obs.data() / f_obs.sigmas()) > params.min_sigma_ratio)
  return f_obs

def calculate_patterson_map(data, params, normalize=False):
  if (normalize):
    data.setup_binner(auto_binning=True)
    data = data.quasi_normalize_structure_factors()
  # XXX not sure what this does - see cctbx/regression/tst_miller.py
  #u_base = xray.calc_u_base(e.d_min(), params.resolution_factor)
  #d_star_sq = e.unit_cell().d_star_sq(e.indices())
  #dw = flex.exp(d_star_sq*2*(math.pi**2)*u_base)
  #eb = miller.array(miller_set=e, data=e.data()/dw)

  map = data.patterson_map(
    resolution_factor=params.resolution_factor,
    mandatory_factors=params.mandatory_factors,
    d_min=params.high_resolution,
    sharpening=params.sharpening,
    origin_peak_removal=params.remove_origin_peak)
  print("Map gridding: ",map.n_real())
  if (params.scaling == "sigma"):
    map.apply_sigma_scaling()
  else :
    map.apply_volume_scaling()
  return map

def extract_data(file_name, hkl_in=None, expected_labels=None, out=sys.stdout):
  from iotbx import file_reader
  if (hkl_in is None):
    hkl_in = file_reader.any_file(file_name,
      force_type="hkl",
      raise_sorry_if_errors=True)
  miller_arrays = hkl_in.file_server.miller_arrays
  obs = None
  all_fs = []
  all_fs_anom = []
  all_is = []
  all_is_anom = []
  print("Reading data from %s..." % hkl_in.file_name, file=out)
  for array in miller_arrays :
    labels = array.info().label_string()
    if (labels == expected_labels):
      obs = array
      break
    elif (expected_labels is None):
      if (array.is_xray_amplitude_array()):
        if (array.anomalous_flag()):
          all_fs_anom.append(array)
        else :
          all_fs.append(array)
      elif (array.is_xray_intensity_array()):
        if (array.anomalous_flag()):
          all_is_anom.append(array)
        else :
          all_is.append(array)
  if (obs is None):
    for choices in [all_fs_anom,all_is_anom,all_fs,all_is] :
      if (len(choices) > 1):
        raise Sorry(("Multiple equally good candidates for data:\n%s\n"+
          "Please specify labels=<your choice here>.") %
          "\n".join([ a.info().label_string() for a in choices ]))
      elif (len(choices) == 1):
        obs = choices[0]
        print("Defaulting to data in %s" % obs.info().label_string(), file=out)
        break
  return obs

def run(args, out=sys.stdout):
  show_development_warning(out=out)
  if (len(args) == 0) or ("--help" in args):
    raise Usage("""\
cctbx.patterson_map data.mtz [options]

Calculates a simple or anomalous difference Patterson map.  Output is in CCP4
format.

Full options:

%s
""" % master_phil.as_str(prefix="  "))
  import iotbx.phil
  from cctbx.array_family import flex
  from cctbx import miller
  from cctbx import xray
  hkl_in = None
  sources = []
  cmdline = iotbx.phil.process_command_line_with_files(
    args=args,
    master_phil=master_phil,
    reflection_file_def="data")
  params = cmdline.work.extract()
  if (params.data is None):
    raise Usage("mmtbx.patterson_map data [options]\n\nFull parameters:\n%s" %
      master_phil.as_str(prefix="  "))
  f_obs = extract_data(
    file_name=params.data,
    expected_labels=params.labels,
    out=out)
  if (f_obs is None):
    raise Sorry("No suitable data found.")
  f_obs = prepare_f_obs(f_obs, params=params)
  final_array = f_obs # default
  is_anom = False
  if (f_obs.anomalous_flag()):
    if (params.map_type in ["auto", "anom"]):
      print("Output will be anomalous Patterson map", file=out)
      is_anom = True
      final_array = f_obs.anomalous_differences()
      final_array = abs(final_array)
      if (params.diff_limit is not None):
        final_array = final_array.select(final_array.data() < params.diff_limit)
    else :
      final_array = f_obs.average_bijvoet_mates()
  map = calculate_patterson_map(data=final_array, params=params,
    normalize=is_anom)
  if (params.map_file_name is None):
    base = os.path.splitext(os.path.basename(params.data))[0]
    params.map_file_name = base + "_patt.ccp4"
  map.as_ccp4_map(
    file_name=params.map_file_name)
  print("Wrote %s" % params.map_file_name, file=out)

def validate_params(params):
  if (params.data is None):
    raise Sorry("Data file not specified.")
  elif (not os.path.isfile(params.data)):
    raise Sorry("The path %s is not a valid file." % params.data)
  return True

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/pdb.as_xray_structure.py
"""Calculate xray_structure from a model and dump as pickle"""
from __future__ import absolute_import, division, print_function
from iotbx import pdb
from iotbx.option_parser import option_parser
from cctbx.array_family import flex
from libtbx.str_utils import show_string
from libtbx import easy_pickle
import sys, os

def run(args, command_name="iotbx.pdb.as_xray_structure"):
  command_line = (option_parser(
    usage=command_name+" [options] pdb_file ...",
    description="Example: %s pdb1ab1.ent" % command_name)
    .enable_symmetry_comprehensive()
    .option(None, "--weak_symmetry",
      action="store_true",
      default=False,
      help="symmetry on command line is weaker than symmetry found in files")
    .option(None, "--ignore_occ_for_site_symmetry",
      action="store_true",
      default=False,
      help="disables non_unit_occupancy_implies_min_distance_sym_equiv_zero")
    .option("-v", "--verbose",
      action="store_true",
      default=False,
      help="show scatterers")
    .option(None, "--pickle",
      action="store",
      type="string",
      help="write all data to FILE ('--pickle .' copies name of input file)",
      metavar="FILE")
    .option(None, "--fake_f_obs_and_r_free_flags_d_min",
      action="store",
      type="float",
      help="write F-calc as F-obs, add random R-free flags (MTZ format)",
      metavar="FLOAT")
  ).process(args=args)
  if (len(command_line.args) == 0):
    command_line.parser.show_help()
  co = command_line.options
  d_min = co.fake_f_obs_and_r_free_flags_d_min
  all_structures = []
  for file_name in command_line.args:
    print("file_name:", file_name)
    sys.stdout.flush()
    pdb_inp = pdb.input(file_name=file_name)
    structure = pdb_inp.xray_structure_simple(
      crystal_symmetry=command_line.symmetry,
      weak_symmetry=co.weak_symmetry,
      non_unit_occupancy_implies_min_distance_sym_equiv_zero=
        not co.ignore_occ_for_site_symmetry)
    structure.show_summary()
    if (structure.special_position_indices().size() != 0):
      structure.show_special_position_shifts(
        sites_cart_original=pdb_inp.atoms().extract_xyz())
    structure.scattering_type_registry().show(show_gaussians=False)
    if (co.verbose):
      structure.show_scatterers()
    if (d_min is not None and d_min > 0):
      f_obs = abs(structure.structure_factors(
        d_min=d_min, anomalous_flag=False).f_calc())
      f_obs = f_obs.customized_copy(sigmas=flex.sqrt(f_obs.data()))
      r_free_flags = f_obs.generate_r_free_flags(fraction=0.05, max_free=None)
      mtz_dataset = f_obs.as_mtz_dataset(column_root_label="F-obs")
      mtz_dataset.add_miller_array(
        miller_array=r_free_flags,
        column_root_label="R-free-flags")
      mtz_object = mtz_dataset.mtz_object()
      history = "%s %s" % (command_name, show_string(file_name))
      lines = flex.std_string(["Fake F-obs, R-free-flags"])
      while (len(history) != 0):
        lines.append(history[:77])
        history = history[77:]
      mtz_object.add_history(lines=lines)
      mtz_object.show_summary()
      mtz_file_name = os.path.basename(file_name).replace(".","_") \
                    + "_fake.mtz"
      print("Writing file:", mtz_file_name)
      mtz_object.write(file_name=mtz_file_name)
    all_structures.append(structure)
    print()
  pickle_file_name = co.pickle
  if (pickle_file_name is not None and len(all_structures) > 0):
    if (pickle_file_name == "."):
      if (len(command_line.args) > 1):
        raise Sorry(
          "Ambiguous name for pickle file (more than one input file).")
      pickle_file_name = os.path.basename(command_line.args[0])
    if (not pickle_file_name.lower().endswith(".pickle")):
      pickle_file_name += ".pickle"
    if (len(all_structures) == 1):
      all_structures = all_structures[0]
    else:
      print()
    print("Writing all xray structures to file:", pickle_file_name)
    easy_pickle.dump(pickle_file_name, all_structures)
    print()

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/pdb.b_factor_stats.py
"""Summarize B-factor statistics from a model"""

from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.pdb.b_factor_stats

import iotbx.pdb
from cctbx import adptbx
from cctbx.array_family import flex
import libtbx.utils
import sys

def run(args):
  for file_name in args:
    print("File name:", file_name)
    try:
      pdb_inp = iotbx.pdb.input(file_name=file_name)
    except KeyboardInterrupt: raise
    except Exception:
      libtbx.utils.format_exception()
    isotropic_b_factors = flex.double()
    all_eigenvalues = flex.double()
    for atom in pdb_inp.atoms():
      if (atom.uij == (-1,-1,-1,-1,-1,-1)):
        isotropic_b_factors.append(atom.b)
      else:
        all_eigenvalues.extend(flex.double(adptbx.eigenvalues(atom.uij)))
    all_eigenvalues *= adptbx.u_as_b(1)
    print("Number of isotropic atoms:  ", isotropic_b_factors.size())
    print("Number of anisotropic atoms:", all_eigenvalues.size() // 3)
    if (isotropic_b_factors.size() != 0):
      print("Histogram of isotropic B-factors:")
      flex.histogram(data=isotropic_b_factors, n_slots=10).show(
        prefix="  ", format_cutoffs="%7.2f")
    if (all_eigenvalues.size() != 0):
      print("Histogram of eigenvalues of anisotropic B-factors:")
      flex.histogram(data=all_eigenvalues, n_slots=10).show(
        prefix="  ", format_cutoffs="%7.2f")
    print()

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/pdb.box_around_molecule.py
"""Make a box around molecule and call it the unit cell"""
from __future__ import absolute_import, division, print_function
from iotbx.cli_parser import run_program
from iotbx.programs import box_around_molecule

if __name__ == '__main__':
  run_program(program_class=box_around_molecule.Program)


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/pdb.hierarchy.py
"""Summarize hierarchy of a model read from a file"""

from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.pdb.hierarchy

from iotbx import pdb
from iotbx.option_parser import option_parser
from libtbx.str_utils import show_string
import sys, os

def run(args, command_name="phenix.pdb.hierarchy"):
  if (len(args) == 0): args = ["--help"]
  command_line = (option_parser(
    usage="%s file..." % command_name)
    .option(None, "--details",
      action="store",
      type="string",
      default=None,
      help="level of detail",
      metavar="|".join(pdb.hierarchy.level_ids))
    .option(None, "--residue_groups_max_show",
      action="store",
      type="int",
      default=10,
      help="maximum number of residue groups to be listed along with"
           " errors or warnings",
      metavar="INT")
    .option(None, "--duplicate_atom_labels_max_show",
      action="store",
      type="int",
      default=10,
      help="maximum number of groups of duplicate atom labels to be listed",
      metavar="INT")
    .option(None, "--prefix",
      action="store",
      type="string",
      default="",
      help="prefix for all output lines",
      metavar="STRING")
    .option(None, "--write_pdb_file",
      action="store",
      type="string",
      default=None,
      help="write hierarchy as PDB coordinate section to file",
      metavar="FILE")
    .option(None, "--set_element_simple",
      action="store_true",
      default=False,
      help="sets or tidies ATOM record element columns (77-78) if necessary"
           " before writing PDB file")
    .option(None, "--reset_serial_first_value",
      action="store",
      type="int",
      default=None,
      help="resets atom serial numbers before writing PDB file",
      metavar="INT")
    .option(None, "--interleaved_conf",
      action="store",
      type="int",
      default=0,
      help="interleave alt. conf. when writing PDB file; possible choices are:"
        " 0 (not interleaved),"
        " 1 (interleaved atom names but not resnames),"
        " 2 (fully interleaved)",
      metavar="INT")
    .option(None, "--no_anisou",
      action="store_true",
      default=False,
      help="suppress ANISOU records when writing PDB file")
    .option(None, "--no_sigatm",
      action="store_true",
      default=False,
      help="suppress SIGATM records when writing PDB file")
    .option(None, "--no_cryst",
      action="store_true",
      default=False,
      help="suppress crystallographic records (e.g. CRYST1 and SCALEn)"
           " when writing PDB file")
  ).process(args=args)
  co = command_line.options
  for file_name in command_line.args:
    if (not os.path.isfile(file_name)): continue
    pdb_inp, h = execute(
      file_name=file_name,
      prefix=co.prefix,
      residue_groups_max_show=co.residue_groups_max_show,
      duplicate_atom_labels_max_show=co.duplicate_atom_labels_max_show,
      level_id=co.details)
    if (co.write_pdb_file is not None):
      if (co.set_element_simple):
        h.atoms().set_chemical_element_simple_if_necessary()
      open_append = False
      if (not co.no_cryst):
        s = pdb_inp.crystallographic_section()
        if (s.size() != 0):
          print("\n".join(s), file=open(co.write_pdb_file, "w"))
          open_append = True
      h.write_pdb_file(
        file_name=co.write_pdb_file,
        open_append=open_append,
        append_end=True,
        interleaved_conf=co.interleaved_conf,
        atoms_reset_serial_first_value=co.reset_serial_first_value,
        sigatm=not co.no_sigatm,
        anisou=not co.no_anisou,
        siguij=not co.no_anisou)
    print(co.prefix.rstrip())

def execute(
      file_name,
      prefix="",
      residue_groups_max_show=10,
      duplicate_atom_labels_max_show=10,
      level_id=None):
  try:
    pdb_inp = pdb.input(file_name=file_name)
    h = pdb_inp.construct_hierarchy()
    h.overall_counts().show(
        prefix=prefix+"  ",
        residue_groups_max_show=residue_groups_max_show,
        duplicate_atom_labels_max_show=duplicate_atom_labels_max_show)
    if (level_id is not None):
      h.show(
          prefix=prefix+"  ",
          level_id=level_id)
    return pdb_inp, h
  except KeyboardInterrupt: raise
  except Exception as e:
    print("Exception: file %s: %s: %s" % (
      show_string(file_name), e.__class__.__name__, str(e)))

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/pdb.insert_scale_records.py
"""Insert SCALE records in a PDB file"""
from __future__ import absolute_import, division, print_function
import iotbx.pdb
from cctbx import uctbx
import sys

def run(args):
  for file_name in args:
    for pdb_str in open(file_name):
      sys.stdout.write(pdb_str)
      if (pdb_str.startswith("CRYST1")):
        cryst1_record = iotbx.pdb.records.cryst1(pdb_str=pdb_str)
        if (cryst1_record.ucparams is not None):
          print(iotbx.pdb.format_scale_records(
            unit_cell=uctbx.unit_cell(cryst1_record.ucparams)))

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/pdb.join_fragment_files.py
"""Combine models into a single model"""
from __future__ import absolute_import, division, print_function
import iotbx.pdb
import iotbx.cif.model
import iotbx.phil
import libtbx
from libtbx.utils import Usage, format_cpu_times
import sys, os

master_phil = iotbx.phil.parse("""
join_fragment_files {
  reset_atom_serial = True
    .type = bool
  model_file = None
    .type = path
    .multiple = True
  format = mmcif pdb
    .type = choice
}
""")

def run(args,  command_name="iotbx.pdb.join_fragment_files"):
  from iotbx import file_reader
  def usage():
    raise Usage("""\
%s file1.pdb file2.pdb [...]

or define the environment variable
  PDB_MIRROR_PDB
to join all fragment files in the PDB.""" % command_name)

  if (len(args) == 0 or args == ["--exercise"]):
    pdb_mirror_pdb = os.environ.get("PDB_MIRROR_PDB")
    if (pdb_mirror_pdb is None):
      if (len(args) == 0): usage()
    else:
      for line in iotbx.pdb.pdb_codes_fragment_files.splitlines():
        print("PDB code group:", line)
        codes = line.split()
        joined = iotbx.pdb.join_fragment_files(
          file_names = [
            os.path.join(pdb_mirror_pdb, code[1:3], "pdb%s.ent.gz" % code)
              for code in codes]).joined
        file_name_out = "%s_%s.pdb" % (codes[0], codes[-1])
        print("  writing:", file_name_out)
        out = open(file_name_out, "w")
        print("\n".join(joined.info), file=out)
        out.write(joined.as_pdb_string(append_end=True))
        if (len(args) != 0): break
    print(format_cpu_times())
  else:
    sources = []
    file_names = []
    interpreter = master_phil.command_line_argument_interpreter()
    input_file_type = None
    for arg in args :
      if os.path.isfile(arg):
        input_file = file_reader.any_file(arg)
        if (input_file.file_type == "pdb"):
          file_names.append(input_file)
          sources.append(interpreter.process(arg="model_file=\"%s\"" % arg))
        elif (input_file.file_type == "phil"):
          sources.append(input_file.file_object)
      else :
        arg_phil = interpreter.process(arg=arg)
        sources.append(arg_phil)
    work_phil = master_phil.fetch(sources=sources)
    work_params = work_phil.extract()
    file_names = work_params.join_fragment_files.model_file
    if (len(file_names) < 2): usage()
    result = iotbx.pdb.join_fragment_files(file_names=file_names)
    joined = result.joined
    if work_params.join_fragment_files.reset_atom_serial:
      joined.atoms_reset_serial()
    if work_params.join_fragment_files.format in (None, libtbx.Auto, "pdb"):
      print("\n".join(joined.info))
      sys.stdout.write(joined.as_pdb_string(append_end=True))
    elif work_params.join_fragment_files.format == "mmcif":
      cif_object = iotbx.cif.model.cif()
      cif_object["combined"] = joined.as_cif_block(
        crystal_symmetry=result.crystal_symmetry)
      cif_object.show(out=sys.stdout)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/pdb.link_as_geometry_restraints_edits.py
"""Create geometry restraints edits from PDB LINK records"""
from __future__ import absolute_import, division, print_function
from iotbx import pdb
from libtbx.str_utils import show_string
from libtbx import adopt_init_args
import sys

def field_as_number(
      line,
      icols,
      target_type,
      strict,
      error_message,
      substitute_value=0):
  try: return target_type(line[icols[0]:icols[1]])
  except ValueError:
    if (strict): raise RuntimeError(
      error_message+"\n"
      + "  PDB input line: " + line.rstrip())
  return substitute_value

class atom_labels(object):

  def __init__(self,
        chain=None,
        resname=None,
        resseq=None,
        icode=None,
        name=None,
        altloc=None,
        segid=None):
    adopt_init_args(self, locals())

  def selection_string(self):
    result = []
    a = result.append
    a('chain %s' % show_string(self.chain))
    a('resname %s' % show_string(self.resname))
    a('resseq %s' % self.resseq)
    a('icode %s' % show_string(self.icode))
    a('name %s' % show_string(self.name))
    a('altloc %s' % show_string(self.altloc))
    return show_string(" and ".join(result))

class link_record(object):

  def __init__(self, line):
    # 13 - 16      Atom            name1       Atom name.
    # 17           Character       altLoc1     Alternate location indicator.
    # 18 - 20      Residue name    resName1    Residue name.
    # 22           Character       chainID1    Chain identifier.
    # 23 - 26      Integer         resSeq1     Residue sequence number.
    # 27           AChar           iCode1      Insertion code.
    # 31 - 40      distance (REFMAC extension: F10.5)
    # 43 - 46      Atom            name2       Atom name.
    # 47           Character       altLoc2     Alternate location indicator.
    # 48 - 50      Residue name    resName2    Residue name.
    # 52           Character       chainID2    Chain identifier.
    # 53 - 56      Integer         resSeq2     Residue sequence number.
    # 57           AChar           iCode2      Insertion code.
    # 60 - 65      SymOP           sym1        Symmetry operator for 1st atom.
    # 67 - 72      SymOP           sym2        Symmetry operator for 2nd atom.
    # 73 - 80      margin (REFMAC extension: _chem_link.id)
    line = line + " "*max(0,80-len(line))
    assert line[:6] == "LINK  "
    self.labels_pair = [atom_labels(
      name=line[12:16],
      altloc=line[16],
      resname=line[17:20],
      chain=line[21],
      resseq=field_as_number(
        line=line, icols=(22,26), target_type=int, strict=True,
        error_message="Serial number must be an integer:"),
      icode=line[26])]
    try: self.distance = float(line[30:40])
    except ValueError: self.distance = None
    self.labels_pair.append(atom_labels(
      name=line[42:46],
      altloc=line[46],
      resname=line[47:50],
      chain=line[51],
      resseq=field_as_number(
        line=line, icols=(52,56), target_type=int, strict=True,
        error_message="Serial number must be an integer:"),
      icode=line[56]))
    self.symops = [line[59:65], line[66:72]]
    self.margin = line[72:80]

  def as_geometry_restraints_edits(self):
    if (self.distance is None):
      distance_ideal = "None"
    else:
      distance_ideal = "%.6g" % self.distance
    return """\
  bond {
    action = *add delete change
    atom_selection_1 = %s
    atom_selection_2 = %s
    symmetry_operation = None
    distance_ideal = %s
    sigma = None
  }
""" % tuple([labels.selection_string() for labels in self.labels_pair]
            + [distance_ideal])

def run(args, command_name="iotbx.pdb.link_as_geometry_restraints_edits"):
  for file_name in args:
    section = pdb.input(file_name=file_name).connectivity_annotation_section()
    print("refinement.geometry_restraints.edits {")
    for line in section:
      if (not line.startswith("LINK  ")): continue
      link = link_record(line=line)
      assert link.symops[0].strip() == "" # not implemented
      assert link.symops[1].strip() == "" # not implemented
      sys.stdout.write(link.as_geometry_restraints_edits())
    print("}")

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/pdb.print_sequence.py
"""Print sequence from a model file"""
from __future__ import absolute_import, division, print_function
import os, sys

from iotbx.pdb.amino_acid_codes import three_letter_given_one_letter as \
  protein_sequence_to_three

dna_rna_sequence_to_three = {
  "A" : "ADE",
  "C" : "CYT",
  "G" : "GUA",
  "N" : None, # any base
  "T" : "THY",
  "U" : "URI",
  }

ps_lookup = {}
for key in protein_sequence_to_three:
  ps_lookup[protein_sequence_to_three[key]] = key
# special lookups
ps_lookup["MSE"] = "M"
#
ds_lookup = {}
for key in dna_rna_sequence_to_three:
  if dna_rna_sequence_to_three[key]:
    ds_lookup[dna_rna_sequence_to_three[key]] = key

def run(filename,
        ignore_residues=[],
        print_unknown=False,
        ):
  protein_only = True
  from libtbx.utils import Sorry
  try:
    import iotbx.pdb
  except ImportError as e:
    raise Sorry("iotbx not available")
  if os.path.exists(filename):
    pdb_io = iotbx.pdb.input(filename)
  elif filename.find("\n")>-1:
    pdb_io = iotbx.pdb.input(source_info=None,
                       lines=flex.split_lines(filename))
  else:
    assert 0
  hierarchy      = pdb_io.construct_hierarchy()

  outl = ""
  unk = ""
  error_outl = ""

  for model in hierarchy.models():
    for chain in model.chains():
      for i_conformer, conformer in enumerate(chain.conformers()):
        for residue in conformer.residues():
          if(i_conformer!=0 and not residue.is_pure_main_conf): continue
          if residue.resname.strip() in ps_lookup:
            outl += "%s" % ps_lookup[residue.resname.strip()]
          elif residue.resname.strip() in ds_lookup:
            outl += "%s" % ds_lookup[residue.resname.strip()]
            protein_only = False
          elif residue.resname.strip() in ignore_residues:
            if unk.find(residue.resname.strip())==-1:
              unk += "%s " % residue.resname.strip()
          elif residue.resname.strip() in dna_rna_sequence_to_three.keys():
            outl += "%s" % residue.resname.strip()
            protein_only = False
          else:
            if not protein_only:
              if not residue.atoms()[0].hetero:
                error_outl += \
                  "This residue is not converted to letter code : %s\n" % (
                  residue.resname.strip(),
                  )
      outl+="\n"
  if unk and print_unknown:
    print("Unconverted residues",unk)
  if error_outl:
    print(error_outl)
  return outl

def exercise():
  for pdb_file in ["1zap",
                   "1a00",
                   ]:
    print(run(os.path.join(os.environ["PDB_MIRROR_UNCOMPRESSED"],
                           "pdb%s.ent",
                           )
              ))

if __name__=="__main__":
  print(run(sys.argv[1]))


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/pdb.superpose_atoms_by_name.py
"""Superpose models using named atom pairs in the two models"""
from __future__ import absolute_import, division, print_function
def run(args):
  assert len(args) == 2
  import iotbx.pdb
  lists_of_atoms = []
  for file_name in args:
    pdb_inp = iotbx.pdb.input(file_name=file_name)
    pdb_inp.construct_hierarchy().only_residue() # raises if more than one
    lists_of_atoms.append(pdb_inp.atoms())
  lookup_dict = {}
  for atom_i in lists_of_atoms[0]:
    lookup_dict[atom_i.name] = atom_i
  atom_pairs = []
  for atom_j in lists_of_atoms[1]:
    atom_i = lookup_dict.get(atom_j.name)
    if (atom_i is not None):
      atom_pairs.append((atom_i, atom_j))
  assert len(atom_pairs) > 2
  from scitbx.array_family import flex
  reference_sites = flex.vec3_double()
  other_sites = flex.vec3_double()
  for pair in atom_pairs:
    reference_sites.append(pair[0].xyz)
    other_sites.append(pair[1].xyz)
  import scitbx.math.superpose
  fit = scitbx.math.superpose.least_squares_fit(
    reference_sites=reference_sites,
    other_sites=other_sites)
  rmsd = fit.other_sites_best_fit().rms_difference(reference_sites)
  print("Number of atoms first pdb: ", lists_of_atoms[0].size())
  print("Number of atoms second pdb:", lists_of_atoms[1].size())
  print("Number of superposed atoms:", reference_sites.size())
  print("RMSD: %.3f" % rmsd)

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/pdb.superpose_centers_of_mass.py
"""Superpose center of mass of model on center of mass of another model"""

from __future__ import absolute_import, division, print_function
from iotbx import pdb
import iotbx.phil
from iotbx.option_parser import option_parser
from cctbx import euclidean_model_matching
from cctbx import sgtbx
from scitbx import matrix
from libtbx.utils import Sorry
from libtbx.str_utils import show_string
from libtbx.test_utils import approx_equal
import sys, os

master_params = iotbx.phil.parse(input_string="""\
reference {
  file_name=None
    .type=path
  atom_selection=None
    .type=str
}
other {
  file_name=None
    .type=path
  atom_selection=None
    .type=str
}
output {
  file_name=None
    .type=path
  atom_selection=None
    .type=str
}
crystal_symmetry {
  unit_cell=None
    .type=unit_cell
  space_group=None
    .type=space_group
}
""")

def run(args, command_name="iotbx.pdb.superpose_centers_of_mass"):
  if (len(args) == 0): args = ["--help"]
  command_line = (option_parser(
    usage=
      "%s [options] [reference_file] [other_file] [parameter_file]" %
       command_name)
    .enable_show_defaults()
    .enable_symmetry_comprehensive()
  ).process(args=args)
  if (command_line.expert_level is not None):
    master_params.show(
      expert_level=command_line.expert_level,
      attributes_level=command_line.attributes_level)
    sys.exit(0)
  #
  # Loop over command-line arguments.
  #
  parameter_interpreter = master_params.command_line_argument_interpreter()
  parsed_params = []
  pdb_file_names = []
  command_line_params = []
  for arg in command_line.args:
    arg_is_processed = False
    if (os.path.isfile(arg)):
      params = None
      try: params = iotbx.phil.parse(file_name=arg)
      except KeyboardInterrupt: raise
      except RuntimeError: pass
      else:
        if (len(params.objects) == 0):
          params = None
      if (params is not None):
        parsed_params.append(params)
        arg_is_processed = True
      elif (pdb.is_pdb_file(file_name=arg)):
        pdb_file_names.append(arg)
        arg_is_processed = True
    if (not arg_is_processed):
      try:
        params = parameter_interpreter.process(arg=arg)
      except Sorry as e:
        if (not os.path.isfile(arg)): raise
        raise Sorry("Unknown file format: %s" % arg)
      else:
        command_line_params.append(params)
  #
  # Consolidation of inputs, resulting in effective phil_params.
  #
  phil_params = master_params.fetch(
    sources=parsed_params+command_line_params)
  params = phil_params.extract()
  for param_group in [params.reference, params.other, params.output]:
    if (param_group.file_name is None
        and len(pdb_file_names) > 0):
      param_group.file_name = pdb_file_names[0]
      pdb_file_names = pdb_file_names[1:]
  if (len(pdb_file_names) > 0):
    raise Sorry("Too many PDB file names: %s" % ", ".join([
      show_string(s) for s in pdb_file_names]))
  if (params.output.file_name is None
      and params.other.file_name is not None):
    name = os.path.basename(params.other.file_name)
    if (name.lower().endswith(".pdb")): name = name[:-4]
    name += "_superposed.pdb"
    params.output.file_name = name
  if (params.crystal_symmetry.unit_cell is None):
    params.crystal_symmetry.unit_cell = \
      command_line.symmetry.unit_cell()
  if (params.crystal_symmetry.space_group is None):
    params.crystal_symmetry.space_group = \
      command_line.symmetry.space_group_info()
  phil_params = master_params.format(python_object=params)
  phil_params.show()
  print("#phil __OFF__")
  #
  # Final checks.
  #
  if (params.reference.file_name is None):
    raise Sorry("Required file name is missing: reference.file_name")
  if (params.other.file_name is None):
    raise Sorry("Required file name is missing: other.file_name")
  if (params.output.file_name is None):
    raise Sorry("Required file name is missing: output.file_name")
  #
  # Processing of input PDB files.
  #
  pdb_objs = []
  sites_carts = []
  centers_of_mass = []
  for param_group in [params.reference, params.other]:
    pdb_obj = pdb.input(file_name=param_group.file_name)
    pdb_obj.atoms = pdb_obj.construct_hierarchy().atoms()
    pdb_objs.append(pdb_obj)
    sites_carts.append(pdb_obj.atoms.extract_xyz())
    sites_sel = sites_carts[-1]
    if (param_group.atom_selection is not None):
      sel = pdb_obj.construct_hierarchy().atom_selection_cache().selection(
        param_group.atom_selection)
      sites_sel = sites_sel.select(sel)
    print("Number of selected sites:", sites_sel.size())
    centers_of_mass.append(sites_sel.mean())
  #
  # Consolidation of crystal symmetries.
  #
  crystal_symmetry = command_line.symmetry
  for pdb_obj in pdb_objs:
    crystal_symmetry_from_pdb = pdb_obj.crystal_symmetry()
    if (crystal_symmetry_from_pdb is not None):
      crystal_symmetry = crystal_symmetry.join_symmetry(
        other_symmetry=crystal_symmetry_from_pdb,
        force=False)
  if (crystal_symmetry.unit_cell() is None):
    raise Sorry("Unknown unit cell parameters."
      "\n  Use --unit_cell or --symmetry to supply unit cell parameters.")
  if (crystal_symmetry.space_group_info() is None):
    raise Sorry("Unknown space group symmetry."
      "\n  Use --space_group or --symmetry to supply symmetry information.")
  crystal_symmetry.show_summary()
  #
  # Obtain transformation to reference setting.
  #   To ensure all allowed origin shifts are parallel to the basis vectors.
  #
  cb_op_to_ref = crystal_symmetry.change_of_basis_op_to_reference_setting()
  sym_ref = crystal_symmetry.change_basis(cb_op=cb_op_to_ref)
  #
  # Obtain allowed origin shifts.
  #   This is the most convenient interface. Essentially we just need
  #   sgtbx.structure_seminvariants.
  #
  match_symmetry = euclidean_model_matching.euclidean_match_symmetry(
    space_group_info=sym_ref.space_group_info(),
    use_k2l=False,
    use_l2n=False)
  #
  # Compute the symmetry operation which maps the center of mass of
  # "other" closest to the center of mass of "reference."
  #
  centers_frac = [
    sym_ref.unit_cell().fractionalize(cb_op_to_ref.c() * center_cart)
      for center_cart in centers_of_mass]
  dist_info = sgtbx.min_sym_equiv_distance_info(
    sym_ref.special_position_settings().sym_equiv_sites(centers_frac[0]),
    centers_frac[1],
    match_symmetry.continuous_shift_flags)
  sym_op = cb_op_to_ref.inverse().apply(dist_info.sym_op())
  print("Rotation in fractional space:", sym_op.r().as_xyz())
  sym_op = sym_op.as_rational().as_float() \
         + matrix.col(dist_info.continuous_shifts())
  print("Translation in fractional space: (%s)" % (
    ", ".join(["%.6g" % t for t in sym_op.t])))
  #
  centers_frac = [sym_ref.unit_cell().fractionalize(center_cart)
    for center_cart in centers_of_mass]
  sym_center_frac = sym_op * centers_frac[1]
  sym_center_cart = crystal_symmetry.unit_cell().orthogonalize(sym_center_frac)
  print("Centers of mass:")
  print("               Reference: (%s)" % ", ".join(["%8.2f" % v
    for v in centers_of_mass[0]]))
  print("          Original other: (%s)" % ", ".join(["%8.2f" % v
    for v in centers_of_mass[1]]))
  print("  Symmetry related other: (%s)" % ", ".join(["%8.2f" % v
    for v in sym_center_cart]))
  print("Cartesian distance between centers of mass: %.4f" % dist_info.dist())
  #
  # Internal consistency check (in input setting).
  #
  assert approx_equal(crystal_symmetry.unit_cell().distance(
    centers_frac[0], sym_center_frac), dist_info.dist())
  #
  # Transform atomic coordinates of "other."
  #
  sites_frac_other = crystal_symmetry.unit_cell().fractionalize(
    sites_cart=sites_carts[1])
  sites_frac_other_superposed = sym_op * sites_frac_other
  sites_cart_other_superposed = crystal_symmetry.unit_cell().orthogonalize(
    sites_frac=sites_frac_other_superposed)
  #
  # Replace original coordinates with transformed coordinates.
  #
  pdb_objs[1].atoms.set_xyz(new_xyz=sites_cart_other_superposed)
  #
  # Write (selected) transformed coordinates.
  #
  pdb_hierarchy = pdb_objs[1].construct_hierarchy()
  if (params.output.atom_selection is not None):
    sel = pdb_hierarchy.atom_selection_cache().selection(
      params.output.atom_selection)
    pdb_hierarchy = pdb_hierarchy.select(atom_selection=sel)
  pdb_hierarchy.write_pdb_file(
    file_name=params.output.file_name,
    crystal_symmetry=crystal_symmetry,
    append_end=True,
    atoms_reset_serial_first_value=1)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/pdb_add_conformations.py
"""This utility will duplicate any set of atoms (by default, the
    entire input model) to create alternate conformations.
"""

from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME iotbx.pdb.add_conformations

import libtbx.phil
from libtbx import runtime_utils
from libtbx.utils import Sorry, Usage
import libtbx.load_env # import dependency
import string
import os
import sys
from six.moves import range
from six.moves import zip

master_phil = libtbx.phil.parse("""
add_conformations
  .caption = This utility will duplicate any set of atoms (by default, the \
    entire input model) to create alternate conformations.  If the new \
    occupancy is not specified, it will be split evently between each \
    conformation.  Please be aware that if alternate conformations or \
    reduced-occupancy atoms are already present in the starting model, the \
    program behavior is not well-defined, and it may fail.
  .style = auto_align caption_img:icons/custom/iotbx.pdb.add_conformations64.png
{
  pdb_file = None
    .type = path
    .short_caption = PDB file
    .style = bold file_type:pdb noauto
  atom_selection = None
    .type = str
    .input_size = 400
    .style = bold noauto
  output = None
    .type = path
    .short_caption = Output file
    .style = bold file_type:pdb new_file noauto
  n_confs = 2
    .type = int
    .short_caption = Total number of conformations
    .style = bold spinner min:2 max:16 noauto
  new_occ = None
    .type = float
    .short_caption = New occupancy
    .style = noauto
  new_altloc = B
    .type = str
    .short_caption = Start at altloc
    .input_size = 64
    .style = noauto
  include scope libtbx.phil.interface.tracking_params
}
""", process_includes=True)
master_params = master_phil # XXX backwards compatibility for phenix gui

def run(args=(), params=None, out=sys.stdout):
  if (len(args) == 0) and (params is None):
    raise Usage("iotbx.pdb.add_conformations model.pdb [selection=...]\n"+
      "Full parameters:\n" + master_phil.as_str())
  from iotbx import file_reader
  import iotbx.pdb
  pdb_in = None
  if (params is None):
    user_phil = []
    interpreter = master_phil.command_line_argument_interpreter(
      home_scope="")
    for arg in args :
      if os.path.isfile(arg):
        f = file_reader.any_file(os.path.abspath(arg))
        if (f.file_type == "pdb"):
          pdb_in = f.file_object.input
          hierarchy = f.file_object.hierarchy
          user_phil.append(libtbx.phil.parse(
            "add_conformations.pdb_file=\"%s\"" % f.file_name))
        elif (f.file_type == "phil"):
          user_phil.append(f.file_object)
        else :
          raise Sorry("Unknown file type '%s' (%s)" % (f.file_type, arg))
      else :
        try :
          arg_phil = interpreter.process(arg=arg)
        except RuntimeError as e :
          raise Sorry("Error parsing '%s': %s" % (arg, str(e)))
        else :
          user_phil.append(arg_phil)
    params = master_phil.fetch(sources=user_phil).extract()
  validate_params(params)
  params = params.add_conformations
  if (pdb_in is None):
    pdb_in = iotbx.pdb.input(params.pdb_file)
    hierarchy = pdb_in.construct_hierarchy()
  if (params.new_occ is None):
    params.new_occ = 1.0 / params.n_confs
    print("Setting new occupancy to %.2f" % params.new_occ, file=out)
  from scitbx.array_family import flex
  all_atoms = hierarchy.atoms()
  all_atoms.reset_i_seq()
  n_atoms = all_atoms.size()
  if (params.atom_selection is not None):
    cache = hierarchy.atom_selection_cache()
    selection = cache.selection(params.atom_selection).as_int()
    if (selection.count(1) == 0):
      raise Sorry("Empty selection.")
  else :
    selection = flex.int(n_atoms, 1)
  for i_seq, atom in enumerate(all_atoms):
    atom.tmp = selection[i_seq]
  for model in hierarchy.models():
    for chain in model.chains():
      n_confs = len(chain.conformers())
      for residue_group in chain.residue_groups():
        i_ag = 0
        for atom_group in residue_group.atom_groups():
          old_atoms = atom_group.atoms()
          flags = old_atoms.extract_tmp_as_size_t()
          if (flags.count(1) > 0):
            if (atom_group.altloc != ""):
              if (n_confs > 0):
                atoms_err = [ a.format_atom_record() for a in old_atoms ]
                raise Sorry("Atom group included in selection already has one "+
                  "or more alternate conformers:\n" + "\n".join(atoms_err))
              elif (atom_group.altloc == params.new_altloc):
                atoms_err = [ a.format_atom_record() for a in old_atoms ]
                raise Sorry("Atom group included in selection has an altloc "+
                  "identical to the new_altloc parameter:\n" +
                  "\n".join(atoms_err))
            else :
              atom_group.altloc = "A"
            old_occ = old_atoms.extract_occ()
            new_altloc = params.new_altloc
            for n in range(params.n_confs - 1):
              new_group = atom_group.detached_copy()
              new_group.altloc = new_altloc
              if (flags.count(0) > 0):
                j_atom = 0
                k_atom = 0
                for atom in new_group.atoms():
                  if (atom.tmp == 0):
                    new_group.remove_atom(j_atom)
                  else :
                    atom.set_occ(params.new_occ)
                    old_atoms[k_atom].set_occ(old_occ[k_atom] - params.new_occ)
                    j_atom += 1
                  k_atom += 1
              else :
                for old_atom, new_atom in zip(old_atoms, new_group.atoms()):
                  old_occ = old_atom.occ - params.new_occ
                  if (old_occ == 0):
                    print("WARNING: zero-occupancy atom:", file=out)
                    print(old_atom.format_atom_record(), file=out)
                  elif (old_occ < 0):
                    raise Sorry("Atom occupancy dropped below zero:\n" +
                      old_atom.format_atom_record() + "\nnew_occ may be set "+
                      "too high.")
                  old_atom.set_occ(old_atom.occ - params.new_occ)
                  new_atom.set_occ(params.new_occ)
              assert (new_group.atoms_size() == flags.count(1))
              residue_group.insert_atom_group(i_ag + 1, new_group)
              i_ag += 1
              new_altloc = increment_altloc(new_altloc)
          i_ag += 1
  n_atoms_new = hierarchy.atoms_size()
  hierarchy.atoms().reset_i_seq()
  hierarchy.atoms_reset_serial()
  if (params.output is None):
    base_name = os.path.basename(params.pdb_file)
    params.output = os.path.splitext(base_name)[0] + "_split.pdb"
  f = open(params.output, "w")
  f.write("\n".join(pdb_in.crystallographic_section()) + "\n")
  f.write(hierarchy.as_pdb_string())
  f.close()
  print("Old model: %d atoms" % n_atoms, file=out)
  print("Modified model: %d atoms" % n_atoms_new, file=out)
  print("Wrote %s" % params.output, file=out)
  return params.output

def increment_altloc(altloc):
  if altloc.isupper():
    letters = string.ascii_uppercase
  elif altloc.islower():
    letters = string.ascii_lowercase
  elif altloc.isdigit():
    letters = string.digits
  else :
    raise Sorry("altloc must be a letter or digit.")
  i = letters.index(altloc) + 1
  if (i == len(letters)):
    raise RuntimeError("Uh-oh, out of altlocs.")
  return letters[i]

def validate_params(params):
  params = params.add_conformations
  if (params.pdb_file is None):
    raise Sorry("Please specify a PDB file!")
  if (params.new_altloc is None) or (len(params.new_altloc) != 1):
    raise Sorry("new_altloc must be a single character (e.g. 'B')")
  if (params.n_confs < 2):
    raise Sorry("Number of conformations must be at least 2!")
  if (params.new_occ is None):
    params.new_occ = 1.0 / params.n_confs
    #print >> out, "Setting new occupancy to %.2f" % params.new_occ
  if (params.new_occ < 0) or (params.new_occ > 1):
    raise Sorry("new_occ must be between 0 and 1.0")
  return True

class launcher(runtime_utils.target_with_save_result):
  def run(self):
    return run(args=list(self.args), out=sys.stdout)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/pdb_as_cif.py
"""Convert PDB formatted model to mmCIF"""
# LIBTBX_SET_DISPATCHER_NAME phenix.pdb_as_cif
from __future__ import absolute_import, division, print_function

from iotbx.cli_parser import run_program
from mmtbx.programs import pdb_as_cif

if __name__ == '__main__':
  run_program(program_class=pdb_as_cif.Program)


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/pdb_as_fasta.py
"""Create fasta sequence file from a model file (PDB or mmCIF format)"""

from __future__ import absolute_import, division, print_function
import libtbx.phil
from libtbx.utils import Sorry
import sys, os, re

def run(args=(), params=None, out=sys.stdout):
  import iotbx.pdb
  import iotbx.phil
  if (params is None):
    cmdline = iotbx.phil.process_command_line_with_files(
      args=args,
      master_phil_string=master_phil_str_template % "None",
      pdb_file_def="pdb_as_fasta.file_name")
    params = cmdline.work.extract()
    validate_params(params)
  params = params.pdb_as_fasta
  fasta_seqs = []
  for pdb_file in params.file_name :
    name_base = ""
    if (len(params.file_name) > 1):
      name_base = "%s " % os.path.splitext(os.path.basename(pdb_file))[0]
    assert os.path.isfile(pdb_file)
    pdb_obj = iotbx.pdb.input(file_name=pdb_file)
    hierarchy = pdb_obj.construct_hierarchy()
    for model in hierarchy.models():
      for chain in model.chains():
        if (chain.is_protein() or chain.is_na(min_content=0.5)):
          if (params.pad_missing_residues):
            seq = chain.as_padded_sequence(
              skip_insertions=(not params.include_insertion_residues))
          elif (not params.include_insertion_residues):
            seq = chain.as_padded_sequence(skip_insertions=True,
              pad=False)
          else :
            seq = "".join(chain.as_sequence())
          if (params.ignore_missing_residues_at_start):
            seq = re.sub("^X*", "", seq)
          seq_lines = []
          k = 0
          while (k < len(seq)):
            if ((k % 70) == 0):
              seq_lines.append("")
            seq_lines[-1] += seq[k]
            k += 1
          seq = "\n".join(seq_lines)
          fasta_seqs.append(">%schain '%2s'\n%s" % (name_base,chain.id, seq))
  if (params.output_file is not None):
    f = open(params.output_file, "w")
    f.write("\n".join(fasta_seqs))
    f.close()
  else :
    print("\n".join(fasta_seqs))
  return params.output_file

def validate_params(params):
  if (len(params.pdb_as_fasta.file_name) == 0):
    raise Sorry("No PDB files defined!")

master_phil_str_template = """
pdb_as_fasta
  .short_caption = Extract sequence from PDB file(s)
  .caption = Only protein and nucleic acid chains are supported by this \
    program.  Except for selenomethionine (MSE), non-standard residues and \
    bases will be replaced by 'X' and 'N', respectively.
  .style = caption_img:icons/custom/phenix.pdbtools.png
{
  file_name = None
    .type = path
    .multiple = True
    .short_caption = PDB file
    .style = bold noauto file_type:pdb
  output_file = %s
    .type = path
    .style = bold noauto file_type:seq new_file
  pad_missing_residues = True
    .type = bool
    .short_caption = \"\"\"Use 'X' in place of missing residues\"\"\"
    .style = bold noauto
  ignore_missing_residues_at_start = False
    .type = bool
    .style = bold noauto
  include_insertion_residues = True
    .type = bool
    .short_caption = Include insertion residues
    .style = bold noauto
}
"""

# XXX for phenix gui
master_phil = libtbx.phil.parse(master_phil_str_template % "pdb_sequences.fa")

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/pdb_cif_conversion.py
"""Information on PDB to CIF conversion process"""

from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.pdb_cif_conversion

info_string = '''

===========================================================================
===========================================================================
CCTBX methods, tools, and strategies for conversion of PDB-format
based methods to mmCIF/PDB compatible methods
2024-01-30 2024-02-01 TT
===========================================================================
===========================================================================
       SECTIONS:

   SUMMARY OF RECOMMENDED PROCEDURES
   GOALS
   RECOMMENDED OVERALL APPROACHES
   DETAILED SUGGESTIONS FOR MAKING CODE CIF-COMPLIANT
     USING THE PROGRAM TEMPLATE TO HANDLE PDB/MMCIF INPUT/OUTPUT
     REWRITING CODE USING PDB-FORMATTED TEXT
     TOOLS AVAILABLE TO FIND CODE THAT NEEDS TO BE MADE CIF-COMPATIBLE
     CREATING CIF TESTS TO CHECK CODE WITH MODELS THAT CANNOT FIT IN PDB FORMAT
   DETAILS OF METHODS ADDED FOR WORKING WITH PDB/CIF
   APPENDIX:  TOOLS FOR EXCEPTIONAL CASES
     USING FORWARD-COMPATIBLE PDB FORMAT FOR CODE REQUIRING PDB-FORMATTED TEXT
     TOOLS AVAILABLE IF YOU CANNOT USE THE PROGRAM TEMPLATE

===========================================================================
===========================================================================

SUMMARY OF RECOMMENDED PROCEDURES

I.    USE THE PROGRAM TEMPLATE
II.   IF CODE USES PDB-FORMATTED TEXT IT SHOULD BE REWRITTEN
III.  TOOLS ARE AVAILABLE TO FIND CODE THAT NEEDS TO BE MADE CIF-COMPATIBLE
IV.   CREATE CIF TESTS TO CHECK CODE WITH MODELS THAT CANNOT FIT IN PDB FORMAT

===========================================================================
===========================================================================

GOALS:

I. Read, write and work with models in mmCIF or PDB format interchangeably if
   models fit in PDB format, otherwise read and write only in mmCIF. In
   exceptional circumstances, allow read/write of forward-compatible PDB files
   representing models that do not fit in PDB format.

II. Use the cctbx hierarchy and model objects to contain and work with
   all models

III. Write mmCIF or PDB-formatted files with the rules:
   a. Write as PDB with extension '.pdb' if output model fits in PDB format and,
     1. User specifies PDB format, or,
     2. User does not specify format and either there is no input model or it is
        PDB format
   b. Write as mmCIF, with extension '.cif', if
     1. Output model does not fit in PDB format, or
     2. User specifies mmCIF, or
     3. Input model is mmCIF and User does not specify which to use
===========================================================================
===========================================================================
         RECOMMENDED OVERALL APPROACHES
===========================================================================
===========================================================================

  (DETAILS IN THE SECTION "DETAILED SUGGESTIONS FOR MAKING CODE CIF-COMPLIANT")

I. USE THE PROGRAM TEMPLATE

Use the Program Template and its data_manager to carry out all read/write
and parsing of model files. If you do this then all mmCIF/PDB handling is
taken care of for you, except only that you need to capture the actual
file names written by the data_manager.

II. IF CODE USES PDB-FORMATTED TEXT IT SHOULD BE REWRITTEN

If code parses PDB-formatted text, generally it should be rewritten
to use the methods in the hierarchy class.

  a. For example, code that edits formatted strings representing a PDB file
    to remove HETATM records can be replaced with the method
    remove_hetero() of the hierarchy class.

  b. All code that accumulates lines from multiple PDB files and then interprets
    the new lines should be replaced by reading each PDB file and merging
    the resulting hierarchies or models.  This can be done for model files
    with the add_models or add_hierarchies methods available in
    iotbx.pdb.utils, or simple custom code can be written to add chains
    from one hierarchy onto another hierarchy.

III.  TOOLS ARE AVAILABLE TO FIND CODE THAT NEEDS TO BE MADE CIF-COMPATIBLE
    You can find possibly-problematic code using the tool
    libtbx.find_pdb_mmcif_problems and specifying a file or directory to check

IV.  CREATE CIF TESTS TO CHECK CODE WITH MODELS THAT CANNOT FIT IN PDB FORMAT
    For any code that uses pdb/cif files or that uses the hierarchy object
    should be tested with models that do not fit in PDB format.  It is
    recommended that each standard test using models should either be
    duplicated  and run with non-PDB-compliant models, or run twice in the
    same script, once as-is, and once after converting models to
    non-PDB-compliant models.  The tool convert_pdb_to_cif_for_pdb_str
    can be used to edit strings in place in tests so that identical
    starting strings can be used in the original and non-PDB-compliant tests.

===========================================================================
===========================================================================
        DETAILED SUGGESTIONS FOR MAKING CODE CIF-COMPLIANT
===========================================================================
===========================================================================

I. USING THE PROGRAM TEMPLATE TO HANDLE PDB/MMCIF INPUT/OUTPUT

A. Use the Program Template and use data_manager for
    all model read/write. If you do this there is only one thing
    you need to do:  capture the actual file name written by
    the data_manager.

    The program template automatically adds the scope
    'output.target_output_format' to your parameters, allowing
    a user to set the output format. If it is not set, the program
    template sets it to the format of the default incoming model if
    present, otherwise to 'pdb'.

  def run(self):
    ...
    self.final_file_name = self.data_manager.write_model_file(
        model, self.params.output.file_name)
    print("Final model written to '%s'" %self.final_file_name)

  def get_results(self):
    return group_args(
      output_file_name = self.final_file_name,
      ...)

---------------------------------------------------------------------------
---------------------------------------------------------------------------
II.  REWRITING CODE USING PDB-FORMATTED TEXT

A. You will want to remove all instances of the following methods. None of these
are mmcif-compliant:

  model.model_as_pdb()
  ph.as_pdb_string()
  ph.write_pdb_file()

The best replacement in all cases is to use the Program template, pass
the data_manager into any modules that write out models, and
use the data_manager to write your model files. If you only have a
hierarchy you can still say:

  m = hierarchy.as_model_manager(crystal_symmetry = crystal_symmetry)
  file_name = 'mypdb.pdb'
  file_name = data_manager.write_model_file(m, file_name)

If for some reason you cannot use the data_manager to write files,
here are some alternatives:

  1. If your code uses model.model_as_pdb() like this:

    file_name = 'mypdb.pdb'
    str = model.model_as_pdb()
    f = open(file_name,'w')
    print(str, file = f)
    f.close()
    print("Wrote model to '%s'" %file_name)

  then get a data_manager and use it instead:

    file_name = 'mypdb.pdb'
    from iotbx.data_manager import DataManager
    dm = DataManager()
    dm.set_overwrite(True)
    file_name = dm.write_model_file(model,
        filename = file_name,
        format = params.output.target_output_format)
    print("Wrote model to '%s'" %file_name)

  2. If your code uses ph.as_pdb_string() and you need the string:

    file_name = 'mypdb.pdb'
    str = ph.as_pdb_string()
    print("Doing something with a string %s" %str)

  Use instead ph.as_pdb_or_mmcif_string() which will give you a PDB or
     mmcif string as appropriate:

    str = ph.as_pdb_or_mmcif_string(
        target_format = params.output.target_output_format)
    print("Doing something with a string %s" %str)

  3. If your code uses ph.as_pdb_string() or ph.write_pdb_file() and you are
    writing the string to a file like this:

    file_name = 'mypdb.pdb'
    str = ph.as_pdb_string(crystal_symmetry = crystal_symmetry)
    f = open(file_name,'w')
    print(str, file = f)
    f.close()
    print("Wrote model to '%s'" %file_name)

   or like this:

    file_name = 'mypdb.pdb'
    str = ph.write_model_file(file_name)
    print("Wrote model to '%s'" %file_name)

   Use instead write_pdb_or_mmcif_file:

    file_name = 'mypdb.pdb'
    file_name = ph.write_pdb_or_mmcif_file(
        target_format = params.output.target_output_format,
        target_filename = file_name)
    print("Wrote model to '%s'" %file_name)

B. You will want to rewrite all code that interprets model text line-by-line.

  If your code looks like this:

  for line in open(model_file).readlines():
    do_something_based_on_a_line_in_file(line)

  You will want instead to read in the model to get a hierarchy, then
  use hierarchy methods to change or interpret the hierarchy.

C. If your code catenates model text like this:

    new_file_name = 'combined.pdb'
    raw_records = list(open(model_file).splitlines())
    raw_records += list(open(other_model_file).splitlines())
    f = open(new_file_name,'w')
    print(raw_records, file = f)
    f.close()
    print("Wrote combined model lines to '%s'" %new_file_name)

   You will want to rewrite it to read in the models and then merge them:

    new_file_name = 'combined.pdb'
    m1 = dm.get_model_file(model_file)
    m2 = dm.get_model_file(other_model_file)
    from iotbx.pdb.utils import add_models
    m1 = add_models(model_list = [m1,m2])
    new_file_name = dm.write_model_file(m1, new_file_name) # capture actual name
    print("Wrote combined model lines to '%s'" %new_file_name)

   Note: you can also merge hierarchies directly with the add_hierarchies method
   in iotbx.pdb.utils

D. If your code names intermediate files with the extension '.pdb':

    new_file_name = 'model.pdb'
    f = open(new_file_name,'w')
    print(model.model_as_pdb(), file = f)
    f.close()
    print("Wrote intermediate model lines to '%s'" %new_file_name)

  Use the data_manager to write the file, and
    capture the actual file name so that you can use it when you read the
    contents of the file back in.

    new_file_name = 'model.pdb'
    new_file_name = dm.write_model_file(model, new_file_name)
    print("Wrote intermediate model lines to '%s'" %new_file_name)


---------------------------------------------------------------------------
---------------------------------------------------------------------------
III.   TOOLS AVAILABLE TO FIND CODE THAT NEEDS TO BE MADE CIF-COMPATIBLE

A.    You can use the libtbx.find_pdb_mmcif_problems to help identify code
   that needs to be modified to make it cif-compatible.

   You can say:

   libtbx.find_pdb_mmcif_problems phenix/phenix/command_line

   and it (recursively) will go through all files/directories in command_line
   and look for problems

   Or you can work on just one file:

   libtbx.find_pdb_mmcif_problems phase_and_build.py

   ====================================================================
   ==>> Here is a **SUPER-HELPFUL HINT** to make the editing easy: <<==
   ====================================================================

B.   Run libtbx.find_pdb_mmcif_problems with the argument "mark_lines":

   1. Run it like this:

      libtbx.find_pdb_mmcif_problems phase_and_build.py mark_lines

   This will edit phase_and_build.py, placing text like:
     " # XXX CHECK PDB: .pdb'"
   at the end of possibly-problematic lines

   2. Then you just edit this file (phase_and_build.py)
     a. find all the places where "CHECK PDB" shows up
     b. fix the problems
     c. mark non-problems with the text " # PDB OK", add explanation if you want

   3. Then clean up by running:

      libtbx.find_pdb_mmcif_problems phase_and_build.py unmark_lines

    which will remove all the " # XXX CHECK PDB" text

   4. Finally, run:

      libtbx.find_pdb_mmcif_problems phase_and_build.py

    again to make sure you got it all.

C. You can run libtbx.find_pdb_mmcif_problems with a file containing a list
  of files:

  1. Put list of your files/directories and put them in files.list:
   files.list:
     phenix/phenix/programs/myfile.py
     phenix/phenix/mydir
   2. Mark/unmark all likely PDB problems in your files
    libtbx.find_pdb_mmcif_problems files.list mark_lines
    libtbx.find_pdb_mmcif_problems files.list unmark_lines

---------------------------------------------------------------------------
---------------------------------------------------------------------------
IV.  CREATING CIF TESTS TO CHECK CODE WITH MODELS THAT CANNOT FIT IN PDB FORMAT

  You will want to create a cif-only version of all your tests that use
  models.  This can be done for some tests just by adding a few lines of
  code at the end of the test where the methods in the test script are
  called.  The purpose of the extra testing is to test all the code that handles
  chain IDs and residue names.

A. Simple conversion of tests to mmCIF if your test uses PDB strings.
   If your test has PDB strings like: pdb_str_1 = """pdb-text""" at the
   top of the file, you can make a small change at the end of your script
   to run mmCIF tests.

   Suppose the end of your script looks like:

if __name__=="__main__":
    tst_01()
    tst_02()

  Then just paste all this in, and indent the tst_01() if necessary:

if __name__=="__main__":
  for as_cif in (False, True):  # XXX as_cif is one way so True must be last
    if as_cif:
      print("\n CONVERTING PDB STRINGS TO CIF AND CHANGING "+
         "CHAIN ID/HETATM RESIDUE NAMES\n")
      # Convert to mmcif and make long chain ID and HETATM resname:
      from libtbx.test_utils import convert_pdb_to_cif_for_pdb_str
      convert_pdb_to_cif_for_pdb_str(locals())
    else:
      print("\n USING PDB STRINGS AS IS\n")

    tst_01()
    tst_02()

  This will run tst_01 and tst_02 twice. The first time is as usual. The
  second time all the pdb_str_xxxx text strings will be converted to mmCIF
  format and chain names and HETATM residue names will be made incompatible
  with PDB format.

  If your test just produces numbers, the two versions of the tests should
  give identical results and no other changes are necessary. If the test
  depends on chain ID or on residue names, then it may be necessary to
  pass in the value of "as_cif=as_cif" and have different checks in it
  for each case.

B. If your test uses models in PDB files, you may simply want to
 make copies of all your models, converting your PDB files into
  mmCIF and edit the chain IDs:

  You can do this with pdbtools:

  phenix.pdbtools x.pdb output.file_name=x.cif old_id=A new_id=AXZLONG

 to make them longer than 2 characters.  If you want, edit
  the HETATM records to change the residue names too.

 Then make a new test tst_xxxx_cif.py that uses these PDB files.
 Note: make sure you rename any restraints file to xxx_restraints.cif
   so you don't overwrite xxx.cif with the new cif-formatted version
   of xxx.pdb

===========================================================================
===========================================================================
   DETAILS OF METHODS ADDED FOR WORKING WITH PDB/CIF
===========================================================================
===========================================================================

     MODULE:    iotbx/cli_parser.py

Method to return the parameters as set up by the data_manager:

def get_program_params(run)

     MODULE: iotbx/data_manager/model.py

Method to set the desired output format for model files, based on user
specification and the format of the default input model file:

 def set_target_output_format(self, target_output_format):

Modified write_model_file method to check whether output model fits in PDB
format and to write as mmCIF it does not, or if the user specified cif as the
output format.

 def write_model_file(self, model_str, filename=Auto, format=Auto,


     MODULE:    iotbx/pdb/hierarchy.py:

Methods for converting hierarchy to forward-compatible (fits in PDB format,
  see above):

  def is_forward_compatible_hierarchy(self):
  def conversion_info(self):
  def convert_multi_word_text_to_forward_compatible(self, text):
  def as_forward_compatible_hierarchy(self, conversion_info = None):
  def forward_compatible_hierarchy_as_standard(self, conversion_info = None):
  def as_forward_compatible_string(self, **kw):

Method for writing as PDB or mmCIF string, using supplied target_format if
possible, returning file name written:

  def write_pdb_or_mmcif_file(self,

Method for obtaining a PDB or mmCIF string, using supplied target_format if
possible, returning the string:

  def as_pdb_or_mmcif_string(self,

NOTE: This method and the corresponding method in model.py use
default of segid_as_auth_segid = False, same as the default in
model_as_mmcif() in model.py and as_mmcif_string() in hierarchy.py
A value of segid_as_auth_segid = True causes any text in the SEGID
field read from a PDB-formatted file to be written to the auth_segid field
in the mmCIF output, and the chain ID from the PDB file is used as
the actual chain ID in the mmCIF output.

Methods supplied so that code elsewhere does not need to parse PDB formatted
strings to remove HETATM, TER, and BREAK records and to sort chains in order
of chain ID, and to guess the element type of atoms where it is not specified:

  def remove_hetero(self):
  def contains_hetero(self):
  def contains_break_records(self):
  def remove_ter_or_break(self):
  def sort_chains_by_id(self):
  def guess_chemical_elements(self, check_pseudo = False,

     MODULE:    mmtbx/model/model.py:

Method for obtaining a PDB or mmCIF string, using supplied target_format if
possible, returning the string:

  def as_pdb_or_mmcif_string(self,

NOTE: This method and the corresponding method in hierarchy.py use
default of segid_as_auth_segid = False , same as the default in
model_as_mmcif() in model.py and as_mmcif_string() in hierarchy.py.
A value of segid_as_auth_segid = True causes any text in the SEGID
field read from a PDB-formatted file to be written to the auth_segid field
in the mmCIF output, and the chain ID from the PDB file is used as
the actual chain ID in the mmCIF output.

     MODULE:   iotbx/pdb/utils.py:

Methods to set the target_output_format parameter in the scope output:

def set_target_output_format_in_params(params,
def get_input_model_file_name_from_params(params):
def target_output_format_in_params(params):
def get_target_output_format_from_file_name(file_name,
def move_down_scope_to_input_files(params, levels = 3):

Method to find file named with 'pdb' or 'cif' when given one or the other.
Returns the file supplied if present, otherwise the other file if it is present,
otherwise empty string. Can find files with the pdb/cif followed by an
underscore such as myfile.pdb_1. Only looks for pdb/cif in the extension:

def get_cif_or_pdb_file_if_present(file_name):

Methods to merge hierarchies:

def add_hierarchies(hierarchies, create_new_chain_ids_if_necessary = True):
def add_hierarchy(hierarchy, other, create_new_chain_ids_if_necessary = True):
def catenate_segment_onto_chain(chain, model, gap = 1,
def get_chain(hierarchy, chain_id = None):


Methods to merge and edit models:

def catenate_segments(model, other, gap = 1,
def catenate_segment_onto_chain(model_chain, s2, gap = 1,
def add_models(model_list,
def add_model(model, other, create_new_chain_ids_if_necessary = True):

Method to keep track of the relative numbering of models with
similar hierarchies:

class numbering_dict:

Method to get hierarchy and pdb_input objects from text files. These differ
from iotbx.pdb.input() and construct_hierarchy() by allowing empty text
for both mmCIF and PDB input, and in packaging a hierarchy, pdb_input, and
crystal_symmetry in a single group_args object that is returned

Normal use:  pdb_info = get_pdb_info(file_name = file_name)

def get_pdb_info(text = None, file_name = None, lines = None,

Shortcuts to get just hierarchy or pdb_input:

def get_pdb_hierarchy(text=None, file_name = None,
def get_pdb_input(text = None, file_name = None, lines = None,

Helper methods for reading pdb_input text and getting hierarchy,
allowing input of models that have incomplete or incorrect
atom and element specifications

def lines_are_really_text(lines):
def get_lines(text = None, file_name = None, lines = None):
def type_of_pdb_input(pdb_inp):
def try_to_get_hierarchy(pdb_inp):

Methods to check for missing elements and incorrect spacings in
atom names in a hierarchy:

def check_for_missing_elements(hierarchy, file_name = None):
def set_element_ignoring_spacings(hierarchy):

Method checking for atom names starting with "Z" (used as pseudo-atoms)

def check_for_pseudo_atoms(atoms):


     MODULE:   iotbx/pdb/forward_compatible_pdb_cif_conversion.py

This module has low-level methods for conversion of hierarchies to a PDB-compatible
form, for reading and writing these hierarchies, and for converting them
back to the original form.

Normally the methods in the hierarchy class should be used, rather
than using these low-level methods directly.

The methods available are:

  def __init__(self, hierarchy = None,
  def is_initialized(self):
  def conversion_required(self):
  def conversion_as_remark_hetnam_string(self):
  def convert_hierarchy_to_forward_compatible_pdb_representation(self,
  def convert_hierarchy_to_full_representation(self, hierarchy):
  def set_conversion_tables_from_remark_hetnam_records(
  def _set_up_conversion_table(self, key, hierarchy, unique_values_dict = None):
  def _unique_chain_ids_from_hierarchy(self, hierarchy):
  def _unique_resnames_from_hierarchy(self, hierarchy):
  def _get_any_forward_compatible_pdb_representation(self,
  def _get_forward_compatible_pdb_representation(self, ids, max_chars,
  def _get_new_unique_id(self, id, max_chars, exclude_list,
  def _get_new_id(self, n_chars, exclude_list, end_with_tilde = None,
  def _choose_allowed_ids(self, unique_values, max_chars):
  def _is_allowed(self, u, max_chars):
  def _get_conversion_table_info(self, key):
  def get_full_text_from_forward_compatible_pdb_text(self, key = None,
  def convert_multi_word_text_to_forward_compatible(self,
  def get_forward_compatible_pdb_text_from_full_text(self,


===========================================================================
===========================================================================
           APPENDIX:  TOOLS FOR EXCEPTIONAL CASES
===========================================================================
===========================================================================

I. TOOLS AVAILABLE IF YOU CANNOT USE THE PROGRAM TEMPLATE

For existing code that cannot use the Program Template or that
reads and writes files outside of the Program Template:

  a.  Try to pass the data_manager from the Program Template and use
     it to read/write files in your programs. Then once again you only
     need to capture the actual file names written by the data_manager.

  b. If you cannot use the data_manager, use the write_pdb_or_mmcif_file
     method of the hierarchy to write your files.
     This method allows setting the preferred output format and capturing
     the name of the actual file that is written.

     Normally you should keep track of the actual file name that is written
     and then use that later when you read the file back in.  If you do
     not use this approach, you can use the get_cif_or_pdb_file_if_present
     tool from iotbx.pdb.utils with your guess of the file name, and it will
     return the name of the file with that name if present, or the name of a
     present file with the opposite extension if it is present instead,
     or blank if neither is present.

     You can use the get_pdb_info tool from iotbx.pdb.utils or the
     iotbx.pdb.input method to read in either mmCIF or PDB formatted files.

Here is how you can do these things.  Note that this only applies for
modules that really cannot use the Program template.

1. Add target_output_format to your "output" scope (if you do not have
    an output scope and have an output_files scope, that is allowed
    but not recommended):

     target_output_format = *None pdb mmcif
       .type = choice
       .help = Desired output format (if possible). Choices are None (\
                try to use input format), pdb, mmcif.  If output model\
                 does not fit in pdb format, mmcif will be used. \
                 Default is pdb.
       .short_caption = Desired output format

2. After you set up your parameters, set the target_output_format:

  from iotbx.pdb.utils import set_target_output_format_in_params
  set_target_output_format_in_params(params)

3. When you write model files, supply the target output format and
  capture the actual file name written:

a. If you have a data manager and a model object:

  file_name = self.data_manager.write_model_file(
        model, self.params.output.file_name)
  print("Model written to '%s'" %file_name)

b. If have only a hierarchy and crystal_symmetry and params:

  file_name = ph.write_pdb_or_mmcif_file(
           target_format = params.output.target_output_format,
           target_filename = params.output.file_name,
           crystal_symmetry=crystal_symmetry)
  print("Model written to '%s'" %file_name)

c. When you read pdb/mmcif files, if you do not know the ending .pdb or
     .mmcif, use the function get_cif_or_pdb_file_if_present:

   from iotbx.pdb.utils import get_cif_or_pdb_file_if_present
   fn = get_cif_or_pdb_file_if_present(fn)

---------------------------------------------------------------------------
---------------------------------------------------------------------------

II.  USING FORWARD-COMPATIBLE PDB FORMAT FOR CODE REQUIRING PDB-FORMATTED TEXT

If you have code or 3rd party code that requires PDB-formatted text you can
convert any hierarchy into a forward-compatible hierarchy that can be
formatted in PDB format (hybrid-36 PDB format).  This conversion (currently)
amounts to replacing chainIDs that are longer than 2 characters with
2-character IDs, and residue names that are 5 characters long with
3-character residue names.  A table of conversions is kept that allows
reversion of the hierarchy to its original form.

a.  This procedure is only partially supported and is not encouraged for
   anything except cases that cannot be managed without PDB formatting.

b.  When this is done, it should be carried out either one-way (conversion
    to forward-compatible PDB and never converted back), or else the
    conversion should be carried out, the operation with the converted file
    done, and the result converted back, all in one small block.

c.  Note that conversion may be very complicated if the chain IDs or the
    residue names are needed in whatever operation is done with the
    converted file. This is one of the reasons this approach is not
    recommended except where required. Tools are supplied to convert
    any text-based parameters are used with the converted file, but they
    are not general and not always simple to use.

d.  The hierarchy class has tools to convert a hierarchy that cannot fit into
   PDB format into one that can and to keep track of the conversion so that
   it can be reversed.

  The main tools are:

  1. Convert a hierarchy to one that fits in PDB format, saving conversion
     information
    fc_ph = ph.as_forward_compatible_hierarchy()

  2. Get the conversion information:
    conversion_info = fc_ph.conversion_info()

  3. Convert back using saved conversion info :
    original_ph = fc_ph.forward_compatible_hierarchy_as_standard()

  4. Convert one-way to PDB format compatible string:
    str =  ph.as_forward_compatible_string()

  5. Identify whether hierarchy has been converted:
    is_fc = ph.is_forward_compatible_hierarchy()

  6. Use saved conversion_info to edit text containing words matching
     chain IDs or residue names, making new text match the chain IDs and
     residue names used in the forward_compatible hierarchy:
    new_text = ph.convert_multi_word_text_to_forward_compatible(text)

  These methods are described in detail in the hierarchy.py code.
===========================================================================
===========================================================================




'''

def run():
  print(info_string)

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/pdb_get_citation.py
"""Given a PDB ID (and an email address, as required by the NCBI), will attempt
to identify the PubMed ID of the primary citation for the structure, download
the article XML from NCBI, and print a bibliography entry.
"""

# LIBTBX_SET_DISPATCHER_NAME iotbx.pdb.get_citation

from __future__ import absolute_import, division, print_function
from libtbx.utils import to_unicode, Sorry, Usage
from xml.dom.minidom import parseString
import sys

master_phil_string = """
pdb_id = None
  .type = str
email = None
  .type = str
"""

def run(args, out=sys.stdout):
  if (len(args) == 0) or ("--help" in args):
    raise Usage("""\
iotbx.pdb.get_citation ID EMAIL

Given a PDB ID (and an email address, as required by the NCBI), will attempt
to identify the PubMed ID of the primary citation for the structure, download
the article XML from NCBI, and print a bibliography entry.
""")
  import iotbx.pdb.fetch
  import iotbx.phil
  try :
    from Bio import Entrez
  except ImportError :
    raise Sorry("BioPython not installed.")
  class _cmdline(iotbx.phil.process_command_line_with_files):
    def process_other(self, arg):
      if (iotbx.pdb.fetch.valid_pdb_id(arg)):
        return iotbx.phil.parse("""pdb_id=%s""" % arg)
      elif (arg.count("@") == 1):
        return iotbx.phil.parse("""email=\"%s\"""" % arg)
      return False
  cmdline = _cmdline(
    args=args,
    master_phil_string=master_phil_string,
    integer_def="pmid")
  params = cmdline.work.extract()
  validate_params(params)
  # XXX should probably use mmCIF here
  pdb_data = iotbx.pdb.fetch.fetch(id=params.pdb_id)
  pmid = None
  for line in pdb_data.readlines():
    if (line.startswith("JRNL")):
      fields = line.split()
      if (fields[1] == "PMID"):
        pmid = int(fields[2].strip())
        break
  if (pmid is None):
    raise Sorry("Couldn't extract PMID from PDB header.")
  # This looks gross, but it's much safer than trying to do any more parsing
  # of unstructured text (even when using mmCIF)
  print("PMID = %s" % pmid, file=out)
  Entrez.email = params.email
  data = Entrez.efetch(db="pubmed", id=str(pmid), rettype="xml",
    retmode="text")
  def get_node_data(xml_node, node_name):
    child_nodes = xml_node.getElementsByTagName(node_name)
    return to_unicode(child_nodes[0].childNodes[0].data)
  xmlrec = parseString(data.read())
  articles = xmlrec.getElementsByTagName("PubmedArticle")
  assert (len(articles) == 1)
  article = articles[0]
  authors = article.getElementsByTagName("Author")
  author_list = []
  for author in authors :
    name = get_node_data(author, "LastName") + ", " + \
      ".".join(get_node_data(author, "Initials")) + "."
    author_list.append(name)
  people = ", ".join(author_list[:-1]) + " & " + author_list[-1]

  title = get_node_data(article, "ArticleTitle")
  if (not title.endswith(".")):
    title += "."
  date = article.getElementsByTagName("PubDate")[0]
  year = get_node_data(article, "Year")
  journal = get_node_data(article, "MedlineTA")
  volume = get_node_data(article, "Volume")
  pages = get_node_data(article, "MedlinePgn")
  # TODO other formats
  print("%s (%s).  %s %s %s, %s." % \
    (people.encode('ascii', 'ignore'), year, title.encode('ascii', 'ignore'),
     journal, volume, pages), file=out)

def validate_params(params):
  if (params.pdb_id is None):
    raise Sorry("PDB ID not specified!")
  if (params.email is None):
    raise Sorry("Please give a valid email address.")
  return True

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/pdb_labels_comparison.py
"""Compare labels in two models"""
from __future__ import absolute_import, division, print_function
def run(args):
  if (len(args) != 2):
    from libtbx.utils import Usage
    import libtbx.load_env
    raise Usage("%s first.pdb second.pdb" % libtbx.env.dispatcher_name)
  import iotbx.pdb
  inp_hier = []
  lbls_sets = []
  for file_name in args:
    pdb_inp = iotbx.pdb.input(file_name=file_name)
    print("%6d atoms in %s" % (pdb_inp.atoms().size(), file_name))
    pdb_hierarchy = pdb_inp.construct_hierarchy()
    inp_hier.append((pdb_inp, pdb_hierarchy))
      # need to keep hierarchy alive to get all labels
    lbls_set = set()
    for atom in pdb_inp.atoms():
      lbls = atom.id_str()
      if (lbls in lbls_set):
        raise RuntimeError("Duplicate atom labels: %s" % lbls)
      lbls_set.add(lbls)
    lbls_sets.append(lbls_set)
  print("%6d matching atom labels" % (
    len(lbls_sets[0].intersection(lbls_sets[1]))))
  def show_missing(i, j):
    diff = lbls_sets[j].difference(lbls_sets[i])
    print("%6d missing in %s" % (len(diff), args[i]))
    for atom in inp_hier[j][0].atoms():
      lbls = atom.id_str()
      if (lbls in diff):
        print("         %s" % lbls)
  show_missing(0, 1)
  show_missing(1, 0)

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/pdb_labels_diff.py
"""Show differences in atom labels in two models"""
from __future__ import absolute_import, division, print_function
def run(args):
  if (len(args) != 2):
    from libtbx.utils import Usage
    import libtbx.load_env
    raise Usage("%s first.pdb second.pdb" % libtbx.env.dispatcher_name)
  import iotbx.pdb
  lbls_list_pair = []
  for file_name in args:
    pdb_inp = iotbx.pdb.input(file_name=file_name)
    pdb_hierarchy = pdb_inp.construct_hierarchy()
    lbls_list = []
    for atom in pdb_inp.atoms():
      lbls_list.append(atom.id_str())
    lbls_list_pair.append("\n".join(lbls_list)+"\n")
  a, b = lbls_list_pair
  if (a != b):
    import difflib
    sys.stdout.write(
      "".join(difflib.unified_diff(a.splitlines(1), b.splitlines(1))))

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/pdb_remediator.py
"""Convert between version 2.3 and version 3.2 of the PDB format"""

from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME iotbx.pdb_remediator

import libtbx.phil
from libtbx.utils import Usage, Sorry
import os
import sys

master_phil = libtbx.phil.parse("""
remediator
  .short_caption = PDB remediation
  .caption = This utility converts between version 2.3 and version 3.2 of \
    the PDB format, which differ primarily in the treatment of hydrogen \
    atoms.  PHENIX always uses v3.2 atom names, as do recent \
    versions of Coot, Refmac, and other programs using the CCP4 monomer \
    library, but it can also interpret previous formats.  You may however \
    need to convert between formats for certain applications.  (The PDB will \
    always convert to v3.2 upon submission.)
  .style = box auto_align caption_img:icons/custom/phenix.pdbtools.png
{
  file_name = None
    .type = path
    .short_caption = PDB file
    .help = '''input coordinate file (pdb)'''
    .style = bold file_type:pdb input_file
  output_file = None
    .type = path
    .optional = True
    .help = '''Enter a .pdb output name'''
    .style = new_file file_type:pdb
  version = *3.2 2.3
    .type = choice(multi=False)
    .short_caption = Format version
  dict = None
    .type = path
    .optional = True
    .short_caption = Custom definition file
    .help = '''custom definition file'''
}
""", process_includes=True)

def run(args=(), params=None, out=sys.stdout):
  from iotbx.pdb.remediation import remediator
  from iotbx import file_reader
  if (params is None):
    interpreter = master_phil.command_line_argument_interpreter()
    pdb_file = None
    sources = []
    for arg in args :
      if os.path.isfile(arg):
        input_file = file_reader.any_file(arg)
        if (input_file.file_type == "pdb"):
          pdb_file = input_file
          sources.append(interpreter.process(arg="file_name=\"%s\"" % arg))
      else :
        arg_phil = interpreter.process(arg=arg)
        sources.append(arg_phil)
    work_phil = master_phil.fetch(sources=sources)
    work_params = work_phil.extract()
  else : # XXX for phenix GUI
    work_params = params
    if (work_params.remediator.output_file is None):
      base, ext = os.path.splitext(work_params.remediator.file_name)
      work_params.remediator.output_file = base + "_remediated.pdb"
  if (work_params.remediator.file_name is None):
    if (pdb_file is None):
      summary = remediator.Program.description
      raise Usage(summary)
    else :
      work_params.remediator.file_name = pdb_file.file_name
  params = work_params.remediator
  remediator.remediator(params)
  return work_params.remediator.output_file

def validate_params(params):
  if (params.remediator.file_name is None):
    raise Sorry("Please specify a PDB file.")
  return True

if(__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/pdb_show_connectivity.py
"""Summarize connectivity of a model"""

# LIBTBX_SET_DISPATCHER_NAME iotbx.pdb.show_connectivity

from __future__ import absolute_import, division, print_function
from libtbx.utils import Sorry, Usage
import sys

master_phil = """
pdb_file = None
  .type = path
selection = None
  .type = atom_selection
"""

def run(args, out=sys.stdout):
  def show_usage():
    raise Usage("""\
iotbx.pdb.show_connectivity model.pdb

Extracts the bondes specified by CONECT records and displays the atom IDs.""")
  if (len(args) == 0) : show_usage()
  import iotbx.pdb
  import iotbx.phil
  from scitbx.array_family import flex
  pdb_inp = None
  cmdline = iotbx.phil.process_command_line_with_files(
    args=args,
    master_phil_string=master_phil,
    pdb_file_def="pdb_file")
  params = cmdline.work.extract()
  if (params.pdb_file is None):
    show_usage()
  pdb_inp = iotbx.pdb.input(file_name=params.pdb_file)
  if (len(pdb_inp.atoms()) == 0):
    raise Sorry("'%s' is not a PDB file or does not contain any atoms." %
      params.pdb_file)
  elif (type(pdb_inp).__name__ == 'cif_input'):
    raise Sorry("Only PDB-format files are supported - mmCIF format does "+
      "not contain the necessary records.")
  bonds = pdb_inp.extract_connectivity()
  if (bonds is None):
    raise Sorry("No CONECT records found in PDB file.")
  atoms = pdb_inp.atoms()
  selection = flex.bool(len(atoms), True)
  if (params.selection is not None):
    selection = pdb_inp.construct_hierarchy().atom_selection_cache().selection(
      params.selection)
  n_bonded = 0
  for i_seq, bonded in enumerate(bonds):
    if (not selection[i_seq]) : continue
    if (len(bonded) > 0):
      n_bonded += 1
      print("%s:" % atoms[i_seq].id_str(), file=out)
      for j_seq in bonded :
        print("  %s" % atoms[j_seq].id_str(), file=out)
  if (n_bonded == 0):
    raise Sorry("No atoms with CONECT records found in selection.")

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/pdb_split_models.py
"""separate a multi-model PDB file (such as an \
    NMR ensemble) into individual files for each model.  The output files \
    will be named similarly to the input file but ending in _1.pdb, _2.pdb, \
    etc.
"""

from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME iotbx.pdb.split_models

from libtbx.utils import Sorry, Usage, null_out
import os
import sys

master_phil = """
split_models
  .short_caption = Split multi-model PDB file
  .caption = This utility will separate a multi-model PDB file (such as an \
    NMR ensemble) into individual files for each model.  The output files \
    will be named similarly to the input file but ending in _1.pdb, _2.pdb, \
    etc.
  .style = auto_align box caption_img:icons/custom/iotbx.pdb.join_fragment_files.png
{
  file_name = None
    .type = path
    .short_caption = PDB file
    .style = file_type:pdb input_file bold
  output_dir = None
    .type = path
    .short_caption = Output directory
    .style = directory default_cwd bold
}
"""

def run(args=(), params=None, out=None):
  if (out is None):
    out = sys.stdout
  if (params is None):
    if (len(args) == 0):
      raise Usage("""
iotbx.pdb.split_models ensemble.pdb [output_dir=/path/...]

Splits a multi-model PDB file into separate files for each model.
""")
    import iotbx.phil
    cmdline = iotbx.phil.process_command_line_with_files(
      args=args,
      master_phil_string=master_phil,
      pdb_file_def="split_models.file_name",
      directory_def="split_models.output_dir")
    params = cmdline.work.extract()
    validate_params(params)
  import iotbx.pdb
  pdb_in = iotbx.pdb.input(params.split_models.file_name)
  hierarchy = pdb_in.construct_hierarchy()
  if (len(hierarchy.models()) <= 1):
    raise Sorry("The PDB file %s already has a single model." %
      params.split_models.file_name)
  pdb_rel_path = os.path.basename(params.split_models.file_name)
  if (pdb_rel_path.endswith(".gz")):
    pdb_rel_path = pdb_rel_path[:-3]
  elif (pdb_rel_path.endswith(".Z")):
    pdb_rel_path = pdb_rel_path[:-2]
  base_name = os.path.splitext(pdb_rel_path)[0]
  if (params.split_models.output_dir is None):
    params.split_models.output_dir = os.getcwd()
  output_base = os.path.join(params.split_models.output_dir, base_name)
  return split_models(
    hierarchy=hierarchy,
    crystal_symmetry=pdb_in.crystal_symmetry(),
    output_base=output_base,
    original_file=params.split_models.file_name,
    log=out)

def split_models(hierarchy,
                  crystal_symmetry,
                  output_base,
                  original_file=None,
                  log=None):
  if (log is None) : log = null_out()
  import iotbx.pdb.hierarchy
  n_models = len(hierarchy.models())
  file_names = []
  for k, model in enumerate(hierarchy.models()):
    k += 1
    new_hierarchy = iotbx.pdb.hierarchy.root()
    new_hierarchy.append_model(model.detached_copy())
    if (model.id == ""):
      model_id = str(k)
    else :
      model_id = model.id.strip()
    output_file = "%s_%s.pdb" % (output_base, model_id)
    final_fname = new_hierarchy.write_pdb_or_mmcif_file(
        target_filename=output_file,
        crystal_symmetry=crystal_symmetry)
    file_names.append(final_fname)
    print("Wrote %s" % final_fname, file=log)
  return file_names

def validate_params(params):
  if (params.split_models.file_name is None):
    raise Sorry("Please specify a PDB file to split!")
  elif (not os.path.isfile(params.split_models.file_name)):
    raise Sorry("The PDB file '%s' does not exist or is not a file." %
      params.split_models.file_name)
  if (params.split_models.output_dir is not None):
    if (not os.path.isdir(params.split_models.output_dir)):
      raise Sorry(("The specified output directory '%s' does not exist or is "+
        "not a directory.") % params.split_models.output_dir)
  return True

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/phil.py
"""Analyze a PHIL file"""
from __future__ import absolute_import, division, print_function
import iotbx.phil
import libtbx.command_line.phil
import sys

if (__name__ == "__main__"):
  libtbx.command_line.phil.run(
    args=sys.argv[1:],
    command_name="iotbx.phil",
    converter_registry=iotbx.phil.default_converter_registry)


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/poscar_as_xray_structure.py
"""Create xray-structure from a poscar file and dump as pickle"""
from __future__ import absolute_import, division, print_function
def run(args):
  assert len(args) > 0
  import iotbx.poscar
  for file_name in args:
    print(file_name)
    poscar = iotbx.poscar.reader(
      lines=open(file_name).read().splitlines(),
      source_info=file_name)
    poscar.make_up_types_if_necessary()
    poscar.xray_structure(u_iso=0.05).show_summary().show_scatterers()
    print()

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/r_free_flags_accumulation.py
"""
Extract R-free flags from reflection files.
Writes reflection count, free fraction pairs to file (for plotting).
Also shows free fraction in bins.
"""
from __future__ import absolute_import, division, print_function

from iotbx import reflection_file_utils
from iotbx import reflection_file_reader
import libtbx.phil
from libtbx.str_utils import show_string
from libtbx.utils import Sorry, Usage
import sys, os
from six.moves import zip

master_params = libtbx.phil.parse("""\
r_free_flags_accumulation {
  file_name=None
    .type=path
  label=None
    .type=str
  test_flag_value=None
    .type=int
  disable_suitability_test=False
    .type=bool
}
r_free_flags_accumulation {
  output=None
    .type=path
  plot_header=None
    .type=str
    .multiple=True
}
""")

def run(args, command_name="iotbx.r_free_flags_accumulation"):
  def raise_usage():
    raise Usage("%s reflection_file [label=value]" % command_name)
  if (len(args) == 0 or "--help" in args or "-h" in args):
    raise_usage()
  phil_objects = []
  argument_interpreter = master_params.command_line_argument_interpreter(
    home_scope="r_free_flags_accumulation")
  reflection_files = []
  for arg in args:
    if (os.path.isfile(arg)):
      refl_file = reflection_file_reader.any_reflection_file(
        file_name=arg)
      if (refl_file.file_type() is not None):
        reflection_files.append(refl_file)
        arg = None
    if (arg is not None):
      try: command_line_params = argument_interpreter.process(arg=arg)
      except KeyboardInterrupt: raise
      except Exception: raise Sorry("Unknown file or keyword: %s" % arg)
      else: phil_objects.append(command_line_params)
  params_scope = master_params.fetch(sources=phil_objects).extract()
  params = params_scope.r_free_flags_accumulation
  srv = reflection_file_utils.reflection_file_server(
    reflection_files=reflection_files)
  r_free_flags, test_flag_value = srv.get_r_free_flags(
    file_name=params.file_name,
    label=params.label,
    test_flag_value=params.test_flag_value,
    disable_suitability_test=params.disable_suitability_test,
    parameter_scope="r_free_flags_accumulation")
  params.file_name = r_free_flags.info().source
  params.label = r_free_flags.info().label_string()
  params.test_flag_value = test_flag_value
  if (params.output is None):
    params.output = os.path.basename(params.file_name) \
                  + ".r_free_flags_accumulation"
  working_params = master_params.format(python_object=params_scope)
  working_params.show()
  print()
  print("#phil __OFF__")
  r_free_flags = r_free_flags.array(
    data=r_free_flags.data()==params.test_flag_value)
  r_free_flags.show_r_free_flags_info()
  print()
  accu = r_free_flags \
    .sort(by_value="resolution") \
    .r_free_flags_accumulation()
  print("Writing file: %s" % show_string(params.output))
  print("  1. column: reflection counts, sorted by resolution")
  print("  2. column: number of free reflections / total number of reflections")
  sys.stdout.flush()
  out = open(params.output, "w")
  for line in params.plot_header:
    print(line, file=out)
  for c,f in zip(accu.reflection_counts, accu.free_fractions):
    print(c, f, file=out)
  out.close()
  print()
  sys.stdout.flush()

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/r_free_flags_as_cns.py
"""Create CNS test set from a reflection file"""
from __future__ import absolute_import, division, print_function
from iotbx import reflection_file_reader
import iotbx.cns.miller_array
import sys, os

def run(args):
  assert len(args) == 1
  reflection_file = reflection_file_reader.any_reflection_file(
    file_name=args[0])
  assert reflection_file.file_type is not None
  r_free_flags = None
  for miller_array in reflection_file.as_miller_arrays():
    if (miller_array.is_integer_array()):
      assert r_free_flags is None
      r_free_flags = miller_array
  assert r_free_flags is not None
  file_name = os.path.splitext(os.path.basename(args[0]))[0]+".cns"
  assert not os.path.isfile(file_name)
  print("Writing:", file_name)
  r_free_flags.export_as_cns_hkl(
    file_object=open(file_name, "w"),
    array_names=["TEST"])

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/r_free_flags_completion_simple.py
"""Try to complete the test set for a reflection file"""

from __future__ import absolute_import, division, print_function
import iotbx.reflection_file_utils
import iotbx.reflection_file_reader
from libtbx.utils import Sorry, Usage
from libtbx.str_utils import show_string
import libtbx.load_env
import os.path as op
import sys

def usage():
    raise Usage("""\
%s reflection_file_name high_resolution_value

  Example: %s your.mtz 2.0
""" % (libtbx.env.dispatcher_name, libtbx.env.dispatcher_name))

def run(args, output_file_name = None, log = sys.stdout):
  if (len(args) == 0 or "--help" in args or "-h" in args):
    usage()
  refl_file_name = None
  refl_file = None
  high_res = None
  for arg in args:
    if (op.isfile(str(arg))):
      refl_file_name = str(arg)
      refl_file = iotbx.reflection_file_reader.any_reflection_file(
        file_name=refl_file_name)
      if (refl_file.file_type() is None):
        raise Sorry("File not recognized: %s" % show_string(arg))
    else:
      try:
        high_res = float(arg)
      except ValueError:
        raise Sorry(
          "Not a file name or high-resolution value: %s"
            % show_string(arg))
      if (high_res <= 0):
        raise Sorry(
          "High-resolution value must be greater than zero (%s given)."
            % show_string(arg))
  if (refl_file is None or high_res is None):
    usage()
  refl_file_server = iotbx.reflection_file_utils.reflection_file_server(
    reflection_files=[refl_file])
  r_free_flags, test_flag_value = refl_file_server.get_r_free_flags(
    file_name=None,
    label=None,
    test_flag_value=None,
    disable_suitability_test=False,
    parameter_scope="r_free_flags")
  print("Summary of existing R-free-flags:", file = log)
  r_free_flags.show_comprehensive_summary(prefix="  ")
  print(file = log)
  print("Test flag value:", test_flag_value, file = log)
  print(file = log)
  assert r_free_flags.unit_cell() is not None
  assert r_free_flags.space_group_info() is not None
  assert r_free_flags.data().size() != 0
  r_free_flags = r_free_flags.array(data=r_free_flags.data()==test_flag_value)
  fraction_free = r_free_flags.data().count(True) / r_free_flags.data().size()
  print("Fraction free: %.2f %%" % (fraction_free*100),file = log)
  assert fraction_free > 0
  print(file = log)
  missing_set = r_free_flags.complete_set(d_min=high_res).lone_set(
    r_free_flags.map_to_asu())
  print("Number of missing R-free-flags:", missing_set.indices().size(),
     file = log)
  print(file = log)
  if missing_set.indices().size() == 0:
    print("No missing r_free flags...skipping missing set generation\n",
      file = log)
    extended_r_free_flags = r_free_flags
  else: # usual
    missing_flags = missing_set.generate_r_free_flags(
      fraction=fraction_free,
      max_free=None,
      use_lattice_symmetry=True)
    extended_r_free_flags = r_free_flags.concatenate(other=missing_flags)
    print("Summary of extended R-free-flags:",file = log)
    extended_r_free_flags.show_comprehensive_summary(prefix="  ")
    print(file = log)
  mtz_dataset = extended_r_free_flags.as_mtz_dataset(
    column_root_label="Extended-R-free-flags")
  if not output_file_name:
    output_file_name = op.basename(refl_file_name)
    i = output_file_name.rfind(".")
    if (i >= 0):
      output_file_name = output_file_name[:i] + "_" + output_file_name[i+1:]
    output_file_name += "_extended_r_free_flags.mtz"
  print("Writing file: %s" % show_string(output_file_name),file = log)
  mtz_dataset.mtz_object().write(file_name=output_file_name)
  print(file = log)
  print("""\
Miscellaneous remarks:

  - ***PLEASE INSPECT*** the extended R-free-flags with this command:

      iotbx.r_free_flags_accumulation %s

  - For use in phenix.refine, simply add the new mtz file as an
    additional command-line argument. If necessary, follow the
    phenix.refine suggestions to select the extended R-free-flag
    array.

  - You may have to remove the
      REMARK r_free_flags.md5.hexdigest
    line from your PDB file(s) to use the new flags in phenix.refine.
    (phenix.refine will tell you why and what you need to do.)

  - phenix.reflection_file_converter can be used to combine reflection
    data from another file with the extended R-free-flags.
""" % show_string(output_file_name),file = log)

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/reflection_file_converter.py
"""Convert or modify reflection file"""
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.reflection_file_converter
# LIBTBX_SET_DISPATCHER_NAME iotbx.reflection_file_converter

from iotbx import reflection_file_converter
import sys

def run():
  try:
    reflection_file_converter.run(args=sys.argv[1:])
  except RuntimeError as e:
    print(e)

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/reflection_file_editor.py
"""Edit a reflection file"""
from __future__ import absolute_import, division, print_function

import sys
from iotbx import reflection_file_editor

if __name__ == "__main__" :
  reflection_file_editor.run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/reflection_file_reader.py
"""Read any reflection file"""
from __future__ import absolute_import, division, print_function
from iotbx import reflection_file_reader
import sys

def run():
  try:
    reflection_file_reader.run(sys.argv[1:])
  except RuntimeError as e:
    print(e)

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/reflection_statistics.py
"""Analyze one or more reflection files including correlations between datasets"""
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.reflection_statistics

from iotbx import reflection_file_reader
from iotbx.option_parser import option_parser
from cctbx import maptbx
from cctbx import miller
from cctbx import crystal
from cctbx import sgtbx
import cctbx.sgtbx.lattice_symmetry
import cctbx.sgtbx.cosets
from cctbx.crystal import reindex
from cctbx.array_family import flex
from libtbx.utils import Sorry
from itertools import count
import sys
from six.moves import range
from six.moves import zip

def show_average_of_binned_data(binned_data_list):
  l = len(binned_data_list[0].binner.bin_legend(0))
  print(" "*(l-9), "average:", end=' ')
  for binned_data in binned_data_list:
    data = flex.double()
    for d in binned_data.data[1:-1]:
      if (d is not None): data.append(d)
    if (data.size() == 0): print(" "*7, end=' ')
    else: print("%7.4f" % flex.mean(data), end=' ')
  print()

class array_cache(object):

  def __init__(self, input, n_bins, lattice_symmetry_max_delta,
     completeness_as_non_anomalous=None):
    self.completeness_as_non_anomalous=completeness_as_non_anomalous
    self.input = input.eliminate_sys_absent(integral_only=True, log=sys.stdout)
    self.lattice_symmetry_max_delta = lattice_symmetry_max_delta
    if (not self.input.is_unique_set_under_symmetry()):
      print("Merging symmetry-equivalent reflections:")
      merged = self.input.merge_equivalents()
      merged.show_summary(prefix="  ")
      print()
      self.input = merged.array()
      del merged
      if (input.info() is not None):
        self.input.set_info(input.info().customized_copy(merged=True))
      else:
        self.input.set_info(miller.array_info(merged=True))
    self.input.show_comprehensive_summary()
    print()
    self.input.setup_binner(n_bins=n_bins)
    self.resolution_range = self.input.resolution_range()
    self.change_of_basis_op_to_minimum_cell \
      = self.input.change_of_basis_op_to_minimum_cell()
    self.observations = self.input.change_basis(
      cb_op=self.change_of_basis_op_to_minimum_cell) \
        .expand_to_p1() \
        .map_to_asu()
    if (self.input.anomalous_flag()):
      self.anom_diffs = abs(self.input.anomalous_differences()).change_basis(
        cb_op=self.change_of_basis_op_to_minimum_cell) \
          .expand_to_p1() \
          .map_to_asu()
    else:
      self.anom_diffs = None
    self.minimum_cell_symmetry = crystal.symmetry.change_basis(
      self.input,
      cb_op=self.change_of_basis_op_to_minimum_cell)
    self.intensity_symmetry = \
      self.minimum_cell_symmetry.reflection_intensity_symmetry(
        anomalous_flag=self.input.anomalous_flag())
    self.lattice_group = sgtbx.lattice_symmetry.group(
      self.minimum_cell_symmetry.unit_cell(),
      max_delta=self.lattice_symmetry_max_delta)
    self.lattice_group.expand_inv(sgtbx.tr_vec((0,0,0)))
    self.lattice_group.make_tidy()
    self.lattice_symmetry = crystal.symmetry(
      unit_cell=self.minimum_cell_symmetry.unit_cell(),
      space_group_info=sgtbx.space_group_info(group=self.lattice_group),
      assert_is_compatible_unit_cell=False)

  def show_completeness(self):
    print("Completeness of %s:" % str(self.input.info()))
    no_sys_abs = self.input.eliminate_sys_absent()
    no_sys_abs.use_binning_of(self.input)
    no_sys_abs.completeness(use_binning=True,
     as_non_anomalous_array=self.completeness_as_non_anomalous).show()
    print()

  def idealized_input_unit_cell(self):
    return self.lattice_symmetry.unit_cell().change_basis(
      cb_op=self.change_of_basis_op_to_minimum_cell.inverse())

  def possible_twin_laws(self):
    cosets = sgtbx.cosets.left_decomposition_point_groups_only(
      g=self.lattice_group,
      h=self.intensity_symmetry.space_group()
          .build_derived_acentric_group()
          .make_tidy())
    return cosets.best_partition_representatives(
      cb_op=self.change_of_basis_op_to_minimum_cell.inverse(),
      omit_first_partition=True,
      omit_negative_determinants=True)

  def show_possible_twin_laws(self):
    print("Space group of the intensities:", \
      self.intensity_symmetry.space_group_info() \
        .as_reference_setting())
    print("Space group of the metric:     ", \
      self.lattice_symmetry.space_group_info() \
        .as_reference_setting())
    d = "%.6g" % self.lattice_symmetry_max_delta
    if (d == "1"): d += " degree"
    else: d += " degrees"
    print("  Tolerance used in the determination of the")
    print("  lattice symmetry:", d)
    twin_laws = self.possible_twin_laws()
    if (len(twin_laws) == 0):
      print("Possible twin laws: None")
    else:
      idealized_cell = self.idealized_input_unit_cell()
      s = str(idealized_cell)
      if (s != str(self.input.unit_cell())):
        print("Idealized unit cell:", s)
      print("Possible twin laws:")
      for s in twin_laws:
        hkl_str = s.r().as_hkl()
        cb_op = sgtbx.change_of_basis_op(hkl_str)
        assert idealized_cell.change_basis(
          cb_op=cb_op).is_similar_to(idealized_cell)
        info = ""
        try:
          cb_sg = self.input.space_group_info().change_basis(cb_op=cb_op)
        except RuntimeError as e:
          if (str(e).find("Unsuitable value for rational") < 0): raise
          info = " # Info: this changes the setting of the input space group"
        else:
          if (cb_sg.group() != self.input.space_group()):
            info = " # Info: new setting: %s" % str(cb_sg)
        print(" ", hkl_str + info)
      print("  Note:")
      print("    phenix.xtriage provides comprehensive twinning analysis")
      print("    facilities for macromolecular structures.")
      print("    For more information enter: phenix.xtriage --help")
    print()

  def show_patterson_peaks(self,
        min_relative_peak_height=0.1,
        show_at_least=3):
    print("Patterson peaks for %s:" % str(self.input.info()))
    reciprocal_map = self.input
    if (reciprocal_map.anomalous_flag()):
      reciprocal_map = reciprocal_map.average_bijvoet_mates()
    patterson_map = reciprocal_map.patterson_map(
      symmetry_flags=maptbx.use_space_group_symmetry)
    patterson_map.apply_sigma_scaling()
    peak_list = patterson_map.tags().peak_search(
      map=patterson_map.real_map(),
      parameters=maptbx.peak_search_parameters())
    max_height = peak_list.heights()[0]
    sym_equiv_origin = sgtbx.sym_equiv_sites(
      unit_cell=patterson_map.unit_cell(),
      space_group=patterson_map.space_group(),
      original_site=(0,0,0))
    print("      Fractional coordinates     Height  Distance from origin")
    for i_peak in range(peak_list.size()):
      height = peak_list.heights()[i_peak]
      if (height < max_height * min_relative_peak_height
          and i_peak > show_at_least): break
      site = peak_list.sites()[i_peak]
      dist_info = sgtbx.min_sym_equiv_distance_info(sym_equiv_origin, site)
      print("  %8.4f %8.4f %8.4f" % (dist_info.sym_op()*site), end=' ')
      print("  %8.3f  %8.3f" % (height, dist_info.dist()))
    print()

  def show_perfect_merohedral_twinning_test(self, n_bins=None):
    assert not self.input.space_group().is_centric()
    print("Perfect merohedral twinning test for %s:"%str(self.input.info()))
    acentric = self.input.select_acentric().as_intensity_array()
    acentric = acentric.array(
      data=acentric.data()/acentric.epsilons().data().as_double())
    acentric.set_observation_type_xray_intensity()
    if (n_bins is not None):
      acentric.setup_binner(n_bins=n_bins)
    else:
      acentric.setup_binner(auto_binning=True)
      if (acentric.binner().n_bins_used() > 30):
        acentric.setup_binner(n_bins=30)
    acentric.binner().counts_complete(include_centric=False)
    sm = acentric.second_moment_of_intensities(use_binning=True)
    wr = acentric.wilson_ratio(use_binning=True)
    print(acentric.second_moment_of_intensities.__doc__)
    print(acentric.wilson_ratio.__doc__)
    print("See also: http://www.doe-mbi.ucla.edu/Services/Twinning/intro.html")
    for i_bin,s,w in zip(count(), sm.data, wr.data):
      print(sm.binner.bin_legend(i_bin), end=' ')
      for v in s, w:
        if (v is None): print(" "*7, end=' ')
        else: print("%7.4f" % v, end=' ')
      print()
    show_average_of_binned_data([sm, wr])
    print()

  def show_second_moments_of_intensities(self, n_bins=None):
    print("Second moments of intensities for %s:"%str(self.input.info()))
    f = self.input.as_intensity_array()
    f = f.array(data=f.data()/f.epsilons().data().as_double())
    f.set_observation_type_xray_intensity()
    if (n_bins is not None):
      f.setup_binner(n_bins=n_bins)
    else:
      f.setup_binner(auto_binning=True)
      if (f.binner().n_bins_used() > 30):
        f.setup_binner(n_bins=30)
    print(f.second_moment_of_intensities.__doc__.split()[0])
    sm = f.second_moment_of_intensities(use_binning=True)
    sm.show()
    show_average_of_binned_data([sm])
    print()

  def show_measurability(self, cutoff=3):
    if (self.input.sigmas() is not None):
      work_array = self.input.select(self.input.sigmas() > 0)
      if (work_array.size() > 0):
        print("Observed measurabilities of %s:" % str(self.input.info()))
        print(self.input.measurability.__doc__.replace("cutoff", str(cutoff)))
        work_array.use_binning_of(self.input)
        meas_obs = work_array.measurability(use_binning=True, cutoff=cutoff)
        meas_obs.show()
      print()

  def unique_reindexing_operators(self,
        other,
        relative_length_tolerance,
        absolute_angle_tolerance):
    #make crystal symmetries
    self_xs = crystal.symmetry( unit_cell = self.input.unit_cell(),
                                space_group = self.input.space_group() )
    other_xs = crystal.symmetry( unit_cell = other.input.unit_cell(),
                                space_group = other.input.space_group() )
    # some downstream routines expect things to be in minimum cell
    self_xs = self_xs.change_basis(
      self.change_of_basis_op_to_minimum_cell )
    other_xs = other_xs.change_basis(
      other.change_of_basis_op_to_minimum_cell )

    double_cosets = reindex.reindexing_operators(
      self_xs,
      other_xs,
      relative_length_tolerance,
      absolute_angle_tolerance,
      self.input.anomalous_flag() )
    result = double_cosets.combined_cb_ops()
    return result

  def combined_cb_op(self, other, cb_op):
    sc = self.change_of_basis_op_to_minimum_cell
    oc = other.change_of_basis_op_to_minimum_cell

    cb_op = cb_op.new_denominators(sc)
    best_choice = None
    best_choice_as_hkl = None
    for s_symop in self.minimum_cell_symmetry.space_group():
      s_symop = sgtbx.change_of_basis_op(sgtbx.rt_mx(
        s_symop.r())).new_denominators(sc)
      for o_symop in other.minimum_cell_symmetry.space_group():
        o_symop = sgtbx.change_of_basis_op(sgtbx.rt_mx(
          o_symop.r())).new_denominators(sc)
        possible_choice = sc.inverse() * s_symop * cb_op * o_symop * oc
        possible_choice_as_hkl = possible_choice.as_hkl()
        if (best_choice_as_hkl is None
            or sgtbx.compare_cb_op_as_hkl(
                 best_choice_as_hkl, possible_choice_as_hkl) > 0):
          best_choice = possible_choice
          best_choice_as_hkl = possible_choice_as_hkl
    assert best_choice is not None
    return best_choice

  def setup_common_binner(self,
        other,
        auto_binning=False,
        reflections_per_bin=0,
        n_bins=0,
        d_tolerance=1.e-6):
    d_max = min(self.resolution_range[0], other.resolution_range[0])
    d_min = max(self.resolution_range[1], other.resolution_range[1])
    if (d_max == d_min):
      d_max += d_max*0.5
      d_min -= d_min*0.5
    else:
      d_max *= (1+d_tolerance)
      d_min *= (1-d_tolerance)
    self.observations.setup_binner(
      d_max=d_max,
      d_min=d_min,
      auto_binning=auto_binning,
      reflections_per_bin=reflections_per_bin,
      n_bins=n_bins)
    if (self.anom_diffs is not None and other.anom_diffs is not None):
      self.anom_diffs.setup_binner(
        d_max=d_max,
        d_min=d_min,
        auto_binning=auto_binning,
        reflections_per_bin=reflections_per_bin,
        n_bins=n_bins)

def _process_miller_arrays(
      command_line,
      input_miller_arrays,
      active_miller_arrays):
  n_f_sq_as_f = 0
  for miller_array in input_miller_arrays:
    info = miller_array.info()
    miller_array = miller_array.select(
      miller_array.indices() != (0,0,0))
    if (miller_array.indices().size() == 0): continue
    if (miller_array.is_xray_intensity_array()):
      miller_array = miller_array.f_sq_as_f()
      n_f_sq_as_f += 1
    elif (miller_array.is_complex_array()):
      miller_array = abs(miller_array)
    if (miller_array.is_real_array()):
      if (miller_array.unit_cell() is None):
        print()
        print("*" * 79)
        print("Unknown unit cell parameters:", miller_array.info())
        print("Use --symmetry or --unit_cell to define unit cell:")
        print("*" * 79)
        print()
        command_line.parser.show_help()
        return -1
      if (miller_array.space_group_info() is None):
        print()
        print("*" * 79)
        print("Unknown space group:", miller_array.info())
        print("Use --symmetry or --space_group to define space group:")
        print("*" * 79)
        print()
        command_line.parser.show_help()
        return -1
      if (   command_line.options.resolution is not None
          or command_line.options.low_resolution is not None):
        miller_array = miller_array.resolution_filter(
          d_max=command_line.options.low_resolution,
          d_min=command_line.options.resolution)
      miller_array = miller_array.map_to_asu()
      miller_array.set_info(info=info)
      active_miller_arrays.append(miller_array)
  return n_f_sq_as_f

def run(
      args,
      command_name="phenix.reflection_statistics",
      additional_miller_arrays=[]):
  print("Command line arguments:", end=' ')
  for arg in args: print(arg, end=' ')
  print()
  print()
  command_line = (option_parser(
    usage=command_name+" [options] reflection_file [...]",
    description="Example: %s data1.mtz data2.sca" % command_name)
    .enable_symmetry_comprehensive()
    .option(None, "--weak_symmetry",
      action="store_true",
      default=False,
      help="symmetry on command line is weaker than symmetry found in files")
    .option(None, "--quick",
      action="store_true",
      help="Do not compute statistics between pairs of data arrays")
    .enable_resolutions()
    .option(None, "--bins",
      action="store",
      type="int",
      dest="n_bins",
      default=10,
      help="Number of bins",
      metavar="INT")
    .option(None, "--bins_twinning_test",
      action="store",
      type="int",
      dest="n_bins_twinning_test",
      default=None,
      help="Number of bins for twinning test",
      metavar="INT")
    .option(None, "--bins_second_moments",
      action="store",
      type="int",
      dest="n_bins_second_moments",
      default=None,
      help="Number of bins for second moments of intensities",
      metavar="INT")
    .option(None, "--lattice_symmetry_max_delta",
      action="store",
      type="float",
      default=3.,
      help="angular tolerance in degrees used in the determination"
           " of the lattice symmetry")
    .option(None, "--completeness_as_non_anomalous_or_anomalous",
      action="store_true",
      help="analyze completeness as is, without conversion to non-anomalous")

  ).process(args=args)
  if (len(command_line.args) == 0 and len(additional_miller_arrays) == 0):
    command_line.parser.show_help()
    return
  active_miller_arrays = []
  completeness_as_non_anomalous= (
     not command_line.options.completeness_as_non_anomalous_or_anomalous)

  n_f_sq_as_f = 0
  for file_name in command_line.args:
    reflection_file = reflection_file_reader.any_reflection_file(
      file_name=file_name)
    miller_arrays = None
    if (reflection_file.file_type() is not None):
      try:
        miller_arrays = reflection_file.as_miller_arrays(
          crystal_symmetry=command_line.symmetry,
          force_symmetry=not command_line.options.weak_symmetry,
          merge_equivalents=False)
      except Sorry as KeyboardInterrupt: raise
      except Exception: pass
    if (miller_arrays is None):
      print("Warning: unknown file format:", file_name, file=sys.stderr)
      print(file=sys.stderr)
      sys.stderr.flush()
    else:
      n = _process_miller_arrays(
        command_line=command_line,
        input_miller_arrays=miller_arrays,
        active_miller_arrays=active_miller_arrays)
      if (n < 0): return
      n_f_sq_as_f += n
  if (additional_miller_arrays is not None):
    n = _process_miller_arrays(
      command_line=command_line,
      input_miller_arrays=additional_miller_arrays,
      active_miller_arrays=active_miller_arrays)
    if (n < 0): return
    n_f_sq_as_f += n
  if (n_f_sq_as_f > 0):
    if (n_f_sq_as_f == 1):
      print("Note: Intensity array has been converted to an amplitude array.")
    else:
      print("Note: Intensity arrays have been converted to amplitude arrays.")
    print()
  if (len(active_miller_arrays) > 2 and not command_line.options.quick):
    print("Array indices (for quick searching):")
    for i_0,input_0 in enumerate(active_miller_arrays):
      print("  %2d:" % (i_0+1), input_0.info())
    print()
    print("Useful search patterns are:")
    print("    Summary i")
    print("    CC Obs i j")
    print("    CC Ano i j")
    print("  i and j are the indices shown above.")
    print()
  n_bins = command_line.options.n_bins
  array_caches = []
  for i_0,input_0 in enumerate(active_miller_arrays):
    print("Summary", i_0+1)
    print()
    cache_0 = array_cache(
      input=input_0,
      n_bins=n_bins,
      lattice_symmetry_max_delta=\
         command_line.options.lattice_symmetry_max_delta,
      completeness_as_non_anomalous=completeness_as_non_anomalous)
    cache_0.show_possible_twin_laws()
    cache_0.show_completeness()
    cache_0.show_patterson_peaks()
    if (not cache_0.input.space_group().is_centric()):
      cache_0.show_perfect_merohedral_twinning_test(
        n_bins=command_line.options.n_bins_twinning_test)
    else:
      cache_0.show_second_moments_of_intensities(
        n_bins=command_line.options.n_bins_second_moments)
    if (cache_0.input.anomalous_flag()):
      print("Anomalous signal of %s:" % str(cache_0.input.info()))
      print(cache_0.input.anomalous_signal.__doc__)
      anom_signal = cache_0.input.anomalous_signal(use_binning=True)
      anom_signal.show()
      print()
      cache_0.show_measurability()
    for i_1,cache_1 in enumerate(array_caches):
      unique_reindexing_operators = cache_1.unique_reindexing_operators(
        other=cache_0,
        relative_length_tolerance=0.05,
        absolute_angle_tolerance=5)
      if (len(unique_reindexing_operators) == 0):
        print("Incompatible unit cells:")
        print("  %2d:" % (i_1+1), cache_1.input.info())
        print("  %2d:" % (i_0+1), cache_0.input.info())
        print("No comparison.")
        print()
      else:
        ccs = flex.double()
        for cb_op in unique_reindexing_operators:
          similar_array_0 = cache_0.observations \
            .change_basis(cb_op) \
            .map_to_asu()
          ccs.append(cache_1.observations.correlation(
            other=similar_array_0,
            assert_is_similar_symmetry=False).coefficient())
        permutation = flex.sort_permutation(ccs, reverse=True)
        ccs = ccs.select(permutation)
        unique_reindexing_operators = flex.select(
          unique_reindexing_operators, permutation=permutation)
        for i_cb_op,cb_op,cc in zip(count(),
                                    unique_reindexing_operators,
                                    ccs):
          combined_cb_op = cache_1.combined_cb_op(other=cache_0, cb_op=cb_op)
          if (not combined_cb_op.c().is_unit_mx()):
            reindexing_note = "  after reindexing %d using %s" % (
              i_0+1, combined_cb_op.as_hkl())
          else:
            reindexing_note = ""
          print("CC Obs %d %d %6.3f  %s" % (
            i_1+1, i_0+1, cc, combined_cb_op.as_hkl()))
          print("Correlation of:")
          print("  %2d:" % (i_1+1), cache_1.input.info())
          print("  %2d:" % (i_0+1), cache_0.input.info())
          print("Overall correlation: %6.3f%s" % (cc, reindexing_note))
          show_in_bins = False
          if (i_cb_op == 0 or (cc >= 0.3 and cc >= ccs[0]-0.2)):
            show_in_bins = True
            similar_array_0 = cache_0.observations \
              .change_basis(cb_op) \
              .map_to_asu()
            cache_1.setup_common_binner(cache_0, n_bins=n_bins)
            correlation = cache_1.observations.correlation(
              other=similar_array_0,
              use_binning=True,
              assert_is_similar_symmetry=False)
            correlation.show()
          print()
          if (    cache_0.anom_diffs is not None
              and cache_1.anom_diffs is not None):
            similar_anom_diffs_0 = cache_0.anom_diffs \
              .change_basis(cb_op) \
              .map_to_asu()
            correlation = cache_1.anom_diffs.correlation(
              other=similar_anom_diffs_0,
              assert_is_similar_symmetry=False)
            print("CC Ano %d %d %6.3f  %s" % (
              i_1+1, i_0+1, correlation.coefficient(), combined_cb_op.as_hkl()))
            print("Anomalous difference correlation of:")
            print("  %2d:" % (i_1+1), cache_1.input.info())
            print("  %2d:" % (i_0+1), cache_0.input.info())
            print("Overall anomalous difference correlation: %6.3f%s" % (
              correlation.coefficient(), reindexing_note))
            if (show_in_bins):
              correlation = cache_1.anom_diffs.correlation(
                other=similar_anom_diffs_0,
                use_binning=True,
                assert_is_similar_symmetry=False)
              correlation.show()
            print()
    if (not command_line.options.quick):
      array_caches.append(cache_0)
    print("=" * 79)
    print()

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/reindex.py
""" Reindex the contents of an MTZ file
    using a given change-of-basis operator
"""
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.reindex

import libtbx.phil
from libtbx.utils import Usage, Sorry
import string
import os
import sys

master_phil = libtbx.phil.parse("""
reindex
  .caption = This utility will reindex the contents of an MTZ file \
    using a given change-of-basis operator.  For instance, to convert a \
    file with symmetry P22121 to P21212, the operator c,a,b could be used. \
    (If your reflections are in a format other than MTZ, you can convert them \
    in the reflection file editor, which also supports change-of-basis \
    operations.)
  .style = box auto_align caption_img:icons/custom/phenix.reflection_file_editor.png
{
  hkl_file = None
    .type = path
    .short_caption = MTZ file
    .style = bold file_type:hkl input_file
  output_file = None
    .type = path
    .short_caption = Output file
    .style = new_file file_type:hkl
  change_of_basis = None
    .type = str
    .short_caption = Change of basis
    .input_size=100
    .style = bold
}""")

def run(args=(), params=None, out=None):
  if (out is None):
    out = sys.stdout
  if (params is None):
    if (len(args) == 0):
      raise Usage("""
phenix.reindex data.mtz change_of_basis=<operator>

Change-of-basis operator: h,k,l or x,y,z or
                          to_reference_setting, to_primitive_setting,
                          to_niggli_cell, to_inverse_hand
""")
    import iotbx.phil
    cmdline = iotbx.phil.process_command_line_with_files(
      args=args,
      master_phil=master_phil,
      reflection_file_def="reindex.hkl_file")
    params = cmdline.work.extract()
  validate_params(params)
  cb_op = convert_operator(params.reindex.change_of_basis)
  from iotbx import file_reader
  hkl_in = file_reader.any_file(params.reindex.hkl_file)
  miller_arrays = hkl_in.file_server.miller_arrays
  new_arrays = []
  labels = ["H","K","L"]
  warnings = []
  for array in miller_arrays :
    labels.extend(array.info().labels)
    array = array.change_basis(cb_op=cb_op)
    new_arrays.append(array)
  mtz_out = new_arrays[0].as_mtz_dataset(
    column_root_label="A")
  for i, array in enumerate(new_arrays[1:]):
    mtz_out.add_miller_array(
      miller_array=array,
      column_root_label="%s" % string.ascii_uppercase[i+1])
  mtz_obj = mtz_out.mtz_object()
  for i, column in enumerate(mtz_obj.columns()):
    column.set_label(labels[i])
  if (params.reindex.output_file is None):
    base,ext = os.path.splitext(params.reindex.hkl_file)
    params.reindex.output_file = base + "_reindex.mtz"
  mtz_obj.write(file_name=params.reindex.output_file)
  print("Reindex reflections written to %s" % params.reindex.output_file, file=out)
  return params.reindex.output_file

def convert_operator(change_of_basis):
  from cctbx import sgtbx
  try :
    c_o_b = sgtbx.change_of_basis_op(change_of_basis)
  except RuntimeError as e :
    raise Sorry(str(e))
  else :
    return c_o_b

def validate_params(params):
  if (params.reindex.hkl_file is None):
    raise Sorry("Please specify a reflections file.")
  if (params.reindex.change_of_basis is None):
    raise Sorry("Please specify a change-of-basis operator.")
  else :
    convert_operator(params.reindex.change_of_basis)
  return True

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/shelx.as_cif.py
"""Convert SHELX to mmCIF format"""
from __future__ import absolute_import, division, print_function
from cctbx import xray
import sys, os
op = os.path

def run(args):
  for f in args:
    try:
      xs = xray.structure.from_shelx(filename=f, strictly_shelxl=False)
    except KeyboardInterrupt:
      raise
    except Exception:
      print("%s is not a .ins or a .res file" % f)
      continue
    r, _ = op.splitext(op.basename(f))
    xs.as_cif_simple(out=open(r + '.cif', 'w'))

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/shelx.as_xray_structure.py
"""Create xray_structure from a SHELX file and dump as pickle"""
from __future__ import absolute_import, division, print_function
from cctbx import xray
from libtbx import easy_pickle
import sys, os

for f in sys.argv[1:]:
  try:
    xs = xray.structure.from_shelx(filename=f, strictly_shelxl=False)
  except KeyboardInterrupt:
    raise
  except Exception:
    print("%s is not a .ins or a .res file" % f)
    continue
  r, _ = os.path.splitext(f)
  easy_pickle.dump(r + '.pickle', xs)


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/shelx.dump_as_python.py
"""Save SHELX xray_structure as python code"""
from __future__ import absolute_import, division, print_function
from cctbx import xray

def run(file_name, exclude_hydrogens=False):
  xs = xray.structure.from_shelx(filename=file_name,
                                 strictly_shelxl=False)
  if exclude_hydrogens:
    xs = xs.select(xs.hd_selection(), negate=True)
  print(xs.as_py_code())

if __name__ == '__main__':
  import sys
  run(sys.argv[1], '--exclude-hydrogens' in sys.argv[2:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/show_distances.py
"""Show distances between non-bonded atoms"""
from __future__ import absolute_import, division, print_function
from iotbx.kriber import strudat
import iotbx.pdb
import iotbx.cif
from iotbx.option_parser import option_parser
from cctbx.crystal import coordination_sequences
from cctbx import crystal, xray
from libtbx.str_utils import show_string
from libtbx.utils import Sorry
import sys

def display(
      distance_cutoff,
      show_cartesian,
      max_shell,
      coseq_dict,
      xray_structure):
  xray_structure.show_summary().show_scatterers()
  print()
  pairs = xray_structure.show_distances(
    distance_cutoff=distance_cutoff,
    show_cartesian=show_cartesian,
    keep_pair_asu_table=True).distances_info
  print()
  if (pairs.pair_counts.size() <= 15):
    print("Pair counts:", list(pairs.pair_counts))
    print()
  if (max_shell is None):
    term_table = None
  else:
    term_table = crystal.coordination_sequences.simple(
      pair_asu_table=pairs.pair_asu_table,
      max_shell=max_shell)
    coordination_sequences.show_terms(
      structure=xray_structure,
      term_table=term_table,
      coseq_dict=coseq_dict)
    print()
  return pairs, term_table

def run(args):
  command_line = (option_parser(
    usage="iotbx.show_distances [options] studat_file [...]",
    description="Example: iotbx.show_distances strudat --tag=SOD")
    .option(None, "--cif_data_block_name",
      action="store",
      type="string",
      default=None,
      help="data block name as it appears in the CIF file")
    .option(None, "--tag",
      action="store",
      type="string",
      help="tag as it appears in the strudat file")
    .option(None, "--distance_cutoff",
      action="store",
      type="float",
      default=5,
      help="Maximum distance to be considered",
      metavar="FLOAT")
    .option(None, "--min_distance_sym_equiv",
      action="store",
      type="float",
      default=0.5,
      help="Minimum distance between symmetry mates"
           " (for special position analysis)",
      metavar="FLOAT")
    .option(None, "--show_cartesian",
      action="store_true",
      help="Show Cartesian coordinates (instead of fractional)")
    .enable_symmetry_comprehensive()
    .option(None, "--cs",
      action="store",
      type="int",
      help="Compute N terms of the coordination sequences",
      metavar="N")
    .option(None, "--coseq",
      action="store",
      type="string",
      help="name of file with known coordination sequences",
      metavar="FILE")
  ).process(args=args)
  if (len(command_line.args) == 0):
    command_line.parser.show_help()
    return
  co = command_line.options
  max_shell = co.cs
  if (co.coseq is not None):
    coseq_dict = coordination_sequences.get_kriber_coseq_file(
      file_name=co.coseq)
    if (max_shell is None): max_shell = 10
  else:
    coseq_dict = None
  def call_display(xray_structure):
    display(
      distance_cutoff=co.distance_cutoff,
      show_cartesian=co.show_cartesian,
      max_shell=max_shell,
      coseq_dict=coseq_dict,
      xray_structure=xray_structure)
  cif_data_block_name_use_counter = 0
  for file_name in command_line.args:
    xray_structure = None
    if (iotbx.pdb.is_pdb_file(file_name=file_name)):
      xray_structure = iotbx.pdb.input(
        file_name=file_name).xray_structure_simple(
          crystal_symmetry=command_line.symmetry,
          cryst1_substitution_buffer_layer=max(5,
            co.distance_cutoff+1),
          min_distance_sym_equiv=co.min_distance_sym_equiv,
          enable_scattering_type_unknown=True)
      call_display(xray_structure)
      continue
    if (file_name.lower().endswith(".cif")):
      xray_structures = iotbx.cif.reader(
        file_path=file_name).build_crystal_structures()
      if (co.cif_data_block_name is not None):
        xray_structure = xray_structures.get(co.cif_data_block_name)
        if (xray_structure is None):
          continue
        cif_data_block_name_use_counter += 1
        xray_structures = [xray_structure]
      else:
        xray_structures = xray_structures.values()  # NOTE: in py3 Im just an iterable!
      for xray_structure in xray_structures:
        call_display(xray_structure)
      continue
    if (   file_name.endswith(".ins")
        or file_name.endswith(".res")):
      xray_structure = xray.structure.from_shelx(
        filename=file_name, strictly_shelxl=False)
      call_display(xray_structure)
      continue
    if (command_line.symmetry is not None
        and (command_line.symmetry.unit_cell() is not None
          or command_line.symmetry.space_group_info() is not None)):
      raise Sorry(
        "Command-line symmetry options not supported for strudat files.")
    strudat_entries = strudat.read_all_entries(open(file_name))
    for entry in strudat_entries.entries:
      if (    co.tag is not None
          and co.tag != entry.tag):
        continue
      print("strudat tag:", entry.tag)
      print()
      xray_structure = entry.as_xray_structure(
        min_distance_sym_equiv=co.min_distance_sym_equiv)
      call_display(xray_structure)
  if (    co.cif_data_block_name is not None
      and cif_data_block_name_use_counter == 0):
    raise Sorry(
      "cif_data_block_name %s not found in any input files"
        % show_string(co.cif_data_block_name))

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/show_systematic_absences.py
"""Show the systematic absences in a reflection file"""
# LIBTBX_SET_DISPATCHER_NAME cctbx.show_systematic_absences

from __future__ import absolute_import, division, print_function
from iotbx.reflection_file_utils import reflection_file_server
import iotbx.phil
from cctbx import crystal
from libtbx.utils import Sorry
import sys

master_phil_str = """
data = None
  .type = path
labels = None
  .type = strings
space_group = None
  .type = space_group
unit_cell = None
  .type = unit_cell
symmetry = None
  .type = path
"""

def run(args, out=sys.stdout):
  cmdline = iotbx.phil.process_command_line_with_files(
    args=args,
    master_phil_string=master_phil_str,
    reflection_file_def="data",
    pdb_file_def="symmetry",
    space_group_def="space_group",
    unit_cell_def="unit_cell",
    usage_string="""\
iotbx.show_systematic_absences data.hkl [space_group] [unit_cell]""")
  params = cmdline.work.extract()
  if (params.data is None):
    raise Sorry("Data file not specified.")
  hkl_file = cmdline.get_file(params.data)
  hkl_server = reflection_file_server(
    crystal_symmetry=None,
    force_symmetry=True,
    reflection_files=[hkl_file.file_object],
    err=sys.stderr)
  data = hkl_server.get_xray_data(
    file_name=params.data,
    labels=params.labels,
    ignore_all_zeros=False,
    parameter_scope="",
    minimum_score=4,
    prefer_amplitudes=False)
  symm = data.crystal_symmetry()
  space_group = unit_cell = None
  if (params.symmetry is not None):
    from iotbx import crystal_symmetry_from_any
    symm = crystal_symmetry_from_any.extract_from(file_name=params.symmetry)
  if (symm is not None):
    space_group = symm.space_group_info()
    unit_cell = symm.unit_cell()
  if (space_group is None):
    if (params.space_group is not None):
      space_group = params.space_group
    else :
      raise Sorry("No space group defined.")
  if (unit_cell is None):
    if (params.unit_cell is not None):
      unit_cell = params.unit_cell
    else :
      raise Sorry("No unit cell defined.")
  symm = crystal.symmetry(
    space_group_info=space_group,
    unit_cell=unit_cell)
  data = data.customized_copy(crystal_symmetry=symm)
  if (data.sigmas() is None):
    raise Sorry("Input data are missing experimental sigmas.")
  data.show_all_possible_systematic_absences(out=out)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/simple_map_coefficients.py
"""Create map coefficients from a reflection file"""

from __future__ import absolute_import, division, print_function
from libtbx.utils import Sorry, Usage
from libtbx import Auto
import os
import sys

master_phil = """
file_name = None
  .type = path
  .short_caption = MTZ file
  .style = file_type:hkl
data_labels = None
  .type = str
  .short_caption = Data labels
  .style = None
phase_labels = None
  .type = str
weight_labels = None
  .type = str
map_type = *Fo anom
  .type = choice
use_weights = Auto
  .type = bool
output_file = None
  .type = path
"""

def run(args, out=sys.stdout):
  from iotbx import file_reader
  import iotbx.phil
  if (len(args) == 0):
    raise Usage("""\
iotbx.simple_map_coefficients data_phases.mtz [options]

Full parameters:
%s""" % iotbx.phil.parse(master_phil).as_str(attributes_level=1, prefix=" "))
  cmdline = iotbx.phil.process_command_line_with_files(
    args=args,
    master_phil_string=master_phil,
    reflection_file_def="file_name")
  params = cmdline.work.extract()
  if (params.file_name is None):
    raise Sorry("No reflection file specified.")
  hkl_in = file_reader.any_file(params.file_name).check_file_type("hkl")
  hkl_server = hkl_in.file_server
  data = hkl_server.get_xray_data(
    file_name=params.file_name,
    labels=params.data_labels,
    ignore_all_zeros=False,
    parameter_name="data_labels",
    parameter_scope="",
    prefer_anomalous=True,
    prefer_amplitudes=True)
  data_labels = data.info().label_string()
  if (data.is_xray_intensity_array()):
    from cctbx.french_wilson import french_wilson_scale
    data = french_wilson_scale(data, log=out)
  phases = hkl_server.get_phases_deg(
    file_name=params.file_name,
    labels=params.phase_labels,
    convert_to_phases_if_necessary=True,
    original_phase_units=None,
    parameter_scope="",
    parameter_name="phase_labels",
    minimum_score=2)
  assert (not phases.anomalous_flag())
  deg = True # FIXME
  weights = None
  if (params.use_weights in [Auto, True]):
    # FIXME centralize this in iotbx.reflection_file_utils
    for array in hkl_server.miller_arrays :
      if (array.is_real_array()):
        label_string = array.info().label_string()
        if ((label_string == params.weight_labels) or
            ((params.weight_labels is None) and ("FOM" in label_string))):
          weights = array
          break
  amplitudes = data
  if (params.map_type == "anom"):
    if (not data.anomalous_flag()):
      raise Sorry("Anomalous map requested, but selected data are merged.")
    amplitudes = data.anomalous_differences()
    print("Using anomalous differences in %s" % data_labels, file=out)
  else :
    print("Using amplitudes in %s" % data_labels, file=out)
    if (data.anomalous_flag()):
      amplitudes = data.average_bijvoet_mates()
  if (params.use_weights is Auto) and (weights is not None):
    if (params.map_type != "anom"):
      params.use_weights = True
  elif (params.use_weights == True) and (weights is None):
    raise Sorry("No weights (FOM, etc.) found in input file.")
  if (params.use_weights == True):
    assert (not weights.anomalous_flag())
    print("Applying weights in %s" % weights.info().label_string(), file=out)
    amplitudes, weights = amplitudes.common_sets(other=weights)
    amplitudes = amplitudes.customized_copy(
      data=amplitudes.data()*weights.data())
  amplitudes = amplitudes.customized_copy(sigmas=None)
  print("Applying phases in %s" % phases.info().label_string(), file=out)
  amplitudes, phases = amplitudes.common_sets(phases)
  coeffs = amplitudes.phase_transfer(phases,
    deg=deg).set_observation_type(None) # FIXME
  if (params.map_type == "anom") : # apply 90-degree phase shift
    coeffs = coeffs.customized_copy(data=coeffs.data()/(2j))
  assert (coeffs.is_complex_array())
  column_root_label = "F"
  decorator = None
  if (params.map_type == "anom"):
    column_root_label = "ANOM"
  elif (params.use_weights == True):
    column_root_label = "FWT"
    decorator = iotbx.mtz.ccp4_label_decorator()
  import iotbx.mtz
  mtz_dataset = coeffs.as_mtz_dataset(
    column_root_label=column_root_label,
    label_decorator=decorator)
  if (params.output_file is None):
    params.output_file = "map_coeffs.mtz"
  mtz_dataset.mtz_object().write(params.output_file)
  print("Wrote %s" % params.output_file, file=out)
  return os.path.abspath(params.output_file)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/sort_atoms.py
"""Sort atoms in residues so they will be in the same order in all residues"""
# LIBTBX_SET_DISPATCHER_NAME iotbx.pdb.sort_atoms

from __future__ import absolute_import, division, print_function
from libtbx.utils import Usage
import sys
import iotbx.pdb
import mmtbx.model

master_phil_str = """
file_name = None
  .type = path
  .multiple = False
  .optional = False
  .style = hidden
"""

def show_usage():
  help_msg = """\
iotbx.pdb.sort_atoms model.pdb

Sort atoms in residues so they will be in the same order in all residues.
Also renumbers atoms (atom serial number field 7-11 columns)."""

  raise Usage(help_msg)

def run(args):
  if len(args) == 0:
    show_usage()
    return
  inp_fn = args[0]
  pdb_input = iotbx.pdb.input(
      file_name=inp_fn,
      source_info=None,
      raise_sorry_if_format_error=True)
  model = mmtbx.model.manager(
      model_input = pdb_input)

  out_fn_prefix = inp_fn
  if inp_fn.endswith(".pdb") or inp_fn.endswith(".cif"):
    out_fn_prefix = inp_fn[:-4]
  out_fn = out_fn_prefix + "_sorted"

  txt = ""
  if model.input_model_format_cif():
    out_fn += ".cif"
    txt = model.model_as_mmcif()
  else:
    out_fn += ".pdb"
    txt = model.model_as_pdb()
  with open(out_fn, 'w') as f:
    f.write(txt)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/split_data_cif.py
"""Split an mmCIF file"""
from __future__ import absolute_import, division, print_function

# LIBTBX_SET_DISPATCHER_NAME iotbx.split_data_cif

from iotbx.programs import split_data_cif
from iotbx.cli_parser import run_program

result = run_program(split_data_cif.Program)


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/symmetry_search.py
"""Search for crystallographic symmetry based on a PDB or POSCAR file"""
from __future__ import absolute_import, division, print_function
def run(args):
  import iotbx.phil
  pcl = iotbx.phil.process_command_line(args=args, master_string="""\
symmetry_search {
  structure_factor_d_min = 2
    .type = float
}
""")
  if (len(pcl.remaining_args) != 1):
    from libtbx.utils import Usage
    import libtbx.load_env
    print()
    pcl.master.show()
    print()
    raise Usage(
      "%s pdb_file|poscar_file [parameters]" % libtbx.env.dispatcher_name)
  inp_file = pcl.remaining_args[0]
  from libtbx.str_utils import show_string
  import iotbx.pdb
  if (iotbx.pdb.is_pdb_file(inp_file)):
    print("PDB file:", show_string(inp_file))
    pdb_inp = iotbx.pdb.input(file_name=inp_file)
    xs = pdb_inp.xray_structure_simple()
  else:
    print("POSCAR file:", show_string(inp_file))
    import iotbx.poscar
    poscar = iotbx.poscar.reader(lines=open(inp_file).read().splitlines())
    poscar.make_up_types_if_necessary()
    xs = poscar.xray_structure()
  print()
  pcl.work.show()
  print()
  params = pcl.work.extract().symmetry_search
  print("Unit cell:", xs.unit_cell())
  print()
  fc_p1 = xs.structure_factors(
    d_min=params.structure_factor_d_min).f_calc().expand_to_p1()
  from cctbx import symmetry_search
  sf_symm = symmetry_search.structure_factor_symmetry(f_in_p1=fc_p1)
  print(sf_symm)
  print()
  print(sf_symm.space_group_info)
  print()

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/unique_with_biomt.py
"""Tool to make an mmCIF file with only part of model
  and _pdbx_struct_assembly* records defining symmetry operations to reconstruct
  the rest of the model."""

from __future__ import absolute_import, division, print_function

# LIBTBX_SET_DISPATCHER_NAME iotbx.unique_with_biomt
# LIBTBX_SET_DISPATCHER_NAME phenix.unique_with_biomt

from iotbx.programs import unique_with_biomt
from iotbx.cli_parser import run_program

result = run_program(unique_with_biomt.Program)


 *******************************************************************************


 *******************************************************************************
iotbx/command_line/xplor.map.show_summary.py
"""Summarize an XPLOR format map"""
from __future__ import absolute_import, division, print_function
import iotbx.xplor.map
import sys

def run(args):
  for file_name in args:
    print("file name:", file_name)
    iotbx.xplor.map.reader(file_name=file_name).show_summary(prefix="  ")
    print()

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************
