

 *******************************************************************************
mmtbx/building/__init__.py

from __future__ import absolute_import, division, print_function
from libtbx import group_args
import sys
import mmtbx.refinement.real_space
from six.moves import zip
from six.moves import range

#-----------------------------------------------------------------------
# MODEL UTILITIES
#-----------------------------------------------------------------------

def reprocess_pdb(pdb_hierarchy, crystal_symmetry, cif_objects, out):
  from mmtbx.monomer_library import pdb_interpretation
  from mmtbx.monomer_library import server
  mon_lib_srv = server.server()
  ener_lib = server.ener_lib()
  for cif_object in cif_objects :
    for srv in [mon_lib_srv, ener_lib]:
      srv.process_cif_object(cif_object=cif_object)
  return pdb_interpretation.process(
    mon_lib_srv=mon_lib_srv,
    ener_lib=ener_lib,
    raw_records=pdb_hierarchy.as_pdb_or_mmcif_string(
      target_format='pdb',crystal_symmetry=crystal_symmetry),
    crystal_symmetry=crystal_symmetry,
    log=out)

def get_nearby_water_selection(
    pdb_hierarchy,
    xray_structure,
    selection,
    selection_buffer_radius=5):
  sel_cache = pdb_hierarchy.atom_selection_cache()
  water_selection = sel_cache.selection("resname HOH")
  selection_within = xray_structure.selection_within(
    radius=selection_buffer_radius,
    selection=selection)
  return (selection_within & water_selection)

def iter_residue_groups(hierarchy):
  for chain in hierarchy.only_model().chains():
    for residue_group in chain.residue_groups():
      yield residue_group

def extract_iselection(pdb_objects):
  from scitbx.array_family import flex
  isel = flex.size_t()
  for pdb_obj in pdb_objects :
    isel.extend(pdb_obj.atoms().extract_i_seq())
  assert not isel.all_eq(0)
  return isel

def remove_sidechain_atoms(pdb_objects):
  for pdb_obj in pdb_objects :
    atoms = pdb_obj.atoms()
    for atom in atoms :
      if (not atom.name.strip() in ["CA","C","N","O","CB"]):
        atom.parent().remove_atom(atom)

def is_stub_residue(atom_group):
  if (atom_group.resname in ["GLY","ALA"]):
    return True
  has_sidechain_atoms = False
  for atom in atom_group.atoms():
    if (not atom.name.strip() in ["H","HA","C","CA","CB","N","O",]):
      has_sidechain_atoms = True
  return not has_sidechain_atoms

def get_non_hydrogen_atom_indices(pdb_object):
  from scitbx.array_family import flex
  i_seqs_no_hd = flex.size_t()
  for atom in pdb_object.atoms():
    if (atom.element.strip() not in ["H","D"]):
      i_seqs_no_hd.append(atom.i_seq)
  return i_seqs_no_hd

def get_window_around_residue(residue, window_size=2):
  residue_group = residue.parent()
  chain = residue_group.parent()
  all_residues = chain.residue_groups()
  sel_residues = []
  for i_res, other_rg in enumerate(all_residues):
    if (other_rg == residue_group):
      for j_res in range(-window_size, window_size+1):
        k_res = i_res + j_res
        if (k_res >= 0) and (k_res < len(all_residues)):
          sel_residues.append(all_residues[k_res])
  assert (len(sel_residues) > 0)
  return sel_residues

def atom_group_as_hierarchy(atom_group):
  """
  Convert an iotbx.pdb.hierarchy.atom_group object to a separate hierarchy
  (leaving the original hierarchy untouched), which allows us to use the
  pickling capabilities of iotbx.pdb.hierarchy.root.
  """
  import iotbx.pdb.hierarchy
  old_rg = atom_group.parent()
  assert (old_rg is not None)
  old_chain = old_rg.parent()
  root = iotbx.pdb.hierarchy.root()
  model = iotbx.pdb.hierarchy.model()
  chain = iotbx.pdb.hierarchy.chain(id=old_chain.id)
  residue_group = iotbx.pdb.hierarchy.residue_group(
    resseq=old_rg.resseq,
    icode=old_rg.icode)
  residue_group.append_atom_group(atom_group.detached_copy())
  chain.append_residue_group(residue_group)
  model.append_chain(chain)
  root.append_model(model)
  atoms = root.atoms()
  atoms.reset_i_seq()
  atoms.reset_serial()
  return root

def residues_are_adjacent(residue1, residue2, max_sep=2.5):
  if (type(residue1).__name__ == "residue_group"):
    residue1 = residue1.atom_groups()[0]
  if (type(residue2).__name__ == "residue_group"):
    residue2 = residue2.atom_groups()[0]
  c_pep = n_pep = None
  for atom in residue1.atoms():
    if (atom.name.strip() == "C"):
      c_pep = atom
      break
  for atom in residue2.atoms():
    if (atom.name.strip() == "N"):
      n_pep = atom
      break
  if (None in [c_pep, n_pep]):
    return False
  return c_pep.distance(n_pep) < max_sep

#-----------------------------------------------------------------------
# MAP-RELATED
#-----------------------------------------------------------------------

def residue_density_quality(
    atom_group,
    unit_cell,
    two_fofc_map,
    fofc_map):
  from scitbx.array_family import flex
  sites_cart = flex.vec3_double()
  atom_names = flex.std_string()
  for atom in atom_group.atoms():
    if (not atom.element.strip() in ["H","D"]):
      sites_cart.append(atom.xyz)
      atom_names.append(atom.name)
  if (len(sites_cart) == 0):
    raise RuntimeError("No non-hydrogen atoms in %s" % atom_group.id_str())
  density = local_density_quality(
    fofc_map=fofc_map,
    two_fofc_map=two_fofc_map,
    sites_cart=sites_cart,
    atom_names=atom_names,
    unit_cell=unit_cell)
  return density

def get_difference_maps(fmodel, resolution_factor=0.25):
  fofc_coeffs = fmodel.map_coefficients(map_type="mFo-DFc",
    exclude_free_r_reflections=True)
  fofc_fft = fofc_coeffs.fft_map(
    resolution_factor=resolution_factor)
  fofc_map = fofc_fft.apply_sigma_scaling().real_map_unpadded()
  two_fofc_coeffs = fmodel.map_coefficients(map_type="2mFo-DFc",
    exclude_free_r_reflections=True)
  two_fofc_fft = two_fofc_coeffs.fft_map(resolution_factor=resolution_factor)
  two_fofc_map = two_fofc_fft.apply_sigma_scaling().real_map_unpadded()
  return two_fofc_map, fofc_map

# XXX this should probably be merged with something else, e.g. the
# local_density_quality class
def get_model_map_stats(
    selection,
    target_map,
    model_map,
    unit_cell,
    sites_cart,
    pdb_atoms,
    local_sampling=False):
  """
  Collect basic statistics for a model map and some target map (usually an
  mFo-DFc map), including CC, mean, and minimum density at the atomic
  positions.
  """
  assert (len(target_map) == len(model_map))
  iselection = selection
  if (type(selection).__name__ == 'bool'):
    iselection = selection.iselection()
  from scitbx.array_family import flex
  sites_cart_refined = sites_cart.select(selection)
  sites_selected = flex.vec3_double()
  map1 = flex.double()
  map2 = flex.double()
  min_density = sys.maxsize
  sum_density = n_sites = 0
  worst_atom = None
  # XXX I'm not sure the strict density cutoff is a good idea here
  for i_seq, xyz in zip(iselection, sites_cart_refined):
    if (pdb_atoms[i_seq].element.strip() != "H"):
      sites_selected.append(xyz)
      site_frac = unit_cell.fractionalize(site_cart=xyz)
      target_value = target_map.tricubic_interpolation(site_frac)
      if (target_value < min_density):
        min_density = target_value
        worst_atom = pdb_atoms[i_seq]
      sum_density += target_value
      n_sites += 1
      if (not local_sampling):
        map1.append(target_value)
        map2.append(model_map.tricubic_interpolation(site_frac))
  assert (n_sites > 0)
  if (local_sampling):
    from cctbx import maptbx
    map_sel = maptbx.grid_indices_around_sites(
      unit_cell=unit_cell,
      fft_n_real=target_map.focus(),
      fft_m_real=target_map.all(),
      sites_cart=sites_selected,
      site_radii=flex.double(sites_selected.size(), 1.0))
    map1 = target_map.select(map_sel)
    map2 = model_map.select(map_sel)
  assert (len(map1) > 0) and (len(map1) == len(map2))
  cc = flex.linear_correlation(x=map1, y=map2).coefficient()
  return group_args(
    cc=cc,
    min=min_density,
    mean=sum_density/n_sites)

#-----------------------------------------------------------------------
# SAMPLING UTILITIES
#-----------------------------------------------------------------------
def generate_sidechain_clusters(residue, mon_lib_srv):
  """
  Extract Chi angle indices (including rotation axis) from the atom_group
  """
  from mmtbx.utils import rotatable_bonds
  from scitbx.array_family import flex
  atoms = residue.atoms()
  axes_and_atoms_aa_specific = \
      rotatable_bonds.axes_and_atoms_aa_specific(residue = residue,
        mon_lib_srv = mon_lib_srv)
  result = []
  if(axes_and_atoms_aa_specific is not None):
    for i_aa, aa in enumerate(axes_and_atoms_aa_specific):
      n_heavy = 0
      #for i_seq in aa[1] :
      #  if (atoms[i_seq].element.strip() != "H"):
      #    n_heavy += 1
      #if (n_heavy == 0) : continue
      if(i_aa == len(axes_and_atoms_aa_specific)-1):
        result.append(mmtbx.refinement.real_space.cluster(
          axis=aa[0],
          atoms_to_rotate=aa[1],
          selection=flex.size_t(aa[1]),
          vector=None)) # XXX
      else:
        result.append(mmtbx.refinement.real_space.cluster(
          axis=aa[0],
          atoms_to_rotate=aa[1],
          selection=flex.size_t([aa[1][0]]),
          vector=None)) # XXX
  return result


 *******************************************************************************


 *******************************************************************************
mmtbx/building/cablam_idealization.py
from __future__ import absolute_import, division, print_function

from libtbx import group_args
import libtbx.phil

from mmtbx.validation.cablam import cablamalyze, fetch_peptide_expectations, \
    fetch_ca_expectations, fetch_motif_contours
from libtbx.utils import Sorry, null_out

from cctbx import geometry_restraints

import itertools

from scitbx.matrix import rotate_point_around_axis

from mmtbx.refinement.geometry_minimization import run2
from mmtbx.building.loop_closure.utils import list_rama_outliers_h
from mmtbx.secondary_structure import manager as ss_manager_class
from mmtbx.geometry_restraints.ramachandran import master_phil as rama_master_phil
import six
from six.moves import range


master_phil_str = '''
cablam_idealization {
  enabled = True
    .type = bool
  nproc = 1
    .type = int
    .help = Parallelization is not implemented
  rotation_angle = 30
    .type = int
    .help = angle to rotate the oxygen while searching for better conformation
  require_h_bond = True
    .type = bool
    .help = require presence of (new) h-bond after rotation
  do_gm = False
    .type = bool
    .help = Run geometry minimization after rotation
  find_ss_after_fixes = True
    .type = bool
    .help = re-evaluate SS after fixing Cablam outliers. May be helpful to \
      identify new or extend previous SS elements
  save_intermediates = False
    .type = bool
    .help = Save all cablam rotation for particular residue in separate file
}
'''

# This is needed to import scope
master_phil = libtbx.phil.parse(master_phil_str)

class cablam_idealization(object):
  def __init__(self, model, params, log):
    """
    model is changed in place
    params - those in master_phil_str without scope name
    """
    self.model = model
    self.params = params
    self.log = log
    self.outliers = None
    self.cablam_contours = fetch_peptide_expectations()
    self.ca_contours = fetch_ca_expectations()
    self.motif_contours = fetch_motif_contours()
    self.n_tried_residues = 0
    self.n_rotated_residues = 0
    self.cablam_fixed_minimized = None

    if not self.params.enabled:
      return

    self.model.process(make_restraints=True)

    print("CaBLAM idealization", file=self.log)

    if self.model.get_hierarchy().models_size() > 1:
      raise Sorry("Multi-model files are not supported")

    self.model.search_for_ncs()
    ncs_obj = self.model.get_ncs_obj()
    nrgl = ncs_obj.get_ncs_restraints_group_list()
    if nrgl.get_n_groups() > 0:
      print(self.model.get_ncs_obj().show_phil_format(), file=self.log)

    self.outliers_by_chain = self.identify_outliers()

    # idealization
    # TODO: verify if outliers by chain is dict
    for chain, outliers in six.iteritems(self.outliers_by_chain):
      b_selection = self.model.selection("chain %s" % chain)
      self.atoms_around = self.model.get_xray_structure().selection_within(7, b_selection).iselection()

      for outlier in outliers:
        self.fix_cablam_outlier(chain, outlier)

    if self.params.find_ss_after_fixes:
      ss_manager = ss_manager_class(
          pdb_hierarchy=self.model.get_hierarchy(),
          geometry_restraints_manager=self.model.get_restraints_manager().geometry,
          sec_str_from_pdb_file=None,
          params=None,
          mon_lib_srv=self.model.get_mon_lib_srv(),
          verbose=-1,
          log=self.log)
      self.model.get_restraints_manager().geometry.set_secondary_structure_restraints(
          ss_manager=ss_manager,
          hierarchy=self.model.get_hierarchy(),
          log=self.log)
      self.model.set_ss_annotation(ann=ss_manager.actual_sec_str)

    if params.do_gm:
      self.cablam_fixed_minimized = self._minimize()

  def _get_ca_atom(self, chainid, resid):
    for chain in self.model.get_master_hierarchy().only_model().chains():
      if chain.id.strip() == chainid.strip():
        for rg in chain.residue_groups():
          if rg.resid() == resid:
            for a in rg.atoms():
              if a.name.strip() == "CA":
                return a
    raise Sorry("Something went wrong. Cannot find CA atom.")
    return None


  def fix_cablam_outlier(self, chain, outlier):
    self.n_tried_residues += 1
    scores = []
    if len(outlier) == 1:
      curresid = outlier[0].residue.resid()
      prevresid = outlier[0].prevres.residue.resid()
      curresseq_int = outlier[0].residue.resseq_as_int()
      prevresseq_int = outlier[0].prevres.residue.resseq_as_int()
    elif len(outlier) == 2:
      curresid = outlier[1].residue.resid()
      prevresid = outlier[1].prevres.residue.resid()
      curresseq_int = outlier[1].residue.resseq_as_int()
      prevresseq_int = outlier[1].prevres.residue.resseq_as_int()
    else:
      print("Don't know how to deal with more than 2 outliers in a row yet. Skipping.", file=self.log)
      return
    # h =  self.model.get_hierarchy()
    # s =  self.model.selection("chain %s and name CA and resid %s" % (chain, prevresid))
    # a1 = self.model.select(s).get_hierarchy().atoms()[0]
    # s =  self.model.selection("chain %s and name CA and resid %s" % (chain, curresid))
    # a2 = self.model.select(s).get_hierarchy().atoms()[0]
    # This is slightly faster, but poorer code. We'll see if it is needed.
    a1 = self._get_ca_atom(chain, prevresid)
    a2 = self._get_ca_atom(chain, curresid)

    print("*"*80, file=self.log)
    print("Atoms for rotation:", chain, prevresid, curresid, file=self.log)
    print("*"*80, file=self.log)

    around_str_sel = "chain %s and resid %d:%d" % (chain, prevresseq_int-2, curresseq_int+2)
    chain_around = self.model.select(self.model.selection(around_str_sel))
    assert chain_around.get_number_of_atoms() > 0
    self.atoms_around_cutted = self.atoms_around.deep_copy()
    # angle = 30
    angle = self.params.rotation_angle

    for i in range(int(360/angle)):
      # rotation
      O_atom, N_atom, C_atom = self._rotate_cablam(self.model, chain,
          prevresid, curresid, a1, a2, angle=angle)
      if [O_atom, N_atom, C_atom].count(None) > 0:
        print("Residues are missing essential atom: O, N or C. Skipping.", file=self.log)
        return
      self._rotate_cablam(chain_around, chain,
          prevresid, curresid, a1, a2, angle=angle)
      if self.params.save_intermediates:
        self.model.pdb_or_mmcif_string_info(
            target_filename="out_%s_%d.pdb" % (curresid.strip(), i),
            write_file=True)
      # Score contains tuple of :
      # angle, N Rama outliers, N Cablam outliers, hbonds
      scores.append(self._score_conformation(O_atom, C_atom, N_atom, chain_around, angle*(i+1)))
    print("angle, rama outliers, cablam outliers, hbonds (type, length, angle)", file=self.log)
    for s in scores:
      print(s[0], s[1], s[2], end=' ', file=self.log)
      if len(s[3]) > 0:
        for e in s[3]:
          print("| %s, %.2f, %.2f|" % (e[0], e[1], e[2]), end=' ', file=self.log)
      print(file=self.log)
    rot_angle = self._pick_rotation_angle(scores, self.params.require_h_bond)
    # rotate
    if rot_angle != 360:
      self.n_rotated_residues += 1
      print("ROTATING by", rot_angle, file=self.log)
      self._rotate_cablam(self.model, chain,
          prevresid, curresid, a1, a2, angle=rot_angle)

  def _rotate_cablam(self, model, chain, prevresid, curresid, a1, a2, angle):
    inside = False
    O_atom = None
    N_atom = None
    C_atom = None
    for c in model.get_master_hierarchy().only_model().chains():
      if c.id.strip() == chain.strip():
        for atom in c.atoms():
          if atom.name.strip() == "CA" and atom.parent().parent().resid() == prevresid:
            inside = True
          if atom.name.strip() == "CA" and atom.parent().parent().resid() == curresid:
            inside = False
          if inside and atom.name.strip() in ["N", "CA", "C", "O"]:
            new_xyz = rotate_point_around_axis(
                axis_point_1=a1.xyz,
                axis_point_2=a2.xyz,
                point=atom.xyz,
                angle=angle,
                deg=True)
            atom.set_xyz(new_xyz)
            if atom.name.strip() == "O":
              O_atom = atom
            elif atom.name.strip() == "N":
              N_atom = atom
            elif atom.name.strip() == "C":
              C_atom = atom

        model.set_sites_cart_from_hierarchy(multiply_ncs=True)

        return O_atom, N_atom, C_atom


  def _pick_rotation_angle(self, scores, require_h_bond=True):
    # I want to pick the rotation with H-bond, less Rama outliers and less
    # cablam outliers.
    best = scores[-1] # last, no rotation
    for s in scores[:-1]:
      # [angle, rama, cablam, hbond]
      if require_h_bond and len(s[3]) > 0:
        # rama better or same, and cablam outliers decreased:
        if s[1] <= best[1] and s[2] < best[2]:
          best = s
      else:
        # same as above, but preserve or increase number of hbonds
        if len(s[3]) >= len(best[3]) and s[1] <= best[1] and s[2] < best[2]:
          best = s
    # check for the claster and try to return the middle one if the case.
    best_position = scores.index(best)
    i = best_position
    while (i < len(scores) and
           scores[i][1] == scores[best_position][1] and
           scores[i][2] == scores[best_position][2] and
           len(scores[i][3]) == len(scores[best_position][3])):
      i += 1
    # If we went past the end, step back one position.
    # if i == len(scores):
    # Backtrack because the condition was broken:
    i -= 1
    middle_pos = (best_position + i) // 2
    # print('lenlenlen', len(scores))
    print('cluster positions:', best_position, i, middle_pos)
    print('cluster angles:', scores[best_position][0], scores[i][0], scores[middle_pos][0])
    return scores[middle_pos][0]

  def _minimize(self):
    m1 = self.model.deep_copy()
    rama_params = rama_master_phil.fetch().extract().ramachandran_plot_restraints
    rama_params.favored = 'oldfield'
    rama_params.allowed = 'oldfield'
    rama_params.outlier = 'oldfield'
    m1.set_ramachandran_plot_restraints(rama_params=rama_params)
    run2(
        restraints_manager=m1.get_restraints_manager(),
        pdb_hierarchy=m1.get_hierarchy(),
        correct_special_position_tolerance=1.0,
        riding_h_manager               = None,
        ncs_restraints_group_list      = [], # These are actually for NCS CONSTRAINTS!
        max_number_of_iterations       = 500,
        number_of_macro_cycles         = 5,
        selection                      = None,
        bond                           = True,
        nonbonded                      = True,
        angle                          = True,
        dihedral                       = True,
        chirality                      = True,
        planarity                      = True,
        parallelity                    = True,
        log = null_out())
    m1.set_sites_cart_from_hierarchy(multiply_ncs=True)
    return m1

  def _score_conformation(self, O_atom, C_atom, N_atom, chain_around, angle):
    # gs = self.model.geometry_statistics()
    # gs.show()
    # print "MOLPROBITY Score:", gs.result().molprobity_score
    # print "Cablam outliers:", gs.result().cablam.outliers
    # print "Clashscore: ", gs.result().clash.score
    hbonds = self._search_hbond(O_atom, C_atom, N_atom, chain_around)
    ro = list_rama_outliers_h(chain_around.get_hierarchy())
    cab_results = cablamalyze(
        pdb_hierarchy=chain_around.get_hierarchy(),
        outliers_only=True,
        out=null_out(),
        quiet=True,
        cablam_contours = self.cablam_contours,
        ca_contours = self.ca_contours,
        motif_contours = self.motif_contours,
        )
    outliers_only = [x for x in cab_results.results if x.feedback.cablam_outlier]
    return (angle, len(ro.split("\n"))-1, len(outliers_only), hbonds)

  def _search_hbond(self, O_atom, C_atom, N_atom, chain_around):
    def good_hbond(angle, distance):
      return angle > 140 and distance < 3.8
    results = []
    atoms = self.model.get_atoms()
    filtered_atoms_around_cutted = []
    for atom in [atoms[i_seq] for i_seq in self.atoms_around_cutted]:
      if atom.distance(O_atom) > 10:
        continue
      # no need to check the same residue, looking for N atom for bonding
      filtered_atoms_around_cutted.append(atom.i_seq)
      if atom.parent() == O_atom.parent() or atom.parent() == N_atom.parent():
        # print "skipping same residue ", atom.id_str()
        continue
      if atom.name.strip() == 'N':
        angle = geometry_restraints.angle(
            sites=[C_atom.xyz, O_atom.xyz, atom.xyz],
            angle_ideal=0,
            weight=1).angle_model
        if good_hbond(angle, atom.distance(O_atom)):
          # print "Potential bond:", atom.id_str(), atom.distance(O_atom), angle
          results.append(('NH', atom.distance(O_atom), angle))
      if atom.name.strip() == 'O':
        # now we want to find attached N atom (another one)
        another_C_atom = atom.parent().get_atom("C")
        if another_C_atom is not None:
          angle = geometry_restraints.angle(
              sites=[another_C_atom.xyz, atom.xyz, N_atom.xyz],
              angle_ideal=0,
              weight=1).angle_model
          if good_hbond(angle, atom.distance(N_atom)):
            # print "Potential backwards bond:", atom.id_str(), atom.distance(N_atom), angle
            results.append(('CO', atom.distance(N_atom), angle))
    self.atoms_around_cutted = filtered_atoms_around_cutted
    return results

  def identify_outliers(self):
    cab_results = cablamalyze(
        pdb_hierarchy=self.model.get_master_hierarchy(),
        outliers_only=True,
        out=null_out(),
        quiet=True,
        cablam_contours = self.cablam_contours,
        ca_contours = self.ca_contours,
        motif_contours = self.motif_contours)
    outliers_only = [x for x in cab_results.results if x.feedback.cablam_outlier]# and x.feedback.c_alpha_geom_outlier]
    outliers_by_chain = {}
    for k, g in itertools.groupby(outliers_only, key=lambda x: x.residue_id()[:2]):
      outliers_by_chain[k] = []
      comb = []
      for i in g:
        # print i.resseq, i.resseq_as_int(), i.icode, i, i.altloc, dir(i)
        if i.altloc.strip() != '':
          print("  ", i, "<--- SKIPPING, alternative conformations.", file=self.log)
          continue
        if len(comb) == 0:
          comb = [i]
        else:
          if (i.resseq_as_int() - comb[-1].resseq_as_int() == 1 or
              (i.resseq_as_int() == comb[-1].resseq_as_int() and i.icode != comb[-1].icode)):
            comb.append(i)
          else:
            outliers_by_chain[k].append(comb)
            comb = [i]
        print("  ", i, file=self.log)
      outliers_by_chain[k].append(comb)
    # here we want to combine them if they are next to each other.
    # probably will go with list of tuples
    return outliers_by_chain

  def get_results(self):
    return group_args(
      model = self.model,
      model_minimized = self.cablam_fixed_minimized,
      n_tried_residues = self.n_tried_residues,
      n_rotated_residues = self.n_rotated_residues)


 *******************************************************************************


 *******************************************************************************
mmtbx/building/extend_sidechains.py

from __future__ import absolute_import, division, print_function
from scitbx.matrix import col
from libtbx.str_utils import make_sub_header
from libtbx.utils import null_out
from libtbx import Auto
import sys
import mmtbx.monomer_library

master_params = """
selection = None
  .type = atom_selection
build_hydrogens = Auto
  .type = bool
max_atoms_missing = None
  .type = int
use_rotamers = True
  .type = bool
anneal_residues = False
  .type = bool
skip_rsr = False
  .type = bool
"""

def correct_sequence(pdb_hierarchy,
    sequences,
    truncate_to_cbeta=False,
    out=sys.stdout):
  """
  Modify the sequence for the pdb hierarchy to match that of the aligned
  sequence.  This will remove incompatible atoms; the sidechains will still
  need to be extended separated.  For proteins only - mismatches in nucleic
  acids will only result in a warning.

  :param pdb_hierarchy: iotbx.pdb.hierarchy.root object
  :param sequences: list of iotbx.bioinformatics.sequence objects
  :param trucate_to_cbeta: chop off entire sidechain to C-beta (default: leave
                           common atoms in place)
  :param out: output filehandle (default = stdout)
  :returns: number of atom_group objects renamed
  """
  from mmtbx.monomer_library import idealized_aa
  import mmtbx.validation.sequence
  from iotbx.pdb.amino_acid_codes import three_letter_given_one_letter
  seq_validation = mmtbx.validation.sequence.validation(
    pdb_hierarchy=pdb_hierarchy,
    sequences=sequences,
    log=out)
  for chain_seq in seq_validation.chains :
    if (chain_seq.chain_type == mmtbx.validation.sequence.NUCLEIC_ACID):
      if (len(chain_seq.mismatch) > 0):
        print("  WARNING: will skip %d mismatches in nucleic acid chain '%s'" % \
          chain_seq.chain_id, file=out)
  res_dict = idealized_aa.residue_dict()
  expected_names = {}
  for resname in res_dict.keys():
    if (not "_h" in resname):
      ideal_res = res_dict[resname]
      expected_names[resname] = set([ a.name for a in ideal_res.atoms() ])
  n_changed = 0
  for chain in pdb_hierarchy.only_model().chains():
    if (not chain.is_protein()):
      continue
    for chain_seq in seq_validation.chains :
      if (chain.id == chain_seq.chain_id) and (len(chain_seq.mismatch) > 0):
        for residue_group in chain.residue_groups():
          resid = residue_group.resid()
          if (resid in chain_seq.mismatch):
            idx = chain_seq.mismatch.index(resid)
            new_code = chain_seq.actual_code[idx]
            new_resname = three_letter_given_one_letter.get(new_code)
            if (new_resname is not None):
              expected_atoms = expected_names[new_resname.lower()]
              if (truncate_to_cbeta):
                expected_atoms = expected_names["ala"]
              for atom_group in residue_group.atom_groups():
                n_changed += 1
                n_removed = 0
                atom_group.resname = new_resname
                for atom in atom_group.atoms():
                  if (not atom.name in expected_atoms):
                    atom_group.remove_atom(atom)
                    n_removed += 1
              print("  chain '%s' %s %s --> %s (%d atoms removed)" % \
                (chain.id, resid, residue_group.atom_groups()[0].resname,
                 new_resname, n_removed), file=out)
  pdb_hierarchy.atoms().reset_i_seq()
  return n_changed

class conformation_scorer(object):
  """
  Stand-in for the conformation scoring class in mmtbx.refinement.real_space;
  instead of calculating fit to the map, this simply uses the change in
  position of the first atom being moved at each rotation.  This allows us to
  superimpose the conformations for those atoms which are present in both the
  old and the new residues.
  """
  def __init__(self, old_residue, new_residue):
    from scitbx.array_family import flex
    old_residue_atoms = old_residue.atoms()
    self.new_residue_atoms = new_residue.atoms()
    n_atoms = self.new_residue_atoms.size()
    self.new_residue_selection = flex.bool(n_atoms, False)
    self.selection_mappings = flex.size_t(n_atoms, 0)
    for i_seq, old_atom in enumerate(old_residue_atoms):
      for j_seq, new_atom in enumerate(self.new_residue_atoms):
        if (old_atom.name == new_atom.name):
          self.new_residue_selection[j_seq] = True
          self.selection_mappings[j_seq] = i_seq
    self.sites_old = old_residue_atoms.extract_xyz()
    self.sites_cart = self.new_residue_atoms.extract_xyz()
    self.dist_min = None

  def update(self, sites_cart, selection):
    first_i_seq = selection[0]
    if (self.new_residue_selection[first_i_seq]):
      dist = abs(col(sites_cart[first_i_seq]) -
        col(self.sites_old[self.selection_mappings[first_i_seq]]))
      if (dist < self.dist_min):
        self.sites_cart = sites_cart
        self.dist_min = dist
        return True
    return False

  def reset(self, sites_cart, selection):
    self.sites_cart = sites_cart
    first_i_seq = selection[0]
    if (self.new_residue_selection[first_i_seq]):
      self.dist_min = abs(col(sites_cart[first_i_seq]) -
        col(self.sites_old[self.selection_mappings[first_i_seq]]))
    else :
      self.dist_min = sys.maxsize

  def apply_final(self):
    self.new_residue_atoms.set_xyz(self.sites_cart)

def extend_residue(
    residue,
    target_atom_group,
    mon_lib_srv):
  """
  Rebuild a sidechain by substituting an ideal amino acid and rotating the
  sidechain to match the old conformation as closely as possible.
  Limited functionality:
    1) Amino-acids only, 2) side chain atoms only.
  """
  from iotbx.pdb import hierarchy
  from mmtbx.building import generate_sidechain_clusters
  import mmtbx.refinement.real_space
  tmp_residue = residue.detached_copy()
  new_residue = hierarchy.substitute_atom_group(
    current_group = tmp_residue,
    new_group     = target_atom_group)
  clusters = generate_sidechain_clusters(
    residue     = new_residue,
    mon_lib_srv = mon_lib_srv)
  scorer = conformation_scorer(
    old_residue = residue,
    new_residue = new_residue)
  mmtbx.refinement.real_space.torsion_search(
    scorer     = scorer,
    clusters   = clusters,
    sites_cart = new_residue.atoms().extract_xyz(),
    start=0, stop=360, step=1)
  scorer.apply_final()
  return new_residue

def extend_protein_model(
    pdb_hierarchy,
    mon_lib_srv,
    add_hydrogens=None,
    selection=None):
  """
  Rebuild a sidechain by substituting an ideal amino acid and rotating the
  sidechain to match the old conformation as closely as possible.
  Limited functionality:
    1) Amino-acids only,
    2) side chain atoms only.
    3) Not terminii aware.
    4) Not aware of v2.3 vs v3.2 atom names e.g. HB1,HB2 vs HB2,HB3.
    5) Skips altlocs.
  """
  from mmtbx.monomer_library import idealized_aa
  from mmtbx.rotamer import rotamer_eval
  from scitbx.array_family import flex
  ideal_dict = idealized_aa.residue_dict()
  pdb_atoms = pdb_hierarchy.atoms()
  if(selection is None):
    selection = flex.bool(pdb_atoms.size(), True)
  partial_sidechains = []
  for chain in pdb_hierarchy.only_model().chains():
    for residue_group in chain.residue_groups():
      if(residue_group.atom_groups_size() != 1): continue # skip altlocs
      for residue in residue_group.atom_groups():
        i_seqs = residue.atoms().extract_i_seq()
        residue_sel = selection.select(i_seqs)
        if not residue.resname.lower() in ideal_dict: continue
        missing_atoms = rotamer_eval.eval_residue_completeness(
          residue          = residue,
          mon_lib_srv      = mon_lib_srv,
          ignore_hydrogens = False)
        if(len(missing_atoms) > 0):
          all_h = list(set([
            s.strip()[0] for s in missing_atoms])) in [['H'],['D'],['T']]
          if(add_hydrogens is False and all_h): continue
          partial_sidechains.append(residue)
  for residue in partial_sidechains:
    residue_elements = [e.strip() for e in residue.atoms().extract_element()]
    res_key = residue.resname.lower()
    if(add_hydrogens is None):
      if("H" in residue_elements): res_key += "_h"
    if(add_hydrogens is True): res_key += "_h"
    target_atom_group = ideal_dict[res_key].only_model().only_chain().\
      only_residue_group().only_atom_group()
    new_residue = extend_residue(
      residue           = residue,
      target_atom_group = target_atom_group,
      mon_lib_srv       = mon_lib_srv)
    missing_atoms = rotamer_eval.eval_residue_completeness(
      residue          = new_residue,
      mon_lib_srv      = mon_lib_srv,
      ignore_hydrogens = False)
    # Set occupancy of newly added non-H atoms to small number so they can be
    # refined later automatically and also don't 'shock' the data terms by
    # coming in in full occupancy!
    anames_old = []
    for a in residue.atoms():
      anames_old.append(a.name)
    for a in new_residue.atoms():
      if a.element_is_hydrogen(): continue
      if a.name in anames_old: continue
      a.set_occ(0.1)
    #
    #assert len(missing_atoms) == 0, missing_atoms
    rg = residue.parent()
    rg.remove_atom_group(residue)
    rg.append_atom_group(new_residue.detached_copy())
  pdb_hierarchy.atoms().reset_i_seq()
  pdb_hierarchy.atoms().reset_serial()
  return len(partial_sidechains)

def refit_residues(
    pdb_hierarchy,
    cif_objects,
    fmodel,
    use_rotamers=True,
    anneal=False,
    verbose=True,
    allow_modified_residues=False,
    out=sys.stdout):
  """
  Use real-space refinement tools to fit newly extended residues.
  """
  from mmtbx.refinement.real_space import fit_residue
  from mmtbx.rotamer import rotamer_eval
  import mmtbx.monomer_library.server
  from mmtbx import building
  from scitbx.array_family import flex
  mon_lib_srv = mmtbx.monomer_library.server.server()
  rotamer_manager = rotamer_eval.RotamerEval()
  ppdb_out = box_out = out
  if (not verbose):
    ppdb_out = null_out()
    box_out = null_out()
  make_sub_header("Processing new model", out=ppdb_out)
  processed_pdb = building.reprocess_pdb(
    pdb_hierarchy=pdb_hierarchy,
    crystal_symmetry=fmodel.f_obs().crystal_symmetry(),
    cif_objects=cif_objects,
    out=ppdb_out)
  print("", file=ppdb_out)
  hierarchy = processed_pdb.all_chain_proxies.pdb_hierarchy
  xrs = processed_pdb.xray_structure()
  grm_geometry = processed_pdb.geometry_restraints_manager()
  make_sub_header("Fitting residues", out=out)
  target_map = fmodel.map_coefficients(
    map_type="2mFo-DFc",
    exclude_free_r_reflections=True).fft_map(
      resolution_factor=0.25).apply_sigma_scaling().real_map_unpadded()
  unit_cell = xrs.unit_cell()
  for chain in hierarchy.only_model().chains():
    if (not chain.is_protein()) and (not allow_modified_residues) : continue
    residue_groups = chain.residue_groups()
    for i_rg, residue_group in enumerate(residue_groups):
      prev_res = next_res = None
      atom_groups = residue_group.atom_groups()
      if (len(atom_groups) > 1) : continue
      residue = atom_groups[0]
      atoms = residue.atoms()
      atoms.reset_tmp()
      segids = atoms.extract_segid()
      if (segids.all_eq("XXXX")):
        sites_start = atoms.extract_xyz()
        def get_two_fofc_mean(residue):
          sum = 0
          n_atoms = 0
          for atom in residue.atoms():
            if (not atom.element.strip() in ["H","D"]):
              site_frac = unit_cell.fractionalize(site_cart=atom.xyz)
              sum += target_map.eight_point_interpolation(site_frac)
              n_atoms += 1
          assert (n_atoms > 0)
          return sum / n_atoms
        sites_start = atoms.extract_xyz().deep_copy()
        two_fofc_mean_start = get_two_fofc_mean(residue)
        refit = fit_residue.run_with_minimization(
          target_map=target_map,
          residue=residue,
          xray_structure=xrs,
          mon_lib_srv=mon_lib_srv,
          rotamer_manager=rotamer_manager,
          geometry_restraints_manager=grm_geometry,
          real_space_gradients_delta=fmodel.f_obs().d_min()*0.25,
          rms_bonds_limit=0.01,
          rms_angles_limit=1.0,
          backbone_sample_angle=20,
          allow_modified_residues=allow_modified_residues)
        two_fofc_mean_end = get_two_fofc_mean(residue)
        sites_end = atoms.extract_xyz()
        flag = ""
        if (two_fofc_mean_end > two_fofc_mean_start):
          flag = " <-- keep"
          xrs = refit.xray_structure
        else :
          atoms.set_xyz(sites_start)
          for atom in atoms :
            atom.tmp = 1
        print("    residue '%s' : rmsd=%5.3f 2fofc_start=%5.3f 2fofc_end=%5.3f%s" \
          % (residue.id_str(), sites_end.rms_difference(sites_start),
            two_fofc_mean_start, two_fofc_mean_end, flag), file=out)
  return hierarchy, xrs

class prefilter(object):
  """
  Optional filter for excluding residues with poor backbone density from being
  extended.  This is done as a separate callback to enable the main rebuilding
  routine to be independent of data/maps.
  """
  def __init__(self, fmodel, out, backbone_min_sigma=1.0):
    target_map = fmodel.map_coefficients(
      map_type="2mFo-DFc",
      exclude_free_r_reflections=True).fft_map(
        resolution_factor=0.25).apply_sigma_scaling().real_map_unpadded()
    self.unit_cell = fmodel.f_obs().unit_cell()
    self.map = target_map
    self.out = out
    self.backbone_min_sigma = backbone_min_sigma

  def __call__(self, residue):
    atoms = residue.atoms()
    sigma_mean = n_bb = 0
    for atom in atoms :
      if (atom.name.strip() in ["N","C","CA", "CB"]):
        site_frac = self.unit_cell.fractionalize(site_cart=atom.xyz)
        sigma_mean += self.map.eight_point_interpolation(site_frac)
        n_bb += 1
    if (n_bb > 1):
      sigma_mean /= n_bb
    if (sigma_mean < self.backbone_min_sigma):
      print("      *** poor backbone density, skipping", file=self.out)
      return False
    return True

class extend_and_refine(object):
  """
  Run the combined sidechain extension and real-space fitting, and optionally
  write final model and map coefficients.
  """
  def __init__(self,
      pdb_hierarchy,
      xray_structure,
      fmodel,
      params,
      cif_objects=(),
      out=sys.stdout,
      output_model=None,
      output_map_coeffs=None,
      prefix=None,
      write_files=True,
      reset_segid=True,
      verbose=True):
    if (write_files):
      assert ((prefix is not None) or
              (not None in [output_model,output_map_coeffs]))
    if (params.build_hydrogens is Auto):
      params.build_hydrogens = xray_structure.hd_selection().count(True) > 0
    make_sub_header("Filling in partial sidechains", out=out)
    prefilter_callback = prefilter(
      fmodel=fmodel,
      out=out)
    n_atoms_start = xray_structure.sites_cart().size()
    self.n_extended = extend_protein_model(
      pdb_hierarchy=pdb_hierarchy,
      add_hydrogens=params.build_hydrogens,
      mon_lib_srv = mmtbx.monomer_library.server.server())
    print("  %d sidechains extended." % self.n_extended, file=out)
    if (self.n_extended > 0) and (not params.skip_rsr):
      pdb_hierarchy, xray_structure = refit_residues(
        pdb_hierarchy=pdb_hierarchy,
        cif_objects=cif_objects,
        fmodel=fmodel,
        use_rotamers=params.use_rotamers,
        anneal=params.anneal_residues,
        out=out)
    else :
      xray_structure = pdb_hierarchy.extract_xray_structure(
        crystal_symmetry=xray_structure)
    fmodel.update_xray_structure(xray_structure, update_f_calc=True)
    n_atoms_end = xray_structure.sites_cart().size()
    self.r_work = fmodel.r_work()
    self.r_free = fmodel.r_free()
    self.n_new_atoms = n_atoms_end - n_atoms_start
    self.pdb_file = self.map_file = None
    if reset_segid :
      for atom in pdb_hierarchy.atoms():
        atom.segid = ""
    if (write_files):
      if (output_model is None):
        output_model = prefix + "_extended.pdb"
      f = open(output_model, "w")
      f.write(pdb_hierarchy.as_pdb_or_mmcif_string(
         crystal_symmetry=fmodel.xray_structure.crystal_symmetry(),
         target_format='pdb'))
      f.close()
      self.pdb_file = output_model
      print("  wrote new model to %s" % output_model, file=out)
      if (output_map_coeffs is None):
        output_map_coeffs = prefix + "_maps.mtz"
      from mmtbx.maps.utils import get_maps_from_fmodel
      import iotbx.map_tools
      two_fofc_map, fofc_map = get_maps_from_fmodel(fmodel)
      iotbx.map_tools.write_map_coeffs(
        fwt_coeffs=two_fofc_map,
        delfwt_coeffs=fofc_map,
        file_name=output_map_coeffs)
      print("  wrote map coefficients to %s" % output_map_coeffs, file=out)
      self.map_file = output_map_coeffs


 *******************************************************************************


 *******************************************************************************
mmtbx/building/ligands/__init__.py
from __future__ import absolute_import, division, print_function
from mmtbx.building.ligands import lifi # special import


 *******************************************************************************


 *******************************************************************************
mmtbx/building/ligands/lifi.py
from __future__ import absolute_import, division, print_function
import iotbx.pdb
import mmtbx.utils
from scitbx.array_family import flex
import mmtbx.refinement.real_space.explode_and_refine
from libtbx.test_utils import approx_equal
from libtbx.utils import null_out
import mmtbx.refinement.real_space.individual_sites
from libtbx import group_args
import iotbx.map_manager
import sys
import iotbx.map_model_manager
import inspect
from libtbx.utils import user_plus_sys_time

class run(object):
  """
  Build and real-space-refine ligand into map. Ligand must be a linear molecule
  such as ATP or PEG.

  map_model_manager:
    - contains masked ligand map in the box;
    - origin is zero;
    - unit cell and symmetry correspond to box cell and symmetry;
    - map values outside ligand region are set to zero;
    - map values inside ligand region are actual map values;
    - contains model with the ideal liagnd from the library positioned
      arbitrarily in space;
  """

  def __init__(self, map_model_manager, d_min, log = sys.stdout):
    # Timing
    self.total_time = 0
    self.time_strings = []
    # Aliases
    self.log = log
    self.d_min = d_min
    self.mmm = map_model_manager
    self.cs = self.mmm.crystal_symmetry()
    self.uc = self.cs.unit_cell()
    # Initiate states collector
    self.states = self.caller(func = self._init_states_accumulator)
    # Modify maps
    self.map_data_ref, self.mc_ref, self.map_data = self.caller(
      func=self._get_modified_maps)
    # Spread atoms evenly inside the blob
    self.dummy_atoms_in_map = self.caller(func = self._initial_trace)
    # pdb hierarchies corresponding to two initial placements
    self.hierarchies_placed = []
    # Place ligand atoms along the trace (forward)
    self.hierarchies_placed.append( self.caller(func = self._place_forward) )
    # Place ligand atoms along the trace (backward)
    self.hierarchies_placed.append( self.caller(func = self._place_backward) )
    # Choose one best placement, set result to mmm's model
    self.caller(func = self._choose_one_placement)
    # Model fragment analysis
    self.fragments = self.caller(func = self._fragments)
    # Explode and refine
    self.caller(func = self._ear)
    # Write final model and all states
    self.caller(func = self._write_final_model)
    self._show_timing()

  def caller(self, func):
    timer = user_plus_sys_time()
    doc = inspect.getdoc(func)
    #if(doc is not None): broadcast(m = doc, log = self.log)
    result = func()
    t = timer.elapsed()
    self.total_time += t
    fmt = "  %s: %s"%(doc, str("%8.3f"%t).strip())
    self.time_strings.append(fmt)
    #self.log.flush()
    return result

  def _print(self, m):
    if(self.log is None): return
    print(m, file=self.log)

  def _show_cc(self, sites_cart):
    xrs = self.mmm.model().get_xray_structure()
    xrs.set_sites_cart(sites_cart)
    fc = self.mc_ref.structure_factors_from_scatterers(
      xray_structure = xrs).f_calc()
    return fc.map_correlation(other=self.mc_ref)

  def _write_final_model(self):
    """
    Write final model and all states
    """
    self.states.write(file_name = "all.pdb")
    self.mmm.write_model(file_name = "final.pdb")

  def _ear(self):
    """
    Explode-and-refine
    """
    model = self.mmm.model()
    xrs = model.get_xray_structure()
    ph = model.get_hierarchy()
    states = mmtbx.utils.states(pdb_hierarchy=ph)
    states.add(sites_cart = xrs.sites_cart())
    ear = mmtbx.refinement.real_space.explode_and_refine.run(
      xray_structure     = model.get_xray_structure(),
      pdb_hierarchy      = model.get_hierarchy(),
      map_data           = self.map_data,
      restraints_manager = model.get_restraints_manager(),
      states             = states,
      resolution         = self.d_min,
      map_data_ref       = self.map_data_ref,
      mode               = "thorough",
      score_method       = ["cc","geometry"],
      fragments          = self.fragments,
      number_of_trials   = 25,
      nproc              = 1,
      log=null_out())
    #
    cc = self._show_cc(sites_cart = ear.pdb_hierarchy.atoms().extract_xyz())
    self._print("Final, CC: %6.4f"%cc)
    self.states.add(hierarchy = ear.pdb_hierarchy)

  def _fragments(self):
    """
    Split into fragments
    """
    return get_fragments(model = self.mmm.model())

  def _t_search(self, model):
    """
    Translational grid search
    """
    CCBEST=-1
    sites_cart = model.get_sites_cart()
    SCBEST=None
    for x in [-2,0,2]:
      for y in [-2,0,2]:
        for z in [-2,0,2]:
          shift = flex.vec3_double([[x,y,z],]*model.size())
          model.set_sites_cart(sites_cart = sites_cart + shift)
          model = refine(model=model, map_data=self.map_data)
          CC = get_cc(
            xrs      = model.get_xray_structure(),
            d_min    = self.d_min,
            map_data = self.map_data_ref)
          if(CC>CCBEST):
            CCBEST=CC
            SCBEST = model.get_sites_cart().deep_copy()
    model.set_sites_cart(sites_cart=SCBEST)
    self.states.add(hierarchy = model.get_hierarchy())

  def _choose_one_placement(self):
    """
    Choose one placement: forward vs backward
    """
    cc_best = -1
    sites_cart_best = None
    for ih, ph in enumerate(self.hierarchies_placed):
      self._print("Orientation %d:"%ih)
      model = get_model_adhoc(crystal_symmetry = self.cs, ph = ph)
      # Pre-refine original placement
      for it in [1,2]:
        # XXX This invalidates grm with no way to get it back!
        #if(it==1): model.set_nonbonded_weight(value=1)
        #else:      model.set_nonbonded_weight(value=1000)
        model = sa_simple(model=model, map_data=self.map_data, log=None)
        model = refine(model=model, map_data=self.map_data)
      self.states.add(hierarchy = model.get_hierarchy())
      cc = self._show_cc(sites_cart = model.get_sites_cart())
      self._print(" SA and minimization, CC: %6.4f"%cc)
      #
      self._t_search(model = model)
      # Evaluate
      cc = self._show_cc(sites_cart = model.get_sites_cart())
      self._print(" Translaton search, CC: %6.4f"%cc)
      if(cc>cc_best):
        cc_best = cc
        sites_cart_best = model.get_sites_cart()
    model.set_sites_cart(sites_cart = sites_cart_best)
    self.states.add(hierarchy = model.get_hierarchy())
    # Atom order is different, so relly need to do this
    self.mmm.set_model(model)

  def _show_timing(self):
    print("Detailed timing:")
    max_len = int(flex.max(flex.double(
      [len(" ".join(it.split()[:-1])) for it in self.time_strings])))
    fmt = "%-"+str(max_len)+"s"
    cntr = 0
    for it in self.time_strings:
      p = it.split()
      p1, p2 = " ".join(p[:-1]), p[-1]
      print("  "+fmt%p1+p2)
      cntr += float(p2)
    print("Total: %8.3f"%self.total_time)
    assert approx_equal(cntr, self.total_time) # total time and the sum match!

  def _init_states_accumulator(self):
    """
    Initialize states accumulator
    """
    return mmtbx.utils.states(pdb_hierarchy = self.mmm.model().get_hierarchy())

  def _get_modified_maps(self):
    """
    Make masked and negated maps
    """
    map_data_ref = self.mmm.map_data().deep_copy()
    map_data_ref = map_data_ref.set_selected(map_data_ref < 1, 0)
    map_data = self.mmm.map_data().deep_copy()
    map_data = map_data.set_selected(map_data<3, -10)
    fc = self.mmm.model().get_xray_structure().structure_factors(
      d_min=self.d_min).f_calc()
    mc_ref = fc.structure_factors_from_map(map=map_data_ref, use_sg=False)
    return map_data_ref, mc_ref, map_data

  def _place_forward(self):
    """
    Replace dummy atoms with ligand atoms (forward)
    """
    hierarchy = trace_to_hierarchy(
      ph         = self.mmm.model().get_hierarchy(),
      trace_cart = self.dummy_atoms_in_map,
      uc         = self.uc)
    self.states.add(hierarchy = hierarchy)
    cc = self._show_cc(sites_cart = hierarchy.atoms().extract_xyz())
    self._print("Trace forward, CC: %6.4f"%cc)
    return hierarchy

  def _place_backward(self):
    """
    Replace dummy atoms with ligand atoms (backward)
    """
    hierarchy = trace_to_hierarchy(
      ph         = self.mmm.model().get_hierarchy(),
      trace_cart = self.dummy_atoms_in_map,
      uc         = self.uc,
      reverse    = True)
    self.states.add(hierarchy = hierarchy)
    cc = self._show_cc(sites_cart = hierarchy.atoms().extract_xyz())
    self._print("Trace backward, CC: %6.4f"%cc)
    return hierarchy

  def _initial_trace(self):
    """
    Place dummy atoms into map
    """
    sites_cart = self.mmm.map_manager().trace_atoms_in_map(
      dist_min = 2, n_atoms  = self.mmm.model().size())
    #
    fmt = "HETATM %4d   O  HOH %5d    %8.3f%8.3f%8.3f  1.00 30.00           O"
    lines = "\n".join(
      [fmt%(i,i,sc[0],sc[1],sc[2]) for i, sc in enumerate(sites_cart)])
    pdb_inp = iotbx.pdb.input(source_info=None, lines = lines)
    model = get_model_adhoc(crystal_symmetry = self.cs, pdb_inp = pdb_inp)

    self.states.add(hierarchy = model.get_hierarchy())
    model = sa_simple(model=model, map_data=self.map_data, log=null_out())
    #
    sites_cart = model.get_sites_cart()
    self.states.add(hierarchy = model.get_hierarchy())
    #
    start, end = get_se(coords = sites_cart, uc = self.uc)
    distances = flex.double([dist(start, s, self.uc) for s in sites_cart])
    sel = flex.sort_permutation(distances)
    sites_cart = sites_cart.select(sel)
    #
    return list(sites_cart)














































def dist(p1,p2, uc):
  return uc.distance(uc.fractionalize(p1), uc.fractionalize(p2))

def sa_simple(
        model,
        map_data,
        log):
  tmp_xrs = model.get_xray_structure().deep_copy_scatterers()
#  ro = mmtbx.refinement.real_space.individual_sites.easy(
#    map_data                    = map_data,
#    xray_structure              = tmp_xrs,
#    pdb_hierarchy               = model.get_hierarchy().deep_copy(),
#    geometry_restraints_manager = model.get_restraints_manager(),
#    rms_bonds_limit             = 0.01,
#    rms_angles_limit            = 1.0,
#    selection                   = None, #TODO
#    log                         = log)
#  weight = ro.w
  weight=50
  #
  from mmtbx.dynamics import simulated_annealing as sa
  tmp = model.get_xray_structure().deep_copy_scatterers()
  params = sa.master_params().extract()
  params.start_temperature=5000
  params.cool_rate=500
  sa.run(
    params             = params,
    xray_structure     = tmp,
    real_space         = True,
    target_map         = map_data,
    restraints_manager = model.get_restraints_manager(),
    wx                 = weight,
    wc                 = 1.,
    verbose            = False,
    log                = log)
  model.set_sites_cart(sites_cart=tmp.sites_cart())
  return model

def refine(model, map_data, start=None, end=None):
  #rm = model.get_restraints_manager().geometry
  #print dir(rm)
  #from mmtbx.geometry_restraints import reference
  #sites_cart_reference = flex.vec3_double([end,start])
  #selection = flex.size_t([0,30])
  #rm.adopt_reference_coordinate_restraints_in_place(
  #  reference.add_coordinate_restraints(
  #      sites_cart = sites_cart_reference,
  #      selection = selection,
  #      sigma = 0.02))

  ro = mmtbx.refinement.real_space.individual_sites.easy(
    map_data                    = map_data,
    xray_structure              = model.get_xray_structure(),
    pdb_hierarchy               = model.get_hierarchy(),
    geometry_restraints_manager = model.get_restraints_manager(),
    rms_bonds_limit             = 0.01,
    rms_angles_limit            = 1,
    selection                   = None, #TODO
    selection_real_space        = flex.bool(model.size(),True),
    w                           = 10,#None,
    log                         = None)
  model.set_sites_cart(sites_cart = ro.xray_structure.sites_cart())
  return model

def merge_common(lists):
    from collections import defaultdict
    neigh = defaultdict(set)
    visited = set()
    for each in lists:
        for item in each:
            neigh[item].update(each)
    def comp(node, neigh = neigh, visited = visited, vis = visited.add):
        nodes = set([node])
        next_node = nodes.pop
        while nodes:
            node = next_node()
            vis(node)
            nodes |= neigh[node] - visited
            yield node
    for node in neigh:
        if node not in visited:
            yield sorted(comp(node))

def get_se(coords, uc):
  d = -1
  start, end = None,None
  for i, c1 in enumerate(coords):
    for j, c2 in enumerate(coords):
      d_ = uc.distance(c1,c2)
      if(d_>d):
        start = c1
        end   = c2
        d     = d_
  return start, end

def get_fragments(model):
  rm = model.get_restraints_manager()
  atoms = model.get_hierarchy().atoms()
  all_selection = list(range(atoms.size()))
  # Planes
  planes = []
  planes_all = []
  for p in rm.geometry.planarity_proxies:
    planes.append(list(p.i_seqs))
    planes_all.extend(list(p.i_seqs))
  planes_all = list(set(planes_all))
#  print "planes    :", planes
#  print "planes_all:", planes_all
#  print
  # Chiral
  chirals = []
  chirals_unique = []
  for p in rm.geometry.chirality_proxies:
#    print "chiral:", p.i_seqs, [atoms[i].name for i in p.i_seqs]
    chirals.append(list(p.i_seqs))
    tmp=[]
    for i in p.i_seqs:
      if(not i in planes_all):
        tmp.append(i)
    chirals_unique.append(tmp)
  chirals_unique = list(merge_common(chirals_unique))[0]
  chirals_all    = list(merge_common(chirals))[0]
#  print "chirals_unique:", chirals_unique
#  print "chirals_all   :", chirals_all
  chirals_mapping = [chirals_all.index(u) for u in chirals_unique]
#  print "mapping:", chirals_mapping
  # Dihedral
  dihedrals = []
  dihedrals_unique = []
  for p in rm.geometry.dihedral_proxies:
#    print "dihedral:", p.i_seqs, [atoms[i].name for i in p.i_seqs]
    dihedrals.append(list(p.i_seqs))
    tmp=[]
    for i in p.i_seqs:
      if(not i in planes_all+chirals_all):
        tmp.append(i)
    dihedrals_unique.append(tmp)
  dihedrals_unique = list(merge_common(dihedrals_unique))[0]
  dihedrals_all    = list(merge_common(dihedrals))[0]
#  print "dihedrals_unique:", dihedrals_unique
#  print "dihedrals_all   :", dihedrals_all
  # Finalize
  pcd = dihedrals_all + chirals_all + planes_all
  #
  tmp = []
  for s in all_selection:
    if s in pcd: continue
    tmp.append(s)
  left = tmp[:]
#  print "pcd :", pcd
#  print "left:", left
  #
  angles = []
  for p in rm.geometry.angle_proxies:
    present = False
    for i in p.i_seqs:
      if i in left:
        present=True
        break
    if not present: continue
#    print list(p.i_seqs)
    angles.append(list(p.i_seqs))
  angles = list(merge_common(angles))
  #
  dihedrals_unique = [dihedrals_unique] + angles
  dihedrals_all    = [dihedrals_all   ] + angles
  dihedrals_unique = list(merge_common(dihedrals_unique))[0]
  dihedrals_all    = list(merge_common(dihedrals_all))[0]
#  print "dihedrals_unique:", dihedrals_unique
#  print "dihedrals_all   :", dihedrals_all
  dihedrals_mapping = [dihedrals_all.index(u) for u in dihedrals_unique]
#  print "mapping:", dihedrals_mapping

  # check
  pcd = dihedrals_unique + chirals_unique + planes_all
  pcd.sort()
  assert approx_equal(pcd, all_selection)
  #
  return group_args(
    planes_all       = planes_all,

    chirals_unique    = chirals_unique,
    chirals_all       = chirals_all,
    chirals_mapping   = flex.size_t(chirals_mapping),

    dihedrals_unique  = dihedrals_unique,
    dihedrals_all     = dihedrals_all,
    dihedrals_mapping = flex.size_t(dihedrals_mapping))

def get_cc(xrs, d_min, map_data):
  fc = xrs.structure_factors(d_min=d_min).f_calc()
  fo = fc.structure_factors_from_map(map=map_data, use_sg=False)
  return fc.map_correlation(other=fo)

def trace_to_hierarchy(ph, trace_cart, uc, reverse=False):
  if(reverse): trace_cart.reverse()
  ph_dc = ph.deep_copy()
  xyz = flex.vec3_double(trace_cart)
  ss =  flex.std_string(ph_dc.as_pdb_string().splitlines())
  sites_cart = ph_dc.atoms().extract_xyz()
  start, end = get_se(coords=sites_cart, uc = uc)
  distances = flex.double([dist(start, s, uc) for s in sites_cart])
  sel = flex.sort_permutation(distances)
  ss = ss.select(sel)
  pi = iotbx.pdb.input(source_info=None, lines=ss)
  ph_dc = pi.construct_hierarchy(sort_atoms=False)
  ph_dc.atoms().set_xyz(xyz)
  return ph_dc

def get_model_adhoc(crystal_symmetry, ph=None, pdb_inp=None):
  params = mmtbx.model.manager.get_default_pdb_interpretation_params()
  params.pdb_interpretation.clash_guard.nonbonded_distance_threshold=None
  params.pdb_interpretation.nonbonded_weight=1000
  if(pdb_inp is not None):
    model = mmtbx.model.manager(
      model_input      = pdb_inp,
      crystal_symmetry = crystal_symmetry,
      log              = null_out())
  else:
    model = mmtbx.model.manager(
       model_input      = None,
       crystal_symmetry = crystal_symmetry,
       log              = null_out(),
       pdb_hierarchy    = ph)
  model.process(pdb_interpretation_params=params, make_restraints=True)
  return model


 *******************************************************************************


 *******************************************************************************
mmtbx/building/ligands/tst_00.py
from __future__ import absolute_import, division, print_function
import random
from scitbx.array_family import flex
import iotbx.map_model_manager
from mmtbx.building import ligands
import libtbx.load_env
import os

if (1):
  random.seed(5198425)
  flex.set_random_seed(5198425)

pdb_str = """
REMARK Idealized model of ATP from a library
HETATM    1  C1' ATP     1      25.100  19.996  20.709  1.00 30.00           C
HETATM    2  C2  ATP     1      26.706  23.954  19.757  1.00 30.00           C
HETATM    3  C2' ATP     1      26.458  19.303  20.846  1.00 30.00           C
HETATM    4  C3' ATP     1      26.049  17.830  20.809  1.00 30.00           C
HETATM    5  C4  ATP     1      25.589  22.474  20.949  1.00 30.00           C
HETATM    6  C4' ATP     1      24.723  17.840  21.563  1.00 30.00           C
HETATM    7  C5  ATP     1      25.243  23.419  21.902  1.00 30.00           C
HETATM    8  C5' ATP     1      24.831  17.625  23.052  1.00 30.00           C
HETATM    9  C6  ATP     1      25.709  24.731  21.693  1.00 30.00           C
HETATM   10  C8  ATP     1      24.377  21.591  22.542  1.00 30.00           C
HETATM   11  N1  ATP     1      26.452  24.967  20.589  1.00 30.00           N
HETATM   12  N3  ATP     1      26.321  22.679  19.849  1.00 30.00           N
HETATM   13  N6  ATP     1      25.459  25.751  22.522  1.00 30.00           N
HETATM   14  N7  ATP     1      24.475  22.846  22.905  1.00 30.00           N
HETATM   15  N9  ATP     1      25.025  21.294  21.370  1.00 30.00           N
HETATM   16  O1A ATP     1      22.686  19.051  25.764  1.00 30.00           O
HETATM   17  O1B ATP     1      20.672  16.689  23.539  1.00 30.00           O
HETATM   18  O1G ATP     1      20.680  12.823  22.913  1.00 30.00           O
HETATM   19  O2' ATP     1      27.306  19.645  19.755  1.00 30.00           O
HETATM   20  O2A ATP     1      24.704  17.520  25.870  1.00 30.00           O
HETATM   21  O2B ATP     1      20.013  16.346  25.973  1.00 30.00           O
HETATM   22  O2G ATP     1      20.809  12.141  25.347  1.00 30.00           O
HETATM   23  O3' ATP     1      25.876  17.362  19.476  1.00 30.00           O
HETATM   24  O3A ATP     1      22.442  16.557  25.361  1.00 30.00           O
HETATM   25  O3B ATP     1      21.206  14.511  24.739  1.00 30.00           O
HETATM   26  O3G ATP     1      18.918  13.574  24.568  1.00 30.00           O
HETATM   27  O4' ATP     1      24.141  19.137  21.303  1.00 30.00           O
HETATM   28  O5' ATP     1      23.571  17.969  23.664  1.00 30.00           O
HETATM   29  PA  ATP     1      23.358  17.852  25.225  1.00 30.00           P
HETATM   30  PB  ATP     1      21.011  16.087  24.844  1.00 30.00           P
HETATM   31  PG  ATP     1      20.385  13.201  24.324  1.00 30.00           P
TER
"""

def run(prefix="tst_00_mmtbx_building_ligands"):
  # Ligand file
  with open("%s.pdb"%prefix,"w") as fo:
    fo.write(pdb_str)
  # Read map and model
  from iotbx.data_manager import DataManager
  dm = DataManager()
  map_file = libtbx.env.find_in_repositories(
    relative_path="mmtbx/building/ligands/tst_00_mmtbx_building_ligands.map",
    test=os.path.isfile)
  mm = dm.get_real_map(map_file)
  model = dm.get_model("%s.pdb"%prefix)
  model.set_crystal_symmetry(mm.crystal_symmetry())
  model.process(make_restraints=True)
  # Create map_model_manager
  mmm = iotbx.map_model_manager.map_model_manager(map_manager=mm, model=model)
  # Build ligand
  o = ligands.lifi.run(map_model_manager = mmm, d_min = 2.5)

if(__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
mmtbx/building/loop_closure/__init__.py
from __future__ import division
pass


 *******************************************************************************


 *******************************************************************************
mmtbx/building/loop_closure/berkeley_ramalyze.py
from __future__ import absolute_import, division, print_function
import iotbx.pdb
from mmtbx.building.loop_closure.utils import list_rama_outliers_h
from mmtbx.rotamer import ramachandran_eval

import sys

def run(args, log=sys.stdout):
  pdb_h = iotbx.pdb.input(source_info=None, file_name=args[0]).\
      construct_hierarchy()
  r = ramachandran_eval.RamachandranEval()
  outp = list_rama_outliers_h(pdb_h, r.rama_eval)
  print(outp)
  print("END")

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/building/loop_closure/ccd.py
from __future__ import absolute_import, division, print_function

from libtbx import adopt_init_args
import mmtbx.utils
from mmtbx.building.loop_closure import utils
from mmtbx.validation.ramalyze import ramalyze, RAMALYZE_OUTLIER, \
    RAMALYZE_ALLOWED, RAMALYZE_FAVORED
from scitbx.matrix import project_point_on_axis
import math
from scitbx.array_family import flex
from libtbx.test_utils import approx_equal
from libtbx.utils import null_out

import boost_adaptbx.boost.python as bp
from six.moves import zip,range
ext = bp.import_ext("mmtbx_validation_ramachandran_ext")
from mmtbx_validation_ramachandran_ext import rama_eval

ext2 = bp.import_ext("mmtbx_building_loop_closure_ext")
from mmtbx_building_loop_closure_ext import ccd_cpp

@bp.inject_into(ccd_cpp)
class _():

  def run(self, direction_forward=True, save_states=False, avoid_allowed_region=False):
    if save_states:
      self.states = mmtbx.utils.states(pdb_hierarchy=self.moving_h)
      self.states.add(sites_cart=self.moving_h.atoms().extract_xyz())

    phi_psi_atoms = utils.get_phi_psi_atoms(self.moving_h)
    if not direction_forward:
      phi_psi_atoms.reverse()

    # here we can start a ccd cycle
    self.n_iter = 0
    rmsd_good = 1000
    previous_rmsd = 1000
    self.early_exit = False
    # self.moving_h.write_pdb_file(file_name="start_ccd.pdb")
    while (rmsd_good > self.needed_rmsd and
        self.n_iter <= self.max_number_of_iterations and not self.early_exit):
      # print_rama_stats(phi_psi_atoms, r)
      # for phi_psi_pair in phi_psi_atoms[:-1]:

      # check rama again separately before the cycle
      # list_rama_outliers(phi_psi_atoms, r)

      for phi_psi_pair, rama_key in phi_psi_atoms:
        before_rama_score = utils.get_rama_score(phi_psi_pair, self.r, rama_key, round_coords=True)
        rama_score = before_rama_score
        # print "rama score:", rama_score, "->",
        for i, atoms in enumerate(phi_psi_pair):
          # current phi-psi angles:
          # find the optimal angle
          if atoms is None:
            continue
          if direction_forward:
            ccd_angle = self._find_angle(atoms[1].xyz, atoms[2].xyz)
          else:
            ccd_angle = self._find_angle(atoms[2].xyz, atoms[1].xyz)
          # print "phi_psi_angles", phi_psi_angles
          # rama_score = r.evaluate("general", phi_psi_angles)
          # print "rama_score", rama_score


          angle_modified = self._modify_angle(ccd_angle)
          # angle_modified = ccd_angle
          # print ("  ccd_angle", ccd_angle, angle_modified)
          # angle_modified = - angle_modified

          phi_psi_angles = utils.get_pair_angles(phi_psi_pair)
          # print "phi_psi_angles", phi_psi_angles
          before_rotation_rama_score = utils.get_rama_score(phi_psi_pair, self.r, rama_key, round_coords=True)
          if (ramalyze.evalScore(rama_key, before_rotation_rama_score) == RAMALYZE_OUTLIER
            or (avoid_allowed_region and ramalyze.evalScore(rama_key, before_rotation_rama_score) == RAMALYZE_ALLOWED)):
            # assert i == 0
            if i != 0:
              # this is a error, we should spot rama outliers on the first angle
              print("i", i)
              print(pair_info(phi_psi_pair))
              print("rama_key", rama_key)
              print("before_rotation_rama_score", before_rotation_rama_score, end=' ')
              print(ramalyze.evalScore(rama_key, before_rotation_rama_score))
              break

            # correct it to the nearest non-outlier region
            target_phi_psi = utils.find_nearest_non_outlier_region(phi_psi_pair, self.r, rama_key)
            # print "For outlier:", phi_psi_angles, target_phi_psi
            # here we want to correct outlier regardless the target function
            # outcome and proceed to the next phi-psi pair
            now_psi_angle0 = utils.get_dihedral_angle(phi_psi_pair[1])
            utils.rotate_atoms_around_bond(self.moving_h, atoms[1], atoms[2],
                angle=-phi_psi_angles[0]+target_phi_psi[0],direction_forward=direction_forward)
            # now psi angle
            now_psi_angle = utils.get_dihedral_angle(phi_psi_pair[1])

            # print "psi angles:", now_psi_angle0, now_psi_angle
            angles_ok = (approx_equal(now_psi_angle0-now_psi_angle, 0, eps=1e-4, out=null_out()) or
                approx_equal(now_psi_angle0-now_psi_angle, 360, eps=1e-4, out=null_out()) or
                approx_equal(now_psi_angle0-now_psi_angle, -360, eps=1e-4, out=null_out()))
            if not angles_ok:
                approx_equal(now_psi_angle0-now_psi_angle, 0, eps=1e-4)
                approx_equal(now_psi_angle0-now_psi_angle, 360, eps=1e-4)
                approx_equal(now_psi_angle0-now_psi_angle, -360, eps=1e-4)
            assert angles_ok
            # approx_equal(now_psi_angle0, now_psi_angle)
            # assert now_psi_angle0 == now_psi_angle
            utils.rotate_atoms_around_bond(self.moving_h, atoms[2], atoms[3],
                angle=-now_psi_angle+target_phi_psi[1], direction_forward=direction_forward)

            # approx_equal(utils.get_dihedral_angle(phi_psi_pair[0]), target_phi_psi[0])
            # approx_equal(utils.get_dihedral_angle(phi_psi_pair[1]), target_phi_psi[1])
            resulting_rama_ev = utils.rama_evaluate(phi_psi_pair, self.r, rama_key)
            # print "evaluation:", resulting_rama_ev, RAMALYZE_FAVORED
            assert resulting_rama_ev == RAMALYZE_FAVORED, resulting_rama_ev
            break # we are done with this phi_psi_pair
          # rotate the whole thing around
          utils.rotate_atoms_around_bond(self.moving_h, atoms[1], atoms[2],
              angle=angle_modified, direction_forward=direction_forward)
          after_rotation_rama_score = utils.get_rama_score(phi_psi_pair, self.r, rama_key, round_coords=True)
          # print "before/after rotation rama:", before_rotation_rama_score, after_rotation_rama_score
          # if before_rotation_rama_score > after_rotation_rama_score:
          eval_score_after_rotation = ramalyze.evalScore(rama_key, after_rotation_rama_score)
          if eval_score_after_rotation == RAMALYZE_OUTLIER or \
             eval_score_after_rotation == RAMALYZE_ALLOWED:
            # rotate back!!! / not always
            # print "  rotate back"
            if True: # always
              utils.rotate_atoms_around_bond(self.moving_h, atoms[1], atoms[2],
                  angle=-angle_modified,direction_forward=direction_forward)
          s = utils.get_rama_score(phi_psi_pair, self.r, rama_key,round_coords=True)
          assert utils.rama_score_evaluate(rama_key, s) != RAMALYZE_OUTLIER, s
          if avoid_allowed_region:
            assert utils.rama_score_evaluate(rama_key, s) != RAMALYZE_ALLOWED, "%s, %s" % (s, after_rotation_rama_score)

        # new rama score:
        after_rama_score = utils.get_rama_score(phi_psi_pair, self.r, rama_key)
        if after_rama_score + 1e-7 < before_rama_score:
          pass
          # print "before, after", before_rama_score, after_rama_score
          # STOP()

      rmsd_good = utils.get_rmsd_xyz_fixed(
          self.fixed_ref_atoms,
          [self.moving_h.atoms()[x] for x in self.moving_ref_atoms_iseqs])
      self.resulting_rmsd = rmsd_good
      # print "n_iter, rmsd:", self.n_iter, rmsd_good
      # print get_main_chain_rmsd(moving_h, original_h)

      if save_states:
        self.states.add(sites_cart=self.moving_h.atoms().extract_xyz())
      # if n_iter % 100 == 0:
      #   moving_h.write_pdb_file(file_name="int_%d.pdb" % n_iter)
      self.n_iter += 1
      self.early_exit = abs(previous_rmsd - rmsd_good) < self.convergence_diff
      # if self.early_exit:
      #   print "  Early exit:", self.early_exit, previous_rmsd - rmsd_good
      previous_rmsd = rmsd_good
    # print "number of iterations:", n_iter
    # print_rama_stats(phi_psi_atoms, r)
    # moving_h.write_pdb_file(file_name="int_%d.pdb" % n_iter)
    # states.write(file_name="all_states.pdb")

    # return rmsd_good, states, n_iter


class ccd_python():
  def __init__(self, fixed_ref_atoms, moving_h, moving_ref_atoms_iseqs,
      max_number_of_iterations=500, needed_rmsd=0.1):
    """
    fixed_ref_atoms - list of 3 atom objects, actually, only xyz's are needed
    moving_ref_atoms_iseqs - list of 3 indeces matching atoms in
      moving_h.atoms()[<here!>].
    moving_h - hierarchy to make closure. Atom positions in it will be changed!

    """
    assert len(fixed_ref_atoms) == 3
    assert len(moving_ref_atoms_iseqs) == 3
    assert moving_h is not None
    assert moving_h.atoms_size() > 10 # arbitrary
    # adopt_init_args(self, locals())
    self.moving_h = moving_h
    self.fixed_ref_atoms = fixed_ref_atoms
    self.moving_ref_atoms_iseqs = moving_ref_atoms_iseqs
    self.max_number_of_iterations = max_number_of_iterations
    self.needed_rmsd = needed_rmsd
    self.set_modify_angle_procedure(self._modify_angle)
    self.r = rama_eval()
    # self.states = mmtbx.utils.states(pdb_hierarchy=moving_h)
    self.convergence_diff = 1e-5
    # will be bool, True if converged before max_number_of_iterations reached
    self.early_exit = None
    self.resulting_rmsd = None


  def set_modify_angle_procedure(self, procedure):
    """
    can be used to set external procedure for angle modification.
    the only argument should be angle, should return new angle in degrees
    """
    self.modify_angle_procedure = procedure

  def _modify_angle(self,angle):
    """
    change angle found by minimization. Primary use - to avoid huge turns
    in first phi-psi angles.
    """
    threshold = 1
    if abs(angle) > threshold:
      if angle > 0:
        return threshold
      else:
        return -threshold
    else:
      return angle

  @staticmethod
  def _get_f_r_s(axis_point_1,axis_point_2, moving_coor, fixed_coor):
    fc_proj = project_point_on_axis(axis_point_1, axis_point_2, fixed_coor)
    mc_proj = project_point_on_axis(axis_point_1, axis_point_2, moving_coor)
    f = (fixed_coor[0]-fc_proj[0],fixed_coor[1]-fc_proj[1],fixed_coor[2]-fc_proj[2])
    r = (moving_coor[0]-mc_proj[0],moving_coor[1]-mc_proj[1],moving_coor[2]-mc_proj[2])
    ap_21 = (axis_point_2[0]-axis_point_1[0], axis_point_2[1]-axis_point_1[1], axis_point_2[2]-axis_point_1[2])
    r_norm = math.sqrt(r[0]*r[0]+r[1]*r[1]+r[2]*r[2])
    r_home = flex.vec3_double([(r[0]/r_norm, r[1]/r_norm, r[2]/r_norm)])
    ap_21_norm = math.sqrt(ap_21[0]*ap_21[0]+ap_21[1]*ap_21[1]+ap_21[2]*ap_21[2])
    theta_home = flex.vec3_double([(ap_21[0]/ap_21_norm, ap_21[1]/ap_21_norm, ap_21[2]/ap_21_norm)])
    tt = theta_home.cross(r_home)
    s_home = tt*(1/tt.norm())
    return flex.vec3_double([f]), s_home, r_norm, r_home

  def _find_angle(self, axis_point_1, axis_point_2):
    f_all = []
    s_home_all = []
    r_all = []
    r_home_all = []
    for fixed_xyz, moving_xyz in zip([x.xyz for x in self.fixed_ref_atoms],
        [self.moving_h.atoms()[x].xyz for x in self.moving_ref_atoms_iseqs]):
      f, s_home, r_norm, r_home = ccd_python._get_f_r_s(
          axis_point_1, axis_point_2, moving_xyz, fixed_xyz)
      f_all.append(f)
      s_home_all.append(s_home)
      r_all.append(r_norm)
      r_home_all.append(r_home)
    # calculating
    b = 0
    c = 0
    for i in range(3):
      b += list(2*r_all[i]*(f_all[i].dot(r_home_all[i])))[0]
      c += list(2*r_all[i]*(f_all[i].dot(s_home_all[i])))[0]
    znam = math.sqrt(b*b+c*c)
    sin_alpha = c/znam
    cos_alpha = b/znam
    alpha = math.atan2(sin_alpha, cos_alpha)
    # print "ver3 alpha:", math.degrees(alpha)
    return math.degrees(alpha)

  def run(self):
    # self.states.add(sites_cart=self.moving_h.atoms().extract_xyz())

    phi_psi_atoms = utils.get_phi_psi_atoms(self.moving_h)

    # here we can start a ccd cycle
    self.n_iter = 0
    rmsd_good = 1000
    previous_rmsd = 1000
    self.early_exit = False
    while (rmsd_good > self.needed_rmsd and
        self.n_iter <= self.max_number_of_iterations and not self.early_exit):
      # print_rama_stats(phi_psi_atoms, r)
      # for phi_psi_pair in phi_psi_atoms[:-1]:

      # check rama again separately before the cycle
      # list_rama_outliers(phi_psi_atoms, r)

      for phi_psi_pair, rama_key in phi_psi_atoms:
        before_rama_score = utils.get_rama_score(phi_psi_pair, self.r, rama_key, round_coords=True)
        rama_score = before_rama_score
        # print "rama score:", rama_score, "->",
        for i, atoms in enumerate(phi_psi_pair):
          # current phi-psi angles:
          # find the optimal angle
          ccd_angle = self._find_angle(atoms[1].xyz, atoms[2].xyz)
          # print "phi_psi_angles", phi_psi_angles
          # rama_score = r.evaluate("general", phi_psi_angles)
          # print "rama_score", rama_score
          angle_modified = self.modify_angle_procedure(ccd_angle)

          phi_psi_angles = utils.get_pair_angles(phi_psi_pair)
          before_rotation_rama_score = utils.get_rama_score(phi_psi_pair, self.r, rama_key, round_coords=True)
          if (ramalyze.evalScore(rama_key, before_rotation_rama_score) == RAMALYZE_OUTLIER):
              # or ramalyze.evalScore(rama_key, before_rotation_rama_score) == RAMALYZE_ALLOWED):
            # assert i == 0
            if i != 0:
              # this is a error, we should spot rama outliers on the first angle
              print("i", i)
              print(pair_info(phi_psi_pair))
              print("rama_key", rama_key)
              print("before_rotation_rama_score", before_rotation_rama_score, end=' ')
              print(ramalyze.evalScore(rama_key, before_rotation_rama_score))
              break

            # correct it to the nearest non-outlier region
            target_phi_psi = utils.find_nearest_non_outlier_region(phi_psi_pair, self.r, rama_key)
            # print "For outlier:", phi_psi_angles, target_phi_psi
            # here we want to correct outlier regardless the target function
            # outcome and proceed to the next phi-psi pair
            now_psi_angle0 = utils.get_dihedral_angle(phi_psi_pair[1])
            utils.rotate_atoms_around_bond(self.moving_h, atoms[1], atoms[2],
                angle=-phi_psi_angles[0]+target_phi_psi[0])
            # now psi angle
            now_psi_angle = utils.get_dihedral_angle(phi_psi_pair[1])

            # print "psi angles:", now_psi_angle0, now_psi_angle
            angles_ok = (approx_equal(now_psi_angle0-now_psi_angle, 0) or
                approx_equal(now_psi_angle0-now_psi_angle, 360) or
                approx_equal(now_psi_angle0-now_psi_angle, -360))

            assert angles_ok
            # approx_equal(now_psi_angle0, now_psi_angle)
            # assert now_psi_angle0 == now_psi_angle
            utils.rotate_atoms_around_bond(self.moving_h, atoms[2], atoms[3],
                angle=-now_psi_angle+target_phi_psi[1])

            approx_equal(utils.get_dihedral_angle(phi_psi_pair[0]), target_phi_psi[0])
            approx_equal(utils.get_dihedral_angle(phi_psi_pair[1]), target_phi_psi[1])
            resulting_rama_ev = utils.rama_evaluate(phi_psi_pair, self.r, rama_key)
            assert resulting_rama_ev == RAMALYZE_FAVORED, resulting_rama_ev
            break # we are done with this phi_psi_pair
          # rotate the whole thing around
          utils.rotate_atoms_around_bond(self.moving_h, atoms[1], atoms[2],
              angle=angle_modified)
          after_rotation_rama_score = utils.get_rama_score(phi_psi_pair, self.r, rama_key, round_coords=True)
          # print "before/after rotation rama:", before_rotation_rama_score, after_rotation_rama_score
          # if before_rotation_rama_score > after_rotation_rama_score:
          if ramalyze.evalScore(rama_key, after_rotation_rama_score) == RAMALYZE_OUTLIER:
            # rotate back!!! / not always
            # print "  rotate back"
            if True: # always
              utils.rotate_atoms_around_bond(self.moving_h, atoms[1], atoms[2],
                  angle=-angle_modified)
          s = utils.get_rama_score(phi_psi_pair, self.r, rama_key,round_coords=True)
          assert utils.rama_score_evaluate(rama_key, s) != RAMALYZE_OUTLIER, s

        # new rama score:
        after_rama_score = utils.get_rama_score(phi_psi_pair, self.r, rama_key)
        if after_rama_score + 1e-7 < before_rama_score:
          pass
          # print "before, after", before_rama_score, after_rama_score
          # STOP()

      rmsd_good = utils.get_rmsd(
          self.fixed_ref_atoms,
          [self.moving_h.atoms()[x].xyz for x in self.moving_ref_atoms_iseqs])
      self.resulting_rmsd = rmsd_good
      # print "n_iter, rmsd:", n_iter, rmsd_good,
      # print get_main_chain_rmsd(moving_h, original_h)

      # self.states.add(sites_cart=self.moving_h.atoms().extract_xyz())
      # if n_iter % 100 == 0:
      #   moving_h.write_pdb_file(file_name="int_%d.pdb" % n_iter)
      self.n_iter += 1
      self.early_exit = previous_rmsd - rmsd_good < self.convergence_diff
      previous_rmsd = rmsd_good
    # print "number of iterations:", n_iter
    # print_rama_stats(phi_psi_atoms, r)
    # moving_h.write_pdb_file(file_name="int_%d.pdb" % n_iter)
    # states.write(file_name="all_states.pdb")

    # return rmsd_good, states, n_iter


 *******************************************************************************


 *******************************************************************************
mmtbx/building/loop_closure/starting_conformations.py
from __future__ import absolute_import, division, print_function

from mmtbx.building.loop_closure import utils
from mmtbx.validation import ramalyze
import itertools
import numpy
import random
from libtbx.utils import null_out

import boost_adaptbx.boost.python as bp
from six.moves import zip
from six.moves import range
ext = bp.import_ext("mmtbx_validation_ramachandran_ext")
from mmtbx_validation_ramachandran_ext import rama_eval

from six.moves import cStringIO as StringIO

def set_rama_angles(moving_h, angles, direction_forward=True, check_omega=False):
  """
  angles = [(phi, psi), (phi, psi), ... (phi, psi)]
  phi or psi == None means we don't change this angle
  returns deep-copied hierarchy with new angles. Change occurs from first to
  last angle so starting point would be in the same place.
  This function should produce up to all possible favored conformations.
  This function doesn't change moving_h
  direction_forward==True - set from beginning to end - the end residue moves
  direction_forward==False - set from end to beginning, the first residue moves
  """
  # print "angles", angles
  # STOP()
  result_h = moving_h.deep_copy()
  result_h.reset_atom_i_seqs()
  fixed_omega = False
  phi_psi_atoms = utils.get_phi_psi_atoms(moving_h, omega=True)
  assert len(phi_psi_atoms) == len(angles), "%d != %d" % (len(phi_psi_atoms), len(angles))
  if not direction_forward:
    phi_psi_atoms.reverse()
    angles.reverse()
  for ps_atoms, target_angle_pair in zip(phi_psi_atoms, angles):
    phi_psi_pair = ps_atoms[0]
    # print "phi_psi_pair", phi_psi_pair
    omega = ps_atoms[2]
    phi_psi_angles = utils.get_pair_angles(phi_psi_pair)
    # print "ps_atoms, target_angle_pair", phi_psi_angles, target_angle_pair
    # phi
    if target_angle_pair[0] is not None and phi_psi_angles[0] is not None:
      rotation_angle = -phi_psi_angles[0]+target_angle_pair[0]
      # print "rot angle", rotation_angle
      # if not direction_forward:
      #   rotation_angle = -rotation_angle
      utils.rotate_atoms_around_bond(
          result_h,
          phi_psi_pair[0][1],
          phi_psi_pair[0][2],
          angle=rotation_angle,
          direction_forward=direction_forward)
    # psi
    if target_angle_pair[1] is not None and phi_psi_angles[1] is not None:
      rotation_angle = -phi_psi_angles[1]+target_angle_pair[1]
      # print "rot angle", rotation_angle
      # if not direction_forward:
      #   rotation_angle = -rotation_angle
      utils.rotate_atoms_around_bond(
          result_h,
          phi_psi_pair[1][1],
          phi_psi_pair[1][2],
          angle=rotation_angle,
          direction_forward=direction_forward)
    # omega
    if omega is not None and abs(abs(omega)-180) > 10 and check_omega:
      rotation_angle= -omega+180
      # print "Omega rotation:", omega, rotation_angle
      utils.rotate_atoms_around_bond(
          result_h,
          phi_psi_pair[0][0],
          phi_psi_pair[0][1],
          angle=rotation_angle,
          direction_forward=direction_forward)
      fixed_omega = True
  # print utils.list_rama_outliers_h(result_h)
  # result_h.write_pdb_file(file_name="variant_%s.pdb" % direction_forward)
  # STOP()
  return result_h, fixed_omega

def is_not_none_combination(comb):
  for pair in comb:
    if pair != (None, None):
      return True
  return False

def get_sampled_rama_favored_angles(rama_key, r=None, step=20):
  if r is None:
    r = rama_eval()
  result = []
  for i in range(-180, 180, step):
    for j in range(-180, 180, step):
      score = r.evaluate_angles(ramalyze.res_types[rama_key], i,j)
      r_ev = ramalyze.ramalyze.evalScore(ramalyze.res_types[rama_key], score)
      if r_ev == ramalyze.RAMALYZE_FAVORED:
        result.append((i,j))
  return result

def get_all_starting_conformations(moving_h, change_radius,
    include_allowed, n_outliers,
    direction_forward=True, cutoff=50, change_all=True, log=null_out(), check_omega=False):
  if log is None:
    log = StringIO()
  variants = []
  result = []
  r = rama_eval()
  phi_psi_atoms = utils.get_phi_psi_atoms(moving_h, omega=True)
  # print "N residue groups in h", [x.resseq for x in moving_h.residue_groups()]
  if len(phi_psi_atoms) == 0:
    print("Strange input to starting conformations!!!", file=log)
    return result
  n_rama = len(phi_psi_atoms)
  # print "n_rama", n_rama
  change_angles = [None]
  if change_all:
    change_angles = range((n_rama)//2-change_radius-n_outliers//2, (n_rama)//2+change_radius+1+n_outliers//2)
    # if change_angles[0] < 0:
    #   change_angles = range(change_angles[-1]-change_angles[0])
  has_twisted = False
  if check_omega:
    omegas = [x[2] for x in phi_psi_atoms]
    for o in omegas:
      if o is not None and abs(abs(o)-180) > 30:
        has_twisted = True
  print("n_outliers", n_outliers, file=log)
  for i, (phi_psi_pair, rama_key, omega) in enumerate(phi_psi_atoms):
    angle_is_outlier = utils.rama_evaluate(phi_psi_pair, r, rama_key) == ramalyze.RAMALYZE_OUTLIER
    angle_is_outlier = angle_is_outlier or (include_allowed and utils.rama_evaluate(phi_psi_pair, r, rama_key) == ramalyze.RAMALYZE_ALLOWED)
    twisted = omega is not None and ((abs(abs(omega)-180) > 30) and check_omega)
    print("in cycle, N, outlier?, change?, twisted?", i, angle_is_outlier, i in change_angles, twisted, file=log)
    if angle_is_outlier and n_outliers < 3:
      vs = get_sampled_rama_favored_angles(rama_key, r)
    elif (i in change_angles) or angle_is_outlier or has_twisted:
      # vs = get_sampled_rama_favored_angles(rama_key, r)
      vs = ramalyze.get_favored_regions(rama_key)
    else:
      vs = [(None, None)]
    variants.append(vs)
  print("variants", variants, file=log)

  # Filtering them, since could be
  # [len(x) for x in variants] = [129, 129, 4, 129, 129]
  # resulting in 1107691524 all_angles_combination
  n_comb = numpy.prod([len(x) for x in variants])
  if n_comb > cutoff:
    # still aiming for ~1000
    n_in_each = int(1000 ** (1/len(variants)))
    variants = [random.sample(x, n_in_each) if len(x)>n_in_each else x for x in variants]
  all_angles_combination = list(itertools.product(*variants))
  # filter none combinations
  # print "len(all_angles_combination)", len(all_angles_combination)
  all_angles_combination_f = []
  for comb in all_angles_combination:
    if is_not_none_combination(comb):
      all_angles_combination_f.append(comb)
  print("len(all_angles_combination_f)", len(all_angles_combination_f), file=log)
  return all_angles_combination_f
  # if len(all_angles_combination_f) == 0:
  #   print "In starting conformations - outlier was fixed?"
  #   return result
  # n_added = 0
  # n_all_combination = len(all_angles_combination_f)
  # i_max = min(cutoff, n_all_combination)
  # assert i_max > 0
  # step = float(n_all_combination-1)/float(i_max-1)
  # if step < 1:
  #   step = 1
  # for i in range(i_max):
  #   comb = all_angles_combination_f[int(round(step*i))]
  #   result.append(set_rama_angles(moving_h, list(comb),direction_forward=direction_forward))
  #   print >> log, "Model %d, angles:" % i, comb
  # return result


 *******************************************************************************


 *******************************************************************************
mmtbx/building/loop_closure/utils.py
from __future__ import absolute_import, division, print_function

from mmtbx.conformation_dependent_library import generate_protein_threes
from scitbx.matrix import rotate_point_around_axis
from mmtbx.validation import ramalyze
import math
from six.moves import cStringIO as StringIO
from mmtbx.validation.ramalyze import res_types
from scitbx.math import dihedral_angle
# from scitbx.matrix import _dihedral_angle # python implementation, but on flex arrays

import boost_adaptbx.boost.python as bp
from six.moves import zip
from six.moves import range
ext = bp.import_ext("mmtbx_validation_ramachandran_ext")
from mmtbx_validation_ramachandran_ext import rama_eval

def get_phi_psi_atoms(hierarchy, omega=False):
  phi_psi_atoms = []
  for three in generate_protein_threes(
        hierarchy=hierarchy,
        geometry=None,
        cdl_class=True):
    psatoms = three.get_phi_psi_atoms()
    if psatoms is not None:
      phi_atoms, psi_atoms = psatoms
    else:
      phi_atoms, psi_atoms = None, None
    rama_key = three.get_ramalyze_key()
    # print "rama_key", rama_key
    if omega:
      phi_psi_atoms.append(([phi_atoms, psi_atoms],rama_key, three.get_omega_value()))
    else:
      phi_psi_atoms.append(([phi_atoms, psi_atoms],rama_key))
  return phi_psi_atoms

def list_omega_outliers(hierarchy, log):
  pso_atoms = get_phi_psi_atoms(hierarchy, omega=True)
  print("Omega outliers:", file=log)
  for psatoms, rama_key, omega in pso_atoms:
    if omega is not None and abs(abs(omega)-180) > 30:
      print("  ", psatoms[0][0].id_str(), omega, file=log)

def list_omega(hierarchy, log):
  pso_atoms = get_phi_psi_atoms(hierarchy, omega=True)
  print("Omega angles:", file=log)
  for psatoms, rama_key, omega in pso_atoms:
    print("  ", psatoms[0][0].id_str(), omega, file=log)

def n_bad_omegas(hierarchy):
  result = 0
  pso_atoms = get_phi_psi_atoms(hierarchy, omega=True)
  for psatoms, rama_key, omega in pso_atoms:
    if omega is not None and abs(abs(omega)-180) > 30:
      result += 1
  return result

def py_dihedral_angle2(sites, deg=True):
  """
  Should not be used anywhere. Algorithm maybe faster that currently available
  in c++, needs further investigation.
  - experimental, while aware of analogous c++ implementation;
  - custom duplication of basic linalg functions is intentional;
  - no tests since not used in production and may be removed in future.
  """
  def dot_product(a,b):
    return a[0]*b[0]+a[1]*b[1]+a[2]*b[2]
  def cross_product(a,b):
    return (a[1] * b[2] - b[1] * a[2],
            a[2] * b[0] - b[2] * a[0],
            a[0] * b[1] - b[0] * a[1])
  """ sites = [(vec3),(vec3),(vec3),(vec3)]
  # supposed to be fast dihedral calculation, taken from here:
  # http://stackoverflow.com/a/34245697
  # Pure python
  Praxeolitic formula
  1 sqrt, 1 cross product
  2.5 times slower than dihedral_angle in cpp
  """

  p0 = sites[0]
  p1 = sites[1]
  p2 = sites[2]
  p3 = sites[3]

  b0 = (p0[0]-p1[0], p0[1]-p1[1], p0[2]-p1[2])
  b1 = (p2[0]-p1[0], p2[1]-p1[1], p2[2]-p1[2])
  b2 = (p3[0]-p2[0], p3[1]-p2[1], p3[2]-p2[2])

  # normalize b1 so that it does not influence magnitude of vector
  # rejections that come next
  # b1 /= np.linalg.norm(b1)
  b1_norm = math.sqrt(b1[0]*b1[0]+b1[1]*b1[1]+b1[2]*b1[2])
  b1 = (b1[0]/b1_norm, b1[1]/b1_norm, b1[2]/b1_norm)

  # vector rejections
  # v = projection of b0 onto plane perpendicular to b1
  #   = b0 minus component that aligns with b1
  # w = projection of b2 onto plane perpendicular to b1
  #   = b2 minus component that aligns with b1
  b0_dp_b1 = dot_product(b0, b1)
  b2_dp_b1 = dot_product(b2, b1)
  v = (b0[0]-b0_dp_b1*b1[0],
       b0[1]-b0_dp_b1*b1[1],
       b0[2]-b0_dp_b1*b1[2])
  w = (b2[0]-b2_dp_b1*b1[0],
       b2[1]-b2_dp_b1*b1[1],
       b2[2]-b2_dp_b1*b1[2])
  # angle between v and w in a plane is the torsion angle
  # v and w may not be normalized but that's fine since tan is y/x
  x = dot_product(v, w)
  b1_cross_v = cross_product(b1, v)
  y = dot_product(b1_cross_v, w)
  return math.degrees(math.atan2(y, x))

def get_dihedral_angle(atoms, round_coords=False):
  # round here is to emulate rounding when dumping to pdb, to get more
  # consistent result for rama outliers inside program and when calculating
  # from resulted pdb file.
  if atoms is None:
    return None
  sites = []
  if round_coords:
    for x in atoms:
      sites.append((round(x.xyz[0], 3), round(x.xyz[1], 3), round(x.xyz[2], 3)))
  else:
    sites = [x.xyz for x in atoms]
  return dihedral_angle(
      sites = sites,
      deg=True)

def rama_score_evaluate(resType, value):
  return ramalyze.ramalyze.evalScore(resType, value)

def pair_info(phi_psi_pair):
  return phi_psi_pair[0][2].id_str()

def list_rama_outliers_h(hierarchy, r=None, include_allowed=False):
  if r is None:
    r = rama_eval()
  phi_psi_atoms = get_phi_psi_atoms(hierarchy)
  outp = list_rama_outliers(phi_psi_atoms, r, include_allowed=include_allowed)
  return outp

def pair_selection(phi_psi_pair, margin=1):
  resnum = phi_psi_pair[0][2].parent().parent().resseq_as_int()
  return "(chain %s and resid %s:%s)" % (phi_psi_pair[0][2].parent().parent().parent().id,
      resnum-margin, resnum+margin)

def rama_score_selection(hierarchy, r=None, score="outlier",margin=1):
  assert score in ["outlier", "allowed"]
  test = ramalyze.RAMALYZE_OUTLIER
  if score == "allowed":
    test = ramalyze.RAMALYZE_ALLOWED
  if r is None:
    r = rama_eval()
  out_sel = []
  phi_psi_atoms = get_phi_psi_atoms(hierarchy)
  for phi_psi_pair, rama_key in phi_psi_atoms:
    rama_score = get_rama_score(phi_psi_pair, r, rama_key)
    if rama_evaluate(phi_psi_pair, r, rama_key) == test:
      out_sel.append(pair_selection(phi_psi_pair, margin))
  out_sel_txt = " or ".join(out_sel)
  return out_sel_txt


def list_rama_outliers(phi_psi_atoms, r, include_allowed=False):
  result = ""
  # out_sel = []
  for phi_psi_pair, rama_key in phi_psi_atoms:
    rama_score = get_rama_score(phi_psi_pair, r, rama_key)
    if rama_evaluate(phi_psi_pair, r, rama_key) == ramalyze.RAMALYZE_OUTLIER:
      result += "  !!! OUTLIER %s, score=%f\n" % (pair_info(phi_psi_pair), rama_score)
    if include_allowed and rama_evaluate(phi_psi_pair, r, rama_key) == ramalyze.RAMALYZE_ALLOWED:
      result += "  !!! Allowed %s, score=%f\n" % (pair_info(phi_psi_pair), rama_score)
    # print "%s, %s, %s" % (pair_info(phi_psi_pair), get_rama_score(phi_psi_pair, r, rama_key), ramalyze.res_types[rama_key])
      # out_sel.append(pair_selection(phi_psi_pair))
    # print_rama_stats(phi_psi_atoms, r)
  # out_sel.txt = " or ".join(out_sel)
  # print out_sel
  return result


def get_rama_score(phi_psi_pair, r, rama_key, round_coords=False):
  # phi_psi_angles = get_pair_angles(phi_psi_pair, round_coords=round_coords)
  phi_psi_angles = get_pair_angles(phi_psi_pair, round_coords=False)
  if phi_psi_angles[0] is None or phi_psi_angles[1] is None:
    return None
  rama_score = r.get_score(rama_key, phi_psi_angles[0], phi_psi_angles[1])
  if round_coords:
    return rama_score*0.98
  return rama_score

def rama_evaluate(phi_psi_pair, r, rama_key, round_coords=False):
  score = get_rama_score(phi_psi_pair, r, rama_key, round_coords=round_coords)
  if score is None:
    return None
  # print "  score, rama_key", score, rama_key
  return r.evaluate_score(rama_key, score)

def get_pair_angles(phi_psi_pair, round_coords=False):
  phi_psi_angles = [0,0]
  phi_psi_angles[0] = get_dihedral_angle(phi_psi_pair[0], round_coords=round_coords)
  phi_psi_angles[1] = get_dihedral_angle(phi_psi_pair[1], round_coords=round_coords)
  return phi_psi_angles

def print_rama_stats(phi_psi_atoms, r):
  result = StringIO()
  for phi_psi_pair, rama_key in phi_psi_atoms:
    for i, atoms in enumerate(phi_psi_pair):
      for a in atoms:
        print(a.id_str(), file=result)
    rama_score = get_rama_score(phi_psi_pair, r, rama_key)
    print("rama score:", get_pair_angles(phi_psi_pair), rama_score, end=' ', file=result)
    print(rama_score_evaluate(rama_key, rama_score), rama_key, file=result)
    print("="*20, file=result)
  print("*"*80, file=result)
  r = result.getvalue()
  return r

def get_rmsd(fixed_points, moving_points):
  rmsd = 0
  for fp, mp in zip(fixed_points, moving_points):
    rmsd += fp.distance(mp)**2
  return math.sqrt(rmsd)

def get_rmsd_xyz_fixed(fixed_points, moving_points):
  rmsd = 0
  for fp, mp in zip(fixed_points, moving_points):
    rmsd += mp.distance(fp)**2
  return math.sqrt(rmsd)


def rotate_atoms_around_bond(
    moving_h, atom_axis_point_1, atom_axis_point_2, angle, degrees=True,
    direction_forward=True):
  # changes moving_h
  # print "in rotation, iseqs:", atom_axis_point_1.i_seq, atom_axis_point_2.i_seq
  #
  # find xyz based on i_seqs
  rotate_xyz1 = None
  rotate_xyz2 = None
  if not direction_forward:
    angle = -angle
  atoms = moving_h.atoms()
  for a in atoms:
    if a.i_seq == atom_axis_point_1.i_seq:
      rotate_xyz1 = a.xyz
    elif a.i_seq == atom_axis_point_2.i_seq:
      rotate_xyz2 = a.xyz
  # rotate stuff
  for a in atoms:
    if ((direction_forward and a.i_seq > atom_axis_point_1.i_seq) or
        (not direction_forward and a.i_seq < atom_axis_point_2.i_seq)):
      new_xyz = rotate_point_around_axis(
          axis_point_1=rotate_xyz1,
          axis_point_2=rotate_xyz2,
          point=a.xyz,
          angle=angle,
          deg=degrees)
      # let's round them
      # print "actually setting coordinates:", a.i_seq, a.xyz, "->", new_xyz
      # a.set_xyz((round(new_xyz[0], 3), round(new_xyz[1], 3), round(new_xyz[2], 3)))
      a.set_xyz(new_xyz)

def find_nearest_non_outlier_region(phi_psi_pair, r, rama_key):
  ''' In current implementation actually finds FAVORED region'''
  def spiral(N, M):
      x,y = 0,0
      dx, dy = 0, -1
      for dumb in range(N*M):
          if abs(x) == abs(y) and [dx,dy] != [1,0] or x>0 and y == 1-x:
              dx, dy = -dy, dx            # corner, change direction
          if abs(x)>N/2 or abs(y)>M/2:    # non-square
              dx, dy = -dy, dx            # change direction
              x, y = -y+dx, x+dy          # jump
          yield x, y
          x, y = x+dx, y+dy
  # ==
  phi_psi_angles = get_pair_angles(phi_psi_pair)
  for dx,dy in spiral(360, 360):
    angles = [phi_psi_angles[0]+dx, phi_psi_angles[1]+dy]
    if (r.evaluate_angles(res_types[rama_key], angles[0], angles[1]) == \
        ramalyze.RAMALYZE_FAVORED):
      return angles


 *******************************************************************************


 *******************************************************************************
mmtbx/building/loop_idealization.py
from __future__ import absolute_import, division, print_function
import iotbx.pdb
import mmtbx.utils
from mmtbx.monomer_library import idealized_aa
from libtbx.utils import Sorry, null_out
from mmtbx.validation import ramalyze
from mmtbx.building.loop_closure.ccd import ccd_cpp
from mmtbx.building.loop_closure import utils, starting_conformations
from mmtbx.secondary_structure.build.ss_idealization import side_chain_placement, \
    set_xyz_smart
from mmtbx.refinement.geometry_minimization import minimize_wrapper_for_ramachandran
from cctbx import maptbx
from scitbx.array_family import flex
from six.moves import cStringIO as StringIO
from mmtbx.conformation_dependent_library import generate_protein_threes
import math
from libtbx import easy_pickle
import scitbx.math
import mmtbx.idealized_aa_residues.rotamer_manager
import mmtbx.refinement.real_space.fit_residues

#import boost_adaptbx.boost.python as bp
#ext = bp.import_ext("mmtbx_validation_ramachandran_ext")
#from mmtbx_validation_ramachandran_ext import rama_eval

from iotbx.pdb.hybrid_36 import hy36encode, hy36decode


from mmtbx.refinement.real_space.individual_sites import minimize_wrapper_with_map
from six.moves import zip
from six.moves import range

loop_idealization_master_phil_str = """
loop_idealization
{
  enabled = True
    .type = bool
    .expert_level = 0
  output_prefix = None
    .type = str
    .expert_level = 0
  minimize_whole = True
    .type = bool
    .expert_level = 1
  fix_rotamers = True
    .type = bool
    .help = Fix rotamers before minimization
    .expert_level = 1
  force_rama_fixes = False
    .type = bool
    .help = If true, the procedure will pick and apply the best variant even \
      if all of them are above thresholds to be picked straight away. \
      Alternatively, when False, the procedure will accept failure and leave \
      a ramachandran outlier intact.
    .expert_level = 1
  include_allowed = False
    .type = bool
    .help = Try to fix residues in allowed Ramachandran region with CCD
  avoid_allowed_region = False
    .type = bool
    .help = If true, CCD will not let residues go to allowed region on \
      Ramachandran plot
  make_all_trans = True
    .type = bool
    .help = If true, procedure will try to get rid of all twisted and \
      cis-peptides making all of them trans.
    .expert_level = 1
  save_states = False
    .type = bool
    .help = Save states of CCD. Generates a states file for every model. \
      Warning! Significantly slower!
    .expert_level = 2
  number_of_ccd_trials = 3
    .type = int
    .help = How many times we are trying to fix outliers in the same chain
    .expert_level = 2
  variant_search_level = 2
    .type = int
    .help = how thoroughly variants will be explored (1-3)
    .expert_level = 2
  variant_number_cutoff = 50
    .type = int
    .help = how many first variants to take from generated
    .expert_level = 2
  variant_deviation_accept_level = low *med high very_high
    .type = choice(multi=False)
    .help = what deviation from starting model is acceptable when screening \
      variants. med is fine for real-space, low is for reciprocal space.
    expert_level = 2
  debug = False
    .type = bool
    .help = Output of intermediate files
    .expert_level = 3
}
"""

master_phil = iotbx.phil.parse(loop_idealization_master_phil_str)

#
# XXX
# XXX  This needs to be much more general tool to be called loop idealization.
# XXX  Right now it is just Ramachandran idealization. This should be
# XXX  separated. Loop idealization should include Cablam and Rama idealization.
# XXX
#


class loop_idealization():
  def __init__(self,
               model, # changed in place
               params=None,
               reference_map=None,
               log=null_out(),
               verbose=False,
               tried_rama_angles={},
               tried_final_rama_angles={},
               n_run=0):
    if model.get_number_of_models() > 1:
      raise Sorry("Multi-model files are not supported")
    self.model = model
    self.original_pdb_h = self.model.get_hierarchy()
    self.reference_map = reference_map
    self.params = self.process_params(params)
    self.log = log
    self.verbose = verbose
    self.ideal_res_dict = idealized_aa.residue_dict()
    self.n_run = n_run

    iaar_rotamer_manager = mmtbx.idealized_aa_residues.rotamer_manager.load(
      rotamers="favored")
    sin_cos_table = scitbx.math.sin_cos_table(n=10000)

    ram = ramalyze.ramalyze(pdb_hierarchy=self.model.get_hierarchy())
    self.p_initial_rama_outliers = ram.out_percent
    self.p_before_minimization_rama_outliers = None
    self.p_after_minimiaztion_rama_outliers = None

    # here we are recording what CCD solutions were used to fix particular
    # outliers to not use the same in the next CCD try.
    # Nested dict. First level:
    # key: chain id, value: dict
    #   key: resid (string), value: list of tried variants.
    self.tried_rama_angles = tried_rama_angles
    self.tried_final_rama_angles = tried_final_rama_angles

    berkeley_count = utils.list_rama_outliers_h(
        self.model.get_hierarchy(),
        self.model.get_ramachandran_manager()).count("\n")
    self.berkeley_p_before_minimization_rama_outliers = \
        berkeley_count/float(self.model.get_hierarchy().overall_counts().n_residues)*100
    n_bad_omegas = utils.n_bad_omegas(self.model.get_hierarchy())

    self.berkeley_p_after_minimiaztion_rama_outliers = self.berkeley_p_before_minimization_rama_outliers
    self.ref_exclusion_selection = ""
    self.number_of_ccd_trials = 0
    # print "logic expr outcome:", (self.number_of_ccd_trials < 10 and self.berkeley_p_before_minimization_rama_outliers > 0.001)
    # print self.number_of_ccd_trials < 10
    print("Rama outliers before idealization:", berkeley_count, self.berkeley_p_before_minimization_rama_outliers, file=self.log)
    if (self.berkeley_p_before_minimization_rama_outliers <= 0.001 and
        (n_bad_omegas<1 and self.params.make_all_trans)):
      print("No ramachandran outliers, skipping CCD step.", file=self.log)
    if self.verbose:
      print("n_bad_omegas", n_bad_omegas)
      print("self.params.make_all_trans",self.params.make_all_trans)
    if not self.params.enabled:
      print("Loop idealization is not enabled, use 'enabled=True'.", file=self.log)
    while (self.number_of_ccd_trials < self.params.number_of_ccd_trials
        and (self.berkeley_p_after_minimiaztion_rama_outliers > 0.001 or
            (n_bad_omegas>=1 and self.params.make_all_trans))
        and self.params.enabled):
      print("CCD try number, outliers:", self.number_of_ccd_trials, self.berkeley_p_before_minimization_rama_outliers, file=self.log)
      processed_chain_ids = []
      # TODO: verify tried_rama_angles is a dict or not
      for chain in self.model.get_master_hierarchy().only_model().chains():
        if chain.id not in self.tried_rama_angles:
          self.tried_rama_angles[chain.id] = {}
        if chain.id not in self.tried_final_rama_angles:
          self.tried_final_rama_angles[chain.id] = {}
        print("Idealizing chain %s" % chain.id, file=self.log)
        if chain.id not in processed_chain_ids:
          processed_chain_ids.append(chain.id)
        else:
          continue
        selection = "protein and chain %s and (name N or name CA or name C or name O)" % chain.id
        sel = self.model.selection("chain %s" % chain.id)
        chain_h = self.model.get_hierarchy().select(sel)
        m = chain_h.only_model()
        i = 0
        cutted_chain_h = None
        for c in m.chains():
          if i == 0:
            cutted_chain_h = iotbx.pdb.hierarchy.new_hierarchy_from_chain(c)
          else:
            print("WARNING!!! Duplicating chain ids! Only the first chain will be processed.", file=self.log)
            print("  Removing chain %s with %d residues" % (c.id, len(c.residues())), file=self.log)
            m.remove_chain(c)
          i += 1
        exclusions, ch_h = self.idealize_chain(
            hierarchy=(cutted_chain_h if cutted_chain_h else chain_h),
            include_allowed=self.params.include_allowed,
            tried_rama_angles_for_chain=self.tried_rama_angles[chain.id],
            tried_final_rama_angles_for_chain=self.tried_final_rama_angles[chain.id])
        if ch_h is not None:
          set_xyz_smart(
              # dest_h=self.model.get_hierarchy(),
              dest_h=chain,
              source_h=ch_h)
          self.model.set_sites_cart_from_hierarchy(multiply_ncs=True)
          for resnum in exclusions:
            selection += " and not resseq %s" % resnum
        self.ref_exclusion_selection += "(%s) or " % selection
        if self.verbose:
          print("self.tried_rama_angles", self.tried_rama_angles)
          print("self.tried_final_rama_angles", self.tried_final_rama_angles)
      #
      # dumping and reloading hierarchy to do proper rounding of coordinates
      resulting_pdb_h = iotbx.pdb.input(
          source_info=None,
          lines=self.model.get_hierarchy().as_pdb_or_mmcif_string()).construct_hierarchy()
      self.model.set_sites_cart(resulting_pdb_h.atoms().extract_xyz())

      berkeley_count = utils.list_rama_outliers_h(resulting_pdb_h).count("\n")
      self.berkeley_p_before_minimization_rama_outliers = \
          berkeley_count/float(resulting_pdb_h.overall_counts().n_residues)*100
      ram = ramalyze.ramalyze(pdb_hierarchy=resulting_pdb_h)
      self.p_before_minimization_rama_outliers = ram.out_percent
      if len(self.ref_exclusion_selection) > 0:
        self.ref_exclusion_selection = self.ref_exclusion_selection[:-3]

      duke_count = ram.get_outliers_count_and_fraction()[0]
      if self.params.debug or berkeley_count != duke_count:
        if berkeley_count != duke_count:
          print("Discrepancy between berkeley and duke after ccd:", berkeley_count, duke_count, file=self.log)
        self.model.pdb_or_mmcif_string_info(
          target_filename="%d%s_discrepancy.pdb" % (self.number_of_ccd_trials, self.params.output_prefix),
          write_file=True)

      if self.verbose:
        print("self.params.minimize_whole", self.params.minimize_whole)
      if self.params.minimize_whole:
        print("minimizing whole chain...", file=self.log)
        if self.verbose:
          print("self.ref_exclusion_selection", self.ref_exclusion_selection, file=self.log)
        # print >> sel
        # XXX but first let's check and fix rotamers...
        if self.params.fix_rotamers:
          print("Fixing/checking rotamers in loop idealization...", file=self.log)
          excl_sel = self.ref_exclusion_selection
          if len(excl_sel) == 0:
            excl_sel = None
          non_outliers_for_check = self.model.selection("(%s)" % self.ref_exclusion_selection)
          result = mmtbx.refinement.real_space.fit_residues.run(
              pdb_hierarchy     = self.model.get_hierarchy(),
              crystal_symmetry  = self.model.crystal_symmetry(),
              map_data          = self.reference_map,
              rotamer_manager   = iaar_rotamer_manager,
              sin_cos_table     = sin_cos_table,
              backbone_sample   = False,
              mon_lib_srv       = self.model.get_mon_lib_srv(),
              log               = self.log)
          model.set_sites_cart(
              sites_cart = result.pdb_hierarchy.atoms().extract_xyz())
        if self.params.debug:
          self.model.pdb_or_mmcif_string_info(
            target_filename="%d%s_all_not_minized.pdb" % (self.number_of_ccd_trials,self.params.output_prefix),
            write_file=True)
        if self.reference_map is None:
          minimize_wrapper_for_ramachandran(
              model = self.model,
              original_pdb_h=self.original_pdb_h,
              excl_string_selection=self.ref_exclusion_selection,
              log=None)
        else:
          mwwm = minimize_wrapper_with_map(
              model = self.model,
              target_map=self.reference_map,
              number_of_cycles=1,
              log=self.log)
      if self.params.debug:
        self.model.pdb_or_mmcif_string_info(
          target_filename="%d%s_all_minized.pdb" % (self.number_of_ccd_trials,self.params.output_prefix),
          write_file=True)
      ram = ramalyze.ramalyze(pdb_hierarchy=self.model.get_hierarchy())
      self.p_after_minimiaztion_rama_outliers = ram.out_percent
      berkeley_count = utils.list_rama_outliers_h(
          self.model.get_hierarchy(),
          self.model.get_ramachandran_manager()).count("\n")
      duke_count = ram.get_outliers_count_and_fraction()[0]
      n_bad_omegas = utils.n_bad_omegas(self.model.get_hierarchy())
      self.berkeley_p_after_minimiaztion_rama_outliers = \
          berkeley_count/float(self.model.get_hierarchy().overall_counts().n_residues)*100
      if berkeley_count != duke_count:
        print("Discrepancy between berkeley and duke after min:", berkeley_count, duke_count, file=self.log)
      else:
        print("Number of Rama outliers after min:", berkeley_count, file=self.log)
      print("Number of bad omegas:", n_bad_omegas, file=self.log)
      self.number_of_ccd_trials += 1
    # return new_h
    # return self.tried_rama_angles, self.tried_final_rama_angles

  def process_params(self, params):
    if params is None:
      params = master_phil.fetch().extract()
      params.loop_idealization.enabled = True
    if hasattr(params, "loop_idealization"):
      p_pars = params.loop_idealization
    else:
      assert hasattr(params, "enabled"), \
          "Something wrong with parameters passed to model_idealization"
      p_pars = params
    if p_pars.output_prefix is None:
      p_pars.output_prefix = "rama_fixed"
    assert isinstance(p_pars.enabled, bool)
    return p_pars

  def idealize_chain(self, hierarchy, include_allowed=False, tried_rama_angles_for_chain={},
      tried_final_rama_angles_for_chain={}):
    # check no ac:
    for c in hierarchy.chains():
      if len(c.conformers()) > 1:
        raise Sorry("Alternative conformations are not supported.")
      if "UNK" in c.get_residue_names_padded():
        pass
        # raise Sorry("UNK residues are not supported.")
    working_h = hierarchy.deep_copy()
    working_h.reset_atom_i_seqs()
    rama_results = []
    ranges_for_idealization = []
    print("rama outliers for input hierarchy:", file=self.log)
    rama_out_resnums = self.get_resnums_of_chain_rama_outliers(
        working_h,
        include_allowed=include_allowed)
    if len(rama_out_resnums) == 0:
      return None, None
    # get list of residue numbers that should be excluded from reference
    list_of_reference_exclusion = []
    for resnum in rama_out_resnums:
      excl_res = get_res_nums_around(
          hierarchy, [resnum], 2, 2, include_intermediate=True)
      list_of_reference_exclusion += excl_res
    out_i = 0
    chain_ss_annot = self.model.get_ss_annotation()
    if chain_ss_annot is not None:
      chain_ss_annot = chain_ss_annot.deep_copy()
      chain_ss_annot.remove_empty_annotations(hierarchy=working_h)
    # combine outliers next to each other
    comb_rama_out_resnums = [[rama_out_resnums[0]]]
    for r_out_resnum in rama_out_resnums[1:]:
      if abs(hy36decode(4, r_out_resnum)-hy36decode(4, comb_rama_out_resnums[-1][-1])) < 2:
        # combine
        comb_rama_out_resnums[-1].append(r_out_resnum)
      else:
        # separate
        comb_rama_out_resnums.append([r_out_resnum])

    print("Combined outliers for fixing:", comb_rama_out_resnums, file=self.log)
    for rama_out_resnum in comb_rama_out_resnums:
      print("Fixing outlier:", rama_out_resnum, file=self.log)
      self.log.flush()

      new_h = self.fix_rama_outlier(
        pdb_hierarchy=working_h,
        out_res_num_list=rama_out_resnum,
        prefix=self.params.output_prefix,
        minimize=False,
        ss_annotation=chain_ss_annot,
        tried_rama_angles_for_chain=tried_rama_angles_for_chain,
        tried_final_rama_angles_for_chain=tried_final_rama_angles_for_chain)
      if self.verbose:
        print("listing outliers after loop minimization", file=self.log)
        outp = utils.list_rama_outliers_h(new_h, self.model.get_ramachandran_manager())
        print(outp, file=self.log)
        utils.list_omega_outliers(new_h, self.log)
      self.log.flush()
      working_h = new_h
      out_i += 1
    return list_of_reference_exclusion, new_h

  def rangle_decart_dist(self, angle1, angle2):
    def normalize_angle(angle):
      result = (angle[0], angle[1])
      if angle[0] < 0:
        result = (angle[0]+180, angle[1])
      if angle[1] < 0:
        result = (angle[0], angle[1]+180)
      return result
    a1 = normalize_angle(angle1)
    a2 = normalize_angle(angle2)
    result = math.sqrt((a1[0]-a2[0])**2 + (a1[1]-a2[1])**2 )
    return result

  def ccd_solution_is_duplicated(self,
      final_angles,
      tried_final_rama_angles_for_chain):
    # first checking for repeated solutions:
    # TODO verify these arguments final_fnales and tried_final* are dicts
    for rn, angles in final_angles:
      if rn in tried_final_rama_angles_for_chain:
        for previous_angles in tried_final_rama_angles_for_chain[rn]:
          if self.rangle_decart_dist(angles, previous_angles) < 20:
            print("Rejecting the same solution:", angles, previous_angles)
            return True
    return False

  def ccd_solution_is_ok(self,
      anchor_rmsd, mc_rmsd, n_outliers, ccd_radius,
      change_all_angles, change_radius,
      contains_ss_element, fixing_omega):

    # then checking rmsd
    adaptive_mc_rmsd = {1:3.0, 2:3.5, 3:4.0, 4:4.5, 5:5.5, 6:7.0, 7:8.5, 8:10.0, 9:12.0}
    num_of_run = max(self.number_of_ccd_trials, self.n_run)
    accept_level_coeff = 1
    if self.params.variant_deviation_accept_level == "low":
      accept_level_coeff = 0.5
    elif self.params.variant_deviation_accept_level == "high":
      accept_level_coeff = 1.5
    elif self.params.variant_deviation_accept_level == "very_high":
      accept_level_coeff = 2.5
    for k in adaptive_mc_rmsd:
      adaptive_mc_rmsd[k] = adaptive_mc_rmsd[k] * (1 + 0.3*num_of_run) * accept_level_coeff
    if fixing_omega:
      for k in adaptive_mc_rmsd:
        adaptive_mc_rmsd[k] += 1
    # print "adaptive_mc_rmsd", adaptive_mc_rmsd
    # adaptive_mc_rmsd = {1:2.5, 2:3.0, 3:3.5}
    if anchor_rmsd is None:
      anchor_rmsd = 0
    ss_multiplier = 1
    if contains_ss_element:
      ss_multiplier = 0.4
    # print "checking is_ok, n_out, target rmsd:", n_outliers, adaptive_mc_rmsd[ccd_radius+n_outliers-1]
    target_rmsd = adaptive_mc_rmsd.get(ccd_radius+n_outliers-1, 14.0)*ss_multiplier
    if (mc_rmsd < target_rmsd  and anchor_rmsd < 0.3):
      return True, target_rmsd
    elif ccd_radius == 3 and change_all_angles and change_radius == 2:
      # we are desperate and trying the most extensive search,
      # this deserves relaxed criteria...
      # print "desperate checking", adaptive_mc_rmsd[ccd_radius+n_outliers+1]*ss_multiplier
      target_rmsd = adaptive_mc_rmsd.get(ccd_radius+n_outliers+1, 14.0)*ss_multiplier
      return mc_rmsd < target_rmsd and anchor_rmsd < 0.4, target_rmsd
    return False, target_rmsd

  def fix_rama_outlier(self,
      pdb_hierarchy, out_res_num_list, prefix="", minimize=True,
      ss_annotation=None,
      tried_rama_angles_for_chain={},
      tried_final_rama_angles_for_chain={}):

    def comb_pair_in_bad_pairs(comb_pair, bad_pairs):
      if None in comb_pair:
        return False
      all_combs = [comb_pair]
      all_combs.append((comb_pair[0]-20, comb_pair[1]))
      all_combs.append((comb_pair[0]+20, comb_pair[1]))
      all_combs.append((comb_pair[0], comb_pair[1]-20))
      all_combs.append((comb_pair[0], comb_pair[1]+20))
      all_c_adj = []
      for p in all_combs:
        new_p = p
        if p[0] > 180:
          new_p = (p[0]-180, p[1])
        if p[0] < -180:
          new_p = (p[0]+180, p[1])
        if p[1] > 180:
          new_p = (p[0], p[1]-180)
        if p[0] < -180:
          new_p = (p[0], p[1]+180)
        all_c_adj.append(new_p)
      for p in all_c_adj:
        if p in bad_pairs:
          return True
      return False

    original_pdb_h = pdb_hierarchy.deep_copy()
    original_pdb_h.reset_atom_i_seqs()
    original_pdb_h_asc = original_pdb_h.atom_selection_cache()
    chain_id = original_pdb_h.only_model().only_chain().id
    all_results = []
    # only forward
    # variants_searches = [
    #     #ccd_radius, change_all, change_radius, direction_forward
    #     ((1, False, 0, True ),1),
    #     # ((1, False, 0, False),1),
    #     ((2, False, 0, True ),1),
    #     # ((2, False, 0, False),1),
    #     ((3, False, 0, True ),2),
    #     # ((3, False, 0, False),2),
    #     ((2, True,  1, True ),1),
    #     # ((2, True,  1, False),1),
    #     ((3, True,  1, True ),2),
    #     # ((3, True,  1, False),2),
    #     ((3, True,  2, True ),3),
    #     # ((3, True,  2, False),3),
    # ]
    # only backward
    # variants_searches = [
    #     #ccd_radius, change_all, change_radius, direction_forward
    #     # ((1, False, 0, True ),1),
    #     ((1, False, 0, False),1),
    #     # ((2, False, 0, True ),1),
    #     ((2, False, 0, False),1),
    #     # ((3, False, 0, True ),2),
    #     ((3, False, 0, False),2),
    #     # ((2, True,  1, True ),1),
    #     ((2, True,  1, False),1),
    #     # ((3, True,  1, True ),2),
    #     ((3, True,  1, False),2),
    #     # ((3, True,  2, True ),3),
    #     ((3, True,  2, False),3),
    # ]
    # both
    variants_searches = [
        #ccd_radius, change_all, change_radius, direction_forward
        ((1, False, 0, True ),1),
        ((1, False, 0, False),1),
        ((2, False, 0, True ),1),
        ((2, False, 0, False),1),
        ((3, False, 0, True ),2),
        ((3, False, 0, False),2),
        ((2, True,  1, True ),1),
        ((2, True,  1, False),1),
        ((3, True,  1, True ),2),
        ((3, True,  1, False),2),
        ((3, True,  2, True ),3),
        ((3, True,  2, False),3),
    ]
    decided_variants = []
    for variant, level in variants_searches:
      if level <= self.params.variant_search_level:
        decided_variants.append(variant)

    for ccd_radius, change_all, change_radius, direction_forward in decided_variants:
    # while ccd_radius <= 3:
      fixing_omega = False
      if self.verbose:
        print("  Starting optimization with radius=%d, " % ccd_radius, end=' ', file=self.log)
        print("change_all=%s, change_radius=%d, " % (change_all, change_radius), end=' ', file=self.log)
        print("direction=forward" if direction_forward else "direction=backwards", file=self.log)
        self.log.flush()
      #
      (moving_h, moving_ref_atoms_iseqs, fixed_ref_atoms,
          m_selection, contains_ss_element, anchor_present) = get_fixed_moving_parts(
              pdb_hierarchy=pdb_hierarchy,
              out_res_num_list=out_res_num_list,
              # n_following=1,
              # n_previous=ccd_radius+ccd_radius-1,
              n_following=ccd_radius,
              n_previous=ccd_radius,
              ss_annotation=ss_annotation,
              direction_forward=direction_forward,
              log=self.log if self.verbose else None)
      # print "  moving_ref_atoms_iseqs", moving_ref_atoms_iseqs
      if self.verbose:
        print("  moving_h resseqs:", [x.resseq for x in moving_h.residue_groups()])
      moving_h_set = []
      all_angles_combination_f = starting_conformations.get_all_starting_conformations(
          moving_h,
          change_radius,
          include_allowed=self.params.include_allowed,
          n_outliers=len(out_res_num_list),
          direction_forward=direction_forward,
          cutoff=self.params.variant_number_cutoff,
          change_all=change_all,
          log=self.log if self.verbose else None,
          check_omega=self.params.make_all_trans,
          )

      #

      # print "len(all_angles_combination_f)", len(all_angles_combination_f)
      if len(all_angles_combination_f) == 0:
        print("In starting conformations - outlier was fixed?")
        # return result
      else:
        # here we should filter  first ones that in
        # tried_rama_angles_for_chain
        filter_out = [] # [[tried values],[tried values],...]
        for three in generate_protein_threes(
            hierarchy=moving_h,
            geometry=None):
          if three[1].resseq in list(tried_rama_angles_for_chain.keys()):
            filter_out.append(tried_rama_angles_for_chain[three[1].resseq])
          else:
            filter_out.append((None, None))
        ff_all_angles = []
        if self.verbose:
          print("filter_out", filter_out, file=self.log)
        for comb in all_angles_combination_f:
          good = True
          for comb_pair, bad_pairs in zip(comb, filter_out):
            if bad_pairs == (None, None):
              continue
            # print "comb_pair, bad_pairs", comb_pair, bad_pairs
            # if comb_pair in bad_pairs:
            if comb_pair_in_bad_pairs(comb_pair, bad_pairs):
              good = False
              # print "  Rejecting comb_pair", comb_pair
              break
          if good:
            ff_all_angles.append(comb)
        if self.verbose:
          print("len(all_angles_combination_f)", len(all_angles_combination_f), file=self.log)
          print("len(ff_all_angles)", len(ff_all_angles), file=self.log)
        n_added = 0
        n_all_combination = len(ff_all_angles)
        if n_all_combination == 0:
          print("Strange - got 0 combinations.", file=self.log)
        i_max = min(self.params.variant_number_cutoff, n_all_combination)
        # assert i_max > 0
        step = 0
        if i_max > 1:
          step = float(n_all_combination-1)/float(i_max-1)
        if step < 1:
          step = 1
        for i in range(i_max):
          comb = ff_all_angles[int(round(step*i))]
          setted_h, fixed_omega = starting_conformations.set_rama_angles(
                  moving_h,
                  list(comb),
                  direction_forward=direction_forward,
                  check_omega=self.params.make_all_trans)
          fixing_omega = fixing_omega or fixed_omega
          # print >> self.log, "Model %d, angles:" % i, comb
          if self.params.make_all_trans and utils.n_bad_omegas(setted_h) != 0:
            # Skipping conformation where omega was set incorrectly for
            # some reason.
            print("Model_%d_angles_%s.pdb" % (i, comb), end=' ')
            print("got ", utils.n_bad_omegas(moving_h_set[-1]), "bad omegas")
            moving_h_set[-1].write_pdb_or_mmcif_file(target_filename="Model_%d_angles_%s.pdb" % (i, comb))
            utils.list_omega(moving_h_set[-1], self.log)
            continue
            # assert 0
          moving_h_set.append(setted_h)

      if len(moving_h_set) == 0:
        # outlier was fixed before somehow...
        # or there's a bug in get_starting_conformations
        print("outlier was fixed before somehow", file=self.log)
        return original_pdb_h
      if self.verbose:
        print("self.tried_rama_angles inside", self.tried_rama_angles, file=self.log)
        print("tried_rama_angles_for_chain", tried_rama_angles_for_chain, file=self.log)
        print("checking values", ccd_radius, change_all, change_radius, direction_forward, file=self.log)
      for i, h in enumerate(moving_h_set):
        # if [x in tried_rama_angles_for_chain.keys() for x in out_res_num_list].count(True) > 0:
        #   print >> self.log, "Warning!!! make something here (check angles or so)"
        #   print >> self.log, "Skipping nonstable solution, tried previously:", (ccd_radius, change_all, change_radius, direction_forward, i)
        #   continue
        resulting_rmsd = None
        n_iter = 0
        if anchor_present:
          fixed_ref_atoms_coors = [x.xyz for x in fixed_ref_atoms]
          # print "params to constructor", fixed_ref_atoms, h, moving_ref_atoms_iseqs
          # easy_pickle.dump(file_name="crash.pkl", obj=[
          #     fixed_ref_atoms_coors,
          #     h,
          #     moving_ref_atoms_iseqs,
          #     direction_forward,
          #     self.params.save_states])
          ccd_obj = ccd_cpp(fixed_ref_atoms_coors, h, moving_ref_atoms_iseqs)
          ccd_obj.run(
              direction_forward=direction_forward,
              save_states=self.params.save_states,
              avoid_allowed_region=self.params.avoid_allowed_region)
          resulting_rmsd = ccd_obj.resulting_rmsd
          n_iter = ccd_obj.n_iter

          if self.params.save_states:
            states = ccd_obj.states
            states.write(file_name="%s%s_%d_%s_%d_%i_states.pdb" % (chain_id, out_res_num_list[0], ccd_radius, change_all, change_radius, i)) # PDB OK
        map_target = 0
        if self.reference_map is not None:
          map_target = maptbx.real_space_target_simple(
              unit_cell   = self.model.crystal_symmetry().unit_cell(),
              density_map = self.reference_map,
              sites_cart  = h.atoms().extract_xyz())

        mc_rmsd = get_main_chain_rmsd_range(moving_h, h, all_atoms=True)
        if self.verbose:
          print("Resulting anchor and backbone RMSDs, mapcc, n_iter for model %d, OK_rmsd:" % i, end=' ', file=self.log)
          print(resulting_rmsd, ",", mc_rmsd, ",", map_target, ",", n_iter, end=' ', file=self.log)
          self.log.flush()
        #
        # setting new coordinates
        #
        moved_with_side_chains_h = pdb_hierarchy.deep_copy()

        # setting xyz
        #
        for i_source, i_dest in enumerate(m_selection):
          moved_with_side_chains_h.atoms()[i_dest].set_xyz(h.atoms()[i_source].xyz)

        # set_xyz_smart(
        #     dest_h=moved_with_side_chains_h,
        #     source_h=h)

        #
        # placing side-chains
        #
        # moved_with_side_chains_h.write_pdb_file(
        #     file_name="%s_before_sc_placement_%d.pdb" % (prefix, i))
        placing_range = get_res_nums_around(moved_with_side_chains_h,
            center_resnum_list=out_res_num_list,
            n_following=ccd_radius,
            n_previous=ccd_radius,
            include_intermediate=True,
            avoid_ss_annot=ss_annotation)
        place_side_chains(moved_with_side_chains_h, original_pdb_h, original_pdb_h_asc,
            self.model.get_rotamer_manager(), placing_range, self.ideal_res_dict)
        # moved_with_side_chains_h.write_pdb_file(
        #     file_name="%s_after_sc_placement_%d.pdb" % (prefix, i))


        #
        # finalizing with geometry_minimization
        #

        # determining angles of interest
        # print "Recording picked angle for outliers"
        threes = generate_protein_threes(
          # hierarchy=moving_h,
          hierarchy=h,
          geometry=None)
        start_angles = []
        final_angles = []
        for angle_pair, three in zip(ff_all_angles[int(round(step*i))], threes):
          # print "three[1].resseq in out_res_num_list, angle_pair", three[1].resseq, out_res_num_list, angle_pair
          if three[1].resseq in out_res_num_list:
            # if three[1].resseq not in tried_rama_angles_for_chain.keys():
            #   tried_rama_angles_for_chain[three[1].resseq] = []
            start_angles.append((three[1].resseq, angle_pair))
            ps_angles = three.get_phi_psi_angles()
            final_angles.append((three[1].resseq, tuple(ps_angles)))
            # tried_rama_angles_for_chain[three[1].resseq].append(angle_pair)
            # print >> self.log, "Ended up with", three[1].resseq, "%.1f %.1f" % (ps_angles[0], ps_angles[1])
        # print "Updated tried_rama_angles_for_chain:", tried_rama_angles_for_chain
        if (not self.ccd_solution_is_duplicated(
            final_angles=final_angles,
            tried_final_rama_angles_for_chain=tried_final_rama_angles_for_chain)):
          all_results.append((moved_with_side_chains_h.deep_copy(), mc_rmsd, resulting_rmsd, map_target, n_iter))
        else:
          if self.verbose:
            print("Duplicate.", file=self.log)
          continue
        (ccd_ok, target_rmsd) = self.ccd_solution_is_ok(
            anchor_rmsd=resulting_rmsd,
            mc_rmsd=mc_rmsd,
            n_outliers=len(out_res_num_list),
            ccd_radius=ccd_radius,
            change_all_angles=change_all,
            change_radius=change_radius,
            contains_ss_element=contains_ss_element,
            fixing_omega=fixing_omega)
        if self.verbose:
          print(", %.2f" % target_rmsd, file=self.log)
        if ccd_ok:
          if self.verbose:
            print("Choosen result (mc_rmsd, anchor_rmsd, map_target, n_iter):", mc_rmsd, resulting_rmsd, map_target, n_iter, file=self.log)
          # Save to tried_ccds
          for rn, angles in start_angles:
            if rn not in list(tried_rama_angles_for_chain.keys()):
              tried_rama_angles_for_chain[rn] = []
            tried_rama_angles_for_chain[rn].append(angles)
          # Save final angles
          for rn, angles in final_angles:
            if rn not in list(tried_final_rama_angles_for_chain.keys()):
              tried_final_rama_angles_for_chain[rn] = []
            tried_final_rama_angles_for_chain[rn].append(angles)
          if self.verbose:
            print("Ended up with", final_angles, file=self.log)
            print("Updated tried_rama_angles_for_chain:", tried_rama_angles_for_chain, file=self.log)
            print("Updated tried_final_rama_angles_for_chain:", tried_final_rama_angles_for_chain, file=self.log)

          self.log.flush()
          assert not minimize
          # This is not working....
          if minimize:
            print("minimizing...", file=self.log)
            # moved_with_side_chains_h.write_pdb_file(
            #     file_name="%s_result_before_min_%d.pdb" % (prefix, i))
            if self.reference_map is None:
              minimize_wrapper_for_ramachandran(
                  hierarchy=moved_with_side_chains_h,
                  xrs=xrs,
                  original_pdb_h=original_pdb_h,
                  log=self.log,
                  grm=self.grm,
                  ss_annotation=self.secondary_structure_annotation)
            else:
              mwwm = minimize_wrapper_with_map(
                  pdb_h=moved_with_side_chains_h,
                  xrs=xrs,
                  target_map=self.reference_map,
                  grm=self.grm,
                  ss_annotation=self.secondary_structure_annotation,
                  log=self.log)
          # moved_with_side_chains_h.write_pdb_file(
          #     file_name="%s_result_minimized_%d.pdb" % (prefix, i))
          final_rmsd = get_main_chain_rmsd_range(moved_with_side_chains_h,
              original_pdb_h, placing_range)
          if self.verbose:
            print("FINAL RMSD after minimization:", final_rmsd, file=self.log)
          return moved_with_side_chains_h


    all_results.sort(key=lambda tup: tup[1])
    if self.verbose:
      print("ALL RESULTS:", file=self.log)
      i = 0
      for ar in all_results:
        print(ar[1:], end=' ', file=self.log)
        if ar[2] < 0.4:
          # fn = "variant_%d.pdb" % i
          # ar[0].write_pdb_file(file_name=fn)
          # print fn
          i += 1
        else:
          print("  no output", file=self.log)
    if self.params.force_rama_fixes:
      # find and apply the best varian from all_results. This would be the one
      # with the smallest rmsd given satisfactory closure
      print("Applying the best found variant:", end=' ', file=self.log)
      i = 0
      while i < len(all_results) and all_results[i][2] > 1.5:
        i += 1
      # apply
      # === duplication!!!!
      if i < len(all_results):
        print(all_results[i][1:], file=self.log)
        if minimize:
          print("minimizing...", file=self.log)
          # all_results[i][0].write_pdb_file(
          #     file_name="%s_result_before_min_%d.pdb" % (prefix, i))
          if self.reference_map is None:
            minimize_wrapper_for_ramachandran(
                hierarchy=all_results[i][0],
                xrs=xrs,
                original_pdb_h=original_pdb_h,
                log=self.log,
                grm=self.grm,
                ss_annotation=self.secondary_structure_annotation)
          else:
            mwwm = minimize_wrapper_with_map(
                pdb_h=all_results[i][0],
                xrs=xrs,
                target_map=self.reference_map,
                grm=self.grm,
                ss_annotation=self.secondary_structure_annotation,
                log=self.log)
        # all_results[i][0].write_pdb_file(
        #     file_name="%s_result_minimized_%d.pdb" % (prefix, i))
        final_rmsd = get_main_chain_rmsd_range(all_results[i][0],
            original_pdb_h, placing_range)
        if self.verbose:
          print("FINAL RMSD after minimization:", final_rmsd, file=self.log)
        return all_results[i][0]
      else:
        if self.verbose:
          print(" NOT FOUND!", file=self.log)
          for i in all_results:
            print(i[1:], file=self.log)
      # === end of duplication!!!!

    else:
      if self.verbose:
        print("Epic FAIL: failed to fix rama outlier:", out_res_num_list, file=self.log)
        print("  Options were: (mc_rmsd, resultign_rmsd, n_iter)", file=self.log)
        for i in all_results:
          print(i[1:], file=self.log)
    return original_pdb_h

  def get_resnums_of_chain_rama_outliers(self, pdb_hierarchy, include_allowed=False):
    phi_psi_atoms = utils.get_phi_psi_atoms(pdb_hierarchy, omega=True)
    # pdb_hierarchy.write_pdb_file(file_name="phi_psi_atoms.pdb")
    # print "len phi psi atoms", len(phi_psi_atoms)
    result = []
    rama_results = []
    ranges_for_idealization = []
    # print >> self.log, "rama outliers for input hierarchy:"
    list_of_reference_exclusion = []
    outp = utils.list_rama_outliers_h(pdb_hierarchy, self.model.get_ramachandran_manager(), include_allowed=include_allowed)
    print(outp, file=self.log)
    for phi_psi_pair, rama_key, omega in phi_psi_atoms:
      if phi_psi_pair[0] is not None and phi_psi_pair[1] is not None:
        # print "resseq:", phi_psi_pair[0][2].parent().parent().resseq
        ev = utils.rama_evaluate(phi_psi_pair, self.model.get_ramachandran_manager(), rama_key)
        # print "  ev", ev
        rama_results.append(ev)
        # print phi_psi_pair[0][0].id_str()
        resnum = phi_psi_pair[0][2].parent().parent().resseq
        if ev == ramalyze.RAMALYZE_OUTLIER:
          result.append(resnum)
        if include_allowed and ev == ramalyze.RAMALYZE_ALLOWED:
          result.append(resnum)
        if omega is not None and abs(abs(omega)-180) > 30:
          print("Spotted twisted/cis peptide:", resnum, omega, file=self.log)
          result.append(resnum)
    # STOP()
    return result


def place_side_chains(hierarchy, original_h, original_h_asc,
    rotamer_manager, placing_range, ideal_res_dict):
  # ideal_res_dict = idealized_aa.residue_dict()
  # asc = original_h.atom_selection_cache()
  gly_atom_names = set([" N  ", " CA ", " C  ", " O  "])
  n_ca_c_present = [False, False, False]
  for rg in hierarchy.residue_groups():
    if rg.resseq in placing_range:
      # cut extra atoms
      ag = rg.only_atom_group()
      for atom in ag.atoms():
        if (atom.name not in gly_atom_names):
          ag.remove_atom(atom=atom)
        if atom.name == " N  ":
          n_ca_c_present[0] = True
        elif atom.name == " CA ":
          n_ca_c_present[1] = True
        elif atom.name == " C  ":
          n_ca_c_present[2] = True
      if n_ca_c_present.count(True) < 3:
        # Not all essential atoms present for placing side-chain.
        continue
      # get ag from original hierarchy
      orig_ag = original_h.select(original_h_asc.selection("resseq %s" % rg.resseq)
          ).models()[0].chains()[0].residue_groups()[0].atom_groups()[0]
      # get ideal
      # ideal_ag = ideal_res_dict[ag.resname.lower()].models()[0].chains()[0].\
      #   residue_groups()[0].atom_groups()[0]
      # print "got to placement"
      side_chain_placement(ag, orig_ag, rotamer_manager)

def get_loop_borders(pdb_hierarchy, center_resnum_list, ss_annot):
  """ get loop resum beginning and end around center_resnum"""
  f_start_res_num =-9999
  f_end_res_num = 9999999
  if ss_annot is not None:
    for elem in ss_annot.simple_elements():
      if f_start_res_num < elem.get_end_resseq_as_int() <= hy36decode(4, center_resnum_list[0]):
        # print "  cutting..."
        f_start_res_num = elem.get_end_resseq_as_int()
      if hy36decode(4, center_resnum_list[-1]) <= elem.get_start_resseq_as_int() < f_end_res_num:
        # print "  cutting..."
        f_end_res_num = elem.get_start_resseq_as_int()
  loop_length = f_end_res_num - f_start_res_num
  return f_start_res_num, f_end_res_num


def get_res_nums_around(pdb_hierarchy, center_resnum_list, n_following, n_previous,
    include_intermediate=False, avoid_ss_annot=None, log=None):
  """
  Warning, this function most likely won't work properly with insertion codes
  """
  if log is None:
    log = StringIO()
  working_ss_annot = None
  if avoid_ss_annot is not None:
    working_ss_annot = avoid_ss_annot.deep_copy()
    working_ss_annot.remove_empty_annotations(
        hierarchy=pdb_hierarchy)
  residue_list = list(
      pdb_hierarchy.only_model().only_chain().only_conformer().residues())
  center_index = []
  for i in range(len(residue_list)):
    if residue_list[i].resseq in center_resnum_list:
      center_index.append(i)
      # break
  if not include_intermediate:
    # return residue_list[max(0,center_index-n_previous)].resseq, \
    #     residue_list[min(len(residue_list)-1,center_index+n_following)].resseq
    print("center_index, resnum list", center_index, center_resnum_list, file=log)
    # assert len(center_index) == len(center_resnum_list)
    start_res_num = residue_list[max(0,center_index[0]-n_previous)].resseq_as_int()
    end_res_num = residue_list[min(len(residue_list)-1,center_index[-1]+n_following)].resseq_as_int()
    srn, ern = get_loop_borders(pdb_hierarchy, center_resnum_list, working_ss_annot)
    print("start_res_num, end_res_num", start_res_num, end_res_num, file=log)
    print("srn, ern", srn, ern, file=log)
    # srn, ern = -9999, 9999999
    # So now we have borders of the loop: srn, ern, center_resnum,
    # n_following, n_previous.
    # We combine the above knowledge to adjust the borders keeping the same
    # loop size
    # adjst beginning
    if srn > start_res_num:
      end_res_num += srn - start_res_num
      start_res_num = srn
    # adjust end
    if ern < end_res_num:
      start_res_num = max(start_res_num - (end_res_num-ern), srn)
      end_res_num = ern

    f_start_res_num = start_res_num
    f_end_res_num = end_res_num
    print("srn, ern", srn, ern, file=log)
    print("f_start_res_num, f_end_res_num", f_start_res_num, f_end_res_num, file=log)
    if f_end_res_num == hy36decode(4, center_resnum_list[-1]):
      f_end_res_num += 1
    if f_start_res_num == hy36decode(4,center_resnum_list[0]):
      f_start_res_num -= 1
    print("after f_start_res_num, f_end_res_num", f_start_res_num, f_end_res_num, file=log)
    return hy36encode(4, f_start_res_num), hy36encode(4, f_end_res_num)
  else:
    res = []
    for i in range(max(0,center_index[0]-n_previous),
        min(len(residue_list)-1,center_index[-1]+n_following+1)):
      res.append(residue_list[i].resseq)
    return res

def get_fixed_moving_parts(pdb_hierarchy, out_res_num_list, n_following, n_previous,
    ss_annotation=None, direction_forward=True, log=None):
  # limitation: only one  chain in pdb_hierarchy!!!
  if log is None:
    log = StringIO()
  original_pdb_h = pdb_hierarchy.deep_copy()
  # print >> log, "  out_res_num, n_following, n_previous", out_res_num_list, n_following, n_previous
  start_res_num, end_res_num = get_res_nums_around(pdb_hierarchy, out_res_num_list,
      n_following, n_previous, include_intermediate=False, avoid_ss_annot=ss_annotation, log=log)
  print("  start_res_num, end_res_num", start_res_num, end_res_num, file=log)
  xrs = original_pdb_h.extract_xray_structure()
  pdb_hierarchy.truncate_to_poly_gly()
  cache = pdb_hierarchy.atom_selection_cache()
  # print "POSSIBLE ERROR:", "selectioin:", "(name N or name CA or name C or name O) and resid %s through %s" % (
  #         start_res_num, end_res_num)
  m_selection = cache.iselection(
      "(name N or name CA or name C or name O) and resid %s:%s" % (
          start_res_num, end_res_num))
  # Somewhere here would be the place to tweak n_following, n_previous to
  # exclude SS parts. It would be nice to increase n_prev in case
  # we need to cut on n_following etc.
  # If no ss_annotation is provided, don't filter.
  contains_ss_element = False
  if ss_annotation is not None:
    ss_selection_str = ss_annotation.overall_selection()
    ss_selection = cache.iselection(ss_selection_str)
    intersect = flex.size_t(sorted(list(set(ss_selection) & set(m_selection))))
    if intersect.size() > 0:
      intersect_h = pdb_hierarchy.select(intersect)
      print("Hitting SS element", file=log)
      print(intersect_h.as_pdb_or_mmcif_string(), file=log)
      contains_ss_element = False
      assert intersect_h.atoms_size() > 0, "Wrong atom count in SS intersection"
      # assert 0, "hitting SS element!"

  # print "m_selection=", list(m_selection)
  moving_h = pdb_hierarchy.select(m_selection)
  moving_h.reset_atom_i_seqs()
  # print >> log, "Moving h:"
  # print >> log, moving_h.as_pdb_string()
  # for rg in moving_h.only_chain().residue_groups():
  #   print >> log, "rg:", rg.resseq
  # print dir(moving_h)
  # STOP()
  m_cache = moving_h.atom_selection_cache()
  # print "len inp h atoms", pdb_hierarchy.atoms_size()
  # print "len moving_h atoms", moving_h.atoms_size()
  # here we need N, CA, C atoms from the end_res_num residue
  eff_end_resnum = end_res_num
  if not direction_forward:
    eff_end_resnum = start_res_num
  sel = m_cache.selection("resid %s" % end_res_num)
  int_eff_resnum = hy36decode(4,eff_end_resnum)
  while len(moving_h.select(sel).atoms()) == 0:
    if direction_forward:
      int_eff_resnum -= 1
    else:
      int_eff_resnum += 1
    # print >> log, "resid %d" % int_eff_resnum
    sel = m_cache.selection("resid %d" % int_eff_resnum)
    # print >> log, "sel:", list(sel)
    if int_eff_resnum < -10:
      assert 0
  eff_end_resnum = hy36encode(4, int_eff_resnum)

  anchor_present = True
  moving_ref_atoms_iseqs = []
  fixed_ref_atoms = []
  # print "fixed_ref_atoms:"
  base_sel = "resid %s and name " % eff_end_resnum
  for ssel in ["N", "CA", "C"]:
    sel = m_cache.selection(base_sel+ssel)
    atoms = moving_h.select(sel).atoms()
    if atoms.size() > 0:
      moving_ref_atoms_iseqs.append(atoms[0].i_seq)
      fixed_ref_atoms.append(atoms[0].detached_copy())
    else:
      anchor_present = False
    # print "  ", atoms[0].id_str()
  print("anchor_present", anchor_present, file=log)
  return (moving_h, moving_ref_atoms_iseqs, fixed_ref_atoms, m_selection,
      contains_ss_element, anchor_present)

def get_main_chain_rmsd_range(
    hierarchy, original_h, all_atoms=False, placing_range=None):
  rmsd = 0
  mc_atoms = None
  if all_atoms:
    mc_atoms = ["N", "CA", "C", "O"]
  else:
    mc_atoms = ["N", "CA", "C"]
  for m_atom, ref_atom in zip(hierarchy.atoms(), original_h.atoms()):
    if m_atom.name.strip() in mc_atoms:
      if (placing_range is None or
          m_atom.parent().parent().resseq in placing_range):
        rmsd += m_atom.distance(ref_atom)**2
  return rmsd**0.5


 *******************************************************************************


 *******************************************************************************
mmtbx/building/merge_models.py
from __future__ import absolute_import, division, print_function
import sys,os
import iotbx.pdb
from libtbx.utils import Sorry
import iotbx.phil
import mmtbx.maps.correlation
from scitbx.array_family import flex
from scitbx.matrix import col
from copy import deepcopy
from libtbx import adopt_init_args
from cctbx.maptbx import resolution_from_map_and_model
from six.moves import range
from six.moves import cStringIO as StringIO

# merge_models.py
# crossover models and pick best parts of each
#


master_phil = iotbx.phil.parse("""

  input_files {
    map_coeffs_file = None
      .type = path
      .help = File with map coefficients
      .short_caption = Map coefficients
      .style = bold file_type:hkl input_file process_hkl child:fobs:data_labels\
        child:space_group:space_group child:unit_cell:unit_cell

    map_coeffs_labels = None
      .type = str
      .input_size = 160
      .help = Optional label specifying which columns of of map coefficients \
          to use
      .short_caption = Map coeffs label
      .style = bold renderer:draw_fobs_label_widget

    map_file = None
      .type = path
      .help = File with CCP4-style map
      .short_caption = Map file

    pdb_in_file = None
      .type = path
      .help = Input PDB file to minimize
      .short_caption = Input PDB file

  }
  output_files {

    pdb_out = merged.pdb
      .type = path
      .help = Output PDB file (merged)
      .short_caption = Output PDB file

  }
  crystal_info {
     resolution = None
       .type = float
       .help = High-resolution limit. Data will be truncated at this\
               resolution. If a map is supplied, it will be Fourier \
               filtered at this resolution. Required if input is a map and \
                only_original_map is not set.
       .short_caption = High-resolution limit
       .style = resolution
     space_group = None
       .type = space_group
       .short_caption = Space Group
       .help = Space group (normally read from the data file)
     unit_cell = None
       .type = unit_cell
       .short_caption = Unit Cell
       .help = Unit Cell (normally read from the data file)

     scattering_table = wk1995  it1992  *n_gaussian  neutron electron
       .type = choice
       .help = Scattering table to use
       .short_caption = Scattering table
  }
  crossover {

     minimum_length = 2
       .type = int
       .short_caption = Minimum length of a crossover
       .help = Minimum length of a crossover

     maximum_fraction = 0.5
       .type = float
       .short_caption = Maximum replacement fraction
       .help = Maximum replacement fraction

     dist_max = 1.0
       .type = float
       .short_caption = Crossover distance
       .help = Maximum distance between atoms where crossover is to occur

     minimum_matching_atoms = 3
       .type = int
       .short_caption = Minimum number of matching atoms to cross over
       .help =  Minimum number of matching atoms to cross over

     crossover_atom =  CA
       .type = str
       .short_caption = Crossover atom
       .help = Atom where crossovers will occur

     smoothing_window = 5
       .type = int
       .short_caption = Smoothing window
       .help = Smoothing window. The residue CC values will be smoothed with \
              this window in calculating the optimal crossover

     max_keep = 10
       .type = int
       .short_caption = Max keep
       .help = Max keep. Number of solutions to carry along during optimization

     max_regions_to_test = 10
       .type = int
       .short_caption = Max regions to test
       .help = Maximum number of regions within a chain to test for crossover \
               with another chain.  Sorted on smoothed differences in local CC

     max_ends_per_region = 5
       .type = int
       .short_caption = Max ends per region
       .help = Maximum number of ends (left and right) to test for each \
               potential crossover region.

     minimum_improvement = 0.01
       .type = float
       .short_caption = Minimum improvement
       .help = Minimum improvement to keep a crossover

  }
  control {
      verbose = False
        .type = bool
        .help = Verbose output
        .short_caption = Verbose output
  }
""", process_includes=True)
master_params = master_phil

def get_params(args,out=sys.stdout):
  command_line = iotbx.phil.process_command_line_with_files(
    reflection_file_def="input_files.map_coeffs_file",
    map_file_def="input_files.map_file",
    pdb_file_def="input_files.pdb_in_file",
    args=args,
    master_phil=master_phil)
  params = command_line.work.extract()
  print("\nMerge_models: Take parts of multiple models to construct one model\n", file=out)
  master_phil.format(python_object=params).show(out=out)
  return params

class model_object:
  def __init__(self,
      source_id=None,
      source_list=None,
      cc_dict=None,
      smoothed_cc_dict=None,
      crossover_dict=None,
      minimum_length=0,
      minimum_improvement=0.01,
      max_regions_to_test=15,
      max_ends_per_region=5,
      maximum_fraction=0.5):

    adopt_init_args(self, locals())

    if self.source_id is not None: # list of models as source for each residue
       self.source_list=cc_dict[self.source_id].size()*[self.source_id]
    assert self.source_list is not None

    self.size=len(self.source_list)
    self.reset_score()

  def show_summary(self,out=sys.stdout):
    print("\nModel with %d sites and score of %7.2f" %(
     len(self.source_list),self.score), file=out)
    print(" ".join(self.source_list).replace("  "," "), file=out)

  def is_allowed_crossover(self,i=None,other=None):
    # return True if a crossover at position i to model other is allowed
    if other.source_list[i] in \
        self.crossover_dict.get(i,{}).get(self.source_list[i],[]):
      return True
    return False

  def customized_copy(self):
    new_model=model_object(
     source_list=deepcopy(self.source_list),
     minimum_length=self.minimum_length,
     minimum_improvement=self.minimum_improvement,
     maximum_fraction=self.maximum_fraction,
     max_regions_to_test=self.max_regions_to_test,
     max_ends_per_region=self.max_ends_per_region,
     cc_dict=self.cc_dict,
     smoothed_cc_dict=self.smoothed_cc_dict,
     crossover_dict=self.crossover_dict)
    return new_model

  def optimize_with_others(self,others=None):
    found=True
    best_model=self
    cycle=0
    while found:
      cycle+=1
      found=False
      for other_model in others:
          new_model=best_model.select_best_from_other_smooth(other_model)
          if not new_model: continue
          if best_model is None or new_model.get_score()>best_model.get_score():
            best_model=new_model
            found=True
    return best_model

  def select_best_from_other_smooth(self,
    other=None):

    # Use smoothed cc_dict to identify location where
    # biggest difference can be found and focus on that

    difference_list=[]
    for i1 in range(self.size):
      source_self=self.source_list[i1]
      source_other=other.source_list[i1]
      difference_list.append( [
       self.cc_dict[source_other][i1]-self.cc_dict[source_self][i1],
       i1])

    difference_list.sort()
    difference_list.reverse()

    best_score=self.get_score()
    original_score=best_score
    best_model=self

    # Now work down difference list until we get something useful.
    # For each one, find how far in either direction we can to go
    #  maximize the score after crossover

    for dd,i in difference_list[:self.max_regions_to_test]:
      if dd<self.minimum_improvement: continue

      #Now figure out where we can cross over on either side of i
      allowed_left_crossovers=[]
      allowed_right_crossovers=[]
      for ib in range(self.size):
        if not self.is_allowed_crossover(i,other): continue
        if ib <i: allowed_left_crossovers.append(ib)
        if ib >i: allowed_right_crossovers.append(ib)

      if not allowed_left_crossovers or not allowed_right_crossovers: continue

      # find best to left and to right, up to max_ends_per_region

      # if possible, find a right-crossover that is minimum_length from center
      i2=allowed_right_crossovers[0]
      for test_i2 in allowed_right_crossovers:
        if test_i2-i>self.minimum_length: # take it; it is long enough
          i2=test_i2
          break

      # find best start (i1, on left)
      best_i=None
      best_i_score=None
      for i1 in allowed_left_crossovers[-self.max_ends_per_region:]:
        if float(i2-i1+1)/self.size > self.maximum_fraction: continue
        # test replacing self with i1 to i2 of other
        test_model=self.customized_copy()
        for i in range(i1,i2+1):
          test_model.source_list[i]=other.source_list[i]
        test_model.reset_score()
        if best_i_score is None or \
           (test_model.get_score() and test_model.get_score()>best_i_score):
          best_i_score=test_model.get_score()
          best_i=i1
      i1=best_i
      if i1 is None:
        continue

      # Now find best end (right side ;i2)
      best_i=None
      best_i_score=None

      for i2 in allowed_right_crossovers[:self.max_ends_per_region]:
        if float(i2-i1+1)/self.size > self.maximum_fraction: continue
        # test replacing self with i1 to i2 of other
        test_model=self.customized_copy()
        for i in range(i1,i2+1):
          test_model.source_list[i]=other.source_list[i]
        test_model.reset_score()
        if best_i_score is None or \
           (test_model.get_score() and test_model.get_score()>best_i_score):
          best_i_score=test_model.get_score()
          best_i=i2

          #  save if best overall
          if test_model.get_score() and \
             test_model.get_score()>best_score+self.minimum_improvement:
            best_score=test_model.get_score()
            best_model=test_model
      if best_model.get_score()>original_score+self.minimum_improvement:
        return best_model  # take it (and skip other possibilities)


  def reset_score(self):
    self.score=None
    self.get_score()

  def get_score(self):
    if self.score is not None:
       return self.score

    # return -999 if any stretch of residues from 1 model is shorter than
    #  self.minimum_length
    last_id=None
    n=0
    for i in range(self.size):
      if last_id is None: last_id=self.source_list[i]
      if self.source_list[i]==last_id:
        n+=1
      elif n < self.minimum_length:
        return -999.
      else:
        n=1
        last_id=self.source_list[i]
    if n>0 and n<self.minimum_length:
      return -999.



    # sum up CC values at each residue
    score=0.
    for i in range(self.size):
      score+=self.cc_dict[self.source_list[i]][i]
    self.score=score
    return score

def get_atom_selection(chain_id=None,model_id=None,resseq_sel=None,
   start_resno=None,end_resno=None):

  if chain_id and chain_id.replace(" ",""):
    chain_sel=" chain %s " %(chain_id)
  else:
    chain_sel=""
  if model_id and model_id.replace(" ",""):
    model_sel="model %s " %(model_id)
  else:
    model_sel=""
  if chain_sel and model_sel:
    and_sel=" and "
  else:
    and_sel=""
  atom_selection="%s %s %s" %(model_sel,and_sel,chain_sel)

  if resseq_sel and resseq_sel.replace(" ",""):
    if atom_selection.replace(" ",""):
      atom_selection="%s and resseq %s" %(atom_selection,resseq_sel)
    else:
      atom_selection="resseq %s" %(resseq_sel)

  elif start_resno is not None and end_resno is not None:
    if atom_selection.replace(" ",""):
      atom_selection="%s and resseq %d:%d" %(atom_selection,start_resno,end_resno)
    else:
      atom_selection="resseq %d:%d" %(start_resno,end_resno)

  return atom_selection

def get_crossover_dict(
      n_residues=None,
      hierarchy=None,
      crossover_atom=None,
      minimum_matching_atoms=None,
      dist_max=None,
      verbose=None,
      out=sys.stdout):
  crossover_dict={}  # Allowed crossover for [position][id1][id2]
  print("\nMaking a table of allowed crossovers", file=out)

  # select out just the crossover atoms...

  atom_selection="name %s " %(crossover_atom)

  asc=hierarchy.atom_selection_cache()
  sel=asc.selection(string = atom_selection)
  sel_hierarchy=hierarchy.select(sel)

  dist_max_sq=dist_max**2
  used_model_ids=[]
  for model1 in sel_hierarchy.models():
    used_model_ids.append(model1.id)
    for chain1 in model1.chains():
      xyz1=chain1.atoms().extract_xyz()
      for model2 in sel_hierarchy.models():
        if model2.id in used_model_ids: continue # already did it
        for chain2 in model2.chains():
          xyz2=chain2.atoms().extract_xyz()
          if xyz1.size()!=xyz2.size():
            print("\nSize of chain " +\
            "'%s' model '%s' (%d) is different than chain '%s' model '%s' (%d) " %(
              chain1.id,model1.id,xyz1.size(),chain2.id,model2.id,xyz2.size()), file=out)
            assert xyz1.size()==xyz2.size()

          for i in range(xyz1.size()):
            x1=col(xyz1[i])
            x2=col(xyz2[i])
            dd=(x1-x2).norm_sq()
            if dd<= dist_max_sq:  # can crossover here
              if not i in crossover_dict: crossover_dict[i]={}
              if not model1.id in crossover_dict[i]:
                crossover_dict[i][model1.id]=[]
              if not model2.id in crossover_dict[i]:
                crossover_dict[i][model2.id]=[]
              if not model2.id in crossover_dict[i][model1.id]:
                  crossover_dict[i][model1.id].append(model2.id)
              if not model1.id in crossover_dict[i][model2.id]:
                  crossover_dict[i][model2.id].append(model1.id)

  # Now remove where the number
  #  of crossover atoms in a row that match is less than minimum_matching_atoms

  if minimum_matching_atoms > 2:
    offset_n=minimum_matching_atoms//2
    offset_range=[]
    for n in range(-offset_n,offset_n+1):
      if n != 0: offset_range.append(n)
    delete_dict={}
    for i in range(n_residues):
      if not i in crossover_dict: continue
      for id1 in crossover_dict[i]:
        for id2 in crossover_dict[i][id1]:
          # check to see if i-1 and i+1 are both ok (if not off the ends)
          for offset in offset_range:
            i1=min(n_residues-1,max(0,i+offset))
            if not id2 in crossover_dict.get(i1,{}).get(id1,[]):
              if not i in delete_dict: delete_dict[i]={}
              if not id1 in delete_dict[i]: delete_dict[i][id1]=[]
              if not id2 in delete_dict[i][id1]:delete_dict[i][id1].append(id2)

    for i in range(n_residues):
      if not i in crossover_dict: continue
      for id1 in crossover_dict[i]:
        new_list=[]
        for id2 in crossover_dict[i][id1]:
          if not id2 in delete_dict.get(i,{}).get(id1,[]):
            new_list.append(id2)
        crossover_dict[i][id1]=new_list

  # Now add all ends to crossover (always ok)

  for pos in [0,n_residues-1]:
    if not pos in crossover_dict:
      crossover_dict[pos]={}
    for id1 in used_model_ids:
      for id2 in used_model_ids:
        if id1==id2: continue
        if not id1 in crossover_dict[pos]:
          crossover_dict[pos][id1]=[]
        if not id2 in crossover_dict[pos][id1]:
          crossover_dict[pos][id1].append(id2)


  if verbose:
    i_list=list(crossover_dict.keys())
    i_list.sort()
    for i in i_list:
      print("\nAllowed crossovers at position %d" %(i), file=out)
      id_list=list(crossover_dict[i].keys())
      id_list.sort()
      print("Crossover pairs:", end=' ')
      for id in id_list:
        second_id_list=crossover_dict[i][id]
        second_id_list.sort()
        for second_id in second_id_list:
          print("%s-%s" %(id,second_id), end=' ')
      print()

  return crossover_dict


def get_cc_dict(hierarchy=None,crystal_symmetry=None,
  map_data=None,d_min=None,
  table=None,out=sys.stdout):

  cc_dict={}
  print("\nMaking a table of residue CC values", file=out)
  cryst1_line=iotbx.pdb.format_cryst1_record(crystal_symmetry=crystal_symmetry)

  # select the model and chain we are interested in
  for model in hierarchy.models():

    f=StringIO()
    atom_selection=get_atom_selection(model_id=model.id)
    asc=hierarchy.atom_selection_cache()
    sel=asc.selection(string = atom_selection)
    sel_hierarchy=hierarchy.select(sel)
    sel_hierarchy.atoms().reset_i_seq()
    xrs = sel_hierarchy.extract_xray_structure(
      crystal_symmetry=crystal_symmetry)
    xrs.scattering_type_registry(table = table)

    cc_calculator=mmtbx.maps.correlation.from_map_and_xray_structure_or_fmodel(
      xray_structure = xrs,
      map_data       = map_data,
      d_min          = d_min)

    for m in sel_hierarchy.models():
      for chain in m.chains():
        cc_list=flex.double()
        cc_dict[model.id]=cc_list
        for rg in chain.residue_groups():
          cc = cc_calculator.cc(selection=rg.atoms().extract_i_seq())
          #print >> out, "  chain id: %s resid %s: %6.4f"%( rg.parent().id, rg.resid(), cc)
          cc_list.append(cc)

  # check to make sure all are same
  std_size=None
  for model_id in cc_dict.keys():
    if std_size is None: std_size=cc_dict[model_id].size()
    if cc_dict[model_id].size()!=std_size:
      raise Sorry(
       "All copies of each chain must have the same size (%d != %d)" %(
         std_size,cc_dict[model_id].size()))
  return cc_dict

def smooth_cc_values(cc_dict=None,
       smoothing_window=None,verbose=None,out=sys.stdout):
  smoothed_cc_dict={}
  delta=(smoothing_window+1)//2
  for id in cc_dict.keys():
    cc_list=cc_dict[id]
    smoothed_cc_list=flex.double()
    for i in range(cc_list.size()):
      r=cc_list[max(0,i-delta):min(cc_list.size(),i+delta+1)]
      smoothed_cc_list.append(r.min_max_mean().mean)
    smoothed_cc_dict[id]=smoothed_cc_list

  keys=list(smoothed_cc_dict.keys())
  keys.sort()
  if verbose:
      for key in keys:
        print("ID:  %s " %(key), file=out)
        print("Position   Unsmoothed  Smoothed", file=out)
        for i in range(cc_dict[key].size()):
         print("  %d     %7.2f     %7.2f" %(
           i,cc_dict[key][i],smoothed_cc_dict[key][i]), file=out)

  return smoothed_cc_dict

# NOTE: Match defaults here and in params at top of file
#     : copy from defaults if params is not None below
#     : See explanations of parameters in params at top of file
def run(
    params=None, # params for running from command line
    map_data=None,  # map_data, as_double()
    pdb_inp=None,
    pdb_hierarchy=None,
    crystal_symmetry=None,
    resolution=None,
    scattering_table='n_gaussian',
    smoothing_window=5,
    crossover_atom='CA',
    minimum_matching_atoms=3,
    minimum_length=2,
    dist_max=1.0,
    minimum_improvement=0.01,
    max_regions_to_test=10,
    max_ends_per_region=5,
    maximum_fraction=0.5,
    max_keep=10,
    map_coeffs_file=None,map_coeffs_labels=None,
    pdb_in_file=None,
    pdb_out=None,
    verbose=None,
    out=sys.stdout):

  if out is None: out=sys.stdout # explode and refine calls it this way

  # get info from params if present
  if params:
     verbose=params.control.verbose
     map_coeffs_file=params.input_files.map_coeffs_file
     map_coeffs_labels=params.input_files.map_coeffs_labels
     pdb_in_file=params.input_files.pdb_in_file
     resolution=params.crystal_info.resolution
     scattering_table=params.crystal_info.scattering_table
     smoothing_window=params.crossover.smoothing_window
     crossover_atom=params.crossover.crossover_atom
     minimum_matching_atoms=params.crossover.minimum_matching_atoms
     minimum_length=params.crossover.minimum_length
     dist_max=params.crossover.dist_max
     minimum_improvement=params.crossover.minimum_improvement
     max_regions_to_test=params.crossover.max_regions_to_test
     max_ends_per_region=params.crossover.max_ends_per_region
     maximum_fraction=params.crossover.maximum_fraction
     max_keep=params.crossover.max_keep
     pdb_out=params.output_files.pdb_out

  # Consistency checks
  if(pdb_hierarchy is not None):
    assert pdb_in_file is None
    assert pdb_inp is None
    assert crystal_symmetry is not None
    # XXX more checks here!

  # Get map_data if not present
  if not map_data:
    if not map_coeffs_file or not os.path.isfile(map_coeffs_file):
      raise Sorry("Cannot find the map_coeffs_file '%s'" %(
        str(map_coeffs_file)))
    from mmtbx.building.minimize_chain import get_map_coeffs
    map_coeffs=get_map_coeffs(map_coeffs_file,
        map_coeffs_labels=map_coeffs_labels)

    fft_map = map_coeffs.fft_map(resolution_factor = 0.25)
    fft_map.apply_sigma_scaling()
    map_data = fft_map.real_map_unpadded()
    map_data=map_data.as_double()
    if map_coeffs and not crystal_symmetry:
      crystal_symmetry=map_coeffs.crystal_symmetry()
    if map_coeffs and not resolution:
      resolution=map_coeffs.d_min()

  # Get the starting model
  if(pdb_hierarchy is None):
    if pdb_inp is None:
      if not pdb_in_file or not os.path.isfile(pdb_in_file):
        raise Sorry("Cannot read input PDB file '%s'" %(
          str(pdb_in_file)))
      else:
        print("Taking models from %s" %(pdb_in_file), file=out)
        pdb_string=open(pdb_in_file).read()
      pdb_inp=iotbx.pdb.input(source_info=None, lines = pdb_string)
      if pdb_inp is None:
        raise Sorry("Need a model or models")
    if not crystal_symmetry:
      crystal_symmetry=pdb_inp.crystal_symmetry()
    assert crystal_symmetry is not None
    hierarchy = pdb_inp.construct_hierarchy()
  else:
    hierarchy = pdb_hierarchy # XXX FIXME
  n_models=0
  for model in hierarchy.models():
    n_models+=1

  if n_models==1:  # nothing to do
    return hierarchy

  xrs = hierarchy.extract_xray_structure(crystal_symmetry=crystal_symmetry)
  xrs.scattering_type_registry(table=scattering_table)
  if not resolution:
    from cctbx import maptbx
    resolution=maptbx.resolution_from_map_and_model.run(
      map_data=map_data, xray_structure=xrs).d_min
  if(resolution is None):
    raise Sorry("Resolution is required")
  print("\nResolution limit: %7.2f" %(resolution), file=out)
  print("\nSummary of input models", file=out)
  xrs.show_summary(f=out, prefix="  ")

  print("\nReady with %d models and map" %(n_models), file=out)
  # Get CC by residue for each model and map

  chain_id_and_resseq_list=[] # Instead set up chain_id and resseq (range)
  from mmtbx.secondary_structure.find_ss_from_ca import \
      split_model
  model_list=split_model(hierarchy=hierarchy,only_first_model=True)
  for m in model_list:
    h=m.hierarchy
    first_resno=h.first_resseq_as_int()
    last_resno=h.last_resseq_as_int()
    chain_id=h.first_chain_id()
    residue_range=[first_resno,last_resno]
    chain_id_and_resseq=[chain_id,residue_range]
    if not chain_id_and_resseq in chain_id_and_resseq_list:
       chain_id_and_resseq_list.append(chain_id_and_resseq)

  # Run through chains separately
  # NOTE: All models of each chain must match exactly

  # Save composite model, chain by chain
  composite_model_stream=StringIO()
  sel_ph_list = []

  for chain_id_and_resseq in chain_id_and_resseq_list:
    f=StringIO()
    chain_id,[start_resno,end_resno]=chain_id_and_resseq
    atom_selection=get_atom_selection(chain_id=chain_id,
      start_resno=start_resno,end_resno=end_resno)
    asc=hierarchy.atom_selection_cache()
    sel=asc.selection(string = atom_selection)
    sel_hierarchy=hierarchy.select(sel)
    sel_hierarchy.atoms().reset_i_seq()
    ph=sel_hierarchy

    print("\nWorking on chain_id='%s' resseq %d:%d\n" %(
       chain_id_and_resseq[0],chain_id_and_resseq[1][0],chain_id_and_resseq[1][1]), file=out)

    # get CC values for all residues
    cc_dict=get_cc_dict(hierarchy=ph,map_data=map_data,d_min=resolution,
     crystal_symmetry=crystal_symmetry,
     table=scattering_table,out=out)

    # smooth CC values with window of smoothing_window
    smoothed_cc_dict=smooth_cc_values(cc_dict=cc_dict,
       smoothing_window=smoothing_window,
       verbose=verbose,out=out)

    # figure out all the places where crossover can occur.
    # FIXME: order of keys changes in py2/3 vthis could be bad. No all are same.
    n_residues=cc_dict[list(cc_dict.keys())[0]].size()

    crossover_dict=get_crossover_dict(
      n_residues=n_residues,
      hierarchy=ph,
      crossover_atom=crossover_atom,
      dist_max=dist_max,
      minimum_matching_atoms=minimum_matching_atoms,
      verbose=verbose,out=out)

    # Now we are ready to identify the best composite model...
    # A composite has reside 0 from model x, residue 1 from model y etc.
    # Each change from model a to model b between residues i and i+1 must have
    #  a crossover between a and b at either residue i or i+1

    keys=list(cc_dict.keys())
    keys.sort()

    sorted_working_model_list=[]
    for key in keys:
      working_model=model_object(source_id=key,
         cc_dict=cc_dict,
         smoothed_cc_dict=smoothed_cc_dict,
         crossover_dict=crossover_dict,
         minimum_length=minimum_length,
         minimum_improvement=minimum_improvement,
         max_regions_to_test=max_regions_to_test,
         max_ends_per_region=max_ends_per_region,
         maximum_fraction=maximum_fraction)
      if verbose:
        working_model.show_summary(out=out)
      sorted_working_model_list.append(
        [working_model.get_score(),working_model])
    sorted_working_model_list.sort()
    sorted_working_model_list.reverse()
    sorted_working_model_list=\
       sorted_working_model_list[:max_keep]
    working_model_list=[]
    for s,m in sorted_working_model_list:
      working_model_list.append(m)

    # Go through all the working models and cross them with other models to
    #  optimize...Then take all the best and cross...

    best_score,best_model=sorted_working_model_list[0]
    found=True
    cycle=0
    while found:
      cycle+=1
      print("\nCYCLE %d current best is %7.3f\n" %(
        cycle,best_model.get_score()), file=out)
      found=False
      sorted_working_model_list=[]
      new_best=best_model
      id=0
      for working_model in working_model_list:
        id+=1
        others=[]
        for m in working_model_list:
          if not working_model==m:  others.append(m)
        new_working_model=working_model.optimize_with_others(others=others)
        if not new_working_model:
          print()
          continue
        aa=[new_working_model.get_score(),new_working_model]
        if not aa in sorted_working_model_list:
          sorted_working_model_list.append(aa)
      if not sorted_working_model_list:
         break # nothing to do

      sorted_working_model_list = sorted(sorted_working_model_list,
         key = lambda wm: wm[0], reverse = True)
      sorted_working_model_list=sorted_working_model_list[:max_keep]

      new_working_score,new_working_model=sorted_working_model_list[0]
      if new_working_score>best_model.get_score():
        best_model=new_working_model
        found=True
        if verbose:
          print("NEW BEST SCORE: %7.2f" %(best_model.get_score()), file=out)
          best_model.show_summary(out=out)

    print("\nDONE... best is %7.3f\n" %(
        best_model.get_score()), file=out)

    # Create composite of this chain

    # Note residue values. We are going to pick each residue from one of
    # the models
    for model in ph.models():
      for chain in model.chains():
        if chain.id != chain_id: continue
        residue_list=[]
        for rg in chain.residue_groups():
          residue_list.append(rg.resseq)
    residue_list.sort()
    assert len(best_model.source_list)==len(residue_list)
    from mmtbx.secondary_structure.find_ss_from_ca import remove_ter_or_break
    for i in range(len(residue_list)):
      atom_selection=get_atom_selection(model_id=best_model.source_list[i],
        resseq_sel=residue_list[i])
      asc=ph.atom_selection_cache()
      sel=asc.selection(string = atom_selection)
      sel_hierarchy=ph.select(sel)
      sel_hierarchy = remove_ter_or_break(sel_hierarchy)
      sel_ph_list.append(sel_hierarchy)
  from iotbx.pdb.utils import add_hierarchies
  pdb_hierarchy = remove_ter_or_break(add_hierarchies(sel_ph_list,
    create_new_chain_ids_if_necessary = False))

  if pdb_out:
    pdb_out = pdb_hierarchy.write_pdb_or_mmcif_file(target_filename = pdb_out,
      crystal_symmetry = crystal_symmetry)
    print("Final model is in: %s\n" %(pdb_out))

  return pdb_hierarchy, pdb_out

if   (__name__ == "__main__"):
  args=sys.argv[1:]
  # Get the parameters
  params=get_params(args=args)
  run(params=params)


 *******************************************************************************


 *******************************************************************************
mmtbx/building/minimize_chain.py
from __future__ import absolute_import, division, print_function
import sys,os
import iotbx.pdb
import mmtbx.utils
from scitbx.array_family import flex
from libtbx.utils import Sorry
import iotbx.phil
import mmtbx.refinement.real_space.explode_and_refine
from mmtbx import monomer_library

master_phil = iotbx.phil.parse("""

  input_files {
    map_coeffs_file = None
      .type = path
      .help = File with map coefficients
      .short_caption = Map coefficients
      .style = bold file_type:hkl input_file process_hkl child:fobs:data_labels\
        child:space_group:space_group child:unit_cell:unit_cell

    map_coeffs_labels = None
      .type = str
      .input_size = 160
      .help = Optional label specifying which columns of of map coefficients \
          to use
      .short_caption = Map coeffs label
      .style = bold renderer:draw_fobs_label_widget

    map_file = None
      .type = path
      .help = File with CCP4-style map
      .short_caption = Map file

    pdb_in = None
      .type = path
      .help = Input PDB file to minimize
      .short_caption = Input PDB file

  }
  output_files {

    pdb_out = None
      .type = path
      .help = Output PDB file with CA positions
      .short_caption = Output PDB file

    prefix = tst_00
      .type = str
      .help = Prefix for output files
      .short_caption = Prefix for output files
  }
  crystal_info {
     resolution = None
       .type = float
       .help = High-resolution limit. Data will be truncated at this\
               resolution. If a map is supplied, it will be Fourier \
               filtered at this resolution. Required if input is a map and \
                only_original_map is not set.
       .short_caption = High-resolution limit
       .style = resolution
     space_group = None
       .type = space_group
       .short_caption = Space Group
       .help = Space group (normally read from the data file)
     unit_cell = None
       .type = unit_cell
       .short_caption = Unit Cell
       .help = Unit Cell (normally read from the data file)
  }
  minimization {
     strategy = ca_only *all_atoms
       .type = choice
       .help = Ignored for now. \
          Strategy.  CA_only uses just CA atoms, all_atoms uses all
       .short_caption = CA only or all atoms

     number_of_macro_cycles = 5
       .type = int
       .short_caption = Number of overall cycles of minimization
       .help = Number of overall (macro) cycles of minimization

     target_bond_rmsd = 0.02
       .type = float
       .short_caption = Target bond rmsd
       .help = Target bond rmsd

     target_angle_rmsd = 2.0
       .type = float
       .short_caption = Target angle RMSD
       .help = Target angle RMSD

     number_of_trials = 20
       .type = int
       .short_caption = Number of trials
       .help = Number of trials

     number_of_sa_models = 20
       .type = int
       .short_caption = Number of SA models
       .help = Number of SA models

     start_xyz_error = 2.0
       .type = float
       .short_caption = Starting coordinate error
       .help = Starting coordinate error

  }
  control {
      verbose = False
        .type = bool
        .help = Verbose output
        .short_caption = Verbose output
      random_seed = None
        .type = int
        .short_caption = Random seed
        .help = Random seed. If set, the same result will be found each time.

      mode = *quick thorough
        .type = choice
        .short_caption = Quick or thorough
        .help = In minimization, use quick or thorough mode. \
                Currently does not affect other steps.

      nproc = 1
        .type = int
        .short_caption = Number of processors
        .help = Number of processors to use

  }
""", process_includes=True)
master_params = master_phil

def get_params(args,out=sys.stdout):
  command_line = iotbx.phil.process_command_line_with_files(
    reflection_file_def="input_files.map_coeffs_file",
    map_file_def="input_files.map_file",
    pdb_file_def="input_files.pdb_in",
    args=args,
    master_phil=master_phil)
  params = command_line.work.extract()
  print("\nMinimize_chain ... optimize a coarse-grain model in EM or low-resolution X-ray map", file=out)
  master_phil.format(python_object=params).show(out=out)
  return params

def ccp4_map(crystal_symmetry, file_name, map_data):
  from iotbx import mrcfile
  mrcfile.write_ccp4_map(
      file_name=file_name,
      unit_cell=crystal_symmetry.unit_cell(),
      space_group=crystal_symmetry.space_group(),
      #gridding_first=(0,0,0),# This causes a bug (map gets shifted)
      #gridding_last=n_real,  # This causes a bug (map gets shifted)
      map_data=map_data,
      labels=flex.std_string([""]))

def get_map_coeffs(
        map_coeffs_file=None,
        map_coeffs_labels=None):
  if not map_coeffs_file:
    return
  if not os.path.isfile(map_coeffs_file):
    raise Sorry("Unable to find the map coeffs file %s" %(map_coeffs_file))
  from iotbx import reflection_file_reader
  reflection_file=reflection_file_reader.any_reflection_file(map_coeffs_file)
  miller_arrays=reflection_file.as_miller_arrays()
  for ma in miller_arrays:
    if not ma.is_complex_array(): continue
    if (not map_coeffs_labels) or map_coeffs_labels==ma.info().labels[0] or \
       map_coeffs_labels == ",".join(ma.info().labels):
      return ma
  raise Sorry("Unable to find map coeffs in the file %s with labels %s" %(
      map_coeffs_file,str(map_coeffs_labels)))

def get_map_data_and_symmetry(
    crystal_symmetry=None,
    map_data=None,
    map_coeffs=None,
    map_file=None,
    map_coeffs_file=None,
    map_coeffs_labels=None,
    out=sys.stdout):

  if map_file:
    from cctbx.maptbx.segment_and_split_map import get_map_object
    map_data,space_group,unit_cell,crystal_symmetry,origin_frac,acc,\
      original_crystal_symmetry,original_unit_cell_grid=\
        get_map_object(file_name=map_file,out=out)
    map_data=map_data.as_double()

  if not map_data:
    if not map_coeffs:
      map_coeffs=get_map_coeffs(
        map_coeffs_file=map_coeffs_file,
        map_coeffs_labels=map_coeffs_labels)
    if not map_coeffs:
      raise Sorry("Need map_coeffs_file")

    fft_map = map_coeffs.fft_map(resolution_factor = 0.25)
    fft_map.apply_sigma_scaling()
    map_data = fft_map.real_map_unpadded()
  if map_coeffs and not crystal_symmetry:
    crystal_symmetry=map_coeffs.crystal_symmetry()
  assert crystal_symmetry is not None
  return map_data,map_coeffs,crystal_symmetry

def get_pdb_inp(
  crystal_symmetry=None,
  pdb_inp=None,
  pdb_string=None,
  pdb_in=None):

  if pdb_inp is None:
    if not pdb_string:
      if pdb_in:
        pdb_string=open(pdb_in).read()
      else:
        raise Sorry("Need an input PDB file")
    from iotbx.pdb.utils import get_pdb_input
    pdb_inp=get_pdb_input(pdb_string)
    cryst1_line=iotbx.pdb.format_cryst1_record(
         crystal_symmetry=crystal_symmetry)
  if pdb_string is None:
    ph = pdb_inp.construct_hierarchy()
    pdb_string = ph.as_pdb_or_mmcif_string(
      crystal_symmetry = crystal_symmetry)
  return pdb_inp,cryst1_line,pdb_string

def run_one_cycle(
    params=None,
    map_data=None,
    map_coeffs=None,
    pdb_inp=None,
    pdb_string=None,
    crystal_symmetry=None,
    params_edits=None,
    out=sys.stdout):
  hierarchy=pdb_inp.construct_hierarchy()
  hierarchy.atoms().reset_i_seq()
  xrs=pdb_inp.xray_structure_simple()
  if not pdb_string:
    pdb_string=hierarchy.as_pdb_or_mmcif_string(crystal_symmetry=xrs.crystal_symmetry())
  # Initialize states accumulator
  states = mmtbx.utils.states(pdb_hierarchy=hierarchy)
  states.add(sites_cart = xrs.sites_cart())
  pdb_inp_params = monomer_library.pdb_interpretation.master_params.extract()
  pdb_inp_params.clash_guard.nonbonded_distance_threshold=None
  pdb_inp_params.max_reasonable_bond_distance=None
  pdb_inp_params.proceed_with_excessive_length_bonds=True
  processed_pdb_file = monomer_library.pdb_interpretation.process(
    mon_lib_srv              = monomer_library.server.server(),
    ener_lib                 = monomer_library.server.ener_lib(),
    raw_records              = pdb_string,
    params                   = pdb_inp_params,
    strict_conflict_handling = True,
    force_symmetry           = True,
    log                      = out)
  geometry = processed_pdb_file.geometry_restraints_manager(
    show_energies                = False,
    plain_pairs_radius           = 5,
    assume_hydrogens_all_missing = True)
  restraints_manager = mmtbx.restraints.manager(
    geometry      = geometry,
    normalization = True)
  ear = mmtbx.refinement.real_space.explode_and_refine.run(
    xray_structure     = xrs,
    pdb_hierarchy      = hierarchy,
    map_data           = map_data,
    restraints_manager = restraints_manager,
    states             = states,
    resolution         = params.crystal_info.resolution,
    mode               = params.control.mode,
    nproc              = params.control.nproc,
    show               = False,
    log                = out)
  return ear.pdb_hierarchy_overall_best(), \
         ear.ensemble_pdb_hierarchy_refined()

def run(args,
    map_data=None,
    map_coeffs=None,
    pdb_inp=None,
    pdb_string=None,
    crystal_symmetry=None,
    params_edits=None,
    out=sys.stdout):

  # Get the parameters
  params=get_params(args=args,out=out)

  if params.control.random_seed:
    import random
    random.seed(params.control.random_seed)
    flex.set_random_seed(params.control.random_seed)
    print("\nUsing random seed of %d" %(params.control.random_seed), file=out)

  # Get map_data if not present
  map_data,map_coeffs,crystal_symmetry=get_map_data_and_symmetry(
    crystal_symmetry=crystal_symmetry,
    map_data=map_data,
    map_coeffs=map_coeffs,
    map_file=params.input_files.map_file,
    map_coeffs_file=params.input_files.map_coeffs_file,
    map_coeffs_labels=params.input_files.map_coeffs_labels,out=out)

  # Get the starting model
  pdb_inp,cryst1_line,pdb_string=get_pdb_inp(
    crystal_symmetry=crystal_symmetry,
    pdb_inp=pdb_inp,
    pdb_string=pdb_string,
    pdb_in=params.input_files.pdb_in)

  pdb_hierarchy,multiple_models_hierarchy=run_one_cycle(
    params=params,
    map_data=map_data,
    pdb_inp=pdb_inp,
    pdb_string=pdb_string,
    crystal_symmetry=crystal_symmetry,
    params_edits=params_edits,
    out=out)

  if params.output_files.pdb_out:
    fn = pdb_hierarchy.write_pdb_or_mmcif_file(
      target_filename=params.output_files.pdb_out,
      crystal_symmetry=crystal_symmetry)
    print("\nWrote output model to %s" %(fn), file=out)
  # all done
  return pdb_hierarchy,multiple_models_hierarchy

if   (__name__ == "__main__"):
  args=sys.argv[1:]
  run(args=args)


 *******************************************************************************


 *******************************************************************************
mmtbx/building/tst_extend_sidechains.py
from __future__ import absolute_import, division, print_function
from six.moves import cStringIO as StringIO
import os.path
import iotbx.pdb.hierarchy
from mmtbx.regression import model_1yjp
from iotbx.data_manager import DataManager
from libtbx.utils import null_out
import mmtbx.model
from mmtbx.building.extend_sidechains import master_params
import iotbx.pdb
from mmtbx.validation import rotalyze

from six.moves import zip

def exercise_model_only():
  from mmtbx.building import extend_sidechains
  import mmtbx.monomer_library
  pdb_in = iotbx.pdb.input(source_info=None, lines="""
ATOM     65  N   LYS A   7       6.033   4.704   1.582  1.00 17.49           N
ATOM     66  CA  LYS A   7       5.159   5.427   2.499  1.00 18.23           C
ATOM     67  C   LYS A   7       4.673   4.437   3.507  1.00 14.78           C
ATOM     68  O   LYS A   7       4.777   3.208   3.297  1.00 15.83           O
ATOM     69  CB  LYS A   7       3.959   6.057   1.760  1.00 23.56           C
ATOM     70  CG  LYS A   7       4.345   7.215   0.830  1.00 33.58           C
ATOM     71  CD  LYS A   7       3.213   7.570  -0.123  1.00 41.39           C
ATOM     72  CE  LYS A   7       2.976   6.471  -1.165  1.00 48.81           C
""")
  h = pdb_in.construct_hierarchy()
  extend_sidechains.extend_protein_model(
    pdb_hierarchy=h,
    mon_lib_srv=mmtbx.monomer_library.server.server())
  assert (h.as_pdb_string() == """\
ATOM      1  N   LYS A   7       6.033   4.704   1.582  1.00 17.49           N
ATOM      2  CA  LYS A   7       5.159   5.427   2.499  1.00 18.23           C
ATOM      3  C   LYS A   7       4.673   4.437   3.507  1.00 14.78           C
ATOM      4  O   LYS A   7       4.777   3.208   3.297  1.00 15.83           O
ATOM      5  CB  LYS A   7       3.980   6.048   1.757  1.00 23.56           C
ATOM      6  CG  LYS A   7       4.366   7.205   0.850  1.00 33.58           C
ATOM      7  CD  LYS A   7       3.241   7.559  -0.109  1.00 41.39           C
ATOM      8  CE  LYS A   7       3.011   6.457  -1.129  1.00 48.81           C
ATOM      9  NZ  LYS A   7       1.911   6.790  -2.075  0.10 26.71           N
TER
""")

def exercise_cmdline_cif():
  #
  params = iotbx.phil.parse(input_string = master_params).extract()
  #
  pdb_in = iotbx.pdb.input(source_info=None, lines=model_1yjp)
  m1 = mmtbx.model.manager(model_input = pdb_in, log = null_out())
  h_in = m1.get_hierarchy()
  #
  mtz_file = "tst_extend_sidechains.mtz"
  xrs = m1.get_xray_structure()
  f_calc = abs(xrs.structure_factors(d_min=1.5).f_calc())
  flags = f_calc.generate_r_free_flags(fraction=0.1)
  mtz = f_calc.as_mtz_dataset(column_root_label="F")
  mtz.add_miller_array(flags, column_root_label="FreeR_flag")
  mtz.mtz_object().write(mtz_file)
  sel_str = "not (resname TYR and not (name c or name o or name n or name oxt or name ca or name cb))"
  sel = m1.selection(sel_str)
  h_trimmed = h_in.select(sel)

  # Convert to mmcif_only:
  h_trimmed.rename_chain_id('A','AXLONG')

  pdb_file = "tst_extend_sidechains.cif"
  h_trimmed.write_pdb_or_mmcif_file(pdb_file)

  pdb_out = "tst_extend_sidechains_out.cif"
  prefix=os.path.splitext(os.path.basename(pdb_out))[0]

  dm = DataManager()
  m3 = dm.get_model(pdb_file)
  ma = dm.get_miller_arrays(filename = mtz_file)
  fmo3 = dm.get_fmodel(scattering_table="n_gaussian")
  out1 = StringIO()
  mmtbx.building.extend_sidechains.extend_and_refine(
    pdb_hierarchy=m3.get_hierarchy(),
    xray_structure=m3.get_xray_structure(),
    fmodel=fmo3,
    params=params,
    prefix=prefix,
    out=out1,
    output_model=pdb_out)

  assert ("1 sidechains extended." in out1.getvalue()), out1.getvalue()

  pdb_new = iotbx.pdb.input(file_name=pdb_out)
  h_new = pdb_new.construct_hierarchy()
  r1 = rotalyze.rotalyze(pdb_hierarchy=h_in, outliers_only=False)
  r2 = rotalyze.rotalyze(pdb_hierarchy=h_new, outliers_only=False)
  for o1, o2 in zip(r1.results, r2.results):
    assert o1.rotamer_name == o2.rotamer_name
  # Cleanup
  if os.path.isfile(pdb_out): os.remove(pdb_out)
  if os.path.isfile(pdb_file): os.remove(pdb_file)
  if os.path.isfile(prefix+'_maps.mtz'): os.remove(prefix+'_maps.mtz')
  #
  # Part 2: with sequence corrections
  #
  out2 = StringIO()
  #seq_file = "tst_extend_sidechains.fa"
  #with open(seq_file, "w") as f:
  #  f.write(">1yjp_new\nGNDQQNY")

  sequences = [iotbx.bioinformatics.sequence("GNDQQNY")]
  h_in_mod = h_trimmed.deep_copy()
  n_changed = mmtbx.building.extend_sidechains.correct_sequence(
    pdb_hierarchy=h_in_mod,
    sequences=sequences,
    out=out2)
  #print(h_in.as_sequence())
  #print(h_in_mod.as_sequence())

  pdb_file = "tst_extend_sidechains_2.cif"
  h_in_mod.write_pdb_or_mmcif_file(pdb_file)

  dm = DataManager()
  m4 = dm.get_model(pdb_file)
  ma = dm.get_miller_arrays(filename = mtz_file)
  fmo4 = dm.get_fmodel(scattering_table="n_gaussian")

  pdb_out = "tst_extend_sidechains_out2.cif"
  prefix=os.path.splitext(os.path.basename(pdb_out))[0]

  mmtbx.building.extend_sidechains.extend_and_refine(
    pdb_hierarchy=m4.get_hierarchy(),
    xray_structure=m4.get_xray_structure(),
    fmodel=fmo4,
    params=params,
    prefix=prefix,
    out=out2,
    output_model=pdb_out)

  assert ("2 sidechains extended." in out2.getvalue()), out2.getvalue()
  # Cleanup
  if os.path.isfile(pdb_out): os.remove(pdb_out)
  if os.path.isfile(pdb_file): os.remove(pdb_file)
  if os.path.isfile(prefix+'_maps.mtz'): os.remove(prefix+'_maps.mtz')
  if os.path.isfile(mtz_file): os.remove(mtz_file)

def exercise_cmdline():
  #
  params = iotbx.phil.parse(input_string = master_params).extract()
  #
  pdb_in = iotbx.pdb.input(source_info=None, lines=model_1yjp)
  m1 = mmtbx.model.manager(model_input = pdb_in, log = null_out())
  h_in = m1.get_hierarchy()
  #
  mtz_file = "tst_extend_sidechains.mtz"
  xrs = m1.get_xray_structure()
  f_calc = abs(xrs.structure_factors(d_min=1.5).f_calc())
  flags = f_calc.generate_r_free_flags(fraction=0.1)
  mtz = f_calc.as_mtz_dataset(column_root_label="F")
  mtz.add_miller_array(flags, column_root_label="FreeR_flag")
  mtz.mtz_object().write(mtz_file)
  sel_str = "not (resname TYR and not (name c or name o or name n or name oxt or name ca or name cb))"
  sel = m1.selection(sel_str)
  h_trimmed = h_in.select(sel)

  pdb_file = "tst_extend_sidechains.pdb"
  h_trimmed.write_pdb_file(pdb_file)

  pdb_out = "tst_extend_sidechains_out.pdb"
  prefix=os.path.splitext(os.path.basename(pdb_out))[0]

  dm = DataManager()
  m3 = dm.get_model(pdb_file)
  ma = dm.get_miller_arrays(filename = mtz_file)
  fmo3 = dm.get_fmodel(scattering_table="n_gaussian")
  out1 = StringIO()
  mmtbx.building.extend_sidechains.extend_and_refine(
    pdb_hierarchy=m3.get_hierarchy(),
    xray_structure=m3.get_xray_structure(),
    fmodel=fmo3,
    params=params,
    prefix=prefix,
    out=out1,
    output_model=pdb_out)

  assert ("1 sidechains extended." in out1.getvalue()), out1.getvalue()

  pdb_new = iotbx.pdb.input(file_name=pdb_out)
  h_new = pdb_new.construct_hierarchy()
  r1 = rotalyze.rotalyze(pdb_hierarchy=h_in, outliers_only=False)
  r2 = rotalyze.rotalyze(pdb_hierarchy=h_new, outliers_only=False)
  for o1, o2 in zip(r1.results, r2.results):
    assert o1.rotamer_name == o2.rotamer_name
  # Cleanup
  if os.path.isfile(pdb_out): os.remove(pdb_out)
  if os.path.isfile(pdb_file): os.remove(pdb_file)
  if os.path.isfile(prefix+'_maps.mtz'): os.remove(prefix+'_maps.mtz')
  #
  # Part 2: with sequence corrections
  #
  out2 = StringIO()
  #seq_file = "tst_extend_sidechains.fa"
  #with open(seq_file, "w") as f:
  #  f.write(">1yjp_new\nGNDQQNY")

  sequences = [iotbx.bioinformatics.sequence("GNDQQNY")]
  h_in_mod = h_trimmed.deep_copy()
  n_changed = mmtbx.building.extend_sidechains.correct_sequence(
    pdb_hierarchy=h_in_mod,
    sequences=sequences,
    out=out2)
  #print(h_in.as_sequence())
  #print(h_in_mod.as_sequence())

  pdb_file = "tst_extend_sidechains_2.pdb"
  h_in_mod.write_pdb_file(pdb_file)

  dm = DataManager()
  m4 = dm.get_model(pdb_file)
  ma = dm.get_miller_arrays(filename = mtz_file)
  fmo4 = dm.get_fmodel(scattering_table="n_gaussian")

  pdb_out = "tst_extend_sidechains_out2.pdb"
  prefix=os.path.splitext(os.path.basename(pdb_out))[0]

  mmtbx.building.extend_sidechains.extend_and_refine(
    pdb_hierarchy=m4.get_hierarchy(),
    xray_structure=m4.get_xray_structure(),
    fmodel=fmo4,
    params=params,
    prefix=prefix,
    out=out2,
    output_model=pdb_out)

  assert ("2 sidechains extended." in out2.getvalue()), out2.getvalue()
  # Cleanup
  if os.path.isfile(pdb_out): os.remove(pdb_out)
  if os.path.isfile(pdb_file): os.remove(pdb_file)
  if os.path.isfile(prefix+'_maps.mtz'): os.remove(prefix+'_maps.mtz')
  if os.path.isfile(mtz_file): os.remove(mtz_file)

def exercise_correct_sequence():
  from mmtbx.building import extend_sidechains
  from mmtbx.regression import model_1yjp
  import iotbx.bioinformatics
  hierarchy = iotbx.pdb.input(source_info=None, lines=model_1yjp).construct_hierarchy()
  sequences = [ iotbx.bioinformatics.sequence("GNDQQNY") ]
  out = StringIO()
  n_changed = extend_sidechains.correct_sequence(
    pdb_hierarchy=hierarchy.deep_copy(),
    sequences=sequences,
    out=out)
  assert (n_changed == 1)
  assert ("  chain 'A'    3  ASP --> ASP (1 atoms removed)" in out.getvalue())
  out = StringIO()
  n_changed = extend_sidechains.correct_sequence(
    pdb_hierarchy=hierarchy.deep_copy(),
    sequences=sequences,
    truncate_to_cbeta=True,
    out=out)
  assert (n_changed == 1)
  assert ("  chain 'A'    3  ASP --> ASP (3 atoms removed)" in out.getvalue())

if (__name__ == "__main__"):
  exercise_cmdline_cif()
  exercise_model_only()
  exercise_correct_sequence()
  exercise_cmdline()
  print("OK")


 *******************************************************************************


 *******************************************************************************
mmtbx/building/tst_extend_sidechains_2.py
from __future__ import absolute_import, division, print_function

from mmtbx.building import extend_sidechains
import mmtbx.monomer_library
from scitbx.array_family import flex
import iotbx.pdb
from libtbx.test_utils import approx_equal

mon_lib_srv = mmtbx.monomer_library.server.server()

###

pdb_str0_bad="""
ATOM      1  N   LYS A   7       6.033   4.704   1.582  1.00 17.49           N
ATOM      2  CA  LYS A   7       5.159   5.427   2.499  1.00 18.23           C
ATOM      3  C   LYS A   7       4.673   4.437   3.507  1.00 14.78           C
ATOM      4  O   LYS A   7       4.777   3.208   3.297  1.00 15.83           O
ATOM      5  CB  LYS A   7       3.959   6.057   1.760  1.00 23.56           C
ATOM      6  CG  LYS A   7       4.368   7.206   0.851  1.00 33.58           C
ATOM      7  CD  LYS A   7       3.242   7.559  -0.108  1.00 41.39           C
ATOM      8  CE  LYS A   7       3.009   6.453  -1.124  1.00 48.81           C
ATOM      9  NZ  LYS A   7       1.909   6.785  -2.070  1.00 48.81           N
ATOM      0  HA  LYS A   7       5.646   6.153   2.918  1.00 18.23           H   new
remark ATOM      0  HB2 LYS A   7       3.514   5.375   1.233  1.00 23.56           H   new
remark ATOM      0  HB3 LYS A   7       3.315   6.378   2.411  1.00 23.56           H   new
remark ATOM      0  HG2 LYS A   7       4.599   7.982   1.386  1.00 33.58           H   new
remark ATOM      0  HG3 LYS A   7       5.161   6.961   0.350  1.00 33.58           H   new
remark ATOM      0  HD2 LYS A   7       2.426   7.717   0.393  1.00 41.39           H   new
remark ATOM      0  HD3 LYS A   7       3.456   8.385  -0.570  1.00 41.39           H   new
remark ATOM      0  HE2 LYS A   7       3.826   6.296  -1.622  1.00 48.81           H   new
remark ATOM      0  HE3 LYS A   7       2.797   5.628  -0.660  1.00 48.81           H   new
remark ATOM      0  HZ1 LYS A   7       1.802   6.117  -2.648  1.00 48.81           H   new
remark ATOM      0  HZ2 LYS A   7       1.154   6.908  -1.616  1.00 48.81           H   new
remark ATOM      0  HZ3 LYS A   7       2.113   7.530  -2.513  1.00 48.81           H   new
"""

pdb_str0_good="""
ATOM      1  N   LYS A   7       6.033   4.704   1.582  1.00 17.49           N
ATOM      2  CA  LYS A   7       5.159   5.427   2.499  1.00 18.23           C
ATOM      3  C   LYS A   7       4.673   4.437   3.507  1.00 14.78           C
ATOM      4  O   LYS A   7       4.777   3.208   3.297  1.00 15.83           O
ATOM      5  CB  LYS A   7       3.959   6.057   1.760  1.00 23.56           C
ATOM      6  CG  LYS A   7       4.368   7.206   0.851  1.00 33.58           C
ATOM      7  CD  LYS A   7       3.242   7.559  -0.108  1.00 41.39           C
ATOM      8  CE  LYS A   7       3.009   6.453  -1.124  1.00 48.81           C
ATOM      9  NZ  LYS A   7       1.909   6.785  -2.070  1.00 48.81           N
ATOM      0  HA  LYS A   7       5.646   6.153   2.918  1.00 18.23           H   new
ATOM      0  HB2 LYS A   7       3.514   5.375   1.233  1.00 23.56           H   new
ATOM      0  HB3 LYS A   7       3.315   6.378   2.411  1.00 23.56           H   new
ATOM      0  HG2 LYS A   7       4.599   7.982   1.386  1.00 33.58           H   new
ATOM      0  HG3 LYS A   7       5.161   6.961   0.350  1.00 33.58           H   new
ATOM      0  HD2 LYS A   7       2.426   7.717   0.393  1.00 41.39           H   new
ATOM      0  HD3 LYS A   7       3.456   8.385  -0.570  1.00 41.39           H   new
ATOM      0  HE2 LYS A   7       3.826   6.296  -1.622  1.00 48.81           H   new
ATOM      0  HE3 LYS A   7       2.797   5.628  -0.660  1.00 48.81           H   new
ATOM      0  HZ1 LYS A   7       1.802   6.117  -2.648  1.00 48.81           H   new
ATOM      0  HZ2 LYS A   7       1.154   6.908  -1.616  1.00 48.81           H   new
ATOM      0  HZ3 LYS A   7       2.113   7.530  -2.513  1.00 48.81           H   new
"""

###

pdb_str1_bad="""
ATOM      1  N   LYS A   7       6.033   4.704   1.582  1.00 17.49           N
ATOM      2  CA  LYS A   7       5.159   5.427   2.499  1.00 18.23           C
ATOM      3  C   LYS A   7       4.673   4.437   3.507  1.00 14.78           C
ATOM      4  O   LYS A   7       4.777   3.208   3.297  1.00 15.83           O
ATOM      5  CB  LYS A   7       3.959   6.057   1.760  1.00 23.56           C
ATOM      6  CG  LYS A   7       4.368   7.206   0.851  1.00 33.58           C
ATOM      7  CD  LYS A   7       3.242   7.559  -0.108  1.00 41.39           C
ATOM      8  CE  LYS A   7       3.009   6.453  -1.124  1.00 48.81           C
remark ATOM      9  NZ  LYS A   7       1.909   6.785  -2.070  1.00 48.81           N
ATOM      0  HA  LYS A   7       5.646   6.153   2.918  1.00 18.23           H   new
ATOM      0  HB2 LYS A   7       3.514   5.375   1.233  1.00 23.56           H   new
ATOM      0  HB3 LYS A   7       3.315   6.378   2.411  1.00 23.56           H   new
ATOM      0  HG2 LYS A   7       4.599   7.982   1.386  1.00 33.58           H   new
ATOM      0  HG3 LYS A   7       5.161   6.961   0.350  1.00 33.58           H   new
ATOM      0  HD2 LYS A   7       2.426   7.717   0.393  1.00 41.39           H   new
ATOM      0  HD3 LYS A   7       3.456   8.385  -0.570  1.00 41.39           H   new
ATOM      0  HE2 LYS A   7       3.826   6.296  -1.622  1.00 48.81           H   new
ATOM      0  HE3 LYS A   7       2.797   5.628  -0.660  1.00 48.81           H   new
ATOM      0  HZ1 LYS A   7       1.802   6.117  -2.648  1.00 48.81           H   new
ATOM      0  HZ2 LYS A   7       1.154   6.908  -1.616  1.00 48.81           H   new
ATOM      0  HZ3 LYS A   7       2.113   7.530  -2.513  1.00 48.81           H   new
"""

pdb_str1_good="""
ATOM      1  N   LYS A   7       6.033   4.704   1.582  1.00 17.49           N
ATOM      2  CA  LYS A   7       5.159   5.427   2.499  1.00 18.23           C
ATOM      3  C   LYS A   7       4.673   4.437   3.507  1.00 14.78           C
ATOM      4  O   LYS A   7       4.777   3.208   3.297  1.00 15.83           O
ATOM      5  CB  LYS A   7       3.959   6.057   1.760  1.00 23.56           C
ATOM      6  CG  LYS A   7       4.368   7.206   0.851  1.00 33.58           C
ATOM      7  CD  LYS A   7       3.242   7.559  -0.108  1.00 41.39           C
ATOM      8  CE  LYS A   7       3.009   6.453  -1.124  1.00 48.81           C
ATOM      9  NZ  LYS A   7       1.909   6.785  -2.070  1.00 48.81           N
ATOM      0  HA  LYS A   7       5.646   6.153   2.918  1.00 18.23           H   new
ATOM      0  HB2 LYS A   7       3.514   5.375   1.233  1.00 23.56           H   new
ATOM      0  HB3 LYS A   7       3.315   6.378   2.411  1.00 23.56           H   new
ATOM      0  HG2 LYS A   7       4.599   7.982   1.386  1.00 33.58           H   new
ATOM      0  HG3 LYS A   7       5.161   6.961   0.350  1.00 33.58           H   new
ATOM      0  HD2 LYS A   7       2.426   7.717   0.393  1.00 41.39           H   new
ATOM      0  HD3 LYS A   7       3.456   8.385  -0.570  1.00 41.39           H   new
ATOM      0  HE2 LYS A   7       3.826   6.296  -1.622  1.00 48.81           H   new
ATOM      0  HE3 LYS A   7       2.797   5.628  -0.660  1.00 48.81           H   new
ATOM      0  HZ1 LYS A   7       1.802   6.117  -2.648  1.00 48.81           H   new
ATOM      0  HZ2 LYS A   7       1.154   6.908  -1.616  1.00 48.81           H   new
ATOM      0  HZ3 LYS A   7       2.113   7.530  -2.513  1.00 48.81           H   new
"""

###

pdb_str2_bad="""
ATOM      1  N   LYS A   7       6.033   4.704   1.582  1.00 17.49           N
ATOM      2  CA  LYS A   7       5.159   5.427   2.499  1.00 18.23           C
ATOM      3  C   LYS A   7       4.673   4.437   3.507  1.00 14.78           C
ATOM      4  O   LYS A   7       4.777   3.208   3.297  1.00 15.83           O
ATOM      5  CB  LYS A   7       3.959   6.057   1.760  1.00 23.56           C
ATOM      6  CG  LYS A   7       4.368   7.206   0.851  1.00 33.58           C
ATOM      7  CD  LYS A   7       3.242   7.559  -0.108  1.00 41.39           C
ATOM      8  CE  LYS A   7       3.009   6.453  -1.124  1.00 48.81           C
remark ATOM      9  NZ  LYS A   7       1.909   6.785  -2.070  1.00 48.81           N
"""

pdb_str2_good="""
ATOM      1  N   LYS A   7       6.033   4.704   1.582  1.00 17.49           N
ATOM      2  CA  LYS A   7       5.159   5.427   2.499  1.00 18.23           C
ATOM      3  C   LYS A   7       4.673   4.437   3.507  1.00 14.78           C
ATOM      4  O   LYS A   7       4.777   3.208   3.297  1.00 15.83           O
ATOM      5  CB  LYS A   7       3.959   6.057   1.760  1.00 23.56           C
ATOM      6  CG  LYS A   7       4.368   7.206   0.851  1.00 33.58           C
ATOM      7  CD  LYS A   7       3.242   7.559  -0.108  1.00 41.39           C
ATOM      8  CE  LYS A   7       3.009   6.453  -1.124  1.00 48.81           C
ATOM      9  NZ  LYS A   7       1.909   6.785  -2.070  1.00 48.81           N
"""

###

pdb_str3_bad="""
ATOM      1  N   LYS A   7       6.033   4.704   1.582  1.00 17.49           N
ATOM      2  CA  LYS A   7       5.159   5.427   2.499  1.00 18.23           C
ATOM      3  C   LYS A   7       4.673   4.437   3.507  1.00 14.78           C
ATOM      4  O   LYS A   7       4.777   3.208   3.297  1.00 15.83           O
ATOM      5  CB  LYS A   7       3.959   6.057   1.760  1.00 23.56           C
ATOM      6  CG  LYS A   7       4.368   7.206   0.851  1.00 33.58           C
remark ATOM      7  CD  LYS A   7       3.242   7.559  -0.108  1.00 41.39           C
ATOM      8  CE  LYS A   7       3.009   6.453  -1.124  1.00 48.81           C
ATOM      9  NZ  LYS A   7       1.909   6.785  -2.070  1.00 48.81           N
"""

pdb_str3_good="""
ATOM      1  N   LYS A   7       6.033   4.704   1.582  1.00 17.49           N
ATOM      2  CA  LYS A   7       5.159   5.427   2.499  1.00 18.23           C
ATOM      3  C   LYS A   7       4.673   4.437   3.507  1.00 14.78           C
ATOM      4  O   LYS A   7       4.777   3.208   3.297  1.00 15.83           O
ATOM      5  CB  LYS A   7       3.959   6.057   1.760  1.00 23.56           C
ATOM      6  CG  LYS A   7       4.368   7.206   0.851  1.00 33.58           C
ATOM      7  CD  LYS A   7       3.242   7.559  -0.108  1.00 41.39           C
ATOM      8  CE  LYS A   7       3.009   6.453  -1.124  1.00 48.81           C
ATOM      9  NZ  LYS A   7       1.909   6.785  -2.070  1.00 48.81           N
"""

###

pdb_str4_bad="""
ATOM      1  N   LYS A   7       6.033   4.704   1.582  1.00 17.49           N
ATOM      2  CA  LYS A   7       5.159   5.427   2.499  1.00 18.23           C
ATOM      3  C   LYS A   7       4.673   4.437   3.507  1.00 14.78           C
remark ATOM      4  O   LYS A   7       4.777   3.208   3.297  1.00 15.83           O
ATOM      5  CB  LYS A   7       3.959   6.057   1.760  1.00 23.56           C
ATOM      6  CG  LYS A   7       4.368   7.206   0.851  1.00 33.58           C
ATOM      7  CD  LYS A   7       3.242   7.559  -0.108  1.00 41.39           C
ATOM      8  CE  LYS A   7       3.009   6.453  -1.124  1.00 48.81           C
ATOM      9  NZ  LYS A   7       1.909   6.785  -2.070  1.00 48.81           N
"""

pdb_str4_good="""
ATOM      1  N   LYS A   7       6.033   4.704   1.582  1.00 17.49           N
ATOM      2  CA  LYS A   7       5.159   5.427   2.499  1.00 18.23           C
ATOM      3  C   LYS A   7       4.673   4.437   3.507  1.00 14.78           C
ATOM      4  O   LYS A   7       4.777   3.208   3.297  1.00 15.83           O
ATOM      5  CB  LYS A   7       3.959   6.057   1.760  1.00 23.56           C
ATOM      6  CG  LYS A   7       4.368   7.206   0.851  1.00 33.58           C
ATOM      7  CD  LYS A   7       3.242   7.559  -0.108  1.00 41.39           C
ATOM      8  CE  LYS A   7       3.009   6.453  -1.124  1.00 48.81           C
ATOM      9  NZ  LYS A   7       1.909   6.785  -2.070  1.00 48.81           N
"""

###

pdb_str5_bad="""
ATOM      1  N   LYS A   7       6.033   4.704   1.582  1.00 17.49           N
remark ATOM      2  CA  LYS A   7       5.159   5.427   2.499  1.00 18.23           C
ATOM      3  C   LYS A   7       4.673   4.437   3.507  1.00 14.78           C
ATOM      4  O   LYS A   7       4.777   3.208   3.297  1.00 15.83           O
ATOM      5  CB  LYS A   7       3.959   6.057   1.760  1.00 23.56           C
ATOM      6  CG  LYS A   7       4.368   7.206   0.851  1.00 33.58           C
ATOM      7  CD  LYS A   7       3.242   7.559  -0.108  1.00 41.39           C
ATOM      8  CE  LYS A   7       3.009   6.453  -1.124  1.00 48.81           C
ATOM      9  NZ  LYS A   7       1.909   6.785  -2.070  1.00 48.81           N
"""

pdb_str5_good="""
ATOM      1  N   LYS A   7       6.033   4.704   1.582  1.00 17.49           N
ATOM      2  CA  LYS A   7       5.159   5.427   2.499  1.00 18.23           C
ATOM      3  C   LYS A   7       4.673   4.437   3.507  1.00 14.78           C
ATOM      4  O   LYS A   7       4.777   3.208   3.297  1.00 15.83           O
ATOM      5  CB  LYS A   7       3.959   6.057   1.760  1.00 23.56           C
ATOM      6  CG  LYS A   7       4.368   7.206   0.851  1.00 33.58           C
ATOM      7  CD  LYS A   7       3.242   7.559  -0.108  1.00 41.39           C
ATOM      8  CE  LYS A   7       3.009   6.453  -1.124  1.00 48.81           C
ATOM      9  NZ  LYS A   7       1.909   6.785  -2.070  1.00 48.81           N
"""

###

pdb_str6_bad="""
ATOM      1  N   LYS A   7       6.033   4.704   1.582  1.00 17.49           N
ATOM      2  CA  LYS A   7       5.159   5.427   2.499  1.00 18.23           C
ATOM      3  C   LYS A   7       4.673   4.437   3.507  1.00 14.78           C
ATOM      4  O   LYS A   7       4.777   3.208   3.297  1.00 15.83           O
remark ATOM      5  CB  LYS A   7       3.959   6.057   1.760  1.00 23.56           C
ATOM      6  CG  LYS A   7       4.368   7.206   0.851  1.00 33.58           C
ATOM      7  CD  LYS A   7       3.242   7.559  -0.108  1.00 41.39           C
ATOM      8  CE  LYS A   7       3.009   6.453  -1.124  1.00 48.81           C
ATOM      9  NZ  LYS A   7       1.909   6.785  -2.070  1.00 48.81           N
TER
"""

pdb_str6_good="""\
ATOM      1  N   LYS A   7       6.033   4.704   1.582  1.00 17.49           N
ATOM      2  CA  LYS A   7       5.159   5.427   2.499  1.00 18.23           C
ATOM      3  C   LYS A   7       4.673   4.437   3.507  1.00 14.78           C
ATOM      4  O   LYS A   7       4.777   3.208   3.297  1.00 15.83           O
ATOM      5  CB  LYS A   7       3.959   6.057   1.760  1.00 23.56           C
ATOM      6  CG  LYS A   7       4.368   7.206   0.851  1.00 33.58           C
ATOM      7  CD  LYS A   7       3.242   7.559  -0.108  1.00 41.39           C
ATOM      8  CE  LYS A   7       3.009   6.453  -1.124  1.00 48.81           C
ATOM      9  NZ  LYS A   7       1.909   6.785  -2.070  1.00 48.81           N
TER
"""

###

pdb_str7_good="""
ATOM      1  N   LYS A   7       6.033   4.704   1.582  1.00 17.49           N
ATOM      2  CA  LYS A   7       5.159   5.427   2.499  1.00 18.23           C
ATOM      3  C   LYS A   7       4.673   4.437   3.507  1.00 14.78           C
ATOM      4  O   LYS A   7       4.777   3.208   3.297  1.00 15.83           O
ATOM      5  CB  LYS A   7       3.959   6.057   1.760  1.00 23.56           C
ATOM      6  CG  LYS A   7       4.368   7.206   0.851  1.00 33.58           C
ATOM      7  CD  LYS A   7       3.242   7.559  -0.108  1.00 41.39           C
ATOM      8  CE  LYS A   7       3.009   6.453  -1.124  1.00 48.81           C
ATOM      9  NZ  LYS A   7       1.909   6.785  -2.070  1.00 48.81           N
ATOM      0  HA  LYS A   7       5.646   6.153   2.918  1.00 18.23           H   new
ATOM      0  HB2 LYS A   7       3.514   5.375   1.233  1.00 23.56           H   new
ATOM      0  HB3 LYS A   7       3.315   6.378   2.411  1.00 23.56           H   new
ATOM      0  HG2 LYS A   7       4.599   7.982   1.386  1.00 33.58           H   new
ATOM      0  HG3 LYS A   7       5.161   6.961   0.350  1.00 33.58           H   new
ATOM      0  HD2 LYS A   7       2.426   7.717   0.393  1.00 41.39           H   new
ATOM      0  HD3 LYS A   7       3.456   8.385  -0.570  1.00 41.39           H   new
ATOM      0  HE2 LYS A   7       3.826   6.296  -1.622  1.00 48.81           H   new
ATOM      0  HE3 LYS A   7       2.797   5.628  -0.660  1.00 48.81           H   new
ATOM      0  HZ1 LYS A   7       1.802   6.117  -2.648  1.00 48.81           H   new
ATOM      0  HZ2 LYS A   7       1.154   6.908  -1.616  1.00 48.81           H   new
ATOM      0  HZ3 LYS A   7       2.113   7.530  -2.513  1.00 48.81           H   new
"""

pdb_str7_bad="""
ATOM      1  N   LYS A   7       6.033   4.704   1.582  1.00 17.49           N
ATOM      2  CA  LYS A   7       5.159   5.427   2.499  1.00 18.23           C
ATOM      3  C   LYS A   7       4.673   4.437   3.507  1.00 14.78           C
ATOM      4  O   LYS A   7       4.777   3.208   3.297  1.00 15.83           O
ATOM      5  CB  LYS A   7       3.959   6.057   1.760  1.00 23.56           C
ATOM      6  CG  LYS A   7       4.368   7.206   0.851  1.00 33.58           C
remark ATOM      7  CD  LYS A   7       3.242   7.559  -0.108  1.00 41.39           C
ATOM      8  CE  LYS A   7       3.009   6.453  -1.124  1.00 48.81           C
ATOM      9  NZ  LYS A   7       1.909   6.785  -2.070  1.00 48.81           N
"""

pdb_str_do_no_move_if_complete="""
ATOM      1  N   LYS A   7       6.187   5.271   2.497  1.00 17.49           N
ATOM      2  CA  LYS A   7       5.198   6.138   3.127  1.00 18.23           C
ATOM      3  C   LYS A   7       4.507   5.426   4.285  1.00 14.78           C
ATOM      4  O   LYS A   7       3.859   4.396   4.096  1.00 15.83           O
ATOM      5  CB  LYS A   7       4.161   6.608   2.104  1.00 23.56           C
ATOM      6  CG  LYS A   7       4.553   7.868   1.345  1.00 33.58           C
ATOM      7  CD  LYS A   7       5.574   7.573   0.257  1.00 41.39           C
ATOM      8  CE  LYS A   7       4.958   6.765  -0.874  1.00 48.81           C
ATOM      9  NZ  LYS A   7       5.929   6.522  -1.976  1.00 48.81           N
TER
END
"""

###

def check(answer, result, bad):
  a = list(answer.atoms().extract_name())
  a.sort()
  #
  r = list(result.atoms().extract_name())
  r.sort()
  #
  b = list(bad.atoms().extract_name())
  b.sort()
  #
  diff = list(set(r).symmetric_difference(set(a)))
  assert len(diff) in [0,1], diff
  if(len(diff)==1):
    assert diff[0]==' H  ', diff
  assert b!=a
  #
  xyz_a = flex.vec3_double()
  xyz_r = flex.vec3_double()
  for aa in answer.atoms():
    for ar in result.atoms():
      if(aa.name == ar.name):
        xyz_a.append(aa.xyz)
        xyz_r.append(ar.xyz)
  print(flex.max(flex.sqrt((xyz_a - xyz_r).dot())))

def exercise_extend_sidechains(pdb_str_bad, pdb_str_good, i, Sorry_msg, add_h):
  pdb_inp = iotbx.pdb.input(source_info=None, lines=pdb_str_bad)
  pdb_h = pdb_inp.construct_hierarchy()
  pdb_h.write_pdb_file(file_name="m_in_%d.pdb"%i)
  pdb_h_bad = pdb_h.deep_copy()
  e = None
  try:
    extend_sidechains.extend_protein_model(
      pdb_hierarchy = pdb_h,
      mon_lib_srv   = mon_lib_srv,
      add_hydrogens = add_h)
  except Exception as e:
    if(Sorry_msg is not None):
      assert str(e).find(Sorry_msg)>-1
      return
  #
  pdb_h.write_pdb_file(file_name="m_completed_%d.pdb"%i)
  pdb_h_result = pdb_h.deep_copy()
  #
  pdb_inp = iotbx.pdb.input(source_info=None, lines=pdb_str_good)
  pdb_h_answer = pdb_inp.construct_hierarchy()
  pdb_h_answer.write_pdb_file(file_name="m_good_%d.pdb"%i)
  #
  check(answer=pdb_h_answer, result=pdb_h_result, bad=pdb_h_bad)

def exercise_do_not_move_if_complete():
  pdb_inp = iotbx.pdb.input(source_info=None,
    lines=pdb_str_do_no_move_if_complete)
  pdb_h = pdb_inp.construct_hierarchy()
  xyz1 = pdb_h.atoms().extract_xyz()
  pdb_h_completed = pdb_h.deep_copy()
  extend_sidechains.extend_protein_model(
    pdb_hierarchy = pdb_h_completed,
    mon_lib_srv   = mon_lib_srv,
    add_hydrogens = False)
  xyz2 = pdb_h_completed.atoms().extract_xyz()
  assert approx_equal(flex.max(flex.sqrt((xyz1 - xyz2).dot())),0.0)

if(__name__ == "__main__"):
  exercise_do_not_move_if_complete()
  #
  for i, t in enumerate([
     (pdb_str0_bad, pdb_str0_good, None, None),
     (pdb_str1_bad, pdb_str1_good, None, None),
     (pdb_str2_bad, pdb_str2_good, None, None),
     (pdb_str3_bad, pdb_str3_good, None, None),
     (pdb_str4_bad, pdb_str4_good, "Main chain must be complete.", None),
     (pdb_str5_bad, pdb_str5_good, "Main chain must be complete.", None),
     (pdb_str6_bad, pdb_str6_good, None, None),
     (pdb_str7_bad, pdb_str7_good, None, True),
    ]):
    exercise_extend_sidechains(
      pdb_str_bad=t[0], pdb_str_good=t[1], i=i, Sorry_msg=t[2], add_h=t[3])
  print("OK")


 *******************************************************************************
