

 *******************************************************************************
iotbx/pdb/tst_secondary_structure_2.py
"""Test secondary structure analysis"""
from __future__ import absolute_import, division, print_function
from libtbx import test_utils
import sys
from iotbx.pdb.tst_secondary_structure import pdb_1ywf_sample_strings, \
    get_annotation
import iotbx.pdb
from iotbx.pdb.utils import all_chain_ids
from iotbx.pdb.secondary_structure import annotation
from six.moves import cStringIO as StringIO


def tst_parsing_phil_single_helix():
  phil_hbond_portion = """\
  hbond {
    donor = chain A and resid 37 and name O
    acceptor = chain A and resid 41 and name N
    }
  hbond {
    donor = chain A and resid 38 and name O
    acceptor = chain A and resid 42 and name N
    }
  hbond {
    donor = chain A and resid 39 and name O
    acceptor = chain A and resid 43 and name N
    }
  hbond {
    donor = chain A and resid 40 and name O
    acceptor = chain A and resid 44 and name N
    }
  hbond {
    donor = chain A and resid 41 and name O
    acceptor = chain A and resid 45 and name N
    }
  hbond {
    donor = chain A and resid 42 and name O
    acceptor = chain A and resid 46 and name N
    }
  hbond {
    donor = chain A and resid 43 and name O
    acceptor = chain A and resid 47 and name N
    }
  hbond {
    donor = chain A and resid 44 and name O
    acceptor = chain A and resid 48 and name N
    }
  """
  phil_str1 = """\
secondary_structure.protein.helix {
  selection = chain A and resseq 37:48
  helix_type = *alpha pi 3_10 unknown
  %s
  }
  """ % phil_hbond_portion

  phil_str2 = """\
secondary_structure.protein.helix {
  selection = chain A and resseq 37:48
  helix_type = alpha *pi 3_10 unknown
  }
  """

  phil_str3 = """\
secondary_structure.protein.helix {
  selection = chain A and resseq 37:48
  helix_type = alpha pi *3_10 unknown
  }
  """

  phil_str4 = """\
secondary_structure.protein.helix {
  selection = chain A and resseq 37:48
  helix_type = alpha pi 3_10 *unknown
  }
  """

  phil_str5 = """\
secondary_structure.protein.helix {
  serial_number = 1
  selection = chain A and resseq 37:48
  helix_type = *alpha pi 3_10 unknown
  }
  """

  phil_str6 = """\
secondary_structure.protein.helix {
  serial_number = 2
  helix_identifier = A
  selection = chain A and resseq 37:48
  helix_type = *alpha pi 3_10 unknown
  }
  """

  phil_str7 = """\
secondary_structure.protein.helix {
  serial_number = 3
  helix_identifier = BB
  selection = chain A and resseq 37:48
  helix_type = *alpha pi 3_10 unknown
  }
  """

  phil_str8 = """\
secondary_structure.protein.helix {
  serial_number = 1
  helix_identifier = C12
  selection = chain A and resseq 37:48
  helix_type = *alpha pi 3_10 unknown
  }
  """

  phil_str9 = """\
secondary_structure.protein.helix {
  serial_number = 1
  helix_identifier = D123
  selection = chain A and resseq 37:48
  helix_type = *alpha pi 3_10 unknown
  }
  """


  result1 = """\
protein.helix {
  helix_identifier = 0
  selection = chain 'A' and resid   37  through   48
  helix_type = alpha
  hbond {
    donor = chain A and resid 37 and name O
    acceptor = chain A and resid 41 and name N
  }
  hbond {
    donor = chain A and resid 38 and name O
    acceptor = chain A and resid 42 and name N
  }
  hbond {
    donor = chain A and resid 39 and name O
    acceptor = chain A and resid 43 and name N
  }
  hbond {
    donor = chain A and resid 40 and name O
    acceptor = chain A and resid 44 and name N
  }
  hbond {
    donor = chain A and resid 41 and name O
    acceptor = chain A and resid 45 and name N
  }
  hbond {
    donor = chain A and resid 42 and name O
    acceptor = chain A and resid 46 and name N
  }
  hbond {
    donor = chain A and resid 43 and name O
    acceptor = chain A and resid 47 and name N
  }
  hbond {
    donor = chain A and resid 44 and name O
    acceptor = chain A and resid 48 and name N
  }
}"""
  result1_1 = """\
protein.helix {
  helix_identifier = 0
  selection = chain 'A' and resid   37  through   48
  helix_type = alpha
}"""
  result2_9 = """\
==================================================
protein.helix {
  helix_identifier = 0
  selection = chain 'A' and resid   37  through   48
  helix_type = pi
}
HELIX    0   0 ASP A   37  GLY A   48  3                                  12
==================================================
protein.helix {
  helix_identifier = 0
  selection = chain 'A' and resid   37  through   48
  helix_type = 3_10
}
HELIX    0   0 ASP A   37  GLY A   48  5                                  12
==================================================
protein.helix {
  helix_identifier = 0
  selection = chain 'A' and resid   37  through   48
  helix_type = unknown
}
HELIX    0   0 ASP A   37  GLY A   48  1                                  12
==================================================
protein.helix {
  serial_number = 1
  helix_identifier = 1
  selection = chain 'A' and resid   37  through   48
  helix_type = alpha
}
HELIX    1   1 ASP A   37  GLY A   48  1                                  12
==================================================
protein.helix {
  serial_number = 2
  helix_identifier = A
  selection = chain 'A' and resid   37  through   48
  helix_type = alpha
}
HELIX    2   A ASP A   37  GLY A   48  1                                  12
==================================================
protein.helix {
  serial_number = 3
  helix_identifier = BB
  selection = chain 'A' and resid   37  through   48
  helix_type = alpha
}
HELIX    3  BB ASP A   37  GLY A   48  1                                  12
==================================================
protein.helix {
  serial_number = 1
  helix_identifier = C12
  selection = chain 'A' and resid   37  through   48
  helix_type = alpha
}
HELIX    1 C12 ASP A   37  GLY A   48  1                                  12
==================================================
protein.helix {
  serial_number = 1
  helix_identifier = D123
  selection = chain 'A' and resid   37  through   48
  helix_type = alpha
}
HELIX    1 D12 ASP A   37  GLY A   48  1                                  12
"""

  annot, ss_from_file = get_annotation(
      phil_lines=phil_str1,
      pdb_lines=pdb_1ywf_sample_strings)
  assert annot.get_n_helices() == 1
  assert annot.get_n_sheets() == 0
  h = annot.helices[0]
  assert h.get_n_defined_hbonds() == 8
  assert annot.get_n_defined_hbonds() == 8
  res = h.as_restraint_group(show_hbonds=True)
  assert not test_utils.show_diff(res, result1,
      strip_trailing_whitespace=True)
  res = h.as_restraint_group(show_hbonds=False)
  assert not test_utils.show_diff(res, result1_1,
      strip_trailing_whitespace=True)
  out = StringIO()
  for ph_str in [phil_str2, phil_str3, phil_str4, phil_str5, phil_str6,
      phil_str7, phil_str8, phil_str9]:
    print("="*50, file=out)
    annot, ss_from_file = get_annotation(
        phil_lines=ph_str,
        pdb_lines=pdb_1ywf_sample_strings)
    assert annot.get_n_defined_hbonds() == 0
    assert annot.get_n_helices() == 1
    assert annot.get_n_sheets() == 0
    h = annot.helices[0]
    print(h.as_restraint_group(), file=out)
    print(h.as_pdb_str(), file=out)
  assert not test_utils.show_diff(out.getvalue(), result2_9,
      strip_trailing_whitespace=True)
  print("OK")

def tst_parsing_phil_single_sheet():
  phil_hbond_portion = """\
  hbond {
    donor = chain A and resid 29 and name O
    acceptor = chain A and resid 13 and name N
  }
  hbond {
    donor = chain A and resid 13 and name O
    acceptor = chain A and resid 29 and name N
  }
  hbond {
    donor = chain A and resid 53 and name O
    acceptor = chain A and resid 159 and name N
  }
  hbond {
    donor = chain A and resid 157 and name O
    acceptor = chain A and resid 53 and name N
  }
  hbond {
    donor = chain A and resid 51 and name O
    acceptor = chain A and resid 157 and name N
  }
  hbond {
    donor = chain A and resid 76 and name O
    acceptor = chain A and resid 54 and name N
  }
  hbond {
    donor = chain A and resid 52 and name O
    acceptor = chain A and resid 76 and name N
  }
  hbond {
    donor = chain A and resid 74 and name O
    acceptor = chain A and resid 52 and name N
  }
  """
  phil_str_1 = """\
  secondary_structure.protein.sheet {
    first_strand = chain A and resseq 13:14
    sheet_id = A
    strand {
      selection = chain A and resseq 27:30
      sense = antiparallel
      bond_start_current = chain A and resseq 29 and name O
      bond_start_previous = chain A and resseq 13 and name N
    }
    strand {
      selection = chain A and resseq 156:159
      sense = parallel
      bond_start_current = chain A and resseq 156 and name O
      bond_start_previous = chain A and resseq 28 and name N
    }
    strand {
      selection = chain A and resseq 51:54
      sense = parallel
      bond_start_current = chain A and resseq 51 and name O
      bond_start_previous = chain A and resseq 157 and name N
    }
    strand {
      selection = chain A and resseq 74:77
      sense = parallel
      bond_start_current = chain A and resseq 74 and name O
      bond_start_previous = chain A and resseq 52 and name N
    }
    %s
  }
  """ % phil_hbond_portion
  phil_str_1_1 = """\
  secondary_structure.protein.sheet {
    first_strand = chain A and resseq 13:14
    sheet_id = AA
    strand {
      selection = chain A and resseq 27:30
      sense = antiparallel
      bond_start_current = chain A and resseq 29 and name O
      bond_start_previous = chain A and resseq 13 and name N
    }
    strand {
      selection = chain A and resseq 156:159
      sense = parallel
      bond_start_current = chain A and resseq 156 and name O
      bond_start_previous = chain A and resseq 28 and name N
    }
    strand {
      selection = chain A and resseq 51:54
      sense = parallel
      bond_start_current = chain A and resseq 51 and name O
      bond_start_previous = chain A and resseq 157 and name N
    }
    strand {
      selection = chain A and resseq 74:77
      sense = parallel
      bond_start_current = chain A and resseq 74 and name O
      bond_start_previous = chain A and resseq 52 and name N
    }
  }
  """
  result1 = """
protein.sheet {
  sheet_id = "  A"
  first_strand = chain 'A' and resid   13  through   14
  strand {
    selection = chain 'A' and resid   27  through   30
    sense = antiparallel
    bond_start_current = chain 'A' and resid   29  and name O
    bond_start_previous = chain 'A' and resid   13  and name N
  }
  strand {
    selection = chain 'A' and resid  156  through  159
    sense = parallel
    bond_start_current = chain 'A' and resid  156  and name O
    bond_start_previous = chain 'A' and resid   28  and name N
  }
  strand {
    selection = chain 'A' and resid   51  through   54
    sense = parallel
    bond_start_current = chain 'A' and resid   51  and name O
    bond_start_previous = chain 'A' and resid  157  and name N
  }
  strand {
    selection = chain 'A' and resid   74  through   77
    sense = parallel
    bond_start_current = chain 'A' and resid   74  and name O
    bond_start_previous = chain 'A' and resid   52  and name N
  }
  hbond {
    donor = chain A and resid 29 and name O
    acceptor = chain A and resid 13 and name N
  }
  hbond {
    donor = chain A and resid 13 and name O
    acceptor = chain A and resid 29 and name N
  }
  hbond {
    donor = chain A and resid 53 and name O
    acceptor = chain A and resid 159 and name N
  }
  hbond {
    donor = chain A and resid 157 and name O
    acceptor = chain A and resid 53 and name N
  }
  hbond {
    donor = chain A and resid 51 and name O
    acceptor = chain A and resid 157 and name N
  }
  hbond {
    donor = chain A and resid 76 and name O
    acceptor = chain A and resid 54 and name N
  }
  hbond {
    donor = chain A and resid 52 and name O
    acceptor = chain A and resid 76 and name N
  }
  hbond {
    donor = chain A and resid 74 and name O
    acceptor = chain A and resid 52 and name N
  }
}"""
  result1_1 = """
protein.sheet {
  sheet_id = "  A"
  first_strand = chain 'A' and resid   13  through   14
  strand {
    selection = chain 'A' and resid   27  through   30
    sense = antiparallel
    bond_start_current = chain 'A' and resid   29  and name O
    bond_start_previous = chain 'A' and resid   13  and name N
  }
  strand {
    selection = chain 'A' and resid  156  through  159
    sense = parallel
    bond_start_current = chain 'A' and resid  156  and name O
    bond_start_previous = chain 'A' and resid   28  and name N
  }
  strand {
    selection = chain 'A' and resid   51  through   54
    sense = parallel
    bond_start_current = chain 'A' and resid   51  and name O
    bond_start_previous = chain 'A' and resid  157  and name N
  }
  strand {
    selection = chain 'A' and resid   74  through   77
    sense = parallel
    bond_start_current = chain 'A' and resid   74  and name O
    bond_start_previous = chain 'A' and resid   52  and name N
  }
}"""

  annot, ss_from_file = get_annotation(
      phil_lines=phil_str_1,
      pdb_lines=pdb_1ywf_sample_strings)
  assert annot.get_n_helices() == 0
  assert annot.get_n_sheets() == 1
  sh = annot.sheets[0]
  assert sh.get_n_defined_hbonds() == 8
  assert annot.get_n_defined_hbonds() == 8
  res = sh.as_restraint_group(show_hbonds=True)
  assert not test_utils.show_diff(res, result1,
      strip_trailing_whitespace=True)
  res = sh.as_restraint_group(show_hbonds=False)
  assert not test_utils.show_diff(res, result1_1,
      strip_trailing_whitespace=True)
  print("OK")


def tst_hybrid_ids():
  inp = iotbx.pdb.input(source_info=None, lines=pdb_1ywf_sample_strings)
  ss_ann = inp.extract_secondary_structure()
  ch_ids = all_chain_ids()[1:1000]
  chain_ids_dict = {'A': ch_ids}
  ss_ann.multiply_to_asu_2(chain_ids_dict)
  # print (ss_ann.as_pdb_str())
  ss_big = annotation.from_records(ss_ann.as_pdb_str().split('\n'))
  # print (ss_big.as_restraint_groups())
  ss_big.as_restraint_groups()

def exercise(args):
  tst_parsing_phil_single_helix()
  tst_parsing_phil_single_sheet()
  tst_hybrid_ids()


if (__name__ == "__main__"):
  exercise(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
iotbx/pdb/tst_tls.py
"""Test TLS analysis"""
from __future__ import absolute_import, division, print_function
import os
from six.moves import cStringIO as StringIO

import libtbx.load_env
from libtbx.test_utils import approx_equal, show_diff
from mmtbx.tls.tools import tls_groups
import iotbx.pdb
from six.moves import zip


def exercise_mmcif_tls():
  pdb_file = libtbx.env.find_in_repositories(
    relative_path="phenix_regression/pdb/3orl.pdb",
    test=os.path.isfile)
  mmcif_file = libtbx.env.find_in_repositories(
    relative_path="phenix_regression/pdb/3orl.cif",
    test=os.path.isfile)

  if pdb_file is None or mmcif_file is None:
    print("Skipping exercise_mmcif_tls(): missing phenix_regression directory.")
    return

  pdb_input = iotbx.pdb.input(file_name=pdb_file)
  pdb_hierarchy = pdb_input.construct_hierarchy()
  cif_input = iotbx.pdb.input(file_name=mmcif_file)
  cif_hierarchy = cif_input.construct_hierarchy()

  pdb_tls_params = pdb_input.extract_tls_params(pdb_hierarchy).tls_params

  cif_block = cif_input.cif_block
  cif_tls_params = cif_input.extract_tls_params(cif_hierarchy).tls_params

  assert len(pdb_tls_params) == len(cif_tls_params) == 3
  check_tls_params(pdb_tls_params, cif_tls_params)

  selection_strings = [tls.selection_string for tls in cif_tls_params]
  tls_grps = tls_groups(tlsos=cif_tls_params, selection_strings=selection_strings)
  cif_block = tls_grps.as_cif_block(hierarchy=cif_hierarchy)

  cif_block.update(cif_hierarchy.as_cif_block())
  cif_model = iotbx.cif.model.cif()
  cif_model["3orl"] = cif_block
  s = StringIO()
  print(cif_model, file=s)
  s.seek(0)
  cif_hierarchy_recycled = iotbx.pdb.input(
    lines=s.readlines(), source_info=None).construct_hierarchy()
  tls_params_recycled = cif_input.extract_tls_params(cif_hierarchy_recycled).tls_params
  assert len(tls_params_recycled) == len(cif_tls_params) == 3
  check_tls_params(tls_params_recycled, cif_tls_params)

  # this one has phenix selection strings
  pdb_file = libtbx.env.find_in_repositories(
    relative_path="phenix_regression/pdb/4g9h.pdb",
    test=os.path.isfile)
  mmcif_file = libtbx.env.find_in_repositories(
    relative_path="phenix_regression/pdb/4g9h.cif",
    test=os.path.isfile)

  pdb_input = iotbx.pdb.input(file_name=pdb_file)
  pdb_hierarchy = pdb_input.construct_hierarchy()
  pdb_tls_params = pdb_input.extract_tls_params(pdb_hierarchy).tls_params

  cif_input = iotbx.pdb.input(file_name=mmcif_file)
  cif_hierarchy = cif_input.construct_hierarchy()
  cif_block = cif_input.cif_block
  cif_tls_params = cif_input.extract_tls_params(cif_hierarchy).tls_params

  assert len(pdb_tls_params) == len(cif_tls_params) == 18
  check_tls_params(pdb_tls_params, cif_tls_params)

  selection_strings = [tls.selection_string for tls in cif_tls_params]
  tls_grps = tls_groups(tlsos=cif_tls_params, selection_strings=selection_strings)
  cif_block = tls_grps.as_cif_block(hierarchy=cif_hierarchy)

  cif_block.update(cif_hierarchy.as_cif_block())
  cif_model = iotbx.cif.model.cif()
  cif_model["4g9h"] = cif_block
  s = StringIO()
  print(cif_model, file=s)
  s.seek(0)
  cif_hierarchy_recycled = iotbx.pdb.input(
    lines=s.readlines(), source_info=None).construct_hierarchy()
  tls_params_recycled = cif_input.extract_tls_params(cif_hierarchy_recycled).tls_params
  assert len(tls_params_recycled) == len(cif_tls_params) == 18
  check_tls_params(tls_params_recycled, cif_tls_params)

  # in this one the tls data items are not looped
  mmcif_file = libtbx.env.find_in_repositories(
    relative_path="phenix_regression/pdb/2xw9.cif",
    test=os.path.isfile)
  cif_input = iotbx.pdb.input(file_name=mmcif_file)
  cif_hierarchy = cif_input.construct_hierarchy()

  cif_block = cif_input.cif_block
  cif_tls_params = cif_input.extract_tls_params(cif_hierarchy).tls_params

  assert len(cif_tls_params) == 1
  cif_tls = cif_tls_params[0]
  assert approx_equal(
    cif_tls.t, [0.0275, 0.0202, 0.0138, -0.0004, 0.0088, -0.0002])
  assert approx_equal(
    cif_tls.l, [0.0554, 0.0231, 0.0573, -0.0127, 0.0112, -0.017])
  assert approx_equal(
    cif_tls.s, [-0.0001, -0.0012, -0.0037, -0.0006, 0.001, 0.0007, -0.0023, -0.0001, -0.0009])
  assert approx_equal(cif_tls.origin, [-1.219, 1.557, 13.138])
  assert approx_equal(cif_tls.selection_string, "(chain A and resseq 1:228)")

  selection_strings = [tls.selection_string for tls in cif_tls_params]
  tls_grps = tls_groups(tlsos=cif_tls_params, selection_strings=selection_strings)
  cif_block = tls_grps.as_cif_block(hierarchy=cif_hierarchy)
  cif_block.update(cif_hierarchy.as_cif_block())
  cif_model = iotbx.cif.model.cif()
  cif_model["2xw9"] = cif_block
  s = StringIO()
  print(cif_model, file=s)
  s.seek(0)
  cif_hierarchy_recycled = iotbx.pdb.input(
    lines=s.readlines(), source_info=None).construct_hierarchy()
  tls_params_recycled = cif_input.extract_tls_params(cif_hierarchy_recycled).tls_params
  assert len(tls_params_recycled) == len(cif_tls_params) == 1
  check_tls_params(tls_params_recycled, cif_tls_params)

def check_tls_params(params1, params2):
  for tls1, tls2 in zip(params1, params2):
    assert approx_equal(tls1.t, tls2.t)
    assert approx_equal(tls1.l, tls2.l)
    assert approx_equal(tls1.s, tls2.s)
    assert approx_equal(tls1.origin, tls2.origin)
    assert not show_diff(tls1.selection_string, tls2.selection_string)


def run():
  exercise_mmcif_tls()
  print("OK")

if __name__ == '__main__':
  run()


 *******************************************************************************


 *******************************************************************************
iotbx/pdb/tst_utils.py
"""Test model utilities"""
from __future__ import absolute_import, division, print_function
import iotbx.pdb.utils

pdb_str_to_be_cif="""
CRYST1   40.339   36.116   46.266  90.00  90.00  90.00 P 1
ATOM      1  CA  ASP AXYB2      34.633  18.762  20.254  1.00 22.59           C
ATOM      2  CA  LYS AXYB3      36.047  17.704  23.610  1.00 19.79           C
ATOM      3  CA  ILE AXYB4      35.551  19.482  26.886  1.00 19.33           C
ATOM      4  CA AHIS AXYB5      38.649  21.223  28.218  0.50 19.79           C
ATOM      5  CA BHIS AXYB6      38.583  21.270  28.209  0.50 20.43           C
ATOM      6  CA  GLY A 138      38.261  15.285  27.690  1.00  6.80           C
ATOM      7  CA  ALA A 139      34.607  14.241  27.428  1.00  4.76           C
ATOM      8  CA ALEU A 140      33.091  14.490  23.937  0.50  5.08           C
ATOM      9  CA BLEU A 140      33.072  14.565  23.972  0.50  5.41           C
ATOM     10  CA  ASN A 141      30.271  17.061  23.474  1.00  5.65           C
"""

pdb_str_other="""
CRYST1   40.339   36.116   46.266  90.00  90.00  90.00 P 1
ATOM      1  CA  ASP DXYB2      34.633  18.762  20.254  1.00 22.59           C
ATOM      2  CA  LYS DXYB3      36.047  17.704  23.610  1.00 19.79           C
ATOM      3  CA  ILE DXYB4      35.551  19.482  26.886  1.00 19.33           C
ATOM      4  CA AHIS DXYB5      38.649  21.223  28.218  0.50 19.79           C
ATOM      5  CA BHIS DXYB6      38.583  21.270  28.209  0.50 20.43           C
ATOM      6  CA  GLY D 138      38.261  15.285  27.690  1.00  6.80           C
ATOM      7  CA  ALA D 139      34.607  14.241  27.428  1.00  4.76           C
ATOM      8  CA ALEU D 140      33.091  14.490  23.937  0.50  5.08           C
ATOM      9  CA BLEU D 140      33.072  14.565  23.972  0.50  5.41           C
ATOM     10  CA  ASN D 141      30.271  17.061  23.474  1.00  5.65           C
"""

pseudo_as_pdb="""
ATOM     10  CA  ASN A 141      30.271  17.061  23.474  1.00  5.65
ATOM     24 ZC1'  GC U  11      10.024   9.813   3.777  1.00 36.50      UNK
"""
spacing_as_pdb="""
ATOM     10  I   ASN A 141      30.271  17.061  23.474  1.00  5.65
ATOM     11 I    ASN A 141      30.271  17.061  23.474  1.00  5.65
HETATM   12  I   LIG A 141      30.271  17.061  23.474  1.00  5.65
HETATM   13 I    LIG A 141      30.271  17.061  23.474  1.00  5.65
"""

as_pdb = pdb_str_to_be_cif
other_as_pdb = pdb_str_other

# Convert pdb_str_hybrid_residues to mmcif:
from libtbx.test_utils import convert_pdb_to_cif_for_pdb_str
convert_pdb_to_cif_for_pdb_str(locals(), chain_addition="ZXLONG")
as_cif = pdb_str_to_be_cif # now it is cif
other_as_cif = pdb_str_other# now it is cif

def exercise_all_chain_ids():
  ids = iotbx.pdb.utils.all_chain_ids()
  assert len(ids)==3906
  assert len(set(ids))==3906

def exercise_add_models_and_hierarchies():
  from iotbx.pdb.utils import get_pdb_info, add_models, add_hierarchies
  ph1 = get_pdb_info(as_pdb).hierarchy
  ph2 = get_pdb_info(other_as_pdb).hierarchy
  m1 = ph1.as_model_manager(crystal_symmetry = None)
  m2 = ph2.as_model_manager(crystal_symmetry = None)
  ph = add_hierarchies(hierarchy_list = [ph1,ph2])
  ph2a = ph.apply_atom_selection("chain D")
  assert ph2.is_similar_hierarchy(ph2a)
  m = add_models(model_list = [m1,m2])
  ph1a = m.get_hierarchy().apply_atom_selection("chain A")
  assert ph1a.is_similar_hierarchy(ph1)


def exercise_set_element_ignoring_spacings():
  from iotbx.pdb.utils import get_pdb_info
  pdb_info = get_pdb_info(spacing_as_pdb, allow_incorrect_spacing = True)
  from iotbx.pdb.utils import set_element_ignoring_spacings
  set_element_ignoring_spacings(pdb_info.hierarchy)

def exercise_check_pseudo_atoms():
  from iotbx.pdb.utils import get_pdb_info
  pdb_info = get_pdb_info(pseudo_as_pdb, check_pseudo = True)
  from iotbx.pdb.utils import check_for_pseudo_atoms
  check_for_pseudo_atoms(pdb_info.hierarchy)

def exercise_get_pdb_info():
  from iotbx.pdb.utils import get_pdb_info
  pdb_info_from_pdb = get_pdb_info(as_pdb)
  pdb_info_from_cif = get_pdb_info(as_cif)
  assert not pdb_info_from_pdb.hierarchy.is_similar_hierarchy(
    pdb_info_from_cif.hierarchy)
  for model in pdb_info_from_cif.hierarchy.models():
    for chain in model.chains():
      chain.id = chain.id.replace("ZXLONG","") # make it short again
  assert pdb_info_from_pdb.hierarchy.is_similar_hierarchy(
    pdb_info_from_cif.hierarchy)
  assert pdb_info_from_pdb.crystal_symmetry.is_similar_symmetry(
    pdb_info_from_cif.crystal_symmetry)

def exercise_interleave_alt_confs():
  from scitbx.array_family import flex
  import iotbx.pdb
  pdb_inp_lines_1 = flex.split_lines("""\
CRYST1   14.600   26.100   29.200  90.00  90.00  90.00 P 21 21 21
SCALE1      0.068493 -0.000000 -0.000000        0.00000
SCALE2      0.000000  0.038314 -0.000000        0.00000
SCALE3      0.000000  0.000000  0.034247        0.00000
ATOM     17  N  ASER     4      -0.155   3.125   4.014  1.00 17.55           N
ATOM     18  CA ASER     4      -0.175   1.896   4.797  1.00 15.51           C
ATOM     19  C  ASER     4       1.158   1.683   5.505  1.00 16.48           C
ATOM     20  O  ASER     4       1.508   0.560   5.868  1.00  6.79           O
ATOM     21  CB ASER     4      -0.490   0.698   3.899  1.00 17.79           C
ATOM     22  OG ASER     4      -1.752   0.849   3.272  0.50 11.67           O
ATOM     24  N  ALEU     5       1.898   2.771   5.698  1.00 10.29           N
ATOM     25  CA ALEU     5       3.208   2.705   6.333  1.00  3.27           C
ATOM     26  C  ALEU     5       3.407   3.868   7.301  1.00  7.66           C
ATOM     27  O  ALEU     5       3.458   5.024   6.884  1.00 14.56           O
ATOM     28  CB ALEU     5       4.310   2.711   5.272  1.00  3.87           C
ATOM     29  CG ALEU     5       5.736   2.474   5.769  1.00 14.70           C
ATOM     30  CD1ALEU     5       5.818   1.155   6.516  1.00 19.83           C
ATOM     31  CD2ALEU     5       6.719   2.499   4.611  1.00 13.84           C
  """)

  pdb_inp_lines_2 = flex.split_lines("""\
CRYST1   14.600   26.100   29.200  90.00  90.00  90.00 P 21 21 21
SCALE1      0.068493 -0.000000 -0.000000        0.00000
SCALE2      0.000000  0.038314 -0.000000        0.00000
SCALE3      0.000000  0.000000  0.034247        0.00000
ATOM     17  N  BSER     4      -0.155   3.125   4.014  1.00 17.55           N
ATOM     18  CA BSER     4      -0.175   1.896   4.797  1.00 15.51           C
ATOM     19  C  BSER     4       1.158   1.683   5.505  1.00 16.48           C
ATOM     20  O  BSER     4       1.508   0.560   5.868  1.00  6.79           O
ATOM     21  CB BSER     4      -0.490   0.698   3.899  1.00 17.79           C
ATOM     23  OG BSER     4       0.484   0.555   2.880  0.50  2.71           O
ATOM     24  N  BLEU     5       1.898   2.771   5.698  1.00 10.29           N
ATOM     25  CA BLEU     5       3.208   2.705   6.333  1.00  3.27           C
ATOM     26  C  BLEU     5       3.407   3.868   7.301  1.00  7.66           C
ATOM     27  O  BLEU     5       3.458   5.024   6.884  1.00 14.56           O
ATOM     28  CB BLEU     5       4.310   2.711   5.272  1.00  3.87           C
ATOM     29  CG BLEU     5       5.736   2.474   5.769  1.00 14.70           C
ATOM     30  CD1BLEU     5       5.818   1.155   6.516  1.00 19.83           C
ATOM     31  CD2BLEU     5       6.719   2.499   4.611  1.00 13.84           C
""")

  h1 = iotbx.pdb.input(source_info=None, lines=pdb_inp_lines_1).construct_hierarchy()
  h2 = iotbx.pdb.input(source_info=None, lines=pdb_inp_lines_2).construct_hierarchy()

  # Interleave the alt confs
  from iotbx.pdb.utils import interleave_alt_confs
  new_h = interleave_alt_confs(h1,h2)

  # Make sure we got both confs
  new_h1 = new_h.apply_atom_selection('altloc A')
  new_h2 = new_h.apply_atom_selection('altloc B')
  assert new_h1.as_pdb_string() == h1.as_pdb_string()
  assert new_h2.as_pdb_string() == h2.as_pdb_string()

  assert new_h1.is_similar_hierarchy(h1)
  assert new_h2.is_similar_hierarchy(h2)

  assert not new_h1.is_similar_hierarchy(h2)
  assert not new_h2.is_similar_hierarchy(h1)

def run():
  exercise_add_models_and_hierarchies()
  exercise_set_element_ignoring_spacings()
  exercise_check_pseudo_atoms()
  exercise_get_pdb_info()
  exercise_all_chain_ids()
  exercise_interleave_alt_confs()
  print("OK")

if __name__ == '__main__':
  run()


 *******************************************************************************


 *******************************************************************************
iotbx/pdb/utils.py
"""Misc utilities for working with models"""
from __future__ import absolute_import, division, print_function
import string
from itertools import product
from six.moves import range
import sys

class generate_n_char_string:
  r""" Iterator to generate strings of length n_chars, using upper-case,
    lower-case and numbers as desired.
    Allows specialty sets of characters as well

  parameters:
    n_chars:  length of string to produce
    include_upper:  include upper-case letters
    include_lower:  include lower-case letters
    include_numbers:  include numbers
    include_special_chars: include special characters:
       []_,.;:"&<>()/\{}'`~!@#$%*|+-
    end_with_tilde:  return n_chars - 1 plus the character "~"
    reverse_order:  reverse the order so numbers 9-0, lower case z-a,
                  upper case Z-A

  returns:
    n_char string, new string on every next()
    None if no more strings to return

  Tested in iotbx/regression/tst_generate_n_char_string.py

  """
  # The doc string must be a raw string because of the special characters
  def __init__(self, n_chars = 1,
      include_upper = True,
      include_lower = True,
      include_numbers = True,
      include_special_chars = False,
      end_with_tilde = False,
      reverse_order = False):
    self._end_with_tilde = end_with_tilde
    if self._end_with_tilde:
      self._n_chars = n_chars - 1
    else: # usual
      self._n_chars = n_chars

    all_chars = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
    all_chars_lc = all_chars.lower()
    all_numbers = '0123456789'
    special_characters = r"""[]_,.;:"&<>()/\{}'`~!@#$%*|+-"""
    self._tilde = """~"""

    self._all_everything = ""
    if include_upper:
       self._all_everything += all_chars
    if include_lower:
       self._all_everything += all_chars_lc
    if include_numbers:
       self._all_everything += all_numbers
    if include_special_chars:
       self._all_everything += special_characters

    if reverse_order:
      # Use them in reverse order
      x = []
      for i in self._all_everything:
        x.append(i)
      x.reverse()
      self._all_everything = "".join(x)

    self._n = len(self._all_everything)
    self._indices = []
    for k in range(self._n_chars):
      self._indices.append(0)
  def next(self):
    # Write out current text based on current indices
    value = ""
    for k in range(self._n_chars):
      value += self._all_everything[self._indices[k]]

    # Update indices
    for kk in range(self._n_chars):
      k = self._n_chars - kk - 1 # from last index to first
      self._indices[k] += 1
      if self._indices[k] < self._n: #  current index is in range
        break
      elif k == 0: # current index is out of range and is first index
        return None # no more available
      else: # current index is out of range but is not first index
        self._indices[k] = 0
    if self._end_with_tilde:
      return value + self._tilde
    else: # usual
      return value


def __permutations(iterable, r=None): # XXX This may go to libtbx or scitbx
  pool = tuple(iterable)
  n = len(pool)
  r = n if r is None else r
  for indices in product(range(n), repeat=r):
    if(len(indices) == r):
      yield tuple(pool[i] for i in indices)

def all_chain_ids():
  """
  Test is in
  iotbx/regression/tst_all_chain_ids.py
  There should not be leading whitespace for one letter chain ids.

  Returns all possible 2 character chain IDs for PDB format files.
  In general, returns single character chains first.
  Also tries to use all combinations of uppercase/numbers before going to lower case.
  """
  chars = string.ascii_uppercase+string.digits
  lowerchars = string.ascii_lowercase
  both_char_upper = __permutations(iterable = chars, r = 2)
  second_char_lower = product(chars, lowerchars)
  first_char_lower = product(lowerchars, chars)
  both_char_lower = __permutations(iterable = lowerchars, r = 2)
  # result = [" "+c for c in chars]+[" "+c for c in lowerchars]+\
  result = [c for c in chars]+[c for c in lowerchars]+\
         ["".join(p) for p in both_char_upper]+\
         ["".join(p) for p in second_char_lower]+\
         ["".join(p) for p in first_char_lower]+\
         ["".join(p) for p in both_char_lower]
  return result

def all_label_asym_ids(maximum_length=4):
  """Return a list of possible label_asym_ids"""
  chars = string.ascii_uppercase
  rc = ["".join(c) for c in chars]
  for r in range(2, maximum_length+1):
    char_upper = __permutations(iterable = chars, r = r)
    rc += ["".join(p) for p in char_upper]
  return rc

def get_input_model_file_name_from_params(params):
  """Return input model file_name from a parameters object"""
  if not params:
    return ""

  input_scopes = [None, 'input_files','map_model','input']
  input_file_types = ['pdb_in','model','input_model','fixed_model',
     'moving_model','fixed_pdb','moving_pdb','search_model']
  file_name = ""
  for s in input_scopes:
    for x in input_file_types:
      if file_name: break
      if s is None:
        file_name = getattr(params,x,None)
      elif hasattr(params,s):
        ss = getattr(params,s)
        file_name = getattr(ss,x,None)
  if type(file_name) in [type([1,2,3]),type((1,2,3))]:
    if file_name:
      file_name = file_name[0]
    else:
      file_name = ''
  return file_name

def target_output_format_in_params(params):
  """
  Find and return value of target_output_format parameter that may be under
  output_files or output phil scope.
  """
  for x in ['output_files','output']:
    if params and hasattr(params,x) and \
         hasattr(getattr(params,x),'target_output_format'):
      target_output_format = getattr(getattr(params,x),'target_output_format')
      if target_output_format in [None,'','None']:
        target_output_format = None
      return target_output_format
  else:
    return None

def get_target_output_format_from_file_name(file_name,
   default = None):
  """Generate reasonable target_output_format (pdb/mmcif/default) from a
  a file name"""
  if file_name:
    import os
    path, ext = os.path.splitext(file_name)
    if ext == '.pdb':
      target_output_format = 'pdb'
    elif ext == '.cif':
      target_output_format = 'mmcif'
    else:
      target_output_format = default
  else:
    target_output_format = default
  return target_output_format

def move_down_scope_to_input_files(params, levels = 3):
  """
  Find one of the scope names from target_scopes below in params.
  levels - depth of the nested scopes to look in.
  returns first suitable name/scope.
  """
  target_scopes = ['input_files','output','output_files','map_model',]
  if levels < 0:
    return None
  for t in target_scopes:
    if hasattr(params, t):
      return params
  for x in dir(params):
    if x.startswith("_"): continue
    new_p = move_down_scope_to_input_files(getattr(params, x),
      levels = levels - 1)
    if new_p:
      return new_p
  return None

def set_target_output_format_in_params(params,
      file_name = None, default = 'pdb', target_output_format = None,
      out = sys.stdout, quiet = True):
  """
  Find target_output_format parameter in params and:
  - If it is not None, leave it as it was
  - If it is None:
    - set it to extension of file_name or default;
  Return what was set - "pdb" or "mmcif"
  """
  params = move_down_scope_to_input_files(params)
  # Now params pointing out at the correct level of phil scope, the one
  # containing output_files.target_output_format.
  # Note that level to which params points outside this function is not changed.
  # At the same time the value of output_files.target_output_format outside
  # WILL be changed by statements below.

  # Do we have it set already:
  target_output_format = target_output_format_in_params(params)
  if not target_output_format:
    if not file_name:
      file_name = get_input_model_file_name_from_params(params)
    target_output_format = get_target_output_format_from_file_name(
      file_name, default = default)

  # set value in params.output_files.target_output_format
  if hasattr(params,'output_files') and \
       hasattr(params.output_files,'target_output_format'):
     params.output_files.target_output_format = target_output_format
  elif hasattr(params,'output') and \
       hasattr(params.output,'target_output_format'):
     params.output.target_output_format = target_output_format

  # print result
  if not quiet:
    print("Target output format will be: %s" %(target_output_format),
      file = out)

  # Return value
  return target_output_format

def catenate_segment_onto_chain(model_chain, s2, gap = 1,
   keep_numbers = False, insertion_chain = None):
  '''  catenate residues from s2 onto model_chain'''
  from iotbx.pdb import resseq_encode
  if not model_chain:
    return
  if not insertion_chain:
    s2_as_ph = s2.get_hierarchy()
    if not s2_as_ph.overall_counts().n_residues > 0:
      return
    insertion_chain = s2.get_hierarchy().models()[0].chains()[0]
  new_segid = model_chain.residue_groups(
     )[0].atom_groups()[0].atoms()[0].segid
  highest_resseq = None
  if len(model_chain.residue_groups()) > 0:
    highest_resseq = model_chain.residue_groups()[0].resseq_as_int()
  for rg in model_chain.residue_groups():
    rg_resseq = rg.resseq_as_int()
    highest_resseq=max(highest_resseq,rg_resseq)
  resseq_as_int = highest_resseq + (gap - 1)
  for rg in insertion_chain.residue_groups():
    resseq_as_int += 1
    rg_copy = rg.detached_copy()
    if (not keep_numbers):
      rg_copy.resseq = resseq_encode(resseq_as_int)
    model_chain.append_residue_group(
       residue_group = rg_copy)
    rg_copy.link_to_previous = True # Required
    for ag in rg_copy.atom_groups():
      for atom in ag.atoms():
        awl = atom.fetch_labels()
        atom.segid = new_segid

def lines_are_really_text(lines):
  ''' Catch case where lines are supplied but actually it is just text,
     not a list or flex array of lines
  '''
  if lines and type(lines) in (type('abc'), type(b'abc')):
    return True
  else:
    return False

def get_lines(text = None, file_name = None, lines = None):
    """Read lines from text or file or lines"""
    import os
    if lines and lines_are_really_text(lines):
      text = lines
    elif lines:
      text = "\n".join(lines)
    elif file_name and os.path.isfile(file_name):
      text = open(file_name).read()
    if not text:
      text = ""
    # Python 3 read fix
    # =======================================================================
    if sys.version_info.major == 3 and type(text) == type(b'abc'):
      text = text.decode("utf-8")
    # =======================================================================
    from cctbx.array_family import flex
    return flex.split_lines(text)

def check_for_missing_elements(hierarchy, file_name = None):
    """Check a hierarchy for missing element names"""
    atoms = hierarchy.atoms()
    elements = atoms.extract_element().strip()
    if (not elements.all_ne("")):
      n_missing = elements.count("")
      missing_list = []
      for atom in list(atoms):
        if not atom.element.strip():
          missing_list.append(atom.format_atom_record())

      raise AssertionError(
        "Uninterpretable elements for %d atoms%s. \n" %(n_missing,
        "" if not file_name else " in '%s'" %(file_name))+
        "Up to 10 listed below: \n%s" % ("\n".join(missing_list[:10])))

def get_pdb_info(text = None, file_name = None, lines = None,
     check_pseudo = False,
     return_group_args = False,
     allow_incorrect_spacing = False):
  ''' Get a pdb_input object from pdb or mmcif file, construct a
      hierarchy, check the hierarchy for missing elements and fill them
      in if from pdb.  Return group_args object with
      hierarchy, pdb_input, and crystal_symmetry.

      If text has no atoms, returns empty hierarchy (Note: iotbx.pdb.input
      returns an empty hierarchy in this case if supplied with PDB input
      and raises an exception if supplied with mmCIF input without atoms).

      This method is preferred over get_pdb_input and get_pdb_hierarchy
      as a method for robust reading of pdb/mmcif files because it
      generates the hierarchy only once.  If you run get_pdb_input and then
      construct the hierarchy it is generated twice.
  '''
  return get_pdb_input(text = text, file_name = file_name,
     lines = lines, check_pseudo = check_pseudo,
     allow_incorrect_spacing = allow_incorrect_spacing,
     return_group_args = True)

def get_pdb_hierarchy(text=None, file_name = None,
     lines = None, check_pseudo = None,
     allow_incorrect_spacing = False):
  ''' Get pdb_input object and construct hierarchy.  Normally use instead
      info =  get_pdb_info and then take info.hierarchy so that you have
      the pdb_input object and crystal_symmetry available as well
  '''
  return get_pdb_input(text = text, file_name = file_name, lines = lines,
     check_pseudo = check_pseudo, return_pdb_hierarchy = True,
     allow_incorrect_spacing = allow_incorrect_spacing)

def get_model(text=None, file_name = None,
     lines = None, check_pseudo = None,
     allow_incorrect_spacing = False):
  ''' Get pdb_input object and construct model object.
  '''
  return get_pdb_input(text = text, file_name = file_name, lines = lines,
     check_pseudo = check_pseudo, return_model= True,
     allow_incorrect_spacing = allow_incorrect_spacing)


def get_pdb_input(text = None, file_name = None, lines = None,
    check_pseudo = False,
    return_pdb_hierarchy = False,
    return_model = False,
    return_group_args = False,
     allow_incorrect_spacing = False):

  ''' Get a pdb_input object from pdb or mmcif file, construct a
      hierarchy, check the hierarchy for missing elements and fill them
      in if from pdb.  Return hierarchy, pdb_input, or
      group_args object with hierarchy, pdb_input, and crystal_symmetry.

      Normally use instead the info = get_pdb_info method and then
      you have hierarchy, pdb_input and crystal_symmetry all available

  '''
  lines = get_lines(text = text, file_name = file_name, lines = lines)

  # Get input object as pdb_inp
  import iotbx.pdb
  pdb_inp = iotbx.pdb.input(source_info=None,lines=lines)

  # Guess elements if PDB is source input and elements are missing.
  # This is can only be done with PDB files
  # because mmcif files lose the positional information
  # in atom names, so CA cannot be distinguished from Ca (calcium) without
  #  element information in an mmCIF file.

  if type_of_pdb_input(pdb_inp) == 'pdb': # Guess elements if missing for PDB
    ph = try_to_get_hierarchy(pdb_inp)
    ph.guess_chemical_elements(check_pseudo = check_pseudo,
      allow_incorrect_spacing = allow_incorrect_spacing)
    check_for_missing_elements(ph)
  else:
    # Make sure we have an element for each atom
    # try to construct and save empty ph if fails
    ph = try_to_get_hierarchy(pdb_inp)
    check_for_missing_elements(ph)

  # Return what is requested
  if return_group_args:
    from libtbx import group_args
    return group_args(group_args_type = 'hierarchy and pdb_input',
      hierarchy = ph,
      pdb_inp = pdb_inp,
      crystal_symmetry = pdb_inp.crystal_symmetry())

  elif return_pdb_hierarchy:
    return ph
  elif return_model:
    return ph.as_model_manager(crystal_symmetry = pdb_inp.crystal_symmetry())
  else:
    return pdb_inp



def set_element_ignoring_spacings(hierarchy):
  ''' Set missing elements ignoring spacings. This allows
   reading a PDB file where there are no elements given and the
   atom names are not justified properly. Intended for hetero atoms
   even if they are not marked as such.  Normally try to set
   elements in normal way first.
  '''

  atoms = hierarchy.atoms()
  elements = atoms.extract_element().strip()
  sel = (elements == "")
  atoms_sel = atoms.select(sel)
  for at in atoms_sel:
    if at.name.startswith(" "):
      at.name = at.name[1:]
    else:
      at.name = " "+at.name[:3]
  atoms.set_chemical_element_simple_if_necessary()

def check_for_pseudo_atoms(hierarchy):
    """Check for special case where PDB input contains pseudo-atoms ZC ZU etc
    """
    atoms = hierarchy.atoms()
    # Do we already have all the elements
    elements = atoms.extract_element().strip()
    if elements.all_ne(""): # all done
      return

    # Are there any pseudo-atoms
    atom_names = atoms.extract_name().strip()
    all_text = "".join(list(atom_names))
    if all_text.find("Z") < 0: # no pseudo-atoms
      return

    # contains some pseudo-atoms ZC ZU etc. Get their elements if necessary
    for atom in atoms:
      if atom.element.replace(" ","") == '':
        # Missing element not fixed by set_chemical_element_simple_if_necessary
        #  take first non-Z, non-blank character
        for c in atom.name.replace("Z","").replace(" ",""):
          if c.isalpha():
            atom.element=c
            break

def type_of_pdb_input(pdb_inp):
  """Determine type of PDB input from a pdb_inp object"""
  format_type = None
  if not pdb_inp:
    return format_type
  else:
    s = str(type(pdb_inp))
    if s.find("cif") > 0:
      format_type = "mmcif"
    elif s.find("pdb") > 0:
      format_type = "pdb"
    return format_type

def try_to_get_hierarchy(pdb_inp):
    """Try to get a hierarchy from a pdb_inp object"""
    try:
      return pdb_inp.construct_hierarchy()
    except Exception as e: # nothing there
      if str(e).find("something is not present") > -1:  # was empty hierarchy
        # NOTE this text is in modules/cctbx_project/iotbx/pdb/mmcif.py
        # If it changes, change it here too.
        from iotbx.pdb import hierarchy
        ph = hierarchy.root()
        return ph
      else:  # Stop and ask developers to check code
        ph_text = "\n".join(lines)
        text = """The above hierarchy could not be read. If it is just empty,
         please ask developers to check that the
         text "something is not present" is used in
         modules/cctbx_project/iotbx/pdb/mmcif.py as part of the assertion that
         atoms are present.  Modify this text to match the assertion if
         necessary"""
        raise Sorry(ph_text+"\n"+text+"\n"+str(e))
def add_hierarchies(hierarchy_list, create_new_chain_ids_if_necessary = True):
  """Append all hierarchies on to the first one"""
  if not hierarchy_list:
    return None
  new_hierarchy_list = []
  for hierarchy in hierarchy_list:
    if hierarchy and (hierarchy.overall_counts().n_residues > 0):
      new_hierarchy_list.append(hierarchy)
  hierarchy_list = new_hierarchy_list
  if not hierarchy_list:
    return None

  hierarchy = hierarchy_list[0]
  for ph in hierarchy_list[1:]:
    hierarchy = add_hierarchy(hierarchy, ph,
      create_new_chain_ids_if_necessary = create_new_chain_ids_if_necessary)
  return hierarchy

def add_hierarchy(hierarchy, other, create_new_chain_ids_if_necessary = True):
  ''' Add chains from hierarchy other to existing hierarchy.
    Only adds chains from first model in other hierarchy'''
  if not hierarchy:
    return other
  hierarchy = hierarchy.deep_copy()
  if not other:
    return hierarchy
  existing_chain_ids = hierarchy.chain_ids()
  for model in other.models()[:1]:
    for chain in model.chains():
      if chain.id in existing_chain_ids: # duplicate chains in add_model
        if not create_new_chain_ids_if_necessary:
          # append to existing chain
          existing_chain = get_chain(hierarchy, chain_id = chain.id)
          catenate_segment_onto_chain(existing_chain, None, gap = 1,
               keep_numbers = True, insertion_chain= chain.detached_copy())
          continue
        else:
          chain.id = get_new_chain_id(existing_chain_ids)
      new_chain = chain.detached_copy()
      existing_chain_ids.append(chain.id)
      for model_mm in hierarchy.models()[:1]:
        model_mm.append_chain(new_chain)
  hierarchy.remove_ter_or_break()
  return hierarchy

def get_chain(hierarchy, chain_id = None):
  """Get chain with id of chain_id"""
  for model in hierarchy.models():
    for chain in model.chains():
      if chain.id == chain_id:
        return chain

def add_models(model_list, create_new_chain_ids_if_necessary = True):
  ''' Method to combine the chains in a set of models to create a new
  model with all the chains.
  param: model_list:  list of model objects
  param: create_new_chain_ids_if_necessary:  If True (default), if a
          model has a duplicate chain ID, create a new one and rename it
  returns:  first model in model_list with all chains from all models.
  '''

  if not model_list:
    return None # nothing to do
  new_model_list = []
  for m in model_list:
    if m and (m.get_hierarchy().overall_counts().n_residues > 0):
      new_model_list.append(m)
  model_list = new_model_list
  if not model_list:
    return None # nothing to do

  if model_list[0].crystal_symmetry() is not None:
    model_list[0] = model_list[0].deep_copy()
    m_had_crystal_symmetry = True
  else: # Need crystal symmetry for deep_copy of model
    crystal_symmetry = None
    for m in model_list:
      if m.crystal_symmetry() and (not crystal_symmetry):
        crystal_symmetry = m.crystal_symmetry()
        break
    # Can deep-copy a hierarchy without crystal_symmetry
    ph = model_list[0].get_hierarchy().deep_copy()
    model_list[0] = ph.as_model_manager(crystal_symmetry = crystal_symmetry)
    model_list[0].add_crystal_symmetry_if_necessary()
    m_had_crystal_symmetry = False

  model = model_list[0]
  for m in model_list[1:]:
    model = add_model(model, m,
         create_new_chain_ids_if_necessary = create_new_chain_ids_if_necessary)

  if not m_had_crystal_symmetry:
    model = model.get_hierarchy().as_model_manager(crystal_symmetry = None)
  return model

def add_model(model, other, create_new_chain_ids_if_necessary = True):
  ''' Add chains from other to existing model to create new composite model'''
  if not model:
    other.reset_after_changing_hierarchy()
    return other
  model.add_crystal_symmetry_if_necessary()
  model = model.deep_copy()
  if not other:
    model.reset_after_changing_hierarchy()
    return model
  model_ph = model.get_hierarchy() # working hierarchy
  existing_chain_ids = []
  for model_mm1 in model_ph.models()[:1]:
    for chain in model_mm1.chains():
      if not chain.id.strip():
        chain.id = get_new_chain_id(existing_chain_ids)
  existing_chain_ids = model_ph.chain_ids()

  for model_mm2 in other.get_hierarchy().models()[:1]:
    for chain in model_mm2.chains():
      if not chain.id.strip():
        chain.id = get_new_chain_id(existing_chain_ids)

      if chain.id in existing_chain_ids: # duplicate chains in add_model
        if not create_new_chain_ids_if_necessary:
          # append to existing chain
          from iotbx.pdb.utils import get_chain
          from iotbx.pdb.utils import catenate_segment_onto_chain
          existing_chain = get_chain(model_ph, chain_id = chain.id)
          catenate_segment_onto_chain(existing_chain, None, gap = 1,
               keep_numbers = True, insertion_chain= chain.detached_copy())
          continue
        else:
          chain.id = get_new_chain_id(existing_chain_ids)
      new_chain = chain.detached_copy()
      existing_chain_ids.append(chain.id)
      for model_mm in model_ph.models()[:1]:
        model_mm.append_chain(new_chain)
  # Remove TER/BREAK
  model.get_hierarchy().remove_ter_or_break()
  model.reset_after_changing_hierarchy()

  # Handle model.info().numbering_dict if present
  if hasattr(model,'info') and model.info().get('numbering_dict') and \
     hasattr(other,'info') and other.info().get('numbering_dict'):
    model.info().numbering_dict.add_from_other(other.info().numbering_dict)
  return model

def get_new_chain_id(existing_chain_ids):
  """Generate a new chain ID not matching existing_chain_ids"""
  lc = "abcdefghijklmnopqrstuvwxyz"
  uc = lc.upper()
  cc = uc+lc
  eci = []
  for x in existing_chain_ids:
    eci.append(x.strip())
  existing_chain_ids = eci
  for b in " "+cc:
    for a in cc:
      d = (a+b).strip()
      if not d in existing_chain_ids:
        return d
  raise AssertionError ("Not able to generate a new chain ID")


def catenate_segments(model, other, gap = 1,
   keep_numbers = False):
  '''
    catenate two models and renumber starting with first residue of model
    if gap is set, start other  gap residue numbers higher than the end of model
    if keep_numbers is set, just keep all the residue numbers
  '''
  model = model.deep_copy()
  model = model.apply_selection_string("not (name OXT)") # get rid of these
  model_ph = model.get_hierarchy() # working hierarchy
  for model_mm in model_ph.models()[:1]:
    for model_chain in model_mm.chains()[:1]:
        from iotbx.pdb.utils import catenate_segment_onto_chain
        catenate_segment_onto_chain(
          model_chain,
          other,
          gap = gap,
          keep_numbers = keep_numbers)
  model.reset_after_changing_hierarchy()
  return model

def catenate_segment_onto_chain(chain, other_model, gap = 1,
   keep_numbers = False, insertion_chain = None):
  '''  catenate residues from other (mmtbx.model object)  onto chain.
     Only includes first chain of first model in other'''
  from iotbx.pdb import resseq_encode
  if not chain:
    return
  if not insertion_chain:
    other_model_as_ph = other_model.get_hierarchy()
    if not other_model_as_ph.overall_counts().n_residues > 0:
      return
    insertion_chain = other_model.get_hierarchy().models()[0].chains()[0]
  new_segid = chain.residue_groups(
     )[0].atom_groups()[0].atoms()[0].segid
  highest_resseq = None
  if len(chain.residue_groups()) > 0:
    highest_resseq = chain.residue_groups()[0].resseq_as_int()
  for rg in chain.residue_groups():
    rg_resseq = rg.resseq_as_int()
    highest_resseq=max(highest_resseq,rg_resseq)
  resseq_as_int = highest_resseq + (gap - 1)
  for rg in insertion_chain.residue_groups():
    resseq_as_int += 1
    rg_copy = rg.detached_copy()
    if (not keep_numbers):
      rg_copy.resseq = resseq_encode(resseq_as_int)
    chain.append_residue_group(
       residue_group = rg_copy)
    rg_copy.link_to_previous = True # Required
    for ag in rg_copy.atom_groups():
      for atom in ag.atoms():
        awl = atom.fetch_labels()
        atom.segid = new_segid


def get_cif_or_pdb_file_if_present(file_name):
   ''' Identify whether a file with the name file_name or with
   alternate extensions replacing pdb/cif is present.
   If file_name is present, return file_name.
   If not, and alternative is present, return alternative file name
   Otherwise return empty string
   NOTE: This is not intended for use on initial read-in of models. That
    should be done by the DataManager.  This is only for intermediate files
    in modules where it is not feasible to use the DataManager.
   '''

   import os
   if file_name and os.path.isfile(file_name): # if it is present, take it
     return file_name
   # Otherwise, look for pdb or cif versions of this file
   p,e = os.path.splitext(file_name)
   e_pdb = e.replace("cif","pdb")
   e_cif = e.replace("pdb","cif")
   pdb_file = "%s%s" %(p,e_pdb)
   cif_file = "%s%s" %(p,e_cif)
   if os.path.isfile(pdb_file):
     return pdb_file
   elif os.path.isfile(cif_file):
     return cif_file
   else:
     return "" # return empty string so os.path.isfile(return_value) works

def interleave_alt_confs(ph1, ph2, selection_string = None):
  """ Method to interleave alternate conformations in two hierarchies
   Requires that all atoms are present in both hierarchies, and that the
   hierarchies have different altloc values for each atom.
   If selection_string is supplied, remove all alternate conformations that
   are not in the selection (keep just selected alternate conformations)
  """

  # Check that hierarchies are similar
  ph1_no_alt = ph1.deep_copy()
  ph1_no_alt.remove_alt_confs(always_keep_one_conformer=True)
  ph2_no_alt = ph2.deep_copy()
  ph2_no_alt.remove_alt_confs(always_keep_one_conformer=True)
  assert ph1_no_alt.is_similar_hierarchy(ph2_no_alt), \
     "Models do not have the same hierarchy"

  # Interleave the hierarchies
  from iotbx.pdb import hierarchy
  new_ph = hierarchy.root()
  for m0, m1 in zip(ph1.models(), ph2.models()):
    m = hierarchy.model()
    m.id = m0.id
    new_ph.append_model(m)
    for c0, c1 in zip(m0.chains(), m1.chains()):
     c = hierarchy.chain()
     c.id = c0.id
     m.append_chain(c)
     for rg0, rg1 in zip(c0.residue_groups(), c1.residue_groups()):
       r = hierarchy.residue_group()
       assert rg0.icode == rg1.icode, "Residue icodes must match"
       assert rg0.resseq == rg1.resseq, "Residue resseqs must match"
       r.resseq = rg0.resseq
       r.icode = rg0.icode
       c.append_residue_group(r)
       for ag0, ag1 in zip(rg0.atom_groups(), rg1.atom_groups()):
         assert ag0.resname == ag1.resname, "Atoms need matching residue names"
         assert ag0.altloc != ag1.altloc, "Atoms need different altloc values"
         # Append each conformer for this atom group
         r.append_atom_group(ag0.detached_copy())
         r.append_atom_group(ag1.detached_copy())

  if selection_string: # Identify atoms to save only one conformer by index
    asc1=new_ph.atom_selection_cache()
    sel1=asc1.selection(string = selection_string) # sel1[i] = True to keep

    i = 0
    for model in new_ph.models():
      for chain in model.chains():
        for rg in chain.residue_groups():
          remove = []
          first = True
          for ag in rg.atom_groups():
            for at in ag.atoms():
              if ((not first) and (not ag in remove) and (not sel1[i])):
                remove.append(ag)
              i += 1 # same indexing as sel1 with this traverse of hierarchy
            first = False
          for ag in remove: # remove all the unwanted atom groups
            rg.remove_atom_group(atom_group=ag)

  return new_ph

class numbering_dict:
  ''' Set up a dict that keeps track of chain ID, residue ID and icode for
    residues relative to their initial values
    dict with keys of original residue chain ID, resseq, icode
    inverse_dict with keys of current, values of original
  '''
  def __init__(self, m):
    self.file_name = m.info().file_name
    self.ph = m.get_hierarchy().deep_copy()
    self.dd = self.get_dict(m) # keys are original, values current
    self.get_inverse_dict()  # keys are current, values original

  def show_summary(self):
    print("Summary of numbering dict for %s: " %(self.file_name))
    for model in self.ph.models():
      for chain in model.chains():
        for rg in chain.residue_groups():
          for conformer in rg.conformers():
            r = conformer.only_residue()
            key = self.get_key(r)
            print(key, self.original_key_from_current(key))

  def update(self, new_m):
    ''' Update the dicts to refer to new current model
    new_m must be similar hierarchy to previous current model
    '''
    new_dd = {}
    new_ph = new_m.get_hierarchy()
    ph = self.ph


    for new_model, model in zip(new_ph.models()[:1], ph.models()[:1]):
      for new_chain, chain in zip(new_model.chains(), model.chains()):
        for new_rg, rg in zip(new_chain.residue_groups(), chain.residue_groups()):
          for new_conformer, conformer in zip(
             new_rg.conformers(),
             rg.conformers()):
            new_r = new_conformer.only_residue()
            r = conformer.only_residue()

          new_key = self.get_key(new_r)
          key = self.get_key(r)
          original_key = self.original_key_from_current(key)
          new_dd[original_key] = new_key
    self.dd = new_dd
    self.ph = new_ph.deep_copy()
    self.get_inverse_dict()

  def get_original_key_list_from_atoms(self, atoms):
   original_key_list = []
   for key in self.get_key_list_from_atoms(atoms):
     original_key_list.append(self.original_key_from_current(key))
   return original_key_list

  def get_key_list_from_atoms(self, atoms):
    key_list = []
    for a in atoms:
      rg = a.parent().parent()
      for c in rg.conformers():
        r = c.only_residue()
        key_list.append(self.get_key(r))
    return key_list

  def add_from_other(self, other):
    for key in other.dd.keys():
      self.dd[key] = other.dd[key]
    self.get_inverse_dict()

  def get_key(self, r):
    conformer = r.parent()
    chain = conformer.parent()
    return "%s %s %s %s" %(r.resname, chain.id, r.resseq, r.icode)

  def current_key_from_current_r(self,r):
    return self.get_key(r)

  def original_key_from_current_r(self,r):
    key = self.get_key(r)
    return self.original_key_from_current(key)

  def original_key_from_current(self, key):
    return self.inverse_dict[key]

  def current_key_from_original(self, key):
    return self.dd[key]

  def get_inverse_dict(self):
    self.inverse_dict = {}
    for key in self.dd.keys():
      self.inverse_dict[self.dd[key]] = key

  def get_dict(self, m):
    dd = {}
    ph = m.get_hierarchy()
    for model in ph.models()[:1]:
      for chain in model.chains():
        for rg in chain.residue_groups():
          for conformer in rg.conformers():
            r = conformer.only_residue()
            key = self.get_key(r)
            dd[key] = key
    return dd

if __name__ == '__main__':
  import time
  l=0
  p=1
  for r in range(1,5):
    t0=time.time()
    rc = all_label_asym_ids(maximum_length=r)
    p*=26
    l+=p
    print('%7d %7d %7d %5s %0.3fs' % (l,p,len(rc), rc[-1], time.time()-t0))
    assert len(rc)==l


 *******************************************************************************


 *******************************************************************************
iotbx/pdb/web_service_api.py
"""
PDB web service API
"""

from __future__ import absolute_import, division, print_function

from iotbx.pdb.download import openurl, NotFound, identity_encoding


class RESTService(object):
  """
  Unified interface for services offering GET and POST requests
  """

  def __init__(self, url, get, post):

    self.url = url
    self.get = get
    self.post = post


  def single(self, identifier):

    return self.get( url = self.url, identifier = identifier )


  def multiple(self, identifiers):

    return self.post( url = self.url, identifiers = identifiers )


class FTPService(object):
  """
  Interface to access PDB files
  """

  def __init__(
    self,
    url,
    namer,
    postprocessing = identity_encoding(),
    opener = openurl,
    ):

    self.url = url
    self.namer = namer
    self.opener = opener
    self.postprocessing = postprocessing


  def single(self, identifier):

    stream = self.opener(
      url = ( self.url + self.namer( identifier = identifier ) ).encode(),
      )
    return self.postprocessing.process( stream = stream )


  def multiple(self, identifiers):

    for ident in identifiers:
      try:
        stream = self.single( identifier = ident )

      except NotFound:
        yield None

      else:
        yield stream


 *******************************************************************************


 *******************************************************************************
iotbx/pdb/xray_structure.py
"""Convert an xray_structure to PDB file format"""
from __future__ import absolute_import, division, print_function
import iotbx.pdb.hierarchy
from cctbx import adptbx
from six.moves import cStringIO as StringIO

def as_pdb_file(self,
      remark,
      remarks,
      fractional_coordinates,
      resname,
      connect):
  if (remark is not None):
    remarks.insert(0, remark)
  s = StringIO()
  for remark in remarks:
    print("REMARK", remark, file=s)
  print("REMARK Number of scatterers:", self.scatterers().size(), file=s)
  print("REMARK At special positions:", \
    self.special_position_indices().size(), file=s)
  if (fractional_coordinates):
    print("REMARK Fractional coordinates", file=s)
  else:
    print("REMARK Cartesian coordinates", file=s)
  print(iotbx.pdb.format_cryst1_record(crystal_symmetry=self), file=s)
  print(iotbx.pdb.format_scale_records(unit_cell=self.unit_cell()), file=s)
  atom = iotbx.pdb.hierarchy.atom_with_labels()
  if (resname is not None):
    atom.resname = resname.upper()
  serial = 0
  for scatterer in self.scatterers():
    serial += 1
    atom.serial = iotbx.pdb.hy36encode(width=5, value=serial)
    if (scatterer.flags.use_u_aniso_only()):
      atom.uij = adptbx.u_star_as_u_cart(self.unit_cell(), scatterer.u_star)
      atom.b = adptbx.u_as_b(adptbx.u_cart_as_u_iso(atom.uij))
    else:
      atom.uij_erase()
      atom.b = adptbx.u_as_b(scatterer.u_iso)
    if (fractional_coordinates):
      atom.xyz = scatterer.site
    else:
      atom.xyz = self.unit_cell().orthogonalize(scatterer.site)
    atom.occ = scatterer.occupancy
    label = scatterer.label.upper()
    atom.name = label[:4]
    if (resname is None):
      atom.resname = label[:3]
    element_symbol = scatterer.element_symbol()
    if (element_symbol is None): element_symbol = "Q"
    assert len(element_symbol) in (1,2)
    atom.element = element_symbol.upper()
    atom.resseq = iotbx.pdb.hy36encode(width=4, value=serial)
    print(atom.format_atom_record_group(), file=s)
  if (connect is not None):
    assert len(connect) == self.scatterers().size()
    i = 0
    for bonds in connect:
      i += 1
      l = "CONNECT%5d" % i
      for bond in bonds:
        l += "%5d" % (bond+1)
      print(l, file=s)
  print("END", file=s)
  return s.getvalue()


 *******************************************************************************
