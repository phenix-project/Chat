

 *******************************************************************************
libtbx/command_line/find_unused_imports.py
from __future__ import absolute_import, division, print_function
import os, fnmatch
from libtbx import python_code_parsing

def run(args):
  if not args: args = [ '.' ]
  work = set()
  arg_filenames = []
  for arg in args:
    if os.path.isdir(arg):
      for dirpath, dirnames, filenames in os.walk(arg):
        work.update( os.path.join(dirpath, f)
                     for f in fnmatch.filter(filenames, '*.py') )
    else:
      arg_filenames.append(arg)
  work.update(fnmatch.filter(arg_filenames, '*.py'))
  for filename in work:
    unused = python_code_parsing.unused_imports(
      python_source_filename=filename,
      ignored_imports=('libtbx.load_env',
                       'libtbx.forward_compatibility',
                       'import libtbx.start_print_trace',
                       'import libtbx.callbacks'),
      ignored_imports_from=('__future__',),
      ignore_imports_flagged_by_comments=('# import dependency',
                                          '# implicit import'))
    if unused:
      print('In file %s:' % filename)
      print(unused)
      print()


if __name__ == '__main__':
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/find_unused_imports_crude.py
from __future__ import absolute_import, division, print_function

import os
op = os.path

import re

# Finds flake8-style ignore directives
# Taken from flake8 source code
RE_FLAKE8 = re.compile(
    r"# noqa(?::[\s]?(?P<codes>([A-Z][0-9]+(?:[,\s]+)?)+))?",
    re.IGNORECASE,
)
# re for flake8 to split a string on spaces, commas
COMMA_SEPARATED_LIST_RE = re.compile(r"[,\s]")

def inspect(py_lines):
  imports_to_ignore = set([
    "from {0} import {1}",
    "import libtbx.forward_compatibility",
    "  import libtbx.start_print_trace",
    "    import libtbx.callbacks"])
  combined_lines = []
  block = []
  for line in py_lines:
    if (line in imports_to_ignore):
      continue
    l = line.strip()
    if (not l.endswith("\\")):
      block.append(l)
      combined_lines.append(" ".join(block))
      block = []
    else:
      block.append(l[:-1])
  if (len(block) != 0):
    combined_lines.append("".join(block))
  imported_names_dict = {}
  non_import_lines = []
  for l in combined_lines:
    def split():
      return l.replace(",", " , ").split()
    if (l.startswith("import ")):
      if (l.endswith(" # import dependency")):
        continue
      if (l.endswith(" # implicit import")):
        continue
      if (l.endswith(" # special import")):
        continue
      # Look for a flake8-style noqa line
      noqa = RE_FLAKE8.search(l)
      if noqa:
        if not noqa.group("codes"):
          # We have a blanket noqa
          continue
        # Split the codes, find if we are ignoring F401
        codes = [x.strip() for x in COMMA_SEPARATED_LIST_RE.split(noqa.group("codes"))]
        if "F401" in codes:
          continue
        # Not a valid ignore, but still have a comment - remove from the
        # import string so that we process correctly
        l = l[:noqa.start()].strip()
      flds = split()
    elif (l.startswith("from ")):
      if (l.endswith(" # import dependency")):
        continue
      if (l.endswith(" # implicit import")):
        continue
      if (l.endswith(" # special import")):
        continue
      # from _ import _ handling is rather broken, don't try to flake8 properly
      if "noqa" in l:
        continue
      if (l.startswith("from __future__ ")):
        continue
      flds = split()
      for i,fld in enumerate(flds):
        if (fld == "import"):
          flds = flds[i:]
          break
      else:
        continue
    else:
      non_import_lines.append(l)
      continue
    assert flds[0] == "import", flds
    flds = flds[1:]
    flds.append(",")
    #
    def collect(flds):
      if (len(flds) == 1):
        name = flds[0]
      elif (len(flds) == 3):
        name = flds[2]
      else:
        return
      if (name == "libtbx.load_env"):
        name = "env"
      else:
        name = name.split(".")[-1] # XXX very crude
      if (name != "*" and name not in imported_names_dict):
        imported_names_dict[name] = len(imported_names_dict)
    i = 0
    for j,fld in enumerate(flds):
      if (fld == ","):
        if (j > i):
          collect(flds[i:j])
        i = j+1
  idc = "_0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"
  imported_names = set(imported_names_dict.keys())
  imported_names.discard("(")
  used_names = set()
  for l in non_import_lines:
    filtered = []
    for c in l:
      if (idc.find(c) < 0):
        c = " "
      filtered.append(c)
    flds = "".join(filtered).split()
    used_names.update(imported_names.intersection(flds))
  unused_names = list(imported_names - used_names)
  unused_names.sort(key=lambda element: imported_names_dict[element])  # keeps import order
  return unused_names

def show_unused_imports(file_name):
  try:
    unused_imports = inspect(
      py_lines=open(file_name).read().splitlines())
    if (len(unused_imports) != 0):
      print("%s: %s" % (file_name, ", ".join(unused_imports)))
      print()
  except Exception as e:
    print('Could not parse file {}, possibly invalid character'.format(file_name))
    unused_imports = ['Failed to parse file']
  return unused_imports

def walk_func(counter, dirname, names):
  for name in names:
    if (not name.endswith(".py")):
      continue
    file_name = op.join(dirname, name)
    if (op.isfile(file_name)):
      if (len(show_unused_imports(file_name)) != 0):
        counter[0] += 1

def run(args):
  if (len(args) == 0):
    args = ["."]
  counter = [0]
  for arg in args:
    if (op.isdir(arg)):
      for root, dirs, files in os.walk(arg):
        walk_func(counter, root, files)
    elif (op.isfile(arg)):
      if (len(show_unused_imports(file_name=arg)) != 0):
        counter[0] += 1
  if (counter[0] != 0):
    print("""\
HINT:
  To suppress flagging of unused imports follow these examples:
    import scitbx.array_family.flex # import dependency
    import something.related # implicit import
    import wingdbstub # special import
""")
    return (1)
  return (0)

if (__name__ == "__main__"):
  import sys
  sys.exit(run(args=sys.argv[1:]))


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/git_avoid_merges.py
from __future__ import absolute_import, division, print_function
from libtbx.auto_build.bootstrap import Toolbox
import libtbx.easy_run
import libtbx.load_env
import os
import sys

what_is_this = '''

The command libtbx.git_avoid_merges identifies all module directories that are
git repositories (ie. it checks all paths listed by libtbx.show_dist_paths),
and changes the git settings of those repositories to 'rebase' by default
instead of creating merge commits. The global git settings are also changed
so any new git repositories are also set to 'rebase' by default.
Any existing settings are left as they are.

What does 'rebase' vs 'merge' mean?
A 'git pull' (without rebase setting or '--rebase' option) will silently
introduce a new commit, a so-called merge commit, if you and someone else have
committed anything since the last time you pulled. Invariably this will create
a lot of merge commits, going quite far back in history as well. Merge commits
will generally have a useless commit message, clutter the project history and
make it difficult to see what was going on. With our repositories the merge
commits will also cause pointless notification mail spam.

A 'rebase' will take your commits off the current tree and tack them back on to
the most recent commit. This results in a linear history.

Now there may be situations where you want to override this default policy.
You can do that by specifying --no-rebase on the command line, eg.:
   git pull --no-rebase

'''

def find_all_git_modules():
  for path in (abs(p) for p in libtbx.env.repository_paths):
    for entry in os.listdir(path):
      if not entry.startswith('.'):
        modulepath = os.path.join(path, entry)
        configfile = os.path.join(modulepath, '.git', 'config')
        if os.path.exists(configfile):
          yield (modulepath, configfile)

def mangle_git_repository(module, config):
  t = Toolbox()
  print("Git repository found:", module)
  t.set_git_repository_config_to_rebase(config)

def set_git_defaults_to_rebase():
  result = libtbx.easy_run.fully_buffered("git config --global --list")
  if result.return_code:
    '''Could not run git executable. Bail out.'''
    return

  expected = {
    'branch.autosetuprebase': 'always',
    'pull.rebase': 'true',
  }
  for line in result.stdout_lines:
    if '=' in line:
      name, value = line.split('=', 1)
      if name in expected:
        del(expected[name])
  if expected:
    print("Updating global git settings:")
    for attribute, value in expected.items():
      print("  %s = %s" % (attribute, value))
      libtbx.easy_run.fully_buffered("git config --global \"%s\" \"%s\"" % (attribute, value))

def run():
  for module, config in find_all_git_modules():
    mangle_git_repository(module, config)
  set_git_defaults_to_rebase()
  print("\nAll done.")

if __name__ == "__main__":
  if len(sys.argv) != 1:
    print(what_is_this)
  else:
    run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/help.py
from __future__ import absolute_import, division, print_function
# XXX This is a workaround for the Boost floating-point error that is
# triggered when importing numpy (used in a variety of modules in CCTBX).
# Importing Numpy before any of the boost extensions avoids a crash.
try :
  import numpy
except ImportError :
  pass
import pydoc

def run():
  pydoc.cli()

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/import_all_ext.py
from __future__ import absolute_import, division, print_function

"""
This tests the ability to import extension modules with two passes:
1) Imports all modules with __init__.py files which should implicitly import all extension modules
2) Discovers all extension modules available and imports them, which picks up any modules not imported by a __init__.py file
"""

def import_modules():
  # Search for __init__.py file and import those modules. This ensures all dependencies are loaded
  # prior to import individual so files
  import libtbx.load_env, os, traceback
  # Modules in the form of X/X/__init__.py
  doubled = ["elbow","phaser","phenix"]
  # These modules are dependencies not maintained by cctbx or should be skipped for other reasons
  skip_modules = ["boost","cbflib","crys3d","PyQuante","phenix_html","tntbx","reel",
                  "amber", # external
                  ]
  # These modules fail to import
  failing_modules = ["dials.framework.dftbx","dials.nexus"]
  # These modules can only import if Eigen is available
  ok_to_fail = ["scitbx.examples.bevington","cctbx.examples.merging","cctbx.examples.merging.samosa"]

  for root_module in libtbx.env.module_list:
    if root_module.name in skip_modules:
      continue
    root_path = libtbx.env.find_in_repositories(root_module.name)
    if root_path is None:
      continue
    if root_module.name in doubled:
      root_path = os.path.join(root_path, root_module.name)
    for dirpath, dirnames, filenames in os.walk(root_path):
      if "__init__.py" in filenames:
        full_module = root_module.name + ".".join(dirpath.split(root_path)[-1].split(os.path.sep))
        if full_module in failing_modules:
          continue
        print(full_module)
        try:
          exec("import %s" % full_module)
        except ImportError as e:
          if full_module not in ok_to_fail:
            print(traceback.format_exc())
            raise e

def run(args):
  assert len(args) == 0
  import_modules()
  import time
  t_start = time.time()
  from libtbx import introspection
  import os
  import sysconfig
  print("After script imports:")
  print("  wall clock time: %.2f" % (time.time() - t_start))
  print()
  mb = 1024 * 1024
  lib = os.path.join(
    os.environ["LIBTBX_BUILD"], # intentionally not using libtbx.env for speed
    "lib")
  ext_so = []
  for node in os.listdir(lib):
    pylibext = sysconfig.get_config_vars("SO")[0]
    if (node.endswith("_ext" + pylibext)):
      ext_so.append(node.split(".")[0])
  print("Before importing extensions:")
  vmi = introspection.virtual_memory_info()
  vmi.show(prefix="  ")
  prev_vms = vmi.get_bytes('VmSize:')
  prev_rss = vmi.get_bytes('VmRSS:')
  print("  wall clock time: %.2f" % (time.time() - t_start))
  print()
  for so in ext_so:
    t0 = time.time()
    exec("import %s" % so)
    vmi = introspection.virtual_memory_info()
    vms = vmi.get_bytes('VmSize:')
    rss = vmi.get_bytes('VmRSS:')
    if (vms is not None) : # won't work on Mac
      print("%.2f %3.0f %3.0f %s" % (
        time.time()-t0, (vms-prev_vms)/mb, (rss-prev_rss)/mb, so))
    else :
      assert (sys.platform in ["darwin", "win32"])
      print("%.2f %s" % (time.time()-t0, so))
    prev_vms = vms
    prev_rss = rss
  print()
  print("After importing all extensions:")
  introspection.virtual_memory_info().show(prefix="  ")
  print("  wall clock time: %.2f" % (time.time() - t_start))
  print()

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/import_all_python.py

from __future__ import absolute_import, division, print_function
import libtbx.load_env
from libtbx.utils import multi_out
from optparse import OptionParser
from six.moves import cStringIO as StringIO
import os.path as op
import os
import sys

# XXX these will be skipped (for various reasons)
ignore_modules = set([
  "libtbx.crossmingw",
  "libtbx.start_print_trace",   # produces lots of output
  "libtbx.command_line.epydoc_run",
  "libtbx.command_line.ipython_shell_start",
  "mmtbx.pdb_distances",        # too much executed code
  "gltbx.wx_viewer_leapmotion", # crashes if Leap installed
  # non-CCTBX modules
  "PyQuante.ThomasFermi",       # uses reserved keyword 'with'
  "elbow.example_script",
  "phenix_regression",
  "phenix_dev",
  "phenix.autosol.bayes_5",     # too much executed code
])

def has_init_py(path_name):
  for file_name in os.listdir(path_name):
    if (file_name == "__init__.py"):
      return True
  return False

def split_all(path_name):
  paths = []
  while True :
    leading_path, dir_name = op.split(path_name)
    if (dir_name != ''):
      paths.append(dir_name)
      path_name = leading_path
    else :
      break
  paths.reverse()
  return paths

def run(args):
  verbose = False
  parser = OptionParser()
  parser.add_option("-v", "--verbose", dest="verbose", action="store_true",
    help="Turn on verbose output")
  parser.add_option("--skip-tests", dest="skip_tests", action="store_true",
    help="Don't import modules beginning with 'tst'")
  options, args = parser.parse_args(args)
  module_list = []
  if (len(args) == 0):
    module_list.extend([ m.name for m in libtbx.env.module_list ])
  else :
    for arg in args :
      assert (arg in libtbx.env.module_dict), arg
      module_list.append(arg)
  has_stdout = []
  stdout_old = sys.stdout
  for module_name in module_list :
    if (module_name in ignore_modules):
      continue
    try :
      module = __import__(module_name)
    except ImportError as e:
      print(e, file=sys.stderr)
      continue
    assert len(module.__path__) == 1
    mod_path = module.__path__[0]
    path_fields = split_all(mod_path)
    n_leading_dirs = len(path_fields) - 1
    for dirname, dirnames, filenames in os.walk(mod_path):
      for file_name in filenames :
        if file_name.endswith(".py") and (file_name != "libtbx_refresh.py"):
          py_mod_name, ext = op.splitext(file_name)
          if (ext != '.py') or ("." in py_mod_name):
            if (options.verbose):
              print("skipping %s" % file_name, file=sys.stderr)
            continue
          py_path = split_all(dirname)[n_leading_dirs:]
          import_name = ".".join(py_path)
          if (not has_init_py(dirname)) or (import_name in ignore_modules):
            continue
          top_level_module = py_path[0]
          if (file_name != "__init__.py"):
            import_name += "." + file_name[:-3]
          if (import_name in ignore_modules):
            continue
          elif ((file_name.startswith("tst_") or file_name.startswith("test_"))
                and options.skip_tests):
            continue
          if (options.verbose):
            print(import_name)
          try :
            sys.stdout = multi_out()
            sys.stdout.register("stdout", stdout_old)
            out = StringIO()
            sys.stdout.register("stringio", out)
            submodule = __import__(import_name)
            if (out.getvalue() != ''):
              has_stdout.append(import_name)
              if (options.verbose):
                print(out.getvalue(), file=sys.stderr)
          except ImportError as e :
            print(e, file=sys.stderr)
          finally :
            sys.stdout = stdout_old
  print("")
  print("*" * 80)
  print("ALL MODULES IMPORTED SUCCESSFULLY")
  print("*" * 80)
  print("")
  if (len(has_stdout) > 0):
    print("Warning: %d modules print to stdout on import" % \
      len(has_stdout), file=sys.stderr)
    for import_name in has_stdout :
      print(import_name, file=sys.stderr)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/install.py
from __future__ import absolute_import, division, print_function

import collections
import errno
import glob
import os
import shutil
import subprocess
import sys
from optparse import SUPPRESS_HELP, OptionParser
from six.moves import range

import libtbx.load_env
from libtbx.auto_build.bootstrap import Toolbox

# Basically 'pip' for selected libtbx/cctbx modules.

class EpilogParser(OptionParser):
  """Simple, small OptionParser subclass to not strip epilog"""
  def format_epilog(self, formatter):
    """Don't strip newlines from this"""
    return self.epilog

def is_source_repository(path):
  return (path / '.git').isdir() or (path / '.svn').isdir()

def run(args):
  # Generate an epilog message
  possible_installs = "\nAvailable Packages:\n    " + "\n    ".join(
    x for x in sorted(warehouse.keys())
  ) + "\n"
  parser = EpilogParser(usage="libtbx.install [package]",
                        description="Installs an additional cctbx package.",
                        epilog=possible_installs)
  parser.add_option("-?", action="help", help=SUPPRESS_HELP)
  options, args = parser.parse_args(args)

  modules_directory = list(filter(lambda dir: not is_source_repository(dir), libtbx.env.repository_paths))
  if not modules_directory:
    sys.exit("No repository path candidate found. Can't install modules without an installation root.")
  if len(modules_directory) > 1:
    print("More than one repository path candidate found.")
  installation_root = modules_directory[0]
  print("Using %s as installation root" % abs(installation_root))

  packages_to_configure = set()

  errors = False
  for package in args:
    if package not in warehouse:
      print("Skipping package %s: Never heard of this before" % package)
      errors = True
      continue
    if (installation_root / package).isdir() and glob.glob(abs(installation_root / package / "*")):
      print("Skipping download of package %s: Non-empty directory already exists in installation root" % package)
      if package not in libtbx.env.module_dict and warehouse[package].get('configure', True):
        packages_to_configure.add(package)
      if warehouse[package].get('force-configure'):
        packages_to_configure.add('libtbx')
      continue

    downloaded = False
    try:
      os.makedirs(abs(installation_root / package))
    except OSError as exc:
      if exc.errno == errno.EEXIST and (installation_root / package).isdir():
        pass
      else:
        raise
    for mech, call in mechanisms.items():
      if mech in warehouse[package]:
        print("Attempting to obtain %s using %s..." % (package, mech), end='')
        sys.stdout.flush()
        if call(package=package,
                location=abs(installation_root / package),
                source=warehouse[package][mech]):
          assert (installation_root / package).isdir(), "Installation failed"
          downloaded = True
          print("success")
          break
        else:
          assert not (installation_root / package).isdir(), "Install mechanism %s did not fail cleanly" % mech
          print("failed")
    if not downloaded:
      print("Skipping package %s: Could not install" % package)
      errors = True
      continue

    if warehouse[package].get('configure', True):
      packages_to_configure.add(package)
    if warehouse[package].get('force-configure'):
      packages_to_configure.add('libtbx')

  if packages_to_configure:
    packages_to_configure = sorted(packages_to_configure)
    print("Configuring package[s] %s..." % ", ".join(packages_to_configure))

    proc = subprocess.Popen(['libtbx.configure'] + packages_to_configure,
      stdout=subprocess.PIPE, stderr=subprocess.PIPE,
      cwd=abs(libtbx.env.build_path)
      )
    out, err = proc.communicate()
    if err:
      errors = True
      print(out.decode())
      print(err.decode())
      print("Configuration failed. Run 'libtbx.configure %s' "
            "once underlying problem solved, then 'make'"
            % " ".join(packages_to_configure))
    else:
      proc = subprocess.Popen(['make'],
        stdout=subprocess.PIPE, stderr=subprocess.PIPE,
        cwd=abs(libtbx.env.build_path)
        )
      out, err = proc.communicate()
      if err:
        errors = True
  if errors:
    sys.exit(1)

def install_git(**kwargs):
  reference = []
  if os.name == 'posix':
    reference_repository_path = os.path.join('/dls/science/groups/scisoft/DIALS/repositories/git-reference', kwargs['package'])
    if os.path.isdir(reference_repository_path):
      reference = ['--reference', reference_repository_path]
      print("using reference repository...", end="")
      sys.stdout.flush()
  try:
    proc = subprocess.Popen(['git', 'clone', '--recursive', kwargs['source'], kwargs['location']] + reference,
      stdout=subprocess.PIPE, stderr=subprocess.PIPE,
      )
    out, err = proc.communicate()
    if err:
      if os.path.exists(kwargs['location']) and not os.listdir(kwargs['location']):
        # git-auth can leave an empty directory behind
        os.rmdir(kwargs['location'])
      return False
    if reference:
      proc = subprocess.Popen(['git', 'repack', '-a', '-d'],
        stdout=subprocess.PIPE, stderr=subprocess.PIPE,
        cwd=kwargs['location']
        )
      out, err = proc.communicate()
      print(out.decode())
      assert proc.returncode == 0, "Repack operation failed. Delete repository and try again."
      os.remove(os.path.join(kwargs['location'], '.git', 'objects', 'info', 'alternates'))
    Toolbox.set_git_repository_config_to_rebase(os.path.join(kwargs['location'], '.git', 'config'))
    return True
  except OSError:
    if os.path.isdir(kwargs['location']):
      shutil.rmtree(kwargs['location'])
    return False # git may not be installed

def install_tgz(**kwargs):
  location = kwargs['location']
  source = kwargs['source']
  tempfile = os.path.join(location, '.tmp.tgz')
  etagfile = os.path.join(location, '..tmp.tgz.etag')
  def cleanup():
    try: os.remove(tempfile)
    except OSError: pass
    try: os.remove(etagfile)
    except OSError: pass
    try: os.rmdir(location)
    except OSError: pass
  if Toolbox.download_to_file(source['url'], tempfile) <= 0:
    cleanup()
    return False
  import tarfile
  with tarfile.open(tempfile, 'r') as fh:
    for t in range(source.get('trim', 0)):
      location = os.path.dirname(location)
    fh.extractall(location)
  cleanup()
  return True

def install_zip(**kwargs):
  location = kwargs['location']
  source = kwargs['source']
  tempfile = os.path.join(location, '.tmp.zip')
  etagfile = os.path.join(location, '..tmp.zip.etag')
  def cleanup():
    try: os.remove(tempfile)
    except OSError: pass
    try: os.remove(etagfile)
    except OSError: pass
    try: os.rmdir(location)
    except OSError: pass
  if Toolbox.download_to_file(source['url'], tempfile) <= 0:
    cleanup()
    return False
  Toolbox.unzip(tempfile, location, trim_directory=source.get('trim', 0))
  cleanup()
  return True

def install_pip(**kwargs):
  git_installation = install_git(**kwargs)
  if not git_installation:
    return False
  proc = subprocess.Popen(['libtbx.pip', 'install', '-e', kwargs['location']],
    stdout=subprocess.PIPE, stderr=subprocess.PIPE,
    )
  out, err = proc.communicate()
  print(out.decode())
  if err:
    return False
  return True

mechanisms = collections.OrderedDict((
  ('git-auth', install_git),
  ('git-anon', install_git),
  ('http-zip', install_zip),
  ('http-tgz', install_tgz),
  ('pip-auth', install_pip),
  ('pip-anon', install_pip),
))

warehouse = {
  'dials_scratch': {
    'git-auth': 'git@github.com:/dials/dials_scratch',
    'git-anon': 'https://github.com/dials/dials_scratch.git',
    'http-zip': { 'url': 'https://github.com/dials/dials_scratch/archive/master.zip', 'trim': 1 },
  },
  'dlstbx': {
    'git-auth': 'git@github.com:/DiamondLightSource/python-dlstbx.git',
  },
  'dxtbx': {
    'git-auth': 'git@github.com:cctbx/dxtbx',
    'git-anon': 'https://github.com/cctbx/dxtbx.git',
    'http-zip': { 'url': 'https://github.com/cctbx/dxtbx/archive/main.zip', 'trim': 1 },
  },
  'fast_dp': {
    'pip-auth': 'git@github.com:/DiamondLightSource/fast_dp',
    'pip-anon': 'https://github.com/DiamondLightSource/fast_dp.git',
    'configure': False,
    'force-configure': True,
  },
  "iota": {
    'pip-auth': 'git@github.com:/ssrl-px/iota',
    'pip-anon': 'https://github.com/ssrl-px/iota.git',
    'configure': False,
    'force-configure': True,
  },
  'screen19': {
    'pip-auth': 'git@github.com:/xia2/screen19',
    'pip-anon': 'https://github.com/xia2/screen19.git',
    'configure': False,
    'force-configure': True,
  },
  'msgpack': {
    'http-tgz': { 'url': 'https://gitcdn.link/repo/dials/dependencies/dials-1.13/msgpack-3.1.1.tar.gz', 'trim': 1 },
    'configure': False,
  },
}

if __name__ == '__main__':
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/install_conda.py
from __future__ import absolute_import, division, print_function

import libtbx.auto_build.install_conda

if __name__ == '__main__':
  libtbx.auto_build.install_conda.run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/ipython_shell_start.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME libtbx.ipython
import re
import sys

from IPython import start_ipython

if __name__ == '__main__':
      sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
      sys.exit(start_ipython())



 *******************************************************************************


 *******************************************************************************
libtbx/command_line/line_count.py
from __future__ import absolute_import, division, print_function
import sys, os
import re
import libtbx.load_env

boost_python_include_pat = re.compile(r"#include\s*<boost(?:/|_)python");

def run(modules):
  directory_paths = [ libtbx.env.dist_path(m) for m in modules ]
  line_counts_in_files_of_type = {}
  for d in directory_paths:
    for root, dirs, files in os.walk(d):
      for f in files:
        if f.startswith('.'): continue
        _, ext = os.path.splitext(f)
        if ext in ('.pyo', '.pyc'): continue
        boost_python_binding = False
        n_lines = 0
        with open(os.path.join(root,f)) as fo:
          for li in fo:
            n_lines += 1
            if (not boost_python_binding
                and boost_python_include_pat.search(li)):
              boost_python_binding = True
        if boost_python_binding:
          file_type = "Boost.Python"
        elif not ext:
          file_type = "unknown"
        else:
          file_type = ext[1:]
        line_counts_in_files_of_type.setdefault(file_type, []).append(n_lines)
  print("Lines of code in %s" % ', '.join(modules))
  print("%-15s%8s" % ('extension', '#lines'))
  output = []
  for file_type, line_counts in line_counts_in_files_of_type.items():
    cnt = sum(line_counts)
    output.append((cnt, "%-15s%8d" % (file_type, cnt)))
  output.sort(reverse=True)
  output = [ entry[1] for entry in output ]
  print('\n'.join(output))


if __name__ == '__main__':
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/list_files.py
from __future__ import absolute_import, division, print_function
from libtbx.utils import detect_binary_file
from libtbx.path import walk_source_tree
from libtbx.option_parser import option_parser
from libtbx.str_utils import show_string
import sys, os

def show_status(path, text, binary, quote):
  def show():
    if (quote): print(show_string(path))
    else: print(path)
  if (text and binary):
    show()
  else:
    status = detect_binary_file.from_initial_block(file_name=path)
    if (status is None or status is binary):
      show()

def run(args, command_name="libtbx.list_files"):
  if (len(args) == 0): args = ["."]
  command_line = (option_parser(
    usage="%s [options] path ..." % command_name,
    description="Recursively lists all files,"
      " excluding CVS and .svn directories and .pyc files.")
    .option("-t", "--text",
      action="store_true",
      default=False,
      help="list text files only")
    .option("-b", "--binary",
      action="store_true",
      default=False,
      help="list binary files only")
    .option("-q", "--quote",
      action="store_true",
      default=False,
      help="quote file names")
  ).process(args=args)
  paths = command_line.args
  co = command_line.options
  text = co.text
  binary = co.binary
  quote = co.quote
  if (not (text or binary)):
    binary = True
    text = True
  if (len(paths) == 0): paths = ["."]
  for path in paths:
    if (not os.path.exists(path)):
      print("No such file or directory:", path, file=sys.stderr)
    elif (os.path.isfile(path)):
      show_status(path=path, text=text, binary=binary, quote=quote)
    else:
      for file_path in walk_source_tree(top=path):
        show_status(path=file_path, text=text, binary=binary, quote=quote)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/list_modules.py

from __future__ import absolute_import, division, print_function

def run():
  import libtbx.load_env # import dependency
  for module in libtbx.env.module_list :
    print(module.name)

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/list_source_files_sorted_by_size.py
from __future__ import absolute_import, division, print_function
def run(args):
  if (len(args) == 0): args = ["."]
  from libtbx.math_utils import iround
  import libtbx.str_utils
  import libtbx.path
  import os
  op = os.path
  file_names = []
  for arg in args:
    if (op.isfile(arg)):
      file_names.append(top)
    elif (op.isdir(arg)):
      file_names.extend(libtbx.path.walk_source_tree(top=arg))
  contents = []
  sz_ln_fn_ext = []
  for fn in file_names:
    i = fn.rfind(".")
    if (i < 0):
      continue
    ext = fn[i+1:]
    if (ext in ["c", "h", "cpp", "hpp", "py", "java", "f", "sh", "csh", "bat"]):
      content = open(fn, "rb").read()
      contents.append(content)
      sz_ln_fn_ext.append((len(content), len(content.splitlines()), fn, ext))
  sz_ln_fn_ext.sort()
  sz_sum = 0
  ln_sum = 0
  ext_counts = libtbx.dict_with_default_0()
  for sz,ln,fn,ext in sz_ln_fn_ext:
    print("%10d %6d %s" % (sz,ln,fn))
    sz_sum += sz
    ln_sum += ln
    ext_counts[ext] += 1
  print()
  print("Number of files by extension:")
  libtbx.str_utils.show_sorted_by_counts(
    label_count_pairs=list(ext_counts.items()),
    prefix="  ")
  print()
  n = len(sz_ln_fn_ext)
  print("Number of files:", n)
  print("Number of lines:", ln_sum)
  if (n != 0):
    print("Sum of sizes:", sz_sum, "(mean: %d, median: %d)" % (
      iround(sz_sum/n), sz_ln_fn_ext[n//2][0]))
    import zlib
    print("Size of all files together zlib.compress'ed:", \
      len(zlib.compress(b"".join(contents))))
  print()

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/make_dist.py

"""
Master script for making distributable installers on Linux and Mac.
"""

from __future__ import absolute_import, division, print_function
from libtbx.auto_build.installer_utils import *
from libtbx.auto_build import setup_installer
from libtbx.auto_build import create_mac_pkg
from libtbx.auto_build import make_bundle
import libtbx.phil.command_line
import libtbx.load_env
from optparse import OptionParser
import shutil
import os.path as op
import time
import os
import sys

master_phil_str = """
package_name = CCTBX
  .type = str
pkg_prefix = cctbx
  .type = str
hide_mac_package_contents = False
  .type = bool
installer_script = cctbx_project/libtbx/auto_build/plus_installer.py
  .type = path
license = cctbx_project/libtbx/LICENSE_2_0.txt
  .type = path
background = None
  .type = path
bin_dir = None
  .type = path
readme = None
  .type = path
  .multiple = True
source_module = None
  .type = str
  .multiple = True
base_module = None
  .type = str
  .multiple = True
exclude_module = None
  .type = str
  .multiple = True
organization = gov.lbl.cci
  .type = str
"""

def full_path(path_name):
  if op.isabs(path_name):
    return path_name
  else :
    path_name_ = libtbx.env.find_in_repositories(
      relative_path=path_name,
      test=op.isfile)
    if (path_name_ is None):
      raise RuntimeError("Can't find path %s" % path_name)
    return path_name_

def run(args):
  parser = OptionParser()
  parser.add_option("--tmp-dir", dest="tmp_dir", action="store",
    help="Temporary directory for assembling packages", default=None)
  parser.add_option("--dist-dir", dest="dist_dir", action="store",
    help="Distribution directory", default=None)
  parser.add_option("--debug", dest="debug", action="store_true")
  parser.add_option("--mtype", dest="mtype", action="store",
    help="Architecture type", default=machine_type())
  parser.add_option("--host-tag", dest="host_tag", action="store",
    help="Host tag (OS/distribution label)", default=None)
  parser.add_option("--version", dest="version", action="store",
    help="Package version",
    default=time.strftime("%Y_%m_%d", time.localtime()))
  parser.add_option("--remove_src", dest="remove_src")
  parser.add_option("--no-pkg", dest="no_pkg", action="store_true",
    help="Disable Mac graphical (.pkg) installer")
  parser.add_option("--make-app", dest="make_apps", action="append",
    help="App bundle to create")
  # TODO installer background?
  options, args = parser.parse_args(args)
  if (len(args) == 0):
    # XXX defaults for CCTBX installer if no parameter file specified
    args = [
      "source_module=cbflib",
      "source_module=annlib",
      "source_module=cbflib_adaptbx",
      "exclude_module=phenix_regression",
      "exclude_module=phenix_dev",
      "exclude_module=chem_data",
    ]
  phil_cmdline = libtbx.phil.command_line.process(
    args=args,
    master_string=master_phil_str)
  params = phil_cmdline.work.extract()
  print("This will be %s-%s" % (params.package_name, options.version))
  root_dir = op.dirname(op.dirname(libtbx.env.find_in_repositories(
    relative_path="cctbx_project",
    test=op.isdir)))
  print("Root directory is %s" % root_dir)
  modules_dir = op.join(root_dir, "modules")
  build_dir = op.join(root_dir, "build")
  base_dir = op.join(root_dir, "base")
  if (not (op.isdir(modules_dir) and op.isdir(build_dir) and
           op.isdir(base_dir))):
    raise RuntimeError(
      "Expected 'modules', 'build', and 'base' in root directory")

  if (options.dist_dir is None):
    options.dist_dir = op.join(root_dir, "dist", options.version)
  if (not op.isdir(options.dist_dir)):
    os.makedirs(options.dist_dir)
  print("Distribution directory is %s" % options.dist_dir)

  if (options.tmp_dir is None):
    options.tmp_dir = op.join(root_dir, "tmp")
  if (not op.isdir(options.tmp_dir)):
    os.makedirs(options.tmp_dir)
  print("Temporary directory is %s" % options.tmp_dir)

  os.chdir(options.tmp_dir)
  installer_dir = "%s-installer-%s" % (params.pkg_prefix, options.version)
  if op.exists(installer_dir):
    shutil.rmtree(installer_dir)
  tar_prefix = installer_dir
  suffix = ""
  if (options.host_tag is not None):
    suffix = options.host_tag
  else :
    suffix = options.mtype

  #############################
  # Run setup_installer.py
  setup_args = [
    "--version=%s" % options.version,
    "--binary",
    "--script=%s"%full_path(params.installer_script),
    "--pkg_dir=%s" % modules_dir,
  ]
  if (len(params.readme) > 0):
    for readme in params.readme :
      setup_args.append("--readme=%s" % full_path(readme))
  if (len(params.base_module) > 0):
    setup_args.append("--base-modules=%s" % ",".join(params.base_module))
  if (params.license):
    setup_args.append("--license=%s" % full_path(params.license))
  print("Arguments for setup_installer.py:")
  for arg_ in setup_args :
    print("  %s" % arg_)
  setup_installer.run(args=setup_args + [ params.pkg_prefix ])
  print("setup_installer.py done.")

  #############################
  # Bundle
  os.chdir(options.tmp_dir)
  assert op.isdir(installer_dir), installer_dir
  bundle_dir = op.join(options.tmp_dir, installer_dir, "bundles")
  os.mkdir(bundle_dir)
  # create bundles of base, build, and module directories
  bundle_args = [
    "--dest=%s" % bundle_dir,
    "--version=%s" % options.version,
    #"--verbose",
  ]
  if (len(params.exclude_module) > 0):
    for module in params.exclude_module :
      bundle_args.append("--ignore=%s" % module)
  if (len(params.base_module) > 0):
    for module in params.base_module :
      bundle_args.append("--ignore=%s" % module)
  print("Arguments for make_bundle.py:")
  for arg_ in bundle_args :
    print("  %s" % arg_)
  make_bundle.run(args=bundle_args + [ root_dir ])
  print("make_bundle.py done.")

  #############################
  # package the entire mess into the complete installer
  find_and_delete_files(installer_dir, file_ext=".pyc")
  os.chdir(options.tmp_dir)
  installer_tar = os.path.join(options.dist_dir, '%s-%s.tar.gz'%(installer_dir, suffix))
  call("tar czf %s %s" % (installer_tar, installer_dir))
  print("Wrote %s" % installer_tar)

  #############################
  # Mac .pkg creation
  os.chdir(options.tmp_dir)
  if (sys.platform == "darwin") and (not getattr(options, "no_pkg", False)):
    if (not os.access("/Applications", os.W_OK|os.X_OK)):
      print("Can't access /Applications - skipping .pkg build")
    else :
      os.chdir(installer_dir)
      pkg_prefix = "/Applications"
      app_root_dir = pkg_prefix + "/" + "%s-%s" % (params.pkg_prefix,
        options.version)

      print("Removing existing Applications directory:", app_root_dir)
      try:
        shutil.rmtree(app_root_dir)
      except Exception as e:
        print(e)

      print("hide_mac_package_contents?", params.hide_mac_package_contents)
      if params.hide_mac_package_contents :
        app_root_dir = "/Applications/%s-%s"%(params.package_name,
          options.version)
        pkg_prefix = app_root_dir + "/Contents"
        try: os.makedirs(pkg_prefix)
        except Exception: pass

      call("./install --prefix=%s --compact --no-app" % pkg_prefix)
      install_dir = "%s/%s-%s" % (pkg_prefix,params.pkg_prefix,options.version)

      # generate .app launchers
      if (options.make_apps):
        exe_path = "%s/build/bin/libtbx.create_mac_app" % install_dir
        apps_log = open("py2app.log", "w")
        for app_name in options.make_apps :
          app_args = [
            exe_path,
            "--app_name=%s-%s" % (app_name, options.version),
            "--python_interpreter=/usr/bin/python",
            "--dest=%s" % app_root_dir,
            app_name,
          ]
          call(" ".join(app_args), log=apps_log)

      # Copy env.* files to top-level directory
      if params.hide_mac_package_contents :
        for file_name in os.listdir(install_dir):
          if file_name.endswith("_env.csh") or file_name.endswith("_env.sh"):
            copy_file(op.join(install_dir, file_name),
                      op.join(app_root_dir, file_name))
        docs_dir = op.join(install_dir, "doc")
        if op.isdir(docs_dir):
          shutil.copytree(docs_dir, op.join(app_root_dir, "doc"))

      create_mac_pkg.run(args=[
        "--package_name=%s" % params.package_name,
        "--version=%s" % options.version,
        "--license=%s" % full_path(params.license),
        "--organization=%s" % params.organization,
        "--machine_type=%s" % suffix,
        "--dist-dir=%s"%options.dist_dir,
        app_root_dir,
      ])

  return 0

if (__name__ == "__main__"):
  sys.exit(run(sys.argv[1:]))


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/make_sphinx_html.py

from __future__ import absolute_import, division, print_function
from libtbx import easy_run
import libtbx.load_env
import os.path as op
import shutil
import os

if (__name__ == "__main__"):
  cctbx_base = libtbx.env.find_in_repositories("cctbx_project")
  assert (cctbx_base is not None)
  base_dir = op.dirname(cctbx_base)
  dest_dir = op.join(base_dir, "cctbx_docs")
  if op.exists(dest_dir):
    shutil.rmtree(dest_dir)
  os.chdir(op.join(cctbx_base, "sphinx"))
  easy_run.call("make html")
  shutil.move("build/html", dest_dir)


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/nequal.py
from __future__ import absolute_import, division, print_function
from operator import itemgetter
from libtbx.utils import Usage
import fileinput
import sys, os

def run(command_name=os.environ.get(
          "LIBTBX_DISPATCHER_NAME", "libtbx.nequal")):
  if (sys.argv[1:] in [["-h"], ["--help"]]):
    raise Usage("%s [file ...]" % command_name + """
  Similar to the Unix uniq command, but each output line is
  prefixed with the number of identical consecutive lines.
  Example command:
    grep Warning log_file | sort | %s
  Example output:
    12: Warning: missing file'
     9: Warning: missing directory'
     1: Warning: unknown file
    Number of lines shown: 3
    Sum of counts: 22""" % command_name)
  buffer = []
  prev = None
  n = 0
  for line in fileinput.input():
    if (prev is None):
      prev = line
      n = 1
    elif (line != prev):
      buffer.append((n, prev))
      prev = line
      n = 1
    else:
      n += 1
  if (n != 0):
    buffer.append((n, prev))
  if (len(buffer) != 0):
    buffer.sort(key=itemgetter(0,1))
    sum_n = 0
    n_fmt = "%%%dd: " % len("%d" % buffer[0][0])
    for n,line in buffer:
      sys.stdout.write(n_fmt % n + line)
      sum_n += n
    print("Number of lines shown:", len(buffer))
    print("Sum of counts:", sum_n)

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/parallel_simple.py
from __future__ import absolute_import, division, print_function
import re
import time
import sys, os
from six.moves import range
op = os.path

def show_traceback(file):
  import traceback
  print(file=file)
  traceback.print_exc(file=file)
  print(file=file)

def fmt_time(t0):
  return "JOB wall clock time: %.2f s" % (time.time() - t0)

def process_dollar_multi(line):
  pat = "$(MULTI:"
  i = line.find(pat)
  if (i < 0): return [line]
  j = line.find(")", i)
  if (j < i): return [line]
  flds = line[i+len(pat):j].split(",")
  j += 1
  if (len(flds) == 0): return [line]
  result = []
  def rapp(a):
    result.append(line[:i] + str(a) + line[j:])
  for fld in flds:
    fld = op.expandvars(fld)
    m = re.match(r"(\d+)([-:])(\d+)$", fld)
    if (m is None):
      rapp(fld)
    else:
      f = int(m.group(1))
      o =     m.group(2)
      l = int(m.group(3))
      s = [1,-1][int(f > l)]
      if (o == "-"): l += s
      for a in range(f,l,s):
        rapp(a)
  return result

def run_one_cmd(cmd_info):
  t0 = time.time()
  from libtbx import easy_run
  if (cmd_info.index == 0):
    print("command:", cmd_info.cmd)
    sys.stdout.flush()
    try:
      easy_run.call(command=cmd_info.cmd)
    except: # intentional
      show_traceback(file=sys.stdout)
    print(fmt_time(t0))
    print()
  else:
    sys.stdout.flush()
    sio = None
    try:
      buffers = easy_run.fully_buffered(
        command=cmd_info.cmd,
        join_stdout_stderr=True,
        stdout_splitlines=False)
    except: # intentional
      from six.moves import cStringIO as StringIO
      sio = StringIO()
      show_traceback(file=sio)
      buffers = None
    f = open(cmd_info.log, "w")
    if (buffers is not None):
      f.write(buffers.stdout_buffer)
    if (sio is not None):
      f.write(sio.getvalue())
    print(fmt_time(t0), file=f)
    del f
  sys.stdout.flush()

def run_in_dir(cmd_info):
  cwd_on_entry = os.getcwd()
  try:
    d = op.dirname(cmd_info.log)
    os.mkdir(d)
    os.chdir(d)
    from libtbx.command_line import printenv
    printenv.show(out=open("os_environ_at_start", "w"))
    import subprocess
    log = open("log", "w")
    t0 = time.time()
    try:
      subprocess.Popen(
        args=cmd_info.cmd,
        shell=True,
        bufsize=-1,
        stdout=log,
        stderr=log,
        universal_newlines=True).wait()
    except: # intentional
      show_traceback(file=log)
    print(fmt_time(t0), file=log)
    sys.stdout.flush()
  finally:
    if (op.isdir(cwd_on_entry)):
      os.chdir(cwd_on_entry)

def run(args):
  if (len(args) == 0): args = ["--help"]
  import libtbx.load_env
  from libtbx.option_parser import option_parser
  command_line = (option_parser(
    usage="%s [options] [var=value] [...] [file_listing_commands] [...]"
      % libtbx.env.dispatcher_name)
    .option(None, "--dirs",
      action="store",
      type="str",
      help="create a sub-directory for each run.")
    .option(None, "--force_clean_dirs",
      action="store_true",
      help="forces removal of existing directories before creation.")
    .option(None, "--command",
      action="append",
      type="str",
      help="command to be executed, e.g. 'echo $(MULTI:1-4)'")
    .option("-j", "--jobs",
      action="store",
      type="int",
      help="maximum number of parallel jobs (default: all CPUs).")
  ).process(args=args)
  co = command_line.options
  #
  from libtbx import easy_mp
  import libtbx.introspection
  import libtbx.utils
  from libtbx.utils import Sorry
  from libtbx.str_utils import show_string
  #
  files_listing_commands = []
  for arg in command_line.args:
    earg = op.expandvars(arg)
    flds = earg.split("=", 1)
    if (len(flds) != 2):
      files_listing_commands.append(earg)
    else:
      k,v = flds
      os.environ[k] = v
  #
  cmd_infos = []
  def cmd_infos_append(line):
    for l in process_dollar_multi(line):
      index = len(cmd_infos)
      cmd_infos.append(libtbx.group_args(index=index, cmd=l, log=None))
  if (co.command is not None):
    for line in co.command:
      cmd_infos_append(line=line)
  for file_name in files_listing_commands:
    file_dir = op.dirname(file_name)
    for line in open(file_name).read().splitlines():
      ll = line.lstrip()
      if (ll.startswith("#")): continue
      if (ll.startswith("set ")): continue
      if (ll.startswith("setenv ")):
        flds = ll.split(None, 2)
        if (len(flds) == 2): flds.append("")
        os.environ[flds[1]] = flds[2]
        continue
      cmd_infos_append(line=line.replace("$(DIRNAME)", file_dir))
  n_proc = min(len(cmd_infos), libtbx.introspection.number_of_processors())
  if (co.jobs is not None):
    n_proc = max(1, min(co.jobs, n_proc))
  print("Number of processors:", n_proc)
  print("Number of jobs:", len(cmd_infos))
  print()
  sys.stdout.flush()
  show_times = libtbx.utils.show_times(time_start="now")
  def show_log(cmd_info):
    need_log = (cmd_info.index != 0 or co.dirs is not None)
    if (cmd_info.log is None):
      if (need_log):
        print("MISSING: output of command with index %03d:" % cmd_info.index)
        print("  %s" % cmd_info.cmd)
    elif (not op.isfile(cmd_info.log)):
      if (need_log):
        print("MISSING:", cmd_info.log)
    else:
      lines = open(cmd_info.log).read().splitlines()
      if (len(lines) > 10):
        print("@BEGIN")
      if (len(lines) != 0):
        print("\n".join(lines))
      if (len(lines) > 10):
        print("@END")
  def show_logs():
    for cmd_info in cmd_infos:
      if (cmd_info.index == 0 and co.dirs is None): continue
      print("command:", cmd_info.cmd)
      show_log(cmd_info=cmd_info)
  if (co.dirs is None):
    for cmd_info in cmd_infos:
      cmd_info.log = "log%03d" % cmd_info.index
      libtbx.utils.remove_files(cmd_info.log)
    if (n_proc < 2):
      for cmd_info in cmd_infos:
        print("command:", cmd_info.cmd)
        run_one_cmd(cmd_info=cmd_info)
        show_log(cmd_info=cmd_info)
    else:
      easy_mp.pool_map(
        processes=n_proc, func=run_one_cmd, args=cmd_infos, chunksize=1)
      show_logs()
  else:
    old_dirs = []
    for cmd_info in cmd_infos:
      d = "%s%03d" % (co.dirs, cmd_info.index)
      if (op.exists(d)):
        if (not co.force_clean_dirs):
          print("exists already: %s" % show_string(d), file=sys.stderr)
        old_dirs.append(d)
      cmd_info.log = op.join(d, "log")
    if (len(old_dirs) != 0):
      if (not co.force_clean_dirs):
        raise Sorry(
          "Please remove the existing directories or files,"
          " or use a different --dirs assignment.")
      from libtbx.clear_paths \
        import remove_or_rename_files_and_directories_if_possible
      remaining = remove_or_rename_files_and_directories_if_possible(
        paths=old_dirs)
      if (len(remaining) != 0):
        for d in remaining:
          print("unable to remove or rename: %s" % show_string(d), file=sys.stderr)
        raise Sorry("Failure removing existing directories.")
    easy_mp.pool_map(
      processes=n_proc, func=run_in_dir, args=cmd_infos, chunksize=1)
    show_logs()
  print()
  show_times()
  print()
  sys.stdout.flush()

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/path_utility.py
from __future__ import absolute_import, division, print_function

import os
import sys

def norm(path):
  return os.path.normcase(os.path.normpath(path))

def run(args):
  assert len(args) >= 2
  mode = args[0]
  env_key = args[1]
  if mode in ("prepend", "append", "delete"):
    assert len(args) == 3
    if args[2] == "__CWD__":
      arg_paths = [os.getcwd()]
    else:
      arg_paths = args[2].split(os.pathsep)
  elif mode == "tidy":
    assert len(args) == 2
    arg_paths = []
  else:
    raise RuntimeError('Unknown mode: "%s"' % mode)
  env_val = os.environ.get(env_key, "")
  env_paths = env_val.split(os.pathsep)
  if os.name == "nt":
    unquoted_paths = []
    for path in env_paths:
      if len(path) >= 2 and path[:1] == '"' and path[-1:] == '"':
        path = path[1:-1]
      unquoted_paths.append(path)
    env_paths = unquoted_paths
  remaining_env_paths = []
  if mode == "delete":
    arg_paths_norm = []
    for path in arg_paths:
      if path == "": continue
      arg_paths_norm.append(norm(path))
    for path in env_paths:
      if path == "": continue
      if norm(path) not in arg_paths_norm:
        remaining_env_paths.append(path)
  else:
    remaining_env_paths_norm = []
    if mode == "prepend":
      all_paths = arg_paths + env_paths
    else:
      all_paths = env_paths + arg_paths
    for path in all_paths:
      if path == "": continue
      if norm(path) not in remaining_env_paths_norm:
        remaining_env_paths.append(path)
        remaining_env_paths_norm.append(norm(path))
  if len(remaining_env_paths) == 0:
    return "L_I_B_T_B_X_E_M_P_T_Y"
  return os.pathsep.join(remaining_env_paths)

if __name__ == "__main__":
  print(run(sys.argv[1:]))


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/phil.py
from __future__ import absolute_import, division, print_function
import libtbx.phil
from libtbx.utils import Sorry
from libtbx.option_parser import option_parser
import sys

def run(args, command_name="libtbx.phil", converter_registry=None):
  if (len(args) == 0): args = ["--help"]
  command_line = (option_parser(
    usage="%s [options] parameter_file ..." % command_name)
    .option(None, "--diff",
      action="store_true",
      help="Display only differences between the first file (master)"
           " and the combined definitions from all other files.")
    .option(None, "--show_help",
      action="store_true",
      help="Display help for each parameter if available.")
    .option(None, "--show_some_attributes",
      action="store_true",
      help="Display non-default attributes for each parameter.")
    .option(None, "--show_all_attributes",
      action="store_true",
      help="Display all attributes for each parameter.")
    .option(None, "--process_includes",
      action="store_true",
      help="Inline include files.")
    .option(None, "--print_width",
      action="store",
      type="int",
      help="Width for output",
      metavar="INT")
    .option(None, "--print_prefix",
      action="store",
      type="string",
      default="",
      help="Prefix string for output")
  ).process(args=args)
  co = command_line.options
  attributes_level = 0
  if (co.show_all_attributes):
    attributes_level = 3
  elif (co.show_some_attributes):
    attributes_level = 2
  elif (co.show_help):
    attributes_level = 1
  prefix = co.print_prefix
  file_names = command_line.args
  def parse(file_name):
    return libtbx.phil.parse(
      file_name=file_name,
      converter_registry=converter_registry,
      process_includes=co.process_includes)
  def show(scope):
    scope.show(
      out=sys.stdout,
      prefix=prefix,
      attributes_level=attributes_level,
      print_width=co.print_width)
  if (not co.diff):
    for file_name in file_names:
      print(prefix.rstrip())
      show(scope=parse(file_name=file_name))
      print(prefix.rstrip())
  else:
    if (len(file_names) < 2):
      raise Sorry("Option --diff requires at least two file names.")
    master = parse(file_name=file_names[0])
    show(scope=master.fetch_diff(
      sources=[parse(file_name=file_name)
        for file_name in file_names[1:]]))

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/prime_factors_of.py
from __future__ import absolute_import, division, print_function
from libtbx.math_utils import prime_factors_of
import sys

def run(args):
  for arg in args:
    n = int(arg)
    assert n > 0
    print("prime factors of %d:" % n, prime_factors_of(n))

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/printenv.py
from __future__ import absolute_import, division, print_function
import sys, os

def show(out):
  var_names = sorted(os.environ.keys())
  for var_name in var_names:
    print("%s=%s" % (var_name, os.environ[var_name]), file=out)

def run(args):
  assert len(args) == 0
  show(out=sys.stdout)

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/py_compile_all.py
from __future__ import absolute_import, division, print_function

import argparse
import compileall
import os
import sys

def run():
  # parser with subset of flags
  parser = argparse.ArgumentParser(description='Compiles .py files into .pyc.')
  parser.add_argument('-f', action='store_true', dest='force',
                      help='force rebuild even if timestamps are up to date')
  parser.add_argument('-i', '--ignore-errors', action='store_true',
                      dest='ignore_errors',
                      help='ignore errors')
  parser.add_argument('-v', action='count', dest='quiet', default=0,
                      help=('default is no output, -v is error messages only, '
                            '-vv is all output'))
  # parser.add_argument('-j', '--workers', default=1,
  #                     type=int, help='Run compileall with multiple cores')
  parser.add_argument('compile_dest', metavar='DIR', nargs='*',
                      help=('zero or more directory names to compile; '
                            'if no arguments given, defaults '
                            'to the current working directory'))
  args = parser.parse_args()

  if (len(args.compile_dest) == 0):
    args.compile_dest = [os.getcwd()]

  args.quiet = 2 - args.quiet
  if (args.quiet < 0):
    args.quiet = 0

  if args.ignore_errors:
    import warnings
    warnings.simplefilter('ignore')

  output = list()
  for dest in args.compile_dest:
    output.append(compileall.compile_dir(dest, 100, force=args.force,
                                         quiet=args.quiet))

  if False in output and not args.ignore_errors:
    return 1
  return 0

if (__name__ == "__main__"):
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/raise_exception_for_testing.py
from __future__ import absolute_import, division, print_function
from libtbx.utils import show_exception_info_if_full_testing
import libtbx.load_env
import sys

def run(args):
  assert args in [[], ["silent"]]
  if (len(args) == 0):
    libtbx.env.full_testing = True
  else:
    libtbx.env.full_testing = False
  try:
    raise RuntimeError("Just for testing.")
  except RuntimeError:
    show_exception_info_if_full_testing()

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/remote_processing.py
from __future__ import absolute_import, division, print_function

if __name__ == "__main__":
  import argparse

  parser = argparse.ArgumentParser(
    description = "Server process handling far end of remote execution",
    usage = "%(prog)s job-factory queue-factory (do not run directly!)",
    )
  parser.add_argument(
    "job",
    help = "Job factory pickle string",
    )
  parser.add_argument(
    "queue",
    help = "Job factory pickle string",
    )
  parser.add_argument( "--folder", default = ".", help = "Process workdir" )
  parser.add_argument(
    "--polltime",
    type = int,
    default = 0.01,
    help = "Poll intervall",
    )

  params = parser.parse_args()

  import os
  import sys
  os.chdir( params.folder )
  sys.path.append( os.path.abspath( params.folder ) )

  from libtbx.queuing_system_utils import remote

  jfact = remote.argument_to_object( arg = params.job )
  qfact = remote.argument_to_object( arg = params.queue )

  from libtbx.queuing_system_utils import scheduling

  manager = scheduling.Scheduler(
    handler = scheduling.Unlimited(
      factory = lambda:
        scheduling.ExecutionUnit(
          factory = jfact,
          processor = scheduling.RetrieveProcessor( queue = qfact(), timeout = 1 ),
          ),
      ),
    polling_interval = params.polltime,
    )

  server = remote.SchedulerServer(
    instream = sys.stdin,
    outstream = sys.stdout,
    manager = manager,
    )

  # Redirect standard filehandles, so that the communication stream is intact
  sys.stdout = sys.stderr

  server.serve()



 *******************************************************************************


 *******************************************************************************
libtbx/command_line/remove_tree.py
from __future__ import absolute_import, division, print_function
from shutil import rmtree
import sys, os

def run():
  for arg in sys.argv[1:]:
    if (os.path.isfile(arg)):
      os.remove(arg)
    elif (os.path.isdir(arg)):
      rmtree(arg)

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/remove_unused_imports.py
from __future__ import division
from __future__ import print_function

from libtbx import group_args

def run(args):
  if len(args) != 1:
    print("phenix.python remove_unused_args <file_with_instructions>")
    return
  file_name = args[0]

  instruction_list = get_instruction_list(file_name)
  for file_instructions in instruction_list:
    edit_one_file(file_instructions)

def edit_one_file(file_instructions):
  file_name = file_instructions.file_name
  lines = []
  for l in open(file_name).readlines():
    lines.append(l.rstrip())
  ok = True
  did_something = False
  for instruction in file_instructions.instructions:
    word = instruction.key
    i = instruction.line_number - 1
    spl = get_split_text(lines[i])
    if not spl:
      ok = False
      continue
    if spl[-1] == "\\":
      ok = False
      continue
    if not word in spl:
      ok = False
      continue
    info = remove_word(lines[i], word)
    if info.removed:
      lines[i] = info.new_line
      did_something = True
  new_text = "\n".join(lines)
  if did_something:
    f = open(file_name,'w')
    f.write(new_text + "\n")
    f.close()
    if ok:
      print("Edited %s" %(file_name))
    else:
      print("Edited %s with errors" %(file_name))
  elif ok:
    print("Nothing done with %s" %(file_name))
  else:
    print("Errors in working with %s" %(file_name))

def remove_word(line, word):
  ''' from x import word, other_word
      import word, other_word
      from word import word
  '''
  info = group_args(group_args_type = 'remove_word info',
    word = word,
    line = line,
    new_line = line,
    removed = None,)
  spl = get_split_text(line)
  if not word in spl:
    return info
  spl = remove_word_after_key(spl, word, key = 'as')
  spl = remove_word_after_key(spl, word, key = 'import')
  starting = get_blanks_at_start(line)
  new_line = starting + " ".join(spl)
  new_line = new_line.replace(", ,",",").replace("import ,", "import").replace("as,", "as")
  if new_line.endswith(","):
    new_line = new_line[:-1].rstrip()
  if new_line.endswith("as") or new_line.endswith("import"): # nothing left
    info.new_line = ""
    info.removed = True
    return info
  info.new_line = new_line
  info.removed = True
  return info

def remove_word_after_key(spl, word, key = None):
  new_spl = []
  found_key = (key is None)
  for w in spl:
    if w == key:
      found_key = True
    if (not found_key) or (w != word):
      new_spl.append(w)
    else:
      pass # skip word after key is found
  return new_spl

def get_blanks_at_start(line):
  starting = ""
  for a in line:
    if a == " ":
      starting += a
    else:
      return starting
  return starting
def get_split_text(line):
  return line.strip().replace(","," , ").split()

def get_instruction_list(file_name):
  all_instructions = []
  for line in open(file_name).readlines():
    if line.startswith("In file"):
      line = line.replace(":","")
      fn = line.split()[-1]
      file_instructions=group_args(group_args_type = 'instructions',
        file_name = fn,
        instructions= [],
       )
      all_instructions.append(file_instructions)
    elif line.find("imported at line") > -1:
       spl = line.split()
       key = spl[0]
       line_number = int(spl[-1])
       single_import = group_args(group_args_type = 'single import',
         key = key,
         line_number = line_number,
         )
       file_instructions.instructions.append(single_import)
  return all_instructions


if __name__ == "__main__":
  import sys
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/resource_monitor_plot.py
# LIBTBX_SET_DISPATCHER_NAME libtbx.resource_monitor_plot
from __future__ import division

import argparse
import inspect

from libtbx.resource_monitor import plot_logs


if __name__ == '__main__':  # make the plot in case the original monitor failed
  parser = argparse.ArgumentParser(description=str(inspect.getdoc(plot_logs)))
  parser.add_argument('prefix', nargs='?', type=str, default='monitor*.log',
                      help='Glob matching all log files to be plotted')
  parser.add_argument('-o', '--output', type=str, default='monitor.png',
                      help='Filepath to save the final plot under')
  args = parser.parse_args()
  plot_logs(log_glob=args.prefix, save_path=args.output)


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/run_pickled_function.py
from __future__ import absolute_import, division, print_function

from libtbx import easy_pickle
import os
import sys

def run(args):
  assert (len(args) > 0)
  assert os.path.isfile(args[0])
  pickle_file = args[0]
  func = easy_pickle.load(pickle_file)
  return func()

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/run_tests_parallel.py
from __future__ import absolute_import, division, print_function
import libtbx.test_utils.parallel
from libtbx.utils import Sorry, Usage
import libtbx.phil
import random
import os
import sys

master_phil = libtbx.phil.parse("""
directory = None
  .type = path
  .multiple = True
module = None
  .type = str
  .multiple = True
script = None
  .type = path
  .multiple = True
nproc = 1
  .type=  int
shuffle = False
  .type = bool
quiet = False
  .type = bool
verbosity = 1
  .type = int
stderr = False
  .type = bool
skip_missing = False
  .type = bool
run_in_tmp_dir = False
  .type = bool
max_time = 180
  .type = float(value_min=0)
  .help = "Print warning and timing for all tests that take longer"
          "than max_time (in seconds) to run."
slow_tests = False
  .type = bool
  .help = "If True, also run any tests marked as slow, if any"
""")

def run(args,
   return_list_of_tests=None,
   python_keyword_text="",
   max_tests=None,
   start_test=None,
   tests_to_skip=None,
   tests_to_run=None,
   expected_failures_from_phenix_regression=[],
   unstables_from_phenix_regression = [],
   supplied_list_of_tests = None):

  if (len(args) == 0):
    raise Usage("""libtbx.run_tests_parallel [module=NAME] [directory=path]""")
  user_phil = []
  for arg in args :
    if os.path.isdir(arg):
      user_phil.append(libtbx.phil.parse("directory=%s" % arg))
    else :
      try :
        arg_phil = libtbx.phil.parse(arg)
      except RuntimeError :
        raise Sorry("Unrecognized argument '%s'" % arg)
      else :
        user_phil.append(arg_phil)

  params = master_phil.fetch(sources=user_phil).extract()
  if params.run_in_tmp_dir:
    from libtbx.test_utils import open_tmp_directory
    run_dir = open_tmp_directory()
    print('Running tests in %s' % run_dir)
    os.chdir(run_dir)
  elif return_list_of_tests:
    pass # don't need to check anything
  else:
    cwd = os.getcwd()
    cwd_files = os.listdir(cwd)
    if cwd_files and cwd_files != ["default.profraw"]:
      raise Sorry("Please run this program in an empty directory.")
  if (len(params.directory) == 0) and (len(params.module) == 0):
    raise Sorry("Please specify modules and/or directories to test.")
  all_tests = []
  expected_failure_list = []
  expected_unstable_list = []
  parallel_list = []
  if (not return_list_of_tests) and (supplied_list_of_tests is None): # (this
       #fails with return_list_of_tests)
    all_tests.extend(libtbx.test_utils.parallel.make_commands(params.script,
      python_keyword_text=python_keyword_text))
  for dir_name in params.directory :
    if os.path.split(dir_name)[-1].find("cctbx_project")>-1:
      print('DANGER '*10)
      print('Using the directory option in cctbx_project can be very time consuming')
      print('DANGER '*10)
    dir_tests = libtbx.test_utils.parallel.find_tests(dir_name)
    all_tests.extend(libtbx.test_utils.parallel.make_commands(dir_tests,
      python_keyword_text=python_keyword_text))
  for module_name in params.module :
    module_tests = libtbx.test_utils.parallel.get_module_tests(module_name,
       slow_tests = params.slow_tests,
       python_keyword_text=python_keyword_text,
        skip_missing = params.skip_missing)
    fail_tests = libtbx.test_utils.parallel.\
      get_module_expected_test_failures(module_name,
        skip_missing = params.skip_missing)
    unstable_tests = libtbx.test_utils.\
      parallel.get_module_expected_unstable_tests(module_name,
        skip_missing = params.skip_missing)
    parallel_tests = libtbx.test_utils.parallel.\
      get_module_parallel_tests(module_name,
        skip_missing = params.skip_missing)
    all_tests.extend(module_tests)
    all_tests.extend(fail_tests)
    all_tests.extend(unstable_tests)
    expected_failure_list.extend(fail_tests)
    expected_unstable_list.extend(unstable_tests)
    parallel_list.extend(parallel_tests)

  # add expected failures from phenix regression
  for ef in expected_failures_from_phenix_regression:
    for t in all_tests:
      if t.find(ef) > -1:
        expected_failure_list.append(t)

  # add unstables from phenix regression
  for u in unstables_from_phenix_regression:
    for t in all_tests:
      if t.find(u) > -1:
        expected_unstable_list.append(t)
  # Run all above to get expected failures etc

  if (supplied_list_of_tests is not None):
    all_tests = supplied_list_of_tests  # just use supplied tests

  # run only specified tests:
  if tests_to_run:
      new_tests=[]
      for t in all_tests:
        keep=False
        for tts in tests_to_run:
          if t.find(tts)>-1:
            keep=True
        if keep:
          print ("Keeping the test %s" %(t))
          new_tests.append(t)
        else:
          pass
      all_tests=new_tests

  # remove any specified tests:
  if tests_to_skip:
      new_tests=[]
      for t in all_tests:
        ok=True
        for tts in tests_to_skip:
          if t.find(tts)>-1:
            ok=False
        if ok:
          new_tests.append(t)
        else:
          print ("Skipping the test %s" %(t))
      all_tests=new_tests


  # check that test lists are unique
  seen = set()
  duplicates = set()
  for t in all_tests:
      if t in seen:
        duplicates.add(t)
      else:
        seen.add(t)
  assert len(duplicates) == 0, "Duplicate tests found.\n%s" % list(duplicates)
  if start_test:
    all_tests=all_tests[start_test:]
    print ("Starting with test # %s " %(start_test))
  if max_tests:
    all_tests=all_tests[:max_tests]
    print("Running only %s tests" %(max_tests))

  if return_list_of_tests:
    return all_tests
  if (len(all_tests) == 0):
    if (supplied_list_of_tests is not None):
      raise Sorry("No tests to run")
    else: # usual
      raise Sorry("No test scripts found in %s." % params.directory)
  if (params.shuffle):
    random.shuffle(all_tests)
  if (params.quiet):
    params.verbosity = 0
  with open("run_tests_parallel_zlog", "w") as log:
    result = libtbx.test_utils.parallel.run_command_list(
      cmd_list=all_tests,
      expected_failure_list=expected_failure_list,
      expected_unstable_list=expected_unstable_list,
      parallel_list=parallel_list,
      nprocs=params.nproc,
      log=log,
      verbosity=params.verbosity,
      max_time=params.max_time)
  print("\nSee run_tests_parallel_zlog for full output.\n")
  if (result.failure > 0):
    print("")
    print("*" * 80)
    print("ERROR: %d TEST FAILURES.  PLEASE FIX BEFORE COMMITTING CODE." % \
      result.failure)
    print("*" * 80)
    print("")
  return result.failure

if (__name__ == "__main__"):
  if (run(sys.argv[1:]) > 0):
    sys.exit(1)


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/scons.py
from __future__ import absolute_import, division, print_function
from libtbx.utils import Sorry, show_times_at_exit
from libtbx.str_utils import show_string
import libtbx.load_env
import sys, os

def find_scons_engine_path():
  join = os.path.join
  isdir = os.path.isdir
  if (libtbx.env.scons_dist_path is not None):
    result = libtbx.env.scons_dist_path / "engine"
    if result.isdir(): return abs(result)
    result = libtbx.env.scons_dist_path / "src" / "engine"
    if result.isdir(): return abs(result)
  for path in libtbx.env.repository_paths:
    result = path / "scons" / "engine"
    if result.isdir(): return abs(result)
    result = path / "scons" / "src" /"engine"
    if result.isdir(): return abs(result)
    # More recent scons-local packages don't use 'engine' directory
    result = path / "scons"
    if result.isdir(): return abs(result)
  return None

def dummy_fetch_win32_parallel_msg():
  pass

def run():
  debug_import = "--debug=import" in sys.argv[1:]
  def show_traceback():
    if (debug_import):
      import traceback
      print(file=sys.stderr)
      traceback.print_exc()
      print(file=sys.stderr)
  engine_path = find_scons_engine_path()
  if (engine_path is not None):
    sys.path.insert(0, engine_path)
    try: import SCons
    except ImportError:
      show_traceback()
      del sys.path[0]
  try: import SCons.Script
  except ImportError:
    show_traceback()
    msg = ["SCons is not available.",
      "  A possible solution is to unpack a SCons distribution in",
      "  one of these directories:"]
    for path in libtbx.env.repository_paths:
      msg.append("    " + show_string(abs(path)))
    msg.extend([
      "  SCons distributions are available at this location:",
      "    http://www.scons.org/",
      "  It may be necessary to rename the unpacked distribution, e.g.:",
      "    mv scons-0.96.1 scons"])
    raise Sorry("\n".join(msg))
  import SCons.Script.Main
  if (hasattr(SCons.Script.Main, "fetch_win32_parallel_msg")):
    SCons.Script.Main.fetch_win32_parallel_msg = dummy_fetch_win32_parallel_msg
  show_times_at_exit()
  SCons.Script.main()

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/seconds_since_the_epoch.py
from __future__ import absolute_import, division, print_function
def run(args):
  import time
  show = args + [str(time.time())]
  print(" ".join(show))

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/sge_available_slots.py
from __future__ import absolute_import, division, print_function
def run(args):
  assert len(args) == 0
  from libtbx import easy_run
  qstat_buffer = easy_run.fully_buffered(command="qstat -g c")
  el = qstat_buffer.stderr_lines
  ol = qstat_buffer.stdout_lines
  if (len(el) != 0):
    print(-1)
  elif (len(ol) < 3):
    print(-2)
  elif (   " ".join(ol[0].split())
        != "CLUSTER QUEUE CQLOAD USED AVAIL TOTAL aoACDS cdsuE"):
    print(-3)
  elif (not ol[1].startswith("----------")):
    print(-4)
  else:
    sum_available = 0
    for line in ol[2:]:
      flds = line.split()
      assert len(flds) == 7
      sum_available += int(flds[3])
    print(sum_available)

if (__name__ == "__main__"):
  import sys
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/sge_qstat_counts.py
from __future__ import absolute_import, division, print_function
from operator import itemgetter
from libtbx.queuing_system_utils.sge_utils import qstat_parse
from libtbx import dict_with_default_0
import sys

def run(args):
  assert len(args) == 0
  qstat_info = qstat_parse()
  user_states = {}
  for items in qstat_info:
    counts = user_states.setdefault(items.user, dict_with_default_0())
    counts[items.state] += items.counts()
  sum_counts = []
  for user,counts in user_states.items():
    sum_counts.append((user, sum(counts.values())))
  sum_counts.sort(key=itemgetter(1, 0))
  cpus=0
  for user,sc in sum_counts:
    counts = user_states[user]
    print("%-10s   %5d r   %5d qw" % (user, counts["r"], counts["qw"]), end=' ')
    cpus+=counts["r"]
    for state,c in counts.items():
      if (state in ["r", "qw"]): continue
      print("  %5d %s" % (c, state), end=' ')
    print("  %5d total" % sc)
  print("-"*45)
  print("%-10s   %5d r" % ("total", cpus))
  print("-"*45)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_all_on_path.py
from __future__ import absolute_import, division, print_function
import os

def run():
  done = set()
  for directory in os.environ["PATH"].split(os.pathsep):
    directory = os.path.normcase(os.path.abspath(directory))
    if (directory in done): continue
    done.add(directory)
    if (not os.path.isdir(directory)): continue
    if (not os.access(directory, os.X_OK)): continue
    for file_name in os.listdir(directory):
      if (file_name.lower().startswith("libtbx.find_clutter")):
        print(directory)
        break

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_bin_path.py
from __future__ import absolute_import, division, print_function
import libtbx.load_env

def run():
  print(abs(libtbx.env.bin_path))

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_build_options.py
from __future__ import absolute_import, division, print_function
import libtbx.load_env

def run():
  libtbx.env.build_options.report()

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_build_path.py
from __future__ import absolute_import, division, print_function

import libtbx.load_env

def run():
  print(abs(libtbx.env.build_path))

if __name__ == "__main__":
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_but_no_repr.py
from __future__ import division, print_function
import sys
import ast

def class_has_show_but_not_repr(node):
    found_repr = False
    found_show = False

    for obj in node.body:
        if isinstance(obj, ast.FunctionDef):
            if obj.name == '__repr__':
                found_repr = True
            if obj.name == '__str__':
                found_repr = True
            if obj.name == 'show':
                found_show = True
    return found_show and not found_repr

class rummage(ast.NodeVisitor):
    def __init__(self, node):
        self.__offenders = []
        self.visit(node)

    def visit_ClassDef(self, node):
        if class_has_show_but_not_repr(node):
            self.__offenders.append(node.name)
        self.generic_visit(node)

    def offenders(self):
        return self.__offenders

if __name__ == '__main__':
    for arg in sys.argv:
        with open(arg) as f:
            tree = ast.parse(f.read())

        r = rummage(tree)
        off = r.offenders()
        if off:
            print('File: %s' % arg)
            for o in off:
                print('Class: %s' % o)


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_commands.py
from __future__ import absolute_import, division, print_function
import libtbx.load_env

def run():
  print("# Listing of commands in: %s" % abs(libtbx.env.bin_path))
  file_names = sorted(libtbx.env.bin_path.listdir())
  print("# Number of commands: %d" % len(file_names))
  for file_name in file_names:
    print(file_name)

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_date_and_time.py
from __future__ import absolute_import, division, print_function
import libtbx.utils
import time
import sys

def run():
  s = libtbx.utils.date_and_time()
  if ("-v" in sys.argv[1:]):
    s += " Seconds since the Epoch %.2f" % time.time()
  print(s)

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_dist_paths.py
from __future__ import absolute_import, division, print_function
from six.moves import range

def run(args):
  import libtbx.load_env
  remaining_args = []
  dirname_count = 0
  for arg in args:
    if (arg == "--dirname"):
      dirname_count += 1
    else:
      remaining_args.append(arg)
  def show(path):
    if (path is not None):
      from os.path import dirname
      for _ in range(dirname_count):
        path = dirname(path)
    print(path)
  if remaining_args:
    for arg in remaining_args:
      show(libtbx.env.dist_path(module_name=arg, default=None))
  else:
    for path in libtbx.env.dist_paths():
      show(path)

if __name__ == "__main__":
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_env.py
"""
Reads a libtbx_env file and dumps the entire contents.
Some structures e.g. module dictionaries refer to the same object in multiple
places. These will be dumped multiple times. Anything that refers back to a
previous level will show as "__selfreference__". Relocatable paths are just
shown as the regular, joined path (from inspection all base off of the build
path anyway).
Usage:
  libtbx.show_env <libtbx_env>
"""

from __future__ import absolute_import, division, print_function

import os
import pickle
import sys
from pprint import pprint
from types import ModuleType

import six


def _read_obj(obj, prev=None):
  if prev is None:
    prev = []
  if obj in prev:
    return "__selfreference__"
  prev = list(prev) + [obj]

  if isinstance(obj, prop_object):
    dic = {name: _read_obj(val, prev) for name, val in obj.__dict__.items()}
    dic["__type__"] = obj._pathed_type
    return dic
  elif isinstance(obj, list):
    p = []
    for i in obj:
      p.append(_read_obj(i, prev))
    return p
  elif isinstance(obj, dict):
    return {a: _read_obj(b, prev) for a, b in obj.items()}
  else:
    return obj


class prop_object(object):
  """Object that can convert itself to a dictionary"""

  def to_dict(self):
    return _read_obj(self)


def pathed_prop_object(path):
  "Create a class that knows the path it's supposed to represent"

  class _pathed_prop_object(prop_object):
    """Object that can convert itself to a dictionary"""

    _pathed_type = path

  return _pathed_prop_object


class relocatable_path(object):
  def __repr__(self):
    return os.path.normpath(os.path.join(self._anchor._path, self.relocatable))


class absolute_path(object):
  def __repr__(self):
    return self._path


def plainlify(thing):
  if (
    isinstance(thing, six.string_types)
    or isinstance(thing, six.integer_types)
    or isinstance(thing, (float, complex))
  ):
    return thing
  if thing in (None, True, False):
    return thing
  if isinstance(thing, tuple):
    return tuple(map(plainlify, thing))
  if isinstance(thing, list):
    return list(map(plainlify, thing))
  if isinstance(thing, dict):
    return {plainlify(key): plainlify(value) for key, value in thing.items()}
  if isinstance(thing, set):
    return {plainlify(item) for item in thing}
  return str(thing)


def new_module(name, doc=None):
  """Create a new module and inject it into sys.modules"""
  m = ModuleType(name, doc)
  m.__file__ = name + ".py"
  sys.modules[name] = m
  return m


# Create the fake libtbx environment
libtbx = new_module("libtbx")
libtbx.env_config = new_module("libtbx.env_config")
libtbx.path = new_module("libtbx.path")
libtbx.env_config.environment = pathed_prop_object("libtbx.env_config.environment")
libtbx.env_config.build_options = pathed_prop_object("libtbx.env_config.build_options")
libtbx.env_config.module = pathed_prop_object("libtbx.env_config.module")
libtbx.path.relocatable_path = relocatable_path
libtbx.path.absolute_path = absolute_path

# Look for arguments
if "--help" in sys.argv or "-h" in sys.argv:
  print(__doc__)
elif len(sys.argv) != 2:
  print("Usage: libtbx.show_env.py <libtbx_env>")
elif not os.path.isfile(sys.argv[1]):
  print("Error: {} is not a file.".format(sys.argv[1]))
else:
  # Load the environment dump and
  env = pickle.load(open(sys.argv[1], "rb"))
  d = plainlify(env.to_dict())
  pprint(d)


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_environ_usage.py
from __future__ import absolute_import, division, print_function
import sys

def run(args):
  assert len(args) == 0
  print("""
LIBTBX_DISABLE_TRACEBACKLIMIT
  If set, Sorry and Usage exceptions are shown with the full traceback.

LIBTBX_NO_LD_PRELOAD
  If set, LD_PRELOAD is never set in the command-line launchers.

LIBTBX_VALGRIND
  Run "libtbx.valgrind python" for more information.

LIBTBX_PRINT_TRACE
  If set, print trace of all Python code executed.
  This can lead to very large output.

LIBTBX_NATIVE_TAR
  Inspected by libtbx.bundle_as_selfx to find alternative tar command.
  Example: setenv LIBTBX_NATIVE_TAR $HOME/bin/tar

LIBTBX_FULL_TESTING
  If set, forces libtbx.env.full_testing = True.

LIBTBX_DEBUG_LOG
  If set, enables libtbx.introspection.method_debug_log.
  See method_debug_log documentation for details.

LIBTBX_WINGIDE_DEBUG
  If set, triggers "import wingdbstub" when libtbx.env is loaded.

LIBTBX_CPP0X=False|True
  If False, disables -std=c++0x (if the boost tree is under revision
  control -std=c++0x is enabled automatically for some compilers).
  If True, enables -std=c++0x for some compilers.
""")

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_full_command_path.py
from __future__ import absolute_import, division, print_function
import libtbx.path
import sys

def run(args):
  assert len(args) == 1
  print(libtbx.path.full_command_path(command=args[0]))

if __name__ == "__main__" :
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_host_and_user.py
from __future__ import absolute_import, division, print_function
from libtbx.utils import host_and_user

def run():
  host_and_user().show()

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_include_paths.py
from __future__ import absolute_import, division, print_function
from libtbx.utils import Sorry
from libtbx.str_utils import show_string
import libtbx.load_env
import sys

def read_include_paths(file_name="include_paths"):
  result = []
  for line in open(libtbx.env.under_build(file_name)).read().splitlines():
    flds = line.split(None, 1)
    assert len(flds) == 2
    result.append(flds)
  return result

def run(args):
  remaining_args = []
  prohibit_white_space = False
  for arg in args:
    if (arg == "--prohibit-white-space"):
      prohibit_white_space = True
    else:
      remaining_args.append(arg)
  include_paths = read_include_paths()
  if (len(remaining_args) == 0):
    for key,path in include_paths:
      print(key)
  else:
    for target_key in remaining_args:
      n_hits = 0
      for key,path in include_paths:
        if (key == target_key):
          if (prohibit_white_space and len(path.split()) != 1):
            raise Sorry(
              "Include path contains white-space: %s" % show_string(path))
          print(path)
          n_hits += 1
      if (n_hits == 0):
        raise Sorry("No such include path: %s" % show_string(arg))

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_lib_path.py
from __future__ import absolute_import, division, print_function
import libtbx.load_env

def run():
  print(abs(libtbx.env.lib_path))

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_module_dependencies.py
from __future__ import absolute_import, division, print_function
import libtbx.load_env
import sys, os
from libtbx.utils import Usage

"""
Search libtbx_config files to show the complete dependency
chain of any cctbx modules. Optional modules are skipped,
as are modules tagged with 'exclude_from_binary_bundle'.
"""

def run():
  if len(sys.argv) != 2:
    raise Usage("%s modulename"%libtbx.env.dispatcher_name)

  initial_root = sys.argv[1]

  # save a list of all modules found so far so as to not enter loops
  all_found = []

  def show_dependencies(root, depth):
    """
    Recursivly search known modules for dependencies
    @param root module to start with
    @param depth recursion depth
    """
    indent = "  " * depth
    if root in all_found:
      # dependency already found
      return
    all_found.append(root)

    root_path = libtbx.env.find_in_repositories(root)
    if root_path is None or not os.path.exists(root_path):
      print(indent, "Dependency not found", root)
      return

    config_path = os.path.join(root_path, "libtbx_config")
    if not os.path.exists(config_path):
      print(indent, root, "has no libtbx_config")
      return

    f = open(config_path)
    config = eval(" ".join(f.readlines()), {}, {})
    f.close()

    all_mods = []
    for key, mods in config.items():
      if "optional" in key: continue
      elif key == "exclude_from_binary_bundle": continue
      else:
        for mod in mods:
          if mod not in all_mods:
            all_mods.append(mod)

    if len(all_mods) == 0:
      print(indent, root, "has no dependencies")
    else:
      print(indent, root, "depends on", " ".join(all_mods))
      for mod in all_mods:
        show_dependencies(mod, depth+1)

  show_dependencies(initial_root, 0)

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_number_of_processors.py
from __future__ import absolute_import, division, print_function

import os
import sys

def run(args):
  try: __file__
  except NameError: d = sys.path[0]
  else: d = os.path.dirname(__file__)
  d,b = os.path.split(os.path.dirname(d))
  if b == "libtbx" and os.path.isdir(d):
    sys.path.insert(0, d)
  import libtbx.introspection
  n = libtbx.introspection.number_of_processors(return_value_if_unknown=None)
  if (n is not None or len(args) == 0):
    print(n)
  else:
    print(" ".join(args))

if __name__ == "__main__":
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_numeric_version.py
from __future__ import absolute_import, division, print_function
def run():
  try: import Numeric
  except ImportError: print("None")
  else: print(Numeric.__version__)

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_numpy_version.py
from __future__ import absolute_import, division, print_function
def run():
  try: import numpy
  except ImportError: print("None")
  else: print(numpy.__version__)

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_python_dependencies.py
#!/usr/bin/env python

"""
Lists the module python dependencies and the state of install.
"""

from __future__ import absolute_import, division, print_function

import argparse
import copy
import re
import sys

import libtbx.load_env
import libtbx.pkg_utils
from libtbx.pkg_utils import pkg_resources
from libtbx.pkg_utils import packaging
from six.moves import range
from six.moves import zip


BOLD = "\033[1m"
RED = "\033[1;31m"
MAGENTA = "\033[1;35m"
GREEN = "\033[32m"
GRAY = "\033[37m"
NC = "\033[0m"

# A regex to check for requirement characters that are not shell-safe
reSafe = re.compile(r"[^a-zA-Z0-9,._+:@%/\[\]-]")


def _get_requirement_status(requirement):
    # type: (packaging.requirements.Requirement) -> Tuple[Any, str]
    """Get the requirement status of a package.

    Args:
        requirement (packaging.requirements.Requirement):
            The requirement object to check

    Returns:
        Tuple[str, str]:
            The status value, and - if it exists - the current version.
            The status value can currently be one of:
                - "SKIPPED": The package is excluded by env markers
                - "VALID":   Already installed with correct version
                - "UNKNOWNEXTRA": Installed, but missing extras
                - "MISSING": The package is not installed
                - "MISMATCH": An incompatible version is installed
    """
    requirement = copy.deepcopy(requirement)
    if requirement.marker and not requirement.marker.evaluate():
        # Try to get a version without the marker
        requirement.marker = None
        # Look to see if we have an installed version anyway
        try:
            version = pkg_resources.require(str(requirement))[0].version
            return ("SKIPPED", version)
        except pkg_resources.ResolutionError:
            return ("SKIPPED", None)

    # Try to find this package
    try:
        pkg = pkg_resources.require(str(requirement))[0]
        return ("VALID", pkg.version)
    except pkg_resources.UnknownExtra:
        # Package exists, but extra is missing. Get the base description.
        requirement.extras = set()
        version = pkg_resources.require(str(requirement))[0].version
        return ("UNKNOWNEXTRA", version)
    except pkg_resources.VersionConflict:
        requirement.specifier = packaging.specifiers.SpecifierSet()
        version = pkg_resources.require(str(requirement))[0].version
        return ("MISMATCH", version)
    except pkg_resources.DistributionNotFound:
        # Package not installed
        return ("MISSING", None)


def _shell_quote_requirement(req):
    # type: (Union[packaging.requirements.Requirement, str]) -> str
    """Returns a shell-quoted requirement string.

    Since we know the form of the requirement, it is safe to single-quote
    anything and convert internal single-quotes to double (we know no
    recursive quoting). But if it's not necessary to do this, it won't.

    Args:
        req (Requirement or str):
            The requirement, as an object or PEP508 string.

    Returns:
        str:
            A shell-safe, potentially escaped version of the string.
    """
    out = str(req)
    if reSafe.search(out):
        # Something needs to be quoted. Quote it, but we know the
        # general form and know we don't have recursively nested quotes
        out = "'" + out.replace("'", '"') + "'"
    return out


def _print_table(rows):
    # type: (List[List[str]]) -> None
    """Prints a pretty formatted table of dependencies.

    Args:
        rows (List[List[str]]):
            The row data, containing six columns in the order of
            Status, Name, Specifier, Available, Marker, From
    """

    titles = ["Status", "Name", "Specifier", "Available", "Marker", "From"]
    justification = ["l", "l", "l", "r", "l", "l"]

    # Remove marker row if no markers
    if not any(x[4] for x in rows):
        for row in rows + [titles] + [justification]:
            row.pop(4)

    column_widths = [
        max(len(str(row[i])) for row in rows + [titles]) for i in range(len(rows[0]))
    ]

    colors = {
        "VALID": GREEN,
        "MISSING": RED,
        "UNKNOWNEXTRA": MAGENTA,
        "MISMATCH": MAGENTA,
        "SKIPPED": GRAY,
        "Status": "",
    }
    # Print a formatted table
    for row in [titles] + rows:
        color = colors[row[0]]
        out_cols = []
        for col, just, width in zip(row[1:], justification[1:], column_widths[1:]):
            col_txt = col.ljust(width)
            if just == "r":
                col_txt = col.rjust(width)
            elif just == "c":
                col_txt = col.center(width)
            out_cols.append(col_txt)
        print(color + " ".join(out_cols) + (NC if color else ""))


if __name__ == "__main__":
    # Parse command-line arguments
    parser = argparse.ArgumentParser(description="Show python package requirements")
    parser.add_argument(
        "--norefresh", action="store_true", help="Don't re-read module config"
    )
    modes = parser.add_mutually_exclusive_group()
    modes.add_argument(
        "--all", action="store_true", help="Just show a list of all dependencies"
    )
    modes.add_argument(
        "--actions", action="store_true", help="Show packages to install/upgrade"
    )
    args = parser.parse_args()

    # Should we do the normal actions if nothing special has been asked for?
    normal_output = not args.all and not args.actions

    # Check for packaging
    if not libtbx.pkg_utils.pkg_resources:
        print(
            "\n".join(
                [
                    "  WARNING: Can not verify python package requirements - pip/setuptools out of date",
                    "  Please update pip and setuptools by running:",
                    "",
                    "    libtbx.python -m pip install pip setuptools --upgrade",
                    "",
                    "  or following the instructions at https://pip.pypa.io/en/stable/installing/",
                ]
            )
        )
        sys.exit(1)

    # Re-read all config files, without a refresh. Not entirely sure that
    # this is the proper thing to do as makes a slight race condition with
    # refresh, and cannot get a stage where module is listed but not refreshed?
    if not args.norefresh:
        for module in libtbx.env.module_list:
            module.process_libtbx_config()

    # Gather the requirements
    requirements = sorted(
        libtbx.pkg_utils.collate_python_requirements(libtbx.env.module_list),
        key=lambda x: x.name.lower(),
    )

    rows = []
    to_action = []

    for requirement in requirements:
        # Check the status of this requirement
        status, cur_ver = _get_requirement_status(requirement)
        name = requirement.name
        if requirement.extras:
            name = name + "[" + ",".join(requirement.extras) + "]"
        # Build a row object for table display
        rows.append(
            [
                status,
                name,
                str(requirement.specifier),
                str(cur_ver) if cur_ver is not None else "",
                str(requirement.marker) if requirement.marker else "",
                ", ".join(sorted(requirement.modules)),
            ]
        )
        if status in {"MISSING", "UNKNOWNEXTRA", "MISMATCH"}:
            to_action.append(requirement)

    # Decide how to do output
    if normal_output and rows:
        _print_table(rows)

        if to_action:
            print(
                "\nThere are packaging actions required. pip command to resolve\npackaging differences:\n"
            )
            print(
                " ".join(
                    ["    libtbx.pip", "install"]
                    + [_shell_quote_requirement(req) for req in to_action]
                )
            )
    elif normal_output and not rows:
        print("No dependencies found.")
    elif args.all:
        print(" ".join(_shell_quote_requirement(x) for x in requirements))
    elif args.actions:
        print(" ".join(_shell_quote_requirement(x) for x in to_action))


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_python_sys_executable.py
from __future__ import absolute_import, division, print_function

import os
import sys

def run(args):
  assert len(args) == 0
  print(os.path.normpath(sys.executable))

if __name__ == "__main__":
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_pythonpath.py
from __future__ import absolute_import, division, print_function
import libtbx.load_env

def run():
  print(":".join([ abs(p) for p in libtbx.env.pythonpath ]))

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_repository_paths.py
from __future__ import absolute_import, division, print_function
import libtbx.load_env

def run():
  for path in libtbx.env.repository_paths:
    print(abs(path))

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_tests.py
from __future__ import absolute_import, division, print_function
import os
import importlib

def match_dir_with_called_in_main(dir_list, f):
  lines_after_main = []
  found_main = False
  with open(f, "r") as fo:
    for l in fo.readlines():
      l = l.strip()
      if(l.count("__main__")): found_main = True
      if(found_main): lines_after_main.append(l)
  matches = 0
  for lid in dir_list:
    for lam in lines_after_main:
      if(lam.startswith(lid)): matches += 1
  if(matches != 1):
    print(lines_after_main)
    print(dir_list)
    assert matches == 1, matches

def get_dirs(realpath):
  modules_found = False
  result = []
  for d in os.path.dirname(realpath).split("/"):
    if(d == "modules"):
      modules_found = True
      continue
    if(modules_found):
      result.append(d)
  result = ".".join(result)
  return result

def run():
  """
  FACTS about this utility:
  0) To execute: run libtbx.show_tests with no args in the current directory.
  1) Show doc strings of test files in the current directory where it is
     executed.
  2) Does not explore sub-directories recursively.
  3) Assume test file name begins with 'tst_' and ends with '.py'.
  4) Tries to assert one test file contains one function that runs the test.
  5) modules/phenix_regression/real_space_refine was used as a model for
     developemnt of this utility.
  """
  for f in os.listdir("."):
    if(f.startswith("tst") and f.endswith(".py")):
      realpath = os.path.realpath(f)
      print( f )
      module = get_dirs(realpath)
      i = importlib.import_module("%s.%s"%(module,f.strip(".py")))
      doc = i.run.__doc__
      print(doc)
      d = dir(i)
      match_dir_with_called_in_main(d, f)

if(__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/show_variable_names.py
from __future__ import absolute_import, division, print_function
import libtbx.load_env

def run():
  pairs = dict(libtbx.env.var_name_and_build_or_dist_path_pairs())
  var_names = sorted(pairs.keys())
  for var_name in var_names:
    print("%s=%s" % (var_name, abs(pairs[var_name])))

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/sphinx_build.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME sphinx.build

import sys
try:
  # try importing scipy.linalg before any cctbx modules, otherwise we
  # sometimes get a segmentation fault/core dump if it is imported after.
  # scipy.linalg is a dependency of e.g. xfel/clustering
  import scipy.linalg # import dependency
except ImportError:
  pass

if __name__ == '__main__':
    try:
        from sphinx import main
        sys.exit(main(sys.argv))
    except ImportError:
        from sphinx.cmd.build import main
        sys.exit(main())


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/start_binary_bundle.py
from __future__ import absolute_import, division, print_function
from libtbx.bundle import copy_all
from libtbx.bundle import install_csh
from libtbx.bundle import install_bat
import sys, os

def run(args):
  if (len(os.listdir(".")) != 0):
    print("Please use this command only in an empty directory.")
    return
  if (len(args) != 2) and (len(args) != 3):
    print("usage: libtbx.start_binary_bundle bundle_name top_modules [--single_directory]")
    return
  single_dir = False
  if (len(args) == 2):
    bundle_name, top_modules = args
  else :
    if (args[2] != "--single_directory"):
      print("usage: libtbx.start_binary_bundle bundle_name top_modules [--single_directory]")
      return
    bundle_name, top_modules = args[:2]
    single_dir = True
  if (single_dir):
    os.mkdir(bundle_name)
    os.chdir(bundle_name)
  copy_all.run(bundle_name)
  if (os.name == "nt"):
    install_script = bundle_name+"_install_script.bat"
    open(install_script, "w").write(
      install_bat.create_script(
        bundle=bundle_name,
        top_modules=top_modules,
        single_dir=single_dir))
  else:
    install_script = bundle_name+"_install_script.csh"
    open(install_script, "w").write(
      install_csh.create_script(
        bundle=bundle_name,
        top_modules=top_modules))
    os.chmod(install_script, 0o755)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/start_process.py
from __future__ import absolute_import, division, print_function
import libtbx.runtime_utils
import sys

if __name__ == "__main__" :
  libtbx.runtime_utils.run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/command_line/wait_for_file.py
from __future__ import absolute_import, division, print_function
def usage():
  from libtbx.utils import Usage
  import libtbx.load_env
  raise Usage("%s timeout file..." % libtbx.env.dispatcher_name)

def run(args):
  if (len(args) < 2): usage()
  timeout = float(args[0])
  if (timeout <= 0): usage()
  file_names = args[1:]
  #
  import libtbx.load_env
  import time
  import os
  op = os.path
  time_start = time.time()
  while True:
    for file_name in file_names:
      if (not op.exists(file_name)):
        if (time.time() - time_start > timeout):
          raise RuntimeError(
            "%s timeout exceeded." % libtbx.env.dispatcher_name)
        time.sleep(0.1)
        break
    else:
      break

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/complex_math.py
from __future__ import absolute_import, division, print_function
from math import pi, atan2, cos, sin

def norm(c):
  return c.real**2 + c.imag**2

def abs_arg(c, deg=False):
  "conversion of complex number: real, imag -> absolute value, polar angle"
  a = abs(c)
  if (a == 0): return (0, 0)
  t = atan2(c.imag, c.real)
  if (deg): t *= 180/pi
  return (a, t)

def arg(c, deg=False):
  "conversion of complex number: real, imag -> polar angle"
  return abs_arg(c, deg)[1]

def polar(a_t, deg=False):
  "conversion of complex number: polar representation -> real, imag"
  a, t = a_t
  if (deg): t *= pi/180
  return complex(a * cos(t), a * sin(t))


 *******************************************************************************


 *******************************************************************************
libtbx/configure.py
from __future__ import absolute_import, division, print_function
import sys, os

def run():
  if sys.hexversion < 0x02070000:
    print()
    print("*" * 78)
    print("FATAL: Python 2.7 or higher is required.")
    print("Version currently in use:", sys.version)
    print("*" * 78)
    print()
    return False
  # test for six and future
  try:
    import six
    import future
  except ImportError:
    print()
    print("*" * 78)
    print("FATAL: For Python 2/3 compatibility, CCTBX currently requires the six and\n  future modules.")
    print("To install, please use pip or conda (if available)")
    print("  pip install six future")
    print("  conda install six future")
    print("*" * 78)
    print()
    return False
  sys.path[0] = os.path.dirname(sys.path[0])
  import libtbx.env_config
  libtbx.env_config.cold_start(sys.argv)
  print("Done.")
  return True

if __name__ == "__main__":
  if not run():
    sys.exit(1)


 *******************************************************************************


 *******************************************************************************
libtbx/console_utils.py

from __future__ import absolute_import, division, print_function
import sys

class colors_(object):
  def __init__(self):
    self.black = 30
    self.red = 31
    self.green = 32
    self.yellow = 33
    self.blue = 34
    self.magenta = 35
    self.cyan = 36
    self.white = 37
    self.endc = 0

  def get_escape_string(self, color, bold=False, bgcolor=None):
    values = []
    if (bold):
      values.append(1)
    if (bgcolor is not None):
      values.append(getattr(self, bgcolor) + 10)
    values.append(getattr(self, color))
    value_str = ";".join([ "%d" % num for num in values ])
    return '\033[%sm' % value_str

colors = colors_()

class console_out(object):
  def __init__(self, console_out=None, other_out=None):
    if (console_out is None):
      console_out = sys.stdout
    self.console_out = console_out
    self.other_out = other_out
    self._color = None

  def set_color(self, color, bold=False, bgcolor=None):
    self._color = color
    escape_string = colors.get_escape_string(color, bold, bgcolor)
    if (self.console_out.isatty()) and (sys.platform != "win32"):
      self.console_out.write('\033[0m')
      self.console_out.write(escape_string)

  def reset(self):
    self._color = None
    if (self.console_out.isatty()) and (sys.platform != "win32"):
      self.console_out.write('\033[0m')

  def write(self, *args, **kwds):
    self.console_out.write(*args, **kwds)
    if (self.other_out is not None):
      self.other_out.write(*args, **kwds)

  def flush(self):
    self.console_out.flush()

  def warn(self, message, endl=True):
    self.set_color("yellow", bold=True)
    self.write(message)
    if (endl) : self.write("\n")
    self.reset()

  def fail(self, message, endl=True):
    self.set_color("red", bold=True)
    self.write(message)
    if (endl) : self.write("\n")
    self.reset()

def exercise():
  out = console_out()
  print("Hello, world!", file=out)
  for color in ["red","blue","green","yellow","magenta","cyan"] :
    out.set_color(color)
    print("Hello, world!", file=out)
  out.warn("this is a warning message")
  out.fail("this is a failure message")

if (__name__ == "__main__"):
  exercise()


 *******************************************************************************


 *******************************************************************************
libtbx/containers.py
from __future__ import absolute_import, division, print_function

import collections
from collections import OrderedDict  # special import
try:
  from collections.abc import MutableSet
except ImportError:
  from collections import MutableSet

class OrderedSet(MutableSet):
  """
  http://code.activestate.com/recipes/576694/ rev9
  recommended replacement: https://pypi.python.org/pypi/orderedset
  """

  def __init__(self, iterable=None):
    self.end = end = []
    end += [None, end, end]         # sentinel node for doubly linked list
    self.map = {}                   # key --> [key, prev, next]
    if iterable is not None:
      self |= iterable

  def __len__(self):
    return len(self.map)

  def __contains__(self, key):
    return key in self.map

  def add(self, key):
    if key not in self.map:
      end = self.end
      curr = end[1]
      curr[2] = end[1] = self.map[key] = [key, curr, end]

  def discard(self, key):
    if key in self.map:
      key, prev, next = self.map.pop(key)
      prev[2] = next
      next[1] = prev

  def __iter__(self):
    end = self.end
    curr = end[2]
    while curr is not end:
      yield curr[0]
      curr = curr[2]

  def __reversed__(self):
    end = self.end
    curr = end[1]
    while curr is not end:
      yield curr[0]
      curr = curr[1]

  def pop(self, last=True):
    if not self:
      raise KeyError('set is empty')
    key = self.end[1][0] if last else self.end[2][0]
    self.discard(key)
    return key

  def __repr__(self):
    if not self:
      return '%s()' % (self.__class__.__name__,)
    return '%s(%r)' % (self.__class__.__name__, list(self))

  def __eq__(self, other):
    if isinstance(other, OrderedSet):
      return len(self) == len(other) and list(self) == list(other)
    return set(self) == set(other)

  def __copy__(self):
    from copy import copy
    result = OrderedSet()
    for elt in self:
      result.add(elt)
    return result

  copy = __copy__

  def __deepcopy__(self, memo):
    from copy import deepcopy
    result = OrderedSet()
    for elt in self:
      result.add(deepcopy(elt, memo))
    return result

class deque_template(object):

  __slots__ = ('_list_proxy', '_set_proxy')

  def __init__(self):
    self._list_proxy = self.__class__.list_proxy_type()
    if self.__class__.set_proxy_type is not None:
      self._set_proxy = self.__class__.set_proxy_type()
    else:
      self._set_proxy = self._list_proxy

  def push(self, item):
    self._list_proxy.append(item)
    if self._set_proxy is not self._list_proxy:
      self._set_proxy.add(item)
    return self

  def __bool__(self):
    return bool(self._list_proxy)

  __nonzero__ = __bool__

  def __contains__(self, item):
    return item in self._set_proxy


class stack(deque_template):
  list_proxy_type = list
  set_proxy_type  = None

  def pull(self):
    result = self._l.pop()
    if self._set_proxy is not self._list_proxy:
      self._set_proxy.discard(result)
    return result


class hashed_stack(stack):
  set_proxy_type = set

class queue(deque_template):
  list_proxy_type = collections.deque
  set_proxy_type  = None

  def pull(self):
    result = self._list_proxy.popleft()
    if self._set_proxy is not self._list_proxy:
      self._set_proxy.discard(result)
    return result

class hashed_queue(queue):
  set_proxy_type = set


 *******************************************************************************


 *******************************************************************************
libtbx/cpp_function_name.py
from __future__ import absolute_import, division, print_function
from libtbx import easy_run

def demangle(symbol):
  """ Return the demangled C++ function name corresponding to symbol
      on platforms featuring c++filt. On those which do not, return symbol
      untouched
  """
  try:
    result = easy_run.fully_buffered("c++filt %s" % symbol)\
                     .raise_if_errors()\
                     .stdout_lines[0]
  except AssertionError:
    result = symbol
  return result

if __name__ == '__main__':
  def exercise_demangle():
    assert (demangle("__ZN5iotbx2xd17master_file_input8on_error"
                     "EPKcRKNS_10flex_bison8locationEPv")
            == "iotbx::xd::master_file_input::on_error"
               "(char const*, iotbx::flex_bison::location const&, void*)")

  exercise_demangle()


 *******************************************************************************


 *******************************************************************************
libtbx/crossmingw.py
from __future__ import absolute_import, division, print_function
# this is Scons tool definition for 'crossmingw' copied from
# http://www.scons.org/wiki/CrossCompilingMingw (2011-11-25)

import os
import os.path

import SCons.Action
import SCons.Builder
import SCons.Tool
import SCons.Util

# This is what we search for to find mingw:
prefixes = SCons.Util.Split("""
  mingw32-
  i386-mingw32msvc-
  i486-mingw32msvc-
  i586-mingw32msvc-
  i686-mingw32msvc-
  i686-pc-mingw32-
  i686-w64-mingw32-
""")

if os.getenv("TARGET"):
    prefixes.insert(0, os.getenv("TARGET")+"-")

def find(env):
  for prefix in prefixes:
    # First search in the SCons path and then the OS path:
    if env.WhereIs(prefix + 'gcc') or SCons.Util.WhereIs(prefix + 'gcc'):
      return prefix

  return ''

def shlib_generator(target, source, env, for_signature):
  cmd = SCons.Util.CLVar(['$SHLINK', '$SHLINKFLAGS'])

  dll = env.FindIxes(target, 'SHLIBPREFIX', 'SHLIBSUFFIX')
  if dll: cmd.extend(['-o', dll])

  cmd.extend(['$SOURCES', '$_LIBDIRFLAGS', '$_LIBFLAGS'])

  implib = env.FindIxes(target, 'LIBPREFIX', 'LIBSUFFIX')
  if implib: cmd.append('-Wl,--out-implib,'+implib.get_string(for_signature))

  def_target = env.FindIxes(target, 'WIN32DEFPREFIX', 'WIN32DEFSUFFIX')
  if def_target: cmd.append('-Wl,--output-def,'+def_target.get_string(for_signature))

  return [cmd]

def shlib_emitter(target, source, env):
  dll = env.FindIxes(target, 'SHLIBPREFIX', 'SHLIBSUFFIX')
  no_import_lib = env.get('no_import_lib', 0)

  if not dll:
    raise SCons.Errors.UserError("A shared library should have exactly one target with the suffix: %s" % env.subst("$SHLIBSUFFIX"))

  if not no_import_lib and \
     not env.FindIxes(target, 'LIBPREFIX', 'LIBSUFFIX'):

    # Append an import library to the list of targets.
    target.append(env.ReplaceIxes(dll,
                    'SHLIBPREFIX', 'SHLIBSUFFIX',
                    'LIBPREFIX', 'LIBSUFFIX'))

  # Append a def file target if there isn't already a def file target
  # or a def file source. There is no option to disable def file
  # target emitting, because I can't figure out why someone would ever
  # want to turn it off.
  def_source = env.FindIxes(source, 'WIN32DEFPREFIX', 'WIN32DEFSUFFIX')
  def_target = env.FindIxes(target, 'WIN32DEFPREFIX', 'WIN32DEFSUFFIX')
  if not def_source and not def_target:
    target.append(env.ReplaceIxes(dll,
                  'SHLIBPREFIX', 'SHLIBSUFFIX',
                  'WIN32DEFPREFIX', 'WIN32DEFSUFFIX'))

  return (target, source)

#shlib_action = SCons.Action.CommandGenerator(shlib_generator)
shlib_action = SCons.Action.Action(shlib_generator, generator=1)

res_action = SCons.Action.Action('$RCCOM', '$RCCOMSTR')

res_builder = SCons.Builder.Builder(action=res_action, suffix='.o',
                  source_scanner=SCons.Tool.SourceFileScanner)
SCons.Tool.SourceFileScanner.add_scanner('.rc', SCons.Defaults.CScan)

def generate(env):
  mingw_prefix = find(env)

  if mingw_prefix:
    dir = os.path.dirname(env.WhereIs(mingw_prefix + 'gcc') or SCons.Util.WhereIs(mingw_prefix + 'gcc'))

    # The mingw bin directory must be added to the path:
    path = env['ENV'].get('PATH', [])
    if not path:
      path = []
    if SCons.Util.is_String(path):
      path = path.split(os.pathsep)

    env['ENV']['PATH'] = os.pathsep.join([dir] + path)

  # Most of mingw is the same as gcc and friends...
  gnu_tools = ['gcc', 'g++', 'gnulink', 'ar', 'gas']
  for tool in gnu_tools:
    SCons.Tool.Tool(tool)(env)

  #... but a few things differ:
  env['CC'] = mingw_prefix + 'gcc'
  env['SHCCFLAGS'] = SCons.Util.CLVar('$CCFLAGS')
  env['CXX'] = mingw_prefix + 'g++'
  env['SHCXXFLAGS'] = SCons.Util.CLVar('$CXXFLAGS')
  env['SHLINKFLAGS'] = SCons.Util.CLVar('$LINKFLAGS -shared')
  env['SHLINKCOM']   = shlib_action
  env.Append(SHLIBEMITTER = [shlib_emitter])
  # This line isn't required and breaks C++ linking
  #env['LINK'] = mingw_prefix + 'g++'
  env['AS'] = mingw_prefix + 'as'
  env['AR'] = mingw_prefix + 'ar'
  env['RANLIB'] = mingw_prefix + 'ranlib'
  env['WIN32DEFPREFIX']    = ''
  env['WIN32DEFSUFFIX']    = '.def'
  env['SHOBJSUFFIX'] = '.o'
  env['STATIC_AND_SHARED_OBJECTS_ARE_THE_SAME'] = 1

  env['RC'] = mingw_prefix + 'windres'
  env['RCFLAGS'] = SCons.Util.CLVar('')
  env['RCINCFLAGS'] = '$( ${_concat(RCINCPREFIX, CPPPATH, RCINCSUFFIX, __env__, RDirs, TARGET)} $)'
  env['RCINCPREFIX'] = '--include-dir '
  env['RCINCSUFFIX'] = ''
  env['RCCOM'] = '$RC $RCINCFLAGS $RCINCPREFIX $SOURCE.dir $RCFLAGS -i $SOURCE -o $TARGET'
  env['BUILDERS']['RES'] = res_builder

  # Some setting from the platform also have to be overridden:
  env['OBJPREFIX']    = ''
  env['OBJSUFFIX']    = '.o'
  env['LIBPREFIX']    = 'lib'
  env['LIBSUFFIX']    = '.a'
  env['SHOBJPREFIX']  = '$OBJPREFIX'
  env['SHOBJSUFFIX']  = '$OBJSUFFIX'
  env['PROGPREFIX']   = ''
  env['PROGSUFFIX']   = '.exe'
  #env['LIBPREFIX']    = ''
  #env['LIBSUFFIX']    = '.lib'
  env['SHLIBPREFIX']  = ''
  env['SHLIBSUFFIX']  = '.dll'
  env['LIBPREFIXES']  = [ '$LIBPREFIX' ]
  env['LIBSUFFIXES']  = [ '$LIBSUFFIX' ]

def exists(env):
  return find(env)



 *******************************************************************************


 *******************************************************************************
libtbx/development/__init__.py
from __future__ import absolute_import, division, print_function

def show_pickle_sizes(obj, indent="",
    display_if_size_greater_than=10000):
  """
  Function for debugging issues with pickle file size, e.g. detecting which
  objects are contributing to bloat.  This is very approximate, and somewhat
  misleading since child objects may appear to be larger than their parents,
  probably for some reason involving duplicated references.
  """
  from six.moves.cPickle import dumps
  if hasattr(obj, "__slots__"):
    attr_names = obj.__slots__
  else :
    attr_names = list(obj.__dict__.keys())
  for attr in attr_names :
    child_obj = getattr(obj, attr, None)
    if (child_obj is not None):
      pkl = dumps(child_obj)
      n_bytes = len(pkl)
      if (n_bytes > display_if_size_greater_than):
        print(indent+attr, n_bytes)
        if isinstance(child_obj, object) and hasattr(child_obj, "__dict__"):
          show_pickle_sizes(child_obj, indent+"  ",
            display_if_size_greater_than=display_if_size_greater_than)
        elif isinstance(child_obj, list):
          for item in child_obj :
            n_bytes_item = len(dumps(item))
            if (n_bytes_item > display_if_size_greater_than):
              print(indent+"  "+type(item).__name__, n_bytes_item)
              if isinstance(item, object) and hasattr(item, "__dict__"):
                show_pickle_sizes(item, indent+"    ",
                  display_if_size_greater_than=display_if_size_greater_than)


 *******************************************************************************


 *******************************************************************************
libtbx/development/except_Exception.py
from __future__ import absolute_import, division, print_function
def run(args):
  if (len(args) == 0):
    folders = ["."]
  else:
    folders = args
  from libtbx.path import walk_source_tree
  mod_count_total = 0
  mod_file_count = 0
  for folder in folders:
    for path in walk_source_tree(folder):
      if (not path.endswith(".py")): continue
      txt = open(path).read()
      mod_lines = []
      mod_count = 0
      for line in txt.splitlines():
        ls = line.strip()
        if (    ls.startswith("except")
            and ls[6:].strip().startswith(":")
            and not ls.endswith(" # intentional")):
          line = line.replace("except", "except Exception", 1)
          mod_count += 1
        mod_lines.append(line)
      if (mod_count != 0):
        print("\n".join(mod_lines), file=open(path, "w"))
        mod_count_total += mod_count
        mod_file_count += 1
  print("Number of modifications: %d in %d files" % (
    mod_count_total, mod_file_count))

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/development/timers.py
from __future__ import absolute_import, division, print_function
import time,sys

# Restore compatibility to Python >= 3.8, where time.clock() is gone
py_version = sys.version_info
if py_version[0]==3 and py_version[1]>=7:
  #work_clock = time.perf_counter # this is an elapsed time, no good for OpenMP
  work_clock = time.process_time # includes the extra work done with OpenMP
else:
  work_clock = time.clock

class Timer:
  """While the class instance is in scope it accumulates CPU and wall clock
     elapsed time.  A report is printed when the instances goes out of scope"""
  def __init__(self,message):
    self.start = work_clock()
    self.start_el = time.time()
    self.message = message
    print("start timing %s"%self.message)

  def tick(self):
    return work_clock() - self.start

  def __del__(self):
    self.end = work_clock()
    self.end_el = time.time()
    print("time for %s: CPU, %8.3fs; elapsed, %8.3fs"%(
      self.message,self.end-self.start,self.end_el-self.start_el))

class DebuggingTimer:
  def __init__(self,message,filename,filemode = 'a'):
    self.start = work_clock()
    self.start_el = time.time()
    self.message = message
    self.k = open(filename,filemode)
    self.current_out = sys.stdout
    self.current_err = sys.stderr
    sys.stdout = self.k
    sys.stderr = self.k
    print("start timing %s"%self.message)


  def __del__(self):
    self.end = work_clock()
    self.end_el = time.time()
    print("time for %s: CPU, %8.3fs; elapsed, %8.3fs"%(
      self.message,self.end-self.start,self.end_el-self.start_el))
    sys.stdout = self.current_out
    sys.stderr = self.current_err
    self.k.flush()
    self.k.close()

class cumulative:
  def __init__(self,tag):
    self.tag = tag
    self.total = 0.0
  def add(self,amt):
    self.total+=amt
  def __del__(self):
    print("tag",self.tag,"total",self.total)

class singleton_data(dict):
  def __str__(self):
    message = []
    for key in self:
      message.append("time for %30s: CPU, %7.3fs; elapsed, %7.3fs, averaging %7.3fms #calls:%4d"%(key,
        self[key][0],self[key][1],1000.*self[key][1]/self[key][2],self[key][2]))
    return "\n".join(message)

  def __del__(self):
    Nkeys = len(self)
    if Nkeys > 0: print("Exiting profiler")
    total_tm =0.
    total_el =0.
    for key in self:
      print("time for %30s: CPU, %8.3fs; elapsed, %8.3fs, #calls:%4d"%(key,
        self[key][0],self[key][1],self[key][2]))
      total_tm+=self[key][0]
      total_el+=self[key][1]
    if Nkeys > 0:
      print("TOTAL    %30s: CPU, %8.3fs; elapsed, %8.3fs"%("",
        total_tm,total_el))


timing_singleton=singleton_data()

class Profiler:
  """Each time the class is instantiated with the same 'message' it turns on a
     timer to accumulate CPU-elapsed and wall clock-elapsed time, until
     the instance goes out of scope.  When
     the program executable goes out of scope a final report is printed,
     explaining how many instantiations took place and the total time
     accumulated.  The Profiler will separately keep track of timings that
     are instantiated with different 'message's."""
  def __init__(self,message):
    self.start = work_clock()
    self.start_el = time.time()
    self.message = message

  def __enter__(self):pass
  def __exit__(self,exception_type,exception_value,traceback):pass

  def __del__(self):
    self.end = work_clock()
    self.end_el = time.time()
    if self.message not in timing_singleton:
      timing_singleton[self.message]=[0.,0.,0]
    timing_singleton[self.message][0]+=self.end-self.start
    timing_singleton[self.message][1]+=self.end_el-self.start_el
    timing_singleton[self.message][2]+=1

    print("individual call time for %s: CPU, %8.3fs; elapsed, %8.3fs"%(
      self.message,self.end-self.start,self.end_el-self.start_el))

class SlimProfiler(Profiler):
  def __del__(self):
    self.end = work_clock()
    self.end_el = time.time()
    if self.message not in timing_singleton:
      timing_singleton[self.message]=[0.,0.,0]
    timing_singleton[self.message][0]+=self.end-self.start
    timing_singleton[self.message][1]+=self.end_el-self.start_el
    timing_singleton[self.message][2]+=1


 *******************************************************************************


 *******************************************************************************
libtbx/development/xcode_build_phase.py
from __future__ import absolute_import, division, print_function
import sys, os, re

def run_scons():
  import libtbx.load_env
  from libtbx import easy_run
  from libtbx.command_line import scons

  print(); print(); print('-'*80)

  m = re.search(r"^(\d+ \. \d+ \. \d+) .*? \[\s*GCC\s* (\d+ \. \d+ \. \d+)",
                sys.version,
                re.X|re.M|re.S)
  print('Python %s (compiled with gcc %s)' % m.groups())
  print()

  print("** %s **" % libtbx.env.build_path.basename())
  libtbx.env.build_options.report()

  print()
  print('-'*80)
  for compiler in ('gcc', 'clang',):
    print(easy_run.fully_buffered('type %s' % compiler).stdout_lines[0])
  print('-'*80)

  os.chdir(os.environ['XCODE_CCTBX_BUILD'])
  sys.argv[1:] = os.environ['XCODE_SCONS_OPTIONS'].split()
  if os.environ.get('XCODE_SCONS_LIB_TARGET'):
    libs = os.environ['XCODE_SCONS_LIB_TARGET'].split()
    sys.argv.extend([ "lib/%s.so" % lib for lib in libs ])
    print("warning: only library being built: %s" % ', '.join(libs))
  elif os.environ.get('XCODE_SCONS_PROGRAM_TARGET'):
    programs = os.environ['XCODE_SCONS_PROGRAM_TARGET'].split()
    sys.argv.extend(programs)
    print("warning: only program being built: %s" % ', '.join(programs))
  scons.run()

def run_filtered_scons():
  import libtbx.load_env
  import subprocess
  proc = subprocess.Popen([ "%s/libtbx.python" % abs(libtbx.env.bin_path),
                            '-u', __file__, 'child'],
                          stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
  error_pat = re.compile(r'^(.*? : \d* : \d* : \s* error:)', re.X)
  prefix = abs(libtbx.env.build_path) + '/'
  for li in proc.stdout:
    m = error_pat.search(li)
    if m and not m.group(1).startswith('/'):
      sys.stdout.write(prefix)
    sys.stdout.write(li)
    sys.stdout.flush()
  proc.wait()
  return proc.returncode

if __name__ == '__main__':
  if sys.argv[1] == "child":
    run_scons()
  elif sys.argv[1] == "parent":
    sys.exit(run_filtered_scons())
  else:
    print("Usage: %s [child|parent]" % os.path.basename(__file__))


 *******************************************************************************


 *******************************************************************************
libtbx/dlite.py
"light-weight, simple source_path, target_path dependency management"
from __future__ import absolute_import, division, print_function

from libtbx import easy_pickle
from libtbx.utils import Sorry
import hashlib
import time
import sys, os

def try_loading_db(file_name):
  '''
  This function tries to load an existing pickle file. If the pickle file
  cannot be loaded, an empty target_db object is returned. This helps
  simplify the rebuilding of chem_data databases when switching Python
  versions.

  Parameters
  ----------
  file_name : str
      The filename for the database file

  Returns
  -------
  target_db : target_db
      If the file exists and the pickle file can be loaded, the target_db
      object. If the pickle protocol is not supported, the file is removed
      and an empty target_db object is returned.
  '''
  db = None
  try:
    db = target_db(file_name)
  except (Sorry, ValueError) as s:
    if 'unsupported pickle protocol' in str(s):
      os.remove(file_name)
      db = target_db(file_name)
  assert db is not None
  return db

class node_info(object):

  def __init__(self, path):
    self.path = path
    self.mtime = None
    self.md5 = None

  def full_path(self, path_prefix=None):
    if (path_prefix is None): return self.path
    return os.path.join(path_prefix, self.path)

  def current_mtime(self, path_prefix=None):
    full_path = self.full_path(path_prefix=path_prefix)
    if (not os.path.exists(full_path)): return None
    return os.path.getmtime(full_path)

  def current_md5(self, path_prefix=None):
    full_path = self.full_path(path_prefix=path_prefix)
    if (not os.path.exists(full_path)): return None
    m = hashlib.md5()
    with open(full_path, "rb") as f:
      m.update(f.read())
    return m.hexdigest()

  def has_changed(self, path_prefix=None, mtime_resolution=2):
    old_mtime = self.mtime
    if (old_mtime is None): return True
    self.mtime = self.current_mtime(path_prefix=path_prefix)
    if (self.mtime == old_mtime
        and time.time() > old_mtime + mtime_resolution): return False
    if (self.md5 is None): return True
    old_md5 = self.md5
    self.md5 = self.current_md5(path_prefix=path_prefix)
    return self.md5 != old_md5

class pair_info(object):

  def __init__(self, source_path, target_path, needs_update=True):
    self.source = node_info(path=source_path)
    self.target = node_info(path=target_path)
    self.needs_update = needs_update

  def eval_needs_update(self, source_path=None, path_prefix=None):
    if (source_path != self.source.path):
      self.source = node_info(path=source_path)
      self.needs_update = True
    elif (not self.needs_update):
      if (   self.source.has_changed(path_prefix=path_prefix)
          or self.target.has_changed(path_prefix=path_prefix)):
        self.needs_update = True
    return self.needs_update

  def start_building_target(self, path_prefix=None):
    if (self.source.mtime is None):
      self.source.mtime = self.source.current_mtime(path_prefix=path_prefix)
    if (self.source.md5 is None):
      self.source.md5 = self.source.current_md5(path_prefix=path_prefix)

  def done_building_target(self, path_prefix=None):
    self.target.mtime = self.target.current_mtime(path_prefix=path_prefix)
    self.target.md5 = self.target.current_md5(path_prefix=path_prefix)
    self.needs_update = False

class target_db(object):

  def __init__(self, file_name, file_name_during_write=None):
    self.file_name = file_name
    if (file_name_during_write is None and self.file_name is not None):
      self.file_name_during_write = self.file_name + ".new"
    else:
      self.file_name_during_write = file_name_during_write
    if (self.file_name is None
        or not os.path.exists(self.file_name)):
      self.pair_infos = {}
    else:
      self.pair_infos = easy_pickle.load(file_name=self.file_name)

  def write(self):
    assert self.file_name is not None
    easy_pickle.dump(file_name=self.file_name_during_write, obj=self.pair_infos)
    if (os.path.exists(self.file_name)):
      os.remove(self.file_name)
    os.rename(self.file_name_during_write, self.file_name)

  def pair_info(self, source_path, target_path, path_prefix=None):
    result = self.pair_infos.get(target_path)
    if (result is None):
      result = pair_info(source_path=source_path, target_path=target_path)
      self.pair_infos[target_path] = result
    else:
      result.eval_needs_update(
        source_path=source_path, path_prefix=path_prefix)
    return result

  def show(self, out=None):
    if (out is None): out = sys.stdout
    for pair_info in self.pair_infos.values():
      for attr in ["source", "target"]:
        node = getattr(pair_info, attr)
        print(attr+":", node.path, "mtime:", node.mtime,\
                                           "md5:", node.md5, file=out)
      print("-"*79, file=out)


 *******************************************************************************


 *******************************************************************************
libtbx/easy_mp.py
from __future__ import absolute_import, division, print_function
from libtbx.str_utils import show_string
from libtbx.math_utils import ifloor
from libtbx import Auto
from six.moves import cStringIO as StringIO
from libtbx import adopt_init_args
from libtbx import group_args
import traceback
import os
import sys
from six.moves import range

_problem_cache = Auto

# Patch Python 2.7 multiprocessing module to avoid unnecessary file operations
# on non-Windows systems.
sys.modules['multiprocessing.random'] = None

def detect_problem():
  """
  Identify situations where multiprocessing will not work as required.
  """
  global _problem_cache
  if (_problem_cache is Auto):
    import os
    if (os.name == "nt"):
      _problem_cache = "libtbx.easy_mp: Windows is not a supported platform."
    else:
      import libtbx.utils
      _problem_cache = libtbx.utils.detect_multiprocessing_problem()
  return _problem_cache

def enable_multiprocessing_if_possible(nproc=Auto, log=None):
  """
  Switch for using multiple CPUs with the pool_map function, usually called at
  the beginning of an app.  If nproc is Auto or None and we are running
  Windows, it will be reset to 1.

  :param nproc: default number of processors to use
  :returns: number of processors to use (None or Auto means automatic)
  """
  if (nproc == 1) or (nproc == 0):
    return 1
  if (log is None):
    from libtbx.utils import null_out
    log = null_out()
  problems = detect_problem()
  if (problems is not None) and (problems is not Auto):
    if (nproc is Auto) or (nproc is None):
      return 1
    else :
      from libtbx.utils import Sorry
      raise Sorry("%s.  Please use nproc=1 or nproc=Auto." % str(problems))
  else :
    print("""
 ******************************************************************
 INFO: Some parts of this job will make use of multiple processors:
 ******************************************************************

   nproc = %s

 Please ask your system administrator for advice about this, in particular if
 you run this job through a queuing system.
""" % str(nproc), file=log)
    return nproc

# FIXME should be more flexible on Windows
def get_processes(processes):
  """
  Determine number of processes dynamically: number of CPUs minus the current
  load average (with a minimum of 1).

  :param processes: default number of processes (may be None or Auto)
  :returns: actual number of processes to use
  """
  if (processes in [None, Auto]):
    if os.name == "nt":
      return 1
    from libtbx import introspection
    auto_adjust = (processes is Auto)
    processes = introspection.number_of_processors()
    if (auto_adjust):
      processes = max(ifloor(processes - os.getloadavg()[0]), 1)
  else :
    assert (processes > 0)
  return processes

from weakref import WeakValueDictionary as _
fixed_func_registry = _()

class fixed_func_proxy(object):
  """Implementation detail"""
  def __init__(self, key, func):
    self.key = key
    fixed_func_registry[key] = func

  def __call__(self, arg):
    key = self.key
    func = fixed_func_registry[key]
    assert func is not None
    return func(arg)

from itertools import count as _
fixed_func_registry_key_generator = _()

try: # cannot use detect_problem() here (hangs in pool.map())
  from multiprocessing.pool import Pool as multiprocessing_Pool
  # on macOS restore "fork" instead of new default of "spawn" on Python 3.8
  # https://bugs.python.org/issue33725
  # may need to re-evaluate if Python is built with macOS 10.13 SDK (or later)
  if sys.platform == 'darwin' and sys.hexversion >= 0x03080000:
    import multiprocessing
    multiprocessing.set_start_method('fork')
except Exception:
  multiprocessing_Pool = object

class Pool(multiprocessing_Pool):
  """Subclass of multiprocessing.Pool, used internally by pool_map."""
  def __init__(self,
        processes=None,
        initializer=None,
        initargs=(),
        maxtasksperchild=None,
        fixed_func=None):
    if (multiprocessing_Pool is object):
      mp_problem = detect_problem()
      assert mp_problem is not None
      raise RuntimeError(mp_problem)
    self.processes = get_processes(processes)
    if (fixed_func is not None):
      key = next(fixed_func_registry_key_generator)
      self.fixed_func_proxy = fixed_func_proxy(key, fixed_func)
    else:
      self.fixed_func_proxy = None
    init = super(Pool, self).__init__
    if (maxtasksperchild is Auto):
      maxtasksperchild = None
    if (maxtasksperchild is None):
      init(
        processes=processes,
        initializer=initializer,
        initargs=initargs)
    else:
      init(
        processes=processes,
        initializer=initializer,
        initargs=initargs,
        maxtasksperchild=maxtasksperchild) # New in Python 2.7

  def map_fixed_func(self, iterable, chunksize=None):
    '''
    Uses fixed_func as passed to the constructor.
    Avoids repeated pickling/unpickling of func, which can be rate-limiting
    if func is large and the amount of work per call is relatively small.
    '''
    assert self.fixed_func_proxy is not None
    return self.map(
      func=self.fixed_func_proxy,
      iterable=iterable,
      chunksize=chunksize)

def show_caught_exception(index, arg):
  print("CAUGHT EXCEPTION: (argument #%d)" % index)
  try:
    r = repr(arg)
  except: # intentional
    pass
  else:
    if (len(r) > 256):
      r = r[:127] + "..." + r[-126:]
    print("ARGUMENT LEADING TO EXCEPTION:", r)
  traceback.print_exc(file=sys.stdout)

class func_wrapper_simple_impl(object):
  """Implementation detail"""

  def __init__(O, options, func):
    O.options = options
    O.func = func

  def __call__(O, index_and_arg):
    assert len(index_and_arg) == 2
    index, arg = index_and_arg
    if (O.options.buffer_stdout_stderr):
      sys.stderr = sys.stdout = sio = StringIO()
    try:
      result = O.func(arg)
    except: # intentional
      result = None
      show_caught_exception(index, arg)
    if (O.options.buffer_stdout_stderr):
      return (sio.getvalue(), result)
    return result

class func_wrapper_simple(object):
  """Implementation detail"""

  def __init__(O, buffer_stdout_stderr=False):
    O.buffer_stdout_stderr = buffer_stdout_stderr

  def wrap(O, func):
    return func_wrapper_simple_impl(options=O, func=func)

class func_wrapper_sub_directories_impl(object):
  """Implementation detail"""

  def __init__(O, options, func):
    O.options = options
    O.func = func

  def __call__(O, index_and_arg):
    assert len(index_and_arg) == 2
    index, arg = index_and_arg
    sub_name = O.options.sub_name_format % index
    op = os.path
    if (op.exists(sub_name)):
      return (
        "sub-directory exists already: %s" % show_string(sub_name),
        None)
    try:
      os.makedirs(sub_name, mode=O.options.makedirs_mode)
    except: # intentional
      return (
        "cannot create sub-directory: %s" % show_string(sub_name),
        None)
    if (not op.isdir(sub_name)):
      return (
        "failure creating sub-directory: %s" % show_string(sub_name),
        None)
    initial_cwd = os.getcwd()
    try:
      try:
        os.chdir(sub_name)
      except: # intentional
        return (
          "cannot chdir to sub-directory: %s" % show_string(sub_name),
          None)
      def sub_log(): return show_string(op.join(sub_name, "log"))
      try:
        log = open("log", "w")
      except: # intentional
        return ("cannot open file: %s" % sub_log(), None)
      initial_out = sys.stdout
      initial_err = sys.stderr
      try:
        sys.stderr = sys.stdout = log
        try:
          result = O.func(arg)
        except: # intentional
          show_caught_exception(index, arg)
          return ("CAUGHT EXCEPTION: %s" % sub_log(), None)
      finally:
        sys.stdout = initial_out
        sys.stderr = initial_err
        log.close()
    finally:
      os.chdir(initial_cwd)
    return (None, result)

class func_wrapper_sub_directories(object):
  """Implementation detail"""

  def __init__(O, sub_name_format="mp%03d", makedirs_mode=0o777):
    assert isinstance(sub_name_format, str)
    s = sub_name_format
    if (s.find("%") < 0):
      i = s.find("#")
      if (i >= 0):
        c = s.count("#", i)
        if (i + c == len(s)):
          s = s[:i] + "%0" + str(c) + "d"
        else:
          i = -1
      if (i < 0):
        s += "%03d"
    sub_name_format = s
    assert len(sub_name_format) != 0
    assert len(sub_name_format % 0) != 0
    O.sub_name_format = sub_name_format
    O.makedirs_mode = makedirs_mode

  def wrap(O, func):
    return func_wrapper_sub_directories_impl(options=O, func=func)

def pool_map(
      processes=None,
      initializer=None,
      initargs=(),
      maxtasksperchild=Auto,
      func=None,
      fixed_func=None,
      iterable=None,
      args=None,
      chunksize=Auto,
      func_wrapper="simple",
      index_args=True,
      log=None,
      call_back_for_serial_run=None):
  """
  Parallelized map() using subclassed multiprocessing.Pool.  If func is not
  None, this function essentially calls the Pool's own map method; this means
  that both func and iterable/args must be pickle-able.  If fixed_func is not
  None, it will not be pickled but instead saved as an attribute of the Pool,
  which will be preserved after the fork() call.  Additional features include
  optional redirection of output and automatic process number determination.

  Note that because of the reliance on fork(), this function will run in serial
  on Windows, regardless of how many processors are available.

  :param processes: number of processes to spawn; if None or Auto, the
    get_processes() function will be used.
  :param func: target function (will be pickled)
  :param fixed_func: "fixed" target function, which will be be propagated to
    the child process when forked (instead of pickling)
  :param iterable: argument list
  :param args: same as iterable (alternate keyword)
  :param chunksize: number of arguments to process at once

  Examples
  --------
  >>> def f(x):
  ...   return some_long_running_method(x)
  ...
  >>> args = range(1000)
  >>> result = easy_mp.pool_map(
  ...   func=f,
  ...   args=args)
  ...
  >>> print len(result)
  ... 1000

  >>> class f_caller(object):
  ...   def __init__(self, non_pickleable_object):
  ...     self._obj = non_pickleable_object
  ...   def __call__(self, x):
  ...     return some_long_running_method(x, self._obj)
  ...
  >>> args = range(1000)
  >>> f = f_caller(processed_pdb_file)
  >>> result = easy_mp.pool_map(
  ...   fixed_func=f,
  ...   args=args)
  ...
  """
  assert [func, fixed_func].count(None) == 1
  assert [iterable, args].count(None) == 1
  assert ((call_back_for_serial_run is None) or
          hasattr(call_back_for_serial_run, "__call__"))
  if (isinstance(func_wrapper, str)):
    if (func_wrapper == "simple"):
      func_wrapper = func_wrapper_simple()
    else:
      if (func_wrapper == "buffer_stdout_stderr"):
        func_wrapper = func_wrapper_simple(buffer_stdout_stderr=True)
      elif (func_wrapper == "sub_directories"):
        func_wrapper = func_wrapper_sub_directories()
      elif (func_wrapper.startswith("sub_directories:")):
        func_wrapper = func_wrapper_sub_directories(
          sub_name_format=func_wrapper[16:])
      else:
        raise RuntimeError("Unknown func_wrapper keyword: %s" % func_wrapper)
      if (maxtasksperchild is Auto):
        maxtasksperchild = 1
      if (chunksize is Auto):
        chunksize = 1
  if (func_wrapper is not None):
    wrap = getattr(func_wrapper, "wrap", None)
    if (wrap is None):
      raise RuntimeError("func_wrapper must have a .wrap() method.")
    if (func is not None):
      func = wrap(func)
    else:
      fixed_func = wrap(fixed_func)
  processes = get_processes(processes)
  # XXX since we want to be able to call this function on Windows too, reset
  # processes to 1
  if os.name == "nt":
    processes = 1
  if (args is not None):
    iterable = args
    if (processes is not None):
      processes = min(processes, len(args))
  if (index_args):
    iterable = enumerate(iterable)
  if (log is not None):
    print("multiprocessing pool size:", processes, file=log)
    flush = getattr(log, "flush", None)
    if (flush is not None):
      flush()
    import time
    time_start = time.time()
  result = None
  # XXX this allows the function to be used even when parallelization is
  # not enabled or supported, which should keep calling code simpler.
  if (processes == 1) or (os.name == "nt"):
    result = []
    for args in iterable :
      if (func is not None):
        result.append(func(args))
      else :
        result.append(fixed_func(args))
      if (call_back_for_serial_run is not None):
        call_back_for_serial_run(result[-1])
  else :
    pool = Pool(
      processes=processes,
      initializer=initializer,
      initargs=initargs,
      maxtasksperchild=maxtasksperchild,
      fixed_func=fixed_func)
    if (chunksize is Auto):
      chunksize = None
    try:
      if (func is not None):
        result = pool.map(func=func, iterable=iterable, chunksize=chunksize)
      else:
        result = pool.map_fixed_func(iterable=iterable, chunksize=chunksize)
    finally:
      pool.close()
      pool.join()
  if (log is not None):
    from libtbx.utils import show_wall_clock_time
    show_wall_clock_time(seconds=time.time()-time_start, out=log)
  return result

del _

#-----------------------------------------------------------------------
# application support for parallelization across multiple cores or a
# queuing system (also Unix-only)
parallel_phil_str_base = """
nproc = 1
  .type = int
  .short_caption = Number of processes
  .style = bold renderer:draw_nproc_widget
technology = %s
  .type = choice
  .short_caption = Parallelization method
  .caption = %s
qsub_command = None
  .type = str
  .short_caption = qsub command
"""

parallel_methods = ["*multiprocessing", "sge", "lsf", "pbs", "condor", "slurm"]
parallel_captions = ["Multiprocessing", "Sun_Grid_Engine", "LSF", "PBS", "Condor", "SLURM"]

parallel_phil_str = parallel_phil_str_base % (
  " ".join(parallel_methods + ["threading"]),
  " ".join(parallel_captions + ["Threading"]))
parallel_phil_str_no_threading = parallel_phil_str_base % (
  " ".join(parallel_methods), " ".join(parallel_captions))


def single_argument(func):

  return func


class posiargs(object):

  def __init__(self, func):

    self.func = func


  def __call__(self, arg):

    return self.func( *arg )


class kwargs(object):

  def __init__(self, func):

    self.func = func


  def __call__(self, arg):

    return self.func( **arg )


class posi_and_kwargs(object):

  def __init__(self, func):

    self.func = func


  def __call__(self, arg):

    ( args, kwargs ) = arg
    return self.func( *args, **kwargs )


def parallel_map(
    func,
    iterable,
    iterable_type = single_argument,
    params=None,
    processes=1,
    method="multiprocessing",
    qsub_command=None,
    asynchronous=True,
    callback=None,
    preserve_order=True,
    preserve_exception_message=False,
    use_manager=False,
    stacktrace_handling = "ignore",
    break_condition = None):
  """
  Generic parallel map() implementation for a variety of platforms, including
  the multiprocessing module and supported queuing systems, via the module
  libtbx.queuing_system_utils.scheduling.  This is less flexible than pool_map
  above, since it does not provide a way to use a non-pickleable target
  function, but it provides a consistent API for programs where multiple
  execution methods are desired.  It will also work on Windows (if the method
  is multiprocessing or threading).

  Note that for most applications, the threading method will be constrained
  by the Global Interpreter Lock, therefore multiprocessing is prefered for
  parallelizing across a single multi-core system.

  See Computational Crystallography Newsletter 3:37-42 (2012) for details of
  the underlying method.

  :param func: target function (must be pickleable)
  :param iterable: list of arguments for func
  :param processes: number of processes/threads to start
  :param method: parallelization method (multiprocessing|threading|sge|lsf|pbs)
  :param qsub_command: command to submit queue jobs (optional)
  :param asynchronous: run queue jobs asynchronously
  :param preserve_exception_message: keeps original exception message
  :param preserve_order: keeps original order of results
  :param break_condition:  if break_condition(result) is True, break
  :returns: a list of result objects
  """
  if (params is not None):
    method = params.technology
    processes = params.nproc
    qsub_command = params.qsub_command

  from libtbx.utils import Sorry
  from libtbx.scheduling import SetupError

  if processes == 1 and "LIBTBX_FORCE_PARALLEL" not in os.environ:
    from libtbx.scheduling import mainthread
    creator = mainthread.creator

  else:
    from libtbx.scheduling import philgen
    from libtbx.scheduling import job_scheduler

    if method == "threading":
      technology = philgen.threading(
        capture_exception = preserve_exception_message,
        )
      jfactory = technology.jfactory()
      qfactory = technology.qfactory()[0]
      capacity = job_scheduler.limited(
        njobs = get_processes( processes = processes )
        )

    elif method == "multiprocessing":
      technology = philgen.multiprocessing(
        capture_stderr = preserve_exception_message,
        qtype = philgen.mp_managed_queue if use_manager else philgen.mp_fifo_queue,
        )
      jfactory = technology.jfactory()
      qfactory = technology.qfactory()[0]
      capacity = job_scheduler.limited(
        njobs = get_processes( processes = processes )
        )

    else:
      technology = philgen.cluster(
        asynchronous = asynchronous,
        capture_stderr = preserve_exception_message,
        )

      assert method in technology.platforms # perhaps something less intrusive

      try:
        jfactory = technology.jfactory( platform = method, command = qsub_command )

      except SetupError as e:
        raise Sorry(e)

      from libtbx.scheduling import file_queue
      qfactory = file_queue.qfactory()

      if processes is Auto or processes is None:
        capacity = job_scheduler.unlimited

      else:
        capacity = job_scheduler.limited( njobs = processes )

    creator = job_scheduler.creator(
      job_factory = jfactory,
      queue_factory = qfactory,
      capacity = capacity,
      )

  import libtbx.scheduling

  if stacktrace_handling == "ignore":
    sthandler = libtbx.scheduling.ignore

  elif stacktrace_handling == "excepthook":
    sthandler = libtbx.scheduling.excepthook

  elif stacktrace_handling == "decorate":
    sthandler = libtbx.scheduling.decorate

  else:
    raise Sorry("Unknown stacktrace handling method: %s" % stacktrace_handling)

  from libtbx.scheduling import parallel_for

  if callback is None:
    callback = lambda r: None

  results = []

  with libtbx.scheduling.holder( creator = creator, stacktrace = sthandler ) as manager:
    adfunc = iterable_type( func )

    try:
      pfi = parallel_for.iterator(
        calculations = ( ( adfunc, ( args, ), {} ) for args in iterable ),
        manager = manager,
        keep_input_order = preserve_order,
        )

      for ( calc, res ) in pfi:
        result = res()
        results.append( result )
        callback( result )
        if break_condition and break_condition(result):
          manager.terminate()
          return results

    except SetupError as e:
      raise Sorry(e)

    manager.shutdown()
    manager.join()

  return results



def multi_core_run( myfunction, argstuples, nproc, keep_input_order=False ):
  """
  Run myfunction on many cpu cores using multiprocessing.
  A simplified version of parallel_map() above

  myfunction: name of the function to be parallelised,
  argstuples: list of tuples of associated input arguments,
  nproc: number of cores to run on.
  keep_input_order: if True, the function returns once all child processes have completed and
                    results are in same order as the argstuples elements

  Both myfunction and its input arguments must be pickleable.

  Output is an iterator where each element is a tuple that contains:
  a tuple of arguments for one particular calculation with myfunction,
  the result of this calculation,
  the stacktrace if myfunction crashed

  Example:

  # define RunMyJob() in a file testjob.py
  def RunMyJob( foo, bar):
    import math
    return math.sqrt(foo)/bar

  # then one can start RunMyJob in parallel like:
  >>> import testjob
  >>> from libtbx import easy_mp
  >>>
  >>> argstuples = [( 3, 4), (2, 3) ] # define tuples of arguments
  >>>
  >>> for args, res, errstr in easy_mp.multi_core_run( testjob.RunMyJob, argstuples, 2):
  ...   print "arguments: %s \nresult: %s \nerrorstring: %s\n" %(args, res, errstr)
  ...
  arguments: (2, 3)
  result: 0.471404520791
  errorstring: None

  arguments: (3, 4)
  result: 0.433012701892
  errorstring: None

  >>>

  """
  from libtbx.scheduling import philgen
  from libtbx.scheduling import job_scheduler
  from libtbx.scheduling import parallel_for
  import libtbx.scheduling
  from libtbx.scheduling import stacktrace

  technology = philgen.multiprocessing(
    capture_stderr = True, # catch each individual error message and stack trace
    qtype = philgen.mp_managed_queue,
    )

  jfactory = technology.jfactory()
  qfactory = technology.qfactory()[0]
  capacity = job_scheduler.limited(
    njobs = get_processes( processes = nproc )
    )

  creator = job_scheduler.creator(
    job_factory = jfactory,
    queue_factory = qfactory,
    capacity = capacity,
    )

  manager = creator.create()
  pfi = parallel_for.iterator(
      calculations = ( ( myfunction, args, {} ) for args in argstuples ),
      manager = manager,
      keep_input_order = keep_input_order,
      )

  for i, ( calc, res ) in enumerate(pfi):
    result = None
    errstr =  None
    try:
      result = res()
    except Exception as e:
      tracestr = ""
      if stacktrace.exc_info()[1]:
        for inf in stacktrace.exc_info()[1]:
          tracestr += inf
      errstr = str(e) + "\n" + tracestr
    #calc[0] is the function name, calc[1] is the tuple of function arguments
    parmres = ( calc[1], result, errstr )

    if i >= len(argstuples)-1:
      manager.shutdown() # clean up once the last calculation has returned
      manager.join()
      creator.destroy( manager = manager )

    yield parmres # spit out results as they emerge



#  -------  SIMPLE INTERFACE TO MULTIPROCESSING -------------

#  For example of use, see phenix_regression/libtbx/tst_easy_mp.py

#  run_parallel

# Simple interface to run any target function in parallel, allowing
# specification of keyword inputs that may be different for each run

#  Class to just run a method. This is part of run_parallel below.

class run_anything(object):
  def __init__(self,kw_list=None,target_function=None):
    self.kw_list=kw_list
    self.target_function=target_function

  def __call__(self, i):
    kw=self.kw_list[i]
    return self.target_function(**kw)

def run_parallel(
   method='multiprocessing',  # multiprocessing, only choice for now
   qsub_command='qsub',       # queue command, not supported yet
   nproc=1,                   # number of processors to use
   target_function=None,      # the method to run
   kw_list=None,           # list of kw dictionaries for target_function
   preserve_order=True,
   break_condition = None,
   try_single_processor_on_failure = True,
   ):

  '''
  :param preserve_order: keeps original order of results
  :param break_condition:  if break_condition(result) is True, break
  :param try_single_processor_on_failure:  Try nproc=1 if nproc>1 fails
  '''
  n=len(kw_list)  # number of jobs to run, one per kw dict

  # Two ways to run:  directly or with parallel_map

  def run_directly(kw_list, target_function, n):
    results=[]
    ra=run_anything(kw_list=kw_list,target_function=target_function)
    for i in range(n):
      results.append(ra(i))
    return results

  def run_with_parallel_map(kw_list, target_function, n):
    from libtbx.easy_mp import parallel_map
    results=parallel_map(
      func=run_anything(target_function=target_function,kw_list=kw_list),
      iterable=range(n),
      method=method,
      processes=nproc,
      callback=None,
      preserve_exception_message=True, # 2016-08-17
      stacktrace_handling ="excepthook",
      qsub_command=qsub_command,
      use_manager=True,  #  Always use manager 2015-10-13 TT (sys.platform == "win32"))
      preserve_order=preserve_order,
      break_condition = break_condition)
    return results

  # Now actually run

  if nproc==1 or n<=1: # just run it for each case in list, no multiprocessing
    results = run_directly(kw_list, target_function, n)

  elif try_single_processor_on_failure:
    try:  # Try as is, then use nproc=1 if it fails for any reason
      results = run_with_parallel_map(kw_list, target_function, n)
    except Exception as e:
      results = run_directly(kw_list, target_function, n)

  else : # standard run, run outside of a try
    results = run_with_parallel_map(kw_list, target_function, n)

  return results

#  -------  END OF SIMPLE INTERFACE TO MULTIPROCESSING -------------

# --  VERY SIMPLE INTERFACE TO MULTIPROCESSING WITH LARGE FIXED OBJECTS --

def simple_parallel(**kw):

  """
  This simple_parallel interface allows you to run in parallel with
  a call that is very similar to one you would use for a simple iteration

  NOTE: all these multiprocessing methods work poorly if a
   large object (> 1 MB) is returned.  Better to write the object as a pickle
   to a unique file, pass the file name back, and read in the object afterwards.

Parameters:
  function:   the function to run
  iteration_list:  list of objects to pass, one at a time, to function
  nproc:  number of processors
  run_in_batches: If None or True, run nproc jobs, grouping as necessary
  log:  optional log stream
  verbose:  optional control of log stream
  any other kw items:  passed directly to function

Sample use:
  result_list = simple_parallel(
    function = run_something,        # function to run
    iteration_list = iteration_list,  # list of N values or objects that vary
    nproc = nproc,        # number of processors
    other_kw1 = other_kw1,  # any other keywords used by run_something
    other_kw2 = other_kw2,  # any other keywords used by run_something
    verbose = False,  # normal log stream
    log = log,            # pass log stream if used
     )

This will run N jobs of run_something, where run_something looks like:

def run_something(
    one_iteration = None,
    other_kw1 = None,
    other_kw2 = None,
    log = None):
  # do something with value and other_kw1, other_kw2
  result = do_something(one_iteration, other_kw1, other_kw2, log = log)
  return result


Example as simple iteration:

def run_something(value):
  return value * 2

def run_as_is(): # run in usual way
  iteration_list = [5,7,9]  # list of anything

  result_list = []
  for i in range(len(iteration_list)):
    result = run_something(iteration_list[i])
    result_list.append(result)
  return result_list

def run_parallel(): # run in parallel

  iteration_list = [5,7,9]  # list of anything

  from libtbx.easy_mp import simple_parallel
  result_list = simple_parallel(
    iteration_list = iteration_list,
    function = run_something,
    nproc = 4, )
  return result_list
  """

  run_in_batches = kw.get('run_in_batches',None)
  function = kw.get('function',None)
  iteration_list = kw.get('iteration_list',None)
  nproc = kw.get('nproc',None)
  run_info = kw.get('run_info',None)
  log = kw.get('log',None)
  verbose = kw.get('verbose',None)

  if function is not None: del kw['function']
  if run_in_batches is not None: del kw['run_in_batches']
  if iteration_list is not None: del kw['iteration_list']
  if nproc is not None: del kw['nproc']
  if log is not None: del kw['log']
  if run_info is not None: del kw['run_info']
  if 'verbose' in list(kw.keys()):
    del kw['verbose'] # never passed to function

  if function is not None and iteration_list is not None and nproc is not None:
    n_tot = len(list(iteration_list))

    end_number = -1
    if run_in_batches is None or run_in_batches:
      n_in_batch = n_tot//nproc
      if n_in_batch * nproc < n_tot:
        n_in_batch = n_in_batch + 1
      assert n_in_batch * nproc >= n_tot
      n_runs = nproc
    else:
      n_in_batch = 1
      n_runs = n_tot


    runs_to_carry_out = []
    for run_id in range(n_tot):
      start_number = end_number + 1
      end_number = min(n_tot-1, start_number + n_in_batch - 1)
      if end_number < start_number: continue
      runs_to_carry_out.append(group_args(
        run_id = run_id,
        start_number = start_number,
        end_number = end_number,
        ))

    kw_dict = kw.copy()
    kw_dict['function'] = function
    kw_dict['iteration_list'] = iteration_list
    if log is None:
      log = sys.stdout

    from libtbx.easy_mp import run_jobs_with_large_fixed_objects
    runs_carried_out = run_jobs_with_large_fixed_objects(
      nproc = nproc,
      verbose = verbose,
      kw_dict = kw_dict,
      run_info_list = runs_to_carry_out,
      job_to_run = simple_parallel,
      log = log)


    runs_carried_out = sorted(runs_carried_out,
      key = lambda r: r.start_number if r else None)
    result_list = []
    printed_something = False
    for result_info in runs_carried_out:
      if result_info and result_info.result and result_info.result.result_list:
        result = result_info.result
        for r in result.result_list:
          if r:
            result_list.append(r)
            if not printed_something:
              print (result.log_as_text, file = log)
              printed_something = True
    return result_list

  else:
    assert run_info is not None and iteration_list is not None
    kw_dict = kw.copy()

    # Determine if function has the kw "log"
    from libtbx.introspection import getfullargspec
    use_log = 'log' in getfullargspec(function).args
    if use_log: # capture the log if it is present in the function call
      kw_dict['log'] = log

    result_list = []
    for i in range(run_info.start_number, run_info.end_number + 1):
      result_list.append(function(iteration_list[i], **kw_dict))

    return group_args(
      group_args_type = 'runs %s to %s of %s' %(
        run_info.start_number, run_info.end_number, str(function)),
      result_list = result_list)

# --  END VERY SIMPLE INTERFACE TO MULTIPROCESSING WITH LARGE FIXED OBJECTS --

# --  SIMPLE INTERFACE TO MULTIPROCESSING WITH LARGE FIXED OBJECTS --

def run_jobs_with_large_fixed_objects(
       nproc = None,
       verbose = None,
       kw_dict = None,           # all the common kw for the function to run
       run_info_list = None,     # list of group_args, each with info of what
                                 # to do for one run
       job_to_run = None,   # the function to run
       multiprocessing_method = 'multiprocessing',  # how to run
       qsub_command='qsub',       # queue command,
       break_condition = None,
       try_single_processor_on_failure = True,
       log = sys.stdout):
  '''

    Run jobs in parallel containing large fixed object shared by all jobs

    The purposes of this interface to multiprocessing are: (1) to get around the
    pickling and duplication of large objects that occurs if the same object
    is passed to each sub-process, and (2) to allow passing model objects which
    cannot be pickled.

    NOTE: Your job_to_run should always return the smallest possible result
    object as a result. Anything very large (like a full-size density map)
    should be written to disk and a file name returned.  Models are ok to be
    returned (except possibly very large ones).

    Procedure to run any method (job_to_run) in parallel with a
    common set of keywords (kw_dict) and one group args for each run
    specifying what happens in that run (run_info_list)

    You should put all large constant objects in kw_dict.  These are passed
    to a fixed class that can be accessed by all the runs and that does not
    have to be pickled or duplicated (depends on the system).

    Put everything that changes between runs in run_info_list.

    The method "job_to_run" should accept all the arguments in kw_dict
    plus the keywords "run_info", "log", "verbose".  Your job_to_run should
    decide what to do based on the group_args object "run_info" that it gets.

    The method "job_to_run" should return a result group_args object

    Returns run_info list, with each run_info getting a .result with the
    result for that run.

    preserve_order: keeps original order of results
    break_condition:  if break_condition(result) is True, break
      where result is the returned object from a run
    try_single_processor_on_failure:  Try nproc=1 if nproc>1 fails

  '''

  index_list=[]
  for i in range(len(run_info_list)):
    index_list.append({'i':i})

  if nproc == 1 or verbose:
    local_log = log
  else:
    local_log = None
  from libtbx.easy_mp import run_parallel
  result_run_info_list = run_parallel(
     method = multiprocessing_method,
     nproc = nproc,
     qsub_command = qsub_command,
     break_condition = break_condition,
     try_single_processor_on_failure = try_single_processor_on_failure,
     target_function = run_one_job_as_class(
       kw_dict = kw_dict,
       job_to_run = job_to_run,
       log = local_log,
       run_info_list = run_info_list),
     preserve_order=False,
     kw_list = index_list)

  # Note log for each result is in run_info.result.log_as_text

  return result_run_info_list

class run_one_job_as_class:
  '''
    Class to hold large fixed objects and a set of small run_info objects
    specifying what to do for each run.  Returns a run_info object with
    the attribute "result" added containing the result
  '''

  def __init__(self,
      kw_dict,
      job_to_run,
      log,
      run_info_list):

    adopt_init_args(self, locals())

  def __call__(self, i):

    # Set up log so that it can be used in multiprocessing

    if self.log is None:
      log = StringIO()
      log_type = 'StringIO'
    else:
      log = self.log
      log_type = 'stream'

    # Run the i'th run_info now
    run_info = self.run_info_list[i]
    result = self.job_to_run(
      run_info = run_info,
      log = log,
      **self.kw_dict)

    # Save the log if not already written out

    if log_type == 'StringIO':
      result.log_as_text = log.getvalue() # save the log as text
    else:
      result.log_as_text = '' # already sent it to stream

    run_info.result = result  # this is what we are going to return

    #Note that result is pickleable so that it can be passed back
    # Make sure that result is small. Any large objects should be saved
    # to disk and a file name returned.

    return run_info

# --  END OF SIMPLE INTERFACE TO MULTIPROCESSING WITH LARGE FIXED OBJECTS --


 *******************************************************************************


 *******************************************************************************
libtbx/easy_pickle.py
"""
Utility functions for automatically opening and serializing a python object into
a file using the latest pickling protocol. Can optionally compress the output if
file_name ends with .gz. Also provides functions to read that object back.
"""

from __future__ import absolute_import, division, print_function

import os

from libtbx.str_utils import show_string
from libtbx import smart_open
import six
from six.moves import cPickle as pickle

def _open(file_name, mode):
  """
  Wraps libtbx.smart_open.

  Parameters
  ----------
  file_name : str
  mode : str

  Returns
  -------
  file
  """
  file_name = os.path.expanduser(file_name)
  try: return smart_open.file(file_name=file_name, mode=mode)
  except IOError as e:
    raise IOError("Cannot open pickle file %s (%s)" % (
      show_string(file_name), str(e)))

def dump(file_name, obj):
  """
  Wraps pickle.dump.

  Parameters
  ----------
  file_name : str
  obj : object

  Examples
  --------
  >>> from libtbx.easy_pickle import dump, load
  >>> dump("output.pkl.gz", [1, 2, 3])
  >>> print load("output.pkl.gz")
  [1, 2, 3]
  """
  with _open(file_name, "wb") as f:
    p = pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)
  return p

def dumps(obj):
  """
  Wraps pickle.dumps.

  Parameters
  ----------
  obj : object

  Returns
  -------
  str
  """
  return pickle.dumps(obj, pickle.HIGHEST_PROTOCOL)

def load(file_name, faster_but_using_more_memory=True):
  """
  Wraps pickle.load.

  Parameters
  ----------
  file_name : str
  faster_but_using_more_memory : bool, optional
      Optionally read the entirety of a file into memory before converting it
      into a python object.

  Returns
  -------
  object
  """
  if (faster_but_using_more_memory):
    if six.PY2:
      with _open(file_name, "rb") as f:
        s = f.read()
      try:
        return pickle.loads(s)
      except ValueError as e:
        from libtbx.utils import Sorry
        import sys
        raise Sorry(
         "Please check that you are not using an old version "+
          "and reading a file from a new version.  "+
         "(The file %s " %(file_name) + "was saved with a version of Python "+
         "that is not supported in this version (%s): %s)" %(
          sys.version, str(e)))

    with _open(file_name, "rb") as f:
      s = f.read()
    return pickle.loads(s, encoding='bytes')
  with _open(file_name, "rb") as f:
    p = pickle.load(f)
  return p

def loads(string):
  """
  Wraps pickle.loads.

  Parameters
  ----------
  string : str

  Returns
  -------
  object

  Examples
  --------
  >>> from libtbx.easy_pickle import dumps, loads
  >>> print loads(dumps([1, 2, 3])
  [1, 2, 3]
  """
  return pickle.loads(string)

def dump_args(*args, **keyword_args):
  """
  Dumps args and keyword_args to args.pickle.
  """
  dump("args.pickle", (args, keyword_args))

def fix_py2_pickle_orig(p):
  '''
  Fix pickles from Python 2
  Original version

  Parameters
  ----------
  p: pickle

  Returns
  -------
  p: the fixed pickle
  '''
  from collections.abc import Mapping, MutableSequence
  from cctbx.crystal import symmetry
  from cctbx.sgtbx import empty, space_group
  from cctbx.xray.structure import structure
  from iotbx.pdb.hierarchy import root
  skip_types = (empty, root, space_group, structure, symmetry)
  if isinstance(p, Mapping):
    for key in list(p.keys()):
      if isinstance(key, bytes):
        str_key = key.decode('utf8')
        p[str_key] = p[key]
        del p[key]
        key = str_key
      if isinstance(p[key], skip_types) or callable(p[key]):
        pass
      else:
        # print(key, type(p[key]), p[key])
        p[key] = fix_py2_pickle_orig(p[key])
  if isinstance(p, MutableSequence):
    for i in range(len(p)):
      p[i] = fix_py2_pickle_orig(p[i])

  if hasattr(p, '__dict__') and '__dict__' in dir(p):
    p.__dict__ = fix_py2_pickle_orig(p.__dict__)
  # miller array object
  if hasattr(p, '_info') and hasattr(p._info, 'labels'):
    p._info.labels = fix_py2_pickle_orig(p._info.labels)

  if isinstance(p, bytes):
    p = p.decode('utf8')

  return p

def fix_py2_pickle(p):
  '''
  Fix pickles from Python 2
  Version 3

  Parameters
  ----------
  p: pickle

  Returns
  -------
  p: the fixed pickle

  Comments:
  ---------

  '''
  from mmtbx.model.model import get_hierarchy_and_run_hierarchy_method
  from collections.abc import Mapping, MutableSequence
  from libtbx import group_args
  from scitbx_array_family_flex_ext import std_string
  if isinstance(p, get_hierarchy_and_run_hierarchy_method):
    return p
  if isinstance(p, group_args):
    p = p() # now it is a dict
    for key in list(p.keys()):    # fix the key
      if isinstance(key, bytes):
        str_key = key.decode('utf8')
        p[str_key] = p[key]
        del p[key]
        key = str_key
      p[key] = fix_py2_pickle(p[key])
    # convert to dict, fix, convert back to group args
    p = group_args(**p)

  elif isinstance(p, bytes):
    p = p.decode('utf8')

  elif isinstance(p, MutableSequence):
    for i in range(len(p)):
      p[i] = fix_py2_pickle(p[i])

  elif isinstance(p, Mapping):
    for key in list(p.keys()):    # fix the key
      if isinstance(key, bytes):
        str_key = key.decode('utf8')
        p[str_key] = p[key]
        del p[key]
        key = str_key
      p[key] = fix_py2_pickle(p[key])


  elif isinstance(p,tuple):
    p = tuple(fix_py2_pickle(list(p)))

  elif isinstance(p, std_string):
    new_p = std_string()
    for x in p:
      new_p.append(fix_py2_pickle(x))
    p = new_p

  # Classes like mmtbx.monomer_library.cif_types.chem_mod_angle remain here
  elif hasattr(p, '__dict__'):
    for key in list(p.__dict__.keys()):    # fix the key
      if isinstance(key, bytes):
        str_key = key.decode('utf8')
        p.__dict__[str_key] = p.__dict__[key]
        del p.__dict__[key]
        key = str_key
      if not key.startswith("__"):
        p.__dict__[key] = fix_py2_pickle(p.__dict__[key])

  else:
    # We have no idea...skip conversion (should never be here)
    pass
  return p


 *******************************************************************************


 *******************************************************************************
libtbx/easy_profile.py
from __future__ import absolute_import, division, print_function
from six.moves import range
class easy_profile(object):
  """ cProfile.Profile easy-to-use wrapper """

  def __init__(self, func, file_name, func_name, line, runs=1):
    """ Profiling of the callable func.
    file_name, func_name, line shall tell where func is defined.
    runs is the number of calls which will be performed
    """
    import cProfile
    self.prof = cProfile.Profile()
    self.func = func
    self.file_name, self.__name__, self.line = file_name, func_name, line
    self.runs = runs

  def time(self, *args, **kwds):
    """ Time spent per-call in self.func(*args, **kwds) """
    for i in range(self.runs):
      self.prof.runcall(self.func, *args, **kwds)
    self.prof.create_stats()
    for (file_name, line, func), data in self.prof.stats.items():
      if self.file_name is not None:
        if not file_name.endswith(self.file_name): continue
      if self.__name__ is not None:
        if func != self.__name__: continue
      if self.line is not None:
        if line != self.line: continue
      break
    else:
      return None
    calls = data[0]
    cumulative = data[3]
    t = cumulative/calls
    return t


 *******************************************************************************


 *******************************************************************************
libtbx/easy_run.py
from __future__ import absolute_import, division, print_function

import os
import subprocess
import sys
import threading
import signal
from six.moves import range


def _show_lines(lines, out, prefix):
  if (out is None): out = sys.stdout
  for line in lines:
    print(prefix+line, file=out)

def macos_dyld():
  '''
  Convenience function for returning either DYLD_LIBRARY_PATH or
  DYLD_FALLBACK_LIBRARY_PATH (for conda environments)
  '''
  dyld_options = ['DYLD_LIBRARY_PATH', 'DYLD_FALLBACK_LIBRARY_PATH']
  for dyld in dyld_options:
    dyld_path = os.environ.get(dyld)
    if (dyld_path is not None):
      return '%s="%s"' % (dyld, dyld_path)
  return 'DYLD_LIBRARY_PATH= '

class fully_buffered_base(object):

  def format_errors_if_any(self):
    assert not self.join_stdout_stderr
    if (len(self.stderr_lines) != 0):
      msg = ["child process stderr output:"]
      msg.append("  command: " + repr(self.command))
      for line in self.stderr_lines:
        msg.append("  " + line)
      return "\n".join(msg)
    if (self.return_code != 0):
      return "non-zero return code: %s"%(self.return_code)
    return None

  def raise_if_errors(self, Error=RuntimeError):
    assert not self.join_stdout_stderr
    msg = self.format_errors_if_any()
    if (msg is not None):
      raise Error(msg)
    return self

  def raise_if_output(self, show_output_threshold=10, Error=RuntimeError):
    def start_msg():
      result = ["unexpected child process output:"]
      result.append("  command: " + repr(self.command))
      return result
    if (self.stdout_buffer is not None):
      if (len(self.stdout_buffer) != 0):
        msg = start_msg()
        msg.append("  length of output: %d bytes" % len(self.stdout_buffer))
        raise Error("\n".join(msg))
    elif (len(self.stdout_lines) != 0):
      msg = start_msg()
      for line in self.stdout_lines[:show_output_threshold]:
        msg.append("  " + line)
      n = len(self.stdout_lines)
      if (n > show_output_threshold):
        if (n <= show_output_threshold+2):
          for line in self.stdout_lines[show_output_threshold:n]:
            msg.append("  " + line)
        else:
          msg.append("  ...")
          msg.append("  remaining %d lines omitted."
            % (n-show_output_threshold))
      raise Error("\n".join(msg))
    return self

  def raise_if_errors_or_output(self, Error=RuntimeError):
    self.raise_if_errors(Error=Error)
    self.raise_if_output(Error=Error)
    return self

  def show_stderr(self, out=None, prefix=""):
    _show_lines(lines=self.stderr_lines, out=out, prefix=prefix)

  def show_stdout(self, out=None, prefix=""):
    assert self.stdout_lines is not None
    _show_lines(lines=self.stdout_lines, out=out, prefix=prefix)

class fully_buffered_simple(fully_buffered_base):
  """\
Executes command, sends stdin_lines (str or sequence), then reads
stdout_lines first, stderr_lines second (if join_stdout_stderr
is False).

The constructor may deadlock if the I/O buffers are too small to allow
the blocking write and reads in the given sequence. Specifically,
stdin_lines may be too big, or there may be too many stderr_lines,
but there can be any number of stdout_lines. The tests below are
known to work under Mac OS X, Windows XP, IRIX, and Tru64 Unix with
stdin_lines up to 1000000, stderr_lines up to 500. I.e. this simple
implementation should cover most practical situations.
  """

  def __init__(self,
        command,
        stdin_lines=None,
        join_stdout_stderr=False,
        stdout_splitlines=True,
        bufsize=-1):
    self.command = command
    self.join_stdout_stderr = join_stdout_stderr
    if (join_stdout_stderr):
      child_stdin, child_stdout = os.popen4(command, "t", bufsize)
      child_stderr = None
    else:
      child_stdin, child_stdout, child_stderr = os.popen3(command,"t",bufsize)
    if (stdin_lines is not None):
      if (not isinstance(stdin_lines, str)):
        stdin_lines = '\n'.join(stdin_lines)
        if (len(stdin_lines) != 0):
          stdin_lines += '\n'
      child_stdin.write(stdin_lines)
    child_stdin.close()
    if (stdout_splitlines):
      self.stdout_buffer = None
      self.stdout_lines = child_stdout.read().splitlines()
    else:
      self.stdout_buffer = child_stdout.read()
      self.stdout_lines = None
    if (child_stderr is not None):
      self.stderr_lines = child_stderr.read().splitlines()
    else:
      self.stderr_lines = []
    child_stdout.close()
    if (child_stderr is not None):
      child_stderr.close()
    self.return_code = None

class fully_buffered_subprocess(fully_buffered_base):
  "This implementation is supposed to never block."

  def __init__(self,
        command,
        timeout=None,
        stdin_lines=None,
        join_stdout_stderr=False,
        stdout_splitlines=True,
        bufsize=-1):
    def target(process, lines, result):
      o, e = process.communicate(input=lines)
      result[0] = o
      result[1] = e

    self.command = command
    self.join_stdout_stderr = join_stdout_stderr
    if (not isinstance(command, str)):
      command = subprocess.list2cmdline(command)
    # Timeout functionality based on:
    # https://stackoverflow.com/questions/1191374/using-module-subprocess-with-timeout
    # https://stackoverflow.com/questions/4789837/how-to-terminate-a-python-subprocess-launched-with-shell-true
    if (sys.platform == 'darwin'):   # bypass SIP on OS X 10.11
      command = ('%s exec ' % macos_dyld()) + command
    if (stdin_lines is not None):
      if (not isinstance(stdin_lines, str)):
        stdin_lines = '\n'.join(stdin_lines)
        if (len(stdin_lines) != 0):
          stdin_lines += '\n'
    if (join_stdout_stderr):
      stderr = subprocess.STDOUT
    else:
      stderr = subprocess.PIPE
    p = subprocess.Popen(
      args=command,
      shell=True,
      bufsize=bufsize,
      stdin=subprocess.PIPE,
      stdout=subprocess.PIPE,
      stderr=stderr,
      universal_newlines=True,
      close_fds=(sys.platform != 'win32'),
      preexec_fn=os.setsid if sys.platform != 'win32' else None)
    if timeout is not None:
      if sys.platform != 'win32':
        r = [None, None]
        thread = threading.Thread(target=target, args=(p, stdin_lines, r))
        thread.start()
        thread.join(timeout)
        if thread.is_alive():
          os.killpg(os.getpgid(p.pid), signal.SIGTERM)
          thread.join()
        o, e = r[0], r[1]
      else: # sys.platform == 'win32'
        # don't respect timeout for now
        o, e = p.communicate(input=stdin_lines)
    else:
      o, e = p.communicate(input=stdin_lines)
    if (stdout_splitlines):
      self.stdout_buffer = None
      self.stdout_lines = o.splitlines()
    else:
      self.stdout_buffer = o
      self.stdout_lines = None
    if (join_stdout_stderr):
      self.stderr_lines = []
    else:
      self.stderr_lines = e.splitlines()
    self.return_code = p.returncode

fully_buffered = fully_buffered_subprocess

def go(command, stdin_lines=None,join_stdout_stderr=True):
  return fully_buffered(
    command=command,
    stdin_lines=stdin_lines,
    join_stdout_stderr=join_stdout_stderr)

def call(command):
  """
  Wraps subprocess.call to run a command.

  Parameters
  ----------
  command : str

  Returns
  -------
  int
      Exit code of subprocess.

  Examples
  --------
  >>> from libtbx.easy_run import call
  >>> ret = call("echo 1")
  1
  >>> print ret
  0
  """
  for s in [sys.stdout, sys.stderr]:
    flush = getattr(s, "flush", None)
    if (flush is not None): flush()
  if (sys.platform == 'darwin'):   # bypass SIP on OS X 10.11
    command = ('%s exec ' % macos_dyld()) + command
  return subprocess.call(args=command, shell=True)

def exercise(args=None):
  from six.moves import cStringIO as StringIO
  if (args is None): args = sys.argv[1:]
  verbose = "--verbose" in args
  #
  if ("--simple" in args):
    fb = fully_buffered_simple
  else:
    fb = fully_buffered
  #
  for command in ["echo hello world", ("echo", "hello", "world")]:
    for result in [fb(command=command).raise_if_errors(),
                   fb(command=command, join_stdout_stderr=True),
                   go(command=command)]:
      if verbose: print(result.stdout_lines)
      assert result.stdout_lines == ["hello world"]
  #
  if (os.path.isfile("/bin/ls")):
    for command in ["/bin/ls /bin", ("/bin/ls", "/bin")]:
      result = fb(command=command).raise_if_errors()
      if verbose: print(result.stdout_lines)
      assert "ls" in result.stdout_lines
  if (os.path.isfile("/usr/bin/wc")):
    for command in ["/usr/bin/wc -l", ("/usr/bin/wc", "-l")]:
      result = fb(command=command).raise_if_errors()
      if verbose: print(result.stdout_lines)
      assert [s.strip() for s in result.stdout_lines] == ["0"]
      result = fb(command=command, stdin_lines=["hello"]) \
        .raise_if_errors()
      if verbose: print(result.stdout_lines)
      assert [s.strip() for s in result.stdout_lines] == ["1"]
      result = fb(command=command, stdin_lines=["hello", "world"]) \
        .raise_if_errors()
      if verbose: print(result.stdout_lines)
      assert [s.strip() for s in result.stdout_lines] == ["2"]
      result = fb(command=command, stdin_lines="hello\nworld\nbye\n") \
        .raise_if_errors()
      if verbose: print(result.stdout_lines)
      assert [s.strip() for s in result.stdout_lines] == ["3"]
  #
  if (os.name == "nt"):
    result = fb(command="dir").raise_if_errors()
    if verbose: print(result.stdout_lines)
    assert len(result.stdout_lines) > 0
    windir = os.environ.get("windir", None)
    if (windir is not None and windir.find(" ") < 0):
      result = fb(command="dir "+windir).raise_if_errors()
      if verbose: print(result.stdout_lines)
      assert len(result.stdout_lines) > 0
  #
  pyexe = sys.executable
  assert pyexe.count('"') == 0
  pyexe = '"' + pyexe + '"'
  if (os.name == "nt"):
    pyexe = "call " + pyexe
  #
  if ("PYTHONPATH" in os.environ):
    if (not hasattr(os, "unsetenv")):
      os.environ["PYTHONPATH"] = ""
    else:
      del os.environ["PYTHONPATH"]
  if (os.name == "nt"):
    result = fb(command="set").raise_if_errors()
  elif (os.path.isfile("/usr/bin/printenv")):
    result = fb(command="/usr/bin/printenv").raise_if_errors()
  else:
    result = None
  if (result is not None):
    if verbose: print(result.stdout_lines)
    for line in result.stdout_lines:
      assert not line.startswith("PYTHONPATH") or line == "PYTHONPATH="
  #
  for stdout_splitlines in [True, False]:
    result = fb(
      command="%s -V" % pyexe,
      stdout_splitlines=stdout_splitlines)
    # python -V outputs to stdout or stderr depending on version
    # https://bugs.python.org/issue18338
    if (len(result.stderr_lines) > 0):
      if verbose: print(result.stderr_lines)
      assert result.stderr_lines[0].startswith(
        "Python " + sys.version.split()[0])
      if (stdout_splitlines):
        assert result.stdout_buffer is None
        assert result.stdout_lines == []
      else:
        assert result.stdout_buffer == ""
        assert result.stdout_lines is None
    else:
      if verbose: print(result.stdout_lines)
      if (stdout_splitlines):
        assert result.stdout_buffer is None
        assert result.stdout_lines[0].startswith(
          "Python " + sys.version.split()[0])
      else:
        assert result.stdout_buffer.startswith(
          "Python " + sys.version.split()[0])
        assert result.stdout_lines is None
  result = go(command="%s -V" % pyexe)
  if verbose: print(result.stdout_lines)
  assert result.stdout_lines[0].startswith("Python " + sys.version.split()[0])
  result = fb(
    command='%s -c "print(3+4)"' % pyexe).raise_if_errors()
  if verbose: print(result.stdout_lines)
  assert result.stdout_lines == ["7"]
  command = command = pyexe \
    + ' -c "import sys; print(len(list(filter(bool, sys.stdin.read().splitlines()))))"'
  result = fb(command=command).raise_if_errors()
  if verbose: print(result.stdout_lines)
  assert result.stdout_lines == ["0"]
  result = fb(command=command, stdin_lines=["hello"]) \
    .raise_if_errors()
  if verbose: print(result.stdout_lines)
  assert result.stdout_lines == ["1"]
  result = fb(command=command, stdin_lines=["hello", "world"]) \
    .raise_if_errors()
  if verbose: print(result.stdout_lines)
  assert result.stdout_lines == ["2"]
  result = fb(command=command, stdin_lines="hello\nworld\nbye\n") \
    .raise_if_errors()
  if verbose: print(result.stdout_lines)
  assert result.stdout_lines == ["3"]
  if ("--quick" in args):
    n_lines_o = 10000
  else:
    n_lines_o = 1000000
  if (fb is fully_buffered_simple):
    n_lines_e = 500 # Windows blocks if this value is greater than 701
  else:
    n_lines_e = 10000
  result = fb(
    command=command, stdin_lines=[str(i) for i in range(n_lines_o)]) \
    .raise_if_errors()
  if verbose: print(result.stdout_lines)
  assert result.stdout_lines == [str(n_lines_o)]
  command = pyexe \
    + ' -c "import sys; sys.stderr.write(sys.stdin.read())"'
  result = fb(command=command, stdin_lines="Hello\nWorld\nBye\n") \
    .raise_if_output()
  s = StringIO()
  result.show_stderr(out=s, prefix="%(")
  if verbose: sys.stdout.write(s.getvalue())
  assert s.getvalue() == """\
%(Hello
%(World
%(Bye
"""
  cat_command = command = pyexe \
    + ' -c "import sys; sys.stdout.write(sys.stdin.read())"'
  result = fb(command=command, stdin_lines="hello\nworld\nbye\n") \
    .raise_if_errors()
  s = StringIO()
  result.show_stdout(out=s, prefix=">:")
  if verbose: sys.stdout.write(s.getvalue())
  assert s.getvalue() == """\
>:hello
>:world
>:bye
"""
  result = fb(
    command=command, stdin_lines=[str(i) for i in range(n_lines_o)]) \
    .raise_if_errors()
  result.stdout_lines = list(filter(bool, result.stdout_lines))
  if verbose: print(result.stdout_lines[:5], result.stdout_lines[-5:])
  assert len(result.stdout_lines) == n_lines_o
  assert result.stdout_lines[:5] == ["0","1","2","3","4"]
  assert result.stdout_lines[-5:] == [str(s)
    for s in range(n_lines_o-5, n_lines_o)]
  command = pyexe \
    + ' -c "import sys; sys.stderr.write(sys.stdin.read())"'
  result = fb(
    command=command, stdin_lines=[str(i) for i in range(n_lines_e,0,-1)])
  assert len(result.stdout_lines) == 0
  result.stderr_lines = list(filter(bool, result.stderr_lines))
  if verbose: print(result.stderr_lines[:5], result.stderr_lines[-5:])
  assert len(result.stderr_lines) == n_lines_e
  assert result.stderr_lines[:5] == [str(s)
    for s in range(n_lines_e, n_lines_e-5, -1)]
  assert result.stderr_lines[-5:] == ["5","4","3","2","1"]
  command = pyexe + "; ".join((''' -c "\
import sys, os
lines = sys.stdin.read()
sys.stdout.write(lines)
sys.stdout.flush()
lines = list(filter(bool, lines.splitlines()))[:%d]
lines.reverse()
nl = chr(%d)
sys.stderr.write(nl.join(lines)+nl)
sys.stderr.flush()"''' % (n_lines_e, ord("\n"))).splitlines())
  result = fb(
    command=command, stdin_lines=[str(i) for i in range(n_lines_o)])
  result.stdout_lines = list(filter(bool, result.stdout_lines))
  result.stderr_lines = list(filter(bool, result.stderr_lines))
  if verbose: print(result.stdout_lines[:5], result.stdout_lines[-5:])
  if verbose: print(result.stderr_lines[:5], result.stderr_lines[-5:])
  assert len(result.stdout_lines) == n_lines_o
  assert result.stdout_lines[:5] == ["0","1","2","3","4"]
  assert result.stdout_lines[-5:] == [str(s)
    for s in range(n_lines_o-5, n_lines_o)]
  assert len(result.stderr_lines) == n_lines_e
  assert result.stderr_lines[:5] == [str(s)
    for s in range(n_lines_e-1, n_lines_e-6, -1)]
  assert result.stderr_lines[-5:] == ["4","3","2","1","0"]
  result = go(
    command=command, stdin_lines=[str(i) for i in range(n_lines_o)])
  result.stdout_lines = list(filter(bool, result.stdout_lines))
  if verbose: print(result.stdout_lines[:5], result.stdout_lines[-5:])
  assert len(result.stdout_lines) == n_lines_o + n_lines_e
  assert result.stdout_lines[:5] == ["0","1","2","3","4"]
  assert result.stdout_lines[-5:] == ["4","3","2","1","0"]
  #
  try: fb(command="C68649356116218352").raise_if_errors()
  except RuntimeError as e:
    if verbose: print(e)
    # Just check for RuntimeError; there are now additional
    # specific error messages.
    pass
    # assert str(e).startswith("child process stderr output:\n")
  else: raise Exception_expected
  #
  for stdout_splitlines in [True, False]:
    for n,b in [(10,20),(11,23),(12,26),(13,29)]:
      try:
        fb(
          command=cat_command,
          stdin_lines=[str(i) for i in range(n)],
          stdout_splitlines=stdout_splitlines).raise_if_output()
      except RuntimeError as e:
        if verbose: print(e)
        assert str(e).startswith("unexpected child process output:\n")
        if (stdout_splitlines):
          if (n != 13):
            assert str(e).endswith(str(n-1))
          else:
            assert str(e).endswith("  remaining 3 lines omitted.")
        else:
          assert str(e).endswith("  length of output: %d bytes" % b)
      else: raise Exception_expected
  #
  fb(command=cat_command).raise_if_errors_or_output()
  #
  result = fb(command=["nslookup", "localhost"])
  if verbose:
    print(result.stdout_lines)
    print(result.stderr_lines)
  #
  while ("--forever" in args): pass
  #
  print("OK")

if (__name__ == "__main__"):
  exercise()


 *******************************************************************************


 *******************************************************************************
libtbx/env_config.py
from __future__ import absolute_import, division, print_function
import libtbx.path
from libtbx.auto_build import regenerate_module_files
from libtbx.auto_build.installer_utils import call
from libtbx.path import relocatable_path, absolute_path
from libtbx.str_utils import show_string
from libtbx.utils import detect_binary_file, to_str
from libtbx import adopt_init_args
import platform
import shutil
from six.moves import zip, map
from six.moves import cPickle as pickle

import io
import os
import re
import site
import sys
import sysconfig
op = os.path

if os.environ.get('LIBTBX_WINGIDE_DEBUG'):
  import wingdbstub # special import

qnew = " -Qnew"

if (os.name == "nt"):
  exe_suffix = ".exe"
else:
  exe_suffix = ""

default_write_full_flex_fwd_h = sys.platform.startswith("irix")
default_msvc_arch_flag = ["None", "SSE2"][int(os.name == "nt")]
default_build_boost_python_extensions = True
default_enable_openmp_if_possible = False
default_enable_boost_threads = True
default_enable_cuda = False
default_enable_kokkos = False
default_opt_resources = False
default_enable_cxx11 = False
default_cxxstd = None
default_use_conda = False

def is_64bit_architecture():
  # this appears to be most compatible (hat tip: James Stroud)
  # http://stackoverflow.com/questions/1405913/how-do-i-determine-if-my-python-shell-is-executing-in-32bit-or-64bit-mode-on-os
  import struct
  nbits = 8 * struct.calcsize("P")
  return (nbits == 64)

def using_conda_python():
  '''
  Return True if Python is from conda, False otherwise.
  This check is independent of being in an active conda environment.
  https://stackoverflow.com/questions/47608532/how-to-detect-from-within-python-whether-packages-are-managed-with-conda?noredirect=1&lq=1
  '''
  conda_prefix = sys.prefix
  if (sys.platform == 'darwin'):
    if ('python.app' in conda_prefix):
      conda_prefix = conda_prefix.split('python.app')[0]
  return os.path.exists(os.path.join(conda_prefix, 'conda-meta'))

def get_conda_prefix():
  '''
  Return the root directory of the conda environment. This function will
  try to figure out the root directory if the environment is not active.
  A special case exists for macOS where the framework package (python.app)
  is used for GUI programs.

  A RuntimeError is raised if the root directory of the conda environment
  cannot be determined.
  '''
  conda_prefix = sys.prefix
  if (using_conda_python()):
    if (sys.platform == 'darwin'):  # case where python.app is used
      if ('python.app' in conda_prefix):
        conda_prefix = conda_prefix.split('python.app')[0]
  return conda_prefix

def unique_paths(paths):
  hash = set()
  result = []
  for path in paths:
    try: path_normcase = abs(path.normcase())
    except AttributeError: path_normcase = op.normcase(path)
    if (path_normcase in hash): continue
    hash.add(path_normcase)
    result.append(path)
  return result

def darwin_shlinkcom(env_etc, env, lo, dylib):
  if env_etc.compiler.startswith('darwin_'):
    if (env_etc.mac_cpu == "powerpc" or env_etc.compiler == "darwin_gcc"):
      dylib1 = "-ldylib1.o"
    else :
      dylib1 = " ".join(env_etc.shlinkflags)
    if (    env_etc.gcc_version is not None
        and env_etc.gcc_version >= 40201):
      opt_m = ""
    else:
      opt_m = " -m"
    shlinkcom = [
      "ld -dynamic%s -headerpad_max_install_names -r -bind_at_load -o %s $SOURCES" %
        (opt_m, lo),
      "$SHLINK -nostartfiles -undefined dynamic_lookup -Wl,-dylib"
        " %s -o %s %s" % (dylib1, dylib, lo)]
    if (env_etc.mac_os_use_dsymutil):
      shlinkcom.append('dsymutil "%s"' % dylib)
    env.Replace(SHLINKCOM=shlinkcom)

def get_darwin_gcc_build_number(gcc='gcc'):
  from libtbx import easy_run
  gcc_version = (easy_run.fully_buffered(command='%s --version' % gcc)
                         .raise_if_errors()
                         .stdout_lines[0].strip())
  m = re.search(r"Apple Inc. build (\d+)\)", gcc_version)
  if m is None: return None
  try:
    return int(m.group(1))
  except ValueError:
    return None

def is_llvm_compiler(gcc='gcc'):
  from libtbx import easy_run
  try:
    gcc_version = (easy_run.fully_buffered(command='%s --version' % gcc)
                           .raise_if_errors()
                           .stdout_lines[0].strip())
    return "llvm" in gcc_version
  except Exception:
    return False

def get_gcc_version(command_name="gcc"):
  # run command in shell subprocess
  from libtbx import easy_run
  buffer = easy_run.fully_buffered(
    command="%s -dumpversion" % command_name)
  # if something went wrong `buffer.stdout_lines` might have len=0
  if len(buffer.stdout_lines) < 1:
      return None

  major_minor_patchlevel = buffer.stdout_lines[0].split(".")
  # output is not a valid version format:
  if (len(major_minor_patchlevel) not in [1,2,3]):
    return None
  # parse version number
  num = []
  for fld in major_minor_patchlevel:
    try: i = int(fld)
    except ValueError:
      return None
    num.append(i)
  # substitute missing minor and patchlevel for gcc7 on Ubuntu18
  if (len(num) == 1): num.append(0); num.append(0)
  if (len(num) == 2): num.append(0) # substitute missing patchlevel

  # format version numbers
  return ((num[0]*100)+num[1])*100+num[2]

def get_hostname():
  try:
    import socket
    return socket.gethostname()
  except Exception:
    return None

def get_ldd_output(target=None):
  if (target is None): target = sys.executable
  from libtbx import easy_run
  return easy_run.go(command="ldd '%s'" % target).stdout_lines

def get_hp_ux_acc_version():
  from libtbx import easy_run
  run_out = easy_run.go(command="aCC -V").stdout_lines
  version = run_out
  if (len(version) > 0):
    version = version[0].strip().split()
  # aCC: HP aC++/ANSI C B3910B A.06.01 [Jan 05 2005]
  if (len(version) >= 6 and version[5].startswith("A.")):
    return version[5]
  raise RuntimeError(
    "\n  ".join(["Unknown C++ compiler (aCC -V):"] + run_out))

def get_mipspro_version():
  from libtbx import easy_run
  run_out = easy_run.go(command="CC -version").stdout_lines
  version = run_out
  if (len(version) > 0):
    version = version[0].strip().split()
  if (version[:3] == "MIPSpro Compilers: Version ".split()):
    if (version[3].startswith("7.3")):
      return "73"
    elif (version[3].startswith("7.4")):
      return "74"
  raise RuntimeError(
    "\n  ".join(["Unknown MIPSpro compiler (CC -version):"] + run_out))

def python_include_path():
  if (sys.platform == "win32"):
    include_path = sys.prefix + r"\include"
  else:
    include_path = sys.prefix + "/include/python%d.%d" % sys.version_info[:2]
  include_path = libtbx.path.norm_join(include_path)

  # I believe the above code to be unnecessary.
  # If this flags up no problems then remove the code above and
  # the assertion test directly below in a month or so.
  if op.isdir(include_path):
    sysconfig_path = sysconfig.get_paths()['include']
    if sys.platform == "win32":
      include_path = include_path.lower()
      sysconfig_path = sysconfig_path.lower()
    assert include_path == sysconfig_path, \
        "%s != %s" % (include_path, sysconfig_path)

  include_path = sysconfig.get_paths()['include']
  if not op.isdir(include_path):
    try:  # conda environment
      conda_prefix = get_conda_prefix()
      include_path = os.path.join(conda_prefix, 'include',
                                  'python%d.%dm' % sys.version_info[:2])
      if not op.isdir(include_path):
        include_path = include_path[:-1]
    except RuntimeError:
      pass
  if not op.isdir(include_path):
    raise RuntimeError("Cannot locate Python's include directory: %s" % include_path)
  return include_path

def highlight_dispatcher_include_lines(lines):
  m = max([len(line) for line in lines])
  if (os.name == "nt"):
    lines.insert(0, "@REM " + "-"*(m-5))
  else :
    lines.insert(0, "# " + "-"*(m-2))
  lines.append(lines[0])

def source_specific_dispatcher_include(pattern, source_file):
  try:
    with io.open(abs(source_file), encoding='utf-8', errors='ignore') as fh:
      source_lines = to_str(fh.read()).splitlines()
  except IOError: return []
  if (os.name == "nt"):
    lines = ["@REM lines marked " + pattern]
  else :
    lines = ["# lines marked " + pattern]
  for line in source_lines:
    pattern_begin = line.find(pattern)
    if (pattern_begin >= 0):
      pattern_end = pattern_begin + len(pattern)
      to_include = line[pattern_end:]
      if (not to_include[:1].isalnum()):
        if (to_include.startswith(" ")):
          to_include = to_include[1:]
        lines.append(to_include)
  highlight_dispatcher_include_lines(lines)
  return lines

def patch_windows_dispatcher(
      dispatcher_exe_file_name,
      binary_string,
      place_holder,
      actual_value):
  place_holder_start = binary_string.find(place_holder)
  if (place_holder_start < 0):
    raise RuntimeError('Place holder "%s" not found in file %s' % (
      place_holder, dispatcher_exe_file_name))
  place_holder_end = binary_string.find("\0", place_holder_start)
  assert len(actual_value) <= place_holder_end - place_holder_start
  return binary_string[:place_holder_start] \
       + actual_value + "\0" \
       + binary_string[place_holder_start+len(actual_value)+1:]

def write_do_not_edit(f, win_bat=False):
  if (win_bat): s = "@rem"
  else:         s = "#"
  print(s+' THIS IS AN AUTOMATICALLY GENERATED FILE.', file=f)
  print(s+' DO NOT EDIT! CHANGES WILL BE LOST.', file=f)

def open_info(path, mode="w", info="   "):
  print(info, path.basename())
  try: return path.open(mode)
  except IOError as e:
    raise RuntimeError(str(e))

class common_setpaths(object):

  def __init__(self, env, shell, suffix):
    self.env = env
    self.shell = shell
    self.suffix = suffix
    self.s = open_info(env.under_build("setpaths%s.%s" % (suffix, shell),
                                       return_relocatable_path=True))
    if (suffix == "_debug"):
      self.u = open_info(env.under_build("unsetpaths.%s" % shell,
                                         return_relocatable_path=True))
    else:
      self.u = open(os.devnull, 'w')

  def all_and_debug(self):
    if (self.suffix == "_debug"):
      self.update_path("PYTHONPATH",
        os.pathsep.join([
          self.path_script_value(_) for _ in self.env.pythonpath]))
      self.update_path(
        self.env.ld_library_path_var_name(),
        os.pathsep.join([self.path_script_value(_)
          for _ in self.env.ld_library_path_additions()]))

  def set_unset_vars(self):
    if (self.suffix != ""):
      for var_name,path in self.env.var_name_and_build_or_dist_path_pairs():
        if (var_name == "LIBTBX_BUILD"): continue
        self.setenv(var_name=var_name, val=self.path_script_value(path))

class unix_setpaths(common_setpaths):

  def __init__(self, env, shell, suffix):
    assert shell in ["sh", "csh"]
    common_setpaths.__init__(self, env, shell, suffix)
    if (self.shell == "sh"):
      self._setenv = "%s="
    else:
      self._setenv = "setenv %s "

  def path_script_value(self, path_obj):
    return path_obj.sh_value()

  def setenv(self, var_name, val):
    if (self.shell == "sh"):
      print('%s="%s"' % (var_name, val), file=self.s)
      print('export %s' % var_name, file=self.s)
      print('unset %s' % var_name, file=self.u)
    else:
      print('setenv %s "%s"' % (var_name, val), file=self.s)
      print('unsetenv %s' % var_name, file=self.u)

  def update_path(self, var_name, val, var_name_in=None):
    if (var_name_in is None): var_name_in = var_name
    for f,action in [(self.s, "prepend"), (self.u, "delete")]:
      if (self.shell == "sh"):
        print('if [ -n "$%s" ]; then' % var_name_in, file=f)
        print('  LIBTBX_TMPVAL="$%s"' % var_name_in, file=f)
        print('else', file=f)
        print('  LIBTBX_TMPVAL=', file=f)
        print('fi', file=f)
        print('export LIBTBX_TMPVAL', file=f)
        fmt = \
          '''%s`libtbx.path_utility %s LIBTBX_TMPVAL "%s" < /dev/null`'''
      else:
        print('if ($?%s) then' % var_name_in, file=f)
        print('  setenv LIBTBX_TMPVAL "$%s"' % var_name_in, file=f)
        print('else', file=f)
        print('  unsetenv LIBTBX_TMPVAL', file=f)
        print('endif', file=f)
        fmt = \
          '''%s"`libtbx.path_utility %s LIBTBX_TMPVAL '%s' < /dev/null`"'''
      print(fmt % (self._setenv % var_name, action, val), file=f)
      if (self.shell == "sh"):
        if (f is self.s):
          print('export %s' % var_name, file=f)
        print('if [ "$%s" = "L_I_B_T_B_X_E_M_P_T_Y" ]; then unset %s; fi' % (
          var_name, var_name), file=f)
      else:
        print('if ("$%s" == "L_I_B_T_B_X_E_M_P_T_Y") unsetenv %s' % (
          var_name, var_name), file=f)

class windows_setpaths(common_setpaths):

  def __init__(self, env, suffix):
    common_setpaths.__init__(self, env, "bat", suffix)

  def path_script_value(self, path_obj):
    return path_obj.bat_value()

  def setenv(self, var_name, val):
    print('@set %s=%s' % (var_name, val), file=self.s)
    print('@set %s=' % var_name, file=self.u)

  def update_path(self, var_name, val, var_name_in=None):
    if (var_name_in is None): var_name_in = var_name
    fmt = '''\
@for /F "delims=" %%%%i in ('libtbx.path_utility %s %s "%s"') do @set %s=%%%%i'''
    for f,action in [(self.s, "prepend"), (self.u, "delete")]:
      print(fmt % (
        action,
        var_name_in,
        val,
        var_name), file=f)
      print('@if "%%%s%%" == "L_I_B_T_B_X_E_M_P_T_Y" @set %s=' % (
        var_name, var_name), file=f)

def _windows_pathext():
  result = os.environ.get("PATHEXT", "").lower().split(os.pathsep)
  for ext in [".py", ".exe", ".bat"]:
    if (ext not in result):
      result.insert(0, ext)
  return result

if os.name == "nt":
  windows_pathext = _windows_pathext()

def remove_or_rename(path):
  assert path is not None
  if not isinstance(path, str):
    path = abs(path)
  if op.isfile(path):
    try: os.remove(path)
    except OSError:
      try: os.remove(path+".old")
      except OSError: pass
      try: os.rename(path, path+".old")
      except OSError: pass

# Constant used in class environment.write_bin_sh_dispatcher -----------------

_SHELLREALPATH_CODE = '''
# ----------------------------------------------------------------------------
# The shellrealpath function resolves an absolute physical path of its
# first argument and stores it in a global shell variable RESULT.
# The function returns nonzero for unreadable or invalid symlinks
# and resets the RESULT to an empty string.

shellrealpath() {
    local ORGDIR="$PWD"
    local TARGET="$1"
    RESULT=""
    # This test fails for a symlink loop.  We can do without resolution
    # of symlinks that point to existing unreadable files.
    [ -r "$TARGET" ] || return $?
    # Check if the readlink command exists.
    type readlink >/dev/null || return $?
    while true; do
        cd "$(dirname "$TARGET")"
        TARGET="$(basename "$TARGET")"
        if [ -L "$TARGET" ]; then
            TARGET="$(readlink "$TARGET")"
            continue
        fi
        RESULT="$(pwd -P)/$TARGET"
        break
    done
    cd "$ORGDIR"
}
# ----------------------------------------------------------------------------
'''

# ----------------------------------------------------------------------------

class environment:

  def __init__(self, build_path):
    self.python_version_major_minor = sys.version_info[:2]
    self.build_path = absolute_path(build_path)
    self.manage_python_version_major_minor()
    self.reset_dispatcher_support()
    self.set_derived_paths()
    self.python_exe = self.as_relocatable_path(sys.executable)
    self.installed = False
    self.installed_modules = []  # used to track installed modules in local env
    self.installed_order = []
    # sanity checks
    assert self.python_exe.isfile()
    assert self.python_exe.access(os.X_OK)

    self.read_command_version_suffix()
    # the following are modules explicitly specified on the command-line
    # --only reset the list and --exclude prunes from it
    self.explicitly_requested_modules = set()
    self.build_options = None
    self.repository_paths = []
    self.command_line_redirections = {}
    self.reset_module_registry()
    self.scons_dist_path = None
    self.pythonpath = []
    self.relocatable = True

  def raise_python_version_incompatible(self, prev_pvmm=None):
    if (prev_pvmm is None):
      prev_pvmm = "%d.%d" % self.python_version_major_minor
    raise RuntimeError("Python version incompatible with this build:\n"
      + "  Build directory: %s\n" % show_string(abs(self.build_path))
      + "  Python version used initially: %s\n" % prev_pvmm
      + "  Python version in use now:     %d.%d" % sys.version_info[:2])

  def manage_python_version_major_minor(self):
    path = self.build_path / "lib"
    if not path.isdir():
      path.makedirs()
    path /= "PYTHON_VERSION_MAJOR_MINOR"
    pvmm = "%d.%d" % self.python_version_major_minor
    if not path.isfile():
      path.open("w").write("""\
# DO NOT EDIT THIS FILE UNDER ANY CIRCUMSTANCE!
# The version number below is purely to insure against accidental use
# of another Python version when re-configuring an existing build.
# To use a different Python version, initialize a new build directory
# with the libtbx/configure.py command.
%s
""" % pvmm)
    else:
      prev_pvmm = path.open().read().splitlines()
      if (len(prev_pvmm) == 0):
        prev_pvmm = None
      else:
        prev_pvmm = prev_pvmm[-1].strip()
      if (prev_pvmm != pvmm):
        self.raise_python_version_incompatible(prev_pvmm=prev_pvmm)

  def reset_dispatcher_support(self):
    self._dispatcher_precall_commands = None

  def reset_module_registry(self):
    self.module_list = []
    self.module_dict = {}
    self.module_dist_paths = {}
    self.missing_for_build = set()
    self.missing_for_use = set()
    self.missing_optional = set()

  def is_ready_for_build(self):
    return True
    #return (len(self.missing_for_build) == 0)

  def as_relocatable_path(self, path):
    if isinstance(path, libtbx.path.path_mixin): return path
    return relocatable_path(self.build_path, path, resolve_symlinks=False)

  def set_derived_paths(self):
    r = self.as_relocatable_path
    self.bin_path     = r("bin")
    self.exe_path     = r("exe")
    self.lib_path     = r("lib")
    self.include_path = r("include")

  def check_installed_env(self, function, *args, **kwargs):
    """
    Loads the installed environment, if available, and runs the function
    in that environment. This is used in the local environment to check
    the installed environment.
    """
    installed_env = get_installed_env()
    if installed_env is not None and not self.installed:
      return getattr(installed_env, function)(*args, **kwargs)
    return None

  def check_local_env(self, function, *args, **kwargs):
    """
    Loads the local environment, if available, and runs the function
    in that environment. This is used in the installed environment to
    check the local environment.
    """
    local_env = get_local_env()
    if local_env is not None and self.installed:
      return getattr(local_env, function)(*args, **kwargs)
    return None

  def get_installed_module_path(self, name):
    """
    Returns the path to the installed path of a module. The path may not
    always be stored in the installed environment. None is returned if
    the module is not installed.
    """
    module_path = None
    installed_env = get_installed_env()
    if installed_env is not None:
      for p in installed_env.repository_paths:
        installed_path = os.path.join(abs(p), name)
        if os.path.isdir(installed_path):
          module_path = installed_path
          break
    return module_path

  def module_is_installed(self, name):
    """
    Returns True if module is in installed environment, False otherwise
    """
    module_path = self.get_installed_module_path(name)
    return module_path is not None

  def under_root(self, path, return_relocatable_path=False):
    return abs(self.build_path / '..' / path)

  def under_base(self, path, return_relocatable_path=False):
    result = self.build_path / '..' / 'conda_base' / path
    if self.installed:
      result = self.bin_path.anchor / path
    elif not self.build_options.use_conda:
      result = self.build_path / '..' / 'base' / path
    if not return_relocatable_path:
      result = abs(result)
    return result

  def under_build(self, path, return_relocatable_path=False):
    result = self.as_relocatable_path(path)
    if return_relocatable_path:
      return result
    else:
      return abs(result)

  def under_dist(self, module_name, path, default=KeyError, test=None,
                 return_relocatable_path=False):
    # check installed environment first
    result = self.check_installed_env('_under_dist', module_name, path, None, test, return_relocatable_path)
    if result is None:
      result = self.get_installed_module_path(module_name)
      if result is not None:
        result = self.as_relocatable_path(result) / path
        if not return_relocatable_path:
          result = abs(result)
    if result is not None:
      return result
    # check current environment
    result = self._under_dist(module_name, path, None, test, return_relocatable_path)
    if result is not None:
      return result
    # then check local environment
    result = self.check_local_env('_under_dist', module_name, path, default, test, return_relocatable_path)
    return result

  def _under_dist(self, module_name, path, default=KeyError, test=None,
                  return_relocatable_path=False):
    if (default is KeyError):
      result = self.module_dist_paths[module_name] / path
    else:
      mdp = self.module_dist_paths.get(module_name)
      if (mdp is None): return default
      result = mdp / path
    if (test is None or test(abs(result))):
      if return_relocatable_path:
        return result
      else:
        return abs(result)
    return None

  def dist_path(self, module_name, default=KeyError,
                return_relocatable_path=False):
    # check installed environment first
    result = self.check_installed_env('_dist_path', module_name, None, return_relocatable_path)
    if result is None:
      result = self.get_installed_module_path(module_name)
      if result is not None:
        result = self.as_relocatable_path(result)
        if not return_relocatable_path:
          result = abs(result)
    if result is not None:
      return result
    # check current environment
    result = self._dist_path(module_name, None, return_relocatable_path)
    if result is not None:
      return result
    # then check local environment
    result = self.check_local_env('_dist_path', module_name, default, return_relocatable_path)
    return result

  def _dist_path(self, module_name, default=KeyError,
                 return_relocatable_path=False):
    if (default is KeyError):
      result = self.module_dist_paths[module_name]
    else:
      result = self.module_dist_paths.get(module_name, default)
    if (isinstance(result, relocatable_path) and not return_relocatable_path):
      result = abs(result)
    return result

  def has_module(self, name):
    # check installed environment first
    result = self.check_installed_env('_has_module', name)
    if result:
      return result
    # check current environment
    result = self._has_module(name)
    if result:
      return result
    # then check local environment
    result = self.check_local_env('_has_module', name)
    return result

  def _has_module(self, name):
    return name in self.module_dist_paths

  def require_module(self, name, error=RuntimeError):
    if (not self.has_module(name)):
      build_path = self.build_path
      from libtbx import introspection
      nproc = introspection.number_of_processors()
      raise error("""\
The %(name)s module is needed but not configured.
Run:
  cd %(build_path)s
  libtbx.configure %(name)s
  libtbx.scons -j %(nproc)d
Wait for the command to finish, then try again.""" % vars())

  def dist_paths(self, return_relocatable_path=False):
    for module in self.module_list:
      for dist_path in module.dist_paths_active():
        if return_relocatable_path:
          yield dist_path
        else:
          yield abs(dist_path)

  def var_name_and_build_or_dist_path_pairs(self):
    yield ("LIBTBX_BUILD", self.build_path)
    for module in self.module_list:
      for name,path in module.name_and_dist_path_pairs():
        yield (name.upper()+"_DIST", path)

  def set_os_environ_all_dist(self):
    for module in self.module_list:
      for name,path in module.name_and_dist_path_pairs():
        os.environ[name.upper()+"_DIST"] = abs(path)

  def clear_bin_directory(self):
    if not self.bin_path.isdir(): return
    buffer = []
    have_libtbx_command = False
    for file_name in self.bin_path.listdir():
      if (    not have_libtbx_command
          and file_name.lower().startswith("libtbx.")):
        have_libtbx_command = True
      path = self.bin_path / file_name
      if path.isfile():
        buffer.append(path)
    if (len(buffer) != 0):
      if (not have_libtbx_command):
        raise RuntimeError("""Existing "bin" sub-directory safety-guard:
  A "bin" sub-directory exists already in the current working directory,
  but it does not contain any "libtbx." commands. Therefore the current
  working directory does not appear to be an existing libtbx-managed
  build directory. To resolve this problem:
    - If this command was accidentally run in the wrong directory,
      change to the correct directory.
    - Remove the "bin" subdirectory, then run this command again.""")
      #
      for path in buffer:
        remove_or_rename(path)

  def write_command_version_suffix(self):
    assert self.command_version_suffix is not None
    path = self.under_build("command_version_suffix")
    try: f = open(path, "w")
    except IOError:
      raise RuntimeError(
        'Cannot write command_version_suffix file: "%s"' % path)
    print(self.command_version_suffix, file=f)

  def read_command_version_suffix(self):
    path = self.build_path / "command_version_suffix"
    if not path.isfile():
      self.command_version_suffix = None
    else:
      try:
        self.command_version_suffix = path.open().read().strip()
      except IOError:
        raise RuntimeError(
          'Cannot read command_version_suffix file: "%s"' % path)

  def register_module(self, dependent_module, module):
    if (dependent_module is None):
      self.module_list.append(module)
    else:
      for dependent_index,registered_module in enumerate(self.module_list):
        if (registered_module is dependent_module): break
      else: raise RuntimeError(
        "Internal error: dependent_module not in module_list.")
      self.module_list.insert(dependent_index, module)
    self.module_dict[module.name] = module
    for name,path in module.name_and_dist_path_pairs():
      self.module_dist_paths[name] = path

  def raise_not_found_in_repositories(self, message):
    if (isinstance(message, str)): message = [message]
    else: message = list(message)
    message.append("  Repository directories searched:")
    for path in self.repository_paths:
      message.append("    %s" % show_string(abs(path)))
    raise RuntimeError("\n".join(message))

  def listdir_in_repositories(self, test=None):
    for path in self.repository_paths:
      for name in path.listdir():
        if (test is None or test(abs(path / name))):
          yield path, name

  def match_in_repositories(self,
        relative_path_pattern,
        test=op.isdir,
        optional=True,
        must_be_unique=True):
    compiled_pattern = re.compile(relative_path_pattern)
    all_matches = []
    for path,name in self.listdir_in_repositories(test=test):
      if (compiled_pattern.match(name) is not None):
        if (len(all_matches) > 0 and all_matches[-1][0] != path):
          break
        all_matches.append((path, name))
    if (len(all_matches) == 0):
      if (not optional):
        self.raise_not_found_in_repositories(
          message="Cannot locate: %s" % show_string(relative_path_pattern))
      return None
    all_matches.sort()
    if (len(all_matches) != 1):
      if (must_be_unique):
        message = ["Multiple matches for search pattern %s:" %
          show_string(relative_path_pattern)]
        message.append("  Repository directory: %s" %
          show_string(all_matches[0][0]))
        for path,name in all_matches:
          message.append('    %s' % show_string(name))
        raise RuntimeError("\n".join(message))
    return libtbx.path.norm_join(*all_matches[0])

  def find_in_repositories(self,
        relative_path,
        test=op.isdir,
        optional=True,
        return_relocatable_path=False):
    # check installed environment first
    result = self.check_installed_env(
      '_find_in_repositories', relative_path, test, True, return_relocatable_path)
    if result is not None:
      return result
    # check current environment
    result = self._find_in_repositories(relative_path, test, True, return_relocatable_path)
    if result is not None:
      return result
    # then check local environment
    result = self.check_local_env(
      '_find_in_repositories', relative_path, test, optional, return_relocatable_path)
    return result

  def _find_in_repositories(self,
        relative_path,
        test=op.isdir,
        optional=True,
        return_relocatable_path=False):
    assert len(relative_path) != 0
    for path in self.repository_paths:
      result = path / relative_path
      if test is None or test(abs(result)):
        if return_relocatable_path:
          return result
        else:
          return abs(result)
    if (not optional):
      self.raise_not_found_in_repositories(
        message="Cannot locate: %s" % show_string(relative_path))
    return None

  def find_dist_path(self, module_name, optional=False,
                     return_relocatable_path=False):
    result = None

    if module_name=='amber': return result # because amber_adaptbx is not an adapter

    # check installed environment first
    result = self.check_installed_env('_find_dist_path', module_name, True, return_relocatable_path)
    if result is not None:
      return result
    # check current environment
    result = self._find_dist_path(module_name, True, return_relocatable_path)
    if result is not None:
      return result
    # then check local environment
    result = self.check_local_env('_find_dist_path', module_name, optional, return_relocatable_path)
    return result

  def _find_dist_path(self, module_name, optional=False,
                      return_relocatable_path=False):
    dist_path = self.command_line_redirections.get(module_name, None)
    if (dist_path is not None):
      return dist_path.self_or_abs_if(return_relocatable_path)
    dist_path = self.find_in_repositories(relative_path=module_name,
                                          return_relocatable_path=True)
    if (dist_path is not None):
      return dist_path.self_or_abs_if(return_relocatable_path)
    trial_module = module(env=self, name=module_name)
    mate_name = trial_module.names[1]
    if (mate_name != module_name):
      if (self.find_in_repositories(relative_path=mate_name,
                                    return_relocatable_path=True) is not None):
        dist_path = self.match_in_repositories(
          relative_path_pattern="%s(?!_%s)" % (
            module_name, trial_module.mate_suffix))
        if (dist_path is not None):
          return dist_path.self_or_abs_if(return_relocatable_path)
    if (not optional):
      self.raise_not_found_in_repositories(
        message="Module not found: %s" % module_name)
    return None

  def process_module(self, dependent_module, module_name, optional):
    dist_path = self.find_dist_path(module_name, optional=optional)
    if (dist_path is None): return False
    if self.module_is_installed(module_name):
      print("{module_name} is already installed".format(module_name=module_name))
      installed_env = get_installed_env()
      if module_name in installed_env.module_dict:
        self.installed_modules.append(installed_env.module_dict[module_name])
      else:
        installed_module = module(env=self, name=module_name, dist_path=dist_path)
        self.installed_modules.append(installed_module)
      return True
    new_module = module(env=self, name=module_name, dist_path=dist_path)
    new_name_normcase = op.normcase(new_module.name)
    for name in self.module_dict:
      if (op.normcase(name) == new_name_normcase): return True
    new_module.find_mate()
    new_module.process_libtbx_config()
    self.register_module(dependent_module=dependent_module, module=new_module)
    new_module.process_dependencies()
    return True

  def add_repository(self, path):
    path = self.as_relocatable_path(path)
    if path not in self.repository_paths:
      self.repository_paths.append(path)

  def process_args(self, pre_processed_args):
    command_line = pre_processed_args.command_line
    self.no_bin_python = command_line.options.no_bin_python
    for path in pre_processed_args.repository_paths:
      if not op.isabs(path):
        path = abs(self.build_path / path)
      self.add_repository(path=path)
    module_names = []
    installed_env = get_installed_env()
    for module_name in command_line.args:
      if (len(module_name) == 0): continue # ignore arguments like ""
      if (module_name == ".."):
        raise RuntimeError('Invalid module name: ".."')
      if (module_name == "."): module_name = "libtbx"
      if (module_name in self.command_line_redirections):
        del self.command_line_redirections[module_name]
      elif (module_name.count("=") == 1
            and self.find_dist_path(module_name, optional=True) is None):
        module_name, redirection = module_name.split("=")
        dist_path = relocatable_path(
          self.build_path, op.expandvars(redirection))
        if not dist_path.isdir():
          raise RuntimeError(
            'Invalid command line redirection:\n'
            '  module name = "%s"\n'
            '  redirection = "%s"\n'
            '  resulting target = "%s"' % (
              module_name, redirection, dist_path))
        self.command_line_redirections[module_name] = dist_path
      # remove any trailing dir separators
      module_name = module_name.rstrip("/\\")
      module_names.append(module_name)
    if (pre_processed_args.warm_start):
      self.explicitly_requested_modules |= set(module_names)
      if (not command_line.options.only):
        excludes = []
        if (command_line.options.exclude):
          excludes = command_line.options.exclude.split(",")
        self.explicitly_requested_modules -= set(excludes)
        for module in self.module_list:
          if (not module.name in excludes):
            module_names.append(module.name)
      else:
        self.explicitly_requested_modules = set(module_names)
    else:
      self.explicitly_requested_modules = set(module_names)
      self.build_options = build_options(
        compiler=command_line.options.compiler,
        mode=command_line.options.build,
        warning_level=command_line.options.warning_level,
        precompile_headers=command_line.options.precompile_headers,
        static_libraries=command_line.options.static_libraries,
        static_exe=command_line.options.static_exe,
        scan_boost=command_line.options.scan_boost,
        write_full_flex_fwd_h=command_line.options.write_full_flex_fwd_h,
        boost_python_no_py_signatures
          =command_line.options.boost_python_no_py_signatures,
        boost_python_bool_int_strict
          =command_line.options.boost_python_bool_int_strict,
        enable_openmp_if_possible
          =command_line.options.enable_openmp_if_possible,
        enable_boost_threads
          =command_line.options.enable_boost_threads,
        enable_cuda=command_line.options.enable_cuda,
        enable_kokkos=command_line.options.enable_kokkos,
        use_conda=command_line.options.use_conda,
        opt_resources=command_line.options.opt_resources,
        use_environment_flags=command_line.options.use_environment_flags,
        force_32bit=command_line.options.force_32bit,
        msvc_arch_flag=command_line.options.msvc_arch_flag,
        enable_cxx11=command_line.options.enable_cxx11,
        cxxstd=command_line.options.cxxstd,
        skip_phenix_dispatchers=command_line.options.skip_phenix_dispatchers)
      self.build_options.get_flags_from_environment()
      # if an installed environment exists, override with build_options
      # from installed environment
      if installed_env is not None:
        self.build_options = installed_env.build_options
      if (self.build_options.use_conda):
        get_conda_prefix()
      if (command_line.options.command_version_suffix is not None):
        self.command_version_suffix = \
          command_line.options.command_version_suffix
        self.write_command_version_suffix()
    if (command_line.options.build_boost_python_extensions is not None):
      self.build_options.build_boost_python_extensions \
        = command_line.options.build_boost_python_extensions
    self.reset_module_registry()
    module_names.insert(0, "libtbx")

    # check for installed environment and remove installed modules
    if installed_env is not None and not self.installed:
      module_set = set(module_names)
      installed_module_names = set([module.name for module in self.installed_modules])
      for module_name in module_names:
        dist_path = installed_env.get_installed_module_path(module_name)
        if module_name in installed_env.module_dict \
          or dist_path is not None:
          try:
            module_set.remove(module_name)
            if module_name not in installed_module_names \
              and module_name != 'boost':
              from libtbx.env_config import module
              if dist_path is not None:
                dist_path = installed_env.as_relocatable_path(dist_path)
              installed_module = module(env=self, name=module_name, dist_path=dist_path)
              self.installed_modules.append(installed_module)
              installed_module_names.add(module_name)
          except (KeyError, ValueError):
            pass
      module_names = list(module_set)
      if len(module_names) == 0:
        print("All modules have already been installed. No new configuration is necessary.")
        sys.exit()

    for module_name in module_names:
      self.process_module(
        dependent_module=None, module_name=module_name, optional=False)
    self.scons_dist_path = self.find_dist_path("scons", optional=True)
    if self.scons_dist_path is None:
      # try to use SCons in Python installation
      try:
        import SCons
      except ImportError:
        pass
      else:
        self.scons_dist_path = self.as_relocatable_path(sys.prefix)
    if installed_env is not None and not self.installed:
      self.path_utility = installed_env.under_dist(
        "libtbx", "command_line/path_utility.py",
        return_relocatable_path=True)
    else:
      self.path_utility = self.under_dist(
        "libtbx", "command_line/path_utility.py",
        return_relocatable_path=True)
    assert self.path_utility.isfile()

  def dispatcher_precall_commands(self):
    if (self._dispatcher_precall_commands is None):
      lines = []
      self._dispatcher_precall_commands = lines
    return self._dispatcher_precall_commands

  def write_dispatcher_include_template(self):
    if (os.name == "nt"):
      print("    dispatcher_include_template.bat")
      f = self.under_build("dispatcher_include_template.bat",
                           return_relocatable_path=True).open("w")
      cp = "@REM"
    else :
      print("    dispatcher_include_template.sh")
      f = self.under_build("dispatcher_include_template.sh",
                           return_relocatable_path=True).open("w")
      cp = "#"
    print(cp+" include at start", file=f)
    print(cp+"   Commands to be executed at the start of the", file=f)
    print(cp+"   auto-generated dispatchers in bin.", file=f)
    print(cp+"", file=f)
    print(cp+" include before command", file=f)
    print(cp+"   Commands to be executed before the target command", file=f)
    print(cp+"   is called by the auto-generated dispatchers in bin.", file=f)
    print(cp+"", file=f)
    print(cp+" To see how the dispatchers work, look at an example:", file=f)
    print(cp+"   %s" % show_string(self.under_build("bin/libtbx.help")), file=f)
    print(cp+"", file=f)
    f.close()

  def reset_dispatcher_bookkeeping(self):
    self._dispatcher_registry = {}
    self._dispatcher_include_at_start = []
    self._dispatcher_include_before_command = []
    include_files = []
    for file_name in self.build_path.listdir():
      path = self.under_build(file_name, return_relocatable_path=True)
      if not path.isfile(): continue
      if (    file_name.startswith("dispatcher_include")
          and ((file_name.endswith(".sh") and os.name != "nt") or
               (file_name.endswith(".bat") and os.name == "nt"))
          and file_name not in ["dispatcher_include_template.sh",
                                "dispatcher_include_template.bat"]):
        include_files.append(path)
    include_files.sort()
    for path in include_files:
      print("Processing: %s" % show_string(abs(path)))
      lines = path.open().read().splitlines()
      lines_at_start = []
      lines_before_command = []
      buffer = lines_before_command
      for line in lines:
        l = " ".join(line.split()).lower()
        if (l.startswith("#include ") or l.startswith("REM include")):
          l = "# " + l[1:]
        if   (l in ["# include at start", "REM include at start"]):
          buffer = lines_at_start
        elif (l in ["# include before command", "REM include before command"]):
          buffer = lines_before_command
        else:
          buffer.append(line)
      for buffer,target in [(lines_at_start,
                             self._dispatcher_include_at_start),
                            (lines_before_command,
                             self._dispatcher_include_before_command)]:
        if (len(buffer) == 0): continue
        if (os.name == "nt"):
          buffer.insert(0, "@REM included from %s" % abs(path))
        else :
          buffer.insert(0, "# included from %s" % abs(path))
        highlight_dispatcher_include_lines(buffer)
        target.extend(buffer)

  def dispatcher_include(self, where):
    assert where in ["at_start", "before_command"]
    assert hasattr(self, "_dispatcher_include_at_start")
    if (where == "at_start"):
      return self._dispatcher_include_at_start
    return self._dispatcher_include_before_command

  def opt_resources_ld_preload(self):
    if (self.build_options.compiler in ["icc", "icpc"]):
      raise RuntimeError(
        "--opt_resources not supported in combination with --compiler=icc")
    def get_libs_dir():
      if (sys.platform.startswith("linux")):
        libs = ["libimf.so", "libirc.so"]
        if (is_64bit_architecture()):
          return "linux64", libs
        return "linux32", libs
      if (sys.platform == "darwin"):
        libs = ["libimf.dylib", "libirc.dylib"]
        if (is_64bit_architecture()):
          return "darwin64", libs
        if (    platform.mac_ver()[0].startswith("10.6")
            and platform.machine() != "Power Macintosh"):
          return None, None # some extensions hang
        return "darwin32", libs
      return None, None
    libs_dir, libs = get_libs_dir()
    if (libs_dir is None):
      return None
    d = self.find_in_repositories(
      relative_path=op.join("opt_resources", libs_dir),
      optional=False)
    result = []
    for l in libs:
      p = d / l
      if not p.isfile():
        raise RuntimeError(
          "Missing file: %s" % show_string(abs(p)))
      if (p.find(":") >= 0):
        raise RuntimeError(
          "File name with embedded colon not supported: %s"
          % show_string(abs(p)))
      result.append(p)
    return ":".join(result)

  def ld_library_path_var_name(self):
    if (os.name == "nt"):
      return "PATH"
    if (sys.platform.startswith("darwin")):
      if (self.build_options.use_conda):
        return "DYLD_FALLBACK_LIBRARY_PATH"
      return "DYLD_LIBRARY_PATH"
    else:
      return "LD_LIBRARY_PATH"

  def ld_library_path_additions(self):
    result = [self.lib_path]
    dirs = []
    if (is_64bit_architecture()):
      dirs.append("lib64")
    dirs.append("lib")
    for d in dirs:
      p = op.join(sys.prefix, d)
      if (op.isdir(p)):
        result.append(self.as_relocatable_path(p))
    return result

  def write_conda_dispatcher(self, source_file, target_file,
                             source_is_python_exe=False):
    '''
    Simplified dispatcher for conda package since many of the environment
    variables are no longer necessary.
    '''
    with target_file.open('w') as f:
      if sys.platform == 'win32':  # windows
        print('@setlocal', file=f)
        print('@set LIBTBX_PREFIX=%~dp0', file=f)
        print('@set LIBTBX_PREFIX=%LIBTBX_PREFIX:~0,-1%', file=f)
        print(r'@for %%F in ("%LIBTBX_PREFIX%") do @set LIBTBX_PREFIX=%%~dpF', file=f)
        print('@set LIBTBX_PREFIX=%LIBTBX_PREFIX:~0,-1%', file=f)
        print('@set LIBTBX_DISPATCHER_NAME=%~nx0', file=f)
        print('@set PATH=%LIBTBX_PREFIX%\\..;%LIBTBX_PREFIX%\\..\\mingw-w64\\bin;%LIBTBX_PREFIX%\\..\\bin;%LIBTBX_PREFIX%\\..\\..\\Scripts;%PATH%', file=f)
        def write_dispatcher_include(where):
          for line in self.dispatcher_include(where=where):
            if (line.startswith("@")):
              print(line, file=f)
            else :
              print("@" + line, file=f)
        write_dispatcher_include(where="at_start")
        print('@set LIBTBX_PYEXE=%s' % self.python_exe.bat_value(anchor_var='LIBTBX_PREFIX'), file=f)
        write_dispatcher_include(where="before_command")
        qnew_tmp = qnew
        if self.python_version_major_minor[0] == 3:
          qnew_tmp = '' # -Q is gone in Python3.
        if source_file.ext().lower() == '.py':
          print('@"%%LIBTBX_PYEXE%%"%s "%s" %%*' % (
            qnew_tmp, source_file.bat_value(anchor_var='LIBTBX_PREFIX')), file=f)
        elif source_file.basename().lower() == 'python.exe':
          print('@"%%LIBTBX_PYEXE%%"%s %%*' % qnew_tmp, file=f)
        else:
          print('@"%s" %%*' % source_file.bat_value(anchor_var='LIBTBX_PREFIX'), file=f)
      else:  # linux and macOS
        if (source_file is not None):
          print('#! /bin/sh', file=f)
          print('# LIBTBX_DISPATCHER DO NOT EDIT', file=f)
        else:
          print('# LIBTBX_DISPATCHER_HEAD DO NOT EDIT', file=f)
          print('#', file=f)
          print('# This file is intended to be sourced from other scripts.', file=f)
          print('# It is like the dispatcher scripts in the bin directory,', file=f)
          print('# but only sets up the environment without calling a', file=f)
          print('# command at the end.', file=f)
        print('#', file=f)
        write_do_not_edit(f=f)
        print('# To customize this auto-generated script create', file=f)
        print('#', file=f)
        print('#   dispatcher_include*.sh', file=f)
        print('#', file=f)
        print('# files in %s and run' % show_string(abs(self.build_path)), file=f)
        print('#', file=f)
        print('#   libtbx.refresh', file=f)
        print('#', file=f)
        print('# to re-generate the dispatchers (libtbx.refresh is a subset', file=f)
        print('# of the functionality of the libtbx/configure.py command).', file=f)
        print('#', file=f)
        print('# See also:', file=f)
        print('#   %s' \
          % show_string(self.under_build("dispatcher_include_template.sh")), file=f)
        print('#', file=f)
        print(_SHELLREALPATH_CODE, file=f)
        print('LIBTBX_PREFIX="$(shellrealpath "$0" && cd "$(dirname "$RESULT")/.." && pwd)"', file=f)
        print('export LIBTBX_PREFIX', file=f)
        print('LIBTBX_PYEXE_BASENAME="%s"' % self.python_exe.basename(), file=f)
        print('export LIBTBX_PYEXE_BASENAME', file=f)
        print('# Set the CCTBX_CONDA_USE_ENVIRONMENT_VARIABLES environment variable', file=f)
        print('# if you want python to use the following environment variables.', file=f)
        print('# Otherwise, this environment takes priority at runtime.', file=f)
        print('if [ -z "${CCTBX_CONDA_USE_ENVIRONMENT_VARIABLES}" ]; then', file=f)
        print('  unset PYTHONHOME', file=f)
        print('  unset PYTHONPATH', file=f)
        print('  unset LD_LIBRARY_PATH', file=f)
        print('  unset DYLD_LIBRARY_PATH', file=f)
        print('  unset DYLD_FALLBACK_LIBRARY_PATH', file=f)
        print('  export PATH="${LIBTBX_PREFIX}/bin:${PATH}"', file=f)
        print('fi', file=f)
        source_is_py = False
        if (source_file is not None):
          dispatcher_name = target_file.basename()
          if (dispatcher_name.find('"') >= 0):
            raise RuntimeError(
              "Dispatcher target file name contains double-quote: %s\n"
                % dispatcher_name
              + "  source file: %s" % source_file)
          print('LIBTBX_DISPATCHER_NAME="%s"' % target_file.basename(), file=f)
          print('export LIBTBX_DISPATCHER_NAME', file=f)
          if source_file.ext().lower() == ".py":
            source_is_py = True
          else:
            with open(abs(source_file), 'rb') as fh:
              first_line = fh.readline()
            if first_line.startswith(b'#!') and b'python' in first_line.lower():
              source_is_py = True
        for line in self.dispatcher_include(where="at_start"):
          print(line, file=f)

        precall_commands = self.dispatcher_precall_commands()
        if (precall_commands is not None):
          for line in precall_commands:
            print(line, file=f)
        if (source_is_py):
          scan_for_dispatcher_includes = True
        elif source_file is None or not source_file.isfile():
          scan_for_dispatcher_includes = False
        else:
          scan_for_dispatcher_includes = not detect_binary_file.from_initial_block(
            file_name=abs(source_file))
        if (scan_for_dispatcher_includes):
          for line in source_specific_dispatcher_include(
                        pattern="LIBTBX_PRE_DISPATCHER_INCLUDE_SH",
                        source_file=source_file):
            print(line, file=f)
        for line in self.dispatcher_include(where="before_command"):
          print(line, file=f)
        if (scan_for_dispatcher_includes):
          for line in source_specific_dispatcher_include(
                        pattern="LIBTBX_POST_DISPATCHER_INCLUDE_SH",
                        source_file=source_file):
            print(line, file=f)
        if (self.build_options.opt_resources):
          ldpl = self.opt_resources_ld_preload()
          if (ldpl is not None):
            print('if [ "${LIBTBX_NO_LD_PRELOAD-UNSET}" == UNSET ]; then', file=f)
            print('  LD_PRELOAD="%s"' % ldpl, file=f)
            print('  export LD_PRELOAD', file=f)
            print('fi', file=f)
        print('LIBTBX_PYEXE="%s"' % (
          self.python_exe.dirname() / "$LIBTBX_PYEXE_BASENAME").sh_value(anchor_var='LIBTBX_PREFIX'), file=f)
        print('export LIBTBX_PYEXE', file=f)

        if (source_file is not None):
          cmd = ""
          if (source_is_py or source_is_python_exe):
            qnew_tmp = qnew
            if self.python_version_major_minor[0] == 3:
              qnew_tmp = '' # -Q is gone in Python3.
            cmd += ' "$LIBTBX_PYEXE"%s' % qnew_tmp
          start_python = False
          if (source_is_py):
            if (len(source_specific_dispatcher_include(
                      pattern="LIBTBX_START_PYTHON",
                      source_file=source_file)) > 3):
              start_python = True
          if (not start_python and not source_is_python_exe):
            cmd += ' "%s"' % source_file.sh_value(anchor_var='LIBTBX_PREFIX')
          print('if [ -n "$LIBTBX__VALGRIND_FLAG__" ]; then', file=f)
          print("  exec $LIBTBX_VALGRIND"+cmd, '"$@"', file=f)
          tmp_reloc = os.path.basename(source_file.relocatable)
          if tmp_reloc.endswith('.py') and cmd.find('-Qnew')>-1:
            print('elif [ -n "$LIBTBX__CPROFILE_FLAG__" ]; then', file=f)
            print('  exec %s "$@"' % cmd.replace(
              '-Qnew',
              '-Qnew -m cProfile -o %s.profile' % os.path.basename(target_file.relocatable),
              ), file=f)
          print("elif [ $# -eq 0 ]; then", file=f)
          print("  exec"+cmd, file=f)
          print("else", file=f)
          print("  exec"+cmd, '"$@"', file=f)
          print("fi", file=f)
        target_file.chmod(0o755)

  def write_bin_sh_dispatcher(self,
        source_file, target_file, source_is_python_exe=False):

    # set SSL_CERT_FILE if certifi is available
    cert_file = None
    try:
      import certifi
      cert_file = self.as_relocatable_path(certifi.where())
    except ImportError:
      pass

    # set OPENBLAS_NUM_THREADS
    # This prevents the binary pip installation of numpy from spawning threads
    # when flex is imported ("from scitbx.array_family import flex")
    # Problem seems to only appear on linux, but should not hurt other operating
    # systems.
    # According to https://github.com/xianyi/OpenBLAS#usage , there are 3
    # environment variables that control the spawning of threads
    #   OPENBLAS_NUM_THREADS
    #   GOTO_NUM_THREADS
    #   OMP_NUM_THREADS
    # where OPENBLAS_NUM_THREADS > GOTO_NUM_THREADS > OMP_NUM_THREADS in terms
    # of precedence. Setting OPENBLAS_NUM_THREADS should allow OMP_NUM_THREADS
    # to be used for OpenMP sections. Using multiple threads for numpy functions
    # that depend on OpenBLAS will require changing the OPENBLAS_NUM_THREADS
    # environment variable in the code that wants that functionality.
    openblas_num_threads = 1

    # determine LC_ALL from environment (Python UTF-8 compatibility in Linux)
    LC_ALL = os.environ.get('LC_ALL')     # user setting
    if (LC_ALL is not None):
      if ( ('UTF-8' not in LC_ALL) and ('utf8' not in LC_ALL) ):
        LC_ALL = None
    if (LC_ALL is None):
      LC_ALL = 'en_US.UTF-8'              # default

    f = target_file.open("w")
    if (source_file is not None):
      print('#! /bin/sh', file=f)
      print('# LIBTBX_DISPATCHER DO NOT EDIT', file=f)
    else:
      print('# LIBTBX_DISPATCHER_HEAD DO NOT EDIT', file=f)
      print('#', file=f)
      print('# This file is intended to be sourced from other scripts.', file=f)
      print('# It is like the dispatcher scripts in the bin directory,', file=f)
      print('# but only sets up the environment without calling a', file=f)
      print('# command at the end.', file=f)
    print('#', file=f)
    write_do_not_edit(f=f)
    print('# To customize this auto-generated script create', file=f)
    print('#', file=f)
    print('#   dispatcher_include*.sh', file=f)
    print('#', file=f)
    print('# files in %s and run' % show_string(abs(self.build_path)), file=f)
    print('#', file=f)
    print('#   libtbx.refresh', file=f)
    print('#', file=f)
    print('# to re-generate the dispatchers (libtbx.refresh is a subset', file=f)
    print('# of the functionality of the libtbx/configure.py command).', file=f)
    print('#', file=f)
    print('# See also:', file=f)
    print('#   %s' \
      % show_string(self.under_build("dispatcher_include_template.sh")), file=f)
    print('#', file=f)
    print(_SHELLREALPATH_CODE, file=f)
    print('unset PYTHONHOME', file=f)
    print('LC_ALL=' + LC_ALL, file=f)
    print('export LC_ALL', file=f)
    print('LIBTBX_BUILD="$(shellrealpath "$0" && cd "$(dirname "$RESULT")/.." && pwd)"', file=f)
    print('export LIBTBX_BUILD', file=f)
    print('LIBTBX_PYEXE_BASENAME="%s"' % self.python_exe.basename(), file=f)
    print('export LIBTBX_PYEXE_BASENAME', file=f)
    source_is_py = False
    if (source_file is not None):
      dispatcher_name = target_file.basename()
      if (dispatcher_name.find('"') >= 0):
        raise RuntimeError(
          "Dispatcher target file name contains double-quote: %s\n"
            % dispatcher_name
          + "  source file: %s" % source_file)
      print('LIBTBX_DISPATCHER_NAME="%s"' % target_file.basename(), file=f)
      print('export LIBTBX_DISPATCHER_NAME', file=f)
      if source_file.ext().lower() == ".py":
        source_is_py = True
      else:
        with open(abs(source_file), 'rb') as fh:
          first_line = fh.readline()
        if first_line.startswith(b'#!') and b'python' in first_line.lower():
          source_is_py = True
    for line in self.dispatcher_include(where="at_start"):
      print(line, file=f)
    essentials = [("PYTHONPATH", self.pythonpath)]
    essentials.append((
      self.ld_library_path_var_name(),
      self.ld_library_path_additions()))
    essentials.append(("PATH", [self.bin_path]))

    if (cert_file is not None):
      print('SSL_CERT_FILE="%s"' % cert_file.sh_value(), file=f)
      print('export SSL_CERT_FILE', file=f)

    print('OPENBLAS_NUM_THREADS="%s"' % openblas_num_threads, file=f)
    print('export OPENBLAS_NUM_THREADS', file=f)

    if sys.version_info[0] == 2:
      pangorc = abs(self.build_path / '..' / 'base' / 'etc' / 'pango' / 'pangorc')
      if os.path.exists(pangorc):
        print('PANGO_RC_FILE="$LIBTBX_BUILD/../base/etc/pango/pangorc"', file=f)
        print('export PANGO_RC_FILE', file=f)
      fontconfig = abs(self.build_path / '..' / 'base' / 'etc' / 'fonts')
      if os.path.exists(fontconfig):
        print('FONTCONFIG_PATH="$LIBTBX_BUILD/../base/etc/fonts"', file=f)
        print('export FONTCONFIG_PATH', file=f)

      # set paths for fontconfig and gdk-pixbuf due to gtk2
      # checks the location of the conda environment
      if self.build_options.use_conda and sys.platform.startswith('linux'):
        fontconfig_path = '{conda_base}/etc/fonts'
        fontconfig_file = '$FONTCONFIG_PATH/fonts.conf'
        gdk_pixbuf_module_file = '{conda_base}/lib/gdk-pixbuf-2.0/2.10.0/loaders.cache'
        gtk_path = '{conda_base}/lib/gtk-2.0/2.10.0'
        conda_base = get_conda_prefix()
        if (os.path.exists(fontconfig_path.format(conda_base=conda_base)) and
            os.path.exists(gdk_pixbuf_module_file.format(conda_base=conda_base))):
          if conda_base == abs(self.build_path / '..' / 'conda_base'):
            conda_base = '$LIBTBX_BUILD/../conda_base'
          print('unset GTK_MODULES', file=f)
          print('unset GTK2_RC_FILES', file=f)
          print('unset GTK_RC_FILES', file=f)
          print('export FONTCONFIG_PATH=' +
                fontconfig_path.format(conda_base=conda_base), file=f)
          print('export FONTCONFIG_FILE=' + fontconfig_file, file=f)
          print('export GDK_PIXBUF_MODULE_FILE=' +
                gdk_pixbuf_module_file.format(conda_base=conda_base), file=f)
          print('export GTK_PATH=' + gtk_path.format(conda_base=conda_base), file=f)

    for n,v in essentials:
      if (len(v) == 0): continue
      v = ":".join([p.sh_value() for p in v])
      print('if [ -n "$%s" ]; then' % n, file=f)
      print('  %s="%s:$%s"' % (n, v, n), file=f)
      print('  export %s' % n, file=f)
      print('else', file=f)
      print('  %s="%s"' % (n, v), file=f)
      print('  export %s' % n, file=f)
      print('fi', file=f)
    precall_commands = self.dispatcher_precall_commands()
    if (precall_commands is not None):
      for line in precall_commands:
        print(line, file=f)
    if (source_is_py):
      scan_for_dispatcher_includes = True
    elif source_file is None or not source_file.isfile():
      scan_for_dispatcher_includes = False
    else:
      scan_for_dispatcher_includes = not detect_binary_file.from_initial_block(
        file_name=abs(source_file))
    if (scan_for_dispatcher_includes):
      for line in source_specific_dispatcher_include(
                    pattern="LIBTBX_PRE_DISPATCHER_INCLUDE_SH",
                    source_file=source_file):
        print(line, file=f)
    for line in self.dispatcher_include(where="before_command"):
      print(line, file=f)
    if (scan_for_dispatcher_includes):
      for line in source_specific_dispatcher_include(
                    pattern="LIBTBX_POST_DISPATCHER_INCLUDE_SH",
                    source_file=source_file):
        print(line, file=f)
    if (self.build_options.opt_resources):
      ldpl = self.opt_resources_ld_preload()
      if (ldpl is not None):
        print('if [ "${LIBTBX_NO_LD_PRELOAD-UNSET}" == UNSET ]; then', file=f)
        print('  LD_PRELOAD="%s"' % ldpl, file=f)
        print('  export LD_PRELOAD', file=f)
        print('fi', file=f)
    print('LIBTBX_PYEXE="%s"' % (
      self.python_exe.dirname() / "$LIBTBX_PYEXE_BASENAME").sh_value(), file=f)
    print('export LIBTBX_PYEXE', file=f)

    # Since El Capitan, Apple Python does not allow relative rpath in shared
    # libraries. Thus any cctbx-based script will fail with an import error
    # because each and every .so references lib/libboost_python.dylib.
    # There are two ways to fix this issue:
    # - we could put the absolute path at compile-time
    # - or we can fix it at runtime
    # The former would make the cctbx build directory non-relocatable. Thus
    # we prefer the latter.
    if sys.platform == "darwin" and abs(self.python_exe).startswith("/usr/bin/"):
      print("""/usr/bin/perl <<'FIXRPATH'
        for $lib(<$ENV{LIBTBX_BUILD}/lib/*.so>) {
            open OTOOL, "-|", "otool", "-L", $lib;
            while(<OTOOL>) {
                m{^\\s+(lib\\S+)} and $libs{$lib}{$1}++;
            }
        }
        while(($so, $relative_libs) = each %libs) {
            for $lib(keys %$relative_libs) {
                system "install_name_tool",
                       "-change", $lib, "\\@loader_path/../$lib", $so;
            }
        }
      """, file=f)
      print("FIXRPATH", file=f)
    if (source_file is not None):
      def pre_cmd():
        return ['', '/usr/bin/arch -i386 '][self.build_options.force_32bit]
      cmd = ""
      if (source_is_py or source_is_python_exe):
        qnew_tmp = qnew
        if self.python_version_major_minor[0] == 3:
          qnew_tmp = '' # -Q is gone in Python3.
        cmd += ' %s"$LIBTBX_PYEXE"%s' % (pre_cmd(), qnew_tmp)
      start_python = False
      if (source_is_py):
        if (len(source_specific_dispatcher_include(
                  pattern="LIBTBX_START_PYTHON",
                  source_file=source_file)) > 3):
          start_python = True
      if (not start_python and not source_is_python_exe):
        cmd += ' "%s"' % source_file.sh_value()
      print('if [ -n "$LIBTBX__VALGRIND_FLAG__" ]; then', file=f)
      print("  exec $LIBTBX_VALGRIND"+cmd, '"$@"', file=f)
      tmp_reloc = os.path.basename(source_file.relocatable)
      if tmp_reloc.endswith('.py') and cmd.find('-Qnew')>-1:
        print('elif [ -n "$LIBTBX__CPROFILE_FLAG__" ]; then', file=f)
        print('  exec %s "$@"' % cmd.replace(
          '-Qnew',
          '-Qnew -m cProfile -o %s.profile' % os.path.basename(target_file.relocatable),
          ), file=f)
      print("elif [ $# -eq 0 ]; then", file=f)
      print("  exec"+cmd, file=f)
      print("else", file=f)
      print("  exec"+cmd, '"$@"', file=f)
      print("fi", file=f)
    f.close()
    target_file.chmod(0o755)

  def write_win32_dispatcher(self,
        source_file, target_file, source_is_python_exe=False):
    f = target_file.open('w')
    # By default, changes to environment variables are  permanent on Windows,
    # i.e. it is as if export VAR was added after each set VAR=...
    # As a result, e.g. set PYTHONPATH=...; %PYTHONPATH% results in growing
    # PYTHONPATH each time a dispatcher script is run.
    # Thus setlocal essential (endlocal is implied)
    print('@setlocal', file=f)
    print('@set LIBTBX_BUILD=%~dp0', file=f)
    print('@set LIBTBX_BUILD=%LIBTBX_BUILD:~0,-1%', file=f)
    print(r'@for %%F in ("%LIBTBX_BUILD%") do @set LIBTBX_BUILD=%%~dpF', file=f)
    print('@set LIBTBX_BUILD=%LIBTBX_BUILD:~0,-1%', file=f)
    print('@set LIBTBX_DISPATCHER_NAME=%~nx0', file=f)
    def write_dispatcher_include(where):
      for line in self.dispatcher_include(where=where):
        if (line.startswith("@")):
          print(line, file=f)
        else :
          print("@" + line, file=f)
    write_dispatcher_include(where="at_start")
    essentials = [("PYTHONPATH", self.pythonpath)]
    essentials.append((self.ld_library_path_var_name(), [self.lib_path]))
    bin_path = [self.bin_path]
    if self.build_options.use_conda:
      bin_path.append(self.as_relocatable_path(get_conda_prefix()) / 'Library' / 'bin')
      bin_path.append(self.as_relocatable_path(get_conda_prefix()) / 'Library' / 'mingw-w64' / 'bin')
    essentials.append(("PATH", bin_path))
    for n,v in essentials:
      if (len(v) == 0): continue
      v = ';'.join([ op.join('%LIBTBX_BUILD%', p.relocatable) for p in v ])
      print('@set %s=%s;%%%s%%' % (n, v, n), file=f)
    print('@set LIBTBX_PYEXE=%s' % self.python_exe.bat_value(), file=f)
    write_dispatcher_include(where="before_command")
    qnew_tmp = qnew
    if self.python_version_major_minor[0] == 3:
      qnew_tmp = '' # -Q is gone in Python3.
    if source_file.ext().lower() == '.py':
      print('@"%%LIBTBX_PYEXE%%"%s "%s" %%*' % (
        qnew_tmp, source_file.bat_value()), file=f)
    elif source_file.basename().lower() == 'python.exe':
      print('@"%%LIBTBX_PYEXE%%"%s %%*' % qnew_tmp, file=f)
    else:
      print('@"%s" %%*' % source_file.bat_value(), file=f)
    f.close()

  def write_dispatcher(self,
        source_file, target_file, source_is_python_exe=False):
    source_file = self.as_relocatable_path(source_file)
    target_file = self.as_relocatable_path(target_file)
    # always skip amber.python
    if target_file.basename() in ['amber.python',
                                  #'rosetta.python',
                                  #'afitt.python',
                                 ]:
      return
    if "phenix" not in self.module_dict and self.build_options.skip_phenix_dispatchers and "phenix" in target_file.basename():
      return
    reg = self._dispatcher_registry.setdefault(target_file, source_file)
    if reg != source_file:
      if not reg.isfile():
        self._dispatcher_registry[target_file] = source_file
      elif (source_file.isfile()
            and (   not hasattr(os.path, "samefile")
                 or not reg.samefile(source_file))):
        raise RuntimeError("Multiple sources for dispatcher:\n"
          + "  target file:\n"
          + "    %s\n" % show_string(abs(target_file))
          + "  source files:\n"
          + "    %s\n" % show_string(abs(reg))
          + "   =%s\n" % reg
          + "    %s\n" % show_string(abs(source_file))
          + "   =%s" % source_file)
    if abs(self.build_path) == os.path.abspath(get_conda_prefix()) or \
      (os.name == "nt" and abs(self.build_path).lower().endswith('library')):
      action = self.write_conda_dispatcher
    elif (os.name == "nt"):
      action = self.write_win32_dispatcher
    else:
      action = self.write_bin_sh_dispatcher
    target_file_ext = target_file
    if os.name == 'nt':
      target_file_ext += '.bat'
    remove_or_rename(target_file_ext)
    try: action(source_file, target_file_ext, source_is_python_exe)
    except IOError as e: print("  Ignored:", e)

  def _write_dispatcher_in_bin(self,
        source_file, target_file, source_is_python_exe=False):
    self.write_dispatcher(
      source_file=source_file,
      target_file=self.under_build("bin/"+target_file,
                                   return_relocatable_path=True),
      source_is_python_exe=source_is_python_exe)

  def write_dispatcher_in_bin(self, source_file, target_file):
    self._write_dispatcher_in_bin(
      source_file=source_file,
      target_file=target_file)

  def write_lib_dispatcher_head(self, target_file="dispatcher_head.sh"):
    if (os.name == "nt"): return
    print("   ", target_file)
    self.write_bin_sh_dispatcher(
      source_file=None,
      target_file=self.under_build(target_file, return_relocatable_path=True))

  def write_setpaths_sh(self, suffix):
    setpaths = unix_setpaths(self, "sh", suffix)
    s, u = setpaths.s, setpaths.u
    for f in s, u:
      write_do_not_edit(f=f)
      f.write("""\
ocwd="`pwd`"
if [ -n "$LIBTBX_BUILD_RELOCATION_HINT" ]; then
  cd "$LIBTBX_BUILD_RELOCATION_HINT"
  LIBTBX_BUILD_RELOCATION_HINT=
  export LIBTBX_BUILD_RELOCATION_HINT
elif [ -n "$BASH_SOURCE" ]; then
  LIBTBX_BUILD=`dirname "$BASH_SOURCE[0]"`
  cd "$LIBTBX_BUILD"
else
  cd "%s"
fi
LIBTBX_BUILD=`pwd -P`
export LIBTBX_BUILD
LIBTBX_OPATH="$PATH"
export LIBTBX_OPATH
PATH="$LIBTBX_BUILD/bin:$PATH"
export PATH
cd "$ocwd"
ocwd=
""" % abs(self.build_path))
    s.write("""\
alias libtbx.setpaths_all=". \\"$LIBTBX_BUILD/setpaths_all.sh\\""
alias libtbx.unsetpaths=". \\"$LIBTBX_BUILD/unsetpaths.sh\\""
""")
    print('unalias libtbx.unsetpaths > /dev/null 2>&1', file=u)
    if (self.is_development_environment()):
      print('''alias cdlibtbxbuild="cd \\"$LIBTBX_BUILD\\""''', file=s)
      print('unalias cdlibtbxbuild > /dev/null 2>&1', file=u)
    setpaths.all_and_debug()
    setpaths.set_unset_vars()
    setpaths.update_path(
      var_name="PATH",
      val=self.bin_path.sh_value(),
      var_name_in="LIBTBX_OPATH")
    for f in s, u:
      print('LIBTBX_TMPVAL=', file=f)
      print('LIBTBX_OPATH=', file=f)
      if (suffix == ""):
        print('LIBTBX_BUILD=', file=f)

  def write_setpaths_csh(self, suffix):
    setpaths = unix_setpaths(self, "csh", suffix)
    s, u = setpaths.s, setpaths.u
    for f in s, u:
      write_do_not_edit(f=f)
      f.write("""\
set ocwd="$cwd"
if ($?LIBTBX_BUILD_RELOCATION_HINT) then
  cd "$LIBTBX_BUILD_RELOCATION_HINT"
  unsetenv LIBTBX_BUILD_RELOCATION_HINT
else
  cd "%s"
endif
setenv LIBTBX_BUILD "`/bin/sh -c 'pwd -P'`"
setenv LIBTBX_OPATH "$PATH"
setenv PATH "$LIBTBX_BUILD/bin:$PATH"
cd "$ocwd"
unset ocwd
""" % abs(self.build_path))
    s.write("""\
alias libtbx.setpaths_all "source '$LIBTBX_BUILD/setpaths_all.csh'"
alias libtbx.unsetpaths "source '$LIBTBX_BUILD/unsetpaths.csh'"
""")
    print('unalias libtbx.unsetpaths', file=u)
    if (self.is_development_environment()):
      print('''alias cdlibtbxbuild "cd '$LIBTBX_BUILD'"''', file=s)
      print('unalias cdlibtbxbuild', file=u)
    setpaths.all_and_debug()
    setpaths.set_unset_vars()
    setpaths.update_path(
      var_name="PATH",
      val=self.bin_path.sh_value(),
      var_name_in="LIBTBX_OPATH")
    for f in s, u:
      print('unsetenv LIBTBX_TMPVAL', file=f)
      print('unsetenv LIBTBX_OPATH', file=f)
      if (suffix == ""):
        print('unsetenv LIBTBX_BUILD', file=f)

  def write_setpaths_bat(self, suffix):
    setpaths = windows_setpaths(self, suffix)
    s, u = setpaths.s, setpaths.u
    for f in s, u:
      write_do_not_edit(f=f, win_bat=True)
      print(r'''@set LIBTBX_BUILD=%~dp0
@set LIBTBX_BUILD=%LIBTBX_BUILD:~0,-1%
@set LIBTBX_OPATH=%PATH%''', file=f)
      print('@set PATH=%s;%%PATH%%' % self.bin_path.bat_value(), file=f)
    setpaths.all_and_debug()
    setpaths.update_path(
      var_name="PATH",
      val=self.bin_path.bat_value(),
      var_name_in="LIBTBX_OPATH")
    for command in ["setpaths_all", "unsetpaths"]:
      print('@doskey libtbx.%s="%s\\%s.bat"' % (
        command, "%LIBTBX_BUILD%", command), file=s)
    print('@doskey libtbx.unsetpaths=', file=u)
    if (self.is_development_environment()):
      print('@doskey cdlibtbxbuild=cd "%LIBTBX_BUILD%"', file=s)
      print('@doskey cdlibtbxbuild=', file=u)
    if (suffix == "_debug"):
      print('@set PYTHONCASEOK=1', file=s) # no unset
    setpaths.set_unset_vars()
    for f in s, u:
      print('@set LIBTBX_OPATH=', file=f)
      if (suffix == ""):
        print('@set LIBTBX_BUILD=', file=f)

  def write_SConstruct(self):
    f = open_info(self.under_build("SConstruct",
                                   return_relocatable_path=True))
    write_do_not_edit(f=f)
    print('SConsignFile()', file=f)
    if os.getenv("SCONS_CACHE"):
      cache_dir = os.getenv("SCONS_CACHE")
      print("Using build cache in %s" % cache_dir)
      print("CacheDir(%r)" % cache_dir, file=f)
      assert os.path.exists(cache_dir) and os.path.isdir(cache_dir), \
        "Specified build cache dir does not exist"

    repository_paths = self.repository_paths
    repository_names = set([abs(p) for p in repository_paths])
    module_list = self.module_list
    module_names = set([module.name for module in module_list])
    # insert repositories and modules from installed environment
    installed_env = get_installed_env()
    if installed_env is not None:
      for repository_path in installed_env.repository_paths:
        if abs(repository_path) in repository_names:
          for p in repository_paths:
            if abs(p) == abs(repository_path):
              try:
                repository_paths.remove(p)
              except ValueError:
                pass
      repository_paths = installed_env.repository_paths + repository_paths
      # collect modules
      all_modules = installed_env.module_list
      local_env = get_local_env()
      if local_env is not None:
        all_modules += local_env.module_list
      all_modules += self.module_list
      # reorder modules
      module_list = []
      for ordered_name in installed_env.installed_order:
        for module in all_modules:
          if ordered_name == module.name:
            module_list.append(module)
            all_modules.remove(module)
            break
      # add remaining modules
      module_list_names = set([module.name for module in module_list])
      for module in all_modules:
        if module.name not in module_list_names:
          module_list.append(module)
          module_list_names.add(module.name)

    for path in repository_paths:
      print('Repository(r"%s")' % abs(path), file=f)
    for module in module_list:
      name,path  = list(module.name_and_dist_path_pairs())[-1]
      for script_name in ["libtbx_SConscript", "SConscript"]:
        if (path / script_name).isfile():
          print('SConscript("%s/%s")' % (name, script_name), file=f)
          break
    f.close()

  def write_Makefile(self):
    if (op.isfile("Makefile")):
      os.rename("Makefile", "Makefile.old")
        # make cja seems to get confused if the file is simply overwritten
    f = open_info(self.under_build("Makefile",
                                   return_relocatable_path=True))
    current_path = os.environ.get('PATH')
    lsj = './bin/libtbx.scons -j "`./bin/libtbx.show_number_of_processors`"'
    lc = './bin/libtbx.configure'
    if get_installed_env() is not None:
      lsj = 'libtbx.scons -j "`libtbx.show_number_of_processors`"'
      lc = 'libtbx.configure'
    f.write("""\
# DO NOT EDIT THIS FILE!
# This file will be overwritten by the next libtbx/configure.py,
# libtbx.configure, or libtbx.refresh.

default:
\t%(lsj)s

nostop:
\t%(lsj)s -k

bp:
\t%(lsj)s -k boost_python_tests=1

reconf:
\t%(lc)s .
\t%(lsj)s

redo:
\t%(lc)s . --clear_scons_memory
\t%(lsj)s

clean:
\t%(lsj)s -c

# example
selfx:
\trm -rf selfx_tmp
\tmkdir selfx_tmp
\tcd selfx_tmp ; \\
\t\tlibtbx.start_binary_bundle example boost ; \\
\t\tlibtbx.bundle_as_selfx example build_id ; \\
\t\tmv example_build_id.selfx .. ; \\
\t\tcd .. ; \\
\t\tls -l example_build_id.selfx
""" % vars())
    f.close()

  def collect_test_scripts(self):
    result = []
    for module in self.module_list:
      result.extend(module.collect_test_scripts())
    return result

  def write_run_tests_csh(self):
    test_scripts = self.collect_test_scripts()
    if (len(test_scripts) > 0):
      path = self.under_build("run_tests.csh", return_relocatable_path=True)
      f = open_info(path)
      print("#! /bin/csh -f", file=f)
      print("set noglob", file=f)
      print("set verbose", file=f)
      for file_name in test_scripts:
        print('libtbx.python "%s" $*' % abs(file_name), file=f)
      f.close()
      path.chmod(0o755)

  def pickle(self):
    self.reset_dispatcher_support()
    file_name = self.build_path / "libtbx_env"
    with file_name.open("wb") as f:
      pickle.dump(self, f, 0)

  def show_module_listing(self):
    print("Relocatable paths anchored at: %s" % abs(self.build_path))
    print("Top-down list of all modules involved:")
    top_down_module_list = list(self.module_list)
    top_down_module_list.reverse()
    labels = [module.names_for_module_listing()
      for module in top_down_module_list]
    if (len(labels) == 0): return
    fmt = "  %%-%ds  %%s" % max([len(label) for label in labels])
    for label,module in zip(labels,top_down_module_list):
      for dist_path in module.dist_paths_active():
        print(fmt % (label, show_string(abs(dist_path))))
        label = ""

  def show_build_options_and_module_listing(self):
    print("Python: %s %s" % (
      sys.version.split()[0], show_string(sys.executable)))
    if (self.is_ready_for_build()):
      self.build_options.report()
    print("command_version_suffix:", self.command_version_suffix)
    self.show_module_listing()
    if (len(self.missing_for_use) > 0):
      raise RuntimeError("Missing modules: "
        + " ".join(sorted(self.missing_for_use)))
    if (not self.is_ready_for_build()):
      if (self.scons_dist_path is not None):
        print("***********************************")
        print("Warning: modules missing for build:")
        for module_name in sorted(self.missing_for_build):
          print(" ", module_name)
        print("***********************************")
      remove_or_rename(self.under_build("SConstruct"))

  def write_setpath_files(self):
    for suffix in ["", "_all", "_debug"]:
      if (sys.platform == "win32"):
        self.write_setpaths_bat(suffix)
      else:
        self.write_setpaths_sh(suffix)
        self.write_setpaths_csh(suffix)

  def process_exe(self):
    for path in [self.exe_path,
                 self.under_build("exe_dev", return_relocatable_path=True)]:
      if path.isdir():
        print("Processing: %s" % show_string(abs(path)))
        for file_name in path.listdir():
          if (file_name.startswith(".")): continue
          target_file = file_name
          if (os.name == "nt"):
            fnl = file_name.lower()
            if (fnl.endswith(".exe.manifest")): continue
            if (fnl.endswith(".exe")): target_file = file_name[:-4]
          self._write_dispatcher_in_bin(source_file=path / file_name,
                                        target_file=target_file)

  def write_python_and_show_path_duplicates(self):
    module_names = []
    for module in self.module_list:
      if (   len(module.command_line_directory_paths()) != 0
          or len(module.assemble_pythonpath()) != 0):
        module_names.append(module.name.lower())
    for module_name in module_names:
      self._write_dispatcher_in_bin(
        source_file=self.python_exe,
        target_file=module_name+".python",
        source_is_python_exe=True)
    d, b = self.python_exe.split()
    pythonw_exe = d / b.replace("python", "pythonw")
    if pythonw_exe.isfile():
      for module_name in module_names:
        self._write_dispatcher_in_bin(
          source_file=pythonw_exe,
          target_file=module_name+".pythonw",
          source_is_python_exe=True)
    def have_ipython():
      for file_name in self.bin_path.listdir():
        file_name_lower = file_name.lower()
        if (file_name_lower.startswith("libtbx.")):
          if (   file_name_lower == "libtbx.ipython"
              or file_name_lower.startswith("libtbx.ipython.")):
            return
    commands = ["show_build_path", "show_dist_paths"]
    if (have_ipython()): commands.append("ipython")
    for command in commands:
      source_file = self.under_dist(
        "libtbx", "command_line/"+command+".py")
      for module_name in module_names:
        self._write_dispatcher_in_bin(
          source_file=source_file,
          target_file=module_name+"."+command)

  @staticmethod
  def get_setuptools_script_dir():
    '''
    Find the location of python entry point console_scripts, ie. things like
    'pip', 'pytest', ...
    This is different from simple /base/bin, eg. on MacOS.

    https://stackoverflow.com/questions/25066084/get-entry-point-script-file-location-in-setuputils-package
    '''
    from setuptools import Distribution
    from setuptools.command.install import install
    class OnlyGetScriptPath(install):
      def run(self):
        # does not call install.run() by design
        self.distribution.install_scripts = self.install_scripts
    dist = Distribution({'cmdclass': {'install': OnlyGetScriptPath}})
    dist.dry_run = True  # not sure if necessary, but to be safe
    dist.parse_config_files()
    command = dist.get_command_obj('install')
    command.ensure_finalized()
    command.run()
    return dist.install_scripts

  def write_command_version_duplicates(self):
    if (self.command_version_suffix is None): return
    suffix = "_" + self.command_version_suffix
    for file_name in self.bin_path.listdir():
      if (file_name.startswith(".")): continue
      source_file = abs(self.bin_path / file_name)
      if (os.name == "nt" and file_name.lower().endswith(".exe")):
        target_file = source_file[:-4] + suffix + source_file[-4:]
      else:
        target_file = source_file + suffix
      remove_or_rename(target_file)
      try: shutil.copy(source_file, target_file)
      except IOError: pass

  def assemble_pythonpath(self):
    # explicitly add site-packages path to avoid conflicts with per user site-packages
    # https://www.python.org/dev/peps/pep-0370/
    if (hasattr(site, 'getsitepackages')):
      pythonpath = [self.as_relocatable_path(p) for p in site.getsitepackages()]
    else:
      # fallback in case of virtualenv
      # https://github.com/pypa/virtualenv/issues/355
      from distutils.sysconfig import get_python_lib
      pythonpath = [self.as_relocatable_path(get_python_lib())]
    pythonpath.append(self.lib_path)
    for module in self.module_list:
      pythonpath.extend(module.assemble_pythonpath())
    pythonpath.reverse()
    self.pythonpath = unique_paths(paths=pythonpath)

  def is_development_environment(self):
    for module in self.module_list:
      if (module.is_version_controlled()):
        return True
    return False

  def relocate_python_paths_if_necessary(self):
    base_directory = abs(self.build_path / '..' / 'base')
    def is_in_local_base_directory(path):
      return os.path.commonprefix([os.path.abspath(path), base_directory]) == base_directory

    if not is_in_local_base_directory(sys.executable):
      return # no relocation required when using non-local (presumably: system) python
    site_packages = site.getsitepackages()
    if any(map(is_in_local_base_directory, site_packages)):
      return # There is a site directory inside the local python path.
             # This means relocation is not required.

    print("libtbx.configure determined that a python relocation is required.")
    old_base_path = os.path.commonprefix(site_packages)
    while old_base_path:
      old_base_path, directory = os.path.split(old_base_path)
      if directory == 'base': break
    if directory != 'base':
      print("WARNING: Relocation not possible, could not determine original base path from '{}'".format(os.path.commonprefix(site_packages)))
      return
    old_base_path = os.path.join(old_base_path, 'base')
    print("Attempting relocate from: {}\n           relocate to  : {}".format(old_base_path, base_directory))

    import libtbx.auto_build.rpath
    libtbx.auto_build.rpath.run(['--otherroot', old_base_path, base_directory])

  def clear_scons_memory(self):
    (self.build_path / ".sconsign.dblite").remove()
    (self.build_path / ".sconf_temp").remove_tree()

  def refresh(self):
    # check if self is modifiable
    if self.installed:
      print("Installed environments cannot be refreshed.")
      try:
        env = unpickle(os.getcwd())
      except FileNotFoundError:
        env = None
      if env is not None:
        print("Updating environment in {}".format(os.getcwd()))
        env.refresh()
        env.pickle()  # need a separate call
    # continue normally
    else:
      completed_file_name = (self.build_path / "libtbx_refresh_is_completed")
      completed_file_name.remove()
      self.assemble_pythonpath()
      self.show_build_options_and_module_listing()
      self.reset_dispatcher_bookkeeping()
      print("Creating files in build directory: %s" \
        % show_string(abs(self.build_path)))
      self.write_dispatcher_include_template()
      self.write_lib_dispatcher_head()
      self.write_setpath_files()
      self.pickle()
      libtbx.env = self
      os.environ["LIBTBX_BUILD"] = abs(self.build_path) # to support libtbx.load_env
      if (self.is_ready_for_build()):
        self.write_SConstruct()
        if (os.name != "nt"):
          self.write_Makefile()
      if (os.name != "nt"):
        self.write_run_tests_csh()
      self.clear_bin_directory()
      if not self.bin_path.isdir():
        self.bin_path.makedirs()
      self.relocate_python_paths_if_necessary()
      python_dispatchers = ["libtbx.python"]
      if (self.is_development_environment() and not self.no_bin_python):
        python_dispatchers.append("python")
      for file_name in python_dispatchers:
        self._write_dispatcher_in_bin(
          source_file=self.python_exe,
          target_file=file_name,
          source_is_python_exe=True)
      for module in self.module_list:
        module.process_command_line_directories()
        # Reload the libtbx_config in case dependencies have changed
        module.process_libtbx_config()

      for path in self.pythonpath:
        sys.path.insert(0, abs(path))

      # Some libtbx_refresh scripts do a `pip install --editable`. The default
      # behavior was changed in setuptools 64 and currently we expect the old
      # behavior. See: https://github.com/pypa/setuptools/pull/3265
      sef_previous = os.environ.get('SETUPTOOLS_ENABLE_FEATURES')
      os.environ['SETUPTOOLS_ENABLE_FEATURES'] = 'legacy_editable'

      for module in self.module_list:
        module.process_libtbx_refresh_py()

      if sef_previous is not None:
          os.environ['SETUPTOOLS_ENABLE_FEATURES'] = sef_previous
      else:
          os.environ.pop('SETUPTOOLS_ENABLE_FEATURES')

      self.write_python_and_show_path_duplicates()
      self.process_exe()
      self.write_command_version_duplicates()
      if (os.name != "nt"):     # LD_LIBRARY_PATH for dependencies
        os.environ[self.ld_library_path_var_name()] = ":".join(
          [abs(p) for p in self.ld_library_path_additions()])
      if sys.version_info[0] == 2:
        if self.build_options.use_conda:
          # refresh loaders.cache for gdk-pixbuf on linux due to gtk2
          if sys.platform.startswith("linux"):
            conda_base = get_conda_prefix()
            command = "{conda_base}/bin/gdk-pixbuf-query-loaders"
            loaders = "{conda_base}/lib/gdk-pixbuf-2.0/2.10.0/loaders/*.so"
            cache = "{conda_base}/lib/gdk-pixbuf-2.0/2.10.0/loaders.cache"
            if os.path.isfile(command.format(conda_base=conda_base)):
              command = command + " " + loaders + " > " + cache
              command = command.format(conda_base=conda_base)
              call(command)
        else:
          regenerate_module_files.run(libtbx.env.under_base('.'), only_if_needed=True)
      self.pickle()
      print("libtbx_refresh_is_completed", file=completed_file_name.open("w"))

  def get_module(self, name, must_exist=True):
    result = self.module_dict.get(name, None)
    if (result is None and must_exist):
      raise RuntimeError("libtbx.env.get_module(name=%s): unknown module" % (
        show_string(name)))
    return result

class module:
  def __init__(self, env, name, dist_path=None, mate_suffix="adaptbx"):
    self.env = env
    self.mate_suffix = mate_suffix
    mate_suffix = "_" + mate_suffix
    if (op.normcase(name).endswith(op.normcase(mate_suffix))):
      self.name = name[:-len(mate_suffix)]
      self.names = [self.name, name]
      if (dist_path is not None):
        self.dist_paths = [None, dist_path]
    else:
      self.name = name
      self.names = [name, name + mate_suffix]
      if (dist_path is not None):
        self.dist_paths = [dist_path, None]

  def names_active(self):
    for name,path in zip(self.names, self.dist_paths):
      if (path is not None): yield name

  def names_for_module_listing(self):
    names_active = list(self.names_active())
    if (len(names_active) == 1): return names_active[0]
    return "+".join([self.name, self.mate_suffix])

  def dist_paths_active(self):
    for path in self.dist_paths:
      if (path is not None): yield path

  def name_and_dist_path_pairs(self, all=False):
    for name,path in zip(self.names, self.dist_paths):
      if (all or path is not None): yield (name,path)

  def find_mate(self):
    new_dist_paths = []
    for name,path in self.name_and_dist_path_pairs(all=True):
      if (path is None):
        path = self.env.find_dist_path(module_name=name, optional=True)
      new_dist_paths.append(path)
    self.dist_paths = new_dist_paths

  def process_libtbx_config(self):
    self.python_paths = []
    self.required_for_build = []
    self.required_for_use = []
    self.optional = []
    self.exclude_from_binary_bundle = []
    dist_paths = []
    self.extra_command_line_locations = []
    for dist_path in self.dist_paths:
      if (dist_path is not None):
        while True:
          path = dist_path / "libtbx_config"
          if not path.isfile():
            config = None
            break
          try: f = path.open()
          except IOError: raise RuntimeError(
            'Cannot open configuration file: "%s"' % abs(path))
          try: config = eval(" ".join(f.readlines()), {}, {})
          except KeyboardInterrupt: raise
          except Exception: raise RuntimeError(
            'Corrupt configuration file: "%s"' % abs(path))
          f.close()
          redirection = config.get("redirection", None)
          if (redirection is None):
            break
          if (not isinstance(redirection, str)):
            raise RuntimeError(
              'Corrupt configuration file:\n'
              '  file = "%s"\n'
              '  redirection must be a Python string' % path)
          new_dist_path = op.expandvars(redirection)
          if (not op.isabs(new_dist_path)):
            new_dist_path = libtbx.path.norm_join(dist_path, new_dist_path)
          if (not op.isdir(new_dist_path)):
            raise RuntimeError(
              'Invalid redirection:\n'
              '  file = "%s"\n'
              '  redirection = "%s"\n'
              '  resulting target = "%s"' % (path, redirection, new_dist_path))
          dist_path = new_dist_path
        if (config is not None):
          self.extra_command_line_locations.extend(config.get(
            "extra_command_line_locations", []))
          self.required_for_build.extend(config.get(
            "modules_required_for_build", []))
          self.required_for_use.extend(config.get(
            "modules_required_for_use", []))
          self.optional.extend(config.get(
            "optional_modules", []))
          self.optional.extend(
            set(config.get("optional_modules_only_if_explicit_request", [])) &
            self.env.explicitly_requested_modules)
          sep = os.sep
          for re_pattern in config.get("exclude_from_binary_bundle", []):
            if (sep != "/"):
              re_pattern = re_pattern.replace("/", "\\"+sep)
            self.exclude_from_binary_bundle.append(re_pattern)
      dist_paths.append(dist_path)
    self.dist_paths = dist_paths

  def process_dependencies(self):
    for module_name in self.required_for_build:
      if (not self.env.process_module(
           dependent_module=self, module_name=module_name, optional=True)):
        self.env.missing_for_build.add(module_name)
    for module_name in self.required_for_use:
      if (not self.env.process_module(
           dependent_module=self, module_name=module_name, optional=True)):
        self.env.missing_for_use.add(module_name)
    for module_name in self.optional:
      if (not self.env.process_module(
           dependent_module=self, module_name=module_name, optional=True)):
        self.env.missing_optional.add(module_name)

  def assemble_pythonpath(self):
    result = []
    for dist_path in self.dist_paths_active():
      path = dist_path / "pythonpath"
      if path.isdir():
        result.append(path)
      for sub_dir in ["", self.name]:
        path = dist_path / sub_dir / "__init__.py"
        if path.isfile():
          result.append(path.dirname().dirname())
      path = dist_path / "src"
      if (path / self.name).isdir() or (path / "__init__.py").isfile():
        result.append(path)
    return result

  def has_top_level_directory(self, directory_name):
    for dist_path in self.dist_paths_active():
      if (dist_path / directory_name).isdir():
        return True
    return False

  def is_version_controlled(self):
    for directory_name in ["CVS", ".svn", ".git"]:
      if (self.has_top_level_directory(directory_name=directory_name)):
        return True
    return False

  def write_dispatcher(self,
        source_dir,
        file_name,
        suppress_warning,
        target_file_name_infix="",
        scan_for_libtbx_set_dispatcher_name=False):
    assert target_file_name_infix == "" or not scan_for_libtbx_set_dispatcher_name
    source_dir = self.env.as_relocatable_path(source_dir)
    if (len(file_name) == 0): return
    source_file = source_dir / file_name
    if not source_file.isfile(): return
    file_name_lower = file_name.lower()
    if (file_name_lower.startswith("__init__.py")): return
    if (file_name_lower.endswith(".pyc")): return
    if (file_name_lower.endswith(".pyo")): return
    if (file_name.startswith(".")): return
    if (file_name.endswith("~")): return # ignore emacs backup files
    if (file_name_lower.endswith(".md")): return # ignore markdown files
    if (file_name == "ipython_shell_start.py" and self.name == "libtbx"):
      try: import IPython
      except ImportError: return
    ext = op.splitext(file_name_lower)[1]
    if (scan_for_libtbx_set_dispatcher_name):
      read_size = 1000
    else:
      read_size = 0
    check_for_hash_bang = False
    if (ext == ".launch"):
      assert read_size != 0
    elif (os.name == "nt"):
      if (ext not in windows_pathext): return
    elif (ext == ".bat"):
      return
    elif (ext not in [".sh", ".py"]):
      read_size = max(2, read_size)
      check_for_hash_bang = True
    target_files = []
    if (read_size != 0):
      try:
        with io.open(abs(source_file), encoding='utf-8', errors='ignore') as fh:
          source_text = to_str(fh.read(read_size))
      except IOError:
        raise RuntimeError('Cannot read file: "%s"' % source_file)
      if (check_for_hash_bang and not source_text.startswith("#!")):
        if (not suppress_warning):
          msg = 'WARNING: Ignoring file "%s" due to missing "#!"' % (
            source_file)
          print("*"*len(msg))
          print(msg)
          print("*"*len(msg))
        return
      for line in source_text.splitlines():
        flds = line.split()
        try:
          i = flds.index("LIBTBX_SET_DISPATCHER_NAME")
        except ValueError:
          pass
        else:
          if (i+1 < len(flds)):
            target_files.append(flds[i+1])
        if (ext == ".launch" and "LIBTBX_LAUNCH_EXE" in flds):
          source_file = self.env.under_build(
            op.join(self.name, "exe", file_name[:-len(ext)]+exe_suffix),
            return_relocatable_path=True)
    if (len(target_files) == 0):
      target_file = self.name.lower() + target_file_name_infix
      if (not file_name_lower.startswith("main.")
           or file_name_lower.count(".") != 1):
        target_file += "." + op.splitext(file_name)[0]
      target_files.append(target_file)
    for target_file in target_files:
      self.env._write_dispatcher_in_bin(
        source_file=source_file,
        target_file=target_file)

  def command_line_directory_paths(self):
    result = []
    for dist_path in self.dist_paths_active():
      for sub_dir in ["command_line", os.path.join(self.name, "command_line") ]+ \
        [os.path.join(a,"command_line") for a in getattr(self,"extra_command_line_locations",[])]:
        path = dist_path / sub_dir
        if path.isdir():
          result.append(path)
    return result

  def program_directory_paths(self):
    '''
    Returns the directory for the program templates in a module
    Generally, this "programs" directory is at the same level as the
    "command_line" directory
    '''
    result = []
    for dist_path in self.dist_paths_active():
      for sub_dir in ['programs', os.path.join(self.name, 'programs')] + \
        [os.path.join(a,'programs') for a in getattr(self,"extra_command_line_locations",[])]:
        path = dist_path / sub_dir
        if path.isdir():
          result.append(path)
    return result

  def process_command_line_directories(self):
    for source_dir in self.command_line_directory_paths():
      print("Processing: %s" % show_string(abs(source_dir)))
      def is_py_sh(file_name):
        return file_name.endswith(".sh") \
            or file_name.endswith(".py")
      nodes = source_dir.listdir()
      py_sh_dict = {}
      for file_name in nodes:
        if (is_py_sh(file_name)):
          py_sh_dict.setdefault(file_name[:-3], []).append(file_name[-2:])
      for file_name in nodes:
        if (    is_py_sh(file_name)
            and len(py_sh_dict[file_name[:-3]]) == 2):
          if (os.name == "nt"): skip = ".sh"
          else:                 skip = ".py"
          if (file_name.endswith(skip)):
            continue
        self.write_dispatcher(
          source_dir=source_dir,
          file_name=file_name,
          suppress_warning=False,
          scan_for_libtbx_set_dispatcher_name=True)

  def process_libtbx_refresh_py(self):
    for dist_path in self.dist_paths_active():
      custom_refresh = dist_path / "libtbx_refresh.py"
      if custom_refresh.isfile():
        print("Processing: %s" % show_string(abs(custom_refresh)))
        global_vars = globals()
        global_vars["__name__"] = dist_path.basename() + ".libtbx_refresh"
        global_vars["self"] = self
        with io.open(abs(custom_refresh), encoding='utf-8', errors='ignore') as fh:
          exec(to_str(fh.read()), global_vars)

  def collect_test_scripts(self,
        file_names=["run_tests.py", "run_examples.py"]):
    result = []
    for dist_path in self.dist_paths_active():
      for file_name in file_names:
        path = dist_path / file_name
        if path.isfile(): result.append(path)
    return result

  def remove_obsolete_pyc_if_possible(self, pyc_file_names):
    for file_name in pyc_file_names:
      for dist_path in self.dist_paths_active():
        path = dist_path / file_name
        if path.isfile(): path.remove()

class build_options:

  supported_modes = [
    "release",
    "max_optimized",
    "quick",
    "debug",
    "debug_optimized",
    "profile"]

  def __init__(self,
        compiler,
        mode,
        warning_level,
        static_libraries,
        static_exe,
        scan_boost,
        write_full_flex_fwd_h=default_write_full_flex_fwd_h,
        build_boost_python_extensions=default_build_boost_python_extensions,
        boost_python_no_py_signatures=False,
        boost_python_bool_int_strict=True,
        enable_openmp_if_possible=default_enable_openmp_if_possible,
        enable_boost_threads=True,
        enable_cuda=default_enable_cuda,
        enable_kokkos=default_enable_kokkos,
        use_conda=default_use_conda,
        opt_resources=default_opt_resources,
        precompile_headers=False,
        use_environment_flags=False,
        force_32bit=False,
        msvc_arch_flag=default_msvc_arch_flag,
        enable_cxx11=default_enable_cxx11,
        cxxstd=default_cxxstd,
        skip_phenix_dispatchers=False):

    adopt_init_args(self, locals())
    assert self.mode in build_options.supported_modes
    assert self.warning_level >= 0
    self.optimization = (self.mode in [
      "release", "max_optimized", "debug_optimized", "profile"])
    self.max_optimized = (self.mode in [
      "max_optimized", "debug_optimized", "profile"])
    self.debug_symbols = (self.mode in [
      "debug", "debug_optimized", "profile"])
    if (self.static_exe):
      self.static_libraries = True
    if (self.msvc_arch_flag == "None"): self.msvc_arch_flag = None

  def get_flags_from_environment(self):
    if (self.use_environment_flags ):
      # get compiler flags from environment vars
      # they will be stored at configure in the file libtbx_env
      # and used during build
      self.env_cxxflags = ""
      self.env_cflags = ""
      self.env_cppflags = ""
      self.env_ldflags = ""
      flg = os.environ.get("CXXFLAGS")
      if flg is not None:
        self.env_cxxflags = flg
      flg = os.environ.get("CFLAGS")
      if flg is not None:
        self.env_cflags = flg
      flg = os.environ.get("CPPFLAGS")
      if flg is not None:
        self.env_cppflags = flg
      flg = os.environ.get("LDFLAGS")
      if flg is not None:
        self.env_ldflags = flg

  def report(self, f=None):
    if (f is None): f = sys.stdout
    print("Compiler:", self.compiler, file=f)
    print("Build mode:", self.mode, file=f)
    print("Warning level:", self.warning_level, file=f)
    print("Precompiled Headers:", self.precompile_headers, file=f)
    print("Static libraries:", self.static_libraries, file=f)
    print("Static exe:", self.static_exe, file=f)
    print("Scan Boost headers:", self.scan_boost, file=f)
    print("Write full flex_fwd.h files:", self.write_full_flex_fwd_h, file=f)
    print("Build Boost.Python extensions:", \
      self.build_boost_python_extensions, file=f)
    print("Define BOOST_PYTHON_NO_PY_SIGNATURES:", \
      self.boost_python_no_py_signatures, file=f)
    print("Define BOOST_PYTHON_BOOL_INT_STRICT:", \
      self.boost_python_bool_int_strict, file=f)
    print("Enable OpenMP if possible:", self.enable_openmp_if_possible, file=f)
    print("Boost threads enabled:", self.enable_boost_threads, file=f)
    print("Enable CUDA:", self.enable_cuda, file=f)
    print("Enable KOKKOS:", self.enable_kokkos, file=f)
    print("Use conda:", self.use_conda, file=f)
    print("Use opt_resources if available:", self.opt_resources, file=f)
    print("Use environment flags:", self.use_environment_flags, file=f)
    print("Enable C++11:", self.enable_cxx11, file=f)
    if( self.use_environment_flags ):
      print("  CXXFLAGS = ", self.env_cxxflags, file=f)
      print("  CFLAGS = ", self.env_cflags, file=f)
      print("  CPPFLAGS = ", self.env_cppflags, file=f)
      print("  LDFLAGS = ", self.env_ldflags, file=f)

class include_registry:

  def __init__(self):
    self._boost_dir_name = "boost"
    self._had_message = {}
    self.scan_boost()

  def scan_boost(self, flag=False):
    self._scan_boost = flag
    return self

  def set_boost_dir_name(self, path):
    self._boost_dir_name = op.basename(path).lower()

  def scan_flag(self, path):
    if (not self._scan_boost
        and op.basename(path).lower() == self._boost_dir_name):
      if (not path in self._had_message):
        print("libtbx.scons: implicit dependency scan disabled for directory", end=' ')
        print(path)
        self._had_message[path] = 1
      return False
    return True

  def prepend_include_switch(self, env, path):
    assert isinstance(path, str)
    return env["INCPREFIX"] + path

  def append(self, env, paths):
    assert isinstance(paths, list)
    paths = unique_paths(paths=paths)
    for path in paths:
      if (self.scan_flag(path)):
        env.Append(CPPPATH=[path])
      else:
        ipath = self.prepend_include_switch(env, path)
        env.Append(CXXFLAGS=[ipath])
        env.Append(SHCXXFLAGS=[ipath])

  def prepend(self, env, paths):
    assert isinstance(paths, list)
    paths = unique_paths(paths=paths)
    paths.reverse()
    for path in paths:
      if (self.scan_flag(path)):
        env.Prepend(CPPPATH=[path])
      else:
        ipath = self.prepend_include_switch(env, path)
        env.Prepend(CXXFLAGS=[ipath])
        env.Prepend(SHCXXFLAGS=[ipath])

class pre_process_args:

  def __init__(self, args, default_repositories=None):
    self.repository_paths = []
    if (len(args) == 0): args = ["--help"]
    if (default_repositories is None):
      command_name = "libtbx.configure"
      self.warm_start = True
    else:
      command_name = "libtbx/configure.py"
      self.warm_start = False
    from libtbx.option_parser import option_parser
    parser = option_parser(
      usage="%s [options] module_name[=redirection_path] ..." % command_name)
    if (self.warm_start):
      parser.option(None, "--only",
        action="store_true",
        default=False,
        help="disable previously configured modules")
      parser.option(None, "--exclude",
        action="store",
        type="string",
        default=None,
        help="Modules to leave out from configuration")
    else:
      parser.option("-r", "--repository",
        action="callback",
        type="string",
        callback=self.option_repository,
        help="path to source code repository"
          " (may be specified multiple times;"
          " paths are searched in the order given)",
        metavar="DIRECTORY")
      if (hasattr(os.path, "samefile")):
        parser.option(None, "--current_working_directory",
          action="store",
          type="string",
          default=None,
          help="preferred spelling of current working directory"
            " (to resolve ambiguities due to soft links)",
          metavar="DIRECTORY")
      parser.option(None, "--build",
        choices=build_options.supported_modes,
        default="release",
        help="build mode (default: release)",
        metavar="|".join(build_options.supported_modes))
      parser.option(None, "--compiler",
        action="store",
        type="string",
        default="default",
        help="select non-standard compiler (platform dependent)",
        metavar="STRING")
      parser.option(None, "--warning_level",
        action="store",
        type="int",
        default=0,
        help="manipulate warning options (platform dependent)")
      parser.option(None, "--static_libraries",
        action="store_true",
        default=False,
        help="build all libraries statically")
      parser.option(None, "--static_exe",
        action="store_true",
        default=False,
        help="link all executables statically (implies --static_libraries)")
      parser.option(None, "--scan_boost",
        action="store_true",
        default=False,
        help="enable implicit dependency scan")
      parser.option(None, "--write_full_flex_fwd_h",
        action="store_true",
        default=default_write_full_flex_fwd_h,
        help="create full flex_fwd.h files to work around platform-specific"
             " problems (see comments in cctbx.source_generators.flex_fwd_h)")
      parser.option(None, "--command_version_suffix",
        action="store",
        type="string",
        default=None,
        help="version suffix for commands in bin directory",
        metavar="STRING")
      parser.option(None, "--use_environment_flags",
        action="store_true",
        default=False,
        help="add compiler flags from environment variables: CXXFLAGS, CFLAGS,"
             " CPPFLAGS, LDFLAGS")
      parser.option(None, "--force_32bit",
        action="store_true",
        default=False,
        help="Force 32-bit compilation on Mac OS 10.6 (Snow Leopard)\n"
             "Not compatible with /usr/bin/python: please run configure\n"
             "with /System/Library/Frameworks/Python.framework/"
             "Versions/2.x/bin/python")
      msvc_arch_flag_choices = ("None", "SSE", "SSE2")
      parser.option(None, "--msvc_arch_flag",
        choices=msvc_arch_flag_choices,
        default=default_msvc_arch_flag,
        help="choose MSVC CPU architecture instruction set"
             " for optimized builds",
        metavar="|".join(msvc_arch_flag_choices))
    parser.option(None, "--build_boost_python_extensions",
      action="store",
      type="bool",
      default=default_build_boost_python_extensions,
      help="build Boost.Python extension modules (default: %s)"
        % default_build_boost_python_extensions,
      metavar="True|False")
    parser.option(None, "--enable_openmp_if_possible",
      action="store",
      type="bool",
      default=default_enable_openmp_if_possible,
      help="use OpenMP if available and known to work (default: %s)"
        % default_enable_openmp_if_possible,
      metavar="True|False")
    parser.option(None, "--enable_boost_threads",
      action="store",
      type="bool",
      default=default_enable_boost_threads,
      help="make Boost.Threads available")
    parser.option(None, "--enable_cuda",
      action="store_true",
      default=default_enable_cuda,
      help="Use optimized CUDA routines for certain calculations.  Requires at least one NVIDIA GPU with compute capability of 2.0 or higher, and CUDA Toolkit 4.0 or higher (default: %s)"
        % default_enable_cuda)
    parser.option(None, "--enable_kokkos",
      action="store_true",
      default=default_enable_kokkos,
      help="Use optimized KOKKOS routines for certain calculations. Which backend (CUDA/HIP/OpenMP) is used, depends on the system (default: %s)"
        % default_enable_kokkos)
    parser.option(None, "--use_conda",
      action="store_true",
      default=default_use_conda,
      help="Use conda as the source for Python and dependencies (default: %s)"
        % default_use_conda)
    parser.option(None, "--opt_resources",
      action="store",
      type="bool",
      default=default_opt_resources,
      help="use opt_resources if available (default: %s)"
        % default_opt_resources,
      metavar="True|False")
    parser.option(None, "--precompile_headers",
      action="store_true",
      default=False,
      help="Precompile headers, especially Boost Python ones (default: don't)")
    if (not self.warm_start):
      parser.option(None, "--boost_python_no_py_signatures",
        action="store_true",
        default=False,
        help="disable Boost.Python docstring Python signatures")
      parser.option(None, "--boost_python_bool_int_strict",
        action="store_false",
        default=True,
        help="disable Boost.Python implicit bool<->int conversions")
    parser.option(None, "--clear_scons_memory",
      action="store_true",
      default=False,
      help="remove scons build signatures and config cache")
    parser.option(None, "--no_bin_python",
                  action="store_true",
                  default=False,
                  help="do not create <build directory>/bin/python even in a development "
                       "environment")
    parser.option(None, "--enable_cxx11",
      action="store_true",
      default=default_enable_cxx11,
      help="use C++11 standard")
    parser.option(None, "--cxxstd",
      action="store",
      type="choice",
      default=default_cxxstd,
      choices=['c++11', 'c++14'], # this should just be the argument to the -std flag
      help="Set the C++ standard. This cannot be set along with --enable_cxx11")
    parser.option("--skip_phenix_dispatchers",
      action="store_true",
      default=False,
      help="Skip all dispatchers with 'phenix' in the title")
    self.command_line = parser.process(args=args)
    if (len(self.command_line.args) == 0):
      raise RuntimeError(
        "At least one module name is required"
        " (use --help to obtain more information).")
    if (not hasattr(os.path, "samefile")):
      self.command_line.options.current_working_directory = None
    if (default_repositories is not None):
      self.repository_paths.extend(default_repositories)
    if (not self.warm_start):
      if (self.command_line.options.force_32bit):
        if (sys.platform != "darwin"):
          raise RuntimeError(
            "The --force_32bit option is only valid on Mac OS systems.")
        if (sys.maxsize > 2**31-1):
          raise RuntimeError(
            'The --force_32bit option can only be used with 32-bit Python.\n'
            '  See also: "man python"')
        from libtbx import easy_run
        buffers = easy_run.fully_buffered(
          command="/usr/bin/arch -i386 /bin/ls /")
        if (   len(buffers.stderr_lines) != 0
            or len(buffers.stdout_lines) == 0):
          raise RuntimeError(
            "The --force_32bit option is not valid for this platform.")
      if (    self.command_line.options.msvc_arch_flag != "None"
          and os.name != "nt"):
        raise RuntimeError(
          "The --msvc_arch_flag option is not valid for this platform.")

      # check that only enable_cxx11 or cxxstd is set
      if self.command_line.options.enable_cxx11 \
        and self.command_line.options.cxxstd is not None:
        raise RuntimeError('''
Both --enable_cxx11 and --cxxstd have been set. Please only set one of
these options.
      ''')

  def option_repository(self, option, opt, value, parser):
    if (not op.isdir(value)):
      raise RuntimeError(
        "Not a directory: --repository %s" % show_string(value))
    self.repository_paths.append(value)

def set_preferred_sys_prefix_and_sys_executable(build_path):
  if (not hasattr(os.path, "samefile")): return
  dirname, basename = op.split(sys.prefix)
  if (dirname and op.samefile(build_path, dirname)):
    new_prefix = op.join(build_path, basename)
    if (op.samefile(new_prefix, sys.prefix)):
      p = op.normpath(op.normcase(sys.prefix))
      if (sys.prefix != new_prefix):
        sys.prefix = new_prefix
      e = op.normpath(op.normcase(sys.executable))
      if (e.startswith(p)):
        new_executable = sys.prefix + e[len(p):]
        if (op.samefile(new_executable, sys.executable)):
          if (sys.executable != new_executable):
            sys.executable = new_executable

def raise_if_source_directory_suspected():
  likely_sources = []
  for level1 in os.listdir("."):
    if (not op.isdir(level1)): continue
    if (level1 == "cctbx_project"):
      likely_sources.append(level1)
    else:
      for file_name in [
            "libtbx_config",
            "libtbx_refresh.py",
            "libtbx_SConscript"]:
        level2 = op.join(level1, file_name)
        if (op.isfile(level2)):
          likely_sources.append(level1)
  if likely_sources:
    likely_sources = sorted(set(likely_sources))
    if (len(likely_sources) == 1): t = "this"; s = "y"
    else:                          t = "these"; s = "ies"
    msg = ["Safety guard:",
      "  The current working directory appears to be a source directory",
      "  as determined by the presence of %s sub-director%s:" % (t, s)]
    msg.extend(["    %s" % show_string(d) for d in likely_sources])
    msg.extend([
      "  To resolve this problem:",
      "  - If this command was accidentally run in the wrong directory,",
      "    change to the correct build directory.",
      "  - Remove or rename the director%s listed above." %s])
    raise RuntimeError("\n".join(msg))

def cold_start(args):
  raise_if_source_directory_suspected()
  cwd_was_empty_at_start = True
  for file_name in os.listdir("."):
    if not file_name.startswith("."):
      cwd_was_empty_at_start = False
      break
  default_repositories = []
  r = op.dirname(op.dirname(args[0]))
  b = op.basename(r)
  if b.lower().startswith("cctbx_project"):
    default_repositories.append(op.dirname(r))
  default_repositories.append(r)
  pre_processed_args = pre_process_args(
    args=args[1:],
    default_repositories=default_repositories)
  build_path=pre_processed_args.command_line.options.current_working_directory
  if (build_path is None):
    build_path = os.getcwd()
  else:
    if (not op.isabs(build_path)):
      raise RuntimeError("Not an absolute path name:"
        " --current_working_directory %s" % show_string(build_path))
    if (not op.isdir(build_path)):
      raise RuntimeError("Not a directory:"
        " --current_working_directory %s" % show_string(build_path))
    if (not op.samefile(build_path, os.getcwd())):
      raise RuntimeError("Not equivalent to the current working directory:"
        " --current_working_directory %s" % show_string(build_path))
    n = len(os.sep)
    while (len(build_path) > n and build_path.endswith(os.sep)):
      build_path = build_path[:-n]
  set_preferred_sys_prefix_and_sys_executable(build_path=build_path)
  env = environment(build_path=build_path)
  env.process_args(pre_processed_args=pre_processed_args)
  if (   pre_processed_args.command_line.options.clear_scons_memory
      or cwd_was_empty_at_start):
    env.clear_scons_memory()
  env.refresh()

def unpickle(build_path=None, env_name="libtbx_env"):
  '''
  Function for loading a libtbx_env file. The build_path and env_name
  parameters are for checking additional environment files.

  Parameters
  ----------
    build_path: str
      The directory containing the environment file
    env_name: str
      The filename for the environment file, default is "libtbx_env"

  Returns
  -------
    env: environment object
  '''
  # try default location in build directory
  if build_path is None:
    build_path = os.getenv("LIBTBX_BUILD")
  # try default installed location
  if not build_path:
    build_path = get_installed_path()
  set_preferred_sys_prefix_and_sys_executable(build_path=build_path)
  with open(op.join(build_path, env_name), "rb") as libtbx_env:
    env = pickle.load(libtbx_env)
  if (env.python_version_major_minor != sys.version_info[:2]):
    env.raise_python_version_incompatible()
  if (op.realpath(build_path) != op.realpath(abs(env.build_path))):
    env.build_path.reset(build_path)
  # XXX backward compatibility 2018-12-10
  if not hasattr(env.build_options, "use_conda"):
    env.build_options.use_conda = False
  # XXX backward compatibility 2020-08-21
  # for installed copies of cctbx, the installed environment is not modifiable
  if not hasattr(env, "installed"):
    env.installed = False
  if not hasattr(env, "installed_modules"):
    env.installed_modules = []
  if not hasattr(env, "installed_order"):
    env.installed_order = []
  # XXX backward compatibility 2022-01-19
  if not hasattr(env.build_options, "enable_kokkos"):
    env.build_options.enable_kokkos = False
  # XXX backward compatibility 2022-12-07
  if not hasattr(env.build_options, "cxxstd"):
    env.build_options.cxxstd = None
  # update installed location
  if env.installed:
    sys_prefix = get_conda_prefix()
    if sys.platform == 'win32':
      sys_prefix = op.join(sys_prefix, 'library')
    sys_prefix = absolute_path(sys_prefix)
    for i in range(len(env.repository_paths)):
      env.repository_paths[i]._anchor = sys_prefix
    env.bin_path._anchor = sys_prefix
    env.exe_path._anchor = sys_prefix
    env.include_path._anchor = sys_prefix
    env.lib_path._anchor = sys_prefix
    env.path_utility._anchor = sys_prefix
    if sys.platform == 'win32':
      for module in env.module_list:
        for dist_path in module.dist_paths:
          if dist_path is not None:
            dist_path._anchor = sys_prefix
  return env

def warm_start(args):
  env = unpickle()
  # ---------------------------------------------------------------------------
  def _warm_start(env, args):
    pre_processed_args = pre_process_args(args=args[1:])
    env.process_args(pre_processed_args=pre_processed_args)
    if (pre_processed_args.command_line.options.clear_scons_memory):
      env.clear_scons_memory()
    env.refresh()
  # ---------------------------------------------------------------------------
  # check if the loaded environment is modifiable
  if env.installed:
    # fix classes
    from libtbx.env_config import build_options as _build_options
    from libtbx.env_config import environment as _environment
    from libtbx.env_config import module as _module

    globals()['build_options'] = _build_options
    globals()['environment'] = _environment
    globals()['module'] = _module

    # load an existing, modifiable environment from the current directory
    if op.exists(op.join(os.getcwd(), "libtbx_env")):
      env = unpickle(build_path=os.getcwd())
      _warm_start(env, args)
    # or create new environment in current directory if it does not exist
    # currently can only run configuration in the "build" directory, so
    # "modules" is one level up.
    else:
      repository_paths = ['-r', os.path.join('..', 'modules')]
      cctbx_project = os.path.join('..', 'modules', 'cctbx_project')
      if os.path.isdir(cctbx_project):
        repository_paths += ['-r', cctbx_project]
      cold_start(args + repository_paths + ['--no_bin_python'])
      env = unpickle(build_path=os.getcwd())
      env.pickle()  # need separate call
  # continue normally
  else:
    _warm_start(env, args)

def get_installed_path():
  """
  Returns the default location of an installed environment
  """
  if sys.platform == 'win32':
    installed_path = os.path.join(sys.prefix, 'Library', 'share', 'cctbx')
  else:
    installed_path = os.path.join(get_conda_prefix(), 'share', 'cctbx')
  return installed_path

def _get_env(build_path, env_name='libtbx_env'):
  current_env = None
  if op.isfile(op.join(build_path, env_name)):
    current_env = unpickle(build_path, env_name)
  return current_env

def get_installed_env():
  """
  Returns the installed environment in the default location or None if
  it does not exist.
  """
  return _get_env(get_installed_path())

def get_local_env(build_dir=None):
  """
  Returns the local environment from build_dir or None
  if it does not exist. By default, build_dir is set to the current
  working directory.

  Parameters
  ----------
    build_dir: str
      The directory with the local environment. Defaults to the current
      working directory

  Returns
  -------
    env: libtbx.env_config.environment or None
      The environment loaded from build_dir or None if it does not
  """
  if build_dir is None:
    build_dir = os.getcwd()
  env = None
  for p in [build_dir] + sys.path:
    e = _get_env(p)
    if e is not None:
      env = e
      break
  return env

def get_boost_library_with_python_version(name, libpath):
  """
  Standard Boost.Python libraries may have the Python version appended
  as a suffix. This function returns the name with the current Python
  version if there is a file with that name in LIBPATH. Otherwise, it
  will return the original name. For example, libboost_python.so may be
  named libboost_python27.so for Python 2.7.

  Parameters
  ----------
  name: str
    The base name for a library (e.g. "boost_python")
  libpath: list
    The paths to search for this library

  Returns
  -------
  name: str
    The input name modified with the current Python version, if available
  """

  version = str(sys.version_info.major) + str(sys.version_info.minor)
  for p in libpath:
    name_version = name + version
    if sys.platform == 'win32':
      full_names = [os.path.join(p, name_version + '.dll'),
                    os.path.join(p, name_version + '.lib')]
    else:
      full_name = os.path.join(p, 'lib' + name_version)
      if sys.platform == 'darwin':
        full_name += '.dylib'
      else:
        full_name += '.so'
      full_names = [full_name]
    for full_name in full_names:
      if os.path.isfile(full_name):
        return name_version
  return name

if (__name__ == "__main__"):
  if (len(sys.argv) == 2 and sys.argv[1] == "__libtbx_refresh__"):
    unpickle().refresh()
  else:
    warm_start(sys.argv)
  print("Done.")


 *******************************************************************************
