

 *******************************************************************************
cctbx_website/__init__.py


 *******************************************************************************


 *******************************************************************************
cctbx_website/command_line/__init__.py


 *******************************************************************************


 *******************************************************************************
cctbx_website/command_line/edit_for_boost.py
"""
Edit python file that contains boost instructions to make it useable
by pdoc3.

Replace code block like:

bp.inject(ext.root, __hash_eq_mixin)
@bp.inject_into(ext.root)
class _():

with

class root:

"""
from __future__ import absolute_import, division, print_function

def get_boost_names(text):
  """find code blocks like:

@bp.inject_into(ext.root)
class _():

and save "root"
  """

  key_text = "@bp.inject_into(ext."
  boost_names = []
  for line in text.splitlines():
    if line.rstrip().startswith(key_text):
      boost_names.append(line.replace(key_text,"").replace(")",""))
  return boost_names


def edit_boost_code_blocks(text, boost_names):
  """Edit the boost code blocks"""

  for boost_name in boost_names:
    search_text = """bp.inject(ext.%s, __hash_eq_mixin)
@bp.inject_into(ext.%s)
class _():""" %(boost_name, boost_name)

    search_text2 = """@bp.inject_into(ext.%s)
class _():""" %(boost_name)

    replacement_text ="class %s:" %(boost_name)
    start_text = str(text)
    text = text.replace(search_text, replacement_text)

    if text == start_text: # try alternate version
      text = text.replace(search_text2, replacement_text)

  return text


def run(args):
  """
  Expect path to file
  """
  assert len(args) == 1
  fn = args[0]
  text = open(fn).read()
  boost_names = get_boost_names(text)
  print("Editing the following boost_names: %s" %(" ".join(boost_names)))
  text = edit_boost_code_blocks(text, boost_names)

  f = open(fn, 'w')
  print(text, file = f)
  f.close()
  print("Wrote edited text to %s" %(fn))

if __name__ == "__main__":
  import sys
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx_website/command_line/edit_html.py
"""
Edit index.html files to simplify the path for display
"""
from __future__ import absolute_import, division, print_function
import os

def run(args):
  """
  Expect path to file and name of indexing directory relative to top level
  """
  assert len(args) == 2
  fn = args[0]
  indexing_dir = args[1]
  text = open(fn).read()
  text_to_find = get_text_to_replace(text)
  if text_to_find:
    ct = len(text)
    lines = text.splitlines()
    new_lines = []
    for line in lines:
      if line.find("<code") > -1:  # edit lines with code marking (not pre)
        line = line.replace(text_to_find,"")
      new_lines.append(line.rstrip())
    text = "\n".join(new_lines)
    new_ct = len(text)
    print("Text to find: '%s' (%s chars removed)" %(text_to_find, ct - new_ct))

  # Figure out path to top level from file name
  spl = fn.split(os.path.sep)
  paths_to_top_level = []
  for i in range(len(spl) - 1):
    paths_to_top_level.append("..")
  path_to_index = os.path.join(os.path.sep.join(paths_to_top_level),indexing_dir,"index.html")
  text = add_super_module_text(text, path_to_index)

  f = open(fn,'w')
  print(text, file = f)
  f.close()
  print("Wrote edited text to %s" %(fn))

def add_super_module_text(text, path_to_index):
  """
   Find the text:
   "<li><h3><a href="#header-submodules">Sub-modules</a></h3>"

   and replace it with:
   '''
<h3><a href="../../index_files/index.html">CCTBX API Index</a></h3>

<li><h3><a href="#header-supermodules">Super-module</a></h3>
<li><code><a title="cctbx_project" href="../index.html">cctbx_project</a></code></li>
</ul>

<ul id="index">
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
   '''

  If Super-module is already present just add index above it
  """

  text1 = """<li><h3><a href="#header-submodules">Sub-modules</a></h3>"""
  text1a = """<li><h3>Super-module</h3>"""

  text2 = """
<h3><a href="%s ">CCTBX API Index</a></h3>

<li><h3><a href="#header-supermodules">Super-module</a></h3>
<li><code><a title="cctbx_project" href="../index.html">cctbx_project</a></code></li>
</ul>

<ul id="index">
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
""" %(path_to_index)

  text2a = """
<h3><a href="%s ">CCTBX API Index</a></h3>

<li><h3>Super-module</h3>

""" %(path_to_index)


  if text.find(text1a) > -1:
     text = text.replace(text1a, text2a)
  elif text.find(text1) > -1:
     text = text.replace(text1, text2)
  return text

def get_text_to_replace(text):
  """Text to replace looks like iotbx.bioinformatics. , where this comes from:
    ">Module <code>iotbx.bioinformatics<"
    "iotbx.bioinformatics." To be replaced with "" everywhere
    Same for Package
    Hardwired for pdoc3 output html
  """
  spl = text.split(">Module <code>")
  if len(spl) < 2:
     spl = text.split(">Package <code>")
  if len(spl) < 2:
     return None
  if not "<" in spl[1]:
     return None
  spl2 = spl[1].split("<")[0]
  text_to_find = "%s." %(spl2)
  return text_to_find

if __name__ == "__main__":
  import sys
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx_website/command_line/extract_script_from_html_cctbx_doc.py
from __future__ import absolute_import, division, print_function
from io import open
from html.parser import HTMLParser
import os
from libtbx.utils import to_unicode

# ------------------------------------------------------------------------------

class MyHTMLParser(HTMLParser):
  '''
  This is a customized class to extract code from an html file

  Anything that is between <pre></pre> tags will be considered code.
  So only code in the html file that is to be executed in the script
  should be between these tags
  '''

  def __init__(self):
    HTMLParser.__init__(self)
    self.is_code = False
    #self.code_str = list()
    self.code_str = ''

  def handle_starttag(self, tag, attrs):
    #print("Encountered a start tag:", tag)
    if tag == 'pre' and attrs == [(u'class', u'codeDL')]:
      self.is_code = True

  def handle_endtag(self, tag):
    #print("Encountered an end tag :", tag)
    if tag == 'pre':
      self.is_code = False

  def handle_data(self, data):
    #print("Encountered some data  :", data)
    if self.is_code == True:
      self.code_str = self.code_str + data
      #self.code_str.extend(data.strip().splitlines())

  def return_result(self):
    return self.code_str

# ------------------------------------------------------------------------------

def run(parent_dir):
  '''
  Walk through directory cctbx_project/cctbx_website/

  Extract code snippets from all .html files in the directory and store them
  in a script with the same basename

  For example:
  template.html --> template.py

  The file template.py will be tested as part of cctbx tests.
  '''
  # this is one directory up: /cctbx_project/cctbx_website/
  #parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

  msg = '''#********************************************************************
# This script is automatically generated when running libtbx.refresh (or bootstrap.py)
# It is not part of the GitHub repository
# So if this script is manually changed, the changes will be lost when updating
#********************************************************************\n'''

  directory = os.path.join(parent_dir, 'html_files')

  for filename in os.listdir(directory):
    # look at all .html files
    if filename.endswith(".html"):
      fn = os.path.join(directory, filename)
      with open(fn, 'r', encoding='utf-8') as html_file:
        # get code in html file
        data = html_file.read()
      parser = MyHTMLParser()
      parser.feed(data)
      code_str = parser.return_result()
      # get filename
      base = os.path.splitext(filename)[0]
      # save code in script and put it in folder cctbx_website/examples/
      dest_dir = os.path.join(parent_dir, 'examples')
      if (not os.path.isdir(dest_dir)):
        os.makedirs(dest_dir)
      script_filename = os.path.join(dest_dir, base+'.py')
      with open(script_filename, 'w', encoding='utf-8') as file:
        file.write(to_unicode('from __future__ import absolute_import, division, print_function\n'))
        file.write(to_unicode(msg))
        file.write(to_unicode(code_str.strip()))
        file.write(to_unicode('\n'))
    else:
      continue


if __name__ == '__main__':
  import libtbx.load_env
  for parent_dir in [libtbx.env.dist_path("cctbx_website", default=None),
    libtbx.env.dist_path("phenix_dev_doc", default=None)]:
    if parent_dir is not None:
      run(parent_dir)


 *******************************************************************************


 *******************************************************************************
cctbx_website/command_line/run_pdoc_cctbx_api.py
# -*- coding: utf-8 -*-

from __future__ import division, print_function
from pdoc import Doc, Context, _pep224_docstrings, _is_public
from pdoc import _is_whitelisted, _is_blacklisted, _is_function, Class
from pdoc import Function, link_inheritance, External, _render_template
from pdoc import Variable, _filter_type

################# MODIFIED CODE FROM pdoc3/__init__.py #################
"""
Python package `pdoc` provides types, functions, and a command-line
interface for accessing public documentation of Python modules, and
for presenting it in a user-friendly, industry-standard open format.
It is best suited for small- to medium-sized projects with tidy,
hierarchical APIs.

.. include:: ./documentation.md
"""
import importlib
import inspect
import os
import os.path as path
import re
import sys
import typing
from contextlib import contextmanager
from copy import copy
from functools import lru_cache
from types import ModuleType
from typing import (  # noqa: F401
    cast, Any, Callable, Dict, Generator, Iterable, List, Literal, Mapping, NewType,
    Optional, Set, Tuple, Type, TypeVar, Union,
)
from warnings import warn

from mako.lookup import TemplateLookup

try:
    from pdoc._version import version as __version__  # noqa: F401
except ImportError:
    __version__ = '???'  # Package not installed


class dummy_module:
  def __init__():
    pass

_get_type_hints = lru_cache()(typing.get_type_hints)

_URL_MODULE_SUFFIX = '.html'
_URL_INDEX_MODULE_SUFFIX = '.m.html'  # For modules named literal 'index'
_URL_PACKAGE_SUFFIX = '/index.html'

# type.__module__ can be None by the Python spec. In those cases, use this value
_UNKNOWN_MODULE = '?'

T = TypeVar('T', 'Module', 'Class', 'Function', 'Variable')

__pdoc__: Dict[str, Union[bool, str]] = {}

tpl_lookup = TemplateLookup(
    cache_args=dict(cached=True,
                    cache_type='memory'),
    input_encoding='utf-8',
    directories=[path.join(path.dirname(__file__), "templates")],
)
"""
A `mako.lookup.TemplateLookup` object that knows how to load templates
from the file system. You may add additional paths by modifying the
object's `directories` attribute.
"""
if os.getenv("XDG_CONFIG_HOME"):
    tpl_lookup.directories.insert(0, path.join(os.getenv("XDG_CONFIG_HOME", ''), "pdoc"))


def import_module(module: Union[str, ModuleType],
                  *, reload: bool = False) -> ModuleType:
    """
    Return module object matching `module` specification (either a python
    module path or a filesystem path to file/directory).
    """
    @contextmanager
    def _module_path(module):
        from os.path import abspath, dirname, isfile, isdir, split
        path = '_pdoc_dummy_nonexistent'
        module_name = inspect.getmodulename(module)
        if isdir(module):
            path, module = split(abspath(module))
        elif isfile(module) and module_name:
            path, module = dirname(abspath(module)), module_name
        try:
            sys.path.insert(0, path)
            yield module
        finally:
            sys.path.remove(path)

    if isinstance(module, Module):
        module = module.obj
    if isinstance(module, str):
        with _module_path(module) as module_path:
            original_module = module
            try:
                module = importlib.import_module(module_path)
            except Exception as e:
                print("FAILED TO IMPORT ",original_module,module_path,"::",str(e),"::")
                from copy import deepcopy
                module = deepcopy(dummy_module) # skipping it and marking
                module.__name__= "%s_dummy_module" %(original_module)
                print("FAILED_TO_IMPORT_MODULE:",original_module)
                failed_file = 'pdoc.failed'
                if os.path.isfile(failed_file):
                  f = open(failed_file,'a')
                else:
                  f = open(failed_file,'w')
                print(original_module, file = f)
                f.close()

    assert inspect.ismodule(module)
    # If this is pdoc itself, return without reloading. Otherwise later
    # `isinstance(..., pdoc.Doc)` calls won't work correctly.
    if reload and not module.__name__.startswith(__name__):
        module = importlib.reload(module)
        # We recursively reload all submodules, in case __all_ is used - cf. issue #264
        for mod_key, mod in list(sys.modules.items()):
            if mod_key.startswith(module.__name__):
                importlib.reload(mod)
    return module


class Module(Doc):
    """
    Representation of a module's documentation.
    """
    __pdoc__["Module.name"] = """
        The name of this module with respect to the context/path in which
        it was imported from. It is always an absolute import path.
        """

    __slots__ = ('supermodule', 'doc', '_context', '_is_inheritance_linked',
                 '_skipped_submodules')

    def __init__(self, module: Union[ModuleType, str], *,
                 docfilter: Optional[Callable[[Doc], bool]] = None,
                 supermodule: Optional['Module'] = None,
                 context: Optional[Context] = None,
                 skip_errors: bool = False):
        """
        Creates a `Module` documentation object given the actual
        module Python object.

        `docfilter` is an optional predicate that controls which
        sub-objects are documentated (see also: `pdoc.html()`).

        `supermodule` is the parent `pdoc.Module` this module is
        a submodule of.

        `context` is an instance of `pdoc.Context`. If `None` a
        global context object will be used.

        If `skip_errors` is `True` and an unimportable, erroneous
        submodule is encountered, a warning will be issued instead
        of raising an exception.
        """
        if isinstance(module, str):
          original_module = module
          try:
            module = import_module(module)
          except Exception as e:
            from copy import deepcopy
            module = deepcopy(dummy_module) # skipping it and marking name
            module.__name__= "%s_dummy_module" %(original_module)
            print("FAILED_IMPORT_MODULE:",original_module)
            failed_file = 'pdoc.failed'
            if os.path.isfile(failed_file):
              f = open(failed_file,'a')
            else:
              f = open(failed_file,'w')
            print(original_module, file = f)
            f.close()

        super().__init__(module.__name__, self, module)
        if self.name.endswith('.__init__') and not self.is_package:
            self.name = self.name[:-len('.__init__')]

        self._context = _global_context if context is None else context
        """
        A lookup table for ALL doc objects of all modules that share this context,
        mainly used in `Module.find_ident()`.
        """
        #assert isinstance(self._context, Context), \ 'pdoc.Module(context=) should be a pdoc.Context instance'

        self.supermodule = supermodule
        """
        The parent `pdoc.Module` this module is a submodule of, or `None`.
        """

        self.doc: Dict[str, Union[Module, Class, Function, Variable]] = {}
        """A mapping from identifier name to a documentation object."""

        self._is_inheritance_linked = False
        """Re-entry guard for `pdoc.Module._link_inheritance()`."""

        self._skipped_submodules = set()

        var_docstrings, _ = _pep224_docstrings(self)

        # Populate self.doc with this module's public members
        public_objs = []
        if hasattr(self.obj, '__all__'):
            for name in self.obj.__all__:
                try:
                    obj = getattr(self.obj, name)
                except AttributeError:
                    warn(f"Module {self.module!r} doesn't contain identifier `{name}` "
                         "exported in `__all__`")
                else:
                    if not _is_blacklisted(name, self):
                        obj = inspect.unwrap(obj)
                    public_objs.append((name, obj))
        else:
            def is_from_this_module(obj):
                mod = inspect.getmodule(inspect.unwrap(obj))
                return mod is None or mod.__name__ == self.obj.__name__

            for name, obj in inspect.getmembers(self.obj):
                if ((_is_public(name) or
                     _is_whitelisted(name, self)) and
                        (_is_blacklisted(name, self) or  # skips unwrapping that follows
                         is_from_this_module(obj) or
                         name in var_docstrings)):

                    if _is_blacklisted(name, self):
                        self._context.blacklisted.add(f'{self.refname}.{name}')
                        continue

                    obj = inspect.unwrap(obj)
                    public_objs.append((name, obj))

            index = list(self.obj.__dict__).index
            public_objs.sort(key=lambda i: index(i[0]))

        for name, obj in public_objs:
            if _is_function(obj):
                self.doc[name] = Function(name, self, obj)
            elif inspect.isclass(obj):
                self.doc[name] = Class(name, self, obj)
            elif name in var_docstrings:
                self.doc[name] = Variable(name, self, var_docstrings[name], obj=obj)

        # If the module is a package, scan the directory for submodules
        if self.is_package:

            def iter_modules(paths):
                """
                Custom implementation of `pkgutil.iter_modules()`
                because that one doesn't play well with namespace packages.
                See: https://github.com/pypa/setuptools/issues/83
                """
                from os.path import isdir, join
                for pth in paths:
                    if pth.startswith("__editable__."):
                        # See https://github.com/pypa/pip/issues/11380
                        continue
                    for file in os.listdir(pth):
                        if file.startswith(('.', '__pycache__', '__init__.py')):
                            continue
                        module_name = inspect.getmodulename(file)
                        if module_name:
                            yield module_name
                        if isdir(join(pth, file)) and '.' not in file:
                            yield file

            for root in iter_modules(self.obj.__path__):
                # Ignore if this module was already doc'd.
                if root in self.doc:
                    continue

                # Ignore if it isn't exported
                if not _is_public(root) and not _is_whitelisted(root, self):
                    continue
                if _is_blacklisted(root, self):
                    self._skipped_submodules.add(root)
                    continue

                assert self.refname == self.name
                fullname = f"{self.name}.{root}"
                try:
                    m = Module(import_module(fullname),
                               docfilter=docfilter, supermodule=self,
                               context=self._context, skip_errors=skip_errors)
                except Exception as ex:
                    if skip_errors:
                        warn(str(ex), Module.ImportWarning)
                        continue
                    raise

                self.doc[root] = m
                # Skip empty namespace packages because they may
                # as well be other auxiliary directories
                if m.is_namespace and not m.doc:
                    del self.doc[root]
                    self._context.pop(m.refname)

        # Apply docfilter
        if docfilter:
            for name, dobj in self.doc.copy().items():
                if not docfilter(dobj):
                    self.doc.pop(name)
                    self._context.pop(dobj.refname, None)

        # Build the reference name dictionary of the module
        self._context[self.refname] = self
        for docobj in self.doc.values():
            self._context[docobj.refname] = docobj
            if isinstance(docobj, Class):
                self._context.update((obj.refname, obj)
                                     for obj in docobj.doc.values())

    class ImportWarning(UserWarning):
        """
        Our custom import warning because the builtin is ignored by default.
        https://docs.python.org/3/library/warnings.html#default-warning-filter
        """

    __pdoc__['Module.ImportWarning'] = False

    @property
    def __pdoc__(self) -> dict:
        """This module's __pdoc__ dict, or an empty dict if none."""
        return getattr(self.obj, '__pdoc__', {})

    def _link_inheritance(self):
        # Inherited members are already in place since
        # `Class._fill_inheritance()` has been called from
        # `pdoc.fill_inheritance()`.
        # Now look for docstrings in the module's __pdoc__ override.

        if self._is_inheritance_linked:
            # Prevent re-linking inheritance for modules which have already
            # had done so. Otherwise, this would raise "does not exist"
            # errors if `pdoc.link_inheritance()` is called multiple times.
            return

        # Apply __pdoc__ overrides
        for name, docstring in self.__pdoc__.items():
            # In case of whitelisting with "True", there's nothing to do
            if docstring is True:
                continue

            refname = f"{self.refname}.{name}"
            if docstring in (False, None):
                if docstring is None:
                    warn('Setting `__pdoc__[key] = None` is deprecated; '
                         'use `__pdoc__[key] = False` '
                         f'(key: {name!r}, module: {self.name!r}).')

                if name in self._skipped_submodules:
                    continue

                if (not name.endswith('.__init__') and
                        name not in self.doc and
                        refname not in self._context and
                        refname not in self._context.blacklisted):
                    warn(f'__pdoc__-overriden key {name!r} does not exist '
                         f'in module {self.name!r}')

                obj = self.find_ident(name)
                cls = getattr(obj, 'cls', None)
                if cls:
                    del cls.doc[obj.name]
                self.doc.pop(name, None)
                self._context.pop(refname, None)

                # Pop also all that startwith refname
                for key in list(self._context.keys()):
                    if key.startswith(refname + '.'):
                        del self._context[key]

                continue

            dobj = self.find_ident(refname)
            if isinstance(dobj, External):
                continue
            if not isinstance(docstring, str):
                raise ValueError('__pdoc__ dict values must be strings; '
                                 f'__pdoc__[{name!r}] is of type {type(docstring)}')
            dobj.docstring = inspect.cleandoc(docstring)

        # Now after docstrings are set correctly, continue the
        # inheritance routine, marking members inherited or not
        for c in _filter_type(Class, self.doc):
            c._link_inheritance()

        self._is_inheritance_linked = True

    def text(self, **kwargs) -> str:
        """
        Returns the documentation for this module as plain text.
        """
        txt = _render_template('/text.mako', module=self, **kwargs)
        return re.sub("\n\n\n+", "\n\n", txt)

    def html(self, minify=True, **kwargs) -> str:
        """
        Returns the documentation for this module as
        self-contained HTML.

        If `minify` is `True`, the resulting HTML is minified.

        For explanation of other arguments, see `pdoc.html()`.

        `kwargs` is passed to the `mako` render function.
        """
        html = _render_template('/html.mako', module=self, **kwargs)
        if minify:
            from pdoc.html_helpers import minify_html
            html = minify_html(html)
        if not html.endswith('\n'):
            html = html + '\n'
        return html

    @property
    def is_package(self) -> bool:
        """
        `True` if this module is a package.

        Works by checking whether the module has a `__path__` attribute.
        """
        return hasattr(self.obj, "__path__")

    @property
    def is_namespace(self) -> bool:
        """
        `True` if this module is a namespace package.
        """
        try:
            return self.obj.__spec__.origin in (None, 'namespace')  # None in Py3.7+
        except AttributeError:
            return False

    def find_class(self, cls: type) -> Doc:
        """
        Given a Python `cls` object, try to find it in this module
        or in any of the exported identifiers of the submodules.
        """
        # XXX: Is this corrent? Does it always match
        # `Class.module.name + Class.qualname`?. Especially now?
        # If not, see what was here before.
        return self.find_ident(f'{cls.__module__ or _UNKNOWN_MODULE}.{cls.__qualname__}')

    def find_ident(self, name: str) -> Doc:
        """
        Searches this module and **all** other public modules
        for an identifier with name `name` in its list of
        exported identifiers.

        The documentation object corresponding to the identifier is
        returned. If one cannot be found, then an instance of
        `External` is returned populated with the given identifier.
        """
        _name = name.rstrip('()')  # Function specified with parentheses

        if _name.endswith('.__init__'):  # Ref to class' init is ref to class itself
            _name = _name[:-len('.__init__')]

        return (self.doc.get(_name) or
                self._context.get(_name) or
                self._context.get(f'{self.name}.{_name}') or
                External(name))

    def _filter_doc_objs(self, type: Type[T], sort=True) -> List[T]:
        result = _filter_type(type, self.doc)
        return sorted(result) if sort else result

    def variables(self, sort=True) -> List['Variable']:
        """
        Returns all documented module-level variables in the module,
        optionally sorted alphabetically, as a list of `pdoc.Variable`.
        """
        return self._filter_doc_objs(Variable, sort)

    def classes(self, sort=True) -> List['Class']:
        """
        Returns all documented module-level classes in the module,
        optionally sorted alphabetically, as a list of `pdoc.Class`.
        """
        return self._filter_doc_objs(Class, sort)

    def functions(self, sort=True) -> List['Function']:
        """
        Returns all documented module-level functions in the module,
        optionally sorted alphabetically, as a list of `pdoc.Function`.
        """
        return self._filter_doc_objs(Function, sort)

    def submodules(self) -> List['Module']:
        """
        Returns all documented sub-modules of the module sorted
        alphabetically as a list of `pdoc.Module`.
        """
        return self._filter_doc_objs(Module)

    def _url(self):
        url = self.module.name.replace('.', '/')
        if self.is_package:
            return url + _URL_PACKAGE_SUFFIX
        elif url.endswith('/index'):
            return url + _URL_INDEX_MODULE_SUFFIX
        return url + _URL_MODULE_SUFFIX
################# END MODIFIED CODE FROM pdoc3/__init__.py #################

def run(args, top_level = None):

  # Catch failed imports in 'pdoc.failed'
  failed_file = 'pdoc.failed'
  if os.path.isfile (failed_file):
     try:
       os.remove(failed_file)
     except Exception as e:
       pass # another job removed it...

  modules = args
  context = Context()

  new_modules = []
  for mod in modules:
    x = Module(mod, context=context, skip_errors = True)
    new_modules.append(x)
  modules = new_modules
  if not modules:
    print("Nothing to do")
    return

  link_inheritance(context)

  def recursive_htmls(mod):
      yield mod, mod.name, mod.html()
      for submod in mod.submodules():
          yield from recursive_htmls(submod)
  def top_level_recursive_htmls(mod):
      yield mod, mod.name, mod.html()
      for submod in mod.submodules():
          yield submod, submod.name, submod.html()

  if top_level:
    get_htmls = top_level_recursive_htmls
    print("\nUsing top-level only")
  else:
    get_htmls = recursive_htmls
    print("\nUsing all levels")

  ok_modules = []
  failed_modules = []

  for mod in modules:
      for m,  module_name, html in get_htmls(mod):
          if module_name.find('_dummy_module')> -1:
             failed_modules.append(module_name.replace('_dummy_module',''))
             continue
          else:
             ok_modules.append(module_name)
          # Determine if this is a directory or a file
          path = m.url()
          # Edit html to remove eg "qttbx.command_line." everywhere
          #remove_text = "%s." %(module_name)
          #html = html.replace(remove_text,"")
          working_path = "."
          for p in path.split(os.path.sep)[:-1]:
            working_path = os.path.join(working_path, p)
            if not os.path.isdir(working_path):
              os.mkdir(working_path)
          f = open('%s' %(path), 'w')
          print(html, file = f)
          f.close()
          print("MODULE: %s lines: %s" %(
              path, len(html.splitlines())))

  if os.path.isfile(failed_file):
    for x in open(failed_file).read().split():
      if not x in failed_modules:
        failed_modules.append(x)

  print("List of failed modules:")
  for m in failed_modules:
    print(m)
  print("\nTotal of %s ok modules and %s failed modules" %(
      len(ok_modules), len(failed_modules)))
if __name__=="__main__":
  import sys
  args = sys.argv[1:]
  if 'top_level' in args:
     top_level = True
     args.remove('top_level')
  else:
     top_level = False

  run(args, top_level = top_level)


 *******************************************************************************


 *******************************************************************************
cctbx_website/examples/doc_hlo_data_manager.py
from __future__ import absolute_import, division, print_function
#********************************************************************
# This script is automatically generated when running libtbx.refresh (or bootstrap.py)
# It is not part of the GitHub repository
# So if this script is manually changed, the changes will be lost when updating
#********************************************************************
from iotbx.map_model_manager import map_model_manager      #   load in the map_model_manager
mmm=map_model_manager()         #   get an initialized instance of the map_model_manager
mmm.generate_map()              #   get a model from a small library model and calculate a map for it
mmm.write_map("map.mrc")        #   write out a map in ccp4/mrc format
mmm.write_model("model.pdb")    #   write out a model in PDB format
from iotbx.data_manager import DataManager    # Load in the DataManager
dm = DataManager()                            # Initialize the DataManager and call it dm
dm.set_overwrite(True)       # tell the DataManager to overwrite files with the same name
dm_many_functions = DataManager(datatypes = ["model", "real_map",
  "phil", "restraint"])   # DataManager data types
model_filename="model.pdb"                         #   Name of model file
dm.process_model_file(model_filename)              #   Read in data from model file
model = dm.get_model(model_filename)               #   Deliver model object with model info
dm.write_model_file(model,filename="output_model.pdb") # write model to a file
map_filename="map.mrc"                    #   Name of map file
dm.process_real_map_file(map_filename)    #   Read in data from map file
mm = dm.get_real_map(map_filename)        #   Deliver map_manager object with map info
dm.write_real_map_file(mm,filename="output_map") # write map
map_coeffs = mm.map_as_fourier_coefficients(d_min = 3)    # map represented by Fourier coefficients
mtz_dataset = map_coeffs.as_mtz_dataset(column_root_label='FC')    # create an mtz dataset
#  mtz_dataset.add_miller_array(
#                 miller_array      = some_other_array_like_map_coeffs,
#                 column_root_label = column_root_label_other_array)
mtz_object=mtz_dataset.mtz_object()      # extract an object that knows mtz format
dm.write_miller_array_file(mtz_object, filename="map_coeffs.mtz") # write map coeffs as MTZ
array_labels = dm.get_miller_array_labels("map_coeffs.mtz")   # List of labels in map_coeffs.mtz
labels=array_labels[0]    #  select the first (only) label string
labels                    # print out the first label string
dm.get_reflection_file_server(filenames=["map_coeffs.mtz"],      # read reflection data.
     labels=[labels])                       # file names and labels are matching lists
miller_arrays=dm.get_miller_arrays()   # extract selected arrays
map_coeffs=miller_arrays[0]    # select the first array in the list called miller_arrays


 *******************************************************************************


 *******************************************************************************
cctbx_website/examples/doc_hlo_intro.py
from __future__ import absolute_import, division, print_function
#********************************************************************
# This script is automatically generated when running libtbx.refresh (or bootstrap.py)
# It is not part of the GitHub repository
# So if this script is manually changed, the changes will be lost when updating
#********************************************************************
from iotbx.map_model_manager import map_model_manager      # load in the map_model_manager
mmm=map_model_manager()     # get an initialized instance of the map_model_manager
mmm.generate_map()     # get a model from a small library model and calculate a map for it
mmm.write_map("map.mrc")     # write out a map in ccp4/mrc format
mmm.write_model("model.pdb")     # write out a model in PDB format


 *******************************************************************************


 *******************************************************************************
cctbx_website/examples/doc_hlo_map_manager.py
from __future__ import absolute_import, division, print_function
#********************************************************************
# This script is automatically generated when running libtbx.refresh (or bootstrap.py)
# It is not part of the GitHub repository
# So if this script is manually changed, the changes will be lost when updating
#********************************************************************
from iotbx.data_manager import DataManager     # load in DataManager
dm = DataManager()                             # Get an initialized version as dm
dm.set_overwrite(True)       #   tell the DataManager to overwrite files with the same name
from iotbx.map_model_manager import map_model_manager      #   load in the map_model_manager
mmm=map_model_manager()         #   get an initialized instance of the map_model_manager
mmm.generate_map()              #   get a model from a small library model and calculate a map for it
mmm.write_map("map.mrc")        #   write out a map in ccp4/mrc format
mmm.write_model("model.pdb")    #   write out a model in PDB format
map_filename="map.mrc"                       #   Name of map file
mm = dm.get_real_map(map_filename)           #   Deliver map_manager object with map info
mm.shift_origin()     #  Make sure that the origin is shifted to (0,0,0)
mm.show_summary()
map_data = mm.map_data()    # get the data.
crystal_symmetry=mm.crystal_symmetry()    # get crystal_symmetry
crystal_symmetry    # crystal_symmetry summary
# help(mm)
# help(mm.map_as_fourier_coefficients)
map_data=mm.map_data()    # get map_data. Note this is just a pointer to the map_data
new_map_data  = 2.* map_data    # multiply map_data  times 2 and create new array new_map_data with new values
map_data[3,4,5], new_map_data[3,4,5]
new_mm=mm.customized_copy(map_data=new_map_data)    #  new map_manager with data from new_map_data
dm.write_real_map_file(new_mm,filename="doubled_map.mrc", overwrite=True)    # write map
a=map_data    # get map data
b=new_map_data    # get other map data
c=a*b    # multiply the maps
d=a+b    # add the maps
e=a/b    # divide the maps (without additionael checks, this will crash if any element is zero)
mm_c=mm.customized_copy(map_data=c)    #  new map_manager with data from map c
dm.write_real_map_file(mm_c,filename="a_times_b.mrc", overwrite=True) # write map
value = map_data[4,5,6]  # notice the brackets for specifying indices in a map
map_data_1d = map_data.as_1d()   #    1D view, note that these contain the same data
map_data_1d.size()  # get how many points there are
map_data.size()   # how many points in the original array (the same)
map_data.count(0)  # how many points have a value of zero
map_data_1d.standard_deviation_of_the_sample()  #  standard deviation of data in map_data
sel = ( map_data < 0 )   # select all grid points with values less than zero and call the selection sel
map_data.set_selected(sel, 0)   # set all the points specified by selection sel to zero
map_data.count(0)  # how many points now  have a value of zero
map_file="map.mrc"                             #   Name of map file
mm = dm.get_real_map(map_file)                 #   Deliver map_manager object with map info
map_data = mm.map_data() #  the map as a 3D real-space map
map_coeffs = mm.map_as_fourier_coefficients(  # map represented by Fourier coefficients
     d_min = 3)
map_coeffs.size()               # number of Fourier coefficients in map_coeffs
map_coeffs.d_min()              #  high_resolution limit of map_coeffs
map_coeffs.crystal_symmetry()   # symmetry and cell dimensions of real-space map
indices = map_coeffs.indices()     # indices of each term in the map_coeffs array
data = map_coeffs.data()           #  data (complex numbers) for each index
indices[1], data[1]                # indices and data for first term
map_coeffs_low_res = map_coeffs.resolution_filter(d_min=4)   #  cut resolution to 4 A
map_coeffs_low_res.size()   # number of data in the low_res Fourier representation
mtz_dataset = map_coeffs_low_res.as_mtz_dataset(column_root_label='F')    # mtz dataset
mtz_object=mtz_dataset.mtz_object()            #  extract an object that knows mtz format
dm.write_miller_array_file(mtz_object, filename="map_coeffs_low_res.mtz") #write map coeffs
mm_low_res = mm.fourier_coefficients_as_map_manager(    # convert to real space
     map_coeffs=map_coeffs_low_res)
dm.write_real_map_file(mm_low_res,filename="map_low_res.mrc", overwrite=True) # write map
map_file="map.mrc"                             #   Name of map file
mm = dm.get_real_map(map_file)                #   Deliver map_manager object with map info
mm.set_original_origin_and_gridding(
   original_origin =(100,100,100),              # Set the origin of the part of map we have
   gridding=(200,200,200) )                     # set the gridding of the full map
mm.show_summary()   # summarize.  Full map is (0,0,0) to (200,200,200)
                    # available map is just part of full map
mm.write_map("non_zero_origin_map.ccp4")    # write the map
map_file="non_zero_origin_map.ccp4"                             #   Name of map file
new_mm = dm.get_real_map(map_file)           #   Deliver map_manager object with map info
new_mm.show_summary()    # summarize
new_mm.shift_origin()    # shift the origin to (0,0,0)
shifted_map_data=new_mm.map_data()    # get data to work with, origin at (0,0,0)
dm.write_real_map_file(new_mm,filename="map_after_shifting.mrc") # write map
mm.find_map_symmetry()    # Find symmetry in the map
print ( mm.ncs_object())
from iotbx.regression.ncs.tst_ncs import pdb_str_9 as dimer_text
dm = DataManager(['model'])
model_file = 'model_with_ncs.pdb'
dm.process_model_str(model_file, dimer_text)
m = dm.get_model(model_file)
dm.write_model_file(m, model_file, overwrite=True)
ncs_mmm=map_model_manager()
ncs_mmm.generate_map(box_cushion=0, file_name=model_file)
ncs_map_manager = ncs_mmm.map_manager()
ncs_map_manager.find_map_symmetry()    # Find symmetry in the map
print ( ncs_map_manager.ncs_object())
text = ncs_map_manager.ncs_object().display_all()


 *******************************************************************************


 *******************************************************************************
cctbx_website/examples/doc_hlo_model_manager.py
from __future__ import absolute_import, division, print_function
#********************************************************************
# This script is automatically generated when running libtbx.refresh (or bootstrap.py)
# It is not part of the GitHub repository
# So if this script is manually changed, the changes will be lost when updating
#********************************************************************
from iotbx.map_model_manager import map_model_manager      #   load in the map_model_manager
mmm=map_model_manager()         #   get an initialized instance of the map_model_manager
mmm.generate_map()              #   get a model from a small library model and calculate a map for it
mmm.write_map("map.mrc")        #   write out a map in ccp4/mrc format
mmm.write_model("model.pdb")    #   write out a model in PDB format
from iotbx.data_manager import DataManager    #   Load in the DataManager
dm = DataManager()                            #   Initialize the DataManager and call it dm
dm.set_overwrite(True)         #   tell the DataManager to overwrite files with the same name
model_filename="model.pdb"                         #   Name of model file
model = dm.get_model(model_filename)               #   Deliver model object with model info
sites_cart = model.get_sites_cart()          #      get coordinates of atoms in Angstroms
print (sites_cart[0])     #    coordinates of first atom
sites_cart = model.get_sites_cart()          # get coordinates of our model
from scitbx.matrix import col                # import a tool that handles vectors
sites_cart += col((1,0,0))                   # shift all coordinates by +1 A in X
model.set_sites_cart(sites_cart)             # replace coordinates with new ones
print (model.get_sites_cart()[0])            # print coordinate of first atom
dm.write_model_file(model, "shifted_model.pdb", overwrite=True)
model_filename="model.pdb"                         #   Name of model file
model = dm.get_model(model_filename)               #   Deliver model object with model info
sel =  model.selection("name CA")     # identify all the atoms in model with name CA
ca_only_model = model.select(sel)     #  select atoms identified by sel and put in new model
print (ca_only_model.as_pdb_or_mmcif_string())      #  print out the CA-only model in PDB format
dm.write_model_file(ca_only_model, "ca_model.pdb", overwrite=True)
model_filename="model.pdb"                         #   Name of model file
model = dm.get_model(model_filename)               #   Deliver model object with model info
from cctbx.development.create_models_or_maps import generate_map_coefficients   # import the tool

map_coeffs = generate_map_coefficients(  # generate map coeffs from model
      model=model,                       # Required model
      d_min=3,                           # Specify resolution
      scattering_table='electron')       # Specify scattering table
from cctbx.development.create_models_or_maps import get_map_from_map_coeffs   #  import the tool
map_data = get_map_from_map_coeffs(map_coeffs = map_coeffs)   #  create map from map coeffs
# mm_model_map= mm.fourier_coefficients_as_map_manager(map_coeffs)   # generate map from map coeffs


 *******************************************************************************


 *******************************************************************************
cctbx_website/examples/doc_hlo_model_map_manager.py
from __future__ import absolute_import, division, print_function
#********************************************************************
# This script is automatically generated when running libtbx.refresh (or bootstrap.py)
# It is not part of the GitHub repository
# So if this script is manually changed, the changes will be lost when updating
#********************************************************************
from iotbx.map_model_manager import map_model_manager      #   load in the map_model_manager
mmm=map_model_manager()         #   get an initialized instance of the map_model_manager
mmm.generate_map()              #   get a model from a small library model and calculate a map for it
mmm.write_map("map.mrc")        #   write out a map in ccp4/mrc format
mmm.write_model("model.pdb")    #   write out a model in PDB format
from iotbx.data_manager import DataManager    #   Load in the DataManager
dm = DataManager()                            #   Initialize the DataManager and call it dm
dm.set_overwrite(True)         #   tell the DataManager to overwrite files with the same name
map_file="map.mrc"                             #   Name of map file
mm = dm.get_real_map(map_file)                 #   Deliver map_manager object with map info
model_file="model.pdb"                         #   Name of model file
model = dm.get_model(model_file)               #   Deliver model object with model info
from iotbx.map_model_manager import map_model_manager  # load map_model_manager
mmm = map_model_manager(        # a new map_model_manager
  model = model,                # initializing with a model
  map_manager = mm )            # and a map_manager
mm = mmm.map_manager()       #  get the map_manager, origin at (0,0,0)
model = mmm.model()          #  get the model, origin matching the map_manager
dm.write_real_map_file(mm,filename="my_map_original_location.mrc")    # write map
dm.write_model_file(model,filename="my_model_original_location", format="pdb") # model
box_mmm = mmm.extract_all_maps_around_model(          # extract a box around model
    selection_string="resseq 219:223")                # select residues 219-223 of model
dm.write_real_map_file(box_mmm.map_manager(),         # get the boxed map_manager
     filename="box_around_219-223.mrc")               # write the map out
#
dm.write_model_file(box_mmm.model(),                  # get the boxed model
      filename="box_around_219-223", format="pdb") # write out boxed model
box_mmm = mmm.extract_all_maps_with_bounds(      #  Use specified bounds to cut out box
   lower_bounds=(1,1,1), upper_bounds=(9,6,3))   #  Lower and upper bounds of box
#
box_mmm = mmm.extract_all_maps_around_density(   #  Find the density in the map and box
    box_cushion = 1)                             # make box just 1 A bigger than density
#
box_mmm = mmm.extract_all_maps_around_unique(    # Find unique part of density and box
    resolution = 3, molecular_mass=2300   )      # resolution of map and molecular_mass,
                                                 # sequence, or solvent_content is required
mmm_copy=mmm.deep_copy()                             # work with a copy of mmm
mmm_copy.box_all_maps_with_bounds_and_shift_origin(  #  Use specified bounds to cut out box
   lower_bounds=(1,1,1), upper_bounds=(9,6,3))       #  Lower and upper bounds of box
box_mmm = mmm.extract_all_maps_around_model(          # extract a box around model
    selection_string="resseq 219:223")                # select residues 219-223 of model
box_mmm_dc = box_mmm.deep_copy()     # save a copy of map_manager
box_mmm.create_mask_around_atoms()   #  create binary mask around atoms in box_mmm model
box_mmm.apply_mask_to_maps()   #  apply existing mask to all maps in box_mmm
dm.write_real_map_file(box_mmm_dc.map_manager(),filename="starting_map.mrc") # original
dm.write_real_map_file(box_mmm.map_manager()   ,filename="masked_map.mrc") # masked
box_mmm_soft_mask=box_mmm_dc.deep_copy()                       # make a copy to work with
box_mmm_soft_mask.create_mask_around_atoms(soft_mask = True)   #  create soft mask
box_mmm_soft_mask.apply_mask_to_maps()   #  apply existing mask to all maps
dm.write_real_map_file(box_mmm_soft_mask.map_manager(),     # write out masked map
       filename="soft_masked.mrc")                         # soft masked


 *******************************************************************************


 *******************************************************************************
cctbx_website/examples/doc_low_flex_advanced.py
from __future__ import absolute_import, division, print_function
#********************************************************************
# This script is automatically generated when running libtbx.refresh (or bootstrap.py)
# It is not part of the GitHub repository
# So if this script is manually changed, the changes will be lost when updating
#********************************************************************
from iotbx.map_model_manager import map_model_manager # load map_model_manager
mmm=map_model_manager() # get an initialized instance of the map_model_manager
mmm.generate_map()# get a model from a small library model and calculate a map
map_data = mmm.map_manager().map_data()  # the map as flex.double() 3D array)
acc = map_data.accessor() #  gridding for map_data
acc.show_summary()        # summarize
print(map_data.last()) # prints (30, 40, 32)  corner of unit cell of map
print(map_data.last(False)) # prints (29, 39, 31) corner of available map
print(map_data.size())    # prints 38400 = 30 x 40 x 32
map_data_as_1d = map_data.as_1d()   # 1D view of map_data
print(map_data_as_1d.size())    # prints 38400, same as the original map_data
map_data_as_1d[0] = 100.   # set a value in map_data_as_1d
print (map_data_as_1d[0])  # prints 100.
print (map_data[0,0,0])  # prints 100.
from scitbx.array_family.flex import grid
new_acc = grid((10,0,0), (40,40,32))  # now from (10,0,0) to (40,40,32)
map_data.reshape(new_acc) #  reshape map_data
map_data.accessor().show_summary()  # summarize map_data now
map_data_as_1d = map_data.as_1d()   # 1D view of map_data
map_data_as_1d[27] = 100.   # set a value in map_data_as_1d
print (map_data_as_1d[27])  # prints 100.
map_data_new_origin = map_data.shift_origin()  # shift and make new array
map_data_new_origin_as_1d = map_data_new_origin.as_1d() # 1D view
print (map_data_new_origin_as_1d[27])  # prints 100 again
map_data_as_1d[27] = 200   # set a new value in map_data
print (map_data_new_origin_as_1d[27])  # prints 200
map_data[0] = 200   # set a few values to 200
map_data[27] = 200   # set a few values to 200
map_data[3973] = 200   # set a few values to 200
sel = (map_data > 100)   #  select all map data elements > 100
print (sel.count(True))   # prints 3, the number of True elements
isel = sel.iselection()  # list of indices the elements in sel that are True
print (isel.size())   # prints 3, how many elements are in isel
print (list(isel))   # prints [0, 27, 3973]
map_data.set_selected(sel, 300)  # set selected elements of map_data to 300


 *******************************************************************************


 *******************************************************************************
cctbx_website/examples/doc_maps_boxing.py
from __future__ import absolute_import, division, print_function
#********************************************************************
# This script is automatically generated when running libtbx.refresh (or bootstrap.py)
# It is not part of the GitHub repository
# So if this script is manually changed, the changes will be lost when updating
#********************************************************************
from iotbx.map_model_manager import map_model_manager # load map_model_manager
mmm=map_model_manager()  # get initialized instance of the map_model_manager
mmm.generate_map() # get a model and calculate a map for it
map_data = mmm.map_data()  #  our 3D map object
lower_bounds = (10,10,10)  # lower bounds for boxed map
upper_bounds = (21,31,21)  # upper bounds for boxed map
from cctbx import maptbx            # import maptbx
box_map_data = maptbx.copy(map_data, lower_bounds, upper_bounds) # box the map
print( box_map_data.origin())  # prints (10, 10, 10)
print( box_map_data.all())     # prints (12, 22, 12)
print( box_map_data.last(False)) # prints (21, 31, 21)
print( box_map_data[11,12,13])  # prints 0.0416163499881
print( box_map_data.size() )  # prints 3168
shifted_box_map_data = box_map_data.shift_origin()   # shift origin to (0,0,0)
print(shifted_box_map_data.origin())  # prints (0, 0, 0)
print(shifted_box_map_data.all())     # prints (12, 22, 12)
print(shifted_box_map_data.last(False)) # prints (11, 21, 11)
print(shifted_box_map_data[1,2,3])  # prints 0.0416163499881
boxed_mmm = mmm.extract_all_maps_with_bounds( # create box
   lower_bounds = lower_bounds,  # lower bounds
   upper_bounds = upper_bounds)  # upper bounds
new_shifted_box_map_data = boxed_mmm.map_manager().map_data() #
print(new_shifted_box_map_data.origin())  # prints (0, 0, 0)
print(new_shifted_box_map_data.all())     # prints (12, 22, 12)
print(new_shifted_box_map_data.last(False)) # prints (11, 21, 11)
print(new_shifted_box_map_data[1,2,3])  # prints 0.0416163499881
boxed_mmm.write_map('boxed_map.ccp4')  # superimposes on orig
working_sites_cart = boxed_mmm.model().get_sites_cart() # sites
boxed_mmm = mmm.extract_all_maps_with_bounds( # create box
   lower_bounds = lower_bounds,  # lower bounds
   upper_bounds = upper_bounds)  # upper bounds
print (mmm.model().get_sites_cart()[0])  # 14.476000000000003, 10.57, 8.342)
print (mmm.map_manager().map_data()[11,12,13]) # prints 0.0416163499881
print(boxed_mmm.model().get_sites_cart()[0])# (7.005666666666668, 3.339250000000002, 0.967625000000001)
print (boxed_mmm.map_manager().map_data()[1,2,3]) # prints 0.0416163499881
boxed_sites_cart = boxed_mmm.model().get_sites_cart() # get boxed sites
boxed_sites_cart[0] = (10,10,10) # set value of one coordinate in boxed sites
boxed_mmm.model().set_sites_cart(boxed_sites_cart) # set coordinates in model
boxed_mmm.map_manager().map_data()[1,2,3] = 77.  # change map value
print (mmm.model().get_sites_cart()[0])  # 14.476000000000003, 10.57, 8.342)
print (mmm.map_manager().map_data()[11,12,13]) # prints 0.0416163499881
mmm_model_ref = mmm.model()  # reference to model in mmm
mmm_map_manager_ref = mmm.map_manager()  # reference to model in mmm
mmm.box_all_maps_with_bounds_and_shift_origin( # change mmm in place
   lower_bounds = lower_bounds,  # lower bounds
   upper_bounds = upper_bounds)  # upper bounds
print (mmm.model().get_sites_cart()[0]) # (7.005666666666668, 3.339250000000002, 0.967625000000001)
print (mmm.map_manager().map_data()[1,2,3]) # prints 0.0416163499881
sites_cart = mmm.model().get_sites_cart() # get boxed sites
sites_cart[0] = (20,20,20) # set value of one coordinate  in sites_cart
mmm.model().set_sites_cart(sites_cart) # set coordinates in model
mmm.map_manager().map_data()[1,2,3] = 222.  # change map value
print (mmm_model_ref.get_sites_cart()[0])  # (20.0, 20.000000000000004, 20.0)
print (mmm_map_manager_ref.map_data()[11,12,13]) # prints 0.0416163499881
m = boxed_mmm.model()  # get the model
print(m)   # prints info about the model including origin shift
shift_cart = m.shift_cart()  # current origin shift
shift_to_apply = tuple([-x for x in shift_cart])  # opposite shift (to apply()
m.shift_model_and_set_crystal_symmetry(shift_to_apply)  # shift the model
print(m)  # now the origin shift is zero (original location)
boxed_mmm.add_model_by_id(model_id = 'model', model = m)  # load the model in
print(m)  #  automatically shifted to match the map_model_manager origin
m.shift_model_and_set_crystal_symmetry(shift_to_apply)  # shift the model again
print(m)  # now the origin shift is zero (original location)
boxed_mmm.shift_any_model_to_match(m)  # shift this model to match the map_model_manager
print(m)  #  automatically shifted to match the map_model_manager origin
mm = boxed_mmm.map_manager()  # get a map manager
mm.set_model_symmetries_and_shift_cart_to_match_map(m)  # set the symmetry and origin


 *******************************************************************************


 *******************************************************************************
cctbx_website/examples/doc_maps_intro.py
from __future__ import absolute_import, division, print_function
#********************************************************************
# This script is automatically generated when running libtbx.refresh (or bootstrap.py)
# It is not part of the GitHub repository
# So if this script is manually changed, the changes will be lost when updating
#********************************************************************
from iotbx.map_model_manager import map_model_manager # load map_model_manager
mmm=map_model_manager()  # get initialized instance of the map_model_manager
mmm.generate_map() # get a model and calculate a map for it
map_data = mmm.map_data()  #  our 3D map object
print(map_data.all())     # prints (30, 40, 32)
print(map_data.size(), 30*40*32)     # prints 38400, 38400
print(map_data.origin())   # prints (0, 0, 0)
print(map_data.last(False))     # prints (29, 39, 31) last available point
print(map_data.last())          # prints (30, 40, 32) start of next unit cell
print(map_data[1,2,3])    # prints -0.0164242834519
site_frac = [i/n for i,n in zip ((11,12,13), map_data.all())] # fractional
print(site_frac) # prints [0.36666666666666664, 0.3, 0.40625]
uc = mmm.crystal_symmetry().unit_cell()  # unit_cell object for our model
site_cart = uc.orthogonalize(site_frac)  # convert to orthogonal Angstroms
print(site_cart) # prints (8.217366666666667, 8.676899999999998, 9.5866875)
site_frac_again = uc.fractionalize(site_cart)  # convert to fractional
print(site_frac_again) # prints ((0.3666666666666667, 0.3, 0.40625)
grid_point =  [n * f for n,f in zip(map_data.all(), site_frac_again)] # grid
print(grid_point) # prints [11.0, 12.0, 13.0]
print(map_data.value_at_closest_grid_point(site_frac)) #  0.0416163499881
print(map_data[11,12,13]) #  0.0416163499881


 *******************************************************************************


 *******************************************************************************
cctbx_website/examples/doc_models_hierarchy.py
from __future__ import absolute_import, division, print_function
#********************************************************************
# This script is automatically generated when running libtbx.refresh (or bootstrap.py)
# It is not part of the GitHub repository
# So if this script is manually changed, the changes will be lost when updating
#********************************************************************
from __future__ import absolute_import, division, print_function
from iotbx.data_manager import DataManager
import sys
dm = DataManager()                    #   Initialize the DataManager and call it dm
dm.set_overwrite(True)                #   tell the DataManager to overwrite files with the same name
model_filename = sys.argv[1:][0]      #   Name of model file
model = dm.get_model(model_filename)  #   Deliver model object with model info

m = model.deep_copy()                 # work on a copy of model object

pdb_hierarchy = m.get_hierarchy()     #   Get hierarchy object
for chain in pdb_hierarchy.only_model().chains():
  for residue_group in chain.residue_groups():
    for atom_group in residue_group.atom_groups():
      for atom in atom_group.atoms():
        if (atom.element.strip().upper() == "ZN"):
          atom_group.remove_atom(atom)
      if (atom_group.atoms_size() == 0):
        residue_group.remove_atom_group(atom_group)
    if (residue_group.atom_groups_size() == 0):
      chain.remove_residue_group(residue_group)
model_file_name = dm.write_model_file(m, "model_Zn_free.pdb")
print("File name written: %s" %(model_file_name))
pdb_hierarchy = model.get_hierarchy() #   Get hierarchy object
import iotbx.pdb
pdb_hierarchy = iotbx.pdb.input(file_name=model_filename).construct_hierarchy()
sel_cache = pdb_hierarchy.atom_selection_cache()
non_zn_sel = sel_cache.selection("not (resname ZN)")
hierarchy_new = pdb_hierarchy.select(non_zn_sel)
# etc
non_zn_sel= model.selection("not (resname ZN)")
hierarchy_new = model.select(non_zn_sel).get_hierarchy()
m = model.deep_copy()
pdb_hierarchy = m.get_hierarchy()
pdb_atoms = pdb_hierarchy.atoms()
xray_structure = m.get_xray_structure()
sel_cache = pdb_hierarchy.atom_selection_cache()
c_alpha_sel = sel_cache.selection("name ca") # XXX not case sensitive!
c_alpha_atoms = pdb_atoms.select(c_alpha_sel)
c_alpha_xray_structure = xray_structure.select(c_alpha_sel)
c_alpha_hierarchy = pdb_hierarchy.select(c_alpha_sel)
m = model.deep_copy()
pdb_hierarchy = m.get_hierarchy()
for chain in pdb_hierarchy.only_model().chains():
  chain_atoms = chain.atoms()
  chain_selection = chain_atoms.extract_i_seq()
selection = pdb_hierarchy.atom_selection_cache().selection("hetatm")
for chain in pdb_hierarchy.only_model().chains():
  for residue_group in chain.residue_groups():
    residue_isel = residue_group.atoms().extract_i_seq()
    if (selection.select(residue_isel).all_eq(True)):
      #do_something_with_heteroatom_residue(residue_group)
      pass
pdb_hierarchy.reset_atom_i_seqs()
pdb_atoms = pdb_hierarchy.atoms()
pdb_atoms.reset_i_seq()


 *******************************************************************************


 *******************************************************************************
cctbx_website/examples/doc_programming_tips_1.py
from __future__ import absolute_import, division, print_function
#********************************************************************
# This script is automatically generated when running libtbx.refresh (or bootstrap.py)
# It is not part of the GitHub repository
# So if this script is manually changed, the changes will be lost when updating
#********************************************************************
b = [1,2,3]  # a list of values
a = b   #  does a get the value of b or is it a pointer
print(a)  # prints out [1,2,3]
print(b)  # prints out [1,2,3]
a[1] = 10  # set value of second element of a
print(a)  # prints out [1,10,3]
print(b)  # prints out [1,10,3]
d = list(b)   #   make a new list from b
print (d)  # d looks like b: [1, 10, 3]
b[0] = 20  # set value of first element of b
print(d)  #  d is not a pointer to b: still prints [1, 10, 3]
f = [6,7,8]  #  f is an object (a list)
x = [1,2,f]  # x is a list with some numeric values and an object (f)
print(x)  #  looks like [1, 2, [6, 7, 8]]
y = list(x)   #  make a new list and call it y
print(y)  #  looks like [1, 2, [6, 7, 8]]
x[0]=7  # replace element 0 of x
x[2]=[3,4,5]  # replace element 2 of x
print(y)  #  y is still [1, 2, [6, 7, 8]]
f = [6,7,8]  #  f is an object (a list)
x = [1,2,f]  # a list with some numeric values and an object (f)
y = list(x)   #  make a new list and call it y
print(y)    # looks like [1, 2, [6, 7, 8]]
x[0] = 100   # change element 0 of x
print(x)    # changed:[100, 2, [6, 7, 8]]
print(y)    # still looks like [1, 2, [6, 7, 8]]
f[0] = 32    # change the object f
print(x)    # changed in x:[100, 2, [32, 7, 8]]
print(y)    # the object f within y changes [1, 2, [32, 7, 8]]
from iotbx.map_model_manager import map_model_manager # load map_model_manager
mmm=map_model_manager() # get an initialized instance of the map_model_manager
mmm.generate_map()# get a model from a small library model and calculate a map
map_data = mmm.map_manager().map_data()  # the map as flex.double() 3D array)
map_data_copy = map_data   #  just a pointer to map_data
map_data_deep_copy = map_data.deep_copy()   #  totally new array
from copy import deepcopy  # import deepcopy
map_data_deepcopy = deepcopy(map_data)   #  totally new array
a = [5,3,8]  # a list of numbers
a.sort()  #  sort the list.  Nothing is returned
n = a.count(3)  # count values of 3 and return the number
print(n)  # prints 1
from scitbx.array_family import flex  # import flex
array = flex.double()  # set up a flex.double() array
array.append(100)  # put in a value of 100
array.append(200)  # and a value of 200
print(list(array)) # prints [100.0, 200.0]
sel = (array == 100)  # identify array elements equal to 100
selected_data = array.select(sel)  # returns new object
print(list(selected_data))  # prints [100.0]
print(list(selected_data))  # prints [100.0]
complex_array = flex.complex_double() # a complex double array
complex_array.append((1+2j))   # append the complex number (1+2i)
complex_array.append((23-6j))   # append the complex number (23-6i)
a,b = complex_array.parts()  # pointers a and b to the real and imaginary parts
print(list(complex_array))  # print out the array: [(1+2j), (23-6j)]
print(list(a), list(b))  # prints ([1.0, 23.0], [2.0, -6.0])
a[1] = 99 #  change pointer to a
print(list(complex_array))  # still prints out [(1+2j), (23-6j)]
map_coeffs = mmm.map_manager().map_as_fourier_coefficients()  # map coeffs
print(map_coeffs.data()[0])  # (22.1332152449-33.1246974818j)
data = map_coeffs.data() # the map coefficients themselves
print(data[0]) # the first map coefficient ((22.1332152449-33.1246974818j))
data[0] = (10+6j)  # set value of data[0]
print(map_coeffs.data()[0])  # prints (10+6j)
phases = map_coeffs.phases() # new object with indices and phases only
map_data = mmm.map_manager().map_data()  # 3D flex.double array
map_data_as_1d = map_data.as_1d()  # new object, data are shared
map_data_as_float = map_data.as_float() # new object, new data
print(map_data[0], map_data_as_1d[0], map_data_as_float[0]) #
map_data[0] = 999.  # set map_data
print(map_data[0], map_data_as_1d[0], map_data_as_float[0]) #
from copy import deepcopy  # import deepcopy
x = [1,2,[6,7,8]]  # a list with some values and a list
y = deepcopy(x)   #  completely new copy of x. Change x; nothing happens to y
from iotbx.map_model_manager import map_model_manager # load map_model_manager
mmm=map_model_manager() # get an initialized instance of the map_model_manager
mmm.generate_map()# get a model from a small library model and calculate a map
map_data = mmm.map_manager().map_data()  # the map as flex.double() 3D array)
print(map_data[27])  # prints original value of -0.0131240713008
map_data_pointer = map_data  #  just points to map_data
map_data_deep_copy = map_data.deep_copy()  #  completely new data
map_data[27] = 100  #  set value of map_data
print(map_data_pointer[27])   # prints 100
print(map_data_deep_copy[27])  # prints original value of -0.0131240713008
x = None
if (not x):  # don't use this
  print("""not x can be 0, None, False, "", [], {}, (),...""")   # happens if x is (0, None, False, "", [], {}, (), ...)
if (x is None):  # Use this instead
  print("x is None")   # happens if x is None (only)
if (x is not None):  # Use this too
  print("x is not None")   # happens unless x is None (only)
def my_bad_function(value, current_list = []):   # don't do this
  current_list.append(value)      # current_list from previous call
  return current_list   # returns current_list
print(my_bad_function(1))   #  prints [1]...current_list was []
print(my_bad_function(2))   #  prints [1, 2] ...current_list was [1]
def better_function(value, current_list = None):   # ok way
  if current_list is None:   # catch uninitialized current_list
     current_list = []       # set its value to []
  current_list.append(value)      # works
  return current_list   # returns current_list
print(better_function(1))   #  prints [1]...current_list was []
print(better_function(2))   #  prints [2]...current_list was []


 *******************************************************************************


 *******************************************************************************
cctbx_website/examples/doc_programming_tips_2.py
from __future__ import absolute_import, division, print_function
#********************************************************************
# This script is automatically generated when running libtbx.refresh (or bootstrap.py)
# It is not part of the GitHub repository
# So if this script is manually changed, the changes will be lost when updating
#********************************************************************
a = (1,2,3)  # a tuple of values
b = (6,6,6) # another tuple of the same length
from scitbx.matrix import col  # import the col methods
c = col(a) + col(b)  #  col objects of the same length can be added together
d = tuple(c)  # now d is a tuple again
print(d)   #  now we get (7,8,9)
from scitbx.array_family import flex # import the flex methods
a = flex.double((1,2,3))  # make a flex array
print(a)  # print it  # you get something like 
print(tuple(a))  # now you can see what is in it: (1.0, 2.0, 3.0)
from scitbx.matrix import col  # import the col methods
a = (1,2,3)   # a tuple
b = (5,3,9)   #  another tuple
d = col(a).dot(col(b))  # dot product of a and b
print(d)     # dot product is 38
from scitbx.matrix import col  # import the col methods
a = (1,2,3)  # a tuple
b = (5,3,9)  # another tuple
ca = col(a)  # col object based on a
cb = col(b)  # col object based on b
print( ca.dot(cb))  # dot product = 38
print( tuple(ca.cross(cb)))  # cross product = (9, 6, -7)
complex_array = flex.complex_double() # a complex double array
complex_array.append((1+2j))   # append the complex number (1+2i)
complex_array.append((23-6j))   # append the complex number (23-6i)
a,b = complex_array.parts()  # pointers a and b to the real and imaginary parts
print(list(complex_array))  # print out the array: [(1+2j), (23-6j)]
print(list(a), list(b))  # prints ([1.0, 23.0], [2.0, -6.0])
from iotbx.map_model_manager import map_model_manager # load map_model_manager
mmm=map_model_manager() # get an initialized instance of the map_model_manager
mmm.generate_map()# get a model from a small library model and calculate a map
map_coeffs = mmm.map_manager().map_as_fourier_coefficients() # get map coeffs
complex_double_array = flex.complex_double()  # a complex double array
indices = map_coeffs.indices()  #  array of indices
sites_cart = mmm.model().get_sites_cart()  # coordinates
def return_a_and_b(a,b): # simple function
  return a,b   # just return a couple values
def return_a_and_b(a,b): # simple function
  from libtbx import group_args   #  import group_args
  result = group_args(              #
    group_args_type = 'just returning a and b',  # a name for this group_args
    a = a,   #   can refer to a as result.a
    b = b)   #   and to b as result.b
  return result  #
result = return_a_and_b(1,2)   # call our function
print(result)   # prints out value of a and b and the label
print(result.a)   # print out value of a
def furthest(sites_cart):  # furthest from center
  center = sites_cart.mean()   # flex method to get mean of vec3_double() array
  diffs = sites_cart - center  # subtract a vector from a vec3_double() array
  norms = diffs.norms()        # get an array of lengths of the diffs array
  return norms.min_max_mean().max  # get maximum value

print(furthest(sites_cart))  # print the result
from scitbx.array_family import flex # import the flex methods
a = flex.vec3_double(((1,1,1),(2,2,2), (3,3,3)))  # make a flex array
b = flex.vec3_double(((3,2,2),(1.1,1.2,1.2),(3,2,2), (4,3,3)))  # make a flex array
dist, i, j = a.min_distance_between_any_pair_with_id(b)  # find closest pair
print(dist, i, j)  # prints  (0.29999999999999993, 0, 1)
a = [5,6,7]  # a list of 3 values
print(a[0])  # prints 5 (indexing starts at zero)
print(a[2])  # prints 7
print(a[-1])  # prints 7
index = -1
index_to_use = len(a) + index   # this is done in the background
print( index, index_to_use, a[index],a[index_to_use]) # prints (-1, 2, 7, 7)
print(a[-3])  # prints 5
a = [5,6,7]  # a list of 3 values
print(a[:2])  # prints [5,6]
print(a[2:])  # prints [7]
k = 2
print(a[:k],a[k:])  # prints ([5, 6], [7])
print( a[k:])  # prints [7]
print( a[k])  # prints 7
print( a[k:k+1])  # prints [7]
print( a[-1:])  # prints [7]
print( a[-1:1])  # prints []
print( a[2:1])  # prints []
from libtbx.test_utils import approx_equal # import it
print( approx_equal(1,1.001))  # prints False (not same within machine precision)
print( approx_equal(1,1.+1.e-50))  # prints True (within machine precision)
print( approx_equal(1,1.001, eps = 0.1)) # prints True (within 0.1)
a=flex.double((1,2,3))  #  set up an array
b = a + 0.0001   # another array that is just a little different
print( approx_equal(a,b) )  #prints False and lists differences
print(  approx_equal(a,b, eps=0.001))  # prints True (all elements within 0.001)


 *******************************************************************************


 *******************************************************************************
cctbx_website/examples/doc_programming_tips_3.py
from __future__ import absolute_import, division, print_function
#********************************************************************
# This script is automatically generated when running libtbx.refresh (or bootstrap.py)
# It is not part of the GitHub repository
# So if this script is manually changed, the changes will be lost when updating
#********************************************************************
from __future__ import print_function  # so we can use print function easily
import sys        # import sys
from libtbx import group_args #  group_args function we will use to return items
def run_something(value):  # simple function
  return value * 2    # just returns 2 * the input value
iteration_list = [5,7,9]  # list of anything
def run_one_by_one(iteration_list): #
  result_list = []                             # initialize result list
  for i in range(len(iteration_list)):         # iterate over input values
    result = run_something(iteration_list[i])  # get result
    result_list.append(result)  # save result
  return result_list   # return the list of results
result_list = run_one_by_one(iteration_list)  # get results one by one
print(result_list)  # prints list of values  [10, 14, 18]
def run_in_parallel(iteration_list, nproc = 4): #
  from libtbx.easy_mp import simple_parallel  # import the simple_parallel code
  result_list = simple_parallel(      # run in parallel
    iteration_list = iteration_list,  # our list of values to run with
    function = run_something,         # the method we are running
    nproc = nproc )                   # how many processors
  return result_list   # return the list of results
result_list = run_in_parallel(iteration_list, nproc = 4)  # run in parallel
print(result_list)  # prints list of values  [10, 14, 18]
def run_advanced(info, big_object = None,  #
     log = sys.stdout):   #  we can specify the log in this method if we want
  output_value = info.value * 2 + big_object[info.index]   # our result
  print("Value: %s Index: %s Output value: %s" %(info.value, info.index, output_value), file = log)
  return group_args( #
    group_args_type = 'Result from one job',  #
    input_info = info,   #
    output_value = output_value,)   #
iteration_list = []   # initialize
from libtbx import group_args
for i in [5,7,9]:  # our values to vary for each job
  iteration_list.append(   # a list of info objects
    group_args(   # info object (group_args)
      group_args_type = 'value of info for one job',   # title
      value = i,   # value of value
      index = 2)   # value of index
    )   #

big_object = [0,1,2,3]  # just some supposedly big object
def advanced_run_as_is(iteration_list,  #
     big_object = None,  #
     log = sys.stdout): # run in usual way
  result_list = []   # initialize
  for i in range(len(iteration_list)):     #  iterate through jobs
    result = run_advanced(iteration_list[i],
      big_object = big_object,
      log = log)  # run job
    result_list.append(result)   #
  return result_list    # return list of results
result_list = advanced_run_as_is( #
   iteration_list, big_object = big_object,
   log = sys.stdout) #
for result in result_list:  # run through results
  print("\nOne result:\n%s" %str(result))  # print this result (it is a group_args object)
def advanced_run_in_parallel(iteration_list,  #
      big_object = None, nproc = 4, log = sys.stdout): # run in parallel w
  from libtbx.easy_mp import simple_parallel  #
  result_list = simple_parallel(  #
    iteration_list = iteration_list, # list of varying inputs
    big_object = big_object, # any number of keyword arguments allowed
    function = run_advanced,  # function to run
    nproc = 3,   # number of processors
    verbose = False,   # non-verbose output
    log = log,
    )
  return result_list
result_list = advanced_run_in_parallel(  #
    iteration_list, #
    big_object = big_object,  #
    log = sys.stdout) #
for result in result_list:  # run through results
  print("\nOne result:\n%s" %str(result))  # print this result (it is a group_args object)


 *******************************************************************************


 *******************************************************************************
cctbx_website/examples/script_1.py
from __future__ import absolute_import, division, print_function
#********************************************************************
# This script is automatically generated when running libtbx.refresh (or bootstrap.py)
# It is not part of the GitHub repository
# So if this script is manually changed, the changes will be lost when updating
#********************************************************************
from __future__ import absolute_import, division, print_function
import iotbx.pdb
import iotbx.mrcfile
import mmtbx.model
import mmtbx.real_space
from scitbx.array_family import flex
from cctbx.development import random_structure
from cctbx import sgtbx
from cctbx import maptbx
# Create random structure
xrs = random_structure.xray_structure(
  space_group_info = sgtbx.space_group_info("P-1"),
  elements         = ["C"]*15,
  unit_cell        = (10, 20, 30, 50, 60, 80))
# Create model object
model = mmtbx.model.manager.from_sites_cart(
  sites_cart       = xrs.sites_cart(),
  crystal_symmetry = xrs.crystal_symmetry(),
  resname          = 'DUM')
# Write it into PDB file
from iotbx.data_manager import DataManager
dm = DataManager()
dm.set_overwrite(True)
output_file_name = dm.write_model_file(model, "model.pdb")
print("Output file name: %s" %(output_file_name))
  # Read the model file
pdb_inp = iotbx.pdb.input(file_name = "model.pdb")
model = mmtbx.model.manager(model_input = pdb_inp)
xrs = model.get_xray_structure()
# Calculate structure factors at given resolution.
f_calc = xrs.structure_factors(d_min = 2.0).f_calc()
# Write them down as MTZ file
mtz_dataset = f_calc.as_mtz_dataset(column_root_label="F-calc")
mtz_object = mtz_dataset.mtz_object()
mtz_object.write(file_name = "f_calc.mtz")
# Convert Fcalc into real map (just do FFT)
fft_map = f_calc.fft_map(resolution_factor=1./4)
fft_map.apply_sigma_scaling()
map_data = fft_map.real_map_unpadded()
# Write real Fourier map into MRC file
iotbx.mrcfile.write_ccp4_map(
  file_name   = "fourier_map.mrc",
  unit_cell   = f_calc.unit_cell(),
  space_group = f_calc.crystal_symmetry().space_group(),
  map_data    = map_data.as_double(),
  labels      = flex.std_string(["Some text"]))
# Calculate exact map and write it down
crystal_gridding = maptbx.crystal_gridding(
  unit_cell        = xrs.unit_cell(),
  space_group_info = xrs.space_group_info(),
  symmetry_flags   = maptbx.use_space_group_symmetry,
  step             = 0.3)
m = mmtbx.real_space.sampled_model_density(
  xray_structure = xrs,
  n_real         = crystal_gridding.n_real())
map_data = m.data()
iotbx.mrcfile.write_ccp4_map(
  file_name   = "exact_map.mrc",
  unit_cell   = f_calc.unit_cell(),
  space_group = f_calc.crystal_symmetry().space_group(),
  map_data    = map_data.as_double(),
  labels      = flex.std_string(["Some text"]))


 *******************************************************************************


 *******************************************************************************
cctbx_website/examples/script_compare_ss.py
from __future__ import absolute_import, division, print_function
#********************************************************************
# This script is automatically generated when running libtbx.refresh (or bootstrap.py)
# It is not part of the GitHub repository
# So if this script is manually changed, the changes will be lost when updating
#********************************************************************
from __future__ import absolute_import, division, print_function
import sys
import mmtbx.secondary_structure
from scitbx.array_family import flex
from libtbx.utils import null_out
from iotbx.data_manager import DataManager

def match_score(x,y):
  assert x.size() == y.size()
  match_cntr = 0
  for x_,y_ in zip(x,y):
    if(x_==y_): match_cntr+=1
  return match_cntr/x.size()

def get_ss(hierarchy,
           sec_str_from_pdb_file=None,
           method="ksdssp",
           use_recs=False):
  if(use_recs): params = None
  else:
    params = mmtbx.secondary_structure.manager.get_default_ss_params()
    params.secondary_structure.protein.search_method=method
    params = params.secondary_structure
  ssm = mmtbx.secondary_structure.manager(
    pdb_hierarchy         = hierarchy,
    sec_str_from_pdb_file = sec_str_from_pdb_file,
    params                = params,
    log                   = null_out())
  alpha = ssm.helix_selection()
  beta  = ssm.beta_selection()
  assert alpha.size() == beta.size() == hierarchy.atoms().size()
  annotation_vector = flex.double(hierarchy.atoms().size(), 0)
  annotation_vector.set_selected(alpha, 1)
  annotation_vector.set_selected(beta, 2)
  return annotation_vector

def run(args):
  dm = DataManager()                    #   Initialize the DataManager and call it dm
  dm.set_overwrite(True)                #   tell the DataManager to overwrite files with the same name
  model_filename = args[0]              #   Name of model file
  model = dm.get_model(model_filename)  #   Deliver model object with model info
  pdb_hierarchy = model.get_hierarchy() #   Get hierarchy object
  sec_str_from_pdb_file = model.get_ss_annotation()
  # get secodary structure annotation vector from HELIX/SHEET records (file header)
  print('Running secondary structure annotation...')
  v1 = get_ss(
    hierarchy             = pdb_hierarchy,
    sec_str_from_pdb_file = sec_str_from_pdb_file)
  # get secodary structure annotation vector from method CA atoms
  v2 = get_ss(hierarchy = pdb_hierarchy, method = "from_ca")
  # secodary structure annotation vector from KSDSSP
  v3 = get_ss(hierarchy = pdb_hierarchy, method = "ksdssp")
  #
  print()
  print("CC REMARK vs from_ca:", flex.linear_correlation(x = v1, y = v2).coefficient())
  print("CC REMARK vs ksdssp:", flex.linear_correlation(x = v1, y = v3).coefficient())
  print("CC from_ca vs ksdssp:", flex.linear_correlation(x = v3, y = v2).coefficient())
  print()
  print("match REMARK vs from_ca:", match_score(x = v1, y = v2))
  print("match REMARK vs ksdssp:", match_score(x = v1, y = v3))
  print("match from_ca vs ksdssp:", match_score(x = v3, y = v2))

if __name__ == '__main__':
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx_website/examples/script_ideal_ss.py
from __future__ import absolute_import, division, print_function
#********************************************************************
# This script is automatically generated when running libtbx.refresh (or bootstrap.py)
# It is not part of the GitHub repository
# So if this script is manually changed, the changes will be lost when updating
#********************************************************************
from __future__ import absolute_import, division, print_function
from mmtbx.secondary_structure.build import ss_idealization as ssb
ph_helix = ssb.secondary_structure_from_sequence(ssb.alpha_helix_str,"ILMKARNDWYV")
ph_helix.write_pdb_file(file_name="m-helix.pdb")
ph_strand = ssb.secondary_structure_from_sequence(ssb.beta_pdb_str,"ILMKARNDWYV")
ph_strand.write_pdb_file(file_name="m-strand.pdb")


 *******************************************************************************


 *******************************************************************************
cctbx_website/examples/script_lbfgs_no_curvature.py
from __future__ import absolute_import, division, print_function
#********************************************************************
# This script is automatically generated when running libtbx.refresh (or bootstrap.py)
# It is not part of the GitHub repository
# So if this script is manually changed, the changes will be lost when updating
#********************************************************************
from __future__ import division, print_function
from scitbx.array_family import flex
from libtbx import adopt_init_args
import scitbx.lbfgs
from scitbx import lbfgsb

class rosenbrock(object):
  def __init__(self, a, b, x):
    adopt_init_args(self, locals())
    assert self.x.size() == 2

  def update(self, x):
    self.x = x
    assert self.x.size() == 2

  def target(self):
    return (self.a-self.x[0])**2+self.b*(self.x[1]-self.x[0]**2)**2

  def gradients(self):
    g1 = 2*(self.x[0]-self.a) + 4*self.b*(self.x[0]**3-self.x[0]*self.x[1])
    g2 = 2*self.b*(self.x[1]-self.x[0]**2)
    return flex.double([g1,g2])

def lbfgs_run(target_evaluator, use_bounds, lower_bound, upper_bound):
  minimizer = lbfgsb.minimizer(
    n   = target_evaluator.n,
    l   = lower_bound, # lower bound
    u   = upper_bound, # upper bound
    nbd = flex.int(target_evaluator.n, use_bounds)) # flag to apply both bounds
  minimizer.error = None
  try:
    icall = 0
    while 1:
      icall += 1
      x, f, g = target_evaluator()
      have_request = minimizer.process(x, f, g)
      if(have_request):
        requests_f_and_g = minimizer.requests_f_and_g()
        continue
      assert not minimizer.requests_f_and_g()
      if(minimizer.is_terminated()): break
  except RuntimeError as e:
    minimizer.error = str(e)
  minimizer.n_calls = icall
  return minimizer

class minimizer_bound(object):

  def __init__(self,
               calculator,
               use_bounds,
               lower_bound,
               upper_bound,
               initial_values):
    adopt_init_args(self, locals())
    self.x = initial_values
    self.n = self.x.size()

  def run(self):
    self.minimizer = lbfgs_run(
      target_evaluator=self,
      use_bounds=self.use_bounds,
      lower_bound = self.lower_bound,
      upper_bound = self.upper_bound)
    self()
    return self

  def __call__(self):
    self.calculator.update(x = self.x)
    self.f = self.calculator.target()
    self.g = self.calculator.gradients()
    return self.x, self.f, self.g

class minimizer_unbound(object):
  #
  def __init__(self, max_iterations, calculator):
    adopt_init_args(self, locals())
    self.x = self.calculator.x
    self.minimizer = scitbx.lbfgs.run(
      target_evaluator=self,
      termination_params=scitbx.lbfgs.termination_parameters(
        max_iterations=max_iterations))

  def compute_functional_and_gradients(self):
    self.calculator.update(x = self.x)
    t = self.calculator.target()
    g = self.calculator.gradients()
    return t,g

def run():
  # Instantiate rosenbrock class
  calculator = rosenbrock(a = 20, b = 10, x = flex.double([0,0]))
  #
  print('Run L-BFGS (no boundaries)')
  m_unbound = minimizer_unbound(max_iterations=100, calculator=calculator)
  print('\tMinimum: ', list(m_unbound.x))
  print()
  print('Run L-BFGS-B with boundaries')
  m_bound = minimizer_bound(
    calculator     = calculator,
    use_bounds     = 2,
    lower_bound    = flex.double([-10000,-10000]),
    upper_bound    = flex.double([10000,10000]),
    initial_values = flex.double([0,0])).run()
  print('\tMinimum: ', list(m_bound.x))

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
cctbx_website/examples/script_lbfgs_with_curvature.py
from __future__ import absolute_import, division, print_function
#********************************************************************
# This script is automatically generated when running libtbx.refresh (or bootstrap.py)
# It is not part of the GitHub repository
# So if this script is manually changed, the changes will be lost when updating
#********************************************************************
from __future__ import division, print_function
from scitbx import lbfgs as scitbx_lbfgs
from scitbx.array_family import flex
from libtbx import adopt_init_args

# Rosenbrock's function, gradients and curvatures

def target(x,y):
  return (1-x)**2+100*(y-x**2)**2

def grad_x(x,y):
  return -2*(1-x) + 400*(-x*y+x**3)

def grad_y(x,y):
  return 2*100*(y-x**2)

def curv_xx(x,y):
  return 2 + 400*(-y+3*x**2)

def curv_yy(x,y):
  return 200

def lbfgs_run(target_evaluator,
              min_iterations=0,
              max_iterations=None,
              traditional_convergence_test=True,
              use_curvatures=False):
  ext = scitbx_lbfgs.ext
  minimizer = ext.minimizer(target_evaluator.n)
  minimizer.error = None
  is_converged = ext.traditional_convergence_test(target_evaluator.n)
  try:
    icall = 0
    requests_f_and_g = True
    requests_diag = use_curvatures
    while 1:
      if (requests_f_and_g):
        icall += 1
      x, f, g, d = target_evaluator(
        requests_f_and_g=requests_f_and_g,
        requests_diag=requests_diag)
      if (use_curvatures):
        if (d is None): d = flex.double(x.size())
        have_request = minimizer.run(x, f, g, d)
      else:
        have_request = minimizer.run(x, f, g)
      if (have_request):
        requests_f_and_g = minimizer.requests_f_and_g()
        requests_diag = minimizer.requests_diag()
        continue
      assert not minimizer.requests_f_and_g()
      assert not minimizer.requests_diag()
      if (minimizer.iter() >= min_iterations and is_converged(x, g)): break
      if (max_iterations is not None and minimizer.iter() >= max_iterations):
        break
      if (use_curvatures):
        have_request = minimizer.run(x, f, g, d)
      else:
        have_request = minimizer.run(x, f, g)
      if (not have_request): break
      requests_f_and_g = minimizer.requests_f_and_g()
      requests_diag = minimizer.requests_diag()
  except RuntimeError as e:
    minimizer.error = str(e)
  minimizer.n_calls = icall
  return minimizer

class minimizer:

  def __init__(self, xx=-3, yy=-4, min_iterations=0, max_iterations=10000):
    adopt_init_args(self, locals())
    self.x = flex.double([xx, yy])
    self.n = self.x.size()

  def run(self, use_curvatures=False):
    self.minimizer = lbfgs_run(
      target_evaluator=self,
      min_iterations=self.min_iterations,
      max_iterations=self.max_iterations,
      use_curvatures=use_curvatures)
    self(requests_f_and_g=True, requests_diag=False)
    return self

  def __call__(self, requests_f_and_g, requests_diag):
    self.xx, self.yy = self.x
    if (not requests_f_and_g and not requests_diag):
      requests_f_and_g = True
      requests_diag = True
    if (requests_f_and_g):
      self.f = target(self.xx,self.yy)
      self.g = flex.double(
        (grad_x(self.xx, self.yy),
         grad_y(self.xx, self.yy)))
      self.d = None
    if (requests_diag):
      self.d = flex.double(
        (curv_xx(self.xx, self.yy),
         curv_yy(self.xx, self.yy)))
      assert self.d.all_ne(0)
      self.d = 1 / self.d
    return self.x, self.f, self.g, self.d

def run():
  for use_curvatures in (False, True):
    print("use_curvatures:", use_curvatures)
    m = minimizer().run(use_curvatures=use_curvatures)
    print(tuple(m.x), "final")
    if (abs(m.x[0]-1) > 1.e-4 or abs(m.x[1]-1) > 1.e-4):
      print(tuple(m.x), "failure, use_curvatures="+str(use_curvatures))
    print("iter,exception:", m.minimizer.iter(), m.minimizer.error)
    print("n_calls:", m.minimizer.n_calls)
    print()
    assert m.minimizer.n_calls == m.minimizer.nfun()

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
cctbx_website/examples/script_rfactors.py
from __future__ import absolute_import, division, print_function
#********************************************************************
# This script is automatically generated when running libtbx.refresh (or bootstrap.py)
# It is not part of the GitHub repository
# So if this script is manually changed, the changes will be lost when updating
#********************************************************************
from __future__ import absolute_import, division, print_function
import iotbx.pdb
import mmtbx.model
import mmtbx.f_model
from iotbx import reflection_file_reader
import os
import libtbx.load_env
pdb_file = libtbx.env.find_in_repositories(
  relative_path="phenix_regression/pdb/1yjp_h.pdb",
  test=os.path.isfile)
mtz_file = libtbx.env.find_in_repositories(
  relative_path="phenix_regression/reflection_files/1yjp.mtz",
  test=os.path.isfile)
assert (not None in [pdb_file, mtz_file])
# Read in the model file and create model object
pdb_inp = iotbx.pdb.input(file_name = pdb_file)
model = mmtbx.model.manager(model_input = pdb_inp)
# Get miller arrays for data and Rfree flags
miller_arrays = reflection_file_reader.any_reflection_file(file_name =
  mtz_file).as_miller_arrays()
for ma in miller_arrays:
  print(ma.info().label_string())
  if(ma.info().label_string()=="FOBS_X,SIGFOBS_X"):
    f_obs = ma
  if(ma.info().label_string()=="R-free-flags"):
    r_free_flags = ma
# Obtain a common set of reflections
f_obs, r_free_flags = f_obs.common_sets(r_free_flags)
r_free_flags = r_free_flags.array(data = r_free_flags.data()==0)
print(r_free_flags.data().count(True), r_free_flags.data().count(False))
fmodel = mmtbx.f_model.manager(
  f_obs          = f_obs,
  r_free_flags   = r_free_flags,
  xray_structure = model.get_xray_structure())
fmodel.update_all_scales()
print("r_work=%6.4f r_free=%6.4f"%(fmodel.r_work(), fmodel.r_free()))
fmodel.show(show_header=False, show_approx=False)


 *******************************************************************************


 *******************************************************************************
cctbx_website/examples/template.py
from __future__ import absolute_import, division, print_function
#********************************************************************
# This script is automatically generated when running libtbx.refresh (or bootstrap.py)
# It is not part of the GitHub repository
# So if this script is manually changed, the changes will be lost when updating
#********************************************************************
from iotbx.map_model_manager import map_model_manager      # load in the map_model_manager
mmm=map_model_manager()     # get an initialized instance of the map_model_manager


 *******************************************************************************


 *******************************************************************************
cctbx_website/libtbx_refresh.py
from __future__ import absolute_import, division, print_function
from cctbx_website.command_line.extract_script_from_html_cctbx_doc import run
import libtbx.load_env

parent_dir = libtbx.env.dist_path("cctbx_website", default=None)
if parent_dir is not None:
  run(parent_dir)


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/__init__.py


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/exercise.py
from __future__ import division, print_function
import os
import sys
import shutil
import libtbx.load_env
from libtbx import easy_run

def exercise(script, tmp_path, use_pdb_file=False):
  regression_dir = os.path.dirname(os.path.abspath(__file__))
  root_dir = os.path.dirname(regression_dir)
  examples_dir = os.path.join(root_dir, 'examples')
  tmp_dir = os.path.join(regression_dir, tmp_path)

  # make temporary directy "tmp_dir"
  if (not os.path.isdir(tmp_dir)):
    os.makedirs(tmp_dir)
  os.chdir(tmp_dir)

  results = list()
  skipped = False

  if script in ["script_ideal_ss.py"] and not libtbx.env.has_module('phenix'):
    print("phenix not available, skipping test")
    skipped = True
  if script in ["script_compare_ss.py"] and not libtbx.env.has_module('ksdssp'):
    if (not libtbx.env.has_module("ksdssp")):
      print("ksdssp not available, skipping test)")
      skipped = True
  if script in ["doc_programming_tips_3.py"]:
    if sys.platform == 'win32':
      print("Not structured for Windows multiprocessing, skipping test")
      skipped = True
  if not skipped:
    # Some scripts use a PDB file, use one from phenix_regression if available
    if use_pdb_file:
      if script in ['doc_models_hierarchy.py']: #
        path = "phenix_regression/mmtbx/ions/3e0f.pdb"
      else:
        path = "phenix_regression/pdb/1ywf.pdb"
      pdb_file = libtbx.env.find_in_repositories(
        relative_path=path,
        test=os.path.isfile)
      if (pdb_file is None):
        print("phenix_regression not available, skipping test")
        return
      cmd = 'libtbx.python ' + os.path.join(examples_dir, script) + ' ' + pdb_file
    else:
      cmd = 'libtbx.python ' + os.path.join(examples_dir, script)
    # run script from html file
    r = easy_run.fully_buffered(cmd)
    results = [script, r.return_code, r.stdout_lines, r.stderr_lines]

    # go back up to "regression" and delete tmp directory
    os.chdir(root_dir)
    shutil.rmtree(tmp_dir)
    #for f in os.listdir(tmp_dir):
    #  os.remove(os.path.join(tmp_dir, f))

  # parse results to see if it failed
  return_code = 0
  if results:
    if (results[1] == 0): re = 'ran successfully'
    else: re = 'failed'
    print('%s %s  ' % (results[0], re))
    if results[1] != 0:
      return_code = 1
      for line in results[3]:
        print('\t', line, file=sys.stderr)
  if skipped:
    print('%s skipped' % script)

  return return_code


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/tst_10_doc_programming_tips_1.py
from __future__ import absolute_import, division, print_function
import sys
from cctbx_website.regression.exercise import exercise

def run():
  return_code = exercise(script   = "doc_programming_tips_1.py",
                         tmp_path = 'tmp_files_10')
  return return_code


if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/tst_11_script_1.py
from __future__ import absolute_import, division, print_function
import sys
from cctbx_website.regression.exercise import exercise

def run():
  return_code = exercise(script   = "script_1.py",
                         tmp_path = 'tmp_files_11')
  return return_code

if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/tst_12_script_compare_ss.py
from __future__ import absolute_import, division, print_function
import sys
from cctbx_website.regression.exercise import exercise

def run():
  return_code = exercise(script   = "script_compare_ss.py",
                         tmp_path = 'tmp_files_12',
                         use_pdb_file = True)
  return return_code

if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/tst_13_script_ideal_ss.py
from __future__ import absolute_import, division, print_function
import sys
from cctbx_website.regression.exercise import exercise

def run():
  return_code = exercise(script   = "script_ideal_ss.py",
                         tmp_path = 'tmp_files_13')
  return return_code

if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/tst_14_script_lbfgs_no_curvature.py
from __future__ import absolute_import, division, print_function
import sys
from cctbx_website.regression.exercise import exercise

def run():
  return_code = exercise(script   = "script_lbfgs_no_curvature.py",
                         tmp_path = 'tmp_files_14')
  return return_code

if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/tst_15_doc_models_hierarchy.py
from __future__ import absolute_import, division, print_function
import sys
from cctbx_website.regression.exercise import exercise

def run():
  return_code = exercise(script   = "doc_models_hierarchy.py",
                         tmp_path = 'tmp_files_15',
                         use_pdb_file = True)
  return return_code

if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/tst_16_script_lbfgs_with_curvature.py
from __future__ import absolute_import, division, print_function
import sys
from cctbx_website.regression.exercise import exercise

def run():
  return_code = exercise(script   = "script_lbfgs_with_curvature.py",
                         tmp_path = 'tmp_files_16')
  return return_code

if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/tst_17_script_rfactors.py
from __future__ import absolute_import, division, print_function
import sys
from cctbx_website.regression.exercise import exercise

def run():
  return_code = exercise(script   = "script_rfactors.py",
                         tmp_path = 'tmp_files_17')
  return return_code

if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/tst_18_doc_programming_tips_2.py
from __future__ import absolute_import, division, print_function
import sys
from cctbx_website.regression.exercise import exercise

def run():
  return_code = exercise(script   = "doc_programming_tips_2.py",
                         tmp_path = 'tmp_files_18')
  return return_code


if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/tst_19_doc_programming_tips_3.py
from __future__ import absolute_import, division, print_function
import sys
from cctbx_website.regression.exercise import exercise

def run():
  return_code = exercise(script   = "doc_programming_tips_3.py",
                         tmp_path = 'tmp_files_19')
  return return_code


if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/tst_1_template.py
from __future__ import absolute_import, division, print_function
import sys
from cctbx_website.regression.exercise import exercise

def run():
  return_code = exercise(script   = "template.py",
                         tmp_path = 'tmp_files_1')
  return return_code

if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/tst_2_doc_hlo_intro.py
from __future__ import absolute_import, division, print_function
import sys
from cctbx_website.regression.exercise import exercise

def run():
  return_code = exercise(script   = "doc_hlo_intro.py",
                         tmp_path = 'tmp_files_2')
  return return_code

if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/tst_3_doc_hlo_model_manager.py
from __future__ import absolute_import, division, print_function
import sys
from cctbx_website.regression.exercise import exercise

def run():
  return_code = exercise(script   = "doc_hlo_model_manager.py",
                         tmp_path = 'tmp_files_3')
  return return_code

if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/tst_4_doc_hlo_data_manager.py
from __future__ import absolute_import, division, print_function
import sys
from cctbx_website.regression.exercise import exercise

def run():
  return_code = exercise(script   = "doc_hlo_data_manager.py",
                         tmp_path = 'tmp_files_4')
  return return_code

if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/tst_5_doc_hlo_map_manager.py
from __future__ import absolute_import, division, print_function
import sys
from cctbx_website.regression.exercise import exercise

def run():
  return_code = exercise(script   = "doc_hlo_map_manager.py",
                         tmp_path = 'tmp_files_5')
  return return_code

if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/tst_6_doc_hlo_model_map_manager.py
from __future__ import absolute_import, division, print_function
import sys
from cctbx_website.regression.exercise import exercise

def run():
  return_code = exercise(script   = "doc_hlo_model_map_manager.py",
                         tmp_path = 'tmp_files_6')
  return return_code


if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/tst_7_doc_low_flex_advanced.py
from __future__ import absolute_import, division, print_function
import sys
from cctbx_website.regression.exercise import exercise

def run():
  return_code = exercise(script   = "doc_low_flex_advanced.py",
                         tmp_path = 'tmp_files_7')
  return return_code


if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/tst_8_doc_maps_intro.py
from __future__ import absolute_import, division, print_function
import sys
from cctbx_website.regression.exercise import exercise

def run():
  return_code = exercise(script   = "doc_maps_intro.py",
                         tmp_path = 'tmp_files_8')
  return return_code


if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/tst_9_doc_maps_boxing.py
from __future__ import absolute_import, division, print_function
import sys
from cctbx_website.regression.exercise import exercise

def run():
  return_code = exercise(script   = "doc_maps_boxing.py",
                         tmp_path = 'tmp_files_9')
  return return_code


if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
cctbx_website/regression/tst_py_from_html.py
from __future__ import division, print_function
import os
import sys
import libtbx.load_env
from libtbx import easy_run

def run():
  '''
  Loop through scripts in cctbx_website/examples and check if they run
  correctly
  '''
  regression_dir = os.path.dirname(os.path.abspath(__file__))
  root_dir = os.path.dirname(regression_dir)
  examples_dir = os.path.join(root_dir, 'examples')
  tmp_dir = os.path.join(regression_dir, 'tmp_files')

  # make temporary directy "tmp_dir"
  if (not os.path.isdir(tmp_dir)):
    os.makedirs(tmp_dir)
  os.chdir(tmp_dir)

  results = list()
  skipped = list()
  # loop through all .py files in "examples"
  for script in os.listdir(examples_dir):
    cmd = 'libtbx.python ' + os.path.join(examples_dir, script)
    #if script in ['doc_map_manager.py', 'doc_model_map_manager.py'] \
    if script in [] \
      and not libtbx.env.has_module('phenix'):
      skipped.append(script)
      continue
    r = easy_run.fully_buffered(cmd)
    results.append([script, r.return_code, r.stdout_lines, r.stderr_lines])
    # remove files once done
    # (the scripts sometimes on the same input files, so need to delete each time)
    for f in os.listdir(tmp_dir):
      os.remove(os.path.join(tmp_dir, f))
  #
  # go back up to "regression" and delete tmp directory
  os.chdir(root_dir)
  os.rmdir(tmp_dir)

  # print info if fail or success; print stderr if failed
  return_code = 0
  for l in results:
    if (l[1] == 0): re = 'ran successfully'
    else: re = 'failed'
    print('%s %s  ' % (l[0], re))
    if l[1] != 0:
      return_code = 1
      for line in l[3]:
        print('\t', line, file=sys.stderr)
  for l in skipped:
    print('%s skipped' % l)

  return return_code

if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
cctbx_website/run_tests.py
from __future__ import absolute_import, division, print_function
from libtbx import test_utils
import libtbx.load_env

#tst_list = [
#  "$D/regression/tst_py_from_html.py"
#  ]

tst_list = [
  "$D/regression/tst_1_template.py",
  "$D/regression/tst_2_doc_hlo_intro.py",
  "$D/regression/tst_3_doc_hlo_model_manager.py",
  "$D/regression/tst_4_doc_hlo_data_manager.py",
  "$D/regression/tst_5_doc_hlo_map_manager.py",
  "$D/regression/tst_6_doc_hlo_model_map_manager.py",
  "$D/regression/tst_7_doc_low_flex_advanced.py",
  "$D/regression/tst_8_doc_maps_intro.py",
  "$D/regression/tst_9_doc_maps_boxing.py",
  "$D/regression/tst_10_doc_programming_tips_1.py",
  "$D/regression/tst_11_script_1.py",
  "$D/regression/tst_12_script_compare_ss.py",
  "$D/regression/tst_13_script_ideal_ss.py",
  "$D/regression/tst_14_script_lbfgs_no_curvature.py",
  "$D/regression/tst_15_doc_models_hierarchy.py",
  "$D/regression/tst_16_script_lbfgs_with_curvature.py",
  "$D/regression/tst_17_script_rfactors.py",
  "$D/regression/tst_18_doc_programming_tips_2.py",
  "$D/regression/tst_19_doc_programming_tips_3.py",
  ]

def run():

  build_dir = libtbx.env.under_build("cctbx_website")
  dist_dir = libtbx.env.dist_path("cctbx_website")

  test_utils.run_tests(build_dir, dist_dir, tst_list)

if (__name__ == "__main__"):
  run()


 *******************************************************************************
