

 *******************************************************************************
libtbx/tst_path.py
from __future__ import absolute_import, division, print_function
from six.moves import range
def exercise_posix_relpath(f, enable_abspath_if_through_root):
  # based on .test_relpath() in Python-2.7.2/Lib/test/test_posixpath.py
  import os
  (real_getcwd, os.getcwd) = (os.getcwd, lambda: r"/home/user/bar")
  try:
    curdir = os.path.split(os.getcwd())[-1]
    def check(args, r_expected, ra_expected=None):
      if (ra_expected is None): ra_expected = r_expected
      result = f(*args)
      assert result == r_expected
      if (enable_abspath_if_through_root):
        result = f(*(args), **{"enable_abspath_if_through_root": True})
        assert result == ra_expected
    check(["a"], "a")
    check([os.path.abspath("a")], "a")
    check(["a/b"], "a/b")
    check(["../a/b"], "../a/b")
    check(["a", "../b"], "../"+curdir+"/a")
    check(["a/b", "../c"], "../"+curdir+"/a/b")
    check(["a", "b/c"], "../../a")
    check(["a", "a"], ".")
    check(["/foo/bar/bat", "/x/y/z"], '../../../foo/bar/bat', "/foo/bar/bat")
    check(["/foo/bar/bat", "/foo/bar"], 'bat')
    check(["/foo/bar/bat", "/"], 'foo/bar/bat', "/foo/bar/bat")
    check(["/", "/foo/bar/bat"], '../../..', "/")
    check(["/foo/bar/bat", "/x"], '../foo/bar/bat', "/foo/bar/bat")
    check(["/x", "/foo/bar/bat"], '../../../x', "/x")
    check(["/", "/"], '.', "/")
    check(["/a", "/a"], '.')
    check(["/a/b", "/a/b"], '.')
    #
    # added tests, may be partially redundant
    check(["/a/b/c", "/"], "a/b/c", "/a/b/c")
    check(["/a/b/c", "/x"], "../a/b/c", "/a/b/c")
    check(["/a/b/c", "/x/y"], "../../a/b/c", "/a/b/c")
    check(["/a/b/c", "/a"], "b/c")
    check(["/a/b/c", "/a/b"], "c")
    check(["/a/b/c", "/a/b/c"], ".")
    check(["/a/b/c", "/a/b/c/d"], "..")
    check(["/conky/mountpoint/a", "/conky/mountpoint/b/c"], "../../a")
  finally:
    os.getcwd = real_getcwd

def exercise_nt_relpath(f, enable_abspath_if_through_root):
  import os
  _, currentdir = os.path.split(os.getcwd())
  def check(args, r_expected, ra_expected=None):
    result = f(*args)
    assert result == r_expected
    if (enable_abspath_if_through_root and ra_expected is not None):
      result = f(*(args), **{"enable_abspath_if_through_root": True})
      assert result == ra_expected
  check(["a"], 'a')
  check([os.path.abspath("a")], 'a')
  check(["a/b"], 'a\\b')
  check(["../a/b"], '..\\a\\b')
  check(["a", "../b"], '..\\'+currentdir+'\\a')
  check(["a/b", "../c"], '..\\'+currentdir+'\\a\\b')
  check(["a", "b/c"], '..\\..\\a')
  check(["//conky/mountpoint/a", "//conky/mountpoint/b/c"], '..\\..\\a',
    "\\\\conky\\mountpoint\\a")
  check(["a", "a"], '.')
  check(["c:/foo/bar/bat", "c:/x/y/z"], '..\\..\\..\\foo\\bar\\bat',
    "c:\\foo\\bar\\bat")
  check(["c:/foo/bar/bat", "c:/foo/bar"], 'bat', 'bat')
  check(["c:/foo/bar/bat", "c:/"], 'foo\\bar\\bat', "c:\\foo\\bar\\bat")
  check(["c:/", "c:/foo/bar/bat"], '..\\..\\..', "c:\\")
  check(["c:/foo/bar/bat", "c:/x"], '..\\foo\\bar\\bat', "c:\\foo\\bar\\bat")
  check(["c:/x", "c:/foo/bar/bat"], '..\\..\\..\\x', "c:\\x")
  check(["c:/", "c:/"], '.', "c:\\")
  check(["/a", "/a"], '.')
  check(["/a/b", "/a/b"], '.')
  check(["c:/foo", "C:/FOO"], '.', '.')
  check(["c:/aa", "C:/cccc"], '..\\aa', 'c:\\aa')
  check(["c:/aa/bbb", "C:/cccc/ddddd"], '..\\..\\aa\\bbb', 'c:\\aa\\bbb')
  #
  if (enable_abspath_if_through_root):
    assert f("c:\\foo", "d:\\foo", True) == "c:\\foo"
    assert f("//m/d", "//n/d", True) == "\\\\m\\d"
    assert f("d:\\foo", "//n/d", True) == "d:\\foo"
    assert f("//n/d", "d:\\foo", True) == "\\\\n\\d"

def exercise_relpath():
  import sys, os
  if (os.name == "nt"):
    exercise = exercise_nt_relpath
  else:
    exercise = exercise_posix_relpath
  if (sys.version_info[:3] >= (2,7,1)):
    # relpath first appeared in Python 2.6
    # Issue #5117 fixed in Python 2.7.1:
    # Fixed root directory related issue on posixpath.relpath()
    # and ntpath.relpath().
    from os.path import relpath
    exercise(relpath, False)
  from libtbx.path import relpath
  exercise(relpath, True)

def exercise_move_old_create_new_directory():
  from libtbx.path import move_old_create_new_directory as mocnd
  import os
  mocnd("tmp_mocnd")
  assert len(os.listdir("tmp_mocnd")) == 0
  for i in range(3):
    mocnd("tmp_mocnd/a")
  assert sorted(os.listdir("tmp_mocnd")) == ["a", "a_001", "a_002"]
  f = open("tmp_mocnd/a_23", "w")
  f.close()
  mocnd("tmp_mocnd/a")
  assert sorted(os.listdir("tmp_mocnd")) == [
    "a", "a_001", "a_002", "a_024", "a_23"]
  f = open("tmp_mocnd/a_log", "w")
  f.close()
  mocnd("tmp_mocnd/a")
  assert sorted(os.listdir("tmp_mocnd")) == [
    "a", "a_001", "a_002", "a_024", "a_025", "a_23", "a_log"]
  mocnd("tmp_mocnd/b")
  assert sorted(os.listdir("tmp_mocnd")) == [
    "a", "a_001", "a_002", "a_024", "a_025", "a_23", "a_log", "b"]
  mocnd("tmp_mocnd/b", serial_sep="", serial_fmt="%d")
  assert sorted(os.listdir("tmp_mocnd")) == [
    "a", "a_001", "a_002", "a_024", "a_025", "a_23", "a_log", "b", "b1"]

def exercise_cleanup():
  from libtbx.path import clean_out_directory
  from six.moves import cStringIO as StringIO
  import shutil
  import os
  if os.path.isdir("tmp_libtbx_path_cleanup"):
    shutil.rmtree("tmp_libtbx_path_cleanup")
  os.mkdir("tmp_libtbx_path_cleanup")
  os.chdir("tmp_libtbx_path_cleanup")
  os.makedirs("AutoSol_run_1_/TEMP0")
  os.makedirs("AutoBuild_run_2_/TEMP0")
  os.makedirs("AutoBuild_run_2_/resolve_1.ccp4")
  with open("AutoBuild_run_2_/TEMP0/model.pdb", "w") as f:
    f.write("END\n")
  os.makedirs("Refine_3/.comm")
  with open("Refine_3/refine_3.geo", "w") as f:
    f.write("\n")
  with open("Refine_3/refine_3.kin", "w") as f:
    f.write("\n")
  with open("Refine_3/refine_3_2fofc.ccp4", "w") as f:
    f.write("\n")
  with open("Refine_3/refine_3_fofc.xplor", "w") as f:
    f.write("\n")
  with open("probe.txt", "w") as f:
    f.write("\n")
  os.mkdir("FFT_4")
  with open("FFT_4/refine_3_2fofc.ccp4", "w") as f:
    f.write("\n")
  c_o_d = clean_out_directory(".")
  out = StringIO()
  c_o_d.show(out=out)
  assert (out.getvalue() == """\
The following 3 directories will deleted:
  ./AutoBuild_run_2_/TEMP0
  ./AutoSol_run_1_/TEMP0
  ./Refine_3/.comm
The following 5 files will be deleted:
  ./Refine_3/refine_3.geo
  ./Refine_3/refine_3.kin
  ./Refine_3/refine_3_2fofc.ccp4
  ./Refine_3/refine_3_fofc.xplor
  ./probe.txt
0.0 KB of disk space will be freed.
"""), out.getvalue()

def exercise_symlinks_in_relocatable_path():
  import os
  import tempfile
  from libtbx.path import abs_real_norm, absolute_path, relocatable_path

  cwd = abs_real_norm(os.getcwd())  # ensure no symbolic links

  with tempfile.NamedTemporaryFile(dir=cwd) as f:

    original = f.name
    link = os.path.join(cwd, 'abc')
    os.symlink(original, link)

    # symbolic link is resolved
    l = relocatable_path(absolute_path(cwd), link)
    assert abs(l) == original

    # symbolic link is kept
    l = relocatable_path(absolute_path(cwd), link, resolve_symlinks=False)
    assert abs(l) == link

def run(args):
  assert len(args) == 0
  exercise_relpath()
  exercise_move_old_create_new_directory()
  from libtbx.path import random_new_directory_name
  assert len(random_new_directory_name()) == len("tmp_dir_00000000")
  import os
  if (os.name == "nt") : # FIXME
    print("skipping directory cleanup and symbolic link tests on Windows")
  else :
    exercise_cleanup()
    exercise_symlinks_in_relocatable_path()
  print("OK")

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/tst_program_template.py
from __future__ import absolute_import, division, print_function

import sys

import libtbx.phil
from libtbx.program_template import ProgramTemplate
from libtbx.utils import multi_out
from libtbx.version import get_version

# =============================================================================
class TestProgram(ProgramTemplate):

  master_phil = """
parameter_a = None
  .type = str
parameter_b = 0
  .type = int
parameter_c = None
  .type = float
"""

class TestVersionProgram(ProgramTemplate):

  version = 'abc'

  master_phil = """
parameter_a = None
  .type = str
parameter_b = 0
  .type = int
parameter_c = None
  .type = float
"""

working_phil = libtbx.phil.parse("parameter_a = not None\nparameter_b = 5")

# -----------------------------------------------------------------------------
def test_phil():
  master_phil = libtbx.phil.parse(TestProgram.master_phil)
  required_output_phil = libtbx.phil.parse(ProgramTemplate.output_phil_str)
  master_phil.adopt_scope(required_output_phil)

  params = master_phil.fetch(working_phil).extract()
  logger = multi_out()
  logger.register('stdout', sys.stdout)
  test_program = TestProgram(None, params, master_phil, logger)

  full_phil = libtbx.phil.parse(test_program.get_program_phil_str())
  full = master_phil.fetch(full_phil).extract()
  assert full.parameter_a == 'not None'
  assert full.parameter_b == 5
  assert full.parameter_c is None
  assert 'parameter_c' in test_program.get_program_phil_str()
  assert 'parameter_c' not in test_program.get_program_phil_str(True)

  assert test_program.get_default_output_filename() == 'cctbx_program_000'
  assert test_program.get_default_output_filename(prefix='abc') == 'abc_000'
  assert test_program.get_default_output_filename(suffix='abc') == 'cctbx_programabc_000'
  assert test_program.get_default_output_filename(serial=999) == 'cctbx_program_999'
  assert test_program.get_default_output_filename(prefix='abc', suffix='def', serial=123) == 'abcdef_123'

  test_program.params.output.prefix = 'prefix'
  test_program.params.output.suffix = 'suffix'
  test_program.params.output.serial = 7
  assert test_program.get_default_output_filename() == 'prefixsuffix_007'
  assert test_program.get_default_output_filename(prefix='abc') == 'abcsuffix_007'
  assert test_program.get_default_output_filename(suffix='abc') == 'prefixabc_007'
  assert test_program.get_default_output_filename(serial=999) == 'prefixsuffix_999'

  try:
    test_program.get_default_output_filename(serial='abc')
  except ValueError as e:
    if str(e) != 'The serial argument should be an integer.':
      raise

# -----------------------------------------------------------------------------
def test_version():
  assert TestProgram.get_version() == get_version()
  assert TestVersionProgram.get_version() == TestVersionProgram.version

# =============================================================================
if __name__ == '__main__':
  test_phil()


 *******************************************************************************


 *******************************************************************************
libtbx/tst_python_code_parsing.py
from __future__ import absolute_import, division, print_function


def exercise_unused_imports():
  from libtbx.python_code_parsing import unused_imports, imported_name
  unused = unused_imports(unused_imports_test_case_1_1)
  assert unused.names == set((
    'foo', 'far', 'close', 'baz', 'barbar', 'bozboz' ))
  unused = unused_imports(unused_imports_test_case_1_2)
  assert unused.names == set((
    'far', 'close', 'baz', 'barbar', 'bozboz' ))
  unused = unused_imports(unused_imports_test_case_1_3)
  assert unused.names == set((
    'foo', 'far', 'close', 'barbar', 'bozboz' ))
  unused = unused_imports(unused_imports_test_case_1_4)
  assert unused.names == set((
    'far', 'close', 'barbar', 'bozboz' ))
  unused = unused_imports(unused_imports_test_case_1_5)
  assert unused.names == set((
    'far', 'close', 'baz', 'barbar', 'bozboz' ))
  unused = unused_imports(unused_imports_test_case_2)
  assert not unused
  unused = unused_imports(unused_imports_test_case_3)
  assert set(unused) == set(( imported_name('foo', lineno=1), ))
  unused = unused_imports(unused_imports_test_case_4)
  assert set(unused) == set(( imported_name('foo', lineno=4), ))
  unused = unused_imports(unused_imports_test_case_5)
  assert set(unused) == set(( imported_name('foo', lineno=4), ))
  unused = unused_imports(unused_imports_test_case_6)
  assert set(unused) == set(( imported_name('bar', lineno=1), ))
  unused = unused_imports(unused_imports_test_case_7)
  assert set(unused) == set(( imported_name('bar', lineno=1),
                              imported_name('foo', lineno=6), ))
  unused = unused_imports(unused_imports_test_case_7_bis)
  assert set(unused) == set(( imported_name('bar', lineno=1), ))
  unused = unused_imports(unused_imports_test_case_8)
  assert set(unused) == set(( imported_name('foo', lineno=1), ))
  unused = unused_imports(unused_imports_test_case_9)
  assert not unused
  unused = unused_imports(unused_imports_test_case_10)
  assert set(unused) == set(( imported_name('foo', lineno=10), ))
  unused = unused_imports(unused_imports_test_case_11)
  assert unused
  unused = unused_imports(unused_imports_test_case_11,
                          ignored_imports=('libtbx.load_env',))
  assert not unused
  unused = unused_imports(unused_imports_test_case_12)
  assert not unused
  unused = unused_imports(unused_imports_test_case_13)
  assert set(unused) == set(( imported_name('bar', lineno=1), ))
  unused = unused_imports(unused_imports_test_case_14)
  assert set(unused) == set(( imported_name('bar', lineno=1), ))
  unused = unused_imports(unused_imports_test_case_15)
  assert set(unused) == set(( imported_name('bar', lineno=1), ))
  unused = unused_imports(unused_imports_test_case_16)
  assert not unused
  unused = unused_imports(unused_imports_test_case_17)
  assert not unused
  unused = unused_imports(unused_imports_test_case_18)
  assert not unused
  unused = unused_imports(unused_imports_test_case_19)
  assert not unused
  unused = unused_imports(unused_imports_test_case_20)
  assert not unused
  unused = unused_imports(unused_imports_test_case_21)
  assert not unused
  unused = unused_imports(unused_imports_test_case_22)
  assert not unused
  unused = unused_imports(unused_imports_test_case_23)
  assert unused
  unused = unused_imports(
    unused_imports_test_case_23,
    ignore_imports_flagged_by_comments=('# import dependency',))
  assert not unused
  unused = unused_imports(unused_imports_test_case_24)
  assert not unused
  unused = unused_imports(unused_imports_test_case_25)
  assert not unused
  unused = unused_imports(unused_imports_test_case_26)
  assert not unused


unused_imports_test_case_1_header = """\
import foo
import far, near as close
from bar import baz
from foobar import barbar, bazbaz as bozboz
from buz import *
"""

unused_imports_test_case_1_1 = """\
%s
""" % unused_imports_test_case_1_header

unused_imports_test_case_1_2 = """\
%s
type(foo.z)
""" % unused_imports_test_case_1_header

unused_imports_test_case_1_3 = """\
%s
type(baz.x)
""" % unused_imports_test_case_1_header

unused_imports_test_case_1_4 = """\
%s
type(foo.z)
type(baz.x)
""" % unused_imports_test_case_1_header

unused_imports_test_case_1_5 = """\
%s
type(foo.baz)
""" % unused_imports_test_case_1_header


unused_imports_test_case_2 = """\
import foo

def f():
  return type(foo.z)
"""

unused_imports_test_case_3 = """\
import foo

def f():
  return type(bar.foo.z)
"""

unused_imports_test_case_4 = """\
import bar

def f():
  import foo
  return type(bar.foo.z)
"""

unused_imports_test_case_5 = """\
import bar

def f():
  import foo
  def g():
    return type(bar.foo.z)
  return g
"""

unused_imports_test_case_6 = """\
import bar

def f():
  import foo
  def g():
    return type(foo.z)
  return g
"""

unused_imports_test_case_7 = """\
import bar

def f():
  def g():
    return type(foo.z)
  import foo
  return g
"""

unused_imports_test_case_7_bis = """\
import bar

def f():
  def g():
    return type(foo.z)
  import foo
  def h():
    return type(foo.y)
  return g, h
"""

unused_imports_test_case_8 = """\
import foo, bar

class klass(object):

  def f(self):
    self.x = bar.z
"""

unused_imports_test_case_9 = """\
import foo, bar

class klass(object):

  attr = foo.x

  def f(self):
    self.x = bar.z
"""

unused_imports_test_case_10 = """\
import bar

class klass(object):

  attr = foo.x

  def f(self):
    self.x = bar.z

import foo
"""

unused_imports_test_case_11 = """\
import libtbx.load_env

def run():
  libtbx.env.build_options.report()
"""

unused_imports_test_case_12 = """\
import foo.bar
type(foo.bar.x)
"""

unused_imports_test_case_13 = """\
import foo, bar
type(foo.moo.maz)
"""

unused_imports_test_case_14 = """\
import foo, bar
type(foo.moo().moz)
"""

unused_imports_test_case_15 = """\
import foo, bar
type(foo.moo[5].moz)
"""

unused_imports_test_case_16 = """\
from foo import bobar
type(bobar)
"""

unused_imports_test_case_17 = """\
import foobar
text = '.'.join(foobar.z)
"""

unused_imports_test_case_18 = """\
import foz
def faaz(arg=foz.x.yyy):
  pass
"""

unused_imports_test_case_19 = """\
import foo.barr
hasattr(foo.barr, 'bok')
"""

unused_imports_test_case_20 = """\
import foo.barr
class bokka(kool, foo.barr.klass):
  pass
"""

unused_imports_test_case_21 = """\
from foo.bar import bakar
import foo.bar.bakar.baaz

type(bakar.baaz)
"""

unused_imports_test_case_22 = """\
from foo.bar import boz
def f():
  return g( boz(q) ).k
"""

unused_imports_test_case_23 = """\
from scitbx.array_family import flex # import dependency
"""

unused_imports_test_case_24 = """\
from foo.bar import boz
import baz.buz
def f():
  boz.x = 1
  baz.buz.y = 2
"""

unused_imports_test_case_25 = """\
from foo.bar import boz

def f():
  return g(a=boz.h()).x
"""

unused_imports_test_case_26 = """\
from foo.bar import boz
import fooo.baz

def f():
  return g[boz.h()].x

def h():
  return g[fooo.baz.x:1000]
"""

def exercise_old_style_classes():
  from libtbx.python_code_parsing import find_old_style_classes, old_style_class
  old_style = find_old_style_classes(old_style_class_test_case_1)
  assert old_style.names == set(('foo',))
  old_style = find_old_style_classes(old_style_class_test_case_2)
  assert old_style.names == set()
  old_style = find_old_style_classes(old_style_class_test_case_3)
  assert old_style.names == set(('bar',))
  old_style = find_old_style_classes(old_style_class_test_case_4)
  assert set(old_style) == set((old_style_class(name='foo', lineno=4),
                                old_style_class(name='bar', lineno=1)))
  old_style = find_old_style_classes(old_style_class_test_case_5)
  assert old_style.names == set(('foo',))

old_style_class_test_case_1 = """\
class foo:
  pass
"""

old_style_class_test_case_2 = """\
class foo(object):
  pass
"""

old_style_class_test_case_3 = """\
class bar:
  pass

class foo(bar):
  pass
"""

old_style_class_test_case_4 = """\
class bar:
  pass

class foo():
  pass
"""

old_style_class_test_case_5 = """\
def bar():
  class foo:
    pass
"""

def run():
  exercise_unused_imports()
  exercise_old_style_classes()
  print('OK')

if __name__ == '__main__':
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/tst_representation.py
from __future__ import absolute_import, division, print_function

from six.moves import range
if (__name__ == "__main__"):
  for x in range(30):
    J = 7205759403792790 + x
    print(J * 10**30 // 2**56)

  T = 0.1 # Target
  # T ~= J / (2**N)
  # where J has exactly R bits
  # J ~= T * (2**N)
  print("BEst",T*(2**52))
  print("    ",T*(2**53))

  import math


  print(52 - math.log(T,2))
  print(53 - math.log(T,2))

  def precision_approx_equal(self,other,precision=24):
    # Use concepts from IEEE-754 to determine if the difference between
    # two numbers is within floating point error.  Not within scope to
    # do this for double precision literals; only interested in the case
    # where the data are from a ~single precision digital-analog converter.
    if self==other:
      return True
    if (self > 0.) != (other > 0.):
      return False
    #compute the exponent
    import math
    T = abs(self)
    Np = math.floor(precision-math.log(T,2))
    significand = int(T * 2**Np)
    val1 = significand/(2**Np) # nearest floating point representation of self
    val2 = (significand+1)/(2**Np) # next-nearest
    return abs(T-abs(other)) <= abs(val1-val2)
  print(precision_approx_equal(0.799999,0.800004,precision=17))


 *******************************************************************************


 *******************************************************************************
libtbx/tst_runtime_utils.py
from __future__ import absolute_import, division, print_function
from libtbx import runtime_utils
from libtbx import easy_pickle
from libtbx import easy_run
import time
import os
import sys

def exercise():
  params = runtime_utils.process_master_phil.extract()
  i = 0
  while True :
    output_dir = os.path.join(os.getcwd(), "simple_run%d" % i)
    if os.path.exists(output_dir):
      i += 1
    else :
      os.makedirs(output_dir)
      break
  run = runtime_utils.simple_run(output_dir)
  params.output_dir = output_dir
  params.buffer_stdout = False
  params.tmp_dir = output_dir
#  driver = runtime_utils.detached_process_driver(output_dir, run)
  params.run_file = os.path.join(output_dir, "run.pkl")
  eff_file = os.path.join(output_dir, "run.eff")
  working_phil = runtime_utils.process_master_phil.format(python_object=params)
  with open(eff_file, "w") as f:
    working_phil.show(out=f)
  easy_pickle.dump(params.run_file, run)
  assert not easy_run.call("libtbx.start_process %s &" % eff_file) #params.run_file)
  client = runtime_utils.simple_client(params)
  client.run()
  assert (client.out.getvalue() == """\
current is 44444.444444
current is 50000.000000
current is 57142.857143
current is 66666.666667
""")
  assert client.n_cb >= 5 # this is variable!
  assert ([ cb.message for cb in client._accumulated_callbacks ] ==
          ['run 0', 'run 1', 'run 2', 'run 3'])

def exercise2():
  f = runtime_utils.simple_func(666)
  easy_pickle.dump("myfunc.pkl", f)
  f_out = easy_run.fully_buffered(
    "libtbx.run_pickled_function myfunc.pkl").stdout_lines
  assert (f_out[0] == "666")

# queueing system support
def exercise3():
  i = 0
  while True :
    output_dir = os.path.join(os.getcwd(), "simple_run%d" % i)
    if os.path.exists(output_dir):
      i += 1
    else :
      os.makedirs(output_dir)
      break
  run = runtime_utils.simple_run(output_dir)
  params = runtime_utils.process_master_phil.extract()
  server = runtime_utils.detached_process_server(run, params)
  from libtbx.queuing_system_utils import generic as queuing
  job = queuing.qsub(
    name="tst_runtime_utils",
    target=server)
  job.start()
  client = runtime_utils.simple_client(params)
  client.run()
  assert (client.out.getvalue() == """\
current is 44444.444444
current is 50000.000000
current is 57142.857143
current is 66666.666667
""")
  assert client.n_cb >= 5 # this is variable!
  time.sleep(1)
  assert ([ cb.message for cb in client._accumulated_callbacks ] ==
          ['run 0', 'run 1', 'run 2', 'run 3'])

if __name__ == "__main__" :
  exercise()
  exercise2()
  if ("-q" in sys.argv):
    print("Testing queueing system support...")
    exercise3()
  print("OK")


 *******************************************************************************


 *******************************************************************************
libtbx/tst_scheduling.py
from __future__ import absolute_import, division, print_function

import unittest
import time
from six.moves import range

def normal_function(arg, wait):

  time.sleep( wait )
  return 3 * arg


def raise_runtime_error(message, wait):

  time.sleep( wait )
  raise RuntimeError(message)


def raise_sorry(message, wait):

  time.sleep( wait )
  from libtbx.utils import Sorry
  raise Sorry(message)


def crash_python(wait):

  time.sleep( wait )
  import boost_adaptbx.boost.python as bp
  bp.ext.dereference_char_pointer(None)


class TestManager(unittest.TestCase):

  def run_normal_function(self, manager, value):

    self.assertTrue( manager.is_empty() )
    jobid = manager.submit( target = normal_function, args = ( value, 0.05 ) )
    self.assertFalse( manager.is_empty() )
    result = next(manager.results())
    self.assertEqual( result[0], jobid )
    self.assertEqual( normal_function( arg = value, wait = 0 ), result[1]() )
    self.assertTrue( manager.is_empty() )


  def run_raise_runtime_error(self, manager, message):

    self.assertTrue( manager.is_empty() )
    jobid = manager.submit( target = raise_runtime_error, args = ( message, 0.05 ) )
    self.assertFalse( manager.is_empty() )
    result = next(manager.results())
    self.assertEqual( result[0], jobid )
    self.assertRaises( RuntimeError, result[1] )
    self.assertTrue( manager.is_empty() )


  def run_raise_sorry(self, manager, message):

    self.assertTrue( manager.is_empty() )
    jobid = manager.submit( target = raise_sorry, args = ( message, 0.05 ) )
    self.assertFalse( manager.is_empty() )
    result = next(manager.results())
    self.assertEqual( result[0], jobid )

    from libtbx.utils import Sorry
    self.assertRaises( Sorry, result[1] )
    self.assertTrue( manager.is_empty() )


  def run_crash_python(self, manager):

    self.assertTrue( manager.is_empty() )
    jobid = manager.submit( target = crash_python, args = ( 0.05, ) )
    self.assertFalse( manager.is_empty() )
    result = next(manager.results())
    self.assertEqual( result[0], jobid )

    self.assertRaises( RuntimeError, result[1] )
    self.assertTrue( manager.is_empty() )


  def run_tests(self, creator, perform_crash_test = False):

    from libtbx.scheduling import holder

    with holder( creator = creator ) as manager:
      for i in range( 5 ):
        self.run_normal_function( manager = manager, value = i )

      self.run_raise_runtime_error( manager = manager, message = "runtime_error message" )
      self.run_raise_sorry( manager = manager, message = "sorry message" )

      if perform_crash_test:
        self.run_crash_python( manager = manager )

      for i in range( 5, 10 ):
        self.run_normal_function( manager = manager, value = i )

      manager.join()


  def test_mainthread(self):

    from libtbx.scheduling import mainthread
    self.run_tests( creator = mainthread.creator )


  def test_job_scheduler_threading(self):

    from libtbx.scheduling import job_scheduler
    from libtbx.scheduling import thread_handler
    import threading

    creator = job_scheduler.creator(
      job_factory = threading.Thread,
      queue_factory = thread_handler.qfactory,
      capacity = job_scheduler.limited( njobs = 1 ),
      )
    self.run_tests( creator = creator )


  def test_job_scheduler_multiprocessing(self):

    from libtbx.scheduling import job_scheduler
    from libtbx.scheduling import mp_handler

    creator = job_scheduler.creator(
      job_factory = mp_handler.stderr_capturing_process,
      queue_factory = mp_handler.fifo_qfactory,
      capacity = job_scheduler.limited( njobs = 1 ),
      )
    import sys
    self.run_tests(
      creator = creator,
      perform_crash_test = ( sys.platform != "win32" ),
      )


  def test_process_pool_threading(self):

    from libtbx.scheduling import process_pool
    from libtbx.scheduling import thread_handler
    import threading

    creator = process_pool.creator(
      job_factory = threading.Thread,
      inq_factory = thread_handler.qfactory,
      outq_factory = thread_handler.qfactory,
      autoscaling = process_pool.constant_capacity( capacity = 1 ),
      lifecycle = process_pool.unlimited,
      )
    self.run_tests( creator = creator )


  def test_process_pool_multiprocessing(self):

    from libtbx.scheduling import process_pool
    from libtbx.scheduling import mp_handler

    creator = process_pool.creator(
      job_factory = mp_handler.stderr_capturing_process,
      inq_factory = mp_handler.fifo_qfactory,
      outq_factory = mp_handler.fifo_qfactory,
      autoscaling = process_pool.constant_capacity( capacity = 1 ),
      lifecycle = process_pool.unlimited,
      )
    import sys
    self.run_tests(
      creator = creator,
      perform_crash_test = ( sys.platform != "win32" ),
      )


suite_manager = unittest.TestLoader().loadTestsFromTestCase(
  TestManager
  )


alltests = unittest.TestSuite(
  [
    suite_manager,
    ]
  )


def load_tests(loader, tests, pattern):

    return alltests


if __name__ == "__main__":
    unittest.TextTestRunner( verbosity = 2 ).run( alltests )


 *******************************************************************************


 *******************************************************************************
libtbx/tst_str_utils.py
from __future__ import absolute_import, division, print_function
from six.moves import range
def exercise():
  from libtbx.test_utils import show_diff, Exception_expected
  from six.moves import cPickle as pickle
  #
  from libtbx.str_utils import split_keeping_spaces
  assert split_keeping_spaces(s="") == []
  assert split_keeping_spaces(s=" ") == [" "]
  assert split_keeping_spaces(s="a") == ["a"]
  assert split_keeping_spaces(s="abc") == ["abc"]
  assert split_keeping_spaces(s=" a") == [" ", "a"]
  assert split_keeping_spaces(s="  a") == ["  ", "a"]
  assert split_keeping_spaces(s="  abc") == ["  ", "abc"]
  assert split_keeping_spaces(s="  abc ") == ["  ", "abc", " "]
  assert split_keeping_spaces(s="  abc  ") == ["  ", "abc", "  "]
  assert split_keeping_spaces(s="a ") == ["a", " "]
  assert split_keeping_spaces(s="a  ") == ["a", "  "]
  assert split_keeping_spaces(s="abc  ") == ["abc", "  "]
  assert split_keeping_spaces(s="a b") == ["a", " ", "b"]
  assert split_keeping_spaces(s="a  b") == ["a", "  ", "b"]
  assert split_keeping_spaces(s="  a  b c   d ") == [
    "  ", "a", "  ", "b", " ", "c", "   ", "d", " "]
  #
  from libtbx.str_utils import size_as_string_with_commas
  assert size_as_string_with_commas(0) == "0"
  assert size_as_string_with_commas(1) == "1"
  assert size_as_string_with_commas(-1) == "-1"
  assert size_as_string_with_commas(10) == "10"
  assert size_as_string_with_commas(100) == "100"
  assert size_as_string_with_commas(1000) == "1,000"
  assert size_as_string_with_commas(12345) == "12,345"
  assert size_as_string_with_commas(12345678) == "12,345,678"
  assert size_as_string_with_commas(-12345678) == "-12,345,678"
  #
  from libtbx.str_utils import show_string
  assert show_string("abc") == '"abc"'
  assert show_string("a'c") == '"a\'c"'
  assert show_string('a"c') == "'a\"c'"
  assert show_string('\'"c') == '"\'\\"c"'
  #
  from libtbx.str_utils import prefix_each_line
  assert prefix_each_line(prefix="^", lines_as_one_string="""\
hello
world""") == """\
^hello
^world"""
  #
  from libtbx.str_utils import prefix_each_line_suffix
  assert prefix_each_line_suffix(prefix="^", lines_as_one_string="""\
hello
world""", suffix=" ") == """\
^hello
^world"""
  assert prefix_each_line_suffix(prefix="^", lines_as_one_string="""\
hello
world""", suffix=" ", rstrip=False) == """\
^hello%s
^world """ % " "
  #
  from libtbx.str_utils import show_sorted_by_counts
  from six.moves import cStringIO
  out = cStringIO()
  assert show_sorted_by_counts(
    label_count_pairs=[("b", 3), ("a", 3), ("c", -2)],
    out=out, prefix="%")
  assert not show_diff(out.getvalue(), """\
%"a"  3
%"b"  3
%"c" -2
""")
  out = cStringIO()
  assert show_sorted_by_counts(
    label_count_pairs=[("b", -3), ("a", -3), ("c", 2)], reverse=False,
     out=out, prefix="%", annotations=[None, "", "x"])
  assert not show_diff(out.getvalue(), """\
%"a" -3
%"b" -3
%"c"  2 x
""")
  #
  from libtbx.str_utils import line_breaker
  for string, expected_result in [
    ("", [""]),
    ("this is", ["this is"]),
    ("this is a", ["this is", "a"]),
    ("this is a sentence", ["this is", "a", "sentence"]),
    ("this is a longer sentence", ["this is", "a", "longer", "sentence"]),
    ("this is a very long sentence indeed",
      ["this is", "a very", "long", "sentence", "indeed"])]:
    assert [block for block in line_breaker(string, width=7)]==expected_result
  #
  from libtbx.str_utils import StringIO
  out1 = cStringIO()
  out2 = StringIO()
  out3 = StringIO("Hello world!\n")
  print("Hello world!", file=out1)
  print("Hello world!", file=out2)
  try :
      print("Hello world!", file=out3)
  except AttributeError :
    pass
  else :
    raise Exception_expected
  out4 = pickle.loads(pickle.dumps(out2))
  out5 = pickle.loads(pickle.dumps(out3))
  assert out4.getvalue()==out1.getvalue()==out2.getvalue()==out5.getvalue()
  #
  from libtbx.str_utils import reformat_terminal_text
  txt1 = """
This is some
terminal-formatted
text which needs
to be reset.
"""
  assert (reformat_terminal_text(txt1) ==
          "This is some terminal-formatted text which needs to be reset.")
  txt2 = """
  This is more
  terminal-formatted
  text which needs
  to be reset.
"""
  #
  from libtbx.str_utils import strip_lines, rstrip_lines
  lines = ["  This is more ", "  terminal-formatted ", "  text "]
  assert (strip_lines(txt2) ==
    "\nThis is more\nterminal-formatted\ntext which needs\nto be reset.")
  assert (rstrip_lines(txt2) ==
    "\n  This is more\n  terminal-formatted\n  text which needs\n  to be reset."
  )
  #
  from libtbx.str_utils import expandtabs_track_columns
  def check(s):
    es,js = expandtabs_track_columns(s=s)
    assert len(js) == len(s)
    assert es == s.expandtabs()
    sr = "".join([es[j] for j in js])
    assert sr == s.replace("\t", " ")
  check("")
  check("\t")
  check("\t\t")
  check("\ty")
  check("x\ty")
  check("x\ty\tz")
  check("\txy\t\tz")
  check("abcdefg\txy\t\tz")
  check("ab defgh\txyz\t\tu")
  #
  from libtbx.str_utils import format_value
  assert format_value("%.4f", 1.2345678) == "1.2346"
  assert format_value("%.4f", None) == "  None"
  assert format_value("%.4f", None, replace_none_with="---") == "   ---"
  #
  from libtbx.str_utils import make_header
  out = StringIO()
  make_header("Header 1", out=out)
  assert (out.getvalue() == """
=================================== Header 1 ==================================

""")
  out = StringIO()
  make_header("Header 2", out=out)
  assert (out.getvalue() == """
=================================== Header 2 ==================================

""")
  #
  import sys
  from libtbx.str_utils import string_representation
  iset = list(range(130)) + list(range(250,256))
  for i in iset:
    s = chr(i)
    for j in iset:
      ss = s + chr(j)
      sr = string_representation(
        string=ss, preferred_quote="'", alternative_quote='"')
      if sys.hexversion < 0x03000000:
        assert sr == repr(ss)
      else:
        assert eval(sr) == ss
  from libtbx.str_utils import framed_output
  out = StringIO()
  box = framed_output(out, frame='#')
  print("Hello, world!", file=box)
  box.close()
  assert (out.getvalue() == """
#################
# Hello, world! #
#################
""")
  out = StringIO()
  box = framed_output(out, frame='-', width=80, center=True,
    title="Refinement stats")
  box.write("r_free = 0.1234")
  box.write("  ")
  box.write("r_work = 0.1567")
  box.close()
  assert (out.getvalue() == """
|--------------------------------Refinement stats------------------------------|
|                       r_free = 0.1234  r_work = 0.1567                       |
|------------------------------------------------------------------------------|
""")
  out = StringIO()
  box = framed_output(out, frame='-', width=72, prefix="    ",
    title="Validation summary")
  print("Overall MolProbity score: 2.56", file=box)
  box.add_separator()
  print("""\
Ramachandran favored:  97.5 %
             outliers:  2.5 %
Rotamer outliers:       5.9 %
Clashscore:            10.9""", file=box)
  assert (out.getvalue() == "")
  del box
  assert (out.getvalue() == """
    |-Validation summary---------------------------------------------------|
    | Overall MolProbity score: 2.56                                       |
    |----------------------------------------------------------------------|
    | Ramachandran favored:  97.5 %                                        |
    |              outliers:  2.5 %                                        |
    | Rotamer outliers:       5.9 %                                        |
    | Clashscore:            10.9                                          |
    |----------------------------------------------------------------------|
""")
  from libtbx.str_utils import print_message_in_box
  out = StringIO()
  print_message_in_box(
    message="This is some terminal-formatted text which needs to be reset.",
    out=out,
    width=32,
    center=True,
    prefix="  ",
    frame='*')
  assert (out.getvalue() == """
  ********************************
  *         This is some         *
  *   terminal-formatted text    *
  *   which needs to be reset.   *
  ********************************
""")
  from libtbx.str_utils import make_big_header
  out = StringIO()
  make_big_header("Section title", out=out)
  assert (out.getvalue() == """
################################################################################
#                                Section title                                 #
################################################################################
""")

def exercise_matching_nested_pairs():
  from libtbx.str_utils import find_matching_closing_symbol
  f = find_matching_closing_symbol('(',')')

  s = '... ( ... ( ... ) ...'
  p = s.find('(')
  q = f(s, p)
  assert q == -1
  p1 = s.find('(', p+1)
  q1 = f(s, p1)
  assert q1 == s.rfind(')')

  s = ' ( ( ) ( ( ( ) ) ) ) ) '
  p = f(s, 1)
  assert p == 19

def run(args):
  assert len(args) == 0
  exercise()
  exercise_matching_nested_pairs()
  print("OK")

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/tst_thread_utils.py

from __future__ import absolute_import, division, print_function

from six.moves import cStringIO as StringIO

from libtbx.thread_utils import thread_with_callback_and_wait
from libtbx.thread_utils import process_with_callbacks
from libtbx.utils import Sorry, Abort
import time
import sys
from six.moves import range

########################################################################
# THREADING ONLY
#
def exercise_threading():
  collected = []

  def first_callback(i):
    collected.append(-i*10)

  def callback(i):
    collected.append(i*10)
    return (i < 5)

  def run(n=3, callback=None):
    i = 1
    while (callback is not None or i <= n):
      collected.append(i)
      if (callback is not None):
        status = callback(i)
        if (status == False):
          break
      i += 1

  run()
  assert collected == [1,2,3]

  for callback1,expected in [
        (None, [1,10]),
        (first_callback, [1,-10])]:
    for n_resume in range(7):
      collected = []
      t = thread_with_callback_and_wait(
        run=run,
        callback=callback,
        first_callback=callback1)
      if (callback1 is None):
        t.start()
      else:
        t.start_and_wait_for_first_callback()
      for i in range(n_resume):
        t.resume()
      t.resume(last_iteration=True).join()
      assert collected == expected
      if (n_resume < 4):
        expected.extend([n_resume+2, (n_resume+2)*10])

########################################################################
# THREADING + MULTIPROCESSING
#
class _callback_handler(object):
  def __init__(self):
    self._err = None
    self._result = None
    self._abort = None
    self._stdout = None
    self._other = None

  def cb_err(self, error, traceback_info):
    self._err = error
    self._tb = traceback_info

  def cb_abort(self):
    self._abort = True

  def cb_result(self, result):
    self._result = result

  def cb_stdout(self, stdout):
    if self._stdout is not None : self._stdout += str(stdout)
    else                        : self._stdout = str(stdout)

  def cb_other(self, data):
    if self._other is not None :
      self._other.append(data)
    else :
      self._other = [data]

  def tst_error_raised(self):
    assert self._err is not None
    assert self._result is None

  def tst_run_success(self, expected_result=None, expected_stdout=None,
      expected_other=None):
    assert self._err is None
    assert self._abort is None
    assert self._result == expected_result
    assert self._stdout == expected_stdout
    assert self._other == expected_other

#--- test 01 : propagate args and kwds to target
def _inner_target_with_args_and_kwds(a, b, c=-1, d=-1):
  assert a < 0 and b < 0
  assert c > 0 and d > 0
  return True

def _target_function01(args, kwds, connection):
  return _inner_target_with_args_and_kwds(*args, **kwds)

def tst_args_kwds():
  ch = _callback_handler()
  p = process_with_callbacks(
    target = _target_function01,
    args   = (-2, -2),
    kwargs = {"c": 2, "d" : 2},
    callback_stdout = ch.cb_stdout,
    callback_final  = ch.cb_result,
    callback_err    = ch.cb_err,
    callback_other  = ch.cb_other)
  p.start()
  while p.is_alive():
    pass
  ch.tst_run_success(expected_result=True, expected_stdout=None,
    expected_other=None)

#--- test 02 : target function does not return a value
def _inner_target_no_return():
  n = 1

def _target_function02(args, kwds, connection):
  return _inner_target_no_return(*args, **kwds)

def tst_no_return_value():
  ch = _callback_handler()
  p = process_with_callbacks(
    target = _target_function02,
    callback_stdout = ch.cb_stdout,
    callback_final  = ch.cb_result,
    callback_err    = ch.cb_err,
    callback_other  = ch.cb_other)
  p.start()
  while p.is_alive():
    pass
  ch.tst_run_success(expected_result=None)

#--- test 03 : callbacks for stdout, runtime, result
def _target_function03(args, kwds, connection):
  for i in range(4):
    print(i)
    connection.send(i)
  return 4

def tst_callbacks():
  ch = _callback_handler()
  p = process_with_callbacks(
    target = _target_function03,
    callback_stdout = ch.cb_stdout,
    callback_final  = ch.cb_result,
    callback_err    = ch.cb_err,
    callback_other  = ch.cb_other)
  p.start()
  while p.is_alive():
    pass
  tstout = \
"""0
1
2
3
"""
  ch.tst_run_success(expected_result=4, expected_stdout=tstout,
    expected_other=[0,1,2,3])

#--- test 04 : stdout consistency
def _tst_print(out=None):
  if out is None :
    out = sys.stdout
  for i in range(1000):
    out.write("%s\n" % i)
  return None

def _target_function04(args, kwds, connection):
  return _tst_print(*args, **kwds)

def tst_stdout():
  tmpout = StringIO()
  _tst_print(tmpout)

  for buffer_stdout in [True, False] :
    ch = _callback_handler()
    p = process_with_callbacks(
      target = _target_function04,
      callback_stdout = ch.cb_stdout,
      buffer_stdout = buffer_stdout)
    p.start()
    while p.is_alive():
      pass
    assert tmpout.getvalue() == ch._stdout

#--- test 05 : propagating standard Exceptions and Sorry
def _target_function05a(args, kwds, connection):
  raise Exception("_target_function05a")

def _target_function05b(args, kwds, connection):
  raise Sorry("_target_function05b")

def tst_exceptions():
  for f in [_target_function05a, _target_function05b] :
    ch = _callback_handler()
    p = process_with_callbacks(
      target = f,
      callback_err = ch.cb_err,
      callback_final = ch.cb_result)
    p.start()
    while p.is_alive():
      pass
    ch.tst_error_raised()
    if f is _target_function05b :
      assert isinstance(ch._err, Sorry)

#--- test 06 : aborting
# Process.terminate() does not work on RedHat 8, but this test will still
# be successful despite taking an extra 100 seconds to finish.
def _target_function06(args, kwds, connection):
  for i in range(10):
    print(i)
    time.sleep(1)

def tst_abort_simple():
  ch = _callback_handler()
  p = process_with_callbacks(
    target = _target_function06,
    callback_abort = ch.cb_abort)
  p.start()
  p.abort()
  while p.is_alive():
    pass
  assert ch._abort == True

def _target_function07(args, kwds, connection):
  time.sleep(2)
  raise Abort()

def tst_abort_2():
  ch = _callback_handler()
  p = process_with_callbacks(
    target=_target_function07,
    callback_abort=ch.cb_abort)
  p.start()
  p.abort()
  while p.is_alive():
    pass
  assert ch._abort == True

def _target_function08(args, kwds, connection):
  import libtbx.callbacks # import dependency

  log = StringIO()
  libtbx.call_back.set_warning_log(log)
  time.sleep(1)
  libtbx.warn("Hello, world!")
  time.sleep(1)

def tst_warn_callback():
  ch = _callback_handler()
  p = process_with_callbacks(
    target=_target_function08,
    callback_other=ch.cb_other)
  p.start()
  while p.is_alive():
    pass
  assert (ch._other[0].message == "warn")
  assert (ch._other[0].data == "Hello, world!")

#--- pause, resume, and kill
def _target_function09(args, kwds, connection):
  for i in range(10):
    print(i)
    time.sleep(1)

class _callback_handler_2(object):
  def __init__(self):
    self.lines = ""
    self.paused = False
    self.resumed = False
    self.aborted = False

  def cb_print(self, data):
    self.lines += data

  def cb_pause(self):
    self.paused = True

  def cb_resume(self):
    self.resumed = True
    self.paused = False

  def cb_abort(self):
    self.aborted = True

def tst_pause_resume_kill():
  if (sys.platform == "win32"):
    print("Skipping pause/resume test (not available on Windows)")
  else :
    ch = _callback_handler_2()
    p = process_with_callbacks(
      target=_target_function09,
      callback_stdout=ch.cb_print,
      callback_pause=ch.cb_pause,
      callback_resume=ch.cb_resume,
      callback_abort=ch.cb_abort)
    p.start()
    time.sleep(1)
    p.pause()
    assert ch.paused
    current_data = str(ch.lines)
    time.sleep(5)
    assert (ch.lines == current_data)
    p.resume()
    assert ch.resumed
    while p.is_alive():
      pass
    assert not ch.aborted
    assert (ch.lines.splitlines() == ['0','1','2','3','4','5','6','7','8','9'])
  #return
  # kill test
  ch = _callback_handler_2()
  p = process_with_callbacks(
    target=_target_function09,
    callback_stdout=ch.cb_print,
    callback_pause=ch.cb_pause,
    callback_resume=ch.cb_resume,
    callback_abort=ch.cb_abort)
  p.start()
  time.sleep(3)
  p.kill()
  assert ch.aborted

def exercise_process():
  #--- run all tests
  try :
    tst_args_kwds()
    tst_no_return_value()
    tst_callbacks()
    tst_stdout()
    tst_exceptions()
    tst_abort_simple()
    tst_abort_2()
    tst_warn_callback()
    tst_pause_resume_kill()
  except ImportError as e:
    print("Skipping thread_utils tests:", str(e))
  else :
    print("OK")

if (__name__ == "__main__"):
  exercise_threading()
  exercise_process()


 *******************************************************************************


 *******************************************************************************
libtbx/tst_topological_sort.py
from __future__ import absolute_import, division, print_function
from six.moves import range
def exercise_specific():
  from libtbx.topological_sort import stable
  from libtbx.topological_sort import strongly_connected_components as scc
  connections = [
    ("a", ["b", "d"]),
    ("b", []),
    ("c", []),
    ("d", ["c"])]
  node_list = stable(connections=connections)
  assert node_list == ["b", "c", "d", "a"]
  assert scc(dict(connections)) == []
  assert scc(dict(connections), omit_single_node_components=False) \
      == [("b",), ("c",), ("d",), ("a",)]
  connections = [
    ("a", ["d", "b"]),
    ("b", []),
    ("c", []),
    ("d", ["c"])]
  node_list = stable(connections=connections)
  assert node_list == ["b", "c", "d", "a"]
  assert scc(dict(connections)) == []
  connections = [
    (0, [1]),
    (1, [2]),
    (2, [1,3]),
    (3, [3])]
  node_list = stable(connections=connections)
  assert node_list == [3,2,1,0]
  assert scc(dict(connections)) == [(1, 2)]
  connections = [
    ("a", ["d", "b", "e"]),
    ("b", []),
    ("c", []),
    ("d", ["c"])]
  node_list = stable(connections=connections)
  assert node_list == ["b", "c", "d", "e", "a"]
  assert scc(dict(connections)) == []
  #
  assert len(scc(
    successors_by_node={
      "node1": ["successor1", "successor2"],
      "node2": ["successor1", "successor3"]},
    omit_single_node_components=False)) == 5

def exercise_random(rng, n_nodes):
  # meant to discover endless loops or similar bugs
  connections = []
  for i_node in range(n_nodes):
    if (rng.randrange(10) > 7):
      continue
    n_del = max(int(n_nodes*0.6), rng.randrange(n_nodes))
    deps = list(range(n_nodes))
    for i_del in range(n_del):
      i = rng.randrange(len(deps))
      del deps[i]
    connections.append((i_node, deps))
  from libtbx.topological_sort import stable
  stable(connections=connections)
  #
  from libtbx.topological_sort import strongly_connected_components as scc
  from libtbx.topological_sort import find_path
  sbn = dict(connections)
  components = scc(successors_by_node=sbn)
  for component in components:
    for a in component:
      for b in component:
        path = find_path(successors_by_node=sbn, from_node=a, to_node=b)
        assert path is not None

def run(args):
  assert len(args) == 0
  exercise_specific()
  import random
  random.seed(0)
  for i_trial in range(10):
    exercise_random(rng=random, n_nodes=10)
  print("OK")

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/tst_utils.py
from __future__ import absolute_import, division, print_function
from libtbx import utils
from libtbx.test_utils import Exception_expected, approx_equal, show_diff
from six.moves import cStringIO as StringIO
import warnings
import random
import time
import os
import stat
import tempfile
from six.moves import range

def exercise_misc():
  utils.host_and_user().show(prefix="### ")
  time_in_seconds = 1.1
  for i_trial in range(55):
    time_in_seconds = time_in_seconds**1.1
    time_units, time_unit = utils.human_readable_time(
      time_in_seconds=time_in_seconds)
    assert approx_equal(
      utils.human_readable_time_as_seconds(time_units, time_unit),
      time_in_seconds)
  #
  fts = utils.format_timestamp
  f12 = utils.format_timestamp_12_hour
  f24 = utils.format_timestamp_24_hour
  def check(string, expected):
    assert len(string) == len(expected)
  check(f12(1280007000), 'Jul 24 2010 02:30 PM')
  check(f24(1280007000), 'Jul 24 2010 14:30')
  check(f12(1280007000, True), '24-07-10 02:30 PM')
  check(f24(1280007000, True), '24-07-10 14:30')
  check(fts(1280007000), 'Jul 24 2010 02:30 PM')
  #
  nfs = utils.number_from_string
  for string in ["True", "False"]:
    try: nfs(string=string)
    except ValueError as e:
      assert str(e) == 'Error interpreting "%s" as a numeric expression.' % (
        string)
    else: raise Exception_expected
  assert nfs(string="-42") == -42
  assert approx_equal(nfs(string="3.14"), 3.14)
  assert approx_equal(nfs(string="cos(0)"), 1)
  try: nfs(string="xxx(0)")
  except ValueError as e:
    assert str(e).startswith(
      'Error interpreting "xxx(0)" as a numeric expression: ')
  else: raise Exception_expected
  #
  s = "[0.143139, -0.125121, None, -0.308607]"
  assert numstr(values=eval(s)) == s
  #
  for s,i in {"2000000" : 2000000,
              "2k" : 2048,
              "2Kb" : 2048,
              "2 Kb" : 2048,
              "5Mb" : 5*1024*1024,
              "2.5Gb" : 2.5*1024*1024*1024,
              "1T": 1024*1024*1024*1024,
              10000 : 10000,
              5.5 : 5.5,
              }.items():
    assert utils.get_memory_from_string(s) == i
  #
  assert utils.tupleize(1) == (1,)
  assert utils.tupleize("abcde") == ('a', 'b', 'c', 'd', 'e')
  assert utils.tupleize([1,2,3]) == (1,2,3)
  #
  sf = utils.search_for
  assert sf(pattern="fox", mode="==", lines=["fox", "foxes"]) \
      == ["fox"]
  assert sf(pattern="o", mode="find", lines=["fox", "bird", "mouse"]) \
      == ["fox", "mouse"]
  assert sf(pattern="fox", mode="startswith", lines=["fox", "foxes"]) \
      == ["fox", "foxes"]
  assert sf(pattern="xes", mode="endswith", lines=["fox", "foxes"]) \
      == ["foxes"]
  assert sf(pattern="es$", mode="re.search", lines=["geese", "foxes"]) \
      == ["foxes"]
  assert sf(pattern="ge", mode="re.match", lines=["geese", "angel"]) \
      == ["geese"]
  #
  nd1d = utils.n_dim_index_from_one_dim
  for size in range(1,5):
    for i1d in range(size):
      assert nd1d(i1d=i1d, sizes=(size,)) == [i1d]
  for sizes in [(1,1), (1,3), (3,1), (2,3)]:
    ni, nj = sizes
    for i in range(ni):
      for j in range(nj):
        i1d = i*nj+j
        assert nd1d(i1d=i1d, sizes=sizes) == [i,j]
  for sizes in [(1,1,1), (1,3,1), (3,2,1), (4,3,2)]:
    ni, nj, nk = sizes
    for i in range(ni):
      for j in range(nj):
        for k in range(nk):
          i1d = (i*nj+j)*nk+k
          assert nd1d(i1d=i1d, sizes=sizes) == [i,j,k]
  #
  from libtbx import easy_run
  b = easy_run.fully_buffered(
    command="libtbx.raise_exception_for_testing")
  for lines in [b.stdout_lines, b.stderr_lines]:
    assert lines[0].startswith("EXCEPTION_INFO: show_stack(0): ")
    assert lines[-1] == "EXCEPTION_INFO: RuntimeError: Just for testing."
  b = easy_run.fully_buffered(
    command="libtbx.raise_exception_for_testing silent")
  b.raise_if_errors_or_output()
  #
  frange = utils.frange
  samples = utils.samples
  assert approx_equal([i/10. for i in range(-2,2)], frange(-0.2,0.2,0.1))
  assert approx_equal([i/10. for i in range(-2,2+1)], samples(-0.2,0.2,0.1))
  assert approx_equal([i/10. for i in range(2,-2,-1)], frange(0.2,-0.2,-0.1))
  assert approx_equal([i/10. for i in range(2,-2-1,-1)], samples(0.2,-0.2,-0.1))
  assert approx_equal([i/4. for i in range(4,8)], frange(1, 2, 0.25))
  assert approx_equal([i/4. for i in range(4,8+1)], samples(1, 2, 0.25))
  assert approx_equal([0.2+i/3. for i in range(4)], frange(0.2, 1.3, 1./3))
  assert approx_equal([0.2+i/3. for i in range(4)], samples(0.2, 1.3, 1./3))
  assert approx_equal(list(range(5)) , frange(5))
  assert approx_equal(list(range(5+1)) , samples(5))
  assert approx_equal(list(range(-5)), frange(-5))
  assert approx_equal(list(range(-5-1)), samples(-5))
  assert approx_equal(list(range(1,3)), frange(1, 3))
  assert approx_equal(list(range(1,3+1)), samples(1, 3))
  assert approx_equal([i/10. for i in range(20,9,-2)], frange(2.0,0.9,-0.2))
  assert approx_equal([i/10. for i in range(20,9,-2)], samples(2.0,0.9,-0.2))
  #
  ff = utils.format_float_with_standard_uncertainty
  assert ff(21.234567, 0.0013) == "21.2346(13)"
  assert ff(21.234567, 0.0023) == "21.235(2)"
  assert ff(12345, 45) == "12350(50)"
  assert ff(12.3,1.2) == "12.3(12)"
  assert ff(-0.2451, 0.8135) == "-0.2(8)"
  assert ff(1.234, 0.196) == "1.2(2)"
  assert ff(1.234, 0.193) == "1.23(19)"
  #
  for n in range(4):
    assert len(utils.random_hex_code(number_of_digits=n)) == n
  #
  print("multiprocessing problem:", utils.detect_multiprocessing_problem())
  #
  print("base36_timestamp():", utils.base36_timestamp(), "now")
  print("base36_timestamp():", utils.base36_timestamp(
    seconds_since_epoch=115855*365.2425*24*60*60), "year 115855 CE")
  #
  print("get_svn_revision():", utils.get_svn_revision())
  print("get_build_tag():", utils.get_build_tag())
  # concatenate_python_script
  # XXX the string concatenation here is required to trick libtbx.find_clutter,
  # which will warn about repetition of the future division import.
  script = """
from __future__ """ + """import division
import os.path

def foo():
  print "bar"
"""
  d = tempfile.mkdtemp()
  name = os.path.join(d, "tst_libtbx_utils_python_script.py")
  name2 = os.path.join(d, "tst_libtbx_utils_python_script2.py")
  with open(name, "w") as f:
    f.write(script)
  f = open(name2, "w")
  utils.concatenate_python_script(out=f, file_name=name)
  f.close()
  with open(name2) as f:
    lines = f.readlines()
  have_def = False
  for line in lines :
    assert (not "__future__" in line)
    if line.startswith("def foo"):
      have_def = True
  assert have_def

def exercise_user_plus_sys_time():
  s = StringIO()
  utils.user_plus_sys_time().show_elapsed(out=s, prefix="e: ")
  s = s.getvalue()
  assert s.startswith("e: ")
  assert s.endswith(" s")
  utils.user_plus_sys_time().show_delta(out=s, prefix="d: ")
  s = s.getvalue()
  assert s.startswith("d: ")
  assert s.endswith(" s")

def exercise_indented_display():
  out = StringIO()
  level0 = utils.buffered_indentor(file_object=out)
  print("level0", file=level0)
  level0.flush()
  level1 = level0.shift_right()
  print("level1", file=level1)
  level1.flush()
  assert out.getvalue() == ""
  level1.write_buffer()
  assert not show_diff(out.getvalue(), """\
level0
  level1
""")
  print("abc", end='', file=level1)
  level1.write_buffer()
  assert not show_diff(out.getvalue(), """\
level0
  level1
  abc""")
  print(file=level1)
  level1.write_buffer()
  assert not show_diff(out.getvalue(), """\
level0
  level1
  abc
""")
  print("def", end='', file=level1)
  level1.write_buffer()
  assert not show_diff(out.getvalue(), """\
level0
  level1
  abc
  def""")
  level1.write("")
  print("hij", file=level1)
  level1.write_buffer()
  assert not show_diff(out.getvalue(), """\
level0
  level1
  abc
  def hij
""")

def exercise_approx_equal():
  assert approx_equal(1., 1. + 1e-11)
  assert approx_equal(1+1j, 0.997+1.004j, eps=1e-2)
  assert approx_equal(1, 0.997+0.004j, eps=1e-2)
  assert approx_equal(1+0.003j, 0.997, eps=1e-2)
  assert approx_equal([ 2.5, 3.4+5.8j, 7.89],
                      [ 2.4+0.1j, 3.5+5.9j, 7.90], eps=0.2)

def exercise_file_utils():
  dir_name = tempfile.mkdtemp()
  if (not os.path.exists(dir_name)):
    os.mkdir(dir_name)
  sorted_files = []
  for prefix in ["XYZ", "abc", "qwerty", "123"] :
    file_name = os.path.join(dir_name, "%s.txt" % prefix)
    with open(file_name, "w") as f:
      f.write(prefix)
    sorted_files.append(file_name)
    time.sleep(1) # XXX the mtime resolution is in seconds :(
  f = open(os.path.join(dir_name, "hkl.log"), "w")
  f.write("hkl")
  f.close()
  file_names = utils.find_files(dir_name, pattern=".txt$")
  sorted_files_2 = utils.sort_files_by_mtime(file_names)
  assert (sorted_files_2 == sorted_files), '''
  Files not in correct order:
    %s
    %s
  ''' % (sorted_files_2, sorted_files)

def exercise_dir_utils():
  dirs = ["tst_utils_1", "tst_utils_2", "tst_utils_45"]
  for dir_name in dirs :
    if (os.path.isdir(dir_name)) : os.rmdir(dir_name)
  dir_name = utils.create_run_directory("tst_utils")
  assert (os.path.basename(dir_name) == "tst_utils_1")
  dir_name = utils.create_run_directory("tst_utils")
  assert (os.path.basename(dir_name) == "tst_utils_2")
  dir_name = utils.create_run_directory("tst_utils", 45)
  assert (os.path.basename(dir_name) == "tst_utils_45")
  for dir_name in dirs :
    os.rmdir(dir_name)
  file_name = "/cctbx/%s/%s/XXXX.pdb" % (random.random(), random.random())
  try :
    utils.check_if_output_directory_exists(file_name)
  except utils.Sorry :
    pass
  else :
    raise Exception_expected
  dir_name = os.getcwd()
  utils.check_if_output_directory_exists(dir_name=dir_name)
  dir_created = False
  if (not os.path.exists("Dropbox")):
    os.mkdir("Dropbox")
    dir_created = True
  dir_name = os.path.join(os.getcwd(), "Dropbox")
  with warnings.catch_warnings(record=True) as w:
    warnings.simplefilter("always")
    utils.check_if_output_directory_exists(dir_name=dir_name)
    assert len(w) == 1
    assert "Dropbox directory" in str(w[-1].message)
  if (dir_created):
    os.rmdir("Dropbox")
  host_info = utils.host_and_user()
  assert not utils.allow_delete_directory(host_info.homedir)
  target_dir = os.path.join(host_info.homedir, "Downloads")
  assert not utils.allow_delete_directory(target_dir)
  target_dir = os.path.join(host_info.homedir, "data", "lysozyme")
  assert utils.allow_delete_directory(target_dir)

def exercise_retrieve_unless_exists():
  from six.moves import urllib
  filehandle, filename = tempfile.mkstemp(prefix='kings_of_france')
  # we will need to pass filename to functions which will open it
  # on Windows this causes a permission exception
  os.close(filehandle)
  with open(filename, 'w') as f:
    f.write(
      'Henri IV, Louis XIII, Louis XIV, Louis XV, Louis XVI, Louis XVIII')
  digestname = os.path.join(os.path.dirname(f.name), 'digests.txt')
  with open(digestname, 'w') as f:
    f.writelines([
      ('%s %s\n') %
      (os.path.basename(filename), utils.md5_hexdigest(filename)),
      'something_else  yyyyyyy',
    ])
  os.chmod(digestname,
           os.stat(digestname).st_mode | stat.S_IWGRP | stat.S_IWOTH)
  d = tempfile.mkdtemp()
  targetname = os.path.join(d, 'target')
  try: os.remove(targetname)
  except Exception: pass
  url = 'file:' + urllib.request.pathname2url(filename)
  assert (utils.retrieve_unless_exists(url=url, filename=targetname) ==
          "Downloaded")
  with open(filename) as source, open(targetname) as target:
    assert source.read() == target.read()
  assert (utils.retrieve_unless_exists(url=url, filename=targetname) ==
          "Cached")
  with open(filename) as source, open(targetname) as target:
    assert source.read() == target.read()

def exercise_str_unicode():
  # tests for to_unicode and to_str
  s = '\xc3\x85'
  u = u'\xc5'
  assert(to_unicode(s) == u)
  assert(to_str(u) == s)

def exercise_group_args():
  from libtbx import group_args
  out = StringIO()
  a = group_args(
      a=1,
      b=2,
      c=3)
  assert a.a==1
  assert a.b==2
  assert a.c==3
  b = group_args(
      d = 'd',
      e = 'e')
  assert b.d=='d'
  assert b.e=='e'
  print(a, file=out)
  v = out.getvalue()
  assert not show_diff(v, """group_args
  a                              : 1
  b                              : 2
  c                              : 3\n""")
  a.merge(b)
  assert a.a==1
  assert a.b==2
  assert a.c==3
  assert a.d=='d'
  assert a.e=='e'
  assert b.d=='d'
  assert b.e=='e'
  c = group_args(
      a = 11,
      b = 12)
  a.merge(c)
  assert a.a==11
  assert a.b==12
  assert a.c==3
  assert c.a==11
  assert c.b==12
  #
  r = group_args(x=1)
  r.stop_dynamic_attributes()
  err = None
  try:
    r.w = 0
  except TypeError as e:
    err = e
  assert str(err) == "Dynamic attributes disabled."

def exercise_round2():
  assert(2 == int(utils.round2(1.5, 0)))
  assert(3 == int(utils.round2(2.5, 0)))
  assert(-2 == int(utils.round2(-1.5, 0)))
  assert(-3 == int(utils.round2(-2.5, 0)))
  assert approx_equal(0.2, utils.round2(0.15, 1))
  assert approx_equal(0.3, utils.round2(0.25, 1))
  assert approx_equal(-0.2, utils.round2(-0.15, 1))
  assert approx_equal(-0.3, utils.round2(-0.25, 1))

def exercise_guess_total_memory():
  assert(utils.guess_total_memory() > 0)

def exercise_display_context():
  text = """
   line with word1
   another line
   another line with word2
   another line with word1
   line with word3
"""
  from libtbx.utils import display_context
  text_block_list = display_context(text = text,
     n_context = 1, search_word = 'word1', quiet = True)
  assert [text_block_list[0].text_block] == [ '     \n  **    line with word1\n        another line\n']

  text_block_list = display_context(text = text,
     n_context = 1, search_word = 'word2', quiet = True)
  assert [text_block_list[0].text_block] == [ '        another line\n  **    another line with word2\n        another line with word1\n']

  text_block_list = display_context(text = text,
     n_context = 1, search_word = 'word2', required_word ='word1', quiet = True)
  assert [text_block_list[0].text_block] == [ '        another line\n  **    another line with word2\n        another line with word1\n']


def run(args):
  assert len(args) == 0
  if '--exercise-retrieve-unless-exists' in args:
    exercise_retrieve_unless_exists()
  else:
    print('Skipping exercise_retrieve_unless_exists')
  exercise_misc()
  assert utils.sequence_index_dict(["a", "b"]) == {"a": 0, "b": 1}
  assert utils.flat_list(0) == [0]
  assert utils.flat_list([1,2,3]) == [1,2,3]
  assert utils.flat_list([1,[2,3,4],3]) == [1,2,3,4,3]
  assert utils.flat_list([1,[2,3,4],[[3,4],[5,6]]]) == [1,2,3,4,3,4,5,6]
  try:
    raise RuntimeError("Trial")
  except KeyboardInterrupt: raise
  except Exception:
    assert utils.format_exception() == "RuntimeError: Trial"
  else: raise Exception_expected
  try:
    assert 1 == 2
  except KeyboardInterrupt: raise
  except Exception:
    s = utils.format_exception()
    assert s.startswith("AssertionError: ")
    assert s.find("tst_utils.py line ") >= 0
  else: raise Exception_expected
  exercise_indented_display()
  exercise_approx_equal()
  exercise_file_utils()
  exercise_dir_utils()
  exercise_group_args()
  exercise_round2()
  exercise_display_context()
  print(utils.format_cpu_times())

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/tst_version.py
from __future__ import absolute_import, division, print_function

from libtbx.version import get_version

# =============================================================================
def test_version():

  assert get_version() is not None
  assert get_version(filename='random_nonexisting_filename') is not None
  assert get_version(filename='random_nonexisting_filename', fail_with_none=True) is None

# =============================================================================
if __name__ == '__main__':
  test_version()

# =============================================================================
# end


 *******************************************************************************


 *******************************************************************************
libtbx/tst_word_index_generator.py
from __future__ import division

"""
Unit tests for word_index_generator (generate an index from html directories).
This module tests visible text extraction, word tokenization, filtering, and index building.
"""

import unittest
import os
import re

OK = True
try:
  from word_index_generator import get_visible_text, tokenize, build_word_index
  from collections import defaultdict
  from bs4 import BeautifulSoup
  from nltk.corpus import stopwords
  import nltk
  test = (BeautifulSoup, stopwords, nltk)
except Exception as e:
  OK = False


class TestWordIndexGenerator(unittest.TestCase):
    """
    Unit tests for the word index generator script.

    These tests verify the behavior of:
    - get_visible_text(): Ensuring hidden content is removed and visible content retained.
    - tokenize(): Splitting input strings into normalized words.
    - stopword and pattern filtering: Ignoring trivial or unwanted words.
    - Integration: Index generation from actual file content.
    """

    def test_visible_text_extraction(self):
        """
        Ensure get_visible_text() extracts only visible content,
        excluding scripts, styles, comments, and hidden elements.
        """
        html = '''<!DOCTYPE html>
        <html><head><style>h1{display:none;}</style></head>
        <body>
        <h1 style="display:none;">Hidden Title</h1>
        <h2>Visible Heading</h2>
        <script>console.log('hi')</script>
        <p>This is a <b>test</b> page.</p>
        </body></html>'''
        visible = get_visible_text(html)
        self.assertIn("Visible Heading", visible)
        self.assertIn("This is a test page.", visible)
        self.assertNotIn("Hidden Title", visible)
        self.assertNotIn("console.log", visible)

    def test_tokenize_words(self):
        """
        Ensure tokenize() splits text into lowercase words,
        stripping out punctuation and handling alphanumerics.
        """
        text = "This is a test: only_words-123 _should be tokenized."
        tokens = tokenize(text)
        self.assertIn("this", tokens)
        self.assertIn("only_words", tokens)
        self.assertIn("123", tokens)
        self.assertNotIn(":", tokens)

    def test_exclusion_filtering(self):
        """
        Ensure filtering logic excludes stopwords, underscores,
        digits, and excluded patterns.
        """
        stop_words = {"this", "is", "a"}
        exclude_pattern = re.compile(r'^[a-zA-Z][0-9_]')
        sample_files = {"/tmp/sample.html"}
        word_index = defaultdict(set)
        words = ["this", "word", "x1", "_private", "z_test", "keepme"]
        for word in words:
            if (
                word not in stop_words and
                len(word) > 2 and
                not word[0].isdigit() and
                not word.startswith("_") and
                not exclude_pattern.match(word)
            ):
                word_index[word].update(sample_files)

        self.assertIn("word", word_index)
        self.assertIn("keepme", word_index)
        self.assertNotIn("this", word_index)
        self.assertNotIn("x1", word_index)
        self.assertNotIn("_private", word_index)
        self.assertNotIn("z_test", word_index)

    def test_build_word_index_from_sample_html(self):
        """
        Full integration test: index a small HTML file and validate words and filtering.
        """
        sample_dir = "test_html"
        os.makedirs(sample_dir, exist_ok=True)
        sample_path = os.path.join(sample_dir, "sample.html")
        with open(sample_path, "w", encoding="utf-8") as f:
            f.write("<html><body><p>Hello world from unittest!</p></body></html>")

        stop_words = {"from"}
        exclude_pattern = re.compile(r'^[a-zA-Z][0-9_]')
        word_index = build_word_index(sample_dir, stop_words, exclude_pattern, index_dir="index_files")

        self.assertIn("hello", word_index)
        self.assertIn("world", word_index)
        self.assertNotIn("from", word_index)

        os.remove(sample_path)
        os.rmdir(sample_dir)

if __name__ == '__main__':
  if OK:
    unittest.main()
  else:
    print("Skipping unit tests (requires nltk beautifulsoup4)")


 *******************************************************************************


 *******************************************************************************
libtbx/tst_xmlrpc_utils.py
from __future__ import absolute_import, division, print_function

from six.moves import cStringIO as StringIO

import os, time
import libtbx.load_env
from libtbx import xmlrpc_utils

def exercise():
  ext_module = libtbx.env.find_in_repositories(
    relative_path="libtbx/xmlrpc_server_example.py",
    test=os.path.isfile)
  full_cmd = "libtbx.python %s" % ext_module
  log = StringIO()
  server = xmlrpc_utils.external_program_server(command=full_cmd,
                                                program_id="TEST",
                                                timeout=None,
                                                cache_requests=True,
                                                log=log)
  server.echo_test()
  time.sleep(1)
  run_server_tests(server)
  port = server.get_port()
  assert log.getvalue() == """XML-RPC server started on port %d
hello, world!
hello, world!
quitting
""" % port
  server.restart()
  time.sleep(1)
  run_server_tests(server)
  print("OK")

def run_server_tests(server):
  assert server.echo_test() == True
  assert server.is_alive() == True
  server.quit()
  assert server.is_alive() == False
  assert server.echo_test() is None

if __name__ == "__main__" :
  exercise()


 *******************************************************************************


 *******************************************************************************
libtbx/utils.py
from __future__ import absolute_import, division, print_function

import atexit
import glob
import hashlib
import math
import os
import re
import shutil
import sys
import time
import traceback
import warnings

from six.moves import cStringIO as StringIO

from libtbx.queuing_system_utils import pbs_utils, sge_utils
from libtbx.math_utils import round2
from libtbx.str_utils import show_string
from six.moves import range
from six.moves import zip
from six.moves import input

try: import gzip
except ImportError: gzip = None
try: import bz2
except ImportError: bz2 = None

hashlib_md5 = hashlib.md5

op = os.path

windows_device_names = """\
CON PRN AUX NUL COM1 COM2 COM3 COM4 COM5 COM6 COM7 COM8 COM9
LPT1 LPT2 LPT3 LPT4 LPT5 LPT6 LPT7 LPT8 LPT9""".split()

def xfrange(start, stop=None, step=None, tolerance=None):
  """
  A float range generator.

  Parameters
  ----------
  start : float
  stop : float, optional
      If empty, start at 0 and stop at the start parameter.
  step : float, optional
  tolerance : float, optional

  Returns
  -------
  generator of float
  """

  if stop is None:
    stop = start + 0.0
    start = 0.0
  else:
    start += 0.0 # force it to be a float
  if step is None:
    step = 1.0
  else:
    assert step != 0.0
  count = int(math.ceil((stop - start) / step))
  if (    tolerance is not None
      and abs(start + count * step - stop) < abs(step * tolerance)):
    count += 1
  for i in range(count):
    yield start + i * step

def safe_div(a,b):
  if abs(b) < 1e-8:
    return 0
  else:
    return a/b

def frange(start, stop=None, step=None):
  """
  Non-generator version of xfrange.

  Parameters
  ----------
  start : float
  stop : float, optional
      If empty, start at 0 and stop at the start parameter.
  step : float, optional

  Returns
  -------
  list of float

  See Also
  --------
  libtbx.utils.xfrange
  """
  return list(xfrange(start, stop=stop, step=step))

def xsamples(start, stop=None, step=None, tolerance=1e-6):
  """
  Wraps xfrange, acts identically.

  Parameters
  ----------
  start : float
  stop : float, optional
      If empty, start at 0 and stop at the start parameter.
  step : float, optional
  tolerance : float, optional

  Returns
  -------
  generator of float

  See Also
  --------
  libtbx.utils.xfrange
  """
  return xfrange(start, stop, step, tolerance)

def samples(start, stop=None, step=None, tolerance=1e-6):
  """
  Non-generator version of xsamples.

  Parameters
  ----------
  start : float
  stop : float, optional
      If empty, start at 0 and stop at the start parameter.
  step : float, optional
  tolerance : float, optional

  Returns
  -------
  list of float

  See Also
  --------
  libtbx.utils.xfrange, libtbx.utils.xsamples
  """
  return list(xsamples(start, stop, step, tolerance))

def escape_sh_double_quoted(s):
  """
  The result is supposed to be double-quoted when passed to sh.
  """
  if (s is None): return None
  return s.replace('\\','\\\\').replace('"','\\"')

def xlen(seq):
  """
  Returns the length of a sequence or None.

  Parameters
  ----------
  seq : iterable or None

  Returns
  -------
  int or None
  """
  if (seq is None): return seq
  return len(seq)

def product(seq):
  """
  Calculates the result of multiplying all elements of a sequence together.

  Parameters
  ----------
  seq : iterable
  """
  result = None
  for val in seq:
    if (result is None):
      result = val
    else:
      result *= val
  return result

def sequence_index_dict(seq, must_be_unique=True):
  """
  Builds a dictionary for each element in seq mapped to its index in the sequence.

  Parameters
  ----------
  seq : iterable of object
  must_be_unique : bool, optional

  Returns
  -------
  dict of object, int

  Examples
  --------
  >>> libtbx.utils.sequence_index_dict(['a', 'b'])
  {'a': 0, 'b': 1}
  """
  result = {}
  for i, elem in enumerate(seq):
    if must_be_unique:
      assert elem not in result
    result[elem] = i
  return result

def number_from_string(string):
  """
  Tries to covert a string into an integer, using builtin int() as well as eval().

  Parameters
  ----------
  string : str

  Returns
  -------
  int

  Raises
  ------
  ValueError
      If string cannot be converted into an integer.
  """
  # similar to libtbx.phil.number_from_value_string
  # (please review if making changes here)
  if (string.lower() in ["true", "false"]):
    raise ValueError(
      'Error interpreting "%s" as a numeric expression.' % string)
  try: return int(string)
  except ValueError: pass
  try: return eval(string, math.__dict__, {})
  except KeyboardInterrupt: raise
  except Exception:
    raise ValueError(
      'Error interpreting "%s" as a numeric expression: %s' % (
        string, format_exception()))

def gzip_open(file_name, mode):
  """
  Wraps gzip.open to open a .gz file.

  Parameters
  ----------
  file_name : str
  mode : str

  Returns
  -------
  file

  Raises
  ------
  RuntimeError
      If gzip is not available.
  """
  assert mode in ["r", "rb", "rt", "w", "wb", "wt", "a", "ab"]
  if (gzip is None):
    un = ""
    if (mode[0] == "r"): un = "un"
    raise RuntimeError(
      "gzip module not available: cannot %scompress file %s"
        % (un, show_string(file_name)))
  return gzip.open(file_name, mode)

def bz2_open(file_name, mode):
  """
  Wraps bz2.open to open a .bz2 file.

  Parameters
  ----------
  file_name : str
  mode : str

  Returns
  -------
  file

  Raises
  ------
  RuntimeError
      If bz2 is not available.
  """
  assert mode in ('r', 'w')
  if bz2 is None:
    raise RuntimeError('bz2 module not available: cannot %compress file %s'
                       % ({'r':'un', 'w':''}[mode], file_name))
  return bz2.BZ2File(file_name, mode)

def warn_if_unexpected_md5_hexdigest(
      path,
      expected_md5_hexdigests,
      hints=[],
      out=None):
  """
  Checks the md5 hash of a file to see if it matches the expected hash.

  Parameters
  ----------
  path : str
  expected_md5_hexdigests : list of str
  hints : list of str, optional
  out : file, optional

  Returns
  -------
  bool
      False if md5 hash of file does not appear in expected_md5_hexdigests.
  """
  m = hashlib.md5()
  m.update("\n".join(open(path).read().splitlines()).encode('utf-8'))
  current_md5_hexdigest = m.hexdigest()
  if (m.hexdigest() in expected_md5_hexdigests): return False
  warning = "Warning: unexpected md5 hexdigest:"
  file_name = "  File: %s" % show_string(path)
  new_hexdigest = "  New md5 hexdigest: %s" % m.hexdigest()
  width = max([len(s) for s in [warning, file_name, new_hexdigest]])
  if (out is None): out = sys.stdout
  print("*"*width, file=out)
  print(warning, file=out)
  print(file_name, file=out)
  print(new_hexdigest, file=out)
  for hint in hints:
    print(hint, file=out)
  print("*"*width, file=out)
  return True

def md5_hexdigest(filename=None, blocksize=256):
  """ Compute the MD5 hexdigest of the content of the given file,
      efficiently even for files much larger than the available RAM.

      The file is read by chunks of `blocksize` MB.
  """
  blocksize *= 1024**2
  m = hashlib.md5()
  with open(filename, 'rb') as f:
    buf = f.read(blocksize)
    while buf:
      m.update(buf)
      buf = f.read(blocksize)
  return m.hexdigest()

def get_memory_from_string(mem_str):
  """
  Converts a string of a memory or file size (i.e. "10G") into a number.

  Parameters
  ----------
  mem_str : int or float

  Returns
  -------
  int or float

  Examples
  --------
  >>> libtbx.utils.get_memory_from_string("10G")
  10737418240.0
  >>> libtbx.utils.get_memory_from_string("10M")
  10485760.0

  Raises
  ------
  RuntimeError
  """
  if type(mem_str) in [type(1), type(1.)]: return mem_str
  mem_str = mem_str.replace(" ","").strip().upper()
  if mem_str == "": return 0
  factor=1024
  for i, greek in enumerate(["K","M","G","T","E","Z","Y"]):
    num_str=None
    if mem_str[-1]==greek:
      num_str = mem_str[:-1]
    if mem_str.find("%sB" % greek)==len(mem_str)-2:
      num_str = mem_str[:-2]
    if num_str is not None:
      try:
        num = float(num_str)
      except ValueError:
        raise RuntimeError("""
   The numerical portion of %s is not a valid float
""" % mem_str)
      break
    factor*=1024
  else:
    try:
      num = int(mem_str)
    except ValueError:
      raise RuntimeError("""
   There is no memory unit or valid float in %s
""" % mem_str)
    factor=1
  return num*factor

def getenv_bool(variable_name, default=False):
  """
  Checks the environment variables for variable, returning it as a boolean.

  Parameters
  ----------
  variable_name : str
  default : bool, optional
      Returned if variable_name is not found.

  Returns
  -------
  bool
  """
  value = os.environ.get(variable_name, None)
  if (value is None): return default
  value_lower = value.lower()
  if (value_lower not in ["false", "true", "0", "1"]):
    raise Sorry(
      'Environment variable %s must be "True", "False", "0", or "1"'
      ' (current value: "%s").' % (variable_name, value))
  return (value_lower in ["true", "1"])

def file_size(file_name):
  """
  Wraps os.stat to calculate a file's size.

  Parameters
  ----------
  file_name : str

  Returns
  -------
  int : size of file, in bytes
  """
  return os.stat(file_name).st_size

def copy_file(source, target, compress=None):
  """
  Copies a file from source to target, optionally compressing it before writing
  it out.

  Parameters
  ----------
  source : str
  target : str
  compress : str, optional
      The compression algorithm to use. Currently only ".gz" is supported. If
      set, target becomes target + compress.
  """
  assert op.isfile(source)
  if (op.isdir(target)):
    target = op.join(target, op.basename(source))
  if (compress is None):
    t = open(target, "wb")
  else:
    assert compress == ".gz"
    t = gzip_open(file_name=target+compress, mode="wb")
  with open(source, "rb") as f:
    t.write(f.read())
  t.close()

def remove_files(pattern=None, paths=None, ensure_success=True):
  """
  Removes a file from disk.

  Parameters
  ----------
  pattern : str, optional
  paths : iterable of str, optional
  ensure_success : bool, optional
  """
  assert [pattern, paths].count(None) == 1
  if (paths is None):
    paths = glob.glob(pattern)
  for path in paths:
    if (ensure_success):
      if (op.exists(path)):
        os.remove(path)
        if (op.exists(path)):
          raise RuntimeError("Cannot remove file: %s" % show_string(path))
    else:
      if (op.isfile(path)):
        os.remove(path)

def find_files(dir_name, pattern="*", files_only=True):
  """
  Find files matching a pattern in a directory.

  Parameters
  ----------
  dir_name : str
  pattern: str, optional
  files_only : bool, optional

  Returns
  -------
  list of str
  """
  assert os.path.isdir(dir_name) and (pattern is not None)
  regex = re.compile(pattern)
  files = os.listdir(dir_name)
  matching_files = []
  for file_name in files :
    full_path = os.path.join(dir_name, file_name)
    if (files_only) and (not os.path.isfile(full_path)):
      continue
    if (regex.search(file_name) is not None):
      matching_files.append(full_path)
  return matching_files

def sort_files_by_mtime(file_names=None, dir_name=None, reverse=False):
  """
  Sorts a list of file names by when they were last modified, ascending.

  Parameters
  ----------
  file_names : iterable of str, optional
  dir_name : str, optional
  reverse : bool, optional

  Returns
  -------
  list of str
  """
  assert ([file_names, dir_name].count(None) == 1)
  if (dir_name is not None):
    assert os.path.isdir(dir_name)
    file_names = [ os.path.join(dir_name, fn) for fn in os.listdir(dir_name) ]
  files_and_mtimes = []
  for file_name in file_names :
    files_and_mtimes.append((file_name, os.path.getmtime(file_name)))
  files_and_mtimes.sort(key=lambda x: x[1])
  if (reverse):
    files_and_mtimes.reverse()
  return [ file_name for file_name, mtime in files_and_mtimes ]

def tupleize(x):
  """
  Coverts x into a tuple, either as a direct cast or by making it the sole
  element of a tuple.

  Parameters
  ----------
  x : object

  Returns
  -------
  tuple
  """
  try:
    return tuple(x)
  except TypeError:
    return (x,)

def plural_s(n, suffix="s"):
  """
  Returns a suffix if n != 1.

  Parameters
  ----------
  n : int
  suffix : str, optional

  Returns
  -------
  int
  str
  """
  if (n == 1): return n, ""
  return n, suffix

def n_dim_index_from_one_dim(i1d, sizes):
  assert len(sizes) > 0
  result = []
  for sz in reversed(sizes):
    assert sz > 0
    result.append(i1d % sz)
    i1d //= sz
  result.reverse()
  return result

def flat_list(nested_list):
  result = []
  if (hasattr(nested_list, "__len__")):
    for sub_list in nested_list:
      result.extend(flat_list(sub_list))
  else:
    result.append(nested_list)
  return result

def select_matching(key, choices, default=None):
  """
  Selects a value from choices where its key pattern matches key.

  Parameters
  ----------
  key : str
  choices : iterable of str, object
  default : object, optional
      Returned if no pattern matches key.

  Returns
  -------
  object
  """
  for key_pattern, value in choices:
    m = re.search(key_pattern, key)
    if m is not None: return value
  return default

class KeepType(object):
  def __str__(self):
    return "Keep"
  def __repr__(self):
    return "Keep"
  def __eq__(self, other):
    return isinstance(other, self.__class__)
  def __ne__(self, other):
    return not self.__eq__(other)
  def __hash__(self):
    return hash(KeepType) # return the same hash value for all instances

Keep = KeepType()

class Sorry(Exception):
  """
  Basic exception type for user errors; the traceback will be suppressed.
  """
  __orig_module__ = __module__
  # trick to get just "Sorry" instead of "libtbx.utils.Sorry"
  __module__ = Exception.__module__

  def reset_module(self):
    """
    Reset the class module on an instance to libtbx.utils.
    """
    self.__class__.__module__ = self.__class__.__orig_module__

disable_tracebacklimit = "LIBTBX_DISABLE_TRACEBACKLIMIT" in os.environ

__prev_excepthook = sys.excepthook

def sorry_excepthook(type, value, traceback):
  """
  Intercepts exception tracebacks, removing tracebacks for Sorry exceptions.

  Parameters
  ----------
  type : type
  value : Exception
  traceback : traceback

  Returns
  -------
  str
  """
  tb_off = (not disable_tracebacklimit and isinstance(value, Sorry))
  if (tb_off):
    class __not_set(object): pass
    prev_tracebacklimit = getattr(sys, "tracebacklimit", __not_set)
    sys.tracebacklimit = 0
  result = __prev_excepthook(type, value, traceback)
  if (tb_off):
    if (prev_tracebacklimit is __not_set):
      del sys.tracebacklimit
    else:
      sys.tracebacklimit = prev_tracebacklimit
  return result

sys.excepthook = sorry_excepthook

class Usage(Sorry):
  """
  Subclass of Sorry, for printing out usage instructions upon program
  invocation without arguments (or --help, etc.).
  """
  __module__ = Exception.__module__

class Abort(Sorry):
  """
  Subclass of Sorry, primarily used in the Phenix GUI in response to user
  input.
  """
  __module__ = Exception.__module__

class Failure(Sorry):
  """
  Subclass of Sorry.
  """
  __module__ = Exception.__module__

def kludge_show_to_str(obj):
  """
  Take an object which has a show method which we shall assume will by default
  write it's output to stdout - capture this with cStringIO and return the
  string. Allows objects which have show() but not __repr__ or __str__ methods
  to add without much code changes.

  Returns
  -------
  str - output

  Raises
  ------
  AttrbuteError if object does not have callable show() method
  """

  out = StringIO()

  stdout = sys.stdout
  sys.stdout = out

  try:
    obj.show()
  finally:
    sys.stdout = stdout

  return out.getvalue().rstrip()

def detect_multiprocessing_problem():
  """
  Checks python and library versions and availability to diagnose why
  multiprocessing fails to work.

  Returns
  -------
  str or None
      String indicating why multiprocessing is not working.
  """
  vers_info = sys.version_info[:2]
  if (vers_info < (2,6)):
    return "multiprocessing module not available:" \
      " Python 2.6 or higher is required" \
      " (version currently in use: %d.%d)" % vers_info
  import libtbx.load_env
  if (libtbx.env.has_module("omptbx")):
    import omptbx
    if (omptbx.omp_version is not None):
      return "multiprocessing is not compatible with OpenMP"
  sem_open_msg = "This platform lacks a functioning sem_open implementation"
  pool = None
  try:
    try:
      import multiprocessing
      pool = multiprocessing.Pool(processes=2)
      pool.map(func=abs, iterable=range(2), chunksize=1)
    except ImportError as e:
      if (not str(e).startswith(sem_open_msg)):
        raise
      return "multiprocessing import error: " + sem_open_msg
  finally:
    if (pool is not None):
      pool.close()
      pool.join()
  return None

def if_none(value, default):
  """
  Returns value or default if value is None.
  """
  if (value is None): return default
  return value

def format_exception():
  """
  Formats an Exception object...
  """
  ei = sys.exc_info()
  type_ = ei[0].__name__
  value = str(ei[1])
  if (value != ""):
    value = value.replace(" (<string>, line ", " (line ")
  else:
    file_name, line = traceback.extract_tb(sys.exc_info()[2], 1)[0][:2]
    if (file_name is not None):
      value = file_name+" "
    if (line is not None):
      value += "line %d" % line
  return ("%s: %s" % (type_, value)).rstrip()

def show_exception_info_if_full_testing(prefix="EXCEPTION_INFO: "):
  """
  Shows information about an exception.

  Parameters
  ----------
  prefix : str, optional

  Returns
  -------
  str or None
  """
  import libtbx.load_env
  if (    not libtbx.env.full_testing
      and not disable_tracebacklimit):
    return
  from libtbx import introspection
  from six.moves import cStringIO as StringIO
  sio = StringIO()
  introspection.show_stack(out=sio)
  traceback.print_exc(file=sio)
  msg = "\n".join([prefix+line for line in sio.getvalue().splitlines()]) + "\n"
  del sio
  done = []
  for out in [sys.stdout, sys.stderr, sys.__stdout__, sys.__stderr__]:
    def is_done():
      for o in done:
        if (o is out): return True
      return False
    if (is_done()): continue
    out.write(msg)
    flush = getattr(out, "flush", None)
    if (flush is not None):
      try:
        flush()
      except Exception as e:
        pass # can happen if stale file handle
    done.append(out)
  return msg

def base36_encode(integer, width=None):
  """
  Encodes integer as a string in base 36, prepending 0's until string is of
  length equal to width.

  Parameters
  ----------
  integer : int
  width : int, optional

  Returns
  -------
  str
  """
  digit_set = "0123456789abcdefghijklmnopqrstuvwxyz"
  digits = []
  while (integer != 0):
    integer, i = divmod(integer, 36)
    digits.append(digit_set[i])
  if (width is not None):
    while (len(digits) < width):
      digits.append("0")
  digits.reverse()
  return "".join(digits)

def base36_timestamp(seconds_since_epoch=None, multiplier=1000, width=10):
  """
  Encodes the number of seconds since the epoch in base 36.

  Parameters
  ----------
  seconds_since_epoch : time, optional
  multiplier : int, optional
  width : int, optional
  """
  s = seconds_since_epoch
  if (s is None):
    s = time.time()
  return base36_encode(integer=int(s * multiplier + 0.5), width=width)

def date_and_time():
  """
  Converts the current time into a string.

  Returns
  -------
  str
  """
  seconds_since_epoch = time.time()
  localtime = time.localtime(seconds_since_epoch)
  if (time.daylight and localtime[8] != 0):
    tzname = time.tzname[1]
    offs = -time.altzone
  else:
    tzname = time.tzname[0]
    offs = -time.timezone
  return time.strftime("Date %Y-%m-%d Time %H:%M:%S", localtime) \
       + " %s %+03d%02d (%.2f s)" % (
           tzname, offs//3600, offs//60%60, seconds_since_epoch)

class timer_base(object):
  """
  Base timer class used to calculate the time elapsed by various operations.
  """

  def __init__(self):
    self.t = self.get()

  def elapsed(self):
    """
    Returns the time elapsed since object was initialized.

    Returns
    -------
    time
    """
    t = self.get()
    d = t - self.t
    return d

  def delta(self):
    """
    Returns time since last call of delta().

    Returns
    -------
    time
    """
    t = self.get()
    d = t - self.t
    self.t = t
    return d

  def show_elapsed(self, prefix="", out=None):
    """
    Prints the time since object was initialized.

    Parameters
    ----------
    prefix : str, optional
    out : file, optional
    """
    if (out == None): out = sys.stdout
    print(prefix+"%.2f s" % self.elapsed(), file=out)

  def show_delta(self, prefix="", out=None):
    """
    Prints the time since last call of delta() or show_delta().

    Parameters
    ----------
    prefix : str, optional
    out : file, optional
    """
    if (out == None): out = sys.stdout
    print(prefix+"%.2f s" % self.delta(), file=out)


class user_plus_sys_time(timer_base):
  """
  Timer class using os.times() to calculate time. Subclasses timer_base.

  Methods
  -------
  get
  """

  def get(self):
    """
    Uses os.times() to calculate the time.
    """
    t = os.times()
    return t[0] + t[1]

class wall_clock_time(timer_base):
  """
  Timer class using time.time() to calculate time. Subclasses timer_base.

  Methods
  -------
  get

  Notes
  -----
  When running multithreaded code, user_plus_sys_time would report the cumulated
  times for all threads: not very useful to analyse the scaling with the number
  of threads! Wall clock time, although it is less reliable is the only solution
  in that case.
  """

  def get(self):
    """
    Uses time.time() to calculate the time.
    """
    return time.time()

class time_log(object):
  """
  Class used to log the time that tasks take.
  """

  def __init__(self, label, use_wall_clock=False):
    self.label = label
    self.use_wall_clock = use_wall_clock
    self.accumulation = 0
    self.n = 0
    self.delta = 0
    self.timer = None

  def start(self):
    """
    Starts the timer.
    """
    if (self.use_wall_clock):
      self.timer = wall_clock_time()
    else:
      self.timer = user_plus_sys_time()
    return self

  def stop(self):
    """
    Stops the timer.
    """
    self.delta = self.timer.delta()
    self.timer = None
    self.accumulation += self.delta
    self.n += 1

  def average(self):
    """
    Calculates the average length for runs of the timer.

    Returns
    -------
    float
    """
    return self.accumulation / max(1, self.n)

  def log(self):
    """
    Stops the timer and runs its report method.
    """
    self.stop()
    return self.report()

  def log_elapsed(self, local_label):
    """
    Returns a string displaying the time elapsed since the timer was started.

    Parameters
    ----------
    local_label : str
        String appended to the end of the output

    Returns
    -------
    str
    """
    return "time_log: %s: %.2f elapsed %s" % (
      self.label, self.timer.elapsed(), local_label)

  legend = "time_log: label: n accumulation delta average"

  def report(self):
    """
    Returns a string including the label, number of stops, accumulated time,
    delta time, and average time for runs of timer.

    Returns
    -------
    str
    """
    assert self.timer is None
    return "time_log: %s: %d %.2f %.3g %.3g" % (
      self.label, self.n, self.accumulation,
      self.delta, self.average())

def human_readable_time(time_in_seconds):
  """
  Rounds a time in seconds to the nearest days / hours / minutes, depending on
  what unit is appropriate.

  Parameters
  ----------
  time_in_seconds : int
      Time, in seconds.

  Returns
  -------
  int : The rounded time in some unit.
  str : The accompanying units for the time.
  """
  time_units = time_in_seconds
  time_unit = "seconds"
  if (time_units > 120):
    time_units /= 60
    time_unit = "minutes"
    if (time_units > 120):
      time_units /= 60
      time_unit = "hours"
      if (time_units > 48):
        time_units /= 24
        time_unit = "days"
  return time_units, time_unit

def human_readable_time_as_seconds(time_units, time_unit):
  """
  Converts time_units and time_unit back into a time with units of seconds.

  Parameters
  ----------
  time_units : int
  time_unit : str

  Returns
  -------
  int
  """
  if (isinstance(time_units, str)): time_units = float(time_units)
  if (time_unit == "seconds"): return time_units
  if (time_unit == "minutes"): return time_units*60
  if (time_unit == "hours"): return time_units*60*60
  if (time_unit == "days"): return time_units*60*60*24
  raise RuntimeError("Unknown time_unit: %s" % time_unit)

def format_timestamp_12_hour(unix_time, short=False, replace_with="unknown"):
  """
  Formats a unix_time in a 12-hour format.

  Parameters
  ----------
  unix_time : time
  short : bool, optional
  replace_with : str, optional
      Returned when unix_time is None.

  Returns
  -------
  str
  """
  if unix_time is None :
    return replace_with
  elif short :
    return time.strftime("%d-%m-%y %I:%M %p", time.localtime(float(unix_time)))
  else :
    return time.strftime("%b %d %Y %I:%M %p", time.localtime(float(unix_time)))

def format_timestamp_24_hour(unix_time, short=False, replace_with="unknown"):
  """
  Formats a unix_time in a 24-hour format.

  Parameters
  ----------
  unix_time : time
  short : bool, optional
  replace_with : str, optional
      Returned when unix_time is None.

  Returns
  -------
  str
  """
  if unix_time is None :
    return "unknown"
  elif short :
    return time.strftime("%d-%m-%y %H:%M", time.localtime(float(unix_time)))
  else :
    return time.strftime("%b %d %Y %H:%M", time.localtime(float(unix_time)))

format_timestamp = format_timestamp_12_hour

def format_cpu_times(show_micro_seconds_per_tick=True):
  t = os.times()
  result = "u+s,u,s: %.2f %.2f %.2f" % (t[0] + t[1], t[0], t[1])
  if (show_micro_seconds_per_tick):
    try: python_ticker = sys.gettickeraccumulation()
    except AttributeError: pass
    else:
      result += " micro-seconds/tick: %.3f" % ((t[0]+t[1])/python_ticker*1.e6)
  return result

def show_total_time(
      out=None,
      show_micro_seconds_per_bytecode_instruction=True):
  """
  Prints the total CPU time and average time for each Python bytecode
  instruction since the process was started.

  Parameters
  ----------
  out : file, optional
  show_micro_seconds_per_bytecode_instruction : bool, optional
  """
  if (out == None): out = sys.stdout
  total_time = user_plus_sys_time().get()
  try: python_ticker = sys.gettickeraccumulation()
  except AttributeError: pass
  else:
    print("Time per interpreted Python bytecode instruction:", end=' ', file=out)
    print("%.3f micro seconds" % (total_time / python_ticker * 1.e6), file=out)
  print("Total CPU time: %.2f %s" % human_readable_time(total_time), file=out)

def show_wall_clock_time(seconds, out=None):
  """
  Prints seconds in a human-readable format.

  Parameters
  ----------
  seconds : float
  out : file, optional

  Examples
  --------
  >>> show_wall_clock_time(750)
  wall clock time: 12 minutes 30.00 seconds (750.00 seconds total)
  >>> show_wall_clock_time(20)
  wall clock time: 20.00 seconds
  """
  if (out is None): out = sys.stdout
  print("wall clock time:", end=' ', file=out)
  if (seconds < 120):
    print("%.2f seconds" % seconds, file=out)
  else:
    m = int(seconds / 60 + 1.e-6)
    s = seconds - m * 60
    print("%d minutes %.2f seconds (%.2f seconds total)" % (
      m, s, seconds), file=out)
  out_flush = getattr(out, "flush", None)
  if (out_flush is not None):
    out_flush()

class show_times:
  """
  Class to track the time past an instance's initialization.
  """

  def __init__(self, time_start=None, out=None):
    """
    Parameters
    ----------
    time_start : time or str, optional
    out : file, optional
    """
    if (time_start is None):
      t = os.times()
      self.time_start = time.time() - (t[0] + t[1])
    elif (time_start == "now"):
      self.time_start = time.time()
    else:
      self.time_start = -(0-time_start) # be sure time_start is a number
    self.out = out

  def __call__(self):
    out = self.out
    if (out is None): out = sys.stdout
    t = os.times()
    usr_plus_sys = t[0] + t[1]
    try: ticks = sys.gettickeraccumulation()
    except AttributeError: ticks = None
    s = "usr+sys time: %.2f seconds" % usr_plus_sys
    if (ticks is not None):
      s += ", ticks: %d" % ticks
      if (ticks != 0):
        s += ", micro-seconds/tick: %.3f" % (usr_plus_sys*1.e6/ticks)
    print(s, file=out)
    show_wall_clock_time(seconds=time.time()-self.time_start, out=out)

def show_times_at_exit(time_start=None, out=None):
  """
  Shows the time since time_start at exit.

  Parameters
  ----------
  time_start : time, optional
  out : file, optional

  See Also
  --------
  libtbx.utils.show_times
  """
  atexit.register(show_times(time_start=time_start, out=out))

class host_and_user:

  def __init__(self):
    self.host = os.environ.get("HOST")
    self.hostname = os.environ.get("HOSTNAME")
    self.computername = os.environ.get("COMPUTERNAME")
    self.hosttype = os.environ.get("HOSTTYPE")
    self.processor_architecture = os.environ.get("PROCESSOR_ARCHITECTURE")
    self.machtype = os.environ.get("MACHTYPE")
    self.ostype = os.environ.get("OSTYPE")
    self.vendor = os.environ.get("VENDOR")
    self.user = os.environ.get("USER")
    self.username = os.environ.get("USERNAME")
    self.homedir = None
    if (os.name == "nt"):
      homedrive = os.environ.get("HOMEDRIVE")
      homepath = os.environ.get("HOMEPATH")
      if (not None in [homedrive, homepath]):
        self.homedir = os.path.join(homedrive, homepath)
    else :
      self.homedir = os.environ.get("HOME")
    getpid = getattr(os, "getpid", None)
    if (getpid is None):
      self.pid = None
    else:
      self.pid = getpid()
    self.sge_info = sge_utils.info()
    self.pbs_info = pbs_utils.chunk_info()

  def get_user_name(self):
    if (self.user is not None):
      return self.user
    else :
      return self.username

  def get_host_name(self):
    if (self.host is not None):
      return self.host
    elif (self.hostname is not None):
      return self.hostname
    elif (self.computername is not None):
      return self.computername
    return None

  def show(self, out=None, prefix=""):
    if (out is None): out = sys.stdout
    if (self.host is not None):
      print(prefix + "HOST =", self.host, file=out)
    if (    self.hostname is not None
        and self.hostname != self.host):
      print(prefix + "HOSTNAME =", self.hostname, file=out)
    if (    self.computername is not None
        and self.computername != self.host):
      print(prefix + "COMPUTERNAME =", self.computername, file=out)
    if (self.hosttype is not None):
      print(prefix + "HOSTTYPE =", self.hosttype, file=out)
    if (self.processor_architecture is not None):
      print(prefix + "PROCESSOR_ARCHITECTURE =", \
        self.processor_architecture, file=out)
    if (   self.hosttype is None
        or self.machtype is None
        or self.ostype is None
        or "-".join([self.machtype, self.ostype]) != self.hosttype):
      if (self.machtype is not None):
        print(prefix + "MACHTYPE =", \
          self.machtype, file=out)
      if (self.ostype is not None):
        print(prefix + "OSTYPE =", \
          self.ostype, file=out)
    if (self.vendor is not None and self.vendor != "unknown"):
      print(prefix + "VENDOR =", \
        self.vendor, file=out)
    if (self.user is not None):
      print(prefix + "USER =", self.user, file=out)
    if (    self.username is not None
        and self.username != self.user):
      print(prefix + "USERNAME =", self.username, file=out)
    if (self.pid is not None):
      print(prefix + "PID =", self.pid, file=out)
    self.sge_info.show(out=out, prefix=prefix)
    self.pbs_info.show(out=out, prefix=prefix)

def allow_delete_directory(target_dir):
  """
  Check for specified reserved directories which are standard on many systems;
  these should never be deleted as part of any program.

  Parameters
  ----------
  target_dir : str

  Returns
  -------
  bool
  """
  homedir = host_and_user().homedir
  safe_dirs = [
    homedir,
    os.path.join(homedir, "Documents"),
    os.path.join(homedir, "Desktop"),
    os.path.join(homedir, "Downloads"),
    os.path.join(homedir, "Library"),
    os.path.join(homedir, "Movies"),
    os.path.join(homedir, "data"),
    "/",
    "/home",
    "/Users",
  ]
  target_dir = os.path.abspath(target_dir)
  for safe_dir in safe_dirs :
    if (target_dir == safe_dir):
      return False
  return True

def _indentor_write_loop(write_method, indent, incomplete_line, lines):
  for line in lines:
    if (len(line) == 0):
      incomplete_line = False
    elif (incomplete_line):
      write_method(line)
      incomplete_line = False
    else:
      write_method(indent)
      write_method(line)
    write_method("\n")

class indentor(object):

  def __init__(self, file_object=None, indent="", parent=None):
    if (file_object is None):
      if (parent is None):
        file_object = sys.stdout
      else:
        file_object = parent.file_object
    self.file_object = file_object
    if (hasattr(self.file_object, "flush")):
      self.flush = self._flush
    self.indent = indent
    self.parent = parent
    self.incomplete_line = False

  def write(self, block):
    if (len(block) == 0): return
    if (block.endswith("\n")):
      _indentor_write_loop(
        write_method=self.file_object.write,
        indent=self.indent,
        incomplete_line=self.incomplete_line,
        lines=block.splitlines())
      self.incomplete_line = False
    else:
      lines = block.splitlines()
      if (len(lines) == 1):
        if (self.incomplete_line):
          self.file_object.write(' ')
          self.file_object.write(lines[-1])
        else:
          self.file_object.write(self.indent + lines[-1])
      else:
        _indentor_write_loop(
          write_method=self.file_object.write,
          indent=self.indent,
          incomplete_line=self.incomplete_line,
          lines=lines[:-1])
        self.file_object.write(self.indent + lines[-1])
      self.incomplete_line = True

  def _flush(self):
    self.file_object.flush()

  def shift_right(self, indent="  "):
    return self.__class__(indent=self.indent+indent, parent=self)

class buffered_indentor(indentor):

  def __init__(self, file_object=None, indent="", parent=None):
    indentor.__init__(self, file_object, indent, parent)
    self.buffer = []

  def write(self, block):
    self.buffer.append(block)

  def write_buffer(self):
    if (self.parent is not None):
      self.parent.write_buffer()
    for block in self.buffer:
      indentor.write(self, block)
    self.buffer = []

class null_out(object):
  """
  Pseudo-filehandle for suppressing printed output.
  """

  def isatty(self): return False
  def close(self): pass
  def flush(self): pass
  def write(self, str): pass
  def writelines(self, sequence): pass

class raise_if_output(object):
  """
  Raises an exception when written to.

  Examples
  --------
  >>> import sys
  >>> sys.stdout = libtbx.utils.raise_if_output()
  >>> print
  RuntimeError
  """

  def isatty(self):
    return False

  def close(self):
    pass

  def flush(self):
    pass

  def write(self, str):
    """
    Raises
    ------
    RuntimeError
    """
    raise RuntimeError
  def writelines(self, sequence):
    """
    Raises
    ------
    RuntimeError
    """
    raise RuntimeError

class multi_out(object):
  """
  Multiplexing output stream, e.g. for simultaneously printing to stdout
  and a logfile.
  """

  def __init__(self):
    self.labels = []
    self.file_objects = []
    self.atexit_send_to = []
    self.closed = False
    self.softspace = 0
    atexit.register(self._atexit)

  def _atexit(self):
    if (not self.closed):
      for f,a in zip(self.file_objects, self.atexit_send_to):
        if (a is not None): a.write(f.getvalue())

  def register(self, label, file_object, atexit_send_to=None):
    """
    Adds an output stream to the list.

    Parameters
    ----------
    label : str
        Label for replacing the stream later
    file_object : file
    atexit_send_to : file, optional
    """
    assert not self.closed
    self.labels.append(label)
    self.file_objects.append(file_object)
    self.atexit_send_to.append(atexit_send_to)
    return self

  def replace_stringio(self,
        old_label,
        new_label,
        new_file_object,
        new_atexit_send_to=None,
        close_old_stream=True):
    """
    Replaces a registered stream with a new file. Dumps everything accumulated
    in stream to the file.
    Useful when at the time of init of this object file name is not known.
    Allows to use StringIO buffer to accumulate output and then dump it to
    file and continue with it.

    Parameters
    ----------
    old_label : str
    new_label : str
    new_file_object : file
    new_atexit_send_to : file, optional
    close_old_stream :  bool, close existing stream
    """
    i = self.labels.index(old_label)
    old_file_object = self.file_objects[i]
    if hasattr(old_file_object, 'getvalue'):
      new_file_object.write(old_file_object.getvalue())
    if close_old_stream:
      old_file_object.close()
    self.labels[i] = new_label
    self.file_objects[i] = new_file_object
    self.atexit_send_to[i] = new_atexit_send_to

  def isatty(self):
    return False

  def close(self):
    for file_object in self.file_objects:
      if (file_object is sys.__stdout__): continue
      if (file_object is sys.__stderr__): continue
      file_object.close()
    self.closed = True

  def flush(self):
    for file_object in self.file_objects:
      flush = getattr(file_object, "flush", None)
      if (flush is not None):
        try:
          flush()
        except Exception as e:
          pass # was closed

  def write(self, str):
    for file_object in self.file_objects:
      file_object.write(str)

  def writelines(self, sequence):
    for file_object in self.file_objects:
      file_object.writelines(sequence)

def write_this_is_auto_generated(f, file_name_generator):
  """
  Writes a C header to a file indicating it was generated automatically.

  Parameters
  ----------
  f : file
  file_name_generator : str
      Name of source generator.
  """
  print("""\
/* *****************************************************
   THIS IS AN AUTOMATICALLY GENERATED FILE. DO NOT EDIT.
   *****************************************************

   Generated by:
     %s
 */
""" % file_name_generator, file=f)

class import_python_object:

  def __init__(self, import_path, error_prefix, target_must_be, where_str):
    path_elements = import_path.split(".")
    if (len(path_elements) < 2):
      raise ValueError(
        '%simport path "%s" is too short%s%s' % (
          error_prefix, import_path, target_must_be, where_str))
    module_path = ".".join(path_elements[:-1])
    try: module = __import__(module_path)
    except ImportError:
      raise ImportError("%sno module %s%s or possibly import errors in "
      "module %s" % (
        error_prefix, module_path, where_str, module_path))
    for attr in path_elements[1:-1]:
      module = getattr(module, attr)
    try: self.object = getattr(module, path_elements[-1])
    except AttributeError:
      raise AttributeError(
        '%sobject "%s" not found in module "%s"%s' % (
          error_prefix, path_elements[-1], module_path, where_str))
    self.path_elements = path_elements
    self.module_path = module_path
    self.module = module

class input_with_prompt(object):

  def __init__(self, prompt, tracebacklimit=0):
    try: import readline
    except Exception: pass
    try: self.previous_tracebacklimit = sys.tracebacklimit
    except Exception: self.previous_tracebacklimit = None
    if (tracebacklimit is not None):
      sys.tracebacklimit = tracebacklimit
    self.input = input(prompt)

  def __del__(self):
    if (self.previous_tracebacklimit is None):
      del sys.tracebacklimit
    else:
      sys.tracebacklimit = self.previous_tracebacklimit

def count_max(assert_less_than):
  """
  Counts the number of times its generator is called, raising an exception if
  called too many times.

  Parameters
  ----------
  assert_less_than : int

  Returns
  -------
  generator of None

  Raises
  ------
  AssertionError
      If .next() is called more than assert_less_than on the generator.
  """
  i = 0
  while True:
    yield None
    i += 1
    assert i < assert_less_than

class detect_binary_file(object):

  def __init__(self, monitor_initial=None, max_fraction_non_ascii=None):
    if (monitor_initial is None):
      self.monitor_initial = 1000
    else:
      self.monitor_initial = monitor_initial
    if (max_fraction_non_ascii is None):
      self.max_fraction_non_ascii = 0.05
    else:
      self.max_fraction_non_ascii = max_fraction_non_ascii
    self.n_ascii_characters = 0
    self.n_non_ascii_characters = 0
    self.status = None

  def is_binary_file(self, block):
    if (self.monitor_initial > 0):
      if block and not isinstance(block[0], int):
        block = (ord(c) for c in block)
      for c in block:
        if (1 < c < 128):
          self.n_ascii_characters += 1
        else:
          self.n_non_ascii_characters += 1
        self.monitor_initial -= 1
        if (self.monitor_initial == 0):
          if (  self.n_non_ascii_characters
              > self.n_ascii_characters * self.max_fraction_non_ascii):
            self.status = True
          else:
            self.status = False
          break
    return self.status

  @staticmethod
  def from_initial_block(
        file_name,
        monitor_initial=None,
        max_fraction_non_ascii=None):
    detector = detect_binary_file(
      monitor_initial=monitor_initial,
      max_fraction_non_ascii=max_fraction_non_ascii)
    with open(file_name, "rb") as fh:
      block = fh.read(detector.monitor_initial)
    if not block:
      return False
    detector.monitor_initial = min(len(block), detector.monitor_initial)
    return detector.is_binary_file(block=block)

def search_for(
      pattern,
      mode,
      re_flags=0,
      lines=None,
      file_name=None):
  """
  Searches for a pattern in a file's contents.

  Parameters
  ----------
  pattern : str
  mode : str
      One of "==", "find", "startswith", "endswith", "re.search", "re.match"
  re_flags : int, optional
  lines : iterable of str, optional
  file_name : str, optional
  """
  assert mode in ["==", "find", "startswith", "endswith", "re.search", "re.match"]
  assert [lines, file_name].count(None) == 1
  if (lines is None):
    lines = open(file_name).read().splitlines()
  result = []
  a = result.append
  if (mode == "=="):
    for l in lines:
      if (l == pattern): a(l)
  elif (mode == "startswith"):
    for l in lines:
      if (l.startswith(pattern)): a(l)
  elif (mode == "endswith"):
    for l in lines:
      if (l.endswith(pattern)): a(l)
  elif (mode == "find"):
    for l in lines:
      if (l.find(pattern) >= 0): a(l)
  elif (mode == "re.search"):
    import re
    for l in lines:
      if (re.search(pattern=pattern, string=l, flags=re_flags) is not None):
        a(l)
  else:
    import re
    for l in lines:
      if (re.match(pattern=pattern, string=l, flags=re_flags) is not None):
        a(l)
  return result

class progress_displayed_as_fraction(object):

  def __init__(self, n):
    self.n = n
    self.i = 0
    if self.n == 1: self.advance = lambda: None
    self.advance()

  def advance(self):
    if self.i > 0: sys.stdout.write('\r')
    sys.stdout.write("%i / %i" % (self.i, self.n))
    sys.stdout.flush()
    self.i += 1

  def done(self):
    if self.n == 1: return
    sys.stdout.write("\n")
    sys.stdout.flush()


class progress_bar(progress_displayed_as_fraction):

  def advance(self):
    characters = ['|']
    if self.i > 0:
      characters.extend(['=']*(self.i-1))
      characters.append('>')
    characters.extend(' '*(self.n - self.i))
    characters.append('|\r')
    sys.stdout.write(''.join(characters))
    sys.stdout.flush()
    self.i += 1

def format_float_with_standard_uncertainty(value, standard_uncertainty,
                                           minimum=1e-15):
  """
  Formats a float, including the uncertainty in its value.

  Parameters
  ----------
  value : float
  standard_uncertainty : float
  minimum : float

  Returns
  -------
  str

  Examples
  --------
  >>> libtbx.utils.format_float_with_standard_uncertainty(5e-3, 1e-3)
  '0.0050(10)'
  >>> libtbx.utils.format_float_with_standard_uncertainty(5e-3, 1e-6)
  '0.0050000(10)'
  """
  if standard_uncertainty <= minimum: return str(value)
  precision = -int(round2(math.log10(standard_uncertainty)))
  if precision > -1:
    su = standard_uncertainty * math.pow(10, precision)
    if round2(su,1) < 2:
      su *= 10
      precision += 1
    fmt_str = "%%.%if(%%i)" %precision
    return fmt_str %(value, round2(su))
  else:
    precision += 1
    su = int(round2(standard_uncertainty, precision))
    fmt_str = "%.0f(%i)"
    return fmt_str %(round2(value, precision), su)

def random_hex_code(number_of_digits):
  """
  Creates a random string of hex characters.

  Parameters
  ----------
  number_of_digits : int

  Returns
  -------
  str
  """
  import random
  digits = []
  for i_digit in range(number_of_digits):
    i = random.randrange(16)
    digits.append("0123456789abcdef"[i])
  return "".join(digits)

def get_svn_revision(path=None):
  # adapted from:
  #   http://code.djangoproject.com/browser/django/trunk/django/utils/version.py
  rev = None
  if path is None:
    import libtbx.load_env
    path = op.dirname(libtbx.env.dist_path(module_name="libtbx"))
  entries_path = '%s/.svn/entries' % path
  try:
    entries = open(entries_path, 'r').read()
  except IOError:
    pass
  else:
    # Versions >= 7 of the entries file are flat text.  The first line is
    # the version number. The next set of digits after 'dir' is the revision.
    if re.match(r'(\d+)', entries):
      rev_match = re.search(r'\d+\s+dir\s+(\d+)', entries)
      if rev_match:
        rev = int(rev_match.groups()[0])
  return rev

def get_build_tag(path=None):
  """
  Returns the build tag for libtbx.

  Parameters
  ----------
  path : str, optional

  Returns
  -------
  str
  """
  tag = None
  if path is None:
    import libtbx.load_env
    path = op.dirname(libtbx.env.dist_path(module_name="libtbx"))
  tag_file_path = "%s/TAG" %path
  if op.exists(tag_file_path):
    tag = open(tag_file_path).readline().strip()
  return tag

def getcwd_safe():
  """
  Returns the current working directory, raising Sorry if it has been deleted or
  unmounted.

  Returns
  -------
  str

  Raises
  ------
  Sorry
      If the current working directory has been deleted or unmounted.
  """
  try :
    cwd = os.getcwd()
  except OSError as e :
    if (e.errno == 2):
      raise Sorry("Could not determine the current working directory because "+
        "it has been deleted or unmounted.")
    else :
      raise e
  return cwd

def getcwd_or_default(default=None):
  """
  Returns the current working directory or default if it cannot be found.

  Parameters
  ----------
  default : str, optional

  Returns
  -------
  str
  """
  if (default is None):
    if (os.name == "nt"):
      home_drive = os.environ.get("HOMEDRIVE", "C:")
      home_dir = os.environ.get("HOMEPATH", "\\")
      default = home_drive + home_dir
    else :
      default = os.environ.get("HOME", "/")
  try :
    cwd = os.getcwd()
  except OSError as e:
    if (e.errno == 2):
      cwd = default
    else :
      raise e
  return cwd

def create_run_directory(prefix, default_directory_number=None):
  """
  Create a program output directory using sequential numbering, picking the
  highest run ID.  In other words, if the prefix is 'Refine' and the current
  directory contains subdirectories named Refine_2 and Refine_9, the new
  directory will be Refine_10.
  """
  dir_number = default_directory_number
  if (dir_number is None):
    dir_ids = []
    for file_name in os.listdir(os.getcwd()):
      if (os.path.isdir(file_name)) and (file_name.startswith(prefix)):
        dir_id = file_name.split("_")[-1]
        if (dir_id.isdigit()):
          dir_ids.append(int(dir_id))
    if (len(dir_ids) > 0):
      dir_number = max(max(dir_ids) + 1, 1)
    else :
      dir_number = 1
  dir_name = prefix + "_" + str(dir_number)
  if (os.path.isdir(dir_name)):
    raise OSError("The directory %s already exists."%os.path.abspath(dir_name))
  else :
    os.makedirs(dir_name)
  return os.path.abspath(dir_name)

class tmp_dir_wrapper(object):
  """
  Convenience methods for running in a (presumably empty) temporary directory
  and copying all files to another directory.  Can be used whether or not the
  temporary directory is actually defined; if None, no action will be taken.
  Otherwise, both tmp_dir and dest_dir (default is current directory) must be
  existing paths.
  """
  def __init__(self, tmp_dir, dest_dir=None, out=sys.stdout):
    if (dest_dir is None):
      dest_dir = os.getcwd()
    self.tmp_dir = tmp_dir
    self.dest_dir = dest_dir
    if (tmp_dir is None):
      pass
    elif (not os.path.isdir(tmp_dir)):
      raise Sorry("The temporary directory %s does not exist." % tmp_dir)
    else :
      if (not os.path.isdir(dest_dir)):
        raise Sorry("The destination directory %s does not exist." % dest_dir)
      print("Changing working directory to %s" % tmp_dir, file=out)
      print("Ultimate destination is %s" % dest_dir, file=out)
      os.chdir(tmp_dir)

  def transfer_files(self, out=sys.stdout):
    if (self.tmp_dir is None) : return False
    assert os.path.isdir(self.dest_dir)
    files = os.listdir(self.tmp_dir)
    print("Copying all output files to %s" % self.dest_dir, file=out)
    for file_name in files :
      print("  ... %s" % file_name, file=out)
      shutil.copy(os.path.join(self.tmp_dir, file_name), self.dest_dir)
    print("", file=out)
    return True

def show_development_warning(out=sys.stdout):
  """
  Shows a warning when running an experimental program.

  Parameters
  ----------
  out : file, optional
  """
  print("""
  !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  !!                  WARNING - EXPERIMENTAL PROGRAM                        !!
  !!                                                                        !!
  !! This program is still in development - some functionality may be       !!
  !! missing and/or untested.  Use at your own risk!  For bug reports, etc. !!
  !! email help@phenix-online.org.                                          !!
  !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
""", file=out)

def check_if_output_directory_exists(file_name=None, dir_name=None):
  if (file_name is not None):
    assert (dir_name is None)
    dir_name = os.path.dirname(file_name)
  if (dir_name == "") : return
  if (dir_name is None):
    raise Sorry("No output directory specified.")
  if (not op.isdir(dir_name)):
    raise Sorry(("The specified output directory (%s) does not exist or "+
      "is not a directory.") % dir_name)
  else :
    # XXX writing to Dropbox folders is generally not a good idea
    head, tail = os.path.split(dir_name)
    while tail != "" :
      if (tail == "Dropbox"):
        warnings.warn("You are directing output to a Dropbox directory.  "+
          "Please note that this is not guaranteed to work in all cases; "+
          "use at your own risk.", UserWarning)
      head, tail = os.path.split(head)

def concatenate_python_script(out, file_name):
  """
  Insert a Python script into an existing file, removing any __future__
  import to prevent syntax errors.  (This could be dangerous in most contexts
  but is required for some of our Coot-related scripts to work.)
  """
  with open(file_name, "r") as f:
    data = f.read()
  print("", file=out)
  print("#--- script copied from %s" % os.path.basename(file_name), file=out)
  for line in data.splitlines():
    if line.startswith("from __future__"):
      continue
    else :
      print(line, file=out)
  print("#--- end", file=out)
  print("", file=out)

def greek_time(secs):
  """
  Converts seconds into its closest form in greek units.

  Parameters
  ----------
  secs : float

  Returns
  -------
  float
  str

  Examples
  --------
  >>> libtbx.utils.greek_time(1e-3)
  (1, "milli")
  >>> libtbx.utils.greek_time(1e-6)
  (1, "micro")
  """
  for greek in ["","milli", "micro", "nano"]:
    if secs>1:
      break
    secs*=1000
  return secs, greek

###########################
# URL retrieval functions #
###########################

libtbx_urllib_proxy = None

def install_urllib_http_proxy(server, port=80, user=None, password=None):
  global libtbx_urllib_proxy
  from six.moves import urllib
  if (user is None):
    proxy = urllib.request.ProxyHandler({'http': '%s:%d' % (server, port) })
    opener = urllib.request.build_opener(proxy)
  else :
    proxy = urllib.request.ProxyHandler({
      'http': 'http://%s:%s@%s:%s' % (user, password, server, port),
    })
    auth = urllib.request.HTTPBasicAuthHandler()
    opener = urllib.request.build_opener(proxy, auth, urllib.request.HTTPHandler)
  libtbx_urllib_proxy = proxy
  urllib.request.install_opener(opener)
  print("Installed urllib proxy at %s:%d" % (server, port))
  return proxy

def urlopen(*args, **kwds):
  """
  Substitute for urllib.request.urlopen, with automatic HTTP proxy configuration
  if specific environment variables are defined.
  """
  if ("CCTBX_HTTP_PROXY" in os.environ) and (libtbx_urllib_proxy is None):
    server = os.environ["CCTBX_HTTP_PROXY_SERVER"]
    port = os.environ.get("CCTBX_HTTP_PROXY_PORT", 80)
    user = os.environ.get("CCTBX_HTTP_PROXY_USER", None)
    passwd = os.environ.get("CCTBX_HTTP_PROXY_PASSWORD", None)
    if (user is not None) and (password is None):
      raise Sorry("You have defined a user name for the HTTP proxy, but "+
        "no password was specified.  Please set the environment variable "+
        "CCTBX_HTTP_PROXY_PASSWORD.")
    install_urllib_http_proxy(
      server=server,
      port=port,
      user=user,
      password=password)
  from six.moves import urllib
  return urllib.request.urlopen(*args, **kwds)

def retrieve_unless_exists(url, filename, digests=None):
  """ Download the file at the given url to the given local filename,
      unless that file is already here. This is asserted by computed a digest
      and comparing it to the entries in the file at the url digests. The latter
      shall have the following format:

      some-file.txt      xxxxxxxxxx
      another-file.txt   yyyyyyyyyy

      If url is ..../some-file.txt, then the expected digest is xxxxxxxxxx.

      If digests is None, then the url of the digest file is expected to be
      named 'digests.txt' and to be next to the downloaded file.
  """
  import urlparse
  from os import path
  from six.moves import urllib
  if digests is None:
    digests = urlparse.urljoin(url, 'digests.txt')
  digest_of = dict(tuple(li.split()) for li in urllib.request.urlopen(digests))
  src_name = os.path.basename(urlparse.urlparse(url).path)
  if (not os.path.isfile(filename)
      or md5_hexdigest(filename) != digest_of[src_name]):
    urllib.request.urlretrieve(url, filename)
    return "Downloaded"
  else:
    return "Cached"




class download_progress(object):
  """
  Simple proxy for displaying download status - here with methods for
  writing to the console, but can be subclassed and used for graphical display.
  """
  def __init__(self, log=None, n_kb_total=None):
    if (log is None):
      log = null_out()
    self.log = log
    self.n_kb_total = n_kb_total
    self.n_kb_elapsed = 0

  def set_total_size(self, n_kb_total):
    """
    Updates the total number of bytes to download and resets the number of bytes
    downloaded.

    Parameters
    ----------
    n_kb_total : int
        Total size of download, in kilobytes.
    """
    self.n_kb_total = n_kb_total
    self.n_kb_elapsed = 0

  def increment(self, n_kb):
    """
    Increments the number of bytes downloaded.

    Parameters
    ----------
    n_kb : int

    Returns
    -------
    bool
    """
    assert (self.n_kb_total is not None)
    self.n_kb_elapsed += n_kb
    return self.show_progress()

  def show_progress(self):
    """
    Prints the number of bytes downloaded out of the total.

    Returns
    -------
    bool
    """
    self.log.write("\r%d/%d KB downloaded" % (self.n_kb_elapsed,
      self.n_kb_total))
    self.log.flush()
    return True

  def percent_finished(self):
    """
    Calculates the percent completion of download.

    Returns
    -------
    float
    """
    assert (self.n_kb_total is not None)
    return 100 * min(1.0, self.n_kb_elapsed / self.n_kb_total)

  def complete(self):
    """
    Prints a final message indicating download completion.
    """
    self.log.write("\rDownload complete")

  def run_continuously(self):
    """
    Placeholder for cases where the download is not being run asynchronously.
    """
    pass

class download_target(object):
  """
  Flexible callable object for retrieving a file from a URL, with optional
  HTTPS authentication.  Designed to be runnable in a separate thread with
  graphical progress update.

  Note that in some circumstances SSL support may be missing from the socket
  module, in which case we use 'curl' to download securely.  (This will not
  work on Windows, obviously.)
  """
  def __init__(self,
      url,
      file_name,
      use_curl=None, # SSL only
      user=None, # SSL only
      password=None, # SSL only
      base_url=None) :  # SSL only
    self.url = url
    self.file_name = file_name
    self.use_curl = use_curl
    self.user = user
    self.password = password
    self.base_url = base_url
    if (not None in [self.user, self.password]):
      assert (self.base_url is not None)
      import socket
      if ((not self.use_curl) and (hasattr(socket, "ssl")) and
          (hasattr(socket.ssl, "__call__"))):
        self.use_curl = False
      else :
        self.use_curl = True

  def __call__(self, log=None, progress_meter=None):
    if (log is None):
      log = null_out()
    if (progress_meter is None):
      progress_meter = download_progress(log=log)
    from libtbx import easy_run
    from six.moves import urllib
    file_name = self.file_name # return value
    if (not self.use_curl):
      if (not None in [self.user, self.password]):
        passman = urllib.request.HTTPPasswordMgrWithDefaultRealm()
        passman.add_password(None, self.base_url, self.user, self.password)
        authhandler = urllib.request.HTTPBasicAuthHandler(passman)
        opener = urllib.request.build_opener(authhandler)
        urllib.request.install_opener(opener)
      req = urllib.request.urlopen(self.url)
      info = req.info()
      n_kb_total = int(info['Content-length']) / 1024
      progress_meter.set_total_size(n_kb_total)
      # TODO adjust chunk size automatically based on download speed
      n_kb_chunk = getattr(self, "n_kb_chunk", 512)
      chunksize = n_kb_chunk * 1024
      fp = open(self.file_name, 'wb')
      while True:
        chunk = req.read(chunksize)
        if not chunk: break
        if not progress_meter.increment(n_kb_chunk):
          file_name = None
          break
        fp.write(chunk)
      fp.close()
      progress_meter.complete()
    else :
      progress_meter.run_continuously()
      if (not None in [self.user, self.password]):
        curl_args = "--user %s:%s" % (self.user, self.password)
      rc = easy_run.call("curl %s \"%s\" -o %s" % (curl_args, self.url,
        self.file_name))
      progress_meter.complete()
      if (rc != 0):
        raise RuntimeError("curl exited with code %d" % rc)
    if (file_name is None):
      return None
    return op.abspath(self.file_name)

def cmd_exists(cmd):
  """
  Test whether a command is available by checking the return code from
  subprocess.call
  """
  import subprocess
  return subprocess.call("type " + cmd,
                         shell=True,
                         stdout=subprocess.PIPE,
                         stderr=subprocess.PIPE) == 0

def remove_path(path_name):
  """
  Bypasses trash and deletes file or directory immediately.
  """
  try:
    if op.isdir(path_name):
      shutil.rmtree(path_name)
    elif op.isfile(path_name):
      os.remove(path_name)
    else:
      raise Sorry('%s is not a file nor a directory.' % path_name)
  except OSError:
    raise Sorry('Unable to delete %s.' % path_name)

def try_send_to_trash(path_name, delete_if_not_available=False,
                       delete_immediately=False):
  """
  Wrapper for deleting a path
  """
  if (delete_immediately):
    remove_path(path_name)
  else:
    try :
      import send2trash
    except ImportError :
      if delete_if_not_available :
        warnings.warn("send2trash not available; will delete path instead.",
          ImportWarning)
        remove_path(path_name)
      else :
        raise Sorry("This function not supported because the required module is "+
          "not installed.")
    else :
      try:
        send2trash.send2trash(path_name)
      except Exception as e:
        print("Unable to send the directory %s to trash" %(path_name))
        return 1 # indicate failure

if sys.hexversion >= 0x03000000:
  unicode = str

def to_unicode(text, codec=None, errors='replace'):
  '''
  Function for handling text when it is first encountered

  Changes bytestring type (str or bytes in Python 2, bytes in Python 3) to
  text string type (unicode in Python 2, str in Python 3)

  The input is returned unmodified if it is already a text string
  Will convert other types (e.g. int, float) to text string
  None is returned as None, not as u'None'

  For Linux/OS X, the default filesystem encoding is utf8.
  For Windows, the default filesystem encoding is mbcs.
  This is important for handling files with basic Python functions
  With the wrong encoding, the filesystem will not recognize the file path
  import sys; sys.getfilesystemencoding()
  '''

  if (codec is None):
    codec = 'utf8'
    if (sys.platform == 'win32'):
      codec = 'mbcs'

  if (isinstance(text, unicode)):
    return text
  elif (isinstance(text, bytes)):
    new_text = text
    try:
      new_text = text.decode(codec, errors)
    except UnicodeDecodeError: # in case errors='strict'
      raise Sorry('Unable to decode text with %s' % codec)
    finally:
      return new_text
  elif (text is not None):
    return unicode(text)
  else:
    return None

def to_bytes(text, codec=None, errors='replace'):
  '''
  Function for handling text when it is passed to cctbx functions that expect
  bytestrings

  Changes text string type (unicode in Python 2, str in Python 3) to
  bytestring type (str or bytes in Python 2, bytes in Python 3)

  The input is returned unmodified if it is already a bytestring
  Will convert other types (e.g. int, float) to bytestring
  None is returned as None, not as 'None'

  For Linux/OS X, the default filesystem encoding is utf8.
  For Windows, the default filesystem encoding is mbcs
  This is important for handling files with basic Python functions.
  With the wrong encoding, the filesystem will not recognize the file path
  import sys; sys.getfilesystemencoding()
  '''

  if (codec is None):
    codec = 'utf8'
    if (sys.platform == 'win32'):
      codec = 'mbcs'

  if (isinstance(text, bytes)):
    return text
  elif (isinstance(text, unicode)):
    new_text = text
    try:
      new_text = text.encode(codec, errors)
    except UnicodeEncodeError: # in case errors='strict'
      raise Sorry('Unable to encode text with %s' % codec)
    finally:
      return new_text
  elif (text is not None):
    return bytes(text)
  else:
    return None

def to_str(text, codec=None, errors='replace'):
  '''
  Function for handling text in a way compatible with both Python 2 and 3 and
  with Boost.

  Boost defines boost::python::str as Unicode text in Python 3 (str type) and
  as text/byte string in Python 2 (also str type, or bytes type).

  This function just calls to_unicode and to_bytes to return the appropriate
  type depending on the Python version
  '''
  if sys.hexversion >= 0x03000000:
    return to_unicode(text, codec, errors)
  else:
    return to_bytes(text, codec, errors)

def guess_total_memory():
  '''
  Use psutil to return the total memory on a system in bytes.
  '''
  import psutil
  return psutil.virtual_memory().total

MANGLE_LEN = 256 # magic constant from compile.c
def mangle(name, klass):
  '''
  Since the compiler module is removed in Python 3, this is a copy of the
  mangle function from compiler.misc.

  This function is used for name mangling in libtbx/__init__.py for the
  slots_getstate_setstate class.
  '''
  if not name.startswith('__'):
    return name
  if len(name) + 2 >= MANGLE_LEN:
    return name
  if name.endswith('__'):
    return name
  try:
    i = 0
    while klass[i] == '_':
      i = i + 1
  except IndexError:
    return name
  klass = klass[i:]

  tlen = len(klass) + len(name)
  if tlen > MANGLE_LEN:
    klass = klass[:MANGLE_LEN-tlen]

  return "_%s%s" % (klass, name)

def path_is_git_lfs_pointer(path):
  '''
  Test if a file is a git lfs pointer. See
  https://github.com/git-lfs/git-lfs/blob/master/docs/spec.md
  '''
  with open(path, 'rb') as f:
    return f.read(12) == b'version http'

def check_git_lfs_pointer_is_loaded(path):
  '''
  Prints a skip if the lfs pointer hasn't been loaded
  '''
  test = path_is_git_lfs_pointer(path)
  if test:
    print ("""
Skipping. %s hasn't been loaded from git
Run these commands to load the data:
cd <repository name>
git lfs install --local
git lsf pull
"""%path)
  return not test

def display_context(text, file_name = 'file name', n_context = 5,
   search_word = None, required_word= None,
   excluded_words = None, category = None,
    quiet = None,
   always_excluded_words = None):
  ''' Search lines in text for search_word and select blocks of size
    n_context on either side. If context_word appears, mark that line

    params: text: block of text
    params: n_context: number of lines on either side of search word to keep
    params: search_word:  word to find
    params: required_word: another word to find (must have both in block
            if required_word is set)
    params: excluded_words: if any are present in text_block, skip it
    params: category: category to pass on in group_args
    params: file_name: file_name (title or name of file) to pass on in group_args
    params: always_excluded_words: add to excluded words
  '''

  text_block_list = []
  from libtbx import group_args
  lines = text.splitlines()
  if not quiet:
    print("\n"+79*"=")
    print(
    "Searching %s with Search word: %s  Required word: %s Excluded word: %s" %(
           file_name, search_word, required_word, excluded_words))
    print("\n"+79*"=")


  if not excluded_words: excluded_words = []
  if not always_excluded_words: always_excluded_words = []
  max_working_lines = 2*n_context
  working_lines = []
  for i in range(len(lines)):
    working_lines.append(lines[i])
    if len(working_lines) > max_working_lines:
      working_lines = working_lines[1:]
    working_lines_text = "\n".join(working_lines)
    if lines[i].find(search_word)>-1  and (
       not lines[i].strip().startswith("#")):
      text_block = ""
      text_block_continuation = ""
      first_line_number = max(0,i-n_context)
      last_line_number = min(len(lines), i+n_context+1)
      for ll in lines[first_line_number: last_line_number]:
        if ll.find(search_word)> -1:
          text_block += "  ** %s\n" %(ll)
        else:
          text_block += "     %s\n" %(ll)
        if ll.endswith("\\"):
          text_block_continuation += "%s" %(ll[:-1].strip())
        else:
          text_block_continuation += "%s\n" %(ll.strip())
      skip = False
      for x in excluded_words + always_excluded_words:
        if text_block_continuation.find(x) > -1:
          skip = True
        if working_lines_text.find(x) > -1: # allow backwards further
          skip = True
      if skip:
        continue
      if required_word and  (text_block_continuation.find(required_word) < 0):
        continue

      if not quiet:
        print("\n%s at line %s. Search word: %s  Required word: %s" %(
          file_name, first_line_number+1, search_word, required_word))
        print(text_block)
      info = group_args(group_args_type = 'text block',
        category = category,
        file_name = file_name,
        search_word = search_word,
        required_word = required_word,
        excluded_words = excluded_words,
        always_excluded_words = always_excluded_words,
        text_block = text_block,
        line_number = i+1,
        )
      text_block_list.append(info)
  return text_block_list


class timer:
  '''
  Context manager for timing blocks of code
  https://stackoverflow.com/questions/33987060/python-context-manager-that-measures-time

  from libtbx.utils import timer

  with timer():
    <block of code to be timed>
  '''
  def __enter__(self):
    self.time = time.perf_counter()
    return self

  def __exit__(self, type, value, traceback):
    self.time = time.perf_counter() - self.time
    print('Elapsed time (s): {}'.format(self.time))


 *******************************************************************************


 *******************************************************************************
libtbx/version.py
from __future__ import absolute_import, division, print_function

import os
import subprocess
import sys
import time

# =============================================================================
def create_version_files(git_repo='cctbx_project', basename='cctbx_version',
                         version=None, setup_template=None):
  '''
  Function for creating the files containing the version. This
  function is called by bootstrap.py after downloading the git
  repository. The development version is the date of the commit and
  the commit information from "git describe". Files containing an
  official release version can created by providing the version as an
  argument

  Parameters
  ----------
  git_repo: str
    The git repository to be versioned. This is the directory name in
    "modules" (e.g. cctbx_project)
  basename: str
    The basename for the filenames. It is also the name of the defintion
    in the C++ header. The ".txt" and ".h" extensions will be added to
    the filenames.
  version: str
    If set, this argument is used as the version
  setup_template: str
    A template for the setup.py file. There should be a {version} field.

  Returns
  -------
  filenames: str
    A tuple containing the three filenames. The first is the plain text
    file, the second is a C++ header file, and the last is a setup.py
    file. These files are located in the git repository. The plain text
    and header cab be copied to the build directory in libtbx_refresh.py.
  '''

  path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', '..', git_repo)
  if not os.path.isdir(path):
    raise RuntimeError('The {path} directory does not exist.'.format(path=path))

  if version is None:
    tagged = False  # True for tagged release

    # create {y}.{m}.dev{d}+{n}.{h} formatted version
    y = None  # year
    m = None  # month
    d = None  # day
    n = None  # number of commits since last tag
    h = None  # g + hash of commit

    # check for release tag
    try:
      output = subprocess.check_output(['git', 'describe'], cwd=path).decode('utf8')
      output = output.split('-')
      if len(output) == 1:  # tagged release does not have -
        tagged = True
        version = output[0][1:].strip()  # remove first v
      else:
        n = int(output[-2])
        h = output[-1].strip()
    except subprocess.CalledProcessError:
      pass

    # create local version
    if not tagged:
      try:
        t = subprocess.check_output(['git', 'log', '-1', '--pretty=%ci'], cwd=path).decode('utf8')
        t = t.split()[0].split('-')
        y = int(t[0])
        m = int(t[1])
        d = int(t[2])
      except subprocess.CalledProcessError:
        t = time.localtime()
        y = t.tm_year
        m = t.tm_mon
        d = t.tm_mday

      version = '{y}.{m}.dev{d}'.format(y=y, m=m, d=d)

      # add latest commit information as local version
      if n is not None and h is not None:
        version += '+{n}.{h}'.format(n=n, h=h)
      else:
        version += '+unknown'

  # write plain text
  txt_filename = os.path.join(path, basename + '.txt')
  with open(txt_filename, 'w') as f:
    f.write(version)

  # write C++ header
  header_template = '''\
// {basename} version header
// This file is automatically generated

#ifndef {basename}_H
#define {basename}_H

#define {basename} "{version}"

#endif
'''
  h_filename = os.path.join(path, basename + '.h')
  with open(h_filename, 'w') as f:
    f.write(header_template.format(basename=basename.upper(), version=version))

  # write setup.py
  if setup_template is None:
    setup_template = '''\
from setuptools import setup
setup(
    name='cctbx-base',
    version='{version}',
    url='https://github.com/cctbx/cctbx_project',
    description='The Computational Crystallography Toolbox (cctbx) is being developed as the open source component of the Phenix system. The goal of the Phenix project is to advance automation of macromolecular structure determination. Phenix depends on the cctbx, but not vice versa. This hierarchical approach enforces a clean design as a reusable library. The cctbx is therefore also useful for small-molecule crystallography and even general scientific applications.',
    author='CCTBX developers',
    author_email='cctbx@cci.lbl.gov',
    maintainer='CCTBX developers',
    maintainer_email='cctbx@cci.lbl.gov',
    license='BSD-3-Clause-LBNL AND BSD-3-Clause AND BSL-1.0 AND LGPL-2.0-only AND LGPL-2.1-only AND LGPL-3.0-only AND MIT AND LGPL-2.0-or-later WITH WxWindows-exception-3.1',
    packages=[],
)
'''

  setup_filename = os.path.join(path, 'setup.py')
  with open(setup_filename, 'w') as f:
    f.write(setup_template.format(version=version))

  return (txt_filename, h_filename, setup_filename)

# -----------------------------------------------------------------------------
def get_version(filename='cctbx_version.txt', fail_with_none=False):
  '''
  Function for returning the version of the current installation
  The file containing the version is manually created for official
  releases and created by bootstrap.py for development releases. The
  version follows calendar versioning, so in the event that the file
  cannot be read, a version based on the current date can be returned.

  Parameters
  ----------
  filename: str
    The filename of the file containing the version number. This can
    be a full path. Otherwise, the directory is assumed to be the build
    directory.
  fail_with_none: bool
    If set, any failure to read the version file will return None.
    Otherwise, the current date is used to generate the version.

  Returns
  -------
  str or None
  '''
  import libtbx.load_env

  version = None
  path = filename
  if not os.path.isabs(path):
    path = os.path.join(abs(libtbx.env.build_path), filename)

  try:
    with open(path) as f:
      version = f.read().strip()
  except IOError:
    if fail_with_none:
      return None

  if version is None:
    t = time.localtime()
    version = '{y}.{m}.dev{d}+unknown'.format(y=t.tm_year, m=t.tm_mon, d=t.tm_mday)

  return version

# =============================================================================
if __name__ == '__main__':
  import argparse
  parser = argparse.ArgumentParser(
    description='Command for generating files containing version information.')
  parser.add_argument(
    '--git-repo',
    help='The name of the git repository in the "modules" directory.',
    default='cctbx_project')
  parser.add_argument(
    '--basename',
    help='The base name for the version filenames.',
    default='cctbx_version')
  parser.add_argument(
    '--version',
    help='An explicit version to be set.',
    default=None)

  namespace = parser.parse_args(sys.argv[1:])

  filenames = create_version_files(
    git_repo=namespace.git_repo,
    basename=namespace.basename,
    version=namespace.version)

  print('Writing files containing version information for {git_repo}'.\
    format(git_repo=namespace.git_repo))
  print('='*79)
  for filename in filenames:
    print('Wrote {filename}'.format(filename=filename))
  print('='*79)

# =============================================================================
# end


 *******************************************************************************


 *******************************************************************************
libtbx/wingide.py
""" Tools for the Python integrated development environment Wing IDE """
from __future__ import absolute_import, division, print_function

def log(stop=False, **kwds):
  """ Helper to ease putting watchpoints

  Synopsis:
    - set a conditional breakpoint
    - write the condition as
        some_condition and log(some_variable=some_variable, ...)
    - debug the code

  The debugger won't stop at that breakpoint but it will log name and values
  of the specified variables each time it passes over that breakpoint if
  and only if the given condition is true.

  Remark:
    Passing stop=True makes it a real breakpoint
  """
  for k,v in kwds.items():
    print("%s = %s" % (k,v))
  return stop


 *******************************************************************************


 *******************************************************************************
libtbx/word_index_generator.py
from __future__ import division

"""
word_index_generator (generate an index from html directories)

Generate a multi-page alphabetical HTML word index from a directory tree of HTML files.
Only visible, non-trivial words (excluding stopwords and filtered tokens) are indexed.
Each section page contains navigable links and structured grouping by word prefix.
Formatted to match pdoc3-style HTML structure.
"""

import os
import re
import html

OK = True
try:
  from bs4 import BeautifulSoup, Comment
  from collections import defaultdict
  from nltk.corpus import stopwords
  import nltk
except Exception as e:
  OK = False

def download_stopwords():
    """Ensure stopwords are available."""
    nltk.download('stopwords')

def get_visible_text(html_content):
    """
    Extracts visible text from HTML content, excluding scripts, styles, comments, and hidden elements.
    """
    soup = BeautifulSoup(html_content, "html.parser")
    for tag in soup(['pre', 'script', 'style', 'meta', 'noscript']):
        tag.decompose()
    for comment in soup.find_all(string=lambda text: isinstance(text, Comment)):
        comment.extract()
    for tag in soup.find_all(style=True):
        style = tag['style'].replace(" ", "").lower()
        if "display:none" in style or "visibility:hidden" in style:
            tag.decompose()
    body = soup.body or soup
    return body.get_text(separator=' ', strip=True)

def tokenize(text):
    """Tokenize input text into lowercase words."""
    return re.findall(r'\b\w+\b', text.lower())

def get_letter_section(word):
    """Returns the first letter of the word or 'other' if not alphabetic."""
    first = word[0].lower()
    return first if first.isalpha() else "other"

def build_word_index(html_dir, stop_words, exclude_pattern, index_dir):
    """
    Walk the HTML directory and build a word index {word -> set of file paths (up to 5)}
    """
    word_index = defaultdict(set)
    for root, _, files in os.walk(html_dir):
        for file in files:
            if file.endswith(".html"):
                filepath = os.path.abspath(os.path.join(root, file))
                rel_filepath = os.path.join("..", os.path.relpath(filepath, os.path.abspath(html_dir)))
                if filepath.find(index_dir) > -1:
                    continue
                try:
                    with open(filepath, "r", encoding="utf-8") as f:
                        html_content = f.read()
                        text = get_visible_text(html_content)

                        if not text.strip():
                            print(f" No visible text in: {filepath}")
                            continue
                        print(f" Visible text found in: {filepath}")

                        words = tokenize(text)
                        for word in words:
                            if (
                                word not in stop_words and
                                len(word) > 2 and
                                not word[0].isdigit() and
                                not word.startswith("_") and
                                not exclude_pattern.match(word) and
                                word.isascii()
                            ):
                                if len(word_index[word]) < 5:
                                    word_index[word].add(rel_filepath)
                except Exception as e:
                    print(f" Skipped {filepath}: {e}")
    return word_index

def generate_html_pages(word_index, index_title, index_dir):
    """
    Generate alphabetically sectioned HTML index files with navigation and pdoc3-style layout.
    """
    sorted_words = sorted(word_index.items())
    sectioned_words = defaultdict(list)
    for word, paths in sorted_words:
        section = get_letter_section(word)
        sectioned_words[section].append((word, paths))

    sections_sorted = sorted(sectioned_words.keys())
    overall_file = None
    for section, word_list in sectioned_words.items():
        section_file = os.path.join(index_dir, f"word_index_{section}.html")
        current_index = sections_sorted.index(section)
        prev_section = sections_sorted[current_index - 1] if current_index > 0 else None
        next_section = sections_sorted[current_index + 1] if current_index + 1 < len(sections_sorted) else None

        lines = [
            "<!doctype html>",
            "<html lang=\"en\">",
            "<head>",
            "<meta charset=\"utf-8\">",
            f"<title>{index_title} Index: {section.upper()}</title>",
            "<meta name='viewport' content='width=device-width, initial-scale=1'>",
            "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css\">",
            "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css\">",
            "<style>",
            "body { font-family: system-ui, sans-serif; background-color: #fff; color: #222; line-height: 1.6; margin: 0; }",
            "main { display: flex; flex-direction: row; flex-wrap: wrap; }",
            "#sidebar { width: 15%; min-width: 160px; padding: 1.5em; background-color: #f9f9f9; border-right: 1px solid #ddd; position: sticky; top: 0; height: 100vh; overflow-y: auto; }",
            "article#content { flex: 1; min-width: 300px; padding: 3em 4em; }",
            "#jump-list { column-count: 2; -webkit-column-count: 2; -moz-column-count: 2; padding-left: 0; list-style: none; }",
            "article ul { column-count: 3; -webkit-column-count: 3; -moz-column-count: 3; padding-left: 0; list-style: none; }",
            "li { margin-bottom: .5em; }",
            "h1, h2, h3 { font-weight: 300; color: #111; }",
            "code { font-family: 'DejaVu Sans Mono', monospace; background-color: #f3f3f3; padding: 1px 4px; border-radius: 3px; }",
            ".nav-links { margin-bottom: 1em; font-size: 0.9em; }",
            "footer { font-size: 0.75em; padding: 1em; text-align: right; color: #999; }",
            "@media (max-width: 768px) { #sidebar { position: relative; height: auto; } article#content { padding: 1em; } }",

            "a { color: #336699; /* softer blue-gray tint */ text-decoration: none; }",
            "a:hover { color: #224466; /* darker shade on hover */ }",

            "</style>",
            "</head>",
            "<body>",
            "<main>",
            "<nav id=\"sidebar\">",
            "<ul id=\"index\">",
            f"<li><a href=\"../index.html\">{index_title}</a></li>",
            "</ul></li>",
            "<li><h3>Jump to</h3>",
            "<ul id=\"jump-list\">",
        ]

        for sec in sections_sorted:
            lines.append(f"<li><a href='word_index_{sec}.html'>{sec.upper()}</a></li>")

        lines += [
            "</ul></li>",
            "</ul>",
            "</nav>",
            "<article id=\"content\">",
            f"<h1>{index_title} Index: {section.upper()}</h1>",
            "<div class=\"nav-links\">",
        ]

        if prev_section:
            lines.append(f"<a href='word_index_{prev_section}.html'>&larr; Previous ({prev_section.upper()})</a>")
        if next_section:
            lines.append(f" | <a href='word_index_{next_section}.html'>Next ({next_section.upper()}) &rarr;</a>")

        lines.append("</div>")

        lines.append("<div class='nav-links'><strong>Subsections:</strong> ")
        subsection_prefixes = sorted(set(word[:2].lower() for word, _ in word_list))
        for prefix in subsection_prefixes:
            lines.append(f"<a href='#{prefix}'>{prefix}</a> ")
        lines.append("</div>")

        current_prefix = ""
        first_prefix = True

        for word, paths in word_list:
            prefix = word[:2].lower()
            if prefix != current_prefix:
                if not first_prefix:
                    lines.append("</ul>")
                lines.append(f"<h3 id='{prefix}'>{prefix}</h3><ul>")
                current_prefix = prefix
                first_prefix = False

            word_html = f"<strong><code>{html.escape(word)}</code></strong>: " + ", ".join(
                f"<a href='{html.escape(path)}' target='_blank'>{os.path.basename(path)}</a>"
                for path in sorted(paths)
            )
            lines.append(f"<li>{word_html}</li>")

        lines.append("</ul>")
        lines.append("</article></main>")
        lines.append("<footer id=\"footer\"><p>Generated by word_index_generator</p></footer>")
        lines.append("</body></html>")

        with open(section_file, "w", encoding="utf-8") as f:
            f.write("\n".join(lines))

        if section == "a":
            overall_file = os.path.join(index_dir, "index.html")
            with open(overall_file, "w", encoding="utf-8") as f:
                f.write("\n".join(lines))

        print(f" Created section: {section_file}")

    print(f" Main index written to '{overall_file}'")

def run(args):
    """
    Entry point: index HTML files in a directory and generate navigable AZ word index.
    Expects path to directory containing html files, path for index files
    (normally same as path to html files + /index_files/ and
    optional third arg with title.
    """
    try:
        html_dir = args[0]
        assert os.path.isdir(html_dir)
        index_dir = args[1]
        assert os.path.relpath(index_dir, html_dir).find(os.path.sep) < 0
        if not os.path.isdir(index_dir):
            os.mkdir(index_dir)
        print(f"HTML to be read from '{html_dir}'")
        print(f"Indexing HTML to be written to '{index_dir}'")
    except Exception as e:
        print("Please run with path to directory containing html files as 1st arg and path to directory inside that for index files (index_files usually)")
        return

    index_title = args[2] if len(args) > 2 else "Word"
    print(f"Title to use: '{index_title}'")

    download_stopwords()
    stop_words = set(stopwords.words('english'))
    exclude_pattern = re.compile(r'^[a-zA-Z][0-9_]')

    word_index = build_word_index(html_dir, stop_words, exclude_pattern, index_dir)
    print(f"\n Indexed {len(word_index)} unique words.")
    generate_html_pages(word_index, index_title, index_dir)

if __name__ == "__main__":
    if OK:
        import sys
        run(sys.argv[1:])
    else:
        print("Cannot run word_index_generator without nltk beautifulsoup4")


 *******************************************************************************


 *******************************************************************************
libtbx/xmlrpc_server_example.py
from __future__ import absolute_import, division, print_function

# This is an example of how a 3rd-party program with Python embedded, such
# as Coot or PyMOL, can be interfaced with CCTBX-based software.  Something
# much like this is used for the Phenix GUI extensions to those programs.
# I haven't tried this with any other software, but anything with a reasonably
# recent version of Python and support for either persistent Python threads
# or some sort of timer callback should be able to use it.

DEFAULT_PORT = 40000

import os, sys, string, signal
import xmlrpclib

try :
  from SimpleXMLRPCServer import SimpleXMLRPCServer
  class external_xmlrpc_server(SimpleXMLRPCServer):
    def __init__(self, addr, cctbx_interface):
      self.cctbx_interface = cctbx_interface
      SimpleXMLRPCServer.__init__(self, addr, logRequests=0)

    def _dispatch(self, method, params):
      if not self.cctbx_interface.enable_xmlrpc :
        return -1
      result = -1
      func = getattr(self.cctbx_interface, method, None)
      if not callable(func):
        print("%s is not a callable object!" % method)
      else :
        result = func(*params)
        if result is None :
          result = -1
      return result

  class external_xmlrpc_interface(object):
    def __init__(self, program_id, auto_start=True, verbose=False):
      self.enable_xmlrpc = True
      self.xmlrpc_server = None
      self.cctbx_server = None
      self.verbose = verbose
      self.timeout = string.atoi(os.environ.get("CCTBX_XMLRPC_TIMEOUT", "250"))
      self.program_id = program_id
      self.supported_modules = []
      self.setup_modules()
      self.setup_server()
      if auto_start :
        self.start_server()

    def setup_modules(self):
      pass

    def add_module(self, module_object=None, module_path=None):
      if module_object is not None :
        self.supported_modules.append(module_object)
      elif module_path is not None :
        module_object = __import__(module_path)
        self.supported_modules.append(module_object)

    def setup_server(self):
      port = os.environ.get("CCTBX_%s_PORT" % self.program_id, DEFAULT_PORT)
      if port is not None :
        self.port = int(port)
        self.xmlrpc_server = external_xmlrpc_server(("127.0.0.1", self.port),
                                                    self)
        if self.verbose :
          print("Listening on port %s" % port)
      cctbx_port = os.environ.get("CCTBX_XMLRPC_PORT", None)
      if cctbx_port is not None :
        uri = "http://localhost:%s/RPC2" % cctbx_port
        self.cctbx_server = xmlrpclib.ServerProxy(uri=uri)
        if self.verbose :
          print("Connecting to XML-RPC server on port %s" % cctbx_port)

    def start_server(self):
      if self.xmlrpc_server is not None :
        print("XML-RPC server started on port %d" % self.port)
        self.xmlrpc_server.serve_forever()

    def start_server_in_separate_thread(self):
      import threading
      t = threading.Thread(target=self.start_server)
      t.setDaemon(1)
      t.start()

    def set_socket_timeout(self, timeout):
      if self.xmlrpc_server is not None :
        self.xmlrpc_server.socket.settimeout(timeout)

    def timeout_func(self, *args):
      if self.xmlrpc_server is not None :
        self.xmlrpc_server.handle_request()
      return True

    def is_alive(self):
      return True

    # XXX: this should be replaced by the proper quit function for the program
    # being extended - e.g. cmd.quit() in PyMOL.
    def quit(self):
      print("quitting")
      sys.stdout.flush()
      os.kill(os.getpid(), signal.SIGKILL)

    def __getattr__(self, name):
      for module_object in self.supported_modules :
        if hasattr(module_object, name):
          return getattr(module_object, name)
      return None

except KeyboardInterrupt :
  raise
except ImportError :
  def external_xmlrpc_server(*args, **kwds):
    raise Exception("SimpleXMLRPCServer not available on this platform.")

  def external_cctbx_interface(*args, **kwds):
    raise Exception("SimpleXMLRPCServer not available on this platform.")

def test_server():
  class test_module(object):
    def echo_test(self):
      print("hello, world!")
      sys.stdout.flush()
      return True

#  os.environ["CCTBX_TEST_PORT"] = "48000"
  test_server = external_xmlrpc_interface("TEST", auto_start=False,
                                          verbose=False)
  module_object = test_module()
  test_server.add_module(module_object)
  test_server.start_server()

def coot_server():
  server = external_xmlrpc_interface("COOT",
    auto_start=False,
    verbose=True)
  server.set_socket_timeout(0.01)
  import coot
  import gobject
  server.add_module(coot)
  gobject.timeout_add(200, server.timeout_func)

if __name__ == "__main__" :
  #test_server()
  coot_server()

#---end


 *******************************************************************************


 *******************************************************************************
libtbx/xmlrpc_utils.py
from __future__ import absolute_import, division, print_function

# see also xmlrpc_server_example.py

# FIXME: rewrite ServerProxy with built-in threading for handling failed
# requests

# XXX: The ServerProxy here is based on the xmlrpclib ServerProxy
# object, but rewritten from scratch to cache requests which failed due
# to a connection error and retry them later.  I'm not sure why I can't
# just subclass it - I suspect it's a "feature" of old-style classes.
#
# XXX: Note that using the hacked ServerProxy violates the intended behavior
# of the XML-RPC protocol.  Therefore, this module allows either the original
# or modified version to be used - the original is left as the default.
#
#
# Original copyright information:
#
# XML-RPC CLIENT LIBRARY
# $Id: xmlrpclib.py 65467 2008-08-04 00:50:11Z brett.cannon $
#
# an XML-RPC client interface for Python.
#
# the marshalling and response parser code can also be used to
# implement XML-RPC servers.
#
# --------------------------------------------------------------------
# The XML-RPC client interface is
#
# Copyright (c) 1999-2002 by Secret Labs AB
# Copyright (c) 1999-2002 by Fredrik Lundh
#
# By obtaining, using, and/or copying this software and/or its
# associated documentation, you agree that you have read, understood,
# and will comply with the following terms and conditions:
#
# Permission to use, copy, modify, and distribute this software and
# its associated documentation for any purpose and without fee is
# hereby granted, provided that the above copyright notice appears in
# all copies, and that both that copyright notice and this permission
# notice appear in supporting documentation, and that the name of
# Secret Labs AB or the author not be used in advertising or publicity
# pertaining to distribution of the software without specific, written
# prior permission.
#
# SECRET LABS AB AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD
# TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANT-
# ABILITY AND FITNESS.  IN NO EVENT SHALL SECRET LABS AB OR THE AUTHOR
# BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY
# DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
# WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
# OF THIS SOFTWARE.
# --------------------------------------------------------------------

from libtbx import adopt_init_args
from libtbx.utils import to_bytes, to_str
try:
  import xmlrpclib
except ImportError:
  import xmlrpc.client as xmlrpclib
try:
  import httplib
except ImportError:
  import http.client as httplib
import socket
import subprocess
import threading
import time
import random
import os
import sys
from six.moves import range

# use unicode check to avoid bytes in Python 3
check_type = bytes
if sys.version_info.major == 2:
  check_type = unicode

# http://stackoverflow.com/questions/372365/set-timeout-for-xmlrpclib-serverproxy
class TimeoutTransport(xmlrpclib.Transport):
  def __init__(self, timeout=socket._GLOBAL_DEFAULT_TIMEOUT, *args, **kwargs):
    xmlrpclib.Transport.__init__(self, *args, **kwargs)
    self.timeout = timeout

  def make_connection(self, host):
    if self._connection and host == self._connection[0]:
      return self._connection[1]
    # create a HTTP connection object from a host descriptor
    chost, self._extra_headers, x509 = self.get_host_info(host)
    #store the host argument along with the connection object
    self._connection = host, httplib.HTTPConnection(chost,
      timeout=self.timeout)
    return self._connection[1]

default_timeout = 5.0
if (sys.platform == "win32"):
  default_timeout = 1.0
class ServerProxy(object):
  def __init__(self, uri, transport=None, encoding=None, verbose=0,
               allow_none=0, use_datetime=0, timeout=default_timeout,
               raise_errors=True):
    self._pending = []
    # establish a "logical" server connection

    # get the url
    from six.moves.urllib.parse import urlparse
    parsed_url = urlparse(uri)
    scheme = parsed_url.scheme
    self.__host = parsed_url.netloc
    self.__handler = parsed_url.path
    if scheme not in ("http", "https"):
      raise IOError("unsupported XML-RPC protocol")
    if not self.__handler:
      self.__handler = "/RPC2"

    if transport is None:
      if scheme == "https":
        transport = xmlrpclib.SafeTransport(use_datetime=use_datetime)
      else:
        transport = TimeoutTransport(timeout=timeout,
          use_datetime=use_datetime)
    self.__transport = transport

    self.__encoding = encoding
    self.__verbose = verbose
    self.__allow_none = allow_none
    self._timeouts = 0
    self._errors = []
    self.raise_errors = raise_errors

  def __request(self, methodname, params):
    self._pending.append((methodname, params))
    return self.flush_requests()

  def flush_requests(self, show_timings=False):
    t1 = time.time()
    result = None
    while len(self._pending) > 0 :
      (methodname, params) = self._pending.pop(0)

      # remove any unicode types in params
      if (isinstance(params, check_type)):
        params = to_str(params)
      elif (isinstance(params, list) or isinstance(params, tuple)):
        new_params = list(params)
        for i in range(len(params)):
          if (isinstance(params[i], check_type)):
            new_params[i] = to_str(params[i])
          else:
            new_params[i] = params[i]
        if (isinstance(params, tuple)):
          new_params = tuple(new_params)
        params = new_params

      # call a method on the remote server
      try :
        request = xmlrpclib.dumps(params, methodname,
                                  encoding=self.__encoding,
                                  allow_none=self.__allow_none)

        response = self.__transport.request(
            self.__host,
            self.__handler,
            to_bytes(request),
            verbose=self.__verbose
        )

        if len(response) == 1 :
          result = response[0]
      except KeyboardInterrupt :
        raise
      except Exception as e :
        msg = to_str(e)
        if (hasattr(e, "errno")):
          if (e.errno in [32,54,61,104,111,10054,10061]):
            self._pending.insert(0, (methodname, params))
            t = time.strftime("%H:%M:%S", time.localtime())
            self._errors.append("%s -- %s" % (t, msg))
            break
        if ("timed out" in msg):
          print("XMLRPC timeout, ignoring request")
          self._timeouts += 1
        elif msg.startswith("<ProtocolError "):
          self._pending = []
          break
        elif ("exceptions.SystemExit" in msg):
          self._pending = []
          break
        else :
          msg = "XMLRPC error: %s\nMethod: %s\nParams: %s\n" % \
            (msg, to_str(methodname), ", ".join([ to_str(p) for p in params ]))
          if (not self.raise_errors):
            print(msg, file=sys.stderr)
          else :
            raise RuntimeError(msg)
    t2 = time.time()
    if (show_timings):
      sys.stderr.write("flush_requests: %.3fs\n" % (t2-t1))
    return result


  def __repr__(self):
    return (
          "<ServerProxy for %s%s>" %
          (self.__host, self.__handler)
          )

  __str__ = __repr__

  # note: to call a remote object with an non-standard name, use
  # result getattr(server, "strange-python-name")(args)

  def __getattr__(self, name):
    # magic method dispatcher
    return xmlrpclib._Method(self.__request, name)

  def number_of_timeout_errors(self):
    return self._timeouts

  def get_error_messages(self):
    return self._errors

#-----------------------------------------------------------------------
class external_program_thread(threading.Thread):
  def __init__(self, command_args, program_id, log=None,
      intercept_output=True, use_env = False):
    adopt_init_args(self, locals())
    if self.log is None :
      self.log = sys.stdout
    threading.Thread.__init__(self)
    self._alive = True

  def run(self):
    if self.use_env:
      # Allow specifically sending the environment (including CCTBX_COOT_PORT)
      #  and do not depend on details of the operating system
      local_env = os.environ.copy()
      if self.intercept_output :
        p = subprocess.Popen(args=self.command_args, stdout=subprocess.PIPE,
          stderr=subprocess.PIPE, shell=True, env = local_env)
      else :
        p = subprocess.Popen(args=self.command_args, shell=True, env = local_env)
    else: # usual
      if self.intercept_output :
        p = subprocess.Popen(args=self.command_args, stdout=subprocess.PIPE,
          stderr=subprocess.PIPE, shell=True)
      else :
        p = subprocess.Popen(args=self.command_args, shell=True)
    while True :
      if p.poll() is not None :
        break
      else :
        time.sleep(0.5)
      if self.intercept_output :
        output = p.stdout.readline()
        if output is not None and output != "" :
          self.log.write(output)
          self.log.flush()
    self._alive = False

  # XXX: this is probably a bad idea
  def is_alive(self):
    return self._alive

class external_program_server(object):
  port_ranges = [ (40001, 40840),
                  (46000, 46999) ]
  def __init__(self, command_args, program_id, timeout, cache_requests=False,
                local_port=None, log=None, intercept_output=False,
                use_env = False):
    adopt_init_args(self, locals())
    assert isinstance(command_args, list) or isinstance(command_args, tuple)
    self._process = None
    self._server = None
    self.initialize_server()

  def initialize_server(self):
    if self._process is None and self._server is None :
      valid_ports = []
      for (start, end) in self.port_ranges :
        valid_ports.extend([ n for n in range(start, end) ])
      i = int(random.random() * (len(valid_ports) - 1))
      self._port = valid_ports[i]
      prog_port_env = "CCTBX_%s_PORT" % self.program_id.upper()
      os.environ[prog_port_env] = str(self._port)
      if self.timeout is not None :
        os.environ["CCTBX_XMLRPC_TIMEOUT"] = str(self.timeout)
      if self.local_port is not None :
        os.environ["CCTBX_XMLRPC_PORT"] = str(self.local_port)
      self._process = external_program_thread(
        command_args=self.command_args,
        program_id=self.program_id,
        log=self.log,
        intercept_output=self.intercept_output,
        use_env = self.use_env)
      self._process.start()
      if self.cache_requests :
        proxy_class = ServerProxy
      else :
        proxy_class = xmlrpclib.ServerProxy
      self._server = proxy_class(uri="http://127.0.0.1:%d/RPC2" %
                                             self._port)

  def flush_requests(self, *args, **kwds):
    if not self.cache_requests :
      return False
    elif self._server is not None :
      return self._server.flush_requests(*args, **kwds)

  def restart(self):
    self._process = None
    self._server = None
    self.initialize_server()

  def is_alive(self):
    if self._process is None or self._server is None :
      return False
    try :
      status = self._server.is_alive()
    except KeyboardInterrupt :
      raise
    except Exception :
      return False
    else :
      if status is None :
        return False
      else :
        return True

  def get_port(self):
    return self._port

  def _ignore(self, *args, **kwds):
    return True

  def __getattr__(self, name):
    if self._process is None or self._server is None :
      return self._ignore
    else :
      return getattr(self._server, name)

#---end


 *******************************************************************************
