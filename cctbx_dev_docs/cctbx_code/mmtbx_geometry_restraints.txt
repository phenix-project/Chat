

 *******************************************************************************
mmtbx/geometry_restraints/__init__.py


 *******************************************************************************


 *******************************************************************************
mmtbx/geometry_restraints/afitt.py
from __future__ import absolute_import, division, print_function
import os, sys
import copy
from cctbx.array_family import flex
from libtbx.utils import Sorry
from six.moves import cStringIO as StringIO
from libtbx import easy_run
from six.moves import zip
from six.moves import range

master_phil_str = """
  use_afitt = False
    .type = bool
  ligand_file_name = None
    .type = str
  ligand_names = None
    .type = str
  ff = 'mmff94s'
    .type = str
  scale = 10
    .type = str
"""

class covalent_object:
  def __init__(self):
    self.n_atoms = None
    self.resname = None
    self.res_id = None
    self.ligand_res_id = None
    self.charge = None
    self.partial_charges = []
    self.atom_elements = []
    self.bonds = []
    self.nbonds = None
    self.sites_cart_ptrs = []
    self.formal_charges = []
    self.res_bond = []


class afitt_object:
  def __init__(self,
               ligand_paths,  # ligand CIF restraints file
               ligand_names,  # ligand 3-codes
               pdb_hierarchy, #
               ff='mmff94s',     #
               scale=10, #
               ):
    self.n_atoms = []
    self.resname = ligand_names
    self.res_ids = [] #[chain, altloc,resseq]
    self.charge = []
    self.partial_charges = []
    self.atom_elements = []
    self.bonds = []
    self.nbonds = []
    self.sites_cart_ptrs = []
    self.formal_charges = []
    self.total_model_atoms = 0
    self.ff = ff
    self.scale = scale
    self.ligand_paths = ligand_paths
    self.pdb_hierarchy = pdb_hierarchy
    self.covalent_data = []
    self.occupancies = []

    cif_objects = []
    for ligand_path in ligand_paths:
      cif_objects.append( self.read_cif_file(ligand_path) )
    self.process_cif_objects( cif_objects, pdb_hierarchy )

  def __repr__(self):
    outl = "Afitt object"
    outl += "\n  %-15s : " %"ligand_files"
    for file in getattr(self, "ligand_paths"):
      outl += "%s " %file
    for attr in ["ff", "scale"]:
      outl += "\n  %-15s : %s" % (attr, getattr(self, attr))
    if self.sites_cart_ptrs:
      atoms = self.pdb_hierarchy.atoms()
      for resname, ptrs in zip(self.resname, self.sites_cart_ptrs):
        outl += "\n    %s" % (resname)
        for j, group in enumerate(ptrs):
          outl += "\n      Entity %s" % (j+1)
          for i in group:
            outl += "\n       %5d : %s" % (i, atoms[i].quote()[1:-1])
    else:
      for resname in self.resname:
        outl += "\n    %s" % resname
    return outl

  def read_cif_file(self, ligand_path):
    from iotbx import cif
    cif_object = cif.reader(file_path=ligand_path, strict=False).model()
    return cif_object

  def get_sites_cart_pointers(self,
                              atom_ids,
                              pdb_hierarchy,
                              chain_id,
                              altloc,
                              resseq,
                              ):
    sites_cart_ptrs=[-1]*len(atom_ids)
    #this should be simplified by using iotbx.pdb.atom_selection.cache
    for model in pdb_hierarchy.models():
      for chain in model.chains():
        if chain.id != chain_id: continue
        for conformer in chain.conformers():
          if conformer.altloc != altloc: continue
          for residue in conformer.residues():
            if residue.resseq != resseq: continue
            for atom in residue.atoms():
              for atom_id in atom_ids:
                if atom.name.strip() != atom_id.strip(): continue
                loc=atom_ids.index(atom_id)
                sites_cart_ptrs[loc] = atom.i_seq
    return sites_cart_ptrs

  def get_res_ids(self, pdb_hierarchy, resname):
    ids=[]
    atoms=[]
    #this should be simplified by using iotbx.pdb.atom_selection.cache
    for model in pdb_hierarchy.models():
      for chain in model.chains():
        for conformer in chain.conformers():
          for residue in conformer.residues():
            if residue.resname == resname:
              id_list=[chain.id,conformer.altloc,residue.resseq]
              ids.append(id_list)
              atoms.append([atom.i_seq for atom in residue.atoms()])

    #if different ligand residues have the same chain name and only one
    #of them has an altconf , multiple instances will be created of all
    #of them. This ugly piece of code removes the extra copies of residues
    #that have only one altconf. There must be a prettier way... Yes, I think
    #you need to use the 'pure main conf' and 'pure alt.conf' and 'proper
    #alt.conf' classification (see http://cci.lbl.gov/cctbx_docs/iotbx/iotbx.pdb.html#api-documentation)
    #but haven't done this yet.
    id_to_remove=[]
    for i in range(len(ids)-1):
      for j in range(i+1,len(ids)):
        atoms_i=atoms[i]
        atoms_j=atoms[j]
        if len(list(set(atoms_i) & set(atoms_j))) == len(atoms_i) and \
           len(list(set(atoms_i) & set(atoms_j))) == len(atoms_j):
          id_to_remove.append(i)
          break
    filtered_ids=[]
    for id in range(len(ids)):
      if id not in id_to_remove:
        filtered_ids.append(ids[id])
    return filtered_ids

  def get_occupancies(self, ptrs, pdb_hierarchy):
    for ptr in ptrs:
      for atom in pdb_hierarchy.atoms():
        if atom.i_seq == ptr:
          if 'occ' in locals():
            if occ > atom.occ:
              occ=atom.occ
          else:
            occ=atom.occ
    return occ

  def check_covalent(self, geometry):
    # for each ligand type
    for resname_i,resname in enumerate(self.resname):
      # covalent_data is a list of lists, has one list for each ligand type.
      # Each ligand_type list holds a covalent_object for each instance of that
      # ligand in the model.
      self.covalent_data.append([])
      # lig_atoms = []
      #for each instance of the ligand type
      for instance_i, instance in enumerate(self.res_ids[resname_i]):
        #search for covalent bonds between ligand and other residues
        # lig_atoms = lig_atoms + self.sites_cart_ptrs[resname_i][instance_i]
        # nonlig_atoms = [atom for atom in self.pdb_hierarchy.atoms()
        #                 if atom.i_seq not in lig_atoms ]
        nonlig_atoms = [atom for atom in self.pdb_hierarchy.atoms()
                        if atom.parent().parent().resseq != instance[2]]
        bond = []
        for lig_atm_iseq in self.sites_cart_ptrs[resname_i][instance_i]:
          for atom in nonlig_atoms:
            bond_t = geometry.bond_params_table.lookup(lig_atm_iseq, atom.i_seq)
            if bond_t != None:
              bond.append([atom, lig_atm_iseq])
        #if more than one covalent bond, exit
        assert len(bond) < 2, "Ligand %s has more than one covalent bond " \
                              "to the model. This is unsupported at " \
                              "present." %(resname)
        # if no covalent bonds, add None covalent_object and continue
        if len(bond) == 0:
          self.covalent_data[-1].append(None)
          continue

        #start populating the covalent object
        cov_obj = covalent_object()
        cov_res=bond[0][0].parent()
        cov_obj.resname = cov_res.resname
        cov_obj.res_id=[cov_res.parent().parent().id,
                       cov_res.altloc,
                       cov_res.parent().resseq]
        cov_obj.ligand_resname = resname
        cov_obj.ligand_res_id = instance
        cov_obj.sites_cart_ptrs = [atom.i_seq for atom in cov_res.atoms()]

        #get the cif file for the covalently bound residue (CBR)
        from mmtbx import monomer_library
        import mmtbx.monomer_library.server
        mon_lib_srv = monomer_library.server.server()
        get_func = getattr(mon_lib_srv, "get_comp_comp_id", None)
        if (get_func is not None):
          ml=get_func(comp_id=cov_obj.resname)
        else:
          ml=mon_lib_srv.get_comp_comp_id_direct(comp_id=cov_obj.resname)
        cif_object = ml.cif_object

        # atom id's in the CBR
        cif_atom_ids = [i for i in cif_object['_chem_comp_atom.atom_id']]
        model_atom_ids = [atom.name.strip() for atom in cov_res.atoms()]

        # because order of atoms in pdb can be different from cif, this
        # array points from the pdb atom to location of that atom in the cif array
        # this also takes care of the missings atoms because which, not
        # bein in the model_atom_ids, won't be in the cif_object_ptrs either
        cif_object_ptrs = [cif_atom_ids.index(atom) for atom in model_atom_ids]

        # get charges, elements, formal charges
        partial_charges = [float(i) for i in cif_object['_chem_comp_atom.partial_charge']]
        cov_obj.partial_charges = [partial_charges[ptr] for ptr in cif_object_ptrs]
        atom_elements = [i for i in cif_object['_chem_comp_atom.type_symbol']]
        cov_obj.atom_elements = [atom_elements[ptr] for ptr in cif_object_ptrs]
        if '_chem_comp_atom.charge' in cif_object:
          formal_charges = [float(i) for i in cif_object['_chem_comp_atom.charge']]
          cov_obj.formal_charges = [formal_charges[ptr] for ptr in cif_object_ptrs]

        # get bonds but exclude missing atom bonds and adjust atom indexes
        bond_atom_1 = [i for i in cif_object['_chem_comp_bond.atom_id_1']]
        bond_atom_2 = [i for i in cif_object['_chem_comp_bond.atom_id_2']]
        bond_dict={'single':1, 'double':2, 'triple':3, 'aromatic':4, 'coval':1,
                 'deloc':4}
        bond_type = [bond_dict[i] for i in cif_object['_chem_comp_bond.type']]
        bonds = list(zip(bond_atom_1, bond_atom_2, bond_type))
        for b in bonds:
          if b[0] in model_atom_ids and b[1] in model_atom_ids:
            cov_obj.bonds.append((model_atom_ids.index(b[0]), model_atom_ids.index(b[1]), b[2]))





        # import code; code.interact(local=dict(globals(), **locals())); sys.exit()
        # atom_ids_filt = [i for i in cif_atom_ids if i not in missing_atoms]

        # add the bond between ligand and CBR
        lig_atom_i = self.sites_cart_ptrs[resname_i][instance_i].index(bond[0][1])
        cov_atom_i = model_atom_ids.index(bond[0][0].name.strip())
        cov_obj.res_bond = [lig_atom_i, self.n_atoms[resname_i]+cov_atom_i, 1]

        #MISSING ATOMS
        # find atoms in the CBR cif that are misssing in the
        # model (covalent bond deletes a hydrogen)
        missing_atoms = [i for i in cif_atom_ids if i not in model_atom_ids]
        # assert that all missing atoms would've been bound to the CBR atom
        # linked to the ligand. Other atoms should not be missing!
        for missing_atom in missing_atoms:
          miss_atm_bound_to_cov_atm=False
          for b in bonds:
            if (b[0] == missing_atom and b[1] == bond[0][0].name.strip()) \
              or (b[1] == missing_atom and b[0] == bond[0][0].name.strip()):
                miss_atm_bound_to_cov_atm=True
          assert miss_atm_bound_to_cov_atm==True,\
            "Atom (%s) in residue (%s %s), which is covalently bound to " \
            "ligand (%s %s), is missing" \
            %(missing_atom, cov_res.resname,cov_res.parent().resseq.strip(),
              resname, instance[2].strip())

        cov_obj.charge = sum(cov_obj.partial_charges)
        cov_obj.nbonds = len(cov_obj.bonds)
        cov_obj.n_atoms = len(cov_obj.atom_elements)

        #sanity checks
        assert cov_obj.n_atoms == len(cov_res.atoms())
        assert cov_obj.n_atoms == len(cov_obj.sites_cart_ptrs)

        #add the covalent_object to covalent_data
        self.covalent_data[-1].append(cov_obj)

  def process_cif_objects(self, cif_objects, pdb_hierarchy):
    cif_object_d = {}
    for res in self.resname:
      for cif_object in cif_objects:
        for i, id in enumerate(cif_object['comp_list']['_chem_comp.id']):
          if res == id:
            assert res not in cif_object_d, "More than one cif file containing residue %s!" %res
            cif_object_d[res] = cif_object
      if res not in cif_object_d:
        raise Sorry("No restraints file containing residue %s!" %res)

    for res in self.resname:
      cif_object = cif_object_d[res]
      for i, id in enumerate(cif_object['comp_list']['_chem_comp.id']):
        if res == id:
          self.n_atoms.append(
            int(cif_object['comp_list']['_chem_comp.number_atoms_all'][i]) )
      comp_rname='comp_%s' %res
      assert comp_rname in cif_object, "Residue %s not in cif file!" %res
      try:
        self.partial_charges.append(
          [float(i) for i in cif_object[comp_rname]['_chem_comp_atom.partial_charge']]
          )
      except Exception:
        self.partial_charges.append( [0]*self.n_atoms[-1] )
      self.atom_elements.append(
        [i for i in cif_object[comp_rname]['_chem_comp_atom.type_symbol']]
        )
      atom_ids = \
        [i for i in cif_object[comp_rname]['_chem_comp_atom.atom_id']]
      bond_atom_1 = \
        [atom_ids.index(i) for i in cif_object[comp_rname]['_chem_comp_bond.atom_id_1']]
      bond_atom_2 = \
        [atom_ids.index(i) for i in cif_object[comp_rname]['_chem_comp_bond.atom_id_2']]
      bond_dict={'single':1, 'double':2, 'triple':3, 'aromatic':4, 'coval':1,
                 'deloc':4}
      bond_type = \
        [bond_dict[i] for i in cif_object[comp_rname]['_chem_comp_bond.type']]
      self.bonds.append( list(zip(bond_atom_1, bond_atom_2, bond_type)) )
      self.charge.append( sum(self.partial_charges[-1]) )
      self.nbonds.append ( len(self.bonds[-1]) )
      res_ids = self.get_res_ids(pdb_hierarchy, res)
      self.res_ids.append(res_ids)
      this_res_sites_cart_ptrs=[]
      for residue_instance in self.res_ids[-1]:
        this_res_sites_cart_ptrs.append( self.get_sites_cart_pointers(
                                          atom_ids,
                                          pdb_hierarchy,
                                          chain_id=residue_instance[0],
                                          altloc=residue_instance[1],
                                          resseq=residue_instance[2])
                                        )
        for ptrs in this_res_sites_cart_ptrs:
          if ptrs.count(-1)>2:
            raise Sorry("Atoms missing from %s. Likely need to add hydrogens." % res)
      self.sites_cart_ptrs.append( this_res_sites_cart_ptrs )
      this_occupancies=[]
      for ptrs in this_res_sites_cart_ptrs:
        this_occupancies.append( self.get_occupancies(ptrs, pdb_hierarchy) )
      self.occupancies.append( this_occupancies )
      if '_chem_comp_atom.charge' in cif_object[comp_rname]:
        self.formal_charges.append(
          [float(i) for i in cif_object[comp_rname]['_chem_comp_atom.charge']]
          )
      else:
        self.formal_charges.append([])

    self.total_model_atoms=pdb_hierarchy.atoms_size()


  def make_afitt_input(self, sites_cart, resname_i, instance_i):
    r_i=resname_i
    i_i=instance_i
    sites_cart_ptrs=self.sites_cart_ptrs[r_i][i_i]
    elements=self.atom_elements[r_i]
    assert len(elements) ==  len(sites_cart_ptrs), \
           "No. of atoms in residue %s, instance %d does not equal to \
           number of atom seq pointers." %(self.resname[resname_i], instance_i)
    f = StringIO()
    if len(self.covalent_data) == 0 or self.covalent_data[r_i][i_i] == None:
    # if True:
      f.write(  '%d\n' %self.n_atoms[r_i])
      f.write('residue_type %s chain %s number %d total_charge %d\n'
              %(self.resname[r_i], self.res_ids[r_i][i_i][0],1,self.charge[r_i] ))
      #~ import code; code.interact(local=dict(globals(), **locals()))
      for atom,ptr in zip(elements, sites_cart_ptrs):

        f.write('%s   %20.16f   %20.16f   %20.16f\n' %(atom,
              sites_cart[ptr][0], sites_cart[ptr][1], sites_cart[ptr][2]) )
      f.write('bond_table_nbonds %d\n' %self.nbonds[r_i])
      for bond in self.bonds[r_i]:
        f.write('%d %d %d\n' %(bond[0], bond[1], bond[2]))
      if self.formal_charges[r_i]:
        n_non_zero_charges = len([ch for ch in self.formal_charges[r_i] if ch != 0])
        f.write("formal_charges %d\n" %n_non_zero_charges)
        if self.formal_charges[r_i]:
          for i,fcharge in enumerate(self.formal_charges[r_i]):
            if fcharge != 0:
              f.write ('%d %d\n' %(i,fcharge))
      f.write('fixed_atoms 0\n')
    else:
      cov_obj =  self.covalent_data[r_i][i_i]
      # print '%d %d\n ' %(self.n_atoms[r_i] , cov_obj.n_atoms)
      f.write('%d\n' %(self.n_atoms[r_i] + cov_obj.n_atoms) )
      f.write('residue_type %s chain %s number %d total_charge %d\n'
              %(self.resname[r_i],
                self.res_ids[r_i][i_i][0],
                1,
                self.charge[r_i] + cov_obj.charge ))
      for atom,ptr in zip(elements, sites_cart_ptrs):
        f.write('%s   %20.16f   %20.16f   %20.16f\n' %(atom,
              sites_cart[ptr][0], sites_cart[ptr][1], sites_cart[ptr][2]) )
      for atom,ptr in zip(cov_obj.atom_elements, cov_obj.sites_cart_ptrs):
        f.write('%s   %20.16f   %20.16f   %20.16f\n' %(atom,
              sites_cart[ptr][0], sites_cart[ptr][1], sites_cart[ptr][2]) )
      # import code; code.interact(local=dict(globals(), **locals()))
      f.write('bond_table_nbonds %d\n'
              %(self.nbonds[r_i]+cov_obj.nbonds+1) )
      for bond in self.bonds[r_i]:
        f.write('%d %d %d\n' %(bond[0], bond[1], bond[2]))
      for bond in cov_obj.bonds:
        f.write('%d %d %d\n' %(
          bond[0] + self.n_atoms[r_i],
          bond[1] + self.n_atoms[r_i],
          bond[2]))
      f.write('%d %d %d\n' %(
          cov_obj.res_bond[0],
          cov_obj.res_bond[1],
          cov_obj.res_bond[2]))
      if self.formal_charges[r_i] or cov_obj.formal_charges:
        n_non_zero_charges = 0
        if self.formal_charges[r_i]:
          n_non_zero_charges += len([ch for ch in self.formal_charges[r_i] if ch != 0])
        if cov_obj.formal_charges:
          n_non_zero_charges += len([ch for ch in cov_obj.formal_charges if ch != 0])
        f.write("formal_charges %d\n" %n_non_zero_charges)
        if self.formal_charges[r_i]:
          for i,fcharge in enumerate(self.formal_charges[r_i]):
            if fcharge != 0:
              f.write ('%d %d\n' %(i,fcharge))
        if cov_obj.formal_charges:
          for i, fcharge in enumerate(cov_obj.formal_charges):
            if fcharge != 0:
              f.write('%d %d\n' %(i+self.n_atoms[r_i], fcharge))
      f.write('fixed_atoms %d\n' %cov_obj.n_atoms)
      for i in range(cov_obj.n_atoms):
        f.write('%d\n' %(i+self.n_atoms[r_i]))
    ##
    # ofile=open('tmpfile','w')
    # ofile.write(f.getvalue())
    # ofile.close()
    # sys.exit()
    # print f.getvalue()
    return f.getvalue()

def get_afitt_command():
  cmd = "afitt_helper_mmff help" # used because afitt_helper_mmff hangs on no input
  ero = easy_run.fully_buffered(command=cmd,
                               )
  out = StringIO()
  ero.show_stderr(out=out)
  exe = "afitt_helper_mmff"
  if out.getvalue().find("OpenEye")>-1:
    return exe
  if os.environ.get("OE_EXE", False):
    oe_dir = os.environ.get("OE_EXE")
    exe = os.path.join(oe_dir, exe)
    if os.path.exists(exe):
      return exe
  return None

def call_afitt(afitt_input, ff):
  exe = get_afitt_command()
  if exe is None:
    raise Sorry("AFITT command not found. Add to path or correctly set OE_EXE")
  cmd = '%s -ff %s' % (exe, ff)
  #print cmd
  #print afitt_input
  ero = easy_run.fully_buffered(command=cmd,
                                stdin_lines=afitt_input,
                               )
  out = StringIO()
  ero.show_stdout(out=out)
  if 'ENERGYTAG' not in out.getvalue().split():
    ero.show_stderr()
    print("AFITT energy call exited with errors printed above.")
    sys.exit()
  return out

def process_afitt_output(afitt_output,
                         geometry,
                         afitt_o,
                         resname_i,
                         instance_i,
                         afitt_allgradients,
                         afitt_alltargets,
                         verbose=False,
                         phenix_gnorms=None):
  r_i=resname_i
  i_i=instance_i
  ptrs = afitt_o.sites_cart_ptrs[r_i][i_i]
  afitt_gradients = flex.vec3_double()
  for line in afitt_output.getvalue().splitlines():
    if line.startswith('ENERGYTAG'):
       afitt_energy=float(line.split()[1])
    elif line.startswith('GRADIENTTAG'):
       afitt_gradients.append (
          (float(line.split()[1]),
           float(line.split()[2]),
           float(line.split()[3]) ) )
  ### debug_stuff
  if verbose:
    print ("AFITT_ENERGY %s_%d_%s: %10.4f\n"
                  %(afitt_o.resname[r_i],
                    int(afitt_o.res_ids[r_i][i_i][2]),
                    afitt_o.res_ids[r_i][i_i][1],
                    afitt_energy ))
  ### end_debug
  #geometry.residual_sum += afitt_energy
  #~ import inspect
  #~ for i in inspect.stack():
    #~ print i[1], i[2], i[4]
  #~ print "\n\n\n\n"
  cov_ptrs=[]
  if afitt_o.covalent_data[r_i][i_i] is not None:
    cov_ptrs= afitt_o.covalent_data[r_i][i_i].sites_cart_ptrs
  if (geometry.gradients is not None):
    # AFITT prints gradient lines for fixed atoms too so I need to check
    # that no. of gradient == ligand atoms + fixed atoms. But since the
    # fixed atom gradient's are always zero and we add gradients to the
    # Phenix gradients, I don't add code to actually do anything with the
    # fixed atom gradients. NOTE: if one day for some reason we decide to
    # replace Phenix gradients with AFITT gradients, this would need to be added.
    assert afitt_gradients.size() == len(ptrs)  +  len(cov_ptrs)
    if afitt_o.scale == 'gnorm':
      from math import sqrt
      # phenix_norm=phenix_gnorms[r_i][i_i]
      phenix_norm=0
      afitt_norm=0
      for afitt_gradient, ptr in zip(afitt_gradients, ptrs):
        phenix_norm += geometry.gradients[ptr][0]**2+geometry.gradients[ptr][1]**2+geometry.gradients[ptr][2]**2
        afitt_norm += afitt_gradient[0]**2+afitt_gradient[1]**2+afitt_gradient[2]**2
      phenix_norm = sqrt(phenix_norm)
      afitt_norm = sqrt(afitt_norm)
      gr_scale = phenix_norm/afitt_norm
      ### debug_stuff
      if verbose:
        print ("GRNORM_RATIO %s_%d_%s: %10.4f\n"
                    %(afitt_o.resname[r_i],
                      int(afitt_o.res_ids[r_i][i_i][2]),
                      afitt_o.res_ids[r_i][i_i][1],
                      gr_scale ))
        # print phenix_norm, afitt_norm
      ### end_debug
    elif afitt_o.scale == 'noafitt':
      gr_scale = None
    else:
      gr_scale = float(afitt_o.scale)

    ### debug_stuff
    print_gradients = False
    if print_gradients:
      print("\n\nGRADIENTS BEFORE AFTER AFITT\n")
      # print "NORMS: %10.4f         %10.4f\n" %(phenix_norm, afitt_norm)
      for afitt_gradient, ptr in zip(afitt_gradients, ptrs):
        print("(%10.4f %10.4f %10.4f) (%4.4f %4.4f %4.4f)" \
            %(geometry.gradients[ptr][0], geometry.gradients[ptr][1], geometry.gradients[ptr][2],
            afitt_gradient[0], afitt_gradient[1], afitt_gradient[2]))
      sys.exit()
    ### end_debug
    if gr_scale:
      scaled_gradients = []
      # occupancy = afitt_o.occupancies[r_i][i_i]
      for afitt_gradient in afitt_gradients:
        scaled_gradient = (afitt_gradient[0]*gr_scale,
                           afitt_gradient[1]*gr_scale,
                           afitt_gradient[2]*gr_scale)
        scaled_gradients.append(scaled_gradient)
      afitt_allgradients[(r_i,i_i)] = scaled_gradients
      afitt_alltargets[(r_i,i_i)] = gr_scale*afitt_energy

def apply_target_gradients(afitt_o, geometry, afitt_allgradients, afitt_alltargets):
  # import code; code.interact(local=dict(globals(), **locals()))
  # sys.exit()
  if (geometry.gradients is not None):
    for key in afitt_allgradients:
      r_i = key[0]
      i_i = key[1]
      gradients = afitt_allgradients[key]
      target = afitt_alltargets[key]
      ptrs=afitt_o.sites_cart_ptrs[r_i][i_i]
      cov_ptrs=[]
      if afitt_o.covalent_data[r_i][i_i] is not None:
        cov_ptrs= afitt_o.covalent_data[r_i][i_i].sites_cart_ptrs
      for i_seq, gradient in zip(ptrs+cov_ptrs,gradients):
        gx = gradient[0] + geometry.gradients[i_seq][0]
        gy = gradient[1] + geometry.gradients[i_seq][1]
        gz = gradient[2] + geometry.gradients[i_seq][2]
        geometry.gradients[i_seq] = (gx,gy,gz)
      geometry.residual_sum += target

  #   for i_seq in afitt_allgradients:
  #     gradient=[0,0,0]
  #     for loc in afitt_allgradients[i_seq]:
  #       gradient[0] += loc[0]
  #       gradient[1] += loc[1]
  #       gradient[2] += loc[2]
  #     if len(afitt_allgradients[i_seq]) >1:
  #       for r in range(3):
  #         gradient[r] /= len(afitt_allgradients[i_seq])
  #     gx = gradient[0] + geometry.gradients[i_seq][0]
  #     gy = gradient[1] + geometry.gradients[i_seq][1]
  #     gz = gradient[2] + geometry.gradients[i_seq][2]
  #     geometry.gradients[i_seq] = (gx,gy,gz)
  # for target in afitt_alltargets:
  #   geometry.residual_sum += afitt_alltargets[target]

  return geometry

def get_afitt_energy(cif_file,
                     ligand_names,
                     pdb_hierarchy,
                     ff,
                     sites_cart,
                     geometry=None):
  afitt_o = afitt_object(
                cif_file,
                ligand_names,
                pdb_hierarchy,
                ff)

  if geometry is not None:
    afitt_o.check_covalent(geometry)

  energies=[]
  for resname_i,resname in enumerate(afitt_o.resname):
    for instance_i, instance in enumerate(afitt_o.res_ids[resname_i]):
      #~ import code; code.interact(local=dict(globals(), **locals()))
      afitt_input = afitt_o.make_afitt_input(sites_cart,
                                             resname_i,
                                             instance_i,
                                             )
      lines = call_afitt(afitt_input, ff)
      for line in lines.getvalue().splitlines():
        if line.startswith('ENERGYTAG'):
          energy=float(line.split()[1])
      energies.append([resname, int(instance[2]), instance[1].strip(), energy] )
  return energies

def validate_afitt_params(params):
  if params.ligand_names is None:
    raise Sorry("Ligand name(s) not specified\n\t afitt.ligand_names=%s" %
                params.ligand_names)
  if params.ff not in ["mmff94", "mmff94s", "pm3", "am1"]:
    raise Sorry("Invalid force field\n\t afitt.ff=%s" % params.ff)

def get_non_afitt_selection(restraints_manager,
                            sites_cart,
                            hd_selection,
                            ignore_hd,
                            verbose=False,
                            ):
  if ignore_hd:
    general_selection = ~hd_selection
  else:
    general_selection = hd_selection|~hd_selection
  ligand_i_seqs = []
  for ligand in restraints_manager.afitt_object.sites_cart_ptrs:
    for group in ligand:
      ligand_i_seqs += group
  for i_seq in ligand_i_seqs:
    general_selection[i_seq] = False
  if verbose:
    print(restraints_manager.afitt_object)
    print("\nNumber of atoms in selection : %d" % len(list(filter(None, general_selection))))
    print(list(general_selection))
  return general_selection

def get_afitt_selection(restraints_manager,
                        sites_cart,
                        hd_selection,
                        ignore_hd,
                        verbose=False,
                        ):
  if ignore_hd:
    hd_selection = ~hd_selection
  else:
    hd_selection = hd_selection|~hd_selection
  general_selection = hd_selection&~hd_selection
  ligand_i_seqs = []
  for ligand in restraints_manager.afitt_object.sites_cart_ptrs:
    for group in ligand:
      ligand_i_seqs += group
  for i_seq in ligand_i_seqs:
    general_selection[i_seq] = True
  rc = general_selection&hd_selection
  if verbose:
    print(restraints_manager.afitt_object)
    print("\nNumber of atoms in selection : %d" % len(list(filter(None, general_selection))))
  return rc

def write_pdb_header(params, out=sys.stdout, remark="REMARK   3  "):
  print("%sAFITT PARAMETERS" % (remark), file=out)
  for attr in params.__dict__:
    if attr.find("__")==0: continue
    print("%s  %s: %s" % (remark,
                                  attr.upper(),
                                  str(getattr(params, attr)).upper(),
                                 ), file=out)
  print("%s" % remark, file=out)

def _show_gradient(g):
  return "(%9.3f %9.3f %9.3f)" % (g)

def adjust_energy_and_gradients(result,
                                restraints_manager,
                                sites_cart,
                                hd_selection,
                                afitt_o,
                                verbose=False):
  # import code; code.interact(local=dict(globals(), **locals()))
  # sys.exit()
  if result.afitt_residual_sum<1e-6:
    if verbose: 'returning without adjusting energy and gradients'
    return result
  general_selection = get_non_afitt_selection(restraints_manager, sites_cart, hd_selection, False)
  rm = restraints_manager.select(general_selection)
  old_normalisation = getattr(rm, "normalization", None)
  if old_normalisation is None:
    es = rm.energies_sites(
      sites_cart = sites_cart.select(general_selection),
      compute_gradients = True,
      normalization = False,
    )
  else:
    rm.normalization=False
    es = rm.energies_sites(
      sites_cart = sites_cart.select(general_selection),
      compute_gradients = True,
    )
    rm.normalization = old_normalisation
  protein_residual_sum = es.residual_sum
  protein_gradients = es.gradients
  #
  general_selection = get_afitt_selection(restraints_manager,
                                          sites_cart,
                                          hd_selection,
                                          False,
                                         )
  rm = restraints_manager.select(general_selection)
  old_normalisation = getattr(rm, "normalization", None)
  if old_normalisation is None:
    es = rm.energies_sites(
      sites_cart = sites_cart.select(general_selection),
      compute_gradients = True,
      normalization = False,
    )
  else:
    rm.normalization=False
    es = rm.energies_sites(
      sites_cart = sites_cart.select(general_selection),
      compute_gradients = True,
    )
    rm.normalization = old_normalisation
  ligand_residual_sum = es.residual_sum
  ligand_gradients = es.gradients
  #
  if verbose:
    print('gradients')
    print('phenix + afitt')
    for i, s in enumerate(general_selection):
      ls = ""
      if s: ls = "*"
      print("%3d %s %s" % (i+1,_show_gradient(result.gradients[i]), ls))
    print('protein-ligand complex')
    for i, s in enumerate(general_selection):
      ls = ""
      if s: ls = "*"
      print("%3d %s %s" % (i+1,_show_gradient(result.complex_gradients[i]), ls))
    print('protein only')
    for i, s in enumerate(protein_gradients):
      print("%3d %s" % (i+1,_show_gradient(s)))
    print('ligand only')
    for i, s in enumerate(ligand_gradients):
      print("%3d %s" % (i+1,_show_gradient(s)))

  result.residual_sum -= ligand_residual_sum

  ligand_i = 0
  # protein_i = 0
  if verbose:
    print("%-40s %-40s %-40s %-40s" % ("phenix protein+ligand",
                                       "phenix+afitt",
                                       "phenix ligand only",
                                       "phenix+afitt final",
                                       ))
  for i, g in enumerate(result.complex_gradients):
    if verbose:
      outl = "%5d %s %s" % (i,_show_gradient(g),str(general_selection[i])[0])
      outl += _show_gradient(result.gradients[i])
    if general_selection[i]:
      # ligand
      result.gradients[i] = (
        result.gradients[i][0] - ligand_gradients[ligand_i][0],
        result.gradients[i][1] - ligand_gradients[ligand_i][1],
        result.gradients[i][2] - ligand_gradients[ligand_i][2],
      )
      if verbose:
        outl += " %3d %s %s" % ( ligand_i,
                                 _show_gradient(ligand_gradients[ligand_i]),
                                 _show_gradient(result.gradients[i]),
                                 )
      ligand_i+=1
    if verbose: print(outl)

  if verbose:
    print('total (phenix+afitt) residual_sum',result.residual_sum)
    print(result.complex_residual_sum)
    print('complex_residual_sum', result.complex_residual_sum)
    print('afitt_residual_sum', result.afitt_residual_sum)
    print('ligand_residual_sum',ligand_residual_sum)
    print('protein_residual_sum',protein_residual_sum)
    #print 'nonbonded_residual_sum',nonbonded_residual_sum
    print('\n\n')
    print('gradients')
    print('protein only')
    for i, s in enumerate(protein_gradients):
      print("%3d %s" % (i,_show_gradient(s)))
    print('ligand only')
    for i, s in enumerate(ligand_gradients):
      print("%3d %s" % (i,_show_gradient(s)))
    print('protein-ligand complex')
    for i, s in enumerate(result.complex_gradients):
      print("%3d %s" % (i,_show_gradient(s)))
    print('unadjusted')
    for i, s in enumerate(result.gradients):
      print("%3d %s" % (i,_show_gradient(s)))

  return result

def adjusted_phenix_g_norm(geometry,
                            restraints_manager,
                            sites_cart,
                            hd_selection,
                            afitt_o,
                            verbose=False):
  from math import sqrt
  general_selection = get_afitt_selection(restraints_manager,
                                          sites_cart,
                                          hd_selection,
                                          False,
                                         )
  rm = restraints_manager.select(general_selection)
  old_normalisation = getattr(rm, "normalization", None)
  if old_normalisation is None:
    es = rm.energies_sites(
      sites_cart = sites_cart.select(general_selection),
      compute_gradients = True,
      normalization = False,
    )
  else:
    rm.normalization=False
    es = rm.energies_sites(
      sites_cart = sites_cart.select(general_selection),
      compute_gradients = True,
    )
    rm.normalization = old_normalisation
  ligand_gradients = es.gradients
  ligand_gradients_and_sites={}
  i=0
  for site in range(len(general_selection)):
    if general_selection[site]:
      ligand_gradients_and_sites[site]=ligand_gradients[i]
      i+=1



  gnorms=[]
  for resname_i,resname in enumerate(afitt_o.resname):
    gnorms.append([])
    for instance_i, instance in enumerate(afitt_o.res_ids[resname_i]):
      gnorm = 0
      ptrs = afitt_o.sites_cart_ptrs[resname_i][instance_i]
      # import code; code.interact(local=dict(globals(), **locals()))
      for ptr in ptrs:
        l1 = ligand_gradients_and_sites[ptr][0]
        l2 = ligand_gradients_and_sites[ptr][1]
        l3 = ligand_gradients_and_sites[ptr][2]
        gnorm += l1**2+l2**2+l3**2
        i+=1
      gnorm = sqrt(gnorm)
      gnorms[resname_i].append(gnorm)
  return gnorms


def finite_difference_test(pdb_file,
                           cif_file,
                           ligand_names,
                           atom,
                           scale=1,
                           verbose=False):
  from mmtbx import monomer_library
  import mmtbx.monomer_library.server
  import mmtbx.monomer_library.pdb_interpretation
  import iotbx.pdb

  mon_lib_srv = monomer_library.server.server()
  ener_lib = monomer_library.server.ener_lib()
  processed_pdb_file = monomer_library.pdb_interpretation.process(
    mon_lib_srv    = mon_lib_srv,
    ener_lib       = ener_lib,
    file_name      = pdb_file,
    raw_records    = None,
    force_symmetry = True)
  pdb_inp = iotbx.pdb.input(file_name=pdb_file)
  pdb_hierarchy = pdb_inp.construct_hierarchy()
  pdb_hierarchy.atoms().reset_i_seq()
  xrs = pdb_hierarchy.extract_xray_structure()
  sites_cart=xrs.sites_cart()

  grm = processed_pdb_file.geometry_restraints_manager(
    show_energies = False,
    plain_pairs_radius = 5.0,
    )
  afitt_o = afitt_object(
              [cif_file],
              ligand_names,
              pdb_hierarchy,
              scale=scale)
  afitt_o.check_covalent(grm)

  if verbose: print("Analytical Gradient")

  geometry = grm.energies_sites(
    sites_cart        = sites_cart,
    compute_gradients = True)
  if verbose: print("  phenix target:   %10.16f" %geometry.target)
  if verbose: print("  phenix gradient: %10.16f" %geometry.gradients[atom][0])

  geometry.complex_residual_sum = geometry.residual_sum
  geometry.complex_gradients = copy.deepcopy(geometry.gradients)
  afitt_allgradients = {}
  afitt_alltargets = {}
  for resname_i,resname in enumerate(afitt_o.resname):
    for instance_i, instance in enumerate(afitt_o.res_ids[resname_i]):
      afitt_input = afitt_o.make_afitt_input(sites_cart,
                                             resname_i,
                                             instance_i)

      lines = call_afitt(afitt_input,
                         afitt_o.ff)

      # print "pawel"
      # print afitt_o.covalent_data

      process_afitt_output(
          lines, geometry, afitt_o,
          resname_i, instance_i, afitt_allgradients, afitt_alltargets)
  if verbose: print("  afitt target:    %10.16f" %afitt_alltargets[(0,0)])
  if verbose:
    if atom in afitt_o.sites_cart_ptrs[0][0]:
      i = afitt_o.sites_cart_ptrs[0][0].index(atom)
      print("  afitt gradients: %10.16f" %afitt_allgradients[(0,0)][i][0])

  geometry = apply_target_gradients(afitt_o,
                                    geometry,
                                    afitt_allgradients,
                                    afitt_alltargets)
  geometry.afitt_residual_sum = geometry.residual_sum -\
                                geometry.complex_residual_sum
  grm.afitt_object = afitt_o
  geometry = adjust_energy_and_gradients(geometry,
                                         grm,
                                         xrs.sites_cart(),
                                         xrs.hd_selection(),
                                         afitt_o,
                                       )
  geometry.target = geometry.residual_sum


  if verbose: print("  final target:    %10.16f" %geometry.target)
  if verbose: print("  final gradient:  %10.16f" %geometry.gradients[atom][0])
  ana_gradient = geometry.gradients[atom][0]
  print("-> %10.9f"%(ana_gradient))

  if verbose: print("\nFinite Diff. Gradient")
  # finite differences
  e = 1.e-5
  site_cart_o = sites_cart[atom]
  ts = []
  phts = []
  afts = []
  for e_ in [e, -1*e]:
    if verbose: print("e = %f" %e_)
    afitt_allgradients = {}
    afitt_alltargets = {}
    site_cart = [site_cart_o[0]+e_,site_cart_o[1],site_cart_o[2]]
    sites_cart[atom] = site_cart
    geometry = grm.energies_sites(
      sites_cart        = sites_cart,
      compute_gradients = True)
    if verbose: print("  phenix target:   %10.16f" %geometry.target)
    phts.append(geometry.target)
    geometry.complex_residual_sum = geometry.residual_sum
    geometry.complex_gradients = copy.deepcopy(geometry.gradients)
    for resname_i,resname in enumerate(afitt_o.resname):
      for instance_i, instance in enumerate(afitt_o.res_ids[resname_i]):
        afitt_input = afitt_o.make_afitt_input(sites_cart,
                                               resname_i,
                                               instance_i)
        lines = call_afitt(afitt_input,
                           afitt_o.ff)
        process_afitt_output(
            lines, geometry, afitt_o,
            resname_i, instance_i, afitt_allgradients, afitt_alltargets)
    if verbose: print("  afitt target:    %10.16f" %afitt_alltargets[(0,0)])
    afts.append(afitt_alltargets[(0,0)])
    geometry = apply_target_gradients(
        afitt_o, geometry, afitt_allgradients, afitt_alltargets)
    geometry.afitt_residual_sum = geometry.residual_sum -\
                                geometry.complex_residual_sum
    grm.afitt_object = afitt_o
    geometry = adjust_energy_and_gradients(
      geometry,
      grm,
      sites_cart,
      xrs.hd_selection(),
      afitt_o,
      )
    geometry.target = geometry.residual_sum

    if verbose: print("  final target:    %10.16f" %geometry.target)
    t=geometry.target
    ts.append(t)
  if verbose: print("  phenix finite diff.: %10.16f" %((phts[0]-phts[1])/(2*e)))
  if verbose: print("  afitt finite diff.: %10.16f" %((afts[0]-afts[1])/(2*e)))
  num_gradient = (ts[0]-ts[1])/(2*e)
  print("-> %10.9f" %(num_gradient))
  gradient_diff = num_gradient - ana_gradient
  assert abs(gradient_diff) <= 1e-4, \
    "TEST FAILS: (analytical - numerical)= %10.9f" %(gradient_diff)
  print("TEST PASSES: (analytical - numerical)= %10.9f" %(gradient_diff))
  return 0

def apply(result, afitt_o, sites_cart,phenix_gnorms=None):
  result.complex_residual_sum = result.geometry.residual_sum
  # needs to be more selective!!!
  result.complex_gradients = copy.deepcopy(result.geometry.gradients)
  afitt_allgradients = {}
  afitt_alltargets = {}
  for resname_i,resname in enumerate(afitt_o.resname):
    for instance_i, instance in enumerate(afitt_o.res_ids[resname_i]):
      afitt_input = afitt_o.make_afitt_input(sites_cart,
                                                  resname_i,
                                                  instance_i,
      )
      lines = call_afitt(afitt_input, afitt_o.ff)
      process_afitt_output(lines,
                           result.geometry,
                           afitt_o,
                           resname_i,
                           instance_i,
                           afitt_allgradients,
                           afitt_alltargets,
                           verbose=False,
                           phenix_gnorms=phenix_gnorms)
  result.geometry = apply_target_gradients(afitt_o, result.geometry,
                                           afitt_allgradients,
                                           afitt_alltargets)

  # used as a trigger for adjust the energy and gradients
  result.afitt_residual_sum = result.geometry.residual_sum -\
                              result.complex_residual_sum
  #print 'Afitt'
  #print afitt_o
  return result

def bond_test(model):
  rm = model.restraints_manager
  bond_params_table = rm.geometry.bond_params_table
  bond = bond_params_table.lookup(0,1)
  print(bond.distance_ideal,bond.weight)
  bond = bond_params_table.lookup(0,10)
  print(bond)
  assert 0

def run(pdb_file, cif_file, ligand_names, ff='mmff94s',covalent=False):
  import iotbx.pdb
  assert os.path.isfile(pdb_file), "File %s does not exist." %pdb_file
  assert os.path.isfile(cif_file), "File %s does not exist." %cif_file
  pdb_inp = iotbx.pdb.input(file_name=pdb_file)
  pdb_hierarchy = pdb_inp.construct_hierarchy()
  pdb_hierarchy.atoms().reset_i_seq()
  xrs = pdb_hierarchy.extract_xray_structure()
  sites_cart=xrs.sites_cart()
  grm=None
  if covalent:
    from mmtbx import monomer_library
    import mmtbx.monomer_library.server
    import mmtbx.monomer_library.pdb_interpretation
    mon_lib_srv = monomer_library.server.server()
    ener_lib = monomer_library.server.ener_lib()
    processed_pdb_file = monomer_library.pdb_interpretation.process(
      mon_lib_srv    = mon_lib_srv,
      ener_lib       = ener_lib,
      file_name      = pdb_file,
      raw_records    = None,
      force_symmetry = True)
    grm = processed_pdb_file.geometry_restraints_manager(
      show_energies = False,
      plain_pairs_radius = 5.0,
      )
  energies = get_afitt_energy([cif_file],
                              ligand_names,
                              pdb_hierarchy,
                              ff,
                              sites_cart,
                              grm)

  for energy in energies:
    print("%s_%d_%s AFITT_ENERGY: %10.4f" %(energy[0], energy[1], energy[2], energy[3]))

def run2():
  import argparse
  parser = argparse.ArgumentParser()
  parser.add_argument("pdb_file", help="pdb file")
  parser.add_argument("cif_file", help="cif file", default=0)
  parser.add_argument("ligand_names", help="3-letter ligand names separated by commas")
  parser.add_argument("-ff", help="afitt theory: mmff94, mmff94s pm3 or am1", default='mmff94s')
  parser.add_argument('-covalent', dest='covalent', action='store_true', help="calculate covalent energy (only for debugging)")
  args = parser.parse_args()
  ligand_names=args.ligand_names.split(',')
  run(args.pdb_file, args.cif_file, ligand_names, args.ff, args.covalent)

if (__name__ == "__main__"):
  run2()


 *******************************************************************************


 *******************************************************************************
mmtbx/geometry_restraints/base_qm_manager.py
from __future__ import absolute_import, division, print_function
import os
from io import StringIO
import tempfile
import time

from libtbx.utils import Sorry
from scitbx.array_family import flex
from libtbx import adopt_init_args
from libtbx import easy_run

def dist2(xyz1, xyz2):
  d2=0
  for i in range(3):
    d2 += (xyz2[i]-xyz1[i])**2
  return d2

def get_internal_coordinate_value(atom1, atom2, atom3=None, atom4=None):
  import math
  from cctbx import geometry_restraints
  if not atom3:
    d2 = dist2(atom1.xyz, atom2.xyz)
    return math.sqrt(d2)
  elif not atom4:
    sites = [atom1.xyz, atom2.xyz, atom3.xyz]
    ang = geometry_restraints.angle(
      sites=sites,
      angle_ideal=109,
      weight=1,
      )
    return ang.angle_model
  sites = [atom1.xyz, atom2.xyz, atom3.xyz, atom4.xyz]
  dih = geometry_restraints.dihedral(
      sites=sites,
      angle_ideal=0,
      weight=1.,
      periodicity=1)
  return dih.angle_model

def loop_over_file(filename):
  f=open(filename, 'r')
  lines = f.read()
  del f
  for line in lines.splitlines():
    yield line

def process_qm_log_file(log_filename=None,
                        generator=None,
                        error_lines=None,
                        log=None,
                        verbose=False,
                        ):
  if log_filename is not None: generator=loop_over_file(log_filename)
  error_line = None
  status = None
  for i, line in enumerate(generator):
    if line.find('GEOMETRY OPTIMIZATION CYCLE')>-1:
      cycle = int(line.split()[4])
      if verbose and cycle==1: print('  QM minimisation started', file=log)
    # if line.find('Max(Improp)')>-1:
    #   conv = process_orca_convergence(last_ten)
      # if cycle%10==0:
        # print('  Opt. cycle %s %s %s %0.1fmin' % (cycle, conv, i, (time.time()-t0)/60))
    if line.find('FINAL HEAT OF FORMATION =')>-1:
      status = True
    if line.find('ORCA TERMINATED NORMALLY')>-1:
      status = True
    if line.find('* JOB ENDED NORMALLY *')>-1:
      status = True
    if error_lines:
      for el in error_lines:
        if line.find(el)>-1:
          error_line = line
          break
    if error_line: break
  if error_line:
    raise Sorry(error_line)
  if not status:
    raise Sorry('QM does not seem to have converged. Check %s' % log_filename)
  return status

def run_command(command):
    """
    execute <command> in a subprocess and check error code
    taken from ASE
    """
    from subprocess import Popen, PIPE
    if command == '':
        raise RuntimeError('no command for run_command :(')
    proc = Popen([command], shell=True, stderr=PIPE)
    proc.wait()
    exitcode = proc.returncode
    if exitcode != 0:
        error='%s exited with error code %i in %s' % (
                       command,exitcode,self.calc_dir)
        stdout,stderr = proc.communicate()
        print('shell output: ',stdout,stderr)
        raise RuntimeError(error)
    return 0

def run_qm_cmd(cmd,
               log_filename,
               error_lines=None,
               redirect_output=True,
               log=None,
               verbose=False,
               ):
  def loop_over_list(l):
    for line in l:
      yield l
  import time
  t0=time.time()
  if verbose: print('run_qm_cmd',cmd,log_filename)
  if redirect_output:
    cmd += ' >& %s' % log_filename

  print('  Starting : %s' % cmd, file=log)
  rc = easy_run.go(cmd)
  if not os.path.exists(log_filename):
    raise Sorry('QM program did not appear to write log file : %s' % log_filename)

  generator = loop_over_file(log_filename)
  # if redirect_output:
  #   generator = loop_over_file(log_filename)
  # else:
  #   generator = loop_over_list(rc.stdout_lines)

  status = process_qm_log_file(generator=generator,
                               error_lines=error_lines,
                               log=log)
  if rc.stderr_lines:
    print('stderr')
    for line in rc.stderr_lines:
      print(line)
    print('stdout')
    for line in rc.stdout_lines:
      print(line)
    assert 0
  return rc

class base_manager():
  def __init__(self,
               atoms,
               method,
               basis_set,
               solvent_model,
               charge,
               multiplicity,
               nproc=1,
               preamble=None,
               log=None,
               ):
    adopt_init_args(self, locals())
    self.times = flex.double()
    self.energies = {}
    if self.preamble is None:
      self.preamble = os.path.basename(tempfile.NamedTemporaryFile().name)
    # validate
    if self.basis_set is None: self.basis_set=''
    if self.solvent_model is None: self.solvent_model=''
    #
    self.ligand_atoms_array = None
    self.error_lines = []

  def __repr__(self):
    program = getattr(self, 'program', '')
    if program: program = ' - %s' % program
    outl = 'QI Manager%s\n' % program
    outl += ' charge: %s multiplicity: %s\n method: %s basis: "%s" solvent: "%s"\n' % (
      self.charge,
      self.multiplicity,
      self.method,
      self.basis_set,
      self.solvent_model,
      )
    residues = []
    for i, atom in enumerate(self.atoms):
      ann=''
      if self.ligand_atoms_array: ann=self.ligand_atoms_array[i]
      outl += '  %s %s\n' % (atom.quote(), ann)
      if atom.parent().id_str() not in residues:
        residues.append(atom.parent().id_str())
    outl += '  residues\n'
    outl += '\n  '.join(residues)
    return outl

  def get_charge(self): return self.charge

  def set_charge(self, charge): self.charge = charge

  def add_atoms(self, atoms, replace=False):
    if replace:
      self.atoms=atoms
    else:
      quotes = []
      for atom in self.atoms:
        quotes.append(atom.quote())
      for atom in atoms:
        assert atom.quote() not in quotes, 'found duplicate %s' % atom.quote()
      self.atoms.append(atoms)

  def set_ligand_atoms(self, selection_array):
    """Set the atoms that are ligand or the optimisation selection

    Args:
        selection_array (array): Selection array that specifies the atoms that
        will be optimised.
    """
    assert len(selection_array)==len(self.atoms)
    self.ligand_atoms_array = selection_array

  def get_energy(self, *args, **kwds): return 0, 'dirac'

  def read_energy(self, *args, **kwds): return 0, 'dirac'

  def read_charge(self, *args, **kwds): return 99

  def get_strain(self, *args, **kwds): return 0, 'dirac'

  def get_bound(self, *args, **kwds): return 0, 'dirac'

  def get_opt(self, *args, **kwds):
    import random
    rc = []
    for atom in self.atoms:
      rc.append([])
      for i in range(3):
        rc[-1].append(atom.xyz[i]+(random.random()-0.5)/10)
    rc_buffer = rc
    tmp = []
    if self.ligand_atoms_array is not None:
      for sel, atom in zip(self.ligand_atoms_array, rc):
        if sel:
          tmp.append(atom)
      rc=tmp
    return flex.vec3_double(rc), flex.vec3_double(rc_buffer)

  def get_gradients(self):
    assert 0

  def get_timings(self, energy=False):
    return '-'

  def get_lines(self, filename=None):
    if filename is None:
      filename = self.get_log_filename()
    assert os.path.exists(filename), 'filename not found %s' % filename
    f=open(filename, 'r')
    lines=f.read()
    del f
    return lines

class base_qm_manager(base_manager):

  def write_input(self, outl):
    f=open(self.get_input_filename(), 'w')
    f.write(outl)
    del f

  def check_file_read_safe(self, optimise_ligand=True, optimise_h=True, constrain_torsions=False):
    outl = self.get_input_lines(optimise_ligand=optimise_ligand,
                                optimise_h=optimise_h,
                                constrain_torsions=constrain_torsions,
                                )
    filename = self.get_input_filename()
    lines=''
    if os.path.exists(filename):
      f=open(filename, 'r')
      lines = f.read()
      del f
      if not(outl==lines):
        print('differences '*5)
        print('proposed')
        print(outl)
        print('='*80)
        print(filename)
        print(lines)
        print('filename',filename)
        print('='*80)
        for i, (line1, line2) in enumerate(zip(outl.splitlines(),lines.splitlines())):
          if line1!=line2: print(' ! %s "%s" <> "%s"' % (i+1, line1, line2))
        print('='*80)
        f, ext = os.path.splitext(filename)
        f=open('old%s' % ext, 'w')
        f.write(lines)
        del f
        f=open('new%s' % ext, 'w')
        f.write(outl)
        del f
        raise Sorry('something has changed making the QM input files different')
    return outl==lines

  def opt_setup(self, optimise_ligand=True, optimise_h=True, constrain_torsions=False):
    outl = self.get_input_lines(optimise_ligand=optimise_ligand,
                                optimise_h=optimise_h,
                                constrain_torsions=constrain_torsions,
                                )
    self.write_input(outl)

  def get_opt(self,
              optimise_h=True,
              constrain_torsions=False,
              cleanup=False,
              file_read=True,
              check_file_read_safe=True,
              coordinate_filename_ext='.xyz',
              log_filename_ext='.log',
              redirect_output=True,
              log=None,
              verbose=False):
    if self.program_goal in ['opt', 'strain']:
      optimise_ligand=True
    # elif self.program_goal in ['energy']:
    #   optimise_ligand=False
    constrain_torsions = self.exclude_torsions_from_optimisation

    coordinates = None
    rc=True
    if file_read and check_file_read_safe:
      if verbose: print('check_file_read_safe',check_file_read_safe)
      rc = self.check_file_read_safe(optimise_ligand=optimise_ligand,
                                     optimise_h=optimise_h,
                                     constrain_torsions=constrain_torsions,
                                     )
      if verbose: print('rc',rc)
    if file_read and rc:
      filename = self.get_coordinate_filename()
      if os.path.exists(filename):
        lf = self.get_log_filename()
        if os.path.exists(lf):
          process_qm_log_file(lf, log=log)
        if verbose: print('  Reading coordinates from %s\n' % filename)
        coordinates = self.read_xyz_output()
    if coordinates is None:
      if verbose: print('no coordinates')
      self.opt_setup(optimise_ligand=optimise_ligand,
                     optimise_h=optimise_h,
                     constrain_torsions=constrain_torsions,
                     )
      self.run_cmd(redirect_output=redirect_output, log=log)
      coordinates = self.read_xyz_output()
    coordinates_buffer = coordinates
    if cleanup: self.cleanup(level=cleanup)
    if self.ligand_atoms_array is not None:
      tmp = []
      for sel, atom in zip(self.ligand_atoms_array, coordinates):
        if sel:
          tmp.append(atom)
      coordinates=tmp
    return flex.vec3_double(coordinates), flex.vec3_double(coordinates_buffer)

  def get_energy(self,
                 optimise_h=True,
                 constrain_torsions=False,
                 cleanup=False,
                 file_read=True,
                 redirect_output=False,
                 log=StringIO(),
                 **kwds):
    energy=None
    old_preamble = self.preamble
    self.preamble += '_energy'
    optimise_ligand=False
    if file_read and self.check_file_read_safe(optimise_ligand=optimise_ligand,
                                               optimise_h=optimise_h,
                                               constrain_torsions=constrain_torsions,
                                               ):
      filename = self.get_log_filename()
      if os.path.exists(filename):
        if os.path.exists(filename):
          process_qm_log_file(filename, log=log)
        # print('  Reading energy from %s\n' % filename, file=log)
        energy, units = self.read_energy()
    if energy is None:
      outl = self.get_input_lines(optimise_ligand=optimise_ligand,
                                  optimise_h=optimise_h,
                                  constrain_torsions=constrain_torsions,
                                  )
      self.write_input(outl)
      self.run_cmd(redirect_output=redirect_output)
      energy, units = self.read_energy()
    if cleanup: self.cleanup(level=cleanup)
    # print('  Current energy = %0.5f %s' % (self.energy, self.units), file=log)
    self.preamble = old_preamble
    return energy, units

  def get_strain(self,
                 cleanup=False,
                 file_read=True,
                 redirect_output=False,
                 log=StringIO(),
                 **kwds):
    #
    # Get the strain energy of a ligand. Only works? when this is applied to
    # the ligand.
    #
    old_preamble = self.preamble
    #
    # get energy with just the H opt
    #
    start_energy, junk = self.get_energy(optimise_h=True,
                                         redirect_output=redirect_output,
                                         cleanup=cleanup,
                                         file_read=file_read,
                                         log=log)
    self.preamble = old_preamble+'_strain'
    #
    # optimise all atoms positions and get energy
    #
    final_energy, units = self.get_opt(redirect_output=redirect_output,
                                       cleanup=cleanup,
                                       file_read=file_read,
                                       log=log)
    final_energy, units = self.read_energy()
    self.strain = start_energy-final_energy
    self.units = units
    # print('  Strain energy = %0.5f %s' % (self.strain, self.units), file=log)
    self.preamble = old_preamble
    return self.strain, self.units

  def get_something_energy( self,
                            preamble,
                            cleanup=False,
                            file_read=True,
                            redirect_output=False,
                            log=StringIO(),
                            verbose=False,
                            **kwds
                            ):
    if verbose:
      print('get %s' % preamble)
      print(self)
    old_preamble = self.preamble
    self.preamble += '_%s' % preamble
    energy, units = self.get_energy(optimise_h=True,
                                    redirect_output=redirect_output,
                                    cleanup=cleanup,
                                    file_read=file_read,
                                    log=log)
    self.preamble = old_preamble
    return energy, units

  def get_bound(self, **kwds):
    return self.get_something_energy('bound', **kwds)

  def get_pocket(self, **kwds):
    return self.get_something_energy('pocket', **kwds)

  def get_gradients(self):
    assert 0

  def get_timings(self, energy=None):
    return '-'
    if not self.times:
      filename = self.get_log_filename()
      if os.path.exists(filename):
        f=open(filename, 'r')
        lines=f.read()
        del f
        for line in lines.splitlines():
          #TOTAL JOB TIME:          1622.77 SECONDS
          if line.find('TOTAL JOB TIME:')>-1:
            print(line)
            # print(energy)
            # if energy is None:
            #   rc=self.read_energy()
            #   print(rc)
            return '  Timings : %0.2fs' % float(line.split()[3])
      # assert 0
      return '-'
    f='  Timings : %0.2fs (%ss)' % (
      self.times[-1],
      self.times.format_mean(format='%.2f'))
    if energy:
      f+=' Energy : %0.6f' % energy
    return f

  def _is_atom_for_opt(self, i, atom, optimise_ligand=True, optimise_h=True):
    ligand_atom = self.ligand_atoms_array[i]
    if optimise_ligand:
      if ligand_atom:
        opt=1
      else:
        opt=0
    else:
      opt=0
    if optimise_h and atom.element_is_hydrogen():
      opt=1
    return opt

  def guess_bonds(self):
    bonds = []
    for i, atom1 in enumerate(self.atoms):
      bonds.append([])
      for j, atom2 in enumerate(self.atoms):
        if i==j: continue
        d2 = dist2(atom1.xyz, atom2.xyz)
        d2_limit=2.5
        if atom1.element_is_hydrogen() and atom2.element_is_hydrogen():
          continue
        elif atom1.element_is_hydrogen() or atom2.element_is_hydrogen():
          d2_limit=1.3
        elif atom1.element in ['P'] or atom2.element in ['P']:
          d2_limit=4
        if d2<d2_limit:
          bonds[i].append(j)
    # for i, atom1 in enumerate(self.atoms):
    #   print(i, atom1.quote())
    #   for j in bonds[i]:
    #     print('  - %s' % self.atoms[j].quote())
    return bonds

  def get_torsion(self, i):
    if not hasattr(self, 'bonds'):
      self.bonds = self.guess_bonds()
    if self.atoms[i].parent().resname in ['HOH']: return None
    rc = [i]
    next = i
    j=0
    while len(rc)<4:
      next_i=self.bonds[i][j]
      if next_i not in rc:
        rc.append(next_i)
        i=next_i
        j=0
      else:
        j+=1
    return rc

def main():
  # test different run methods
  from mmtbx.geometry_restraints import mopac_manager
  dat = ''' AM1 XYZ GEO-OK
 HOH.dat

 O -23.081267 1 18.356610 1 -21.628018 1
 H -22.165708 1 18.441448 1 -21.593653 1
 H -23.452909 1 18.384220 1 -20.699162 1

'''
  f=open('HOH.dat', 'w')
  f.write(dat)
  del f
  cmd = '%s HOH.dat' % mopac_manager.get_exe()
  print(cmd)
  for i, func in enumerate([os.system, run_command, run_qm_cmd]):
    print(func)
    if i==2:
      func(cmd, 'HOH.out', redirect_output=False)
    else:
      func(cmd)
    f=open('HOH.out', 'r')
    lines=f.read()
    del f
    print(lines[-150:])

if __name__ == '__main__':
  main()


 *******************************************************************************


 *******************************************************************************
mmtbx/geometry_restraints/c_beta.py
from __future__ import absolute_import, division, print_function
import cctbx.geometry_restraints
from cctbx.array_family import flex
from iotbx.pdb.amino_acid_codes import three_letter_l_given_three_letter_d
from libtbx.utils import Sorry


def get_c_beta_torsion_proxies(pdb_hierarchy,
                               selection=None,
                               sigma=2.5):
  origin_ids = cctbx.geometry_restraints.linking_class.linking_class()
  c_beta_origin_id = origin_ids.get_origin_id('C-beta')
  if (selection is not None):
    if (isinstance(selection, flex.bool)):
      actual_bselection = selection
    elif (isinstance(selection, flex.size_t)):
      actual_bselection = flex.bool(pdb_hierarchy.atoms_size(), False)
      actual_bselection.set_selected(selection, True)
    else:
      raise Sorry("Bad selection supplied for c_beta restraints")
  if selection is None:
    actual_bselection = flex.bool(pdb_hierarchy.atoms_size(), True)
  cache = pdb_hierarchy.atom_selection_cache()
  sel = cache.selection("name N or name CA or name C or name CB")
  c_beta_dihedral_proxies = \
      cctbx.geometry_restraints.shared_dihedral_proxy()
  c_beta_residues_skipped = {}
  s0 = set([' N  ', ' CA ', ' C  ', ' CB '])
  for model in pdb_hierarchy.select(sel).models():
    for chain in model.chains():
      for rg in chain.residue_groups():
        for conformer in rg.conformers():
          for residue in conformer.residues():
            if(not s0.issubset(set(residue.atoms().extract_name()))): continue
            CB_atom = residue.find_atom_by(name=" CB ")
            if residue.resname in three_letter_l_given_three_letter_d:
              c_beta_residues_skipped.setdefault("d-peptide", [])
              c_beta_residues_skipped['d-peptide'].append(CB_atom)
              continue
            CA_atom = residue.find_atom_by(name=" CA ")
            N_atom  = residue.find_atom_by(name=" N  ")
            C_atom  = residue.find_atom_by(name=" C  ")
            if(N_atom is not None and CA_atom is not None
               and C_atom is not None and CB_atom is not None):
              if not (actual_bselection[N_atom.i_seq] and
                  actual_bselection[CA_atom.i_seq] and
                  actual_bselection[C_atom.i_seq] and
                  actual_bselection[CB_atom.i_seq] ):
                continue
              # check for correct chiral volume
              sites_cart = [N_atom.xyz, C_atom.xyz, CA_atom.xyz, CB_atom.xyz]
              CAC_dist = C_atom.distance(CA_atom)
              if CAC_dist>2.:
                c_beta_residues_skipped.setdefault('CA---C', [])
                c_beta_residues_skipped['CA---C'].append(CB_atom)
                continue
              chiral = cctbx.geometry_restraints.chirality(
                sites_cart,
                volume_ideal=0.,
                both_signs=True,
                weight=1.,
                )
              if(chiral.volume_model<0):
                c_beta_residues_skipped.setdefault("-ve", [])
                c_beta_residues_skipped["-ve"].append(CB_atom)
                continue
              dihedralNCAB, dihedralCNAB = get_cb_target_angle_pair(
                                             resname=residue.resname)
              #NCAB
              i_seqs = [N_atom.i_seq,C_atom.i_seq,CA_atom.i_seq,CB_atom.i_seq]
              dp_add = cctbx.geometry_restraints.dihedral_proxy(
                i_seqs=i_seqs,
                angle_ideal=dihedralNCAB,
                weight=1/sigma**2,
                origin_id=c_beta_origin_id)
              c_beta_dihedral_proxies.append(dp_add)
              #CNAB
              i_seqs = [C_atom.i_seq,N_atom.i_seq,CA_atom.i_seq,CB_atom.i_seq]
              dp_add = cctbx.geometry_restraints.dihedral_proxy(
                i_seqs=i_seqs,
                angle_ideal=dihedralCNAB,
                weight=1/sigma**2,
                origin_id=c_beta_origin_id)
              c_beta_dihedral_proxies.append(dp_add)
  return c_beta_dihedral_proxies, c_beta_residues_skipped # BAD

def get_cb_target_angle_pair(resname):
  target_angle_dict = {
    "ALA" : (122.9, -122.6),
    "PRO" : (115.1, -120.7),
    "VAL" : (123.4, -122.0),
    "THR" : (123.4, -122.0),
    "ILE" : (123.4, -122.0),
    "GLY" : (121.6, -121.6)
  }
  dihedralNCAB, dihedralCNAB = target_angle_dict.get(resname, (122.8, -122.6))
  return dihedralNCAB, dihedralCNAB


 *******************************************************************************


 *******************************************************************************
mmtbx/geometry_restraints/external.py

"""
Accessory module for interfacing phenix.refine (or similar programs) with
various external third-party software such as AFITT, DivCon, Schrodinger.
"""

from __future__ import absolute_import, division, print_function
import libtbx.load_env
import os

VERBOSE=False

external_energy_params_str = ""

amber_installed = False
if libtbx.env.has_module("amber_adaptbx"):
  build_dir = libtbx.env.under_build("amber_adaptbx")
  try: import sander
  except ImportError as e: sander = False
  if sander:
  #if (build_dir is not None) and (os.path.isdir(build_dir)):
    amber_installed = True

if VERBOSE:
  print(libtbx.env.has_module("amber_adaptbx"))

if (amber_installed):
  external_energy_params_str += """
    amber
      .help = Parameters for using Amber in refinement.
      .expert_level = 3
    {
      include scope amber_adaptbx.master_phil_str
    }
"""

qb_installed = os.environ.get("QBHOME", False)
if qb_installed: qb_installed = os.path.isdir(qb_installed)
if (qb_installed):
  external_energy_params_str += """
    qbio
      .short_caption = QuantumBio refinement plugin
    {
      include scope qbpy.qb_params.qblib_master_params
    }
"""

#afitt
afitt_installed=False
if os.environ.get("OE_EXE", None):
  if os.path.exists(os.environ["OE_EXE"]):
    afitt_installed = True

if (afitt_installed):
  external_energy_params_str += """
    afitt
      .help = Parameters for using AFITT ligand gradients.
      .expert_level = 3
    {
      include scope mmtbx.geometry_restraints.afitt.master_phil_str
    }
"""

# Schrodinger
def is_schrodinger_installed(env):
  """
  Check if Schrodinger is installed and interface requested. Schrodinger is
  installed if SCHRODINGER env variable is set to root directory and if
  PHENIX_SCHRODINGER env variable is set.

  Parameters
  ----------
  env: dict
     Environment dictionary

  Returns
  -------
  out : bool
    Boolean indicating if Schrodinger is installed and requested.
  """
  return (
     env.get('PHENIX_SCHRODINGER', False)
     and env.get("SCHRODINGER", False)
     and os.path.exists(env["SCHRODINGER"])
  )

schrodinger_installed = is_schrodinger_installed(os.environ)
if schrodinger_installed:
  from glob import glob
  paths = glob(os.path.join(
      os.environ["SCHRODINGER"], 'psp-v*', 'data', 'phenix'))
  if len(paths) == 1:
    import sys
    sys.path.append(paths[0])
  try:
    import phenix_schrodinger
    external_energy_params_str += """
    schrodinger
      .help = Parameters for using Schrodinger's force fields.
      .expert_level = 3
    {
      include scope phenix_schrodinger.master_phil_str
    }
"""
  except ImportError:
    schrodinger_installed = False

from mmtbx.geometry_restraints.quantum_interface import is_any_quantum_package_installed

any_quantum_package_installed = is_any_quantum_package_installed(os.environ)
if any_quantum_package_installed:
  external_energy_params_str += any_quantum_package_installed

if __name__=='__main__':
  print('external_energy_params_str',external_energy_params_str)
  assert external_energy_params_str.find('amber')>-1


 *******************************************************************************


 *******************************************************************************
mmtbx/geometry_restraints/geo_file_parsing.py
from __future__ import division
from collections import defaultdict
from itertools import chain
import shlex
import re
from libtbx import group_args
from libtbx.utils import Sorry
from cctbx import geometry_restraints
from cctbx.geometry_restraints.linking_class import linking_class
from cctbx.array_family import flex
from cctbx import crystal
from cctbx.crystal import direct_space_asu

origin_ids = linking_class()


class Entry:
  """
  1. Base class for an 'entry' in a geo file. Analogous to both a proxy and restraint
    Entry is subclasses for each type of entry that may be encountered during geo file parsing.
    The functions for parsing and value type conversion are implemented on the subclasses

  2. Accessing the 'entry.record' attribute will return a plain dict with all relevant data

  3. Atom labels can appear in two lists:
    a. self.atom_labels: The raw atom label strings,  often atom.id_str()
    b. self.i_seqs: The integer i_seqs coming from:
                      a. The .geo file if all atom labels are also ints
                      b. A model file provided upon initialization and id_str labels

  4. Implement a method to convert entry object to cctbx proxy object (self.to_proxy())
  """

  def __init__(self,lines,origin_id=0,origin_label="covalent"):
    """
    An entry is initialized first, then data is added with entry.lines.append()

    Attributes:
      origin_id (int): the integer origin id for an entry
    """
    # Parsing data structures
    self.lines = lines               # raw .geo lines
    self.i_seqs = []                 # list of integer i_seqs (if possible)
    self.sites_cart = None           # Flex vec3 array, coord for each i_seq if available
    self.atom_labels  = []           # list of string atom label from .geo
    self._numerical = None           # a dict of numerical geo data
    self.origin_id = origin_id
    self.origin_label = origin_label

    # Initialize result data structures
    self._proxy = None
    self._record = None

    self._prepare()

    # Check if labels are i_seqs (integers)
    labels_are_i_seqs, self.i_seqs = self._check_labels_are_i_seqs(self.atom_labels)
    if labels_are_i_seqs:
      self.atom_labels = []

  def labels_are_available(self):
    return len(self.atom_labels)>0

  def i_seqs_are_available(self):
    return len(self.i_seqs)>0

  def _prepare(self):
    # Parse Atom labels
    values = []
    for line in self.lines[:-2]:
      if not line.startswith(" "):
        line = line.replace(line.split()[0],"") # remove name like 'bond', 'angle'
      value = line.strip()
      values.append(value)

    self.atom_labels = values

    # Numerical labels
    labels = self.lines[-2]
    numerical_labels = labels.split()

    # Numerical values
    values = self.lines[-1]
    numerical_values =  values.split()
    numerical_values = [coerce_type(v) for v in numerical_values]
    self._numerical = dict(zip(numerical_labels,numerical_values))

  def _check_labels_are_i_seqs(self,atom_labels):
    """
    If all the labels are integers, assume i_seqs
    """
    i_seqs = [try_int(v) for v in atom_labels]
    check =   all([isinstance(i_seq,int)  for i_seq in i_seqs])
    if not check:
      i_seqs = []
    return check, i_seqs

  @property
  def record(self):
    """
    A dictionary representation of an entry
      Atom labels are split up into single atom key:value pairs
    """
    if not self._record:
      d = {
        "i_seqs":self.i_seqs,
        "atom_labels":self.atom_labels,
        }
      d.update(self._numerical)
      d["origin_id"] = self.origin_id
      self._record = d
    return self._record



  @property
  def ideal(self):
    """
    Provide the restraint ideal value
    """
    return float(self._numerical["ideal"])

  @property
  def weight(self):
    """
    Provide the restraint weight value
    """
    return float(self._numerical["weight"])


  @property
  def proxy(self):
    """
    Only create a proxy object if necessary, and if so only do it once
    """
    if not self._proxy and self.i_seqs_are_available():
      self._proxy = self.to_proxy()
    return self._proxy

### Start of Entry subclasses

class NonBondedEntry(Entry):
  pass

class AngleEntry(Entry):

  def to_proxy(self):
    proxy = geometry_restraints.angle_proxy(
    i_seqs=self.i_seqs,
    angle_ideal=self.ideal,
    weight=self.weight,
    origin_id=self.origin_id)
    return proxy


class BondEntry(Entry):

  def has_sym_op(self):
    if "sym.op." in self._numerical.keys() and self._numerical["sym.op."] not in ["",None]:
      return True
    else:
      return False

  def to_proxy(self):
    if self.has_sym_op():
      asu_mappings = direct_space_asu.non_crystallographic_asu_mappings(
      sites_cart=self.sites_cart)
      pair_generator = crystal.neighbors_fast_pair_generator(
      asu_mappings=asu_mappings,
      distance_cutoff=5)
      pair = geometry_restraints.bond_asu_proxy(
        pair=next(pair_generator),
        distance_ideal=self.ideal,
        weight=self.weight,
        origin_id=self.origin_id)
      proxy = geometry_restraints.bond_asu_proxy(pair=pair, params=pair)
      return proxy

    else:
      proxy = geometry_restraints.bond_simple_proxy(
              i_seqs=self.i_seqs,
              distance_ideal=self.ideal,
              weight=self.weight,
              origin_id=self.origin_id,
              )
    return proxy

class DihedralEntry(Entry):

  def is_harmonic(self):
    return "harmonic" in self._numerical.keys()

  def is_sinusoidal(self):
    return "sinusoidal" in self._numerical.keys()

  @property
  def periodicity(self):
    if self.is_harmonic():
      return int(self._numerical["harmonic"])
    else:
      return int(self._numerical["sinusoidal"])

  def to_proxy(self):
    proxy = geometry_restraints.dihedral_proxy(
      i_seqs=self.i_seqs,
      angle_ideal=self.ideal,
      weight=self.weight,
      periodicity=self.periodicity,
      alt_angle_ideals=None,
      origin_id=self.origin_id)
    return proxy


class ChiralityEntry(Entry):

  @property
  def both_signs(self):
    return bool(self._numerical["both_signs"])

  def to_proxy(self):
    proxy = geometry_restraints.chirality_proxy(
      i_seqs=self.i_seqs,
      volume_ideal=self.ideal,
      weight=self.weight,
      both_signs=self.both_signs,
      origin_id=self.origin_id
      )
    return proxy

class PlaneEntry(Entry):
  """
  Planes are very different because they can have varying number of atoms
    Most methods must be overridden
  """
  name = "plane"


  def _prepare(self):
    """
    Interpret lines from a Plane entry.
    """

    self.atom_labels = []
    nums = [[None]*5 for l in range(len(self.lines)-1)] # 5 values
    for i,line in enumerate(self.lines[1:]):
      line = line.replace("plane","")
      pdb_part = re.search(r'pdb="([^"]*)"', line)
      if pdb_part:
        pdb_value = pdb_part.group(0)  # Preserve the whole pdb="..." string
        remaining_line = line.replace(pdb_value, "")

        parts = shlex.split(remaining_line)
        parts.insert(0, pdb_value)
        # check seg id
        if len(parts)>1:
          if "segid=" in parts[1]:
            parts = [" ".join(parts[0:2])] + parts[2:]

      else:
        # No pdb="..." part
        parts = shlex.split(line)
      comp_value = parts[0]

      self.atom_labels.append(comp_value.strip())
      for j,p in enumerate(parts[1:]):
        nums[i][j] = p

    line = self.lines[0]
    numerical_labels = line.strip().split()

    # fill empty values down columns
    for i,row in enumerate(nums):
      if i>0:
        nums[i][-2] = nums[0][-2]
        nums[i][-1] = nums[0][-1]
    nums_T = list(map(list, zip(*nums))) # transpose
    numerical_values = nums_T

    numerical_values = [[coerce_type(v) for v in vals] for vals in numerical_values]
    self._numerical = dict(zip(numerical_labels,numerical_values))

  @property
  def n_atoms(self):
    # Override for planes
    return len(self.atom_labels)


  @property
  def weights(self):
    return [float(w) for w in self._numerical["weight"]]

  def to_proxy(self):
    proxy = geometry_restraints.planarity_proxy(
        i_seqs=self.i_seqs,
        weights=self.weights,
        origin_id=self.origin_id,
    )
    return proxy

class ParallelityEntry(Entry):

  def __init__(self,*args,**kwargs):
    """
    Parallelity is special because there are two sets of atoms for each plane i, j
    Here, self.i_seqs is only the first plane, not all atoms as in other entries.
    """
    self._atom_labels = []

    # add extra fields for 'j' atoms
    self.j_seqs = []
    self.atom_labels_i = []
    self.atom_labels_j = []
    super().__init__(*args,**kwargs)
    labels_are_i_seqs, self.i_seqs = self._check_labels_are_i_seqs(self.atom_labels)
    if labels_are_i_seqs:
      self.atom_labels_i = []
      self.atom_labels_j = []
    self.i_seqs, self.j_seqs = self.i_seqs # unpack tuple


  @property
  def atom_labels(self):
    return self.atom_labels_i + self.atom_labels_j

  @atom_labels.setter
  def atom_labels(self,value):
    self._atom_labels = value

  def _prepare(self):
    """
    Interpret lines from a Parallelity entry.
    """
    line0 = self.lines[0]
    line1 = self.lines[1]
    plane_2_idx = line0.index("plane 2")

    all_parts = []
    for line in self.lines[1:]:
      pdb_parts = re.findall(r'pdb="([^"]*)"', line)

      if len(pdb_parts) >= 1:
        pdb_value_i = 'pdb="{}"'.format(pdb_parts[0])

        remaining_line = line.replace(pdb_value_i, "", 1)

        if len(pdb_parts) == 2:
          pdb_value_j = 'pdb="{}"'.format(pdb_parts[1])

          remaining_line = remaining_line.replace(pdb_value_j, "", 1)
          parts = shlex.split(remaining_line)

          parts.insert(0, pdb_value_i)
          parts.insert(1, pdb_value_j)
        else:
          # Only one pdb="..." found, handle just pdb_value_i
          parts = shlex.split(remaining_line)
          parts.insert(0, pdb_value_i)

      else:
        # No pdb="..." part found, just split the line
        parts = shlex.split(line)
      all_parts.append(parts)

    for i,row in enumerate(all_parts):
      val = row[0].replace("parallelity","").strip()
      self.atom_labels_i.append(val)

    for j,row in enumerate(all_parts):
      if len(row)>1:
        val = row[1].replace("parallelity","").strip()
        self.atom_labels_j.append(val)

    num_idx = plane_2_idx+len("plane 2")
    num_labels = shlex.split(line0[num_idx:])
    num_values = all_parts[0][2:]

    num_values = [coerce_type(v) for v in num_values]
    self._numerical = dict(zip(num_labels,num_values))

  def _check_labels_are_i_seqs(self,*args):
    """
    If all the labels are integers, assume i_seqs
    """
    check_func = super()._check_labels_are_i_seqs
    check_i, i_seqs = check_func(self.atom_labels_i)
    check_j, j_seqs = check_func(self.atom_labels_j)
    check = check_i and check_j
    return check, (i_seqs, j_seqs)

  @property
  def n_atoms(self):
    return len(self.atom_labels_i) + len(sel.atom_labels_j)

  def to_proxy(self):
    proxy = geometry_restraints.parallelity_proxy(
        i_seqs=self.i_seqs,
        j_seqs=self.j_seqs,
        weight=10, # Can get from .geo?
        origin_id=self.origin_id,
    )
    return proxy

  @property
  def record(self):
    """
    A dictionary representation of an entry
      Atom labels are split up into single atom key:value pairs
    """
    d = {
      "i_seqs":self.i_seqs,
      "j_seqs":self.j_seqs,
      "atom_labels_i":self.atom_labels_i,
      "atom_labels_j":self.atom_labels_j,
      }
    d.update(self._numerical)
    d["origin_id"] = self.origin_id
    return d

### End Entry classes

entry_config_default = {
  # Keys: The name of the restraint class in the geo header
  #
  # entry_class: An Entry subclass, defines parsing function and handles value type conversion
  # entry_trigger: a unique text field in a .geo file which indicates the start of a new entry
  "Nonbonded": {
    "entry_class": NonBondedEntry,
    "entry_trigger": "nonbonded"
  },
  "Bond angle": {
    "entry_class": AngleEntry,
    "entry_trigger": "angle"
  },
  "Bond": {
    "entry_class": BondEntry,
    "entry_trigger": "bond"
  },
  "Dihedral angle": {
    "entry_class": DihedralEntry,
    "entry_trigger": "dihedral"
  },
  "Chirality": {
    "entry_class": ChiralityEntry,
    "entry_trigger": "chirality"
  },
  "Parallelity": {
    "entry_class": ParallelityEntry,
    "entry_trigger": "plane 1"
  },
  "Planarity": {
    "entry_class": PlaneEntry,
    "entry_trigger": "delta"
  }
}


class GeoParser:
  """
  A container class to hold parsed geometry entries, and to implement
    the parsing functions. The full functionality is to go:
    .geo text file ==> cctbx proxy objects

  Usage:
    parser = GeoParser(geo_lines)     # Initialize
    entries = container.entries       # Access data as Entry instances
    records = container.records       # Access data as plain dictionaries


    proxies = container.proxies       # Access data as proxy objects, if possible
  """


  def __init__(self,geo_lines,model=None,entry_config=None):
    """
     Initialize with a list of Entry subclasses

     Params:
       geo_lines (list):             List of line strings from .geo file
       model (mmtbx.model.manager):  Optional model file, a source of atom_label: i_seq matching.
       entry_config (dict):          Configuration dict
    """

    # Set initial arguments
    self.entry_config = (entry_config if entry_config else entry_config_default)
    self.model = model

    # Initialize parsing variables
    self.lines = geo_lines + ["\n"]

    # Initialize result variables
    self.entries = defaultdict(list) # Entry instances
    self._proxies = None             # cctbx geometry proxies
    self._records = None             # dictionaries

    # Parse the file
    self._parse()

    # If model present, add i_seqs
    if self.model:
      self._fill_labels_from_model(self.model)
      self._fill_sites_cart_from_model(self.model)

  @property
  def proxies(self):
    return self._proxies

  def has_proxies(self):
    return self.proxies is not None

  def i_seqs_are_available(self):
    return all([entry.i_seqs_are_available() for entry in self.entries_list])

  def _fill_sites_cart_from_model(self,model):
    # Verify iseqs
    if not self.i_seqs_are_available():
      self._fill_labels_from_model(model)
    # get sites cart
    sites_cart = model.get_sites_cart()
    for entry in self.entries_list:
      entry.sites_cart = sites_cart.select(flex.size_t(entry.i_seqs))


  def _fill_labels_from_model(self, model):
    """
    Add i_seq attributes for each atom on each entry
    """
    if not self.i_seqs_are_available():
      # make i_seq:id_str mapping
      map_idstr_to_iseq = {
        atom.id_str():atom.i_seq for atom in model.get_atoms()}

      for entry in self.entries_list:
        # Case where entry was loaded with id_strs, can load i_seqs
        labels_are_id_strs = True
        for val in entry.atom_labels:
          if val not in map_idstr_to_iseq:
            labels_are_id_strs = False

        if labels_are_id_strs:
          entry.i_seqs = [map_idstr_to_iseq[idstr] for idstr in entry.atom_labels]

  @property
  def entries_list(self):
    """
    Coalesce all entries (of all restraint entry types) into ao single list
    """
    return list(chain.from_iterable(self.entries.values()))

  @property
  def records_list(self):
    """
    Coalesce all records into ao single list
    """
    return list(chain.from_iterable(self.records.values()))

  @property
  def proxies_list(self):
    """
    Coalesce all proxies into ao single list
    """
    if self.proxies is not None:
      return list(chain.from_iterable(self.proxies.values()))

  def _end_entry(self, entry_start_line_number, i, entries_info):
    # check that this is not the first line of the block
    if entry_start_line_number != -1:
      # Create an entry
      lines_for_entry = self.lines[entry_start_line_number:i]
      new_entry = entries_info.entry_class(
          lines=lines_for_entry,
          origin_id=entries_info.origin_id,
          origin_label=entries_info.origin_label,
          )
      # add new_entry to somewhere
      self.entries[entries_info.origin_header].append(new_entry)
    return i

  def _parse(self):
    entries_info=None
    entry_start_line_number = -1
    for i, l in enumerate(self.lines):
      if entries_info is None:
        # new block starts because we don't know entries_info

        # Query linking class with line
        result = origin_ids.get_origin_label_and_internal(l)
        if result:
          # if recognized as header, unpack result, store in entries_info
          origin_id, header, label, num = result
          entry_class = self.entry_config[header]["entry_class"]
          entry_trigger = self.entry_config[header]["entry_trigger"]
          entries_info = group_args(
              entry_class = entry_class,
              origin_id = origin_id,
              origin_label = label,
              origin_header = header,
              entry_trigger = entry_trigger,
              )
          entry_start_line_number = -1

      elif l.startswith("Sorted by"):
        pass
      elif l.strip() == "":
        # block ends
        entry_start_line_number = self._end_entry(entry_start_line_number, i, entries_info)
        entries_info=None
      elif l.strip().startswith(entries_info.entry_trigger):
        # entry ends, the next is coming
        entry_start_line_number = self._end_entry(entry_start_line_number, i, entries_info)
      else:
        # entry continues, do nothing
        pass

  @property
  def records(self):
    """
    Express the restraint entries as a dict of lists of dicts (records).
      This ONLY uses the entry object, not the proxies/grm.
      Meaning the only data present will be what was parsed.
    """
    if not self._records:
      record_dict = {}
      for entry_name, entries in self.entries.items():
        if len(entries)>0:
          record_dict[entry_name] = [entry.record for entry in entries]
      self._records = record_dict
    return self._records


  def build_proxies(self):
    """
    Convert the entry objects to cctbx proxy objects.
      Collect into a dict of lists of proxies.
    """
    if not self.model and not self.i_seqs_are_available():
      raise Sorry("Cannot build proxies without instantiating with a model.")
    self._proxies = defaultdict(list)
    for entries in self.entries.values():
      if len(entries)>0:
        entry_class = entries[0].__class__
      if hasattr(entry_class,"to_proxy") and not hasattr(entry_class,"ignore"):
        self._proxies[entry_class.__name__] = [entry.proxy for entry in entries]
    return self.proxies


def try_int(val):
  """
  Try to convert to int
  """
  try:
    return int(val)
  except (ValueError, TypeError):
    return None

def try_float(val):
  """
  Try to convert to flaot
  """
  try:
    return float(val)
  except (ValueError, TypeError):
    return None

def try_numeric(val):
  """
  Try to convert input to 1) int, 2) float
  Otherwise return None
  """
  out = try_int(val)
  if out is not None:
    return out
  out = try_float(val)
  if out is not None:
    return out
  return None

def coerce_type(val):
  """
  If input can be numeric, convert it
  Else return unmodified
  """
  out = try_numeric(val)
  if out is not None:
    return out
  return val # input (probably string)


 *******************************************************************************


 *******************************************************************************
mmtbx/geometry_restraints/mopac_manager.py
from __future__ import absolute_import, division, print_function
import os
import time

from scitbx.array_family import flex
from mmtbx.geometry_restraints import base_qm_manager

import libtbx.load_env
from libtbx import Auto

from mmtbx.geometry_restraints.base_qm_manager import get_internal_coordinate_value

def get_exe():
  bin_dir = libtbx.env.under_base('bin')
  exe_path = os.path.join(bin_dir, 'mopac')
  bin_dir = libtbx.env.under_base('Library')
  win_exe_path = os.path.join(bin_dir,"bin", 'mopac.exe')
  if os.environ.get('PHENIX_MOPAC', False):
    return os.environ['PHENIX_MOPAC']
  elif os.path.exists(exe_path):
    return exe_path
  elif os.path.exists(win_exe_path):
    return win_exe_path
  return False

class mopac_manager(base_qm_manager.base_qm_manager):
  def get_coordinate_filename(self):
    return 'mopac_%s.arc' % self.preamble

  def get_log_filename(self):
    return 'mopac_%s.out' % self.preamble

  def _input_header(self):
    if self.nproc==0:
      nproc_str=''
    else:
      nproc_str='THREADS=%s' % self.nproc
    multiplicity_str=''
    if self.multiplicity not in [None, Auto]:
      multiplicity_str=[None,
                        'singlet', # - 0 unpaired electrons
                        'doublet', # - 1 unpaired electrons
                        'triplet', # - 2 unpaired electrons
                        'quartet', # - 3 unpaired electrons
                        'quintet', # - 4 unpaired electrons
                        'sextet', # - 5 unpaired electrons
                        ][self.multiplicity]
    outl = '%s %s %s %s DISP %s\n%s\n\n' % (
     self.method,
     self.basis_set,
     self.solvent_model,
     'CHARGE=%s %s' % (self.charge, nproc_str),
     multiplicity_str,
     self.preamble,
     )
    return outl

  def get_coordinate_lines(self,
                           optimise_ligand=True,
                           optimise_h=True,
                           constrain_torsions=False,
                           verbose=False):
    outl = ''
    for i, atom in enumerate(self.atoms):
      opt = self._is_atom_for_opt(i,
                                  atom,
                                  optimise_ligand=optimise_ligand,
                                  optimise_h=optimise_h)
      tmp = ''
      if constrain_torsions:
        def _get_B_A_D(torsions, round_d=False):
          b=get_internal_coordinate_value(self.atoms[torsions[0]],
                                          self.atoms[torsions[1]],
                                          )
          a=get_internal_coordinate_value(self.atoms[torsions[0]],
                                          self.atoms[torsions[1]],
                                          self.atoms[torsions[2]],
                                          )
          d=get_internal_coordinate_value(self.atoms[torsions[0]],
                                          self.atoms[torsions[1]],
                                          self.atoms[torsions[2]],
                                          self.atoms[torsions[3]],
                                          )
          if round_d:
            if abs(d)<45:
              d=0.
            elif abs(180-abs(d))<45:
              d=180.
            else:
              assert 0
          return b,a,d
        bad=None
        if opt and not atom.element_is_hydrogen():
          torsions = self.get_torsion(i)
          # C         1.5 0 120 1 180 1 2 5 3
          bad=list(_get_B_A_D(torsions))
          bad.insert(0, atom.element)
        if opt and atom.element_is_hydrogen():
          ligand_atom = self.ligand_atoms_array[i]
          if ligand_atom and atom.name in [' HD1', ' HE2']:
            torsions = self.get_torsion(i)
            bad = list(_get_B_A_D(torsions, round_d=True))
            bad.insert(0, atom.element)
        if bad:
          tmp = ' %s %12.5f 1 %12.5f 1 %12.5f 0' % tuple(bad)
          for j in torsions[1:]: tmp += ' %s' % (j+1)
          tmp += '\n'
      if tmp:
        outl += tmp
      else:
        outl += ' %s %0.5f %d %0.5f %d %0.5f %d\n' % (
          atom.element,
          atom.xyz[0],
          opt,
          atom.xyz[1],
          opt,
          atom.xyz[2],
          opt,
          )
      if verbose and ligand_atom: print(atom.quote())
    outl += '\n'
    return outl

  def get_input_lines(self, optimise_ligand=True, optimise_h=True, constrain_torsions=False):
    outl = self._input_header()
    outl += self.get_coordinate_lines(optimise_ligand=optimise_ligand,
                                      optimise_h=optimise_h,
                                      constrain_torsions=constrain_torsions,
                                      )
    return outl

  def get_input_filename(self):
    return 'mopac_%s.mop' % self.preamble

  def read_xyz_output(self, verbose=False):
    filename = self.get_coordinate_filename()
    filename = filename.replace('.arc', '.out')
    if not os.path.exists(filename):
      raise Sorry('QM output filename not found: %s' % filename)
    if verbose: print('reading %s' % filename)
    f=open(filename, 'r')
    lines = f.read()
    del f
    rc = flex.vec3_double()
    read_xyz = False
    i_done = 1e9
    for i, line in enumerate(lines.splitlines()):
      if i>i_done and not line.strip(): read_xyz=False
      if read_xyz:
        if line.find('NO.       ATOM           X           Y           Z')>-1: continue
        tmp = line.split()
        if len(tmp) in [5]:
          rc.append((float(tmp[2]), float(tmp[3]), float(tmp[4])))
      if line.find('CARTESIAN COORDINATES')>-1:
        read_xyz=True
        i_done=i+2
    return rc

  def get_cmd(self):
    cmd = '%s mopac_%s' % (
      get_exe(),
      self.preamble,
      )
    return cmd

  def run_cmd(self, redirect_output=False, log=None):
    t0=time.time()
    cmd = self.get_cmd()
    base_qm_manager.run_qm_cmd(cmd,
                               'mopac_%s.out' % self.preamble,
                               error_lines=self.error_lines,
                               redirect_output=redirect_output,
                               log=log,
                               )
    self.times.append(time.time()-t0)

  def read_energy(self, filename=None):
    lines = self.get_lines(filename=filename)
    # FINAL HEAT OF FORMATION =       -132.17152 KCAL/MOL =    -553.00562 KJ/MOL
    for line in lines.splitlines():
      if line.find('FINAL HEAT OF FORMATION = ')>-1:
        self.energy = float(line.split()[5])
        self.units = line.split()[6].lower()
    return self.energy, self.units

  def read_charge(self, filename=None):
    lines = self.get_lines(filename=filename)
    #  CHARGE ON SYSTEM =
    for line in lines.splitlines():
      if line.find('CHARGE ON SYSTEM = ')>-1:
        self.charge = float(line.split()[5])
        break
    return self.charge

  def validate_atomic_charges(self, filename=None):
    '''
                 NET ATOMIC CHARGES AND DIPOLE CONTRIBUTIONS

  ATOM NO.   TYPE          CHARGE      No. of ELECS.   s-Pop       p-Pop
    1          C          -0.691089        4.6911     1.10997     3.58112
    2          C           0.963519        3.0365     1.15413     1.88235
    3          O          -0.111514        6.1115     1.65968     4.45183
    4          H           0.405761        0.5942     0.59424
    5          H           0.399617        0.6004     0.60038
    6          H           0.404684        0.5953     0.59532
    7          H           1.000000        0.0000     0.00000
    8          H           1.000000        0.0000     0.00000
    9          H           0.629022        0.3710     0.37098
 DIPOLE           X         Y         Z       TOTAL
 POINT-CHG.    29.803  -147.398  -116.121   189.996
 HYBRID         0.786     0.431     0.475     1.015
 SUM           30.590  -146.966  -115.646   189.496'''
    lines = self.get_lines(filename=filename)
    reading=False
    for line in lines.splitlines():
      if reading:
        print(line)
        assert 0
      if line.find('ATOM NO.   TYPE          CHARGE      No. of ELECS.')>-1:
        reading=True

  def validate_calculation(self):
    self.validate_atomic_charges()

  def read_gradients(self, filename=None):
    lines = self.get_lines(filename=filename)
    print(lines)
    assert 0

  def cleanup(self, level=None, verbose=False):
    if level=='all':
      assert 0

if __name__ == '__main__':
  exe = get_exe()
  print('mopac executable',exe)


 *******************************************************************************


 *******************************************************************************
mmtbx/geometry_restraints/orca_manager.py
from __future__ import absolute_import, division, print_function
import os
import time

from libtbx.utils import Sorry
from scitbx.array_family import flex
from mmtbx.geometry_restraints import base_qm_manager

class orca_manager(base_qm_manager.base_qm_manager):

  error_lines = [
                  'ORCA finished by error termination in GSTEP',
                  '-> impossible',
                  'SCF NOT CONVERGED AFTER',
                  'SERIOUS PROBLEM IN SOSCF',
                ]
  def get_input_filename(self): return 'orca_%s.in' % self.preamble

  def get_coordinate_filename(self): return 'orca_%s.xyz' % self.preamble

  def get_log_filename(self): return 'orca_%s.log' % self.preamble

  def read_engrad_output(self):
    '''#
# Number of atoms
#
 5
#
# The current total energy in Eh
#
    -49.737578240166
#
# The current gradient in Eh/bohr
#
       0.009609074575
       0.007643624367
      -0.019142934602
       0.010258288141
      -0.020537435105
      -0.000346851479
       0.000773577750
       0.021293697927
       0.011393000407
      -0.018928466970
      -0.006660132835
       0.008456622796
      -0.001712473496
      -0.001739754355
      -0.000359837122
#
# The atomic numbers and current coordinates in Bohr
#
   8    59.0407136   72.7582356   32.5750991
   8    57.8558553   75.8403789   29.3417777
   8    58.8800869   71.4618835   28.1663680
   8    62.2022254   74.3474953   29.5553167
  16    59.4829095   73.6048329   29.8973572'''
    f=open('orca_%s.engrad' % self.preamble, 'r')
    lines = f.read()
    del f
    lines = lines.split('#')

    energy = None
    gradients = flex.vec3_double()
    for line in lines[6].splitlines():
      if len(line.strip()):
        energy = float(line)
        break
    tmp=[]
    for line in lines[9].splitlines():
      if len(line.strip()):
        tmp.append(float(line)*harkcal*bohrang)
        if len(tmp)==3:
          gradients.append(tmp)
          tmp=[]

    self.energy = energy
    self.gradients = gradients
    return self.energy, self.gradients

  def read_charge(self):
    filename = self.get_log_filename()
    f=open(filename, 'r')
    lines=f.readlines()
    del f
    #Sum of atomic charges:   -1.0000000
    for line in lines:
      if line.find('Sum of atomic charges:')>-1:
        if len(line.split())==5:
          self.charge = float(line.split()[-1])
        else:
          self.charge = 99
    return self.charge

  def read_energy(self):
    filename = self.get_log_filename()
    f=open(filename, 'r')
    lines=f.readlines()
    del f
    for line in lines:
      if line.find('FINAL SINGLE POINT ENERGY')>-1:
        if len(line.split())==5:
          self.energy = float(line.split()[-1])
        else:
          self.energy = 1e-9
        self.units = 'Hartree'
    return self.energy, self.units

  def read_xyz_output(self):
    filename = self.get_coordinate_filename()
    if not os.path.exists(filename):
      raise Sorry('QM output filename not found: %s' % filename)
    f=open(filename, 'r')
    lines = f.read()
    del f
    rc = flex.vec3_double()
    for i, line in enumerate(lines.splitlines()):
      if i>=2:
        tmp = line.split()
        rc.append((float(tmp[1]), float(tmp[2]), float(tmp[3])))
    return rc

  def get_cmd(self):
    cmd = '%s orca_%s.in' % (
      os.environ['PHENIX_ORCA'],
      self.preamble,
      )
    return cmd

  def run_cmd(self, redirect_output=True, log=None):
    t0=time.time()
    cmd = self.get_cmd()
    assert redirect_output
    base_qm_manager.run_qm_cmd(cmd,
                               'orca_%s.log' % self.preamble,
                               error_lines=self.error_lines,
                               redirect_output=redirect_output,
                               log=log,
                               )
    self.times.append(time.time()-t0)

  def _input_header(self):
    standard_options = '''%scf maxiter=500

SOSCFStart 0.00033 # Default value of orbital gradient is 0.0033. Here reduced by a factor of 10.

end
'''
    outl = '%s\n! %s %s %s %s\n\n' % (standard_options,
                                       self.method,
                                       self.basis_set,
                                       self.solvent_model,
                                       ['Opt', 'LooseOpt'][1],
                                       )
    return outl

  def get_coordinate_lines(self, optimise_ligand=True, optimise_h=True, constrain_torsions=False):
    outl = '* xyz %s %s\n' % (self.charge, self.multiplicity)
    for i, atom in enumerate(self.atoms):
      outl += ' %s %0.5f %0.5f %0.5f # %s %s\n' % (
        atom.element,
        atom.xyz[0],
        atom.xyz[1],
        atom.xyz[2],
        atom.id_str(),
        i,
        )
    outl += '*\n'
    return outl

  def get_input_lines(self, optimise_ligand=True, optimise_h=True, constrain_torsions=False):
    outl = self._input_header()
    outl += self.get_coordinate_lines(optimise_ligand=optimise_ligand,
                                      optimise_h=optimise_h,
                                      constrain_torsions=constrain_torsions,
                                      )
    freeze_outl = '''%geom
      Constraints
'''
    added = 0
    for i, (sel, atom) in enumerate(zip(self.ligand_atoms_array, self.atoms)):
      if optimise_h and atom.element in ['H', 'D']: continue
      opt = self._is_atom_for_opt(i,
                                  atom,
                                  optimise_ligand=optimise_ligand,
                                  optimise_h=optimise_h)
      tmp=''
      if constrain_torsions:
        if opt and atom.element not in ['H', 'D']:
          torsions = self.get_torsion(i)
          tmp = '{D %d %d %d %d C } # Constraining dihedral' % tuple(torsions)
          tmp += ' "%s %s %s" :' % (atom.parent().parent().parent().id,
                                    atom.parent().parent().resseq.strip(),
                                    atom.parent().resname,
                                    )
          for j in torsions: tmp += ' %s' % self.atoms[j].name.strip()
          tmp += '\n'
      if tmp:
        freeze_outl += tmp
      if sel and optimise_ligand: continue
      freeze_outl += '{C %d C} # Constraining xyz %s\n' % (i, atom.id_str())
      added+=1
    freeze_outl += 'end\nend\n'
    if added: outl+=freeze_outl
    assert outl.find('Opt')>-1
    return outl

  def get_engrad(self):
    outl = '! %s %s %s EnGrad\n\n' % (self.method,
                                      self.basis_set,
                                      self.solvent_model)
    outl += self.get_coordinate_lines()
    if outl in self.energies:
      self.times.append(0)
      return self.energies[outl]
    self.write_input(outl)
    self.run_cmd()
    energy, gradients = self.read_engrad_output()
    self.print_timings(energy)
    self.energies[outl] = (energy, gradients)
    return energy, gradients

  def cleanup(self, level=None, verbose=False):
    if not self.preamble: return
    if level is None: return
    #
    tf = 'orca_%s.trj' % self.preamble
    if os.path.exists(tf):
      uf = 'orca_%s_trj.xyz' % self.preamble
      # print('rename',tf,uf)
      os.rename(tf, uf)
    most_keepers = ['.xyz', '.log', '.in', '.engrad', '.trj']
    for filename in os.listdir('.'):
      if filename.startswith('orca_%s' % self.preamble):
        if level=='most':
          name, ext = os.path.splitext(filename)
          if ext in most_keepers: continue
        if verbose: print('  removing',filename)
        os.remove(filename)

  def view(self, cmd, ext='.xyz'):
    # /Applications/Avogadro.app/Contents/MacOS/Avogadro
    print(cmd)
    tf = 'orca_%s' % self.preamble
    print(tf)
    filenames =[]
    for filename in os.listdir('.'):
      if filename.startswith(tf) and filename.endswith(ext):
        filenames.append(filename)
    filenames.sort()
    print(filenames)
    cmd += ' %s' % filenames[-1]
    easy_run.go(cmd)


 *******************************************************************************


 *******************************************************************************
mmtbx/geometry_restraints/qi_utils.py
from __future__ import absolute_import, division, print_function
import os

def classify_histidine(hierarchy, resname='HIS'):
  from mmtbx.validation.rotalyze import rotalyze
  result = rotalyze(
      pdb_hierarchy=hierarchy,
      quiet=False)
  names = []
  for rot in result.results:
    if rot.resname!=resname: continue
    names.append(rot.rotamer_name)
  hs=0
  ha=None
  for atom in hierarchy.atoms():
    if atom.parent().resname!=resname: continue
    if atom.name.strip() in ['HD1', 'HE2']:
      hs+=1
      ha=atom.name.strip()
  assert len(names)==1
  if hs==2: ha = 'HD1, HE2'
  return names[0], ha

def run_hbond(args):
  from iotbx.cli_parser import run_program
  from mmtbx.programs.hbond import Program
  hbonds = run_program(program_class=Program,
                       args=tuple(args),
                       )
  return hbonds

def run_serial_or_parallel(func, argstuples, nproc=1, log=None):
  import time
  from libtbx import easy_mp
  if nproc==-1: assert 0, 'testing using %s' % nproc
  rc = []
  name = func.__name__.replace('_',' ')
  if nproc==1:
    for i, args in enumerate(argstuples):
      t0=time.time()
      # print('  Running "%s" job %d' % (name, i+1), file=log)
      res = func(*args)
      rc.append(res)
      # print('    Time for job %d: %0.1fs' % (i+1, time.time()-t0), file=log)
  elif nproc>1:
    print('  Running %d jobs on %d procs' % (len(argstuples), nproc), file=log)
    i=0
    t0=time.time()
    for args, res, err_str in easy_mp.multi_core_run( func,
                                                      argstuples,
                                                      nproc,
                                                      keep_input_order=True):
      assert not err_str, '\n\nDebug in serial :\n%s' % err_str
      print('  Running "%s" job %d : %0.1fs' % (name, i+1, time.time()-t0), file=log)
      rc.append(res)
      i+=1
  return rc

def get_hbonds_via_filenames(filenames, nq_or_h, nproc=1, restraint_filenames=None):
  assert nproc>0
  argstuples = []
  for i, filename in enumerate(filenames):
    assert os.path.exists(filename), '"%s"' % filename
    argstuples.append([[filename,
                       '--quiet',
                       'output_pymol_file=True',
                       'output_restraint_file=False',
                       'output_skew_kurtosis_plot=False',
                       'min_data_size=0',
                       'prefix=%s' % filename.replace('.pdb',''),
                       ]])
    if restraint_filenames:
      argstuples[-1][-1]+=restraint_filenames

  rc = run_serial_or_parallel(run_hbond, argstuples, nproc=nproc)

  i=0
  hbondss=[]
  pymols = ''
  for i, filename in enumerate(filenames):
    hbondss.append(rc[i])
    pf = filename.replace('.pdb', '.pml')
    assert os.path.exists(pf), 'file not found %s' % pf
    f=open(pf, 'a')
    f.write('\n')
    f.write('show sticks, resn %s\n' % nq_or_h)
    del f
    pymols += '  phenix.pymol %s &\n' % pf
  return hbondss, pymols

def get_rotamers_via_filenames(filenames, selection, resname='HIS'):
  from iotbx import pdb
  rotamers=[]
  for i, filename in enumerate(filenames):
    hierarchy = pdb.input(filename).construct_hierarchy()
    asc1 = hierarchy.atom_selection_cache()
    sel = asc1.selection(selection)
    hierarchy = hierarchy.select(sel)
    rc = classify_histidine(hierarchy, resname=resname)
    rotamers.append(rc[0])
    i+=1
  return rotamers


 *******************************************************************************


 *******************************************************************************
mmtbx/geometry_restraints/qm_manager.py
from __future__ import absolute_import, division, print_function
from libtbx.utils import Sorry
from mmtbx.geometry_restraints import base_qm_manager, mopac_manager, orca_manager

harkcal = 627.50946900
bohrang = 0.52918
#
# QM runner
#
def qm_runner(qmm,
              cleanup=True,
              file_read=False,
              check_file_read_safe=True,
              log=None,
              ):
  def get_func(manager, attr):
    return getattr(manager, 'get_%s' % attr, None)
  redirect_output=True
  # fake
  coordinate_filename_ext='.nwm'
  log_filename_ext='.nwm'
  if qmm.program=='test':
    func = get_func(base_qm_manager.base_manager, qmm.program_goal)
  elif qmm.program=='orca':
    func = get_func(orca_manager.orca_manager, qmm.program_goal)
    coordinate_filename_ext='.xyz'
    log_filename_ext='.log'
    # raise Sorry('Orca temporarily unsupported. Consider using MOPAC.')
  elif qmm.program=='mopac':
    func = get_func(mopac_manager.mopac_manager, qmm.program_goal)
    coordinate_filename_ext='.arc' # maybe better from .out?
    log_filename_ext='.out'
    redirect_output=False
  else:
    raise Sorry('QM program not found or set "%s"' % qmm.program)
  if func is None:
    raise Sorry('QM manager does not have get_%s' % qmm.program_goal)
  ligand_xyz, buffer_xyz = func(qmm,
                                cleanup=cleanup,
                                file_read=file_read,
                                check_file_read_safe=check_file_read_safe,
                                coordinate_filename_ext=coordinate_filename_ext,
                                log_filename_ext=log_filename_ext,
                                redirect_output=redirect_output,
                                log=log)
  return ligand_xyz, buffer_xyz

def main():
  from iotbx import pdb
  pdb_lines = '''
HETATM   97  S   SO4 A  13      31.477  38.950  15.821  0.50 25.00           S
HETATM   98  O1  SO4 A  13      31.243  38.502  17.238  0.50 25.00           O
HETATM   99  O2  SO4 A  13      30.616  40.133  15.527  0.50 25.00           O
HETATM  100  O3  SO4 A  13      31.158  37.816  14.905  0.50 25.00           O
HETATM  101  O4  SO4 A  13      32.916  39.343  15.640  0.50 25.00           O
'''
  pdb_inp = pdb.input(lines=pdb_lines, source_info='lines')
  qi_grm = orca_manager(pdb_inp.atoms(),
                        'PM3',
                        '',
                        '',
                        -2,
                        1,
                        preamble='test',
                        )
  print(qi_grm)
  energy, gradients = qi_grm.get_engrad()
  print(energy, list(gradients))
  coordinates = qi_grm.get_opt()
  print(list(coordinates))

if __name__ == '__main__':
  main()


 *******************************************************************************


 *******************************************************************************
mmtbx/geometry_restraints/quantum_interface.py
from __future__ import absolute_import,division, print_function
import os
from libtbx import Auto

from mmtbx.geometry_restraints import mopac_manager

def env_exists_exists(env, var, check=True):
  if check:
    orca_env = env.get(var, False)
    if not orca_env: return orca_env
    if orca_env.find('LD_LIBRARY_PATH')>-1:
      lib, orca_env = orca_env.split()
    if os.path.exists(orca_env): return True
    # return (env.get(var, False) and os.path.exists(env[var]))
  else:
    return env.get(var, False)

def is_orca_installed(env, var):
  return env_exists_exists(env, var)

def is_mopac_installed(env, var):
  if mopac_manager.get_exe():
    return True
  else:
    return env_exists_exists(env, var)

def is_qm_test_installed(env, var):
  return True #env_exists_exists(env, var, check=False)

program_options = {
  'orca' : (is_orca_installed, 'PHENIX_ORCA'),
  'mopac' : (is_mopac_installed, 'PHENIX_MOPAC'),
  'test' : (is_qm_test_installed, 'PHENIX_QM_TEST'),
  }

def get_qm_restraints_scope(validate=True, verbose=False):
  qm_package_scope = '''
  package
  {
    program = %s
      .type = choice
    charge = Auto
      .type = int
    multiplicity = Auto
      .type = int
    method = Auto
      .type = str
    basis_set = Auto
      .type = str
    solvent_model = None
      .type = str
    nproc = 1
      .type = int
    read_output_to_skip_opt_if_available = False
      .type = bool
    ignore_input_differences = False
      .type = bool
    view_output = None
      .type = str
  }
'''

  qm_restraints_scope = '''
qm_restraints
  .multiple = True
{
  selection = None
    .type = atom_selection
    .help = selection for core of atoms to calculate new restraints via a QM \
            geometry minimisation
  run_in_macro_cycles = *first_only first_and_last all last_only test
    .type = choice
    .help = the steps of the refinement that the restraints generation is run
  buffer = 3.5
    .type = float
    .help = distance to include entire residues into the enviroment of the core
  specific_atom_charges
    .optional = True
    .multiple = True
    .short_caption = Specify the charge for a specific atom (mostly metal ions)
    .style = auto_align
  {
    atom_selection = None
      .type = atom_selection
      .input_size = 400
    charge = None
      .type = int
  }
  specific_atom_multiplicities
    .optional = True
    .multiple = True
    .short_caption = Specify the multiplicity for a specific atom (mostly metal ions). \
    Selection is not needed but is great for bookkeeping.
    .style = auto_align
  {
    atom_selection = None
      .type = atom_selection
      .input_size = 400
    multiplicity = None
      .type = int
  }

  calculate = *in_situ_opt starting_energy final_energy \
starting_strain final_strain starting_bound final_bound \
starting_binding final_binding \
starting_higher_single_point final_higher_single_point
    .type = choice(multi=True)
    .help = Choose QM calculations to run
    .caption = in_situ_optimisation_of_selection \
      starting_energy_of_isolated_ligand final_energy_of_isolated_ligand \
      strain_energy_of_starting_ligand_geometry \
      strain_energy_of_final_ligand_geometry \
      starting_energy_of_bound_ligand_cluster \
      starting_binding_energy_of)ligand final_binding_energy_of_ligand \
      final_energy_of_bound_ligand_cluster not_implemented not_implemented

  write_files = *restraints pdb_core pdb_buffer pdb_final_core pdb_final_buffer
    .type = choice(multi=True)
    .help = which ligand or cluster files to write
    .caption = restraints_file \
      input_ligand_in_PDB_format input_cluster_in_PDB_format \
      final_ligand_in_PDB_format final_cluster_in_PDB_format

  protein_optimisation_freeze = *all None main_chain main_chain_to_beta main_chain_to_delta torsions
    .type = choice(multi=True)
    .help = the parts of protein residues that are frozen when an amino \
            acid is the main selection
    .caption = all None N_CA_C_O N_CA_CB_C_O N_CA_CB_CD_C_O all_torsions

  remove_water = False
    .type = bool
    .style = hidden

  restraints_filename = Auto
    .type = path
    .style = new_file
    .help = restraints filename is based on model name if not specified
  cleanup = all *most None
    .type = choice
  ignore_x_h_distance_protein = False
    .type = bool
    .help = skip check on transfer of proton during QM optimisation
  ignore_lack_of_h_on_ligand = False
    .type = bool
    .help = skip check on protonation of ligand for entities such as MgF3
  capping_groups = True
    .type = bool

  freeze_specific_atoms
    .optional = True
    .multiple = True
    .short_caption = specify atoms of the main selection frozen in optimisation
    .caption = can be used to freeze a ligand from moving too far. use Auto \
               to freeze the atom closest to the centre of mass.
    .style = auto_align
  {
    atom_selection = None
      .type = atom_selection
      .input_size = 400
  }

  include_nearest_neighbours_in_optimisation = False
    .type = bool
    .short_caption = include protein side chain in ligand optimisation
    .help = include the side chains of protein in the QM optimisation

  include_inter_residue_restraints = False
    .type = bool
    .short_caption = include residue (including metal) linking in restraints \
                     update

  do_not_update_restraints = False
    .type = bool
    .style = hidden
    .help = For testing and maybe getting strain energy of standard restraints
  buffer_selection = None
    .type = atom_selection
    .help = use this instead of distance from selection
    .style = hidden
  %s
}
'''
  programs = ''
  for package, (func, var) in program_options.items():
    if func(os.environ, var):
      if package=='mopac':
        programs += ' *%s' % package
      else:
        programs += ' %s' % package
  if verbose: print(programs)
  if validate:
    assert programs, 'Need to set some parameters for QM programs %s' % program_options
  qm_package_scope = qm_package_scope % programs
  qm_restraints_scope = qm_restraints_scope % qm_package_scope
  return qm_restraints_scope

master_phil_str = get_qm_restraints_scope()

def electrons(model,
              specific_atom_charges=None,
              specific_atom_multiplicities=None,
              log=None):
  from libtbx.utils import Sorry
  from mmtbx.ligands import electrons
  atom_valences = electrons.electron_distribution(
    model.get_hierarchy(), # needs to be altloc free
    model.get_restraints_manager().geometry,
    specific_atom_charges=specific_atom_charges,
    specific_atom_multiplicities=specific_atom_multiplicities,
    log=log,
    verbose=False,
  )
  rc = atom_valences.validate(ignore_water=True,
                              raise_if_error=False)
  # rc = atom_valences.report(ignore_water)
  if rc:
    print('''
  Unusual atom valences
%s
    ''' % str(atom_valences), file=log)
    print(atom_valences)
    for key, item in rc.items():
      print('  %s' % key, file=log)
      for i in item:
        print('    %s' % i[0], file=log)
    # raise Sorry('Unusual charges found')
  charged_atoms = atom_valences.get_charged_atoms()
  print('''
  Complete valence picture
%s
  '''% (atom_valences.show()), file=log)
  return atom_valences.get_total_charge()

def get_safe_filename(s, compact_selection_syntax=True):
  import string
  assert compact_selection_syntax
  if compact_selection_syntax:
    s=s.replace('chain', '')
    s=s.replace('resid', '')
    s=s.replace('resseq', '')
    s=s.replace('resname', '')
    s=s.replace('and', '')
  while s.find('  ')>-1:
    s=s.replace('  ',' ')
  if s[0]==' ': s=s[1:]
  s=s.replace(' ','_')
  for i in range(26):
    a=string.ascii_uppercase[i]
    s=s.replace("'%s'"%a, a)
  s=s.replace("'",'_prime_')
  s=s.replace('*','_star_')
  s=s.replace('(','_lb_')
  s=s.replace(')','_rb_')
  s=s.replace('=', '_equals_')
  s=s.replace(':', '_colon_')
  s=s.replace('"', '_quote_')
  while s.find('__')>-1:
    s=s.replace('__','_')
  return s

def populate_qmr_defaults(qmr):
  def default_defaults(qmr):
    if qmr.package.basis_set is Auto:
      qmr.package.basis_set=''
    if qmr.package.solvent_model is Auto:
      qmr.package.solvent_model=''
    # if qmr.package.multiplicity is Auto:
    #   qmr.package.multiplicity=1
    # if qmr.package.charge is Auto:
    #   qmr.package.charge=0
  program = qmr.package.program
  if program=='test':
    pass
  elif program=='orca':
    default_defaults(qmr)
    if qmr.package.method is Auto:
      qmr.package.method='AM1'
      qmr.package.method='PBEh-3c'
  elif program=='mopac':
    default_defaults(qmr)
    if qmr.package.method is Auto:
      qmr.package.method='PM7'
      qmr.package.method='PM6-D3H4'
  else:
    assert 0
  return qmr

def get_working_directory(model, params, prefix=None):
  rc = 'qm_work_dir'
  return rc
  if prefix is None:
    prefix = getattr(params.output, 'prefix', None)
  if prefix is not None:
    rc='%s_%s' % (prefix, rc)
  return rc

def get_total_multiplicity(qmr):
  tm = 0
  macs = qmr.specific_atom_multiplicities
  for mac in macs:
    tm += mac.multiplicity
  return max(tm,1)

def get_preamble(macro_cycle, i, qmr, old_style=False, compact_selection_syntax=True):
  qmr = populate_qmr_defaults(qmr)
  s=''
  if macro_cycle is not None:
    s+='%02d_' % macro_cycle
  # else:
  #   s+='00_'
  if old_style:
    s+='%02d_%s_%s' % (i+1, get_safe_filename(qmr.selection), qmr.buffer)
  else:
    s+='%s_%s' % (get_safe_filename(qmr.selection,
                                    compact_selection_syntax=compact_selection_syntax),
                  qmr.buffer)
  if qmr.capping_groups:
    s+='_C'
  if qmr.include_nearest_neighbours_in_optimisation:
    s+='_N'
  if 'main_chain_to_delta' in qmr.protein_optimisation_freeze:
    s+='_D'
  elif 'main_chain_to_beta' in qmr.protein_optimisation_freeze:
    s+='_B'
  elif 'main_chain' in qmr.protein_optimisation_freeze:
    s+='_S'
  if 'torsions' in qmr.protein_optimisation_freeze:
    s+='_T'
  if qmr.package.method is not Auto:
    s+='_%s' % get_safe_filename(qmr.package.method)
  if qmr.package.basis_set is not Auto and qmr.package.basis_set:
    s+='_%s' % get_safe_filename(qmr.package.basis_set)
  if qmr.package.solvent_model is not Auto and qmr.package.solvent_model:
    s+='_%s' % get_safe_filename(qmr.package.solvent_model)
  multiplicity=get_total_multiplicity(qmr)
  if multiplicity!=1:
    s+='_%s' % (multiplicity)
  return s

def is_any_quantum_package_installed(env):
  installed = []
  actions = []
  outl = ''
  for key, (question, var) in program_options.items():
    if question(os.environ, var):
      installed.append(key)
  if installed:
    # refine_buffer_hydrogen_atoms = False
    #   .type = bool
    #   .style = hidden
    outl = '''
  qi
    .help = QM
    .expert_level = 3
  {
    working_directory = None
      .type = path
      .style = hidden
      .caption = not implemented
    %s
  }
''' % get_qm_restraints_scope()
  return outl

def validate_qm_restraints(qm_restraints, verbose=False):
  """Simple check for active QM restraints

  Args:
      qm_restraints (PHIL list): List of QM restraints PHIL scopes
      verbose (bool, optional): D'oh

  Returns:
      TYPE: Description
  """
  for i, qmr in enumerate(qm_restraints):
    if verbose: print(i, qmr.selection)
    if i==0 and qmr.selection is None:
      return False
  return True

def is_quantum_interface_active(params, verbose=False):
  """Checks whether the QI is active at all

  Args:
      params (PHIL): PHIL scope with a possible 'qi' scope
      verbose (bool, optional): D'oh

  Returns:
      TYPE: False or True and the type of QI active
  """
  if not hasattr(params, 'qi'):
    if verbose: assert 0
    return False
  if len(params.qi.qm_restraints):
    if validate_qm_restraints(params.qi.qm_restraints, verbose=verbose):
      return True, 'qm_restraints' # includes restraints and energy
  return False

def is_quantum_interface_active_this_macro_cycle(params,
                                                 macro_cycle,
                                                 energy_only=False,
                                                 verbose=False):
  from mmtbx.geometry_restraints.quantum_restraints_manager import running_this_macro_cycle
  qi = is_quantum_interface_active(params)
  if verbose: print('qi',qi,'energy_only',energy_only,'macro_cycle',macro_cycle)
  if qi:
    rc = []
    if qi[1]=='qm_restraints':
      number_of_macro_cycles = 1
      if hasattr(params, 'main'):
        number_of_macro_cycles = params.main.number_of_macro_cycles
      for i, qmr in enumerate(params.qi.qm_restraints):
        pre_refinement=True
        if energy_only and macro_cycle==number_of_macro_cycles:
          pre_refinement=False
        tmp = running_this_macro_cycle(qmr,
                                       macro_cycle,
                                       number_of_macro_cycles,
                                       energy_only=energy_only,
                                       pre_refinement=pre_refinement,
                                       verbose=verbose)
        if verbose: print(tmp)
        if tmp: rc.append(True)
    else:
      assert 0
    return rc
  else:
    return False

class unique_item_list(list):
  def append(self, item):
    if item not in self:
      list.append(self, item)

def get_qi_macro_cycle_array(params, verbose=False, log=None):
  from mmtbx.geometry_restraints.quantum_restraints_manager import running_this_macro_cycle
  qi = is_quantum_interface_active(params)
  if not qi: return {}
  if hasattr(params, 'main'):
    number_of_macro_cycles = params.main.number_of_macro_cycles
  else:
    number_of_macro_cycles = 1
  if qi:
    data={}
    for i, qmr in enumerate(params.qi.qm_restraints):
      data[qmr.selection]=[]
      rc=[]
      for j in range(number_of_macro_cycles+1):
        rc.append(unique_item_list())
        yn = running_this_macro_cycle(qmr, j, number_of_macro_cycles)
        if yn:
          rc[j].append(yn)
        pre_refinement=(j!=number_of_macro_cycles)
        yn = running_this_macro_cycle(qmr, j, number_of_macro_cycles,
                                           energy_only=True,
                                           pre_refinement=pre_refinement)
        if yn:
          for k in range(len(yn)):
            yn[k]=yn[k].split('_')[-1]
          rc[j]+=yn
      data[qmr.selection] = rc
      if verbose:
        print('    %s' % qmr.selection, file=log)
        for j, actions in enumerate(rc):
          if actions:
            print('      %2d : %s' % (j, ' '.join(actions)), file=log)
    if 0:
      for key, item in data.items():
        print(key, item)
  return data

def digester(model, geometry, params, log=None):
  active, choice = is_quantum_interface_active(params)
  assert active
  if not model.has_hd():
    from libtbx.utils import Sorry
    raise Sorry('Model must have Hydrogen atoms')
  if choice=='qm_restraints':
    from mmtbx.geometry_restraints import quantum_restraints_manager
    geometry = quantum_restraints_manager.digester(model,
                                                   geometry,
                                                   params,
                                                   log=log)
  else:
    assert 0
  return geometry

def main():
  print('testing QI')
  for var, item in program_options.items():
    if item[1] in os.environ: os.environ.pop(item[1])
  assert 'PHENIX_ORCA' not in os.environ
  rc = is_any_quantum_package_installed(os.environ)
  assert not rc
  for var1, item1 in program_options.items():
    os.environ[item1[1]]=os.getcwd()
    for var2, item2 in program_options.items():
      os.environ[item2[1]]=os.getcwd()
      rc = is_any_quantum_package_installed(os.environ)
      rc = get_qm_restraints_scope(verbose=True)
      # print(rc)
      os.environ.pop(item2[1])
    if item1[1] in os.environ: os.environ.pop(item1[1])

if __name__ == '__main__':
  main()


 *******************************************************************************


 *******************************************************************************
mmtbx/geometry_restraints/quantum_restraints_manager.py
from __future__ import absolute_import,division, print_function
from io import StringIO
import time
import os

from libtbx import Auto
from libtbx.str_utils import make_header
from libtbx.utils import Sorry
from libtbx.utils import null_out
from libtbx import group_args
from cctbx.geometry_restraints.manager import manager as standard_manager
from cctbx.array_family import flex
from mmtbx.geometry_restraints import quantum_interface
from mmtbx.geometry_restraints import qm_manager
from mmtbx.geometry_restraints import mopac_manager
from mmtbx.geometry_restraints import orca_manager

from mmtbx.model.restraints import get_restraints_from_model_via_grm

import iotbx
get_class = iotbx.pdb.common_residue_names_get_class

from scitbx.matrix import col

WRITE_STEPS_GLOBAL=False

def predict_time(x,y):
  coeff_str = '''
[ 1.15779091e+02 -4.56245017e+00 -1.64820657e+00  2.16405554e-02
  5.61327262e-03  3.52624540e-02]
  '''
  coeff_str=coeff_str.replace('[','').replace(']','')
  coeffs = []
  for s in coeff_str.split(): coeffs.append(float(s))
  variables = [1, x, y, x**2, y**2, x*y]
  rc = 0
  for coeff, var in zip(coeffs,variables): rc += coeff*var
  return rc

def dist2(r1,r2): return (r1[0]-r2[0])**2+(r1[1]-r2[1])**2+(r1[2]-r2[2])**2
def min_dist2(residue_group1, residue_group2, limit=1e-2):
  min_d2=1e9
  min_ca_d2=1e9
  for atom1 in residue_group1.atoms():
    for atom2 in residue_group2.atoms(): # ligand but could be more than one rg!!!
      d2 = dist2(atom1.xyz, atom2.xyz)
      if d2<limit and min_ca_d2<1e9: return d2, min_ca_d2
      min_d2 = min(min_d2, d2)
      if atom1.name.strip()=='CA':
        min_ca_d2 = min(min_ca_d2, d2)
  return min_d2, min_ca_d2

class manager(standard_manager):
  def __init__(self,
               params,
               log=StringIO()
               ):
    pass

  def __repr__(self):
    return 'QM restraints manager'

  def cleanup(self, log=StringIO()):
    make_header('Cleaning up - QM restraints', out=log)
    assert 0

def digester(model,
             standard_geometry_restraints_manager,
             params,
             log=StringIO(),
             ):
  #
  # Digest
  #
  sgrm = standard_geometry_restraints_manager
  qm_grm = manager(params, log=log)
  for attr, value in list(vars(sgrm).items()):
    if attr.startswith('__'): continue
    setattr(qm_grm, attr, value)
  qm_grm.standard_geometry_restraints_manager = sgrm
  #
  make_header('QM Restraints Initialisation', out=log)
  qm_restraints_initialisation(params, log=log)
  run_program=True
  for i, qmr in enumerate(params.qi.qm_restraints):
    if qmr.run_in_macro_cycles=='test': break # REMOVE AFTER TESTING!!!
  else: run_program=False
  run_energies(model,
               params,
               run_program=run_program,
               # transfer_internal_coordinates=transfer_internal_coordinates,
               log=log,
              )
  return qm_grm

def get_prefix(params, user_prefix=None):
  if hasattr(params, 'output') and hasattr(params.output, 'prefix'):
    prefix = params.output.prefix
  else:
    prefix = 'qmr'
  return prefix

def write_pdb_file(model, filename, log=None):
  outl = model.model_as_pdb()
  print('    Writing PDB : %s' % filename, file=log)
  f=open(filename, 'w')
  f.write(outl)
  del f

def write_restraints(model, filename, header=None, log=None):
  """Write restraints from a model

  Args:
      model (model class): Model with one entity and no alt. loc.
      filename (TYPE): Description
      log (None, optional): Description

  """
  try:
    co = get_restraints_from_model_via_grm(model, ideal=False)
  except AssertionError:
    print('\n  Failed to write restraints', file=log)
    return
  print('\n  Writing restraints : %s' % filename, file=log)
  f=open(filename, 'w')
  if header:
    for line in header.splitlines():
      if not line.startswith('#'):
        line = '# %s' % line
      f.write('%s\n' % line)
  f.write(str(co))
  del f

def retain_only_one_alternative_conformation(model, alt_loc_id):
  ph = model.get_hierarchy()
  for residue_group in ph.residue_groups():
    remove=[]
    for atom_group in residue_group.atom_groups():
      if atom_group.altloc:
        if atom_group.altloc!=alt_loc_id:
          remove.append(atom_group)
    if remove:
      for atom_group in remove:
        residue_group.remove_atom_group(atom_group)
    if len(residue_group.atom_groups())==0:
      chain = residue_group.parent()
      chain.remove_residue_group(residue_group)

def add_additional_hydrogen_atoms_to_model( model,
                                            use_capping_hydrogens=False,
                                            # use_neutron_distances=True,
                                            retain_original_hydrogens=True,
                                            append_to_end_of_model=False,
                                            n_terminal_charge=True,
                                            ):
  from mmtbx.ligands.ready_set_utils import add_terminal_hydrogens
  from mmtbx.ligands.ready_set_utils import add_water_hydrogen_atoms_simple
  from mmtbx.ligands.ready_set_utils import delete_charged_n_terminal_hydrogens
  rc = add_terminal_hydrogens( model.get_hierarchy(),
                               model.get_restraints_manager().geometry,
                               use_capping_hydrogens=use_capping_hydrogens,
                               retain_original_hydrogens=retain_original_hydrogens,
                               append_to_end_of_model=append_to_end_of_model,
                               )
  assert not rc
  rc = add_water_hydrogen_atoms_simple(model.get_hierarchy())
  if not n_terminal_charge:
    rc = delete_charged_n_terminal_hydrogens(model.get_hierarchy())
  hierarchy = model.get_hierarchy()
  for i, atom in enumerate(hierarchy.atoms()):
    if i and not atom.tmp: atom.tmp=-1

def select_and_reindex(model,
                       selection_str=None,
                       selection_array=None,
                       reindex=True,
                       verbose=False):
  from scitbx_array_family_flex_ext import reindexing_array
  def _reindexing(mod, sel, verbose=False):
    isel = sel.iselection()
    ra = reindexing_array(len(sel),
                          flex.size_t(isel).as_int())
    atoms = mod.get_atoms()
    for i_seq in isel:
      atoms[ra[i_seq]].tmp=i_seq
    if verbose:
      for atom in mod.get_atoms():
        print('...',atom.quote(), atom.i_seq, atom.tmp)
    return mod
  assert (selection_array, selection_str).count(None)==1
  if selection_str:
    selection_array = model.selection(selection_str)
  selected_model = model.select(selection_array)
  if reindex:
    rc = _reindexing(selected_model, selection_array, verbose=verbose)
  return selected_model

def super_cell_and_prune(buffer_model,
                         ligand_model,
                         buffer,
                         prune_limit=5.,
                         do_not_prune=False,
                         write_steps=False):
  from cctbx.crystal import super_cell
  def find_movers(buffer_model, ligand_model, buffer, prune_limit=5.):
    buffer*=buffer
    prune_limit*=prune_limit
    movers = []
    close = []
    removers = []
    same = []
    prune_main = []
    for residue_group1 in buffer_model.get_hierarchy().residue_groups():
      for residue_group2 in ligand_model.get_hierarchy().residue_groups():
        if residue_group1.id_str()==residue_group2.id_str():
          same.append(residue_group1)
          continue
        if list(residue_group1.unique_resnames())==list(residue_group2.unique_resnames()):
          min_d2, min_ca_d2 = min_dist2(residue_group1, residue_group2, limit=.1)
          if min_d2<=.1:
            removers.append(residue_group1)
        else:
          min_d2, min_ca_d2 = min_dist2(residue_group1, residue_group2, limit=buffer)
        if min_d2<=buffer:
          close.append(residue_group1)
        else:
          movers.append(residue_group1)
        if min_ca_d2 is not None and min_ca_d2>prune_limit:
          prune_main.append(residue_group1)
      assert residue_group1 in movers or residue_group1 in close or residue_group1 in same
    for chain in buffer_model.get_hierarchy().chains():
      if do_not_prune: break
      for rg in movers+removers:
        if rg in chain.residue_groups():
          chain.remove_residue_group(rg)
    # if prune_main: prune_main_chain(residue_group1, prune_main)
    return movers, removers
  def prune_main_chain(residue_group1, prune_main):
    mainchain = ['N', 'CA', 'C', 'O', 'OXT', 'H', 'HA', 'H1', 'H2', 'H3']
    for residue_group1 in prune_main:
      ur = residue_group1.unique_resnames()
      if 'PRO' in ur or 'GLY' in ur:
        if list(ur)==['PRO']:
          assert 0
        continue
      cb_atom = None
      for atom in residue_group1.atoms():
        if atom.name.strip()=='CB':
          cb_atom=atom
          break
      if cb_atom is None: continue
      pruning=False
      for atom in residue_group1.atoms():
        if atom.name.strip()=='CA':
          atom.name=' HBC'
          atom.element='H'
          atom.xyz = ((atom.xyz[0]+cb_atom.xyz[0])/2,
                      (atom.xyz[1]+cb_atom.xyz[1])/2,
                      (atom.xyz[2]+cb_atom.xyz[2])/2,
                      )
          pruning=True
          break
      if pruning:
        for atom in residue_group1.atoms():
          if atom.name.strip() in mainchain:
              ag = atom.parent()
              ag.remove_atom(atom)

  complete_p1 = super_cell.manager(
    pdb_hierarchy        = buffer_model.get_hierarchy(),
    crystal_symmetry     = buffer_model.crystal_symmetry(),
    select_within_radius = buffer,
    )
  super_sphere_hierarchy = complete_p1.super_sphere_hierarchy
  if(write_steps):
    super_sphere_hierarchy.write_pdb_file(file_name="complete_p1.pdb",
      crystal_symmetry = complete_p1.cs_super_sphere)
  for atom in super_sphere_hierarchy.atoms(): atom.tmp=-1
  for atom1, atom2 in zip(buffer_model.get_atoms(), super_sphere_hierarchy.atoms()):
    atom2.tmp = atom1.tmp
  buffer_model._pdb_hierarchy = super_sphere_hierarchy
  movers, removers = find_movers(buffer_model, ligand_model, buffer)
  assert len(buffer_model.get_atoms())>0

def use_neutron_distances_in_model_in_place(model):
  """Changes the X-H distances in place

  Args:
      model (model): model
  """
  params = model.get_current_pdb_interpretation_params()
  params.pdb_interpretation.use_neutron_distances = True
  model.log=null_out()
  model.process(make_restraints           = True,
                pdb_interpretation_params = params)
  model.set_hydrogen_bond_length(show=False)

def reverse_shift(original_model, moved_model):
  from scitbx.matrix import col
  ph=original_model.get_hierarchy()
  sites_cart=ph.atoms().extract_xyz()
  box_cushion = sites_cart.min()
  ph=moved_model.get_hierarchy()
  sites_cart=ph.atoms().extract_xyz()
  translate = sites_cart.min()
  sites_cart=sites_cart+col(box_cushion)-col(translate)
  ph.atoms().set_xyz(sites_cart)

def validate_super_cell_cluster(buffer_model, selection):
  if buffer_model.has_atoms_in_special_positions(selection):
    outl = '''
  Ligand "%s" has atoms in special positions. Check special_positions.pdb
  Reducing symmetry should help.
  ''' % selection
    write_pdb_file(buffer_model, 'special_positions.pdb', None)
    raise Sorry(outl)
  ph=buffer_model.get_hierarchy()
  for i, rg1 in enumerate(ph.residue_groups()):
    for j, rg2 in enumerate(ph.residue_groups()):
      if j<=i: continue
      min_d2, tmp = min_dist2(rg1,rg2)
      if min_d2<1:
        outl = '''
  Two residues in ligand cluster appear too close. Check overlapping_residues.pdb
  May be due not selecting an altloc or symmetry copy overlap.'''
        write_pdb_file(buffer_model, 'overlapping_residues.pdb', None)
        raise Sorry(outl)

def validate_ligand_buffer_models(ligand_model, buffer_model, qmr, log=None):
  '''
  validate models before allowing QM
  '''
  assert buffer_model.restraints_manager_available()
  #
  if not ligand_model.has_hd():
    for atom_group in ligand_model.get_hierarchy().atom_groups():
      if qmr.ignore_lack_of_h_on_ligand:
        print('    Selection %s has no H/D but is skipped via PHIL - continue' % (
              qmr.selection,
              ),
              file=log)
        break
      elif get_class(atom_group.resname) in [ 'common_small_molecule',
                                              'common_element',
        ]:
        print('    Selection %s has no H/D but is %s - continue' % (
              qmr.selection,
              get_class(atom_group.resname),
              ),
              file=log)
        break
    else:
      raise Sorry('\n    Ligand "%s" has no H/D. Check the model. %s' % (
        qmr.selection,
        get_class(atom_group.resname),
        ))
  for residue_group in buffer_model.get_hierarchy().residue_groups():
    if (residue_group.atom_groups_size() != 1):
      raise Sorry("Not implemented: cannot run QI on buffer "+
                  "molecules with alternate conformations")
  for atom_group in buffer_model.get_hierarchy().atom_groups():
    if get_class(atom_group.resname) in ["common_rna_dna",
                                         "modified_rna_dna",
                                         "ccp4_mon_lib_rna_dna"]:
      raise Sorry('QI cannot protonate RNA/DNA : "%s"' % atom_group.id_str())
  for atom_group in buffer_model.get_hierarchy().atom_groups():
    if atom_group.resname in ['HOH', 'DOD']: continue
    if get_class(atom_group.resname) in [ 'common_small_molecule',
                                          'common_element',
                                          ]: continue
    hs=0
    for atom in atom_group.atoms():
      if atom.element_is_hydrogen(): hs+=1
    if not hs:
      print('  Warning: Atom group %s has no H/D atoms' % (atom_group.id_str()),
            file=log)

def get_ligand_buffer_models(model, qmr, verbose=False, write_steps=False, log=None, debug=False):
  if WRITE_STEPS_GLOBAL: write_steps=True
  if debug: write_steps=True
  ligand_model = select_and_reindex(model, qmr.selection)
  #
  # check for to sparse selections like a ligand in two monomers
  #
  if len(ligand_model.get_atoms())==0:
    raise Sorry('selection "%s" results in empty model' % qmr.selection)
  if write_steps: write_pdb_file(ligand_model, 'model_selection.pdb', None)
  assert qmr.selection.find('within')==-1
  if qmr.buffer_selection:
    buffer_selection_string = qmr.buffer_selection
  else:
    buffer_selection_string = 'residues_within(%s, %s)' % (qmr.buffer,
                                                           qmr.selection)
  if debug: print('buffer_selection_string',buffer_selection_string)
  buffer_model = select_and_reindex(model, buffer_selection_string)
  if write_steps: write_pdb_file(buffer_model, 'pre_remove_altloc.pdb', None)
  altloc=None
  if qmr.selection.find('altloc')>-1:
    tmp = qmr.selection.split()
    i = tmp.index('altloc')
    altloc=tmp[i+1]
    altloc=altloc.replace(')','')
    altloc=altloc.replace('"','')
    altloc=altloc.replace("'",'')
  if 0: retain_only_one_alternative_conformation(buffer_model, altloc)
  buffer_model.remove_alternative_conformations(always_keep_one_conformer=True,
                                                altloc_to_keep=altloc)
  if write_steps: write_pdb_file(buffer_model, 'post_remove_altloc.pdb', None)
  validate_ligand_buffer_models(ligand_model, buffer_model, qmr, log=log)
  if write_steps: write_pdb_file(buffer_model, 'pre_super_cell.pdb', None)
  do_not_prune = qmr.buffer_selection
  super_cell_and_prune(buffer_model,
                       ligand_model,
                       qmr.buffer,
                       do_not_prune=do_not_prune,
                       write_steps=write_steps)
  if write_steps: write_pdb_file(buffer_model, 'post_super_cell.pdb', None)
  validate_super_cell_cluster(buffer_model, qmr.selection)
  buffer_model.unset_restraints_manager()
  buffer_model.log=null_out()
  if write_steps: write_pdb_file(buffer_model, 'pre_add_terminii.pdb', None)
  buffer_model.process(make_restraints=True)
  add_additional_hydrogen_atoms_to_model(buffer_model,
                                         use_capping_hydrogens=qmr.capping_groups)
  buffer_model.unset_restraints_manager()
  buffer_model.log=null_out()
  if write_steps: write_pdb_file(buffer_model, 'post_add_terminii.pdb', None)
  buffer_model.process(make_restraints=True)
  ligand_atoms = ligand_model.get_atoms()
  buffer_atoms = buffer_model.get_atoms()
  def compare_id_str(s1,s2):
    # needs to be updated for PDB and mmCIF
    ptr=9
    if s1[:ptr]==s2[:ptr] and s1[ptr+1:]==s2[ptr+1:]:
      return True
    return False
  for atom1 in ligand_atoms:
    if debug: print('ligand',atom1.quote())
    for atom2 in buffer_atoms:
      if debug: print('buffer',atom2.quote())
      if compare_id_str(atom1.id_str(), atom2.id_str()):
        break
    else:
      raise Sorry('''Bug alert
  Atom %s from ligand does not appear in buffer. Contact Phenix with input files.
  ''' % atom1.quote())
  #
  # necessary for amino acid selections to calculate energies
  #
  # ligand_model.unset_restraints_manager()
  # ligand_model.log=null_out()
  # ligand_model.process(make_restraints=True)
  # add_additional_hydrogen_atoms_to_model(ligand_model,
  #                                        use_capping_hydrogens=qmr.capping_groups)
  # ligand_model.unset_restraints_manager()
  # ligand_model.log=null_out()
  # ligand_model.process(make_restraints=True)
  #
  # reverse_shift(original_model, buffer_model_p1)
  def move_atoms(local_model):
    ph=local_model.get_hierarchy()
    sites_cart=ph.atoms().extract_xyz()
    sites_cart=sites_cart-col(box)+col(mc)
    ph.atoms().set_xyz(sites_cart)
  # move_atoms(buffer_model)
  # move_atoms(ligand_model)
  if write_steps: write_pdb_file(buffer_model, 'post_reverse_shift.pdb', None)
  use_neutron_distances_in_model_in_place(ligand_model)
  use_neutron_distances_in_model_in_place(buffer_model)
  if write_steps:
    write_pdb_file(buffer_model, 'post_neutron_cluster.pdb', None)
    write_pdb_file(ligand_model, 'post_neutron_ligand.pdb', None)
  return ligand_model, buffer_model

def show_ligand_buffer_models(ligand_model, buffer_model):
  # need to update for nearest neighbour...
  outl = '    Core atoms\n'
  ags = []
  for atom in ligand_model.get_atoms():
    outl += '      %s (%5d)\n' % (atom.id_str().replace('pdb=',''), atom.tmp)
  for atom in buffer_model.get_atoms():
    agi = atom.parent().id_str()
    if agi not in ags: ags.append(agi)
  outl += '    Buffer residues\n'
  for agi in ags:
    outl += '      %s\n' % agi
  return outl

def get_specific_atom_charges(qmr):
  rc=[]
  sacs = qmr.specific_atom_charges
  for sac in sacs:
    rc.append(sac)
  return rc

def get_qm_manager(ligand_model, buffer_model, qmr, program_goal, log=StringIO()):
  program = qmr.package.program
  default_solvent_model=''
  if program=='test':
    qmm = qm_manager.base_qm_manager.base_qm_manager
  elif program=='orca':
    qmm = orca_manager.orca_manager
    default_solvent_model='CPCM'
  elif program=='mopac':
    qmm = mopac_manager.mopac_manager
    default_solvent_model='EPS=78.4'
  else:
    assert 0
  qmr = quantum_interface.populate_qmr_defaults(qmr)
  if qmr.package.solvent_model:
    default_solvent_model=qmr.package.solvent_model
  else:
    if program_goal in ['energy', 'strain']:
      print(u'  Update solvent model for "%s" ligand %s to "%s"' % (qmr.selection,
                                                                    program_goal,
                                                                    default_solvent_model,
                                                                   )
      )
  electron_model = None
  solvent_model = qmr.package.solvent_model
  if program_goal in ['energy', 'strain']:
    electron_model = ligand_model
    solvent_model = default_solvent_model
  elif program_goal in ['opt', 'bound']:
    electron_model = buffer_model
  elif program_goal in ['pocket']:
    tmps=[]
    for atom in ligand_model.get_atoms(): tmps.append(atom.tmp)
    list_of_i_seqs=[]
    for atom in buffer_model.get_atoms():
      if atom.tmp not in tmps: list_of_i_seqs.append(atom.i_seq)
    pocket_model=buffer_model.select(flex.size_t(list_of_i_seqs))
    electron_model=pocket_model
  else:
    assert 0, 'program_goal %s not in list' % program_goal
  specific_atom_charges = qmr.specific_atom_charges
  specific_atom_multiplicities = qmr.specific_atom_multiplicities
  total_charge = quantum_interface.electrons(
    electron_model,
    specific_atom_charges=specific_atom_charges,
    specific_atom_multiplicities=specific_atom_multiplicities,
    log=log)
  if qmr.package.charge is Auto: #total_charge!=qmr.package.charge:

    print(u'  Update charge for "%s" cluster : %s ~> %s' % (qmr.selection,
                                                            qmr.package.charge,
                                                            total_charge),
          file=log)
    # qmr.package.charge=total_charge
  else:
    print(u'  Setting charge for "%s" cluster : %s (not calculated %s)' % (
                                                             qmr.selection,
                                                             qmr.package.charge,
                                                             total_charge),
          file=log)
    total_charge=qmr.package.charge
  #######
  # MULTI
  #######
  total_multiplicity = quantum_interface.get_total_multiplicity(qmr)
  if qmr.package.multiplicity is Auto: #total_multiplicity!=qmr.package.multiplicity:
    print(u'  Update multiplicity for "%s" cluster : %s ~> %s' % (qmr.selection,
                                                                  qmr.package.multiplicity,
                                                                  total_multiplicity),
          file=log)
    qmr.package.multiplicity=total_multiplicity
  else:
    print(u'  Setting multiplicity for "%s" cluster : %s (not calculated %s)' % (
                                                                  qmr.selection,
                                                                  qmr.package.multiplicity,
                                                                  total_multiplicity),
          file=log)
  qmm = qmm(electron_model.get_atoms(),
            qmr.package.method,
            qmr.package.basis_set,
            solvent_model,
            total_charge, #qmr.package.charge,
            qmr.package.multiplicity,
            qmr.package.nproc,
            # preamble='%02d' % (i+1),
            )
  qmm.program=program
  qmm.program_goal=program_goal
  ligand_i_seqs = []
  for atom in ligand_model.get_atoms():
    ligand_i_seqs.append(atom.tmp)
  hd_selection = electron_model.get_hd_selection()
  ligand_selection = []
  for i, (sel, atom) in enumerate(zip(hd_selection, electron_model.get_atoms())):
    if atom.tmp in ligand_i_seqs:
      ligand_selection.append(True)
    else:
      ligand_selection.append(False)
  if qmr.include_nearest_neighbours_in_optimisation:
    for i, (sel, atom) in enumerate(zip(ligand_selection, electron_model.get_atoms())):
      if atom.name.strip() in ['CA', 'C', 'N', 'O', 'OXT']: continue
      ligand_selection[i]=True
  if 'main_chain_to_delta' in qmr.protein_optimisation_freeze:
    for i, (sel, atom) in enumerate(zip(ligand_selection, electron_model.get_atoms())):
      if atom.name.strip() in ['CA', 'C', 'N', 'O', 'OXT', 'CB', 'CG']: # mostly for HIS...
        ligand_selection[i]=False
  elif 'main_chain_to_beta' in qmr.protein_optimisation_freeze:
    for i, (sel, atom) in enumerate(zip(ligand_selection, electron_model.get_atoms())):
      if atom.name.strip() in ['CA', 'C', 'N', 'O', 'OXT', 'CB']:
        ligand_selection[i]=False
  elif 'main_chain' in qmr.protein_optimisation_freeze:
    for i, (sel, atom) in enumerate(zip(ligand_selection, electron_model.get_atoms())):
      if atom.name.strip() in ['CA', 'C', 'N', 'O', 'OXT']:
        ligand_selection[i]=False
  if qmr.freeze_specific_atoms:
    min_d2=1e9
    min_i=None
    ph=ligand_model.get_hierarchy()
    atoms = ph.atoms()
    xyzs=atoms.extract_xyz()
    m=xyzs.mean()
    for i, (sel, atom) in enumerate(zip(ligand_selection, electron_model.get_atoms())):
      if sel and not atom.element_is_hydrogen():
        d2 = dist2(m, atom.xyz)
        if d2<min_d2:
          min_d2=d2
          min_i=i
    ligand_selection[min_i]=False
  qmm.set_ligand_atoms(ligand_selection)
  return qmm

def qm_restraints_initialisation(params, log=StringIO()):
  for i, qmr in enumerate(params.qi.qm_restraints):
    if not i: print('  QM restraints selections', file=log)
    print('    %s - buffer %s (%s)' % (qmr.selection,
                                       qmr.buffer,
                                       qmr.capping_groups), file=log)
  print('',file=log)
  quantum_interface.get_qi_macro_cycle_array(params, verbose=True, log=log)

def running_this_macro_cycle(qmr,
                             macro_cycle,
                             number_of_macro_cycles=-1,
                             energy_only=False,
                             pre_refinement=True,
                             verbose=False,
                             ):
  if verbose:
    print(qmr)
    print('macro_cycle',macro_cycle)
    print('number_of_macro_cycles',number_of_macro_cycles)
    print('energy_only',energy_only)
    print('pre_refinement',pre_refinement)
  from mmtbx.geometry_restraints.quantum_interface import get_qi_macro_cycle_array
  if not energy_only:
    if 'in_situ_opt' not in qmr.calculate: return False
    if qmr.run_in_macro_cycles=='all':
      return 'restraints'
    elif qmr.run_in_macro_cycles in ['first_only', 'first_and_last'] and macro_cycle==1:
      return 'restraints'
    elif ( qmr.run_in_macro_cycles in ['first_and_last', 'last_only'] and
          macro_cycle==number_of_macro_cycles):
      return 'restraints'
    elif qmr.run_in_macro_cycles=='test' and macro_cycle in [0, None]:
      return 'restraints'
  else:
    if pre_refinement:
      checks = 'starting_strain starting_energy starting_bound starting_binding'
      tmp = set(checks.split())
      inter = tmp.intersection(set(qmr.calculate))
      if macro_cycle==1:
        return list(inter)
    else:
      checks = 'final_strain final_energy final_bound final_binding'
      tmp = set(checks.split())
      inter = tmp.intersection(set(qmr.calculate))
      if macro_cycle==number_of_macro_cycles or macro_cycle==-1:
        return list(inter)
  return False

def update_bond_restraints(ligand_model,
                           buffer_model,
                           model_grm=None, # flag for update vs checking
                           ignore_x_h_distance_protein=False,
                           include_inter_residue_restraints=False,
                           log=StringIO()):
  ligand_grm = ligand_model.get_restraints_manager()
  ligand_atoms = ligand_model.get_atoms()
  ligand_i_seqs = []
  for atom in ligand_atoms: ligand_i_seqs.append(atom.tmp)
  buffer_grm = buffer_model.get_restraints_manager()
  atoms = buffer_model.get_atoms()
  bond_proxies_simple, asu = buffer_grm.geometry.get_all_bond_proxies(
    sites_cart=buffer_model.get_sites_cart())
  sorted_table, n_not_shown = bond_proxies_simple.get_sorted(
    'delta',
    buffer_model.get_sites_cart())
  i=0
  for info in sorted_table:
    #
    # loop over buffer restraints
    #
    (i_seq, j_seq, i_seqs, distance_ideal, distance_model, slack, delta, sigma, weight, residual, sym_op_j, rt_mx) = info
    i_atom=atoms[i_seq]
    j_atom=atoms[j_seq]
    if model_grm:
      if i_atom.element_is_hydrogen(): continue
      if j_atom.element_is_hydrogen(): continue
    i_seqs=[i_seq, j_seq]
    bond=buffer_grm.geometry.bond_params_table.lookup(*list(i_seqs))
    i+=1
    if model_grm:
      if include_inter_residue_restraints:
        if not(i_atom.tmp in ligand_i_seqs or j_atom.tmp in ligand_i_seqs):
          continue
      else:
        if not(i_atom.tmp in ligand_i_seqs and j_atom.tmp in ligand_i_seqs):
          continue
      Z=(distance_model-bond.distance_ideal)/sigma
      print('    %-5d %s - %s %5.3f ~> %5.3f (Z=%4.1f)' % (
        i,
        i_atom.id_str().replace('pdb=',''),
        j_atom.id_str().replace('pdb=',''),
        bond.distance_ideal,
        distance_model,
        Z), file=log)
      bond.distance_ideal=distance_model
      i_seqs=[i_atom.tmp, j_atom.tmp]
      bond=model_grm.geometry.bond_params_table.lookup(*list(i_seqs))
      bond.distance_ideal=distance_model
    else:
      if ( i_atom.element_is_hydrogen() or j_atom.element_is_hydrogen()):
        if distance_model>1.5:
          print('    %-5d %s - %s %5.3f ~> %5.3f' % (
            i,
            i_atom.id_str().replace('pdb=',''),
            j_atom.id_str().replace('pdb=',''),
            bond.distance_ideal,
            distance_model), file=log)
          if not ignore_x_h_distance_protein:
            raise Sorry('''
  The QM optimisation has caused a X-H covalent bond to exceed 1.5 Angstrom.
  This may be because the input geometry was not appropriate or the QM method
  is not providing the biological answer. Check the QM result for issues. This
  check can be skipped by using ignore_x_h_distance_protein=True.
  ''')

def update_bond_restraints_simple(model):
  """Update bond restraints in model to match the actual model values

  Args:
      model (model): model!
  """
  grm = model.get_restraints_manager()
  atoms = model.get_atoms()
  bond_proxies_simple, asu = grm.geometry.get_all_bond_proxies(
    sites_cart=model.get_sites_cart())
  sorted_table, n_not_shown = bond_proxies_simple.get_sorted(
    'delta',
    model.get_sites_cart())
  # for single ions there is no bond table
  if sorted_table is None: return
  for info in sorted_table:
    (i_seq, j_seq, i_seqs, distance_ideal, distance_model, slack, delta, sigma, weight, residual, sym_op_j, rt_mx) = info
    i_atom=atoms[i_seq]
    j_atom=atoms[j_seq]
    # exclude X-H because x-ray...
    if i_atom.element_is_hydrogen(): continue
    if j_atom.element_is_hydrogen(): continue
    i_seqs=[i_seq, j_seq]
    bond=grm.geometry.bond_params_table.lookup(*list(i_seqs))
    bond.distance_ideal=distance_model

def update_angle_restraints(ligand_model,
                            buffer_model,
                            model_grm=None, # flag for update vs checking
                            ignore_x_h_distance_protein=False,
                            include_inter_residue_restraints=False,
                            log=StringIO()):
  ligand_grm = ligand_model.get_restraints_manager()
  ligand_atoms = ligand_model.get_atoms()
  ligand_i_seqs = []
  for atom in ligand_atoms: ligand_i_seqs.append(atom.tmp)
  buffer_grm = buffer_model.get_restraints_manager()
  atoms = buffer_model.get_atoms()
  # ligand_i_seq_min=None
  # for atom in atoms:
  #   if atom.tmp in ligand_i_seqs:
  #     ligand_i_seq_min=atom.i_seq
  #     break
  sorted_table, n_not_shown = buffer_grm.geometry.angle_proxies.get_sorted(
    'delta',
    buffer_model.get_sites_cart())
  # ligand_lookup = {}
  # model_lookup = {}
  i=0
  if sorted_table is None: sorted_table=[]
  for info in sorted_table:
    (i_seqs, angle_ideal, angle_model, delta, sigma, weight, residual) = info
    i_atom=atoms[int(i_seqs[0])]
    j_atom=atoms[int(i_seqs[1])]
    k_atom=atoms[int(i_seqs[2])]
    key = [i_atom.tmp, j_atom.tmp, k_atom.tmp]
    intersect = set(ligand_i_seqs).intersection(set(key))
    if include_inter_residue_restraints:
      if not len(intersect): continue
    else:
      if len(intersect)!=3: continue
    # key = (int(i_seqs[0])-ligand_i_seq_min,
    #        int(i_seqs[1])-ligand_i_seq_min,
    #        int(i_seqs[2])-ligand_i_seq_min)
    # key = (int(i_seqs[0]), int(i_seqs[1]), int(i_seqs[2]))
    # ligand_lookup[key]=angle_model
    # key = (int(i_seqs[0]), int(i_seqs[1]), int(i_seqs[2]))
    i+=1
    Z=(angle_model-angle_ideal)/sigma
    print('    %-5d %s - %s - %s %5.1f ~> %5.1f (Z=%4.1f)' % (
      i,
      i_atom.id_str().replace('pdb=',''),
      j_atom.id_str().replace('pdb=',''),
      k_atom.id_str().replace('pdb=',''),
      angle_ideal,
      angle_model,
      Z), file=log)
    assert len(intersect)!=0, '%s' % intersect
    # key = (atoms[key[0]].tmp, atoms[key[1]].tmp, atoms[key[2]].tmp)
    # model_lookup[key]=angle_model
    # # key = (int(i_seqs[2])-ligand_i_seq_min,
    #        int(i_seqs[1])-ligand_i_seq_min,
    #        int(i_seqs[0])-ligand_i_seq_min)
    # ligand_lookup[key]=angle_model
    # key = (atoms[key[2]].tmp, atoms[key[1]].tmp, atoms[key[0]].tmp)
    # model_lookup[key]=angle_model
  # for angle_proxy in ligand_grm.geometry.angle_proxies:
  #   angle = ligand_lookup.get(angle_proxy.i_seqs, None)
  #   print('angle',angle_proxy.i_seqs, angle)
  #   tmp=ligand_model.get_atoms()
  #   print(atoms[angle_proxy.i_seqs[0]].quote())
  #   print(atoms[angle_proxy.i_seqs[1]].quote())
  #   print(atoms[angle_proxy.i_seqs[2]].quote())
  #   if angle is None: continue
  #   angle_proxy.angle_ideal=angle
  # for angle_proxy in model_grm.geometry.angle_proxies:
  #   angle = model_lookup.get(angle_proxy.i_seqs, None)
  #   if angle is None: continue
  #   angle_proxy.angle_ideal=angle

  # assert 0

def update_angle_restraints_simple(model):
  """Update angle restraints in model to match the actual model values

  Args:
      model (model): model!
  """
  grm = model.get_restraints_manager()
  atoms = model.get_atoms()
  sorted_table, n_not_shown = grm.geometry.angle_proxies.get_sorted(
    'delta',
    model.get_sites_cart())
  if sorted_table is None: return
  lookup={}
  for info in sorted_table:
    (i_seqs, angle_ideal, angle_model, delta, sigma, weight, residual) = info
    for i in range(len(i_seqs)):
      i_seqs[i]=int(i_seqs[i])
    lookup[tuple(i_seqs)]=angle_model
  for angle_proxy in grm.geometry.angle_proxies:
    angle = lookup.get(angle_proxy.i_seqs, None)
    # tmp=model.get_atoms()
    # print(atoms[angle_proxy.i_seqs[0]].quote())
    # print(atoms[angle_proxy.i_seqs[1]].quote())
    # print(atoms[angle_proxy.i_seqs[2]].quote())
    if angle is None: assert 0
    angle_proxy.angle_ideal=angle

def update_dihedral_restraints( ligand_model,
                                buffer_model,
                                model_grm=None, # flag for update vs checking
                                ignore_x_h_distance_protein=False,
                                include_inter_residue_restraints=False,
                                log=StringIO()):
  ligand_grm = ligand_model.get_restraints_manager()
  ligand_atoms = ligand_model.get_atoms()
  ligand_i_seqs = []
  for atom in ligand_atoms: ligand_i_seqs.append(atom.tmp)
  buffer_grm = buffer_model.get_restraints_manager()
  atoms = buffer_model.get_atoms()
  # ligand_i_seq_min=None
  # for atom in atoms:
  #   if atom.tmp in ligand_i_seqs:
  #     ligand_i_seq_min=atom.i_seq
  #     break
  sorted_table, n_not_shown = buffer_grm.geometry.dihedral_proxies.get_sorted(
    'delta',
    buffer_model.get_sites_cart())
  # ligand_lookup = {}
  # model_lookup = {}
  i=0
  if sorted_table is None: sorted_table=[]
  for info in sorted_table:
    (i_seqs, angle_ideal, angle_model, delta, period, sigma, weight, residual) = info
    i_atom=atoms[int(i_seqs[0])]
    j_atom=atoms[int(i_seqs[1])]
    k_atom=atoms[int(i_seqs[2])]
    l_atom=atoms[int(i_seqs[3])]
    key = [i_atom.tmp, j_atom.tmp, k_atom.tmp, l_atom.tmp]
    intersect = set(ligand_i_seqs).intersection(set(key))
    if include_inter_residue_restraints:
      if not len(intersect): continue
    else:
      if len(intersect)!=4: continue
    i+=1
    print('    %-5d %s - %s - %s - %s %6.1f ~> %6.1f' % (
      i,
      i_atom.id_str().replace('pdb=',''),
      j_atom.id_str().replace('pdb=',''),
      k_atom.id_str().replace('pdb=',''),
      l_atom.id_str().replace('pdb=',''),
      angle_ideal,
      angle_model), file=log)
    assert len(intersect)!=0, '%s' % intersect

def update_dihedral_restraints_simple(model):
  """Update dihedral restraints in model to match the actual model values

  Args:
      model (model): model!
  """
  grm = model.get_restraints_manager()
  atoms = model.get_atoms()
  sorted_table, n_not_shown = grm.geometry.dihedral_proxies.get_sorted(
    'delta',
    model.get_sites_cart())
  if sorted_table is None: return
  lookup={}
  for info in sorted_table:
    (i_seqs, angle_ideal, angle_model, delta, period, sigma, weight, residual) = info
    for i in range(len(i_seqs)):
      i_seqs[i]=int(i_seqs[i])
    lookup[tuple(i_seqs)]=angle_model
  for angle_proxy in grm.geometry.dihedral_proxies:
    angle = lookup.get(angle_proxy.i_seqs, None)
    if angle is None: assert 0
    angle_proxy.angle_ideal=angle

def get_program_goal(qmr, macro_cycle=None, energy_only=False):
  program_goal=[]
  if not energy_only:
    program_goal=['opt']
    return program_goal
  if macro_cycle==1:
    if qmr.calculate.count('starting_energy'):
      program_goal.append('energy')
    if qmr.calculate.count('starting_strain'):
      program_goal.append('strain')
    if qmr.calculate.count('starting_bound'):
      program_goal.append('bound')
    if qmr.calculate.count('starting_binding'):
      program_goal.append('energy')
      program_goal.append('strain')
      program_goal.append('bound')
      program_goal.append('pocket')
  else: # only called with final energy on final macro cycle
    if qmr.calculate.count('final_energy'):
      program_goal.append('energy')
    if qmr.calculate.count('final_strain'):
      program_goal.append('strain')
    if qmr.calculate.count('final_bound'):
      program_goal.append('bound')
    if qmr.calculate.count('final_binding'):
      program_goal.append('energy')
      program_goal.append('strain')
      program_goal.append('bound')
      program_goal.append('pocket')
  return program_goal

def setup_qm_jobs(model,
                  params,
                  macro_cycle,
                  energy_only=False,
                  pre_refinement=True,
                  log=StringIO()):
  prefix = get_prefix(params)
  objects = []
  # if params.qi.working_directory:
  #   if params.qi.working_directory is Auto:
  #     working_directory = prefix
  #   else:
  #     working_directory = params.qi.working_directory
  #   if not os.path.exists(working_directory):
  #     os.mkdir(working_directory)
  #   print('  Changing to %s' % working_directory, file=log)
  #   os.chdir(working_directory)
  for i, qmr in enumerate(params.qi.qm_restraints):
    if len(qmr.freeze_specific_atoms)>2:
      raise Sorry('Only Auto supported so multiple freezes not necessary.')
    elif len(qmr.freeze_specific_atoms)==1:
      if qmr.freeze_specific_atoms[0].atom_selection!=Auto:
        raise Sorry('Freezing ligand atoms only supports "Auto" for centre of mass.')
    number_of_macro_cycles = 1
    if hasattr(params, 'main'):
      number_of_macro_cycles = params.main.number_of_macro_cycles
    if macro_cycle==99: number_of_macro_cycles = 99
    if macro_cycle is not None and not running_this_macro_cycle(
        qmr,
        macro_cycle,
        energy_only=energy_only,
        number_of_macro_cycles=number_of_macro_cycles,
        pre_refinement=pre_refinement):
      print('    Skipping this selection in this macro_cycle : %s' % qmr.selection,
            file=log)
      continue
    #
    # get ligand and buffer region models
    #
    debug=getattr(params.qi, 'debug', False)
    ligand_model, buffer_model = get_ligand_buffer_models(model, qmr, debug=debug)
    #
    # get appropriate QM manager
    #
    program_goals = get_program_goal(qmr, macro_cycle, energy_only=energy_only)
    for program_goal in program_goals:
      qmm = get_qm_manager(ligand_model, buffer_model, qmr, program_goal, log=log)
      preamble = quantum_interface.get_preamble(macro_cycle, i, qmr)
      if not energy_only: # only write PDB files for restraints update
        if 'pdb_core' in qmr.write_files:
          write_pdb_file(ligand_model, '%s_ligand_%s.pdb' % (prefix, preamble), log)
        if 'pdb_buffer' in qmr.write_files:
          write_pdb_file(buffer_model, '%s_cluster_%s.pdb' % (prefix, preamble), log)
      qmm.preamble='%s_%s' % (prefix, preamble)
      # for attr in ['exclude_torsions_from_optimisation']:
      #   setattr(qmm, attr, getattr(qmr, attr))
      attr = 'exclude_torsions_from_optimisation'
      setattr(qmm, attr, qmr.protein_optimisation_freeze.count('torsions'))
      #
      objects.append([ligand_model, buffer_model, qmm, qmr])
  print('',file=log)
  return objects

def run_jobs(objects, macro_cycle, nproc=1, log=StringIO()):
  assert objects
  from mmtbx.geometry_restraints.qi_utils import run_serial_or_parallel
  argstuples=[]
  for i, (ligand_model, buffer_model, qmm, qmr) in enumerate(objects):
    argstuples.append((qmm,
                       qmr.cleanup,
                       qmr.package.read_output_to_skip_opt_if_available,
                       not(qmr.package.ignore_input_differences),
                       log,
                       ))
    if type(qmm.method)==type('') and qmm.method.find('PM6-D3H4')==0:
      key = (ligand_model.get_number_of_atoms(),
             buffer_model.get_number_of_atoms())
      predicted_time = predict_time(*key)
      msg = '  Predicted time of QM calculation : %7.1fs' % predicted_time
      if log is None: print(msg)
      else: print(msg, file=log)
  results = run_serial_or_parallel(qm_manager.qm_runner, argstuples, nproc)
  if results:
    xyzs = []
    xyzs_buffer = []
    energies = {}
    for i, (ligand_model, buffer_model, qmm, qmr) in enumerate(objects):
      xyz, xyz_buffer = results[i]
      units=''
      if qmm.program_goal in ['opt']:
        energy, units = qmm.read_energy()
        charge = qmm.read_charge()
        if 0 : #os.getlogin()=='NWMoriarty':
          from mmtbx.geometry_restraints import curve_fit_3d
          key = (ligand_model.get_number_of_atoms(),
                 buffer_model.get_number_of_atoms())
          time_query = qmm.get_timings()
          curve_fit_3d.load_and_display(qmm.program_goal, key, time_query, show=True)
      elif qmm.program_goal in ['energy', 'strain', 'bound', 'pocket']:
        energy=xyz
        units=xyz_buffer
        xyz=None
        xyz_buffer=None
        qmm.preamble += '_%s' % qmm.program_goal
        if qmm.program_goal in ['bound']: qmm.preamble += '_energy'
        elif qmm.program_goal in ['pocket']: qmm.preamble += '_energy'
          # qmm.preamble=qmm.preamble.replace(qmm.program_goal, 'pocket_energy')
        charge = qmm.read_charge()
        # except: charge=-99
      else:
        assert 0, 'program_goal %s not in list' % qmm.program_goal
      energies.setdefault(qmr.selection,[])
      energies[qmr.selection].append([qmm.program_goal,
                                      energy,
                                      ligand_model.get_number_of_atoms(),
                                      buffer_model.get_number_of_atoms(),
                                      charge,
                                      ])
      xyzs.append(xyz)
      xyzs_buffer.append(xyz_buffer)
      print('  Time for calculation of "%s" using %s %s %s: %s' % (
        qmr.selection,
        qmr.package.method,
        qmr.package.basis_set,
        qmr.package.solvent_model,
        qmm.get_timings().split(':')[-1],
        ), file=log)
  print('',file=log)
  return xyzs, xyzs_buffer, energies, units

def run_energies(model,
                 params,
                 macro_cycle=None,
                 run_program=True,
                 pre_refinement=True,
                 nproc=1,
                 log=StringIO(),
                 ):
  t0 = time.time()
  energy_only=True
  if not model.restraints_manager_available():
    model.log=null_out()
    model.process(make_restraints=True)
  if macro_cycle in [None, 0]: run_program=False
  # qi_array = quantum_interface.get_qi_macro_cycle_array(params)
  if quantum_interface.is_quantum_interface_active_this_macro_cycle(params,
                                                                    macro_cycle,
                                                                    energy_only=energy_only,
                                                                    # pre_refinement=pre_refinement,
                                                                    ) and run_program:
    print('  QM energy calculations for macro cycle %s' % macro_cycle, file=log)
  #
  # setup QM jobs
  #
  objects = setup_qm_jobs(model,
                          params,
                          macro_cycle,
                          energy_only=energy_only,
                          pre_refinement=pre_refinement,
                          log=log)
  if not run_program: return
  assert macro_cycle is not None
  #
  # run jobs
  #
  working_dir = quantum_interface.get_working_directory(model, params)
  if not os.path.exists(working_dir):
    try: os.mkdir(working_dir)
    except Exception as e: pass
  os.chdir(working_dir)
  xyzs, xyzs_buffer, energies, units = run_jobs(objects,
                                                macro_cycle=macro_cycle,
                                                nproc=nproc,
                                                log=log)
  os.chdir('..')
  print('  Total time for QM energies: %0.1fs' % (time.time()-t0), file=log)
  print('%s%s' % ('<'*40, '>'*40), file=log)
  return group_args(energies=energies,
                    units=units,
                    )

def update_restraints(model,
                      params,
                      macro_cycle=None,
                      # run_program=True,
                      # transfer_internal_coordinates=True,
                      never_write_restraints=False,
                      nproc=1,
                      parallel_id=None,
                      prefix=None,
                      log=StringIO(),
                      ):
  def is_ligand_going_to_be_same_size(qmr):
    rc=True
    inter = set(qmr.protein_optimisation_freeze).intersection(set(['main_chain_to_delta',
                                                                  'main_chain_to_beta',
                                                                  'main_chain',
                                                                  'torsions']))
    if (qmr.include_nearest_neighbours_in_optimisation or inter):
      rc=False
    if len(qmr.freeze_specific_atoms)>0: rc=False
    return rc
  t0 = time.time()
  times=[]
  energy_only=False
  if not model.restraints_manager_available():
    model.log=StringIO()
    try:
      model.process(make_restraints=True)
    except Sorry as e:
      print(model.log.getvalue())
      raise e
  if quantum_interface.is_quantum_interface_active_this_macro_cycle(params,
                                                                    macro_cycle,
                                                                    energy_only=energy_only,
                                                                    ):
    print('  QM restraints calculations for macro cycle %s' % macro_cycle,
      file=log)
  #
  # setup QM jobs
  #
  objects = setup_qm_jobs(model, params, macro_cycle, energy_only=energy_only, log=log)
  #
  # run jobs
  #
  assert objects
  if not objects: return None
  cwd_dir = os.getcwd()
  working_dir = quantum_interface.get_working_directory(model, params)
  if not os.path.exists(working_dir):
    try: os.mkdir(working_dir)
    except Exception as e: pass
  os.chdir(working_dir)
  xyzs, xyzs_buffer, energies, units = run_jobs(objects,
                                                macro_cycle=macro_cycle,
                                                nproc=nproc,
                                                log=log)
  times.append(time.time()-t0)
  #
  # update model restraints
  #
  rmsds=[]
  final_pdbs = []
  if prefix is None:
    prefix = get_prefix(params, prefix)
  for i, ((ligand_model, buffer_model, qmm, qmr), xyz, xyz_buffer) in enumerate(
    zip(objects,
        xyzs,
        xyzs_buffer,
        )):
    final_pdbs.append([])
    if qmr.package.view_output: qmm.view(qmr.package.view_output)
    if i: print(' ',file=log)
    print('  Updating QM restraints: "%s"' % qmr.selection, file=log)
    print(show_ligand_buffer_models(ligand_model, buffer_model), file=log)
    gs = ligand_model.geometry_statistics()
    print('  Starting stats: %s' % gs.show_bond_and_angle_and_dihedral(), file=log)
    #
    # update coordinates of ligand
    #
    ligand_rmsd = None
    old = ligand_model.get_hierarchy().atoms().extract_xyz()
    if is_ligand_going_to_be_same_size(qmr):
      ligand_rmsd = old.rms_difference(xyz)
      if ligand_rmsd>5:
        print('  QM minimisation has large rms difference in cartesian coordinates: %0.1f' % (ligand_rmsd),
              file=log)
        print('  Check the QM minimisation for errors or incorrect protonation.',
              file=log)
        if ligand_rmsd>20:
          print('  Movement of cartesian coordinates is very large.', file=log)
      ligand_model.get_hierarchy().atoms().set_xyz(xyz)
    old = buffer_model.get_hierarchy().atoms().extract_xyz()
    # rmsd = old.rms_difference(xyz_buffer)
    buffer_model.get_hierarchy().atoms().set_xyz(xyz_buffer)
    #
    ligand_atoms = ligand_model.get_hierarchy().atoms()
    ligand_i_seqs = []
    number_of_ligand_atoms=len(ligand_atoms)
    for atom in ligand_atoms:
      if atom.element.strip() in ['H', 'D']: continue
      ligand_i_seqs.append(atom.id_str())
    buffer_atoms = buffer_model.get_hierarchy().atoms()
    new_old = flex.vec3_double()
    new_new = flex.vec3_double()
    for atom, told, tnew in zip(buffer_atoms,old,xyz_buffer):
      if atom.id_str() in ligand_i_seqs:
        new_old.append(told)
        new_new.append(tnew)
    rmsd = new_old.rms_difference(new_new)
    rmsds.append([ligand_rmsd, rmsd])
    print('    RMS difference in entire QM model : %9.3f' % (rmsd), file=log)
    #
    gs = ligand_model.geometry_statistics()
    print('  Interim stats : %s' % gs.show_bond_and_angle_and_dihedral(), file=log)
    preamble = quantum_interface.get_preamble(macro_cycle, i, qmr)
    if 'pdb_final_core' in qmr.write_files:
      write_pdb_file(ligand_model, '%s_ligand_final_%s.pdb' % (prefix, preamble), log)
      final_pdbs[-1].append('%s_ligand_final_%s.pdb' % (prefix, preamble))
    if 'pdb_final_buffer' in qmr.write_files:
      write_pdb_file(buffer_model, '%s_cluster_final_%s.pdb' % (prefix, preamble), log)
      final_pdbs[-1].append('%s_cluster_final_%s.pdb' % (prefix, preamble))
    if qmr.do_not_update_restraints:
      print('  Skipping updating restaints %s %s' % (prefix, preamble), file=log)
      continue
    #
    # transfer geometry to proxies
    #  - bonds
    #
    model_grm = model.get_restraints_manager()
    print('\n  Checking', file=log)
    update_bond_restraints(buffer_model,
                           buffer_model,
                           ignore_x_h_distance_protein=qmr.ignore_x_h_distance_protein,
                           log=log)
    print('\n  Transfer : old ~> new', file=log)
    update_bond_restraints(ligand_model,
                           buffer_model,
                           model_grm=model_grm,
                           include_inter_residue_restraints=qmr.include_inter_residue_restraints,
                           log=log)
    update_bond_restraints_simple(ligand_model)
    #
    #  - angles
    #
    update_angle_restraints(ligand_model,
                            buffer_model,
                            model_grm=model_grm,
                            include_inter_residue_restraints=qmr.include_inter_residue_restraints,
                            log=log)
    update_angle_restraints_simple(ligand_model)
    #
    #  - torsions
    #
    update_dihedral_restraints( ligand_model,
                                buffer_model,
                                model_grm=model_grm,
                                include_inter_residue_restraints=qmr.include_inter_residue_restraints,
                                log=log)
    update_dihedral_restraints_simple(ligand_model)
    print('', file=log)
    #
    # final stats
    #
    gs = ligand_model.geometry_statistics()
    print('  Finished stats : %s' % gs.show_bond_and_angle_and_dihedral(
            assert_zero=not qmr.include_inter_residue_restraints),
          file=log)
    print('%s%s' % (' '*19, gs.show_planarity_details()), file=log)
    r=gs.result()
    if r.planarity.mean>0.02 or r.planarity.max>0.05:
      print('  %s\n   rmsd values for planarity restraints are high. Check QM minimisation. \n  %s' % (
            '-'*71,
            '-'*71,
            ),
            file=log)
    if ('restraints' in qmr.write_files and
        not never_write_restraints and
        number_of_ligand_atoms>1
        ):
      header='''
Restraints written by QMR process in phenix.refine
      ''' % ()
      if qmr.restraints_filename is not Auto:
        tmp_cif_filename = qmr.restraints_filename
      else:
        tmp_cif_filename = os.path.join(cwd_dir, '%s.cif' % qmm.preamble)
      if not tmp_cif_filename.endswith('.cif'):
        tmp_cif_filename = '%s.cif' % tmp_cif_filename
      write_restraints(ligand_model,
                       tmp_cif_filename,
                       header=header,
                       log=log,
                       )
  os.chdir('..')
  print('\n  Total time for QM restaints: %0.1fs\n' % (time.time()-t0), file=log)
  print('%s%s' % ('/'*39, '\\'*40), file=log)
  print('%s%s' % ('\\'*39, '/'*40), file=log)
  return group_args(energies=energies,
                    units=units,
                    rmsds=rmsds,
                    times=times,
                    final_pdbs=final_pdbs,
                    )

if __name__ == '__main__':
  print(quantum_chemistry_scope)


 *******************************************************************************


 *******************************************************************************
mmtbx/geometry_restraints/ramachandran.py
from __future__ import absolute_import, division, print_function
import libtbx.load_env
import iotbx.phil
from libtbx import adopt_init_args
import sys
import os, math
import boost_adaptbx.boost.python as bp
from scitbx.array_family import flex
from mmtbx.validation import ramalyze
from mmtbx.conformation_dependent_library import generate_protein_threes
from six.moves import range
from collections import OrderedDict
from mmtbx.rotamer import ramachandran_eval

ext = bp.import_ext("mmtbx_ramachandran_restraints_ext")
from mmtbx_ramachandran_restraints_ext import lookup_table, \
    ramachandran_residual_sum, phi_psi_targets
ext2 = bp.import_ext("mmtbx_validation_ramachandran_ext")
from mmtbx_validation_ramachandran_ext import rama_eval

old_master_phil = iotbx.phil.parse("""
  rama_weight = 1.0
    .type = float
    .short_caption = Ramachandran gradients weight
    .expert_level = 1
    .style = hidden
  scale_allowed = 1.0
    .type = float
    .short_caption = Rescale allowed region pseudo-energy by
    .style = hidden
  rama_potential = *oldfield emsley
    .type = choice(multi=False)
    .short_caption = Ramachandran potential
    .caption = Oldfield Coot
    .style = hidden
  oldfield
    .short_caption = Oldfield potential parameters
    .style = box auto_align hidden
  {
    esd = 10.0
      .type = float
      .expert_level = 2
      .short_caption = E.S.D.
    weight_scale = 1.0
      .type = float
      .expert_level = 2
    dist_weight_max = 10.0
      .type = float
      .expert_level = 2
    weight = None
      .type = float
      .expert_level = 2
    plot_cutoff = 0.027
      .type = float
      .expert_level = 2
  }
  rama_selection = None
    .type = atom_selection
    .short_caption = Atom selection for Ramachandran restraints
    .help = Selection of part of the model for which \
        Ramachandran restraints will be set up.
    .expert_level = 1
    .style = hidden
  restrain_rama_outliers = True
    .type = bool
    .help = Apply restraints to Ramachandran outliers
    .style = hidden
  restrain_rama_allowed = True
    .type = bool
    .help = Apply restraints to residues in allowed region on Ramachandran plot
    .style = hidden
  restrain_allowed_outliers_with_emsley = False
    .type = bool
    .help = In case of restrain_rama_outliers=True and/or restrain_rama_allowed=True \
      still restrain these residues with emsley. Make sense only in case of \
      using oldfield potential.
    .style = hidden
""")

master_phil = iotbx.phil.parse("""\
ramachandran_plot_restraints {
  enabled = False
    .type = bool
    .short_caption = Ramachandran restraints

  favored = *oldfield emsley emsley8k phi_psi_2
    .type = choice(multi=False)

  allowed = *oldfield emsley emsley8k phi_psi_2
    .type = choice(multi=False)

  outlier = *oldfield emsley emsley8k phi_psi_2
    .type = choice(multi=False)

  selection = None
    .type = atom_selection
    .short_caption = Atom selection for Ramachandran restraints
    .help = Selection of part of the model for which \
        Ramachandran restraints will be set up.
    .expert_level = 1
  inject_emsley8k_into_oldfield_favored = True
    .type=bool
    .expert_level = 3
    .help = Backdoor to disable temporary dirty hack to use both
  oldfield
    .short_caption = Oldfield settings
    .expert_level = 2
    .style = box
  {
    weight = 0.
      .type = float
      .expert_level = 2
      .help = Direct weight value. If 0 the weight will \
          be calculated as following: \
          (w, op.esd, op.dist_weight_max, 2.0, op.weight_scale) \
                                                                \
           1 / esd^2  *  max(2.0,   min(current_distance_to_allowed, dist_weight_max))    * weight_scale \
                         max(2.0,   current_distance_to_allowed) \
                                                                  \
           1 / esd^2  * weight_scale  *  max(distance_to_allowed_cutoff,   current_distance_to_allowed)   \
                weight_scale(=0.01)  *  max(distance_weight_min(=2.), min(distance_weight_max(=10.), current_distance_to_allowed))
    weight_scale = 0.01
      .type = float
      .expert_level = 2
    distance_weight_min = 2.0
      .type = float
      .expert_level = 2
      .help = minimum coefficient when scaling depending on how far the residue \
          is from allowed region.
    distance_weight_max = 10.0
      .type = float
      .expert_level = 2
      .help = maximum coefficient when scaling depending on how far the residue \
          is from allowed region.
    plot_cutoff = 0.027
      .type = float
      .expert_level = 2
  }
  emsley
    .short_caption = Emsley settings
    .style = box
  {
    weight = 1.0
      .type = float
      .short_caption = Ramachandran plot restraints weight (emsley)
      .expert_level = 1
    scale_allowed = 1.0
      .type = float
      .short_caption = Rescale allowed region pseudo-energy by
  }
  emsley8k
    .short_caption = Emsley8k settings
    .expert_level = 1
    .style = box
  {
    weight_favored = 5.0
      .type = float
      .short_caption = Ramachandran plot restraints weight (emsley8k, favored)
      .expert_level = 1
    weight_allowed = 10.0
      .type = float
      .short_caption = Ramachandran plot restraints weight (emsley8k, allowed)
      .expert_level = 1
    weight_outlier = 10.0
      .type = float
      .short_caption = Ramachandran plot restraints weight (emsley8k, outlier)
      .expert_level = 1
  }
  phi_psi_2
    .style = box
  {
    favored_strategy = *closest highest_probability random weighted_random
      .type = choice(multi=False)
    allowed_strategy = *closest highest_probability random weighted_random
      .type = choice(multi=False)
    outlier_strategy = *closest highest_probability random weighted_random
      .type = choice(multi=False)
  }
}
  """)

# Transformation from old to new parameters:
# weight = old.weight if (old.weight is None or old.weight > 0) else 0
# weight_scale = 1/old.esd^2 * old.weight_scale
# distance_to_allowed_cutoff = 2 if old.dist_weight_max > 2 else old.dist_weight_max
#

def is_proxy_present(proxies, n_seq, proxy):
  p_iseqs = list(proxy.get_i_seqs())
  ps = proxies.proxy_select(n_seq=n_seq,
      iselection=flex.size_t(p_iseqs))
  return ps.size() > 0

class ramachandran_manager(object):
  def __init__(self, pdb_hierarchy, params=None,
      log=sys.stdout,
      proxies=None, tables=None,
      initialize=True):
    assert pdb_hierarchy is not None
    assert not pdb_hierarchy.atoms().extract_i_seq().all_eq(0), ""+\
        "Probably all atoms have i_seq = 0 which is wrong"

    if params is None:
      # print ('init, params is None')
      w_params = master_phil.fetch().extract()
      w_params = w_params.ramachandran_plot_restraints
    elif hasattr(params, 'enabled'):
      # print ("init, hasattr(params, 'enabled')")
      # New params
      w_params = params
    elif hasattr(params, 'ramachandran_plot_restraints'):
      # print ("init, hasattr(params, 'ramachandran_plot_restraints'")
      # print ("init, ", type(params), type(params.ramachandran_plot_restraints), params.ramachandran_plot_restraints)
      w_params = params.ramachandran_plot_restraints
    else:
      # print ("init, else")
      w_params = master_phil.fetch().extract()
      w_params = w_params.ramachandran_plot_restraints
      # old params, make transfer
      w_params.selection = params.rama_selection
      # oldfield
      w_params.enabled = True
      w_params.oldfield.weight = \
          params.oldfield.weight if (params.oldfield.weight is None or params.oldfield.weight > 0) else 0
      w_params.oldfield.weight_scale = \
          1/(params.oldfield.esd**2) * params.oldfield.weight_scale
      w_params.oldfield.distance_weight_min = 2.0
      w_params.oldfield.distance_weight_max = params.oldfield.dist_weight_max

      # emsley
      w_params.emsley.weight = params.rama_weight
      w_params.emsley.scale_allowed = params.scale_allowed
      # strategy
      if params.rama_potential == 'oldfield':
        pass
      elif params.rama_potential == 'emsley':
        w_params.favored = 'emsley'
        w_params.allowed = 'emsley'
        w_params.outlier = 'emsley'
      if params.restrain_rama_outliers:
        w_params.outlier = params.rama_potential
      else:
        w_params.outlier = None
      if params.restrain_rama_allowed:
        w_params.allowed = params.rama_potential
      else:
        w_params.allowed = None
      if params.restrain_allowed_outliers_with_emsley:
        if not params.restrain_rama_allowed:
          w_params.allowed = 'emsley'
        if not params.restrain_rama_outliers:
          w_params.outlier = 'emsley'

    self.params = w_params
    self.rama_eval = rama_eval()
    self.hierarchy = pdb_hierarchy # only for def select()
    self.log = log
    self._oldfield_proxies = ext.shared_phi_psi_proxy()
    self._emsley_proxies   = ext.shared_phi_psi_proxy()
    self._emsley8k_proxies = ext.shared_phi_psi_proxy()
    self._phi_psi_2_proxies = ext.shared_phi_psi_proxy()
    self._oldfield_tables = None
    self._emsley_tables   = None
    self._emsley8k_tables = None
    self._phi_psi_2_tables = None
    if proxies is not None:
      self._oldfield_proxies, \
      self._emsley_proxies, \
      self._emsley8k_proxies, \
      self._phi_psi_2_proxies = proxies
    if tables is not None:
      self._oldfield_tables, \
      self._emsley_tables, \
      self._emsley8k_tables, \
      self._phi_psi_2_tables = tables
    self.initialize = initialize
    # bad hack to keep emsley potential in working(?) condition after
    # changing from rama500 to rama8000
    self.new_to_old_conversion = {"general":"ala", "glycine":"gly",
        "cis-proline":"pro", "trans-proline":"pro", "pre-proline":"prepro",
        "isoleucine or valine":"ala"}
    bool_atom_selection = self._determine_bool_atom_selection(pdb_hierarchy)
    fao = [self.params.favored, self.params.allowed, self.params.outlier]
    if initialize:
      if 'oldfield' in fao:
        self._oldfield_tables = ramachandran_plot_data(
          plot_cutoff=self.params.oldfield.plot_cutoff)
      if 'emsley' in fao:
        self._emsley_tables = load_tables()
      #
      ### THIS IS CRUEL. REMOVE ONCE favored/allowed/outlier are made multiple!
      #
      if 'emsley8k' in fao or self.params.inject_emsley8k_into_oldfield_favored:
        self._emsley8k_tables = load_emsley8k_tables()
      if 'phi_psi_2' in fao:
        self._phi_psi_2_tables = load_phi_psi_2_tables()
      # get proxies
      self.extract_proxies(pdb_hierarchy)
    if 'oldfield' in fao:
      self.target_phi_psi = self.update_phi_psi_targets_on_init(
        hierarchy = pdb_hierarchy)
    self.initialize = False

  def _determine_bool_atom_selection(self, hierarchy):
    bool_atom_selection = None
    if self.params.selection is None:
      bool_atom_selection = flex.bool(hierarchy.atoms_size(), True)
    else:
      cache = hierarchy.atom_selection_cache()
      bool_atom_selection = cache.selection(self.params.selection)
    return bool_atom_selection

  def proxy_select(self, n_seq, iselection):
    new_manager = ramachandran_manager(
      pdb_hierarchy = self.hierarchy,
      params        = self.params,
      log           = self.log,
      proxies = (None if self.get_n_oldfield_proxies() == 0 else self._oldfield_proxies.proxy_select(n_seq, iselection),
                 None if self.get_n_emsley_proxies()   == 0 else self._emsley_proxies.proxy_select(n_seq, iselection),
                 None if self.get_n_emsley8k_proxies() == 0 else self._emsley8k_proxies.proxy_select(n_seq, iselection),
                 None if self.get_n_phi_psi_2_proxies() == 0 else self._phi_psi_2_proxies.proxy_select(n_seq, iselection),
                 ),
      tables = (self._oldfield_tables, self._emsley_tables, self._emsley8k_tables, self._phi_psi_2_tables),
      initialize=False)
    return new_manager

  def extract_proxies(self, hierarchy):
    def _get_motifs():
      from phenix.programs.phi_psi_2 import results_manager as pp2
      pp2_manager = pp2(model=None, log=self.log)
      phi_psi_2_motifs = pp2_manager.get_overall_motif_count_and_output(
        None,
        self.hierarchy,
        return_rama_restraints=True,
        )
      return phi_psi_2_motifs
    phi_psi_2_motifs = None
    favored = ramalyze.RAMALYZE_FAVORED
    allowed = ramalyze.RAMALYZE_ALLOWED
    outlier = ramalyze.RAMALYZE_OUTLIER
    self.hierarchy = hierarchy
    bool_atom_selection = self._determine_bool_atom_selection(hierarchy)
    selected_h = hierarchy.select(bool_atom_selection)
    n_seq = flex.max(selected_h.atoms().extract_i_seq())
    # Drop all previous proxies
    self._oldfield_proxies = ext.shared_phi_psi_proxy()
    self._emsley_proxies   = ext.shared_phi_psi_proxy()
    self._emsley8k_proxies = ext.shared_phi_psi_proxy()
    self._phi_psi_2_proxies = ext.shared_phi_psi_proxy()
    # it would be great to save rama_eval, but the fact that this is called in
    # pdb_interpretation, not in mmtbx.model makes it impossible
    self.rama_eval = rama_eval()
    outl = []
    for three in generate_protein_threes(hierarchy=selected_h, geometry=None):
      rc = three.get_phi_psi_atoms()
      if rc is None: continue
      rama_key = three.get_ramalyze_key()
      angles = three.get_phi_psi_angles()
      rama_score = self.rama_eval.get_score(rama_key, angles[0], angles[1])
      r_eval = self.rama_eval.evaluate_score(rama_key, rama_score)
      phi_atoms, psi_atoms = rc
      i_seqs = [atom.i_seq for atom in phi_atoms] + [psi_atoms[-1].i_seq]
      resnames = three.get_resnames()
      r_name = resnames[1]
      assert rama_key in range(6)
      text_rama_key = ramalyze.res_types[rama_key]
      assert text_rama_key in ["general", "glycine", "cis-proline",
        "trans-proline", "pre-proline", "isoleucine or valine"]
      # pick where to put...
      ev_match_dict = {
        favored: self.params.favored,
        allowed: self.params.allowed,
        outlier: self.params.outlier}
      r_type = ev_match_dict[r_eval]
      if r_type == 'oldfield':
        proxy = ext.phi_psi_proxy(
          residue_type = text_rama_key,
          i_seqs       = i_seqs,
          weight       = 1) # XXX Not used in oldfield
        self.append_oldfield_proxies(proxy, n_seq)

        ### THIS IS CRUEL. REMOVE ONCE favored/allowed/outlier are made multiple!
        if(self.params.inject_emsley8k_into_oldfield_favored):
          proxy = ext.phi_psi_proxy(
            residue_type = text_rama_key,
            i_seqs       = i_seqs,
            weight       = 5)
          self.append_emsley8k_proxies(proxy, n_seq)
        ###

      elif r_type == 'emsley':
        weight = self.params.emsley.weight
        proxy = ext.phi_psi_proxy(
          residue_type = text_rama_key,
          i_seqs       = i_seqs,
          weight       = weight)
        self.append_emsley_proxies(proxy, n_seq)
      elif r_type == 'emsley8k':
        if(  r_eval is favored): weight=self.params.emsley8k.weight_favored
        elif(r_eval is allowed): weight=self.params.emsley8k.weight_allowed
        elif(r_eval is outlier): weight=self.params.emsley8k.weight_outlier
        else:                    raise RuntimeError("Rama eveluation failed.")
        proxy = ext.phi_psi_proxy(
          residue_type = text_rama_key,
          i_seqs       = i_seqs,
          weight       = weight)
        self.append_emsley8k_proxies(proxy, n_seq)
      elif r_type == 'phi_psi_2':
        from mmtbx.validation.phi_psi_2_data import get_phi_psi_key_for_rama_proxy
        if phi_psi_2_motifs is None: phi_psi_2_motifs = _get_motifs()
        if(  r_eval is favored): strategy=self.params.phi_psi_2.favored_strategy
        elif(r_eval is allowed): strategy=self.params.phi_psi_2.allowed_strategy
        elif(r_eval is outlier): strategy=self.params.phi_psi_2.outlier_strategy
        else:                    raise RuntimeError("Rama eveluation failed.")
        if strategy=='closest':
          strategy+='_%0.1f_%0.1f' % tuple(three.get_phi_psi_angles())
        pp2_key = get_phi_psi_key_for_rama_proxy(phi_psi_2_motifs,
                                                 three,
                                                 strategy=strategy,
                                                 )
        if pp2_key is None: continue
        weight=1
        proxy = ext.phi_psi_proxy(
          residue_type = pp2_key,
          i_seqs       = i_seqs,
          weight       = weight)
        outl.append([proxy.residue_type, three])
        self.append_phi_psi_2_proxies(proxy, n_seq)
      elif(r_type is None): pass
      else:
        raise RuntimeError("Not an option: %s"%str(r_type))

    print("", file=self.log)
    print("  %d Ramachandran restraints generated." % (
        self.get_n_proxies()), file=self.log)
    print("    %d Oldfield, %d Emsley, %d emsley8k and %d Phi/Psi/2." % (
      self.get_n_oldfield_proxies(),
      self.get_n_emsley_proxies(),
      self.get_n_emsley8k_proxies(),
      self.get_n_phi_psi_2_proxies()), file=self.log)
    if outl:
      print('    Rama restraints by Phi/Psi/2')
      for pp2, three in outl:
        print('      %s : %s' % (three[1].id_str(), pp2.split('|')[0]), file=self.log)

  @staticmethod
  def _append_proxies(proxies, proxy, n_seq):
    if not is_proxy_present(proxies, n_seq, proxy):
      proxies.append(proxy)

  def append_oldfield_proxies(self, proxy, n_seq):
    ramachandran_manager._append_proxies(self._oldfield_proxies, proxy, n_seq)

  def append_emsley_proxies(self, proxy, n_seq):
    ramachandran_manager._append_proxies(self._emsley_proxies, proxy, n_seq)

  def append_emsley8k_proxies(self, proxy, n_seq):
    ramachandran_manager._append_proxies(self._emsley8k_proxies, proxy, n_seq)

  def append_phi_psi_2_proxies(self, proxy, n_seq):
    ramachandran_manager._append_proxies(self._phi_psi_2_proxies, proxy, n_seq)

  def update_phi_psi_targets_on_init(self, hierarchy):
    if 'oldfield' in [self.params.favored, self.params.allowed, self.params.outlier]:
      sites_cart = hierarchy.atoms().extract_xyz()
      self.target_phi_psi = phi_psi_targets(
        sites_cart     = hierarchy.atoms().extract_xyz(),
        proxies        = self._oldfield_proxies,
        general_table  = self._oldfield_tables.general,
        gly_table      = self._oldfield_tables.gly,
        cispro_table   = self._oldfield_tables.cispro,
        transpro_table = self._oldfield_tables.transpro,
        prepro_table   = self._oldfield_tables.prepro,
        ileval_table   = self._oldfield_tables.ileval)
      return self.target_phi_psi
    return None

  def update_phi_psi_targets(self, hierarchy):
    self.hierarchy = hierarchy
    if not self.initialize:
      self.extract_proxies(hierarchy)
    self.update_phi_psi_targets_on_init(hierarchy)

  def target_and_gradients(self,
      unit_cell,
      sites_cart,
      gradient_array=None):
    if(gradient_array is None):
      gradient_array = flex.vec3_double(sites_cart.size(), (0.0,0.0,0.0))
    overall_residual_sum = 0
    # Oldfield
    self.residuals_array_oldfield = None #residuals_array_oldfield
    n_oldfield_proxies = self.get_n_oldfield_proxies()
    oldfield_residual_sum = 0
    if n_oldfield_proxies > 0:
      if self.residuals_array_oldfield is None:
        self.residuals_array_oldfield = flex.double(n_oldfield_proxies, 0.)
      op = self.params.oldfield
      w = op.weight
      if w is None:
        w = 0.
      oldfield_residual_sum = ramachandran_residual_sum(
          sites_cart=sites_cart,
          proxies=self._oldfield_proxies,
          gradient_array=gradient_array,
          phi_psi_targets = self.target_phi_psi,
          weights=(w, op.weight_scale, op.distance_weight_min, op.distance_weight_max),
          residuals_array=self.residuals_array_oldfield)
      overall_residual_sum += oldfield_residual_sum
    # Emsley
    self.residuals_array_emsley = None #residuals_array_emsley
    n_emsley_proxies = self.get_n_emsley_proxies()
    if n_emsley_proxies > 0:
      if self.residuals_array_emsley is None:
        self.residuals_array_emsley = flex.double(n_emsley_proxies, 0.)
      #assert (self.params.rama_weight >= 0.0)
      # Moving these cycles to C++ part would speed them up only up to 10%
      for i, proxy in enumerate(self._emsley_proxies):
        rama_table = self._emsley_tables[self.new_to_old_conversion[proxy.residue_type]]
        self.residuals_array_emsley[i] = rama_table.compute_gradients(
            gradient_array=gradient_array,
            sites_cart=sites_cart,
            proxy=proxy,
            epsilon=0.001)
      overall_residual_sum += flex.sum(self.residuals_array_emsley)
    # emsley8k
    self.residuals_array_emsley8k = None
    n_emsley8k_proxies = self.get_n_emsley8k_proxies()
    if n_emsley8k_proxies > 0:
      if self.residuals_array_emsley8k is None:
        self.residuals_array_emsley8k = flex.double(n_emsley8k_proxies, 0.)
      for i, proxy in enumerate(self._emsley8k_proxies):
        rama_table = self._emsley8k_tables[proxy.residue_type]
        self.residuals_array_emsley8k[i] = rama_table.compute_gradients(
          gradient_array = gradient_array,
          sites_cart     = sites_cart,
          proxy          = proxy,
          epsilon        = 1.0) # XXX
      overall_residual_sum += flex.sum(self.residuals_array_emsley8k)
    # phi/psi/2
    from mmtbx.validation.phi_psi_2_data import get_rama_table
    self.residuals_array_phi_psi_2 = None
    n_phi_psi_2_proxies = self.get_n_phi_psi_2_proxies()
    if n_phi_psi_2_proxies:
      if self.residuals_array_phi_psi_2 is None:
        self.residuals_array_phi_psi_2 = flex.double(n_phi_psi_2_proxies, 0.)
      for i, proxy in enumerate(self._phi_psi_2_proxies):
        # assert self.params.phi_psi_2.outlier_strategy=='highest_probability'
        rama_table = get_rama_table(
          proxy,
          self._phi_psi_2_tables,
          )
        if rama_table is None: continue
        self.residuals_array_phi_psi_2[i] = rama_table.compute_gradients(
          gradient_array = gradient_array,
          sites_cart     = sites_cart,
          proxy          = proxy,
          epsilon        = 1.0) # XXX
      overall_residual_sum += flex.sum(self.residuals_array_phi_psi_2)
    return overall_residual_sum

  def get_n_oldfield_proxies(self):
    if self._oldfield_proxies is not None:
      return self._oldfield_proxies.size()
    return 0

  def get_n_emsley_proxies(self):
    if self._emsley_proxies is not None:
      return self._emsley_proxies.size()
    return 0

  def get_n_emsley8k_proxies(self):
    if self._emsley8k_proxies is not None:
      return self._emsley8k_proxies.size()
    return 0

  def get_n_phi_psi_2_proxies(self):
    if self._phi_psi_2_proxies is not None:
      return self._phi_psi_2_proxies.size()
    return 0

  def get_n_proxies(self):
    return self.get_n_emsley_proxies() + \
           self.get_n_oldfield_proxies() + \
           self.get_n_emsley8k_proxies() + self.get_n_phi_psi_2_proxies()

  def _get_sorted_proxies_for_show(self,
      by_value,
      sites_cart,
      site_labels=None):
    class rama_for_show:
      def __init__(self,
          labels,
          residual):
        adopt_init_args(self, locals())
    assert by_value in ["residual", "delta"]
    assert site_labels is None or len(site_labels) == sites_cart.size()
    if self.get_n_proxies() == 0:
      return
    self.target_and_gradients(
        unit_cell=None,
        sites_cart=sites_cart)
    result_oldfield = []
    result_emsley   = []
    result_emsley8k  = []
    result_phi_psi_2 = []
    labels = site_labels if site_labels is not None \
        else [str(i) for i in range(sites_cart.size())]
    for proxies, residual_array, result in [
        (self._oldfield_proxies, self.residuals_array_oldfield, result_oldfield),
        (self._emsley_proxies, self.residuals_array_emsley, result_emsley),
        (self._emsley8k_proxies, self.residuals_array_emsley8k, result_emsley8k),
        (self._phi_psi_2_proxies, self.residuals_array_phi_psi_2, result_phi_psi_2),
        ]:
      if proxies is not None and proxies.size() > 0:
        for i, pr in enumerate(proxies):
          i_seqs = pr.get_i_seqs()
          result.append(rama_for_show(
              [labels[i_seqs[0]],
               labels[i_seqs[1]],
               labels[i_seqs[2]],
               labels[i_seqs[3]],
               labels[i_seqs[4]]],
              residual_array[i]))
        if by_value == "residual":
          result.sort(key=lambda x: x.residual, reverse=True)
    return result_oldfield, result_emsley, result_emsley8k, result_phi_psi_2

  def show_sorted(self,
      by_value,
      sites_cart,
      site_labels=None,
      proxy_label=None, # not used yet
      f=None,
      prefix="",
      max_items=None):
    if self.get_n_proxies() == 0:
      return
    if (f is None): f = sys.stdout
    if by_value != "residual":
      by_value = "residual"
    sorted_oldfield_proxies_for_show, \
    sorted_emsley_proxies_for_show, \
    sorted_emsley8k_proxies_for_show, \
    sorted_phi_psi_2_proxies_for_show = \
      self._get_sorted_proxies_for_show(
        by_value=by_value,
        sites_cart=sites_cart,
        site_labels=site_labels)
    for proxies, label in [
        (sorted_oldfield_proxies_for_show, "Oldfield"),
        (sorted_emsley_proxies_for_show, "Emsley"),
        (sorted_emsley8k_proxies_for_show, "emsley8k"),
        (sorted_phi_psi_2_proxies_for_show, "phi/psi/2"),
        ]:
      print("Ramachandran plot restraints (%s): %d" % (label, len(proxies)), file=f)
      print("Sorted by %s:" % by_value, file=f)
      for p in proxies:
        print("phi-psi angles formed by             residual", file=f)
        print("    %s            %5.2e" % (p.labels[0], p.residual), file=f)
        for i in range(1,5):
          print("    %s" % p.labels[i], file=f)
      print("", file=f)

def load_tables():
  tables = {}
  for residue_type in ["ala", "gly", "prepro", "pro"] :
    file_name = libtbx.env.find_in_repositories(
      relative_path="chem_data/rotarama_data/%s.rama.combined.data" %
        residue_type,
      test=os.path.isfile)
    data = flex.double()
    with open(file_name, "r") as f:
      lines = f.readlines()
    for line in lines:
      val, phi, psi = line.split()
      assert ((int(phi) % 2 == 1) and (int(psi) % 2 == 1))
      data.append(float(val))
    t = lookup_table(data, 180)
    tables[residue_type] = t
  return tables

def load_emsley8k_tables():
  tables = {}
  name_to_file = [
    ("general",              "rama8000-general-noGPIVpreP.data", 0),
    ("glycine",              "rama8000-gly-sym.data", 1),
    ("cis-proline",          "rama8000-cispro.data", 2),
    ("trans-proline",        "rama8000-transpro.data", 3),
    ("pre-proline",          "rama8000-prepro-noGP.data", 4),
    ("isoleucine or valine", "rama8000-ileval-nopreP.data", 5)]
  tmp = OrderedDict()
  rr = [i for i in range(-179,180,2)]
  for i in rr:
    for j in rr:
      tmp[(i,j)]=0
  R = ramachandran_eval.RamachandranEval()
  outlier = ramalyze.RAMALYZE_OUTLIER
  favored = ramalyze.RAMALYZE_FAVORED
  allowed = ramalyze.RAMALYZE_ALLOWED
  for (rama_key, file_name, selfstore) in name_to_file:
    file_name = libtbx.env.find_in_repositories(
      relative_path="chem_data/rotarama_data/%s"%(file_name),
      test=os.path.isfile)
    di        = {}
    outlier_vals = flex.double()
    favored_vals = flex.double()
    allowed_vals = flex.double()
    status       = {}
    with open(file_name, "r") as f:
      lines = f.readlines()
    for line in lines:
      if line[0]=="#": continue
      phi, psi, val = line.split()
      phi=int(float(phi))
      psi=int(float(psi))
      val=float(val)
      di[(phi,psi)]=val
      rama_score = R.rama_eval.get_score(selfstore, phi, psi)
      evaluation = R.rama_eval.evaluate_score(selfstore, rama_score)
      if  (evaluation==outlier):
        outlier_vals.append(val)
        status[(phi,psi)]=outlier
      elif(evaluation==favored):
        favored_vals.append(val)
        status[(phi,psi)]=favored
      elif(evaluation==allowed):
        allowed_vals.append(val)
        status[(phi,psi)]=allowed
      else: raise RuntimeError("Not supposed to be here.")
    data = flex.double()
    max_outlier = flex.max(outlier_vals)
    max_favored = flex.max(favored_vals)
    min_favored = flex.min(favored_vals)
    max_allowed = flex.max(allowed_vals)
    for k, v in zip(tmp.keys(), tmp.values()):
      try:
        val = di[k]
        if  (status[k]==outlier): val = -1 + val/max_outlier
        elif(status[k]==favored): val = val #math.exp(val)**0.5/2.71828182846**0.5 #math.exp(val)**3
        elif(status[k]==allowed): val = val #math.exp(val)**0.5/2.71828182846**0.5 #math.exp(val/max_allowed)**3
      except KeyError:
        val = -1
      data.append(val)
    t = lookup_table(data, 180)
    tables[rama_key] = t
  return tables

def load_phi_psi_2_tables():
  from mmtbx.validation.phi_psi_2_data import load_phi_psi_2_rama_restraints_tables
  return load_phi_psi_2_rama_restraints_tables()

class ramachandran_plot_data(object):
  def __init__(self, plot_cutoff=0.027):
    self.plot_cutoff = plot_cutoff
    self.general = None
    self.gly = None
    self.cispro = None
    self.transpro = None
    self.prepro = None
    self.ileval = None
    stuff = [None]*6
    data = [
      ("general",              "rama8000-general-noGPIVpreP.data", 0),
      ("glycine",              "rama8000-gly-sym.data", 1),
      ("cis-proline",          "rama8000-cispro.data", 2),
      ("trans-proline",        "rama8000-transpro.data", 3),
      ("pre-proline",          "rama8000-prepro-noGP.data", 4),
      ("isoleucine or valine", "rama8000-ileval-nopreP.data", 5)]
    for (rama_key, file_name, selfstore) in data:
      file_name = libtbx.env.find_in_repositories(
        relative_path="chem_data/rotarama_data/%s" % file_name,
        test = os.path.isfile)
      stuff[selfstore] = flex.vec3_double()
      with open(file_name, "r") as f:
        lines = f.readlines()
      for line in lines:
        line = line.split()
        if(len(line)==3):
          phi_, psi_, val = float(line[0]),float(line[1]),float(line[2])
          triplet = [phi_, psi_, val]
          stuff[selfstore].append(triplet)
    self.general  = self.select_good(data=stuff[0], step=1)
    self.gly      = self.select_good(data=stuff[1], step=1)
    self.cispro   = self.select_good(data=stuff[2], step=1)
    self.transpro = self.select_good(data=stuff[3], step=1)
    self.prepro   = self.select_good(data=stuff[4], step=1)
    self.ileval   = self.select_good(data=stuff[5], step=1)

  def select_good(self, data, step):
    phi, psi, val = self.split_array(data=data)
    # 0.02 is border for favored, 0.007 - arbitrary addition to ensure more
    # residues in favored region. Moved to plot_cutoff.
    sel = (val>self.plot_cutoff)
    phi_values = set(list(phi))
    psi_values = set(list(psi))
    phi_list = sorted(phi_values)
    psi_list = sorted(psi_values)
    needed_phi_values = set([phi_list[i] for i in range(0, len(phi_list),step)])
    needed_psi_values = set([psi_list[i] for i in range(0, len(psi_list),step)])
    result = flex.vec3_double()
    selected = data.select(sel)
    for phi, psi, val in selected:
      if phi in needed_phi_values and psi in needed_psi_values:
        result.append([phi, psi, val])
    return result

  def split_array(self, data):
    phi = flex.double()
    psi = flex.double()
    val = flex.double()
    for x,y,z in data:
      phi.append(x)
      psi.append(y)
      val.append(z)
    return phi, psi, val


 *******************************************************************************


 *******************************************************************************
mmtbx/geometry_restraints/reference.py
from __future__ import absolute_import, division, print_function
from cctbx.array_family import flex
from cctbx import geometry_restraints
from libtbx.utils import Sorry
import boost_adaptbx.boost.python as bp
ext = bp.import_ext("mmtbx_reference_coordinate_ext")
from mmtbx.rotamer.sidechain_angles import collect_residue_torsion_angles


def generate_torsion_restraints(
      pdb_hierarchy,
      sites_cart,
      selection=None,
      sigma=2.5,
      limit=15.0,
      chi_angles_only=False,
      top_out_potential=False,
      origin_id=None):
  """
  selection ties up hierarchy with sites cart. Basically, if applied
    to hierarchy, remaining atoms should correspond to sites_cart.
    Therefore it is necessary that
    len(sites_cart) == len(actual_selection) below.
    This seems to be done this way to make it possible to use sites_cart
    from another source (reference model) which is not necessary
    of the same size as hierarchy.
  """
  pdb_hierarchy.atoms().reset_i_seq()
  torsion_proxies = geometry_restraints.shared_dihedral_proxy()
  if pdb_hierarchy.atoms_size() < 4:
    return torsion_proxies
  assert not pdb_hierarchy.atoms().extract_i_seq().all_eq(0)
  bool_pdbh_selection = flex.bool(pdb_hierarchy.atoms_size(), False)
  if (selection is not None):
    if (isinstance(selection, flex.bool)):
      assert len(selection) == pdb_hierarchy.atoms_size()
      bool_pdbh_selection = selection
    elif (isinstance(selection, flex.size_t)):
      bool_pdbh_selection.set_selected(selection, True)
  if selection is None:
    bool_pdbh_selection = flex.bool(pdb_hierarchy.atoms_size(), True)
  actual_selection = bool_pdbh_selection.iselection()

  assert len(sites_cart) == len(actual_selection)

  if abs(sigma) < 1e-6:
    raise Sorry("Please set non-zero sigma for reference model restraints.")
  weight = 1.0 / (sigma**2)
  selection_to_sites_map = get_selection_to_sites_map(
                             sites_cart=sites_cart,
                             selection=actual_selection)
  residue_torsions = collect_residue_torsion_angles(
                   pdb_hierarchy=pdb_hierarchy,
                   atom_selection=bool_pdbh_selection,
                   chi_angles_only=chi_angles_only)
  for residue_info in residue_torsions:
    for chi in residue_info.chis:
      i_seqs = chi.i_seqs
      sites = []
      for i_seq in i_seqs:
        sites.append(selection_to_sites_map[i_seq])
      di = geometry_restraints.dihedral(
             sites=sites, angle_ideal=0.0, weight=weight)
      angle_ideal = di.angle_model
      dp = geometry_restraints.dihedral_proxy(
        i_seqs=i_seqs,
        angle_ideal=angle_ideal,
        weight=weight,
        limit=limit,
        top_out=top_out_potential,
        origin_id=origin_id)
      torsion_proxies.append(dp)
  return torsion_proxies

def get_selection_to_sites_map(sites_cart, selection):
  sites_selection_map = {}
  assert isinstance(selection, flex.size_t)
  for i, i_seq in enumerate(selection):
    sites_selection_map[i_seq] = sites_cart[i]
  return sites_selection_map

def add_coordinate_restraints(
      sites_cart,
      selection=None,
      sigma=0.5,
      limit=1.0,
      top_out_potential=False):
  import boost_adaptbx.boost.python as bp
  ext_rcp = bp.import_ext("mmtbx_reference_coordinate_ext")
  result = ext_rcp.shared_reference_coordinate_proxy()
  if (selection is not None):
    if (isinstance(selection, flex.bool)):
      selection = selection.iselection()
  if selection is None:
    selection = flex.bool(
      len(sites_cart),
      True).iselection()
  # Not clear why this assertion should present. What if we want to restrain
  # only part of the molecule?
  # Very likely the mechanics is similar to the above procedure (generate_torsion_restraints),
  # selection is related to sites_cart.
  assert len(sites_cart) == len(selection)
  weight = 1.0 / (sigma**2)
  for k, i_seq in enumerate(selection):
    i_seqs = [i_seq]
    ref_sites = sites_cart[k]
    proxy = ext_rcp.reference_coordinate_proxy(
              i_seqs=i_seqs,
              ref_sites=ref_sites,
              weight=weight,
              limit=limit,
              top_out=top_out_potential)
    result.append(proxy)
  return result

def exclude_outliers_from_reference_restraints_selection(
    pdb_hierarchy,
    restraints_selection):
  from mmtbx.validation.ramalyze import ramalyze
  # the import below is SLOW!!!
  from mmtbx.rotamer.rotamer_eval import RotamerEval
  assert restraints_selection is not None
  # ramachandran plot outliers
  rama_outlier_selection = ramalyze(pdb_hierarchy=pdb_hierarchy,
    outliers_only=False).outlier_selection()
  rama_outlier_selection = flex.bool(restraints_selection.size(),
    rama_outlier_selection)
  # rotamer outliers
  rota_outlier_selection = flex.size_t()
  rotamer_manager = RotamerEval() # SLOW!!!
  for model in pdb_hierarchy.models():
    for chain in model.chains():
      for residue_group in chain.residue_groups():
        conformers = residue_group.conformers()
        if(len(conformers)>1): continue
        for conformer in residue_group.conformers():
          residue = conformer.only_residue()
          if(rotamer_manager.evaluate_residue(residue)=="OUTLIER"):
            rota_outlier_selection.extend(residue.atoms().extract_i_seq())
  rota_outlier_selection = flex.bool(restraints_selection.size(),
    rota_outlier_selection)
  outlier_selection = rama_outlier_selection | rota_outlier_selection
  return restraints_selection & (~outlier_selection)


 *******************************************************************************


 *******************************************************************************
mmtbx/geometry_restraints/torsion_restraints/__init__.py


 *******************************************************************************


 *******************************************************************************
mmtbx/geometry_restraints/torsion_restraints/reference_model.py
from __future__ import absolute_import, division, print_function
import cctbx.geometry_restraints
from mmtbx.validation import rotalyze
from mmtbx.utils import rotatable_bonds
from mmtbx.rotamer.sidechain_angles import SidechainAngles
import mmtbx.monomer_library
from cctbx.array_family import flex
import iotbx.phil
import libtbx.load_env
from libtbx.utils import Sorry
from mmtbx import secondary_structure
from scitbx.matrix import rotate_point_around_axis
from libtbx.str_utils import make_sub_header
from mmtbx.geometry_restraints.torsion_restraints import utils
import sys
import time
import iotbx
from six.moves import zip
from six.moves import range

TOP_OUT_FLAG = True

renamed_ncs_search_str = iotbx.ncs.ncs_search_options.replace(
    "ncs_search", "search_options")
renamed_ncs_search_str = renamed_ncs_search_str.replace(
    "chain_max_rmsd = 2.", "chain_max_rmsd = 100.")
renamed_ncs_search_str = renamed_ncs_search_str.replace(
    "residue_match_radius = 4.0", "residue_match_radius = 1000")
# removing 'enabled' parameter
i1 = renamed_ncs_search_str.find("enabled")
i2 = renamed_ncs_search_str.find("exclude_selection")
renamed_ncs_search_str = renamed_ncs_search_str[:i1]+renamed_ncs_search_str[i2:]

reference_model_str = """
reference_model
    .caption = The reference torsion restraints are used to steer refinement \
      of the  working model.  This technique is advantageous in cases where \
      the working data set is low resolution, but there is a known related \
      structure solved at higher resolution.  The higher resolution \
      reference model is used to generate a set of dihedral restraints \
      that are applied to each matching dihedral in the working model. \
      To specify a PDB file as the reference model, add it to the list of \
      input files in the main window, then change the data type from \
      "Input model" to "Reference model".
    .style = box auto_align menu_item
    .short_caption = Reference model restraints
{
  enabled = False
    .short_caption = Reference model restraints
    .type = bool
    .help = Restrains the dihedral angles to a high-resolution reference \
      structure to reduce overfitting at low resolution.  You will need to \
      specify a reference PDB file (in the input list in the main window) \
      to use this option.
    .style = bold noauto
  file = None
    .type = path
    .short_caption = Reference model
    .style = bold file_type:pdb hidden
    .multiple = True
  use_starting_model_as_reference = False
    .type = bool
    .short_caption = use starting model as reference
  sigma = 1.0
    .type = float(value_min=0.001)
  limit = 15.0
    .type = float
  hydrogens = False
    .type = bool
    .help = Include dihedrals with hydrogen atoms
  main_chain = True
    .type = bool
    .help = Include dihedrals formed by main chain atoms
  side_chain = True
    .type = bool
    .help = Include dihedrals formed by side chain atoms
  fix_outliers = True
    .type = bool
    .help = Try to fix rotamer outliers in refined model
  strict_rotamer_matching = False
    .type = bool
    .help = Make sure that rotamers in refinement model matches those in \
      reference model even when they are not outliers
  auto_shutoff_for_ncs = False
    .type = bool
    .help = Do not apply to parts of structure covered by NCS restraints
  secondary_structure_only = False
    .type = bool
    .help = Only apply reference model restraints to secondary structure \
      elements (helices and sheets)
  reference_group
    .multiple=True
    .optional=True
    .short_caption=Reference group
    .style = noauto auto_align menu_item parent_submenu:reference_model
  {
    reference=None
      .type=atom_selection
      .short_caption=Selection in the reference model
    selection=None
      .type=atom_selection
      .short_caption=Selection in the refined model
    file_name=None
      .type=path
      .optional=True
      .short_caption = Reference model for this restraint group
      .style = bold hidden
      .help = this is to used internally to disambiguate cases where multiple \
              reference models contain the same chain ID. This normally does \
              not need to be set by the user
  }
  %s
}
""" % renamed_ncs_search_str

reference_model_params = iotbx.phil.parse(
    reference_model_str)

def add_reference_dihedral_restraints_if_requested(
    model,
    geometry,
    params=None,
    selection=None,
    log=None):
  if not params.enabled:
    return 0
  if (params.use_starting_model_as_reference and
    (len(params.file) > 0) and params.file[0] is not None):
    raise Sorry("Cannot not restrain working model to self and a "+
                    "reference model simultaneously")
  reference_file_list = set()
  reference_hierarchy_list = None
  if params.use_starting_model_as_reference:
    reference_hierarchy_list = [model.get_hierarchy()]
    reference_file_list = None
    print("*** Restraining model using starting model ***", file=log)
  else:
    for file_name in params.file:
      reference_file_list.add(file_name)
    for rg in params.reference_group:
      if rg.file_name is not None:
        reference_file_list.add(rg.file_name)
  print("*** Adding Reference Model Restraints (torsion) ***", file=log)
  #test for inserted TER cards in working model
  ter_indices = model._ter_indices
  if ter_indices is not None:
    utils.check_for_internal_chain_ter_records(
      pdb_hierarchy=model.get_hierarchy(),
      ter_indices=ter_indices)
  if reference_file_list is not None:
    reference_file_list = list(reference_file_list)
  rm = reference_model(
    model,
    reference_file_list=reference_file_list,
    reference_hierarchy_list=reference_hierarchy_list,
    params=params,
    selection=selection,
    log=log)
  rm.show_reference_summary(log=log)
  geometry.adopt_reference_dihedral_manager(rm)

class reference_model(object):

  def __init__(self,
               model,
               reference_hierarchy_list=None,
               reference_file_list=None,
               params=None,
               selection=None,
               log=None):
    assert [reference_hierarchy_list,
            reference_file_list].count(None) == 1
    if(log is None):
      log = sys.stdout
    self.log=log
    # self.model = model
    self.params = params
    self.selection = selection
    self.mon_lib_srv = model.get_mon_lib_srv()
    self.ener_lib = model.get_ener_lib()
    self.pdb_hierarchy = model.get_hierarchy()
    self.pdb_hierarchy.reset_i_seq_if_necessary()
    sites_cart = self.pdb_hierarchy.atoms().extract_xyz()
    if self.selection is None:
      self.selection = flex.bool(len(sites_cart), True)
    if reference_hierarchy_list is None:
      reference_hierarchy_list = \
        utils.process_reference_files(
          reference_file_list=reference_file_list,
          log=log)
    if reference_file_list is None:
      reference_file_list = \
          ["ref%d" % x for x in range(len(reference_hierarchy_list))]
    #
    # this takes 20% of constructor time.
    self.dihedral_proxies_ref = utils.get_reference_dihedral_proxies(
        reference_hierarchy_list=reference_hierarchy_list,
        reference_file_list=reference_file_list,
        mon_lib_srv=self.mon_lib_srv,
        ener_lib=self.ener_lib,
        restraint_objects=model.get_restraint_objects(),
        monomer_parameters=model.get_monomer_parameters(),
        log=log)
    self.i_seq_name_hash = utils.build_name_hash(
                             pdb_hierarchy=self.pdb_hierarchy)
    #reference model components
    self.sites_cart_ref = {}
    self.pdb_hierarchy_ref = {}
    self.i_seq_name_hash_ref = {}
    self.reference_dihedral_hash = {}
    self.reference_file_list = reference_file_list
    #triage reference model files
    for file, hierarchy in zip(reference_file_list,
                               reference_hierarchy_list):
      self.sites_cart_ref[file] = hierarchy.atoms().extract_xyz()
      self.pdb_hierarchy_ref[file] = hierarchy
      self.i_seq_name_hash_ref[file] = \
        utils.build_name_hash(
          pdb_hierarchy=hierarchy)
      self.reference_dihedral_hash[file] = \
        self.build_dihedral_hash(
          dihedral_proxies=self.dihedral_proxies_ref[file],
          sites_cart=self.sites_cart_ref[file],
          pdb_hierarchy=hierarchy,
          include_hydrogens=self.params.hydrogens,
          include_main_chain=self.params.main_chain,
          include_side_chain=self.params.side_chain)
    self.match_map = None
    self.proxy_map = None
    self.build_reference_dihedral_proxy_hash()
    #
    # This takes 80% of constructor time!!!
    self.residue_match_hash = {} # {key_model: ('file_name', key_ref)}
    self.match_map = {} # {'file_name':{i_seq_model:i_seq_ref}}
    if params.use_starting_model_as_reference:
      self.get_matching_from_self()
    else:
      self.get_matching_from_ncs(log=log)
    if self.match_map == {}:
      # making empty container
      new_ref_dih_proxies = self.reference_dihedral_proxies = \
          cctbx.geometry_restraints.shared_dihedral_proxy()
    else:
      new_ref_dih_proxies = self.get_reference_dihedral_proxies(model)

  def get_matching_from_self(self):
    """ Shortcut for the case when restraining on starting model """
    if self.reference_file_list[0] not in self.match_map.keys():
      self.match_map[self.reference_file_list[0]] = {}
    for chain in self.pdb_hierarchy.only_model().chains():
      for rg in chain.residue_groups():
        # Filling out self.residue_match_hash
        key_model = "%s %s" % (rg.unique_resnames()[0], rg.id_str().strip())
        if key_model not in self.residue_match_hash:
          self.residue_match_hash[key_model] = (self.reference_file_list[0], key_model)
        # Filling out self.match_map
        for atom in rg.atoms():
          self.match_map[self.reference_file_list[0]][atom.i_seq] = atom.i_seq



  def _make_matching_and_fill_dictionaries(self, model_h, ref_h, fn,
      m_cache, model_selection_str="all", ref_selection_str="all"):
    ref_cache = self.pdb_hierarchy_ref[fn].atom_selection_cache()
    model_selection_str += " and not element H and not element D and not water"
    ref_selection_str += " and not element H and not element D and not water"
    m_sel = m_cache.selection(model_selection_str)
    ref_sel = ref_cache.selection(ref_selection_str)
    combined_h = model_h.select(m_sel).deep_copy()
    if combined_h.atoms_size() == 0:
      msg = "Selection '%s' selected 0 atoms in refined model.\n" % (model_selection_str) +\
          "Please check if the selection provided is correct."
      raise Sorry(msg)
    ref_h = ref_h.select(ref_sel).deep_copy()
    if ref_h.atoms_size() == 0:
      msg = "Reference selection '%s' selected 0 atoms in %s.\n" % (ref_selection_str, fn) +\
          "Please check if the selection provided is correct."
      raise Sorry(msg)
    for chain in ref_h.only_model().chains():
      chain.id +="ref"
    combined_h.transfer_chains_from_other(ref_h)
    combined_h.reset_atom_i_seqs()
    temp_h = combined_h.deep_copy()
    temp_h.atoms().reset_i_seq()

    # combined_h.write_pdb_file(fn+"_combined.pdb")
    ncs_obj = iotbx.ncs.input(
        hierarchy=temp_h,
        params = self.params.search_options,
        log = self.log)
    # For each found NCS group we going to do matching procedure between
    # copies
    for group_list in ncs_obj.get_ncs_restraints_group_list():
      # combine selections from master and copies into one list...
      n_total_selections = len(group_list.copies) + 1
      ncs_iselections = [group_list.master_iselection]
      ncs_residue_groups = []
      ncs_hierarchys = []
      for i in range(len(group_list.copies)):
        ncs_iselections.append(group_list.copies[i].iselection)
      # and loop over it making new hierarchies.
      for i, isel in enumerate(ncs_iselections):
        ncs_h = combined_h.select(isel)
        ncs_hierarchys.append(ncs_h)
        rgs = list(ncs_h.residue_groups())
        if len(rgs)>0:
          ncs_residue_groups.append(rgs)

      n_total_ncs_residue_groups = len(ncs_residue_groups)
      if n_total_ncs_residue_groups == 0:
        continue
      len_ncs_rg = len(ncs_residue_groups[0])
      for ncs_rg in ncs_residue_groups:
        assert len(ncs_rg) == len_ncs_rg
      if fn not in self.match_map.keys():
        self.match_map[fn] = {}
      ref_indeces = []
      for i in range(n_total_ncs_residue_groups):
        if (len(ncs_residue_groups[i][0].parent().id) > 2 and
            ncs_residue_groups[i][0].parent().id[-3:] == 'ref'):
          ref_indeces.append(i)
      if len(ref_indeces) == 0:
        # Reference model does not participate in particular found NCS copy.
        # If it is in another copy, that's fine.
        continue
      for i in range(n_total_ncs_residue_groups):
        # Figuring out what is reference and what is model
        if i in ref_indeces:
          continue
        a = ncs_residue_groups[i]
        for j in range(len_ncs_rg):
          model_rg = a[j]
          # Here we want to be smarter and find more appropriate reference,
          # in case A, Aref, B, Bref we want to match A-Aref, B-Bref
          current_ref_index = ref_indeces[0]
          if len(ref_indeces) > 1:
            model_chain_id = model_rg.parent().id
            for ri in ref_indeces:
              ref_chain_id = ncs_residue_groups[ri][j].parent().id
              if (ref_chain_id[:-3] == model_chain_id
                  or ref_chain_id == model_chain_id):
                current_ref_index = ri
          reference_rg = ncs_residue_groups[current_ref_index][j]
          # Filling out self.residue_match_hash
          if len(reference_rg.parent().id) > 2 and reference_rg.parent().id[-3:] == 'ref':
            reference_rg.parent().id = reference_rg.parent().id[:-3]
          key_model = "%s %s" % (model_rg.unique_resnames()[0],
              model_rg.id_str().strip())
          key_ref = "%s %s" % (reference_rg.unique_resnames()[0],
              reference_rg.id_str().strip())
          if key_model not in self.residue_match_hash:
            self.residue_match_hash[key_model] = (self.reference_file_list[0], key_ref)
          # Filling out self.match_map
          info_rgs = [[],[]]
          assert reference_rg.atoms_size() == model_rg.atoms_size(), "%s, %s" % (
              model_rg.id_str(), reference_rg.id_str())
          for rg, info in [(model_rg, info_rgs[0]), (reference_rg, info_rgs[1])]:
            info.append(rg.parent().id)
            info.append(rg.unique_resnames()[0])
            info.append(rg.resseq)
            info.append(rg.icode)
          m_str = "chain '%s' and resseq '%s' and icode '%s'" % (
              info_rgs[0][0], info_rgs[0][2], info_rgs[0][3])
          ref_str = "chain '%s' and resseq '%s' and icode '%s'" % (
              info_rgs[1][0], info_rgs[1][2], info_rgs[1][3])
          m_sel = m_cache.selection(m_str)
          ref_sel = ref_cache.selection(ref_str)
          for m_atom, ref_atom in zip(self.pdb_hierarchy.select(m_sel).atoms(),
              self.pdb_hierarchy_ref[fn].select(ref_sel).atoms()):
            self.match_map[fn][m_atom.i_seq] = ref_atom.i_seq

  def is_reference_groups_provided(self):
    if hasattr(self.params, "reference_group"):
      if (len(self.params.reference_group) == 0 or
          (len(self.params.reference_group) == 1 and
          self.params.reference_group[0].reference is None and
          self.params.reference_group[0].selection is None and
          self.params.reference_group[0].file_name is None)):
        return False
      else:
        for i, rg in enumerate(self.params.reference_group):
          if rg.file_name is None:
            if len(self.reference_file_list) > i:
              rg.file_name = self.reference_file_list[i]
            elif len(self.params.file) != 1:
              raise Sorry("Ambigous definition of groups in reference model")
            else:
              rg.file_name = self.params.file[0]
        return True
    else:
      return False

  def get_matching_from_ncs(self, log):
    import iotbx.ncs
    m_cache = self.pdb_hierarchy.atom_selection_cache()
    if not self.is_reference_groups_provided():
      # only files are specified
      for fn in self.reference_file_list:
        print("\nreference file: %s" % fn, file=log)
        print("Model:              Reference:", file=log)
        self._make_matching_and_fill_dictionaries(
            model_h=self.pdb_hierarchy,
            ref_h=self.pdb_hierarchy_ref[fn],
            fn=fn,
            m_cache=m_cache)
    else:
      # We got reference_group section
      for rg in self.params.reference_group:
        file_name = rg.file_name
        print("\nreference file: %s" % file_name, file=log)
        print("Model:              Reference:", file=log)
        self._make_matching_and_fill_dictionaries(
            model_h=self.pdb_hierarchy,
            ref_h=self.pdb_hierarchy_ref[file_name],
            fn=file_name,
            m_cache=m_cache,
            model_selection_str=rg.selection,
            ref_selection_str=rg.reference)

  def proxy_remove(self, selection=None):
    if self.reference_dihedral_proxies is not None:
      self.reference_dihedral_proxies = \
          self.reference_dihedral_proxies.proxy_remove(selection=selection)

  def proxy_select(self, n_seq, iselection):
    import copy
    new_proxies = None
    if self.reference_dihedral_proxies is not None:
      new_proxies = self.reference_dihedral_proxies.proxy_select(
          n_seq, iselection)
    new_manager = copy.copy(self)
    new_manager.reference_dihedral_proxies = new_proxies
    return new_manager

  def show_sorted(self, by_value, sites_cart, site_labels, proxy_label, f):
    if self.reference_dihedral_proxies is not None:
      self.reference_dihedral_proxies.show_sorted(
          by_value=by_value,
          sites_cart=sites_cart,
          site_labels=site_labels,
          proxy_label=proxy_label,
          f=f)

  def target_and_gradients(self, unit_cell, sites_cart, gradient_array):
    res_sum = 0
    if self.reference_dihedral_proxies is not None:
      if unit_cell is None:
        res_sum = cctbx.geometry_restraints.dihedral_residual_sum(
            sites_cart=sites_cart,
            proxies=self.reference_dihedral_proxies,
            gradient_array=gradient_array)
      else:
        res_sum = cctbx.geometry_restraints.dihedral_residual_sum(
            unit_cell=unit_cell,
            sites_cart=sites_cart,
            proxies=self.reference_dihedral_proxies,
            gradient_array=gradient_array)
    return res_sum

  def get_n_proxies(self):
    if self.reference_dihedral_proxies is not None:
      return self.reference_dihedral_proxies.size()
    return 0

  def top_out_function(self, x, weight, top):
    return top*(1-exp(-weight*x**2/top))

  def top_out_gradient(self, x, weight, top):
    return (2*weight*x)*exp(-(weight*x**2)/top)

  def top_out_curvature(self, x, weight, top):
    return (2*weight*(top - 2*weight*x**2))/top**2*exp(-(weight*x**2)/top)

  def build_reference_dihedral_proxy_hash(self):
    self.reference_dihedral_proxy_hash = {}
    for ref in self.dihedral_proxies_ref.keys():
      self.reference_dihedral_proxy_hash[ref] = {}
      proxies = self.dihedral_proxies_ref[ref]
      for dp in proxies:
        key = ""
        for i_seq in dp.i_seqs:
          key += self.i_seq_name_hash_ref[ref][i_seq]
        self.reference_dihedral_proxy_hash[ref][key] = dp

  def build_dihedral_hash(self,
                          dihedral_proxies=None,
                          sites_cart=None,
                          pdb_hierarchy=None,
                          include_hydrogens=False,
                          include_main_chain=True,
                          include_side_chain=True):
    if not include_hydrogens:
      i_seq_element_hash = \
        utils.build_element_hash(pdb_hierarchy=pdb_hierarchy)
    i_seq_name_hash = \
      utils.build_name_hash(pdb_hierarchy=pdb_hierarchy)
    dihedral_hash = dict()

    for dp in dihedral_proxies:
      try:
        #check for H atoms if required
        if not include_hydrogens:
          for i_seq in dp.i_seqs:
            if i_seq_element_hash[i_seq] == " H":
              raise StopIteration()
        #ignore backbone dihedrals
        if not include_main_chain:
          sc_atoms = False
          for i_seq in dp.i_seqs:
            if i_seq_name_hash[i_seq][0:4] not in [' CA ',' N  ',' C  ',' O  ']:
              sc_atoms = True
              break
          if not sc_atoms:
            raise StopIteration()
        if not include_side_chain:
          sc_atoms = False
          for i_seq in dp.i_seqs:
            if i_seq_name_hash[i_seq][0:4] \
              not in [' CA ', ' N  ', ' C  ', ' O  ']:
              sc_atoms = True
              break
          if sc_atoms:
            raise StopIteration()
        key = ""
        for i_seq in dp.i_seqs:
          key = key+i_seq_name_hash[i_seq]
        di = \
          cctbx.geometry_restraints.dihedral(
            sites_cart=sites_cart,
            proxy=dp)
        dihedral_hash[key] = di.angle_model
      except StopIteration:
        pass
    return dihedral_hash

  def _is_proxy_already_present(self, proxy_array, proxy):
    for p in proxy_array:
      if proxy.i_seqs == p.i_seqs:
        return True
    return False

  def get_reference_dihedral_proxies(self, model):
    complete_dihedral_proxies = utils.get_dihedrals_and_phi_psi(
        model=model)
    generated_reference_dihedral_proxies = \
      cctbx.geometry_restraints.shared_dihedral_proxy()
    sigma = self.params.sigma
    limit = self.params.limit
    ref_ss_m = None
    ss_selection = None
    if self.params.secondary_structure_only:
      if (not libtbx.env.has_module(name="ksdssp")):
        raise RuntimeError(
          "ksdssp module is not configured, "+\
          "cannot generate secondary structure reference")
      ref_ss_m = {}
      ss_selection = {}
      for file in self.reference_file_list:
        ref_ss_m[file] = secondary_structure.manager(
          pdb_hierarchy=self.pdb_hierarchy_ref[file],
          sec_str_from_pdb_file=None)
        sec_str_from_pdb_file = ref_ss_m[file].actual_sec_str
        if sec_str_from_pdb_file != None:
          overall_selection = sec_str_from_pdb_file.overall_selection()
          sel_cache_ref = self.pdb_hierarchy_ref[file].atom_selection_cache()
          bsel = sel_cache_ref.selection(string=overall_selection)
          if bsel.all_eq(False):
            raise Sorry("No atom selected")
          ss_selection[file] = bsel

    t_sum = 0
    for dp in complete_dihedral_proxies:
      key_work = ""
      complete = True
      for i_seq in dp.i_seqs:
        if not self.selection[i_seq]:
          complete = False
      if not complete:
        continue

      for i_seq in dp.i_seqs:
        key_work = key_work + self.i_seq_name_hash[i_seq]
      #find matching key
      key = None
      file_match = None
      for file in self.reference_file_list:
        if key is not None or file not in self.match_map:
          continue
        else:
          key = ""
          ref_match = True
          for i_seq in dp.i_seqs:
            if ref_match:
              map_part = self.match_map[file].get(i_seq)
              if map_part is not None:
                key_part = self.i_seq_name_hash_ref[file].get(map_part)
                if key_part is None:
                  ref_match = False
                  key = None
                  file_match = None
                else:
                  key = key+key_part
              else:
                ref_match = False
                key = None
                file_match = None
            if key is not None:
              file_match = file
      try:
        reference_angle = self.reference_dihedral_hash[file_match][key]
      except Exception:
        continue
      w_limit = limit
      w_weight = 1/sigma**2
      if (self.params.secondary_structure_only and ss_selection is not None
          and ss_selection[file_match] is not None):
        limit2 = 15.0
        w_weight = 0.04
        if (ss_selection[file_match][self.match_map[file_match][dp.i_seqs[0]]] and
            ss_selection[file_match][self.match_map[file_match][dp.i_seqs[1]]] and
            ss_selection[file_match][self.match_map[file_match][dp.i_seqs[2]]] and
            ss_selection[file_match][self.match_map[file_match][dp.i_seqs[3]]]):
          limit2 = 30.0
          w_weight = 1
        dp_add = cctbx.geometry_restraints.dihedral_proxy(
            i_seqs=dp.i_seqs,
            angle_ideal=reference_angle,
            weight=w_weight,
            limit=w_limit,
            top_out=TOP_OUT_FLAG)
        generated_reference_dihedral_proxies.append(dp_add)
      else:
        dp_add = cctbx.geometry_restraints.dihedral_proxy(
            i_seqs=dp.i_seqs,
            angle_ideal=reference_angle,
            weight=1/sigma**2,
            limit=limit,
            top_out=TOP_OUT_FLAG)
        # print "Already_there:", self._is_proxy_already_present(generated_reference_dihedral_proxies,dp_add)
        # if not self._is_proxy_already_present(generated_reference_dihedral_proxies,dp_add):
        generated_reference_dihedral_proxies.append(dp_add)
    self.reference_dihedral_proxies = generated_reference_dihedral_proxies

  def show_reference_summary(self, log=None):
    if log is None:
      log = sys.stdout
    print("--------------------------------------------------------", file=log)
    print("Reference Model Matching Summary:", file=log)
    keys = list(self.residue_match_hash.keys())
    def get_key_chain_num(res):
      return res[4:]
    keys.sort(key=get_key_chain_num)
    for file in self.reference_file_list:
      print("\nreference file: %s\n" % file, file=log)
      print("Model:              Reference:", file=log)
      for key in keys:
        if self.residue_match_hash[key][0] == file:
          print("%s  <=====>  %s" % \
            (key, self.residue_match_hash[key][1]), file=log)
    print("\nTotal # of matched residue pairs: %d" % len(keys), file=log)
    print("Total # of reference model restraints: %d" % \
      len(self.reference_dihedral_proxies), file=log)
    print("--------------------------------------------------------", file=log)

  def set_rotamer_to_reference(self,
                               xray_structure,
                               mon_lib_srv=None,
                               log=None,
                               quiet=False):
    if self.mon_lib_srv is None:
      self.mon_lib_srv = mon_lib_srv
    assert isinstance(self.mon_lib_srv, mmtbx.monomer_library.server.server)
    if(log is None): log = sys.stdout
    make_sub_header(
      "Correcting rotamer outliers to match reference model",
      out=log)
    sa = SidechainAngles(False)
    r = rotalyze.rotalyze(pdb_hierarchy=self.pdb_hierarchy)
    rot_list_reference = {}
    coot_reference = {}
    for key in self.pdb_hierarchy_ref.keys():
      hierarchy = self.pdb_hierarchy_ref[key]
      rot_list_reference[key] = \
        rotalyze.rotalyze(pdb_hierarchy=hierarchy)
    model_hash = {}
    model_chis = {}
    reference_hash = {}
    reference_chis = {}
    model_outliers = 0
    for rot in r.results:
      model_hash[rot.id_str()] = rot.rotamer_name
      if rot.rotamer_name == "OUTLIER":
        model_outliers += 1

    for key in rot_list_reference.keys():
      reference_hash[key] = {}
      for rot in rot_list_reference[key].results:
        reference_hash[key][rot.id_str()] = rot.rotamer_name

    print("** evaluating rotamers for working model **", file=log)
    for model in self.pdb_hierarchy.models():
      for chain in model.chains():
        for residue_group in chain.residue_groups():
            all_dict = rotalyze.construct_complete_sidechain(residue_group)
            for atom_group in residue_group.atom_groups():
              try:
                atom_dict = all_dict.get(atom_group.altloc)
                chis = sa.measureChiAngles(atom_group, atom_dict)
                if chis is not None:
                  key = utils.id_str(
                          chain_id=chain.id,
                          resseq=residue_group.resseq,
                          resname=atom_group.resname,
                          icode=residue_group.icode,
                          altloc=atom_group.altloc)
                  model_chis[key] = chis
              except Exception:
                print('  %s%5s %s is missing some sidechain atoms, **skipping**' % (
                      chain.id, residue_group.resid(),
                      atom_group.altloc+atom_group.resname), file=log)
    if model_outliers == 0:
      print("No rotamer outliers detected in working model", file=log)
      return
    else:
      print("Number of rotamer outliers: %d" % model_outliers, file=log)

    print("\n** evaluating rotamers for reference model **", file=log)
    for file in self.pdb_hierarchy_ref.keys():
      hierarchy = self.pdb_hierarchy_ref[file]
      reference_chis[file] = {}
      for model in hierarchy.models():
        for chain in model.chains():
          for residue_group in chain.residue_groups():
              all_dict = rotalyze.construct_complete_sidechain(residue_group)
              for atom_group in residue_group.atom_groups():
                try:
                  atom_dict = all_dict.get(atom_group.altloc)
                  chis = sa.measureChiAngles(atom_group, atom_dict)
                  if chis is not None:
                    key = utils.id_str(
                            chain_id=chain.id,
                            resseq=residue_group.resseq,
                            resname=atom_group.resname,
                            icode=residue_group.icode,
                            altloc=atom_group.altloc)
                    reference_chis[file][key] = chis
                except Exception:
                  print('  %s%5s %s is missing some sidechain atoms, **skipping**' % (
                        chain.id, residue_group.resid(),
                        atom_group.altloc+atom_group.resname), file=log)

    print("\n** fixing outliers **", file=log)
    sites_cart_start = xray_structure.sites_cart()
    for model in self.pdb_hierarchy.models():
      for chain in model.chains():
        for residue_group in chain.residue_groups():
          if len(residue_group.conformers()) > 1:
            print("  %s%5s %s has multiple conformations, **skipping**" % (
              chain.id, residue_group.resid(),
              " "+residue_group.atom_groups()[0].resname), file=log)
            continue
          for conformer in residue_group.conformers():
            for residue in conformer.residues():
              if residue.resname == "PRO":
                continue
              key = utils.id_str(
                      chain_id=chain.id,
                      resseq=residue_group.resseq,
                      resname=residue_group.atom_groups()[0].resname,
                      icode=residue_group.icode,
                      altloc=conformer.altloc)
              if len(chain.id) == 1:
                chain_id = " "+chain.id
              else:
                chain_id = chain.id
              file_key = '%s%s%s' %(residue.resname,
                                    chain_id,
                                    residue_group.resid())
              file_key = file_key.strip()
              file_match = self.residue_match_hash.get(file_key)
              if file_match is not None:
                file = file_match[0]
              else:
                continue
              model_rot = model_hash.get(key)
              reference_rot = reference_hash[file].get(self.one_key_to_another(file_match[1]))
              m_chis = model_chis.get(key)
              r_chis = reference_chis[file].get(self.one_key_to_another(file_match[1]))
              if model_rot is not None and reference_rot is not None and \
                  m_chis is not None and r_chis is not None:
                if (model_rot == 'OUTLIER' and \
                    reference_rot != 'OUTLIER'): # or \
                    #atom_group.resname in ["LEU", "VAL", "THR"]:
                  self.change_residue_rotamer_in_place(
                      sites_cart_start,residue, m_chis,r_chis,self.mon_lib_srv)
                  xray_structure.set_sites_cart(sites_cart_start)

                elif self.params.strict_rotamer_matching and \
                  (model_rot != 'OUTLIER' and reference_rot != 'OUTLIER'):
                  if model_rot != reference_rot:
                    self.change_residue_rotamer_in_place(
                        sites_cart_start,residue, m_chis,r_chis,self.mon_lib_srv)
                    xray_structure.set_sites_cart(sites_cart_start)

  def one_key_to_another(self,key):
    # Work-around function, don't have time to dig into 10 different cache
    # types... Probably better data structure could be suggested to handle
    # all needed information.

    # sp = key.split()
    # assert len(sp) == 3
    var1 = " %s  %s" % (key[4:], key[:3])
    return var1

  def change_residue_rotamer_in_place(self,sites_cart, residue,
      m_chis, r_chis, mon_lib_srv):
    assert m_chis.count(None) == 0
    assert r_chis.count(None) == 0
    axis_and_atoms_to_rotate= \
      rotatable_bonds.axes_and_atoms_aa_specific(
          residue=residue,
          mon_lib_srv=mon_lib_srv,
          remove_clusters_with_all_h=True,
          log=None)
    if axis_and_atoms_to_rotate is None:
      return
    assert len(m_chis) == len(axis_and_atoms_to_rotate)
    assert len(r_chis) >= len(m_chis)
    counter = 0
    residue_iselection = residue.atoms().extract_i_seq()
    sites_cart_residue = sites_cart.select(residue_iselection)
    for aa in axis_and_atoms_to_rotate:
      axis = aa[0]
      atoms = aa[1]
      residue.atoms().set_xyz(new_xyz=sites_cart_residue)
      new_xyz = flex.vec3_double()
      angle_deg = r_chis[counter] - m_chis[counter]
      if angle_deg < 0:
        angle_deg += 360.0
      for atom in atoms:
        new_xyz = rotate_point_around_axis(
                    axis_point_1=sites_cart_residue[axis[0]],
                    axis_point_2=sites_cart_residue[axis[1]],
                    point=sites_cart_residue[atom],
                    angle=angle_deg, deg=True)
        sites_cart_residue[atom] = new_xyz
      sites_cart = sites_cart.set_selected(
            residue_iselection, sites_cart_residue)
      counter += 1

  def remove_restraints_with_ncs_matches(self,
                                         ncs_dihedral_proxies,
                                         ncs_match_hash,
                                         log=None):
    if not self.params.auto_shutoff_for_ncs:
      return
    if log is None:
      log = sys.stdout
    proxy_list = []
    remaining_proxies = cctbx.geometry_restraints.shared_dihedral_proxy()
    remaining_match_hash = {}
    for dp in ncs_dihedral_proxies:
      proxy_list.append(dp.i_seqs)
    for dp in self.reference_dihedral_proxies:
      if dp.i_seqs not in proxy_list:
        remaining_proxies.append(dp)
    for key in self.residue_match_hash:
      found_match = False
      for key2 in ncs_match_hash:
        if key == key2:
          found_match = True
        else:
          for match in ncs_match_hash[key2]:
            if key == match:
              found_match = True
      if not found_match:
        remaining_match_hash[key] = self.residue_match_hash[key]
    self.reference_dihedral_proxies = remaining_proxies
    self.residue_match_hash = remaining_match_hash
    print("\n**Removed reference restraints that overlap "+ \
                       "with torsion NCS restraints**\n", file=log)
    print("Updated Reference Model Restraints:", file=log)
    self.show_reference_summary(log=log)


 *******************************************************************************


 *******************************************************************************
mmtbx/geometry_restraints/torsion_restraints/rotamer_search.py
from __future__ import absolute_import, division, print_function
from cctbx.array_family import flex
import math, sys
from mmtbx.utils import rotatable_bonds
import mmtbx.geometry_restraints.torsion_restraints.utils as torsion_utils
from scitbx.matrix import rotate_point_around_axis
import mmtbx.monomer_library.server
from mmtbx.validation import rotalyze
import iotbx.phil
from libtbx import adopt_init_args
from six.moves import zip

torsion_search_params_str = """\
torsion_search
  .style = box auto_align
{
  min_angle_between_solutions = 5
    .type = float
    .short_caption = Min. angle between solutions
  range_start = -40
    .type = float
  range_stop = 40
    .type = float
  step = 2
    .type = float
}
"""

def generate_range(start, stop, step):
  assert abs(start) <= abs(stop)
  inc = start
  result = []
  while abs(inc) <= abs(stop):
    result.append(inc)
    inc += step
  return result

def target(sites_cart_residue, unit_cell, m):
  sites_frac_residue = unit_cell.fractionalize(sites_cart_residue)
  result = 0
  for rsf in sites_frac_residue:
    result += m.eight_point_interpolation(rsf)
  return result

def torsion_search_params():
  return iotbx.phil.parse(input_string = torsion_search_params_str)

class rotamer_evaluator(object):
  def __init__(self, sites_cart_start,
                     unit_cell,
                     two_mfo_dfc_map,
                     mfo_dfc_map):
    adopt_init_args(self, locals())
    t1 = target(self.sites_cart_start, self.unit_cell, self.two_mfo_dfc_map)
    t2 = target(self.sites_cart_start, self.unit_cell, self.mfo_dfc_map)
    self.t1 = t1
    self.t2 = t2
    self.t_start = t1+t2
    self.t_best = self.t_start
    self.t1_start = t1
    self.t1_best = self.t1_start
    self.t2_start = t2
    self.t2_best = self.t2_start

  def is_better(
                self,
                sites_cart,
                percent_cutoff=0.0,
                verbose=False):
    t1 = target(sites_cart, self.unit_cell, self.two_mfo_dfc_map)
    t2 = target(sites_cart, self.unit_cell, self.mfo_dfc_map)
    t = t1+t2#*3 # XXX very promising thing to do, but reaaly depends on resolution
    result = False
    size = sites_cart.size()
    if 1:
      if(t > self.t_best):
        if percent_cutoff > 0.0 and self.t_best > 0.0:
          percent = (t - self.t_best) / self.t_best
          if percent < percent_cutoff:
            return False
        if((t2 > 0 and self.t2_best > 0 and t2 > self.t2_best) or
           (t2 < 0 and self.t2_best < 0 and abs(t2)<abs(self.t2_best)) or
           (t2 > 0 and self.t2_best < 0)):
          result = True
          self.t2_best = t2
          self.t1_best = t1
          self.t_best = t
    return result

def torsion_search(residue_evaluator,
                   cluster_evaluators,
                   axes_and_atoms_to_rotate,
                   rotamer_sites_cart,
                   rotamer_id_best,
                   residue_sites_best,
                   params = None,
                   rotamer_id = None,
                   include_ca_hinge = False):
  if(params is None):
    params = torsion_search_params().extract().torsion_search
    params.range_start = 0
    params.range_stop = 360
    params.step = 1.0
  rotamer_sites_cart_ = rotamer_sites_cart.deep_copy()
  n_clusters = len(axes_and_atoms_to_rotate)
  c_counter = 0
  for cluster_evaluator, aa in zip(cluster_evaluators,axes_and_atoms_to_rotate):
    #account for CA hinge at beginning of search
    if include_ca_hinge and c_counter == 0:
      cur_range_start = -6.0
      cur_range_stop = 6.0
    else:
      cur_range_start = params.range_start
      cur_range_stop = params.range_stop
    c_counter += 1
    axis = aa[0]
    atoms = aa[1]
    angle_deg_best = None
    angle_deg_good = None
    for angle_deg in generate_range(start = cur_range_start, stop =
                                    cur_range_stop, step = params.step):
      if(c_counter != n_clusters):
        if include_ca_hinge and c_counter == 1:
          new_xyz = flex.vec3_double()
          for atom in atoms:
            new_xyz.append(rotate_point_around_axis(
              axis_point_1 = rotamer_sites_cart[axis[0]],
              axis_point_2 = rotamer_sites_cart[axis[1]],
              point  = rotamer_sites_cart[atom],
              angle = angle_deg, deg=True))
        else:
          point_local = rotamer_sites_cart[atoms[0]]
          new_xyz = flex.vec3_double([rotate_point_around_axis(
            axis_point_1 = rotamer_sites_cart[axis[0]],
            axis_point_2 = rotamer_sites_cart[axis[1]],
            point  = point_local,
            angle = angle_deg, deg=True)])
      else:
        new_xyz = flex.vec3_double()
        for atom in atoms:
          new_xyz.append(rotate_point_around_axis(
            axis_point_1 = rotamer_sites_cart[axis[0]],
            axis_point_2 = rotamer_sites_cart[axis[1]],
            point  = rotamer_sites_cart[atom],
            angle = angle_deg, deg=True))
      if(cluster_evaluator.is_better(sites_cart = new_xyz)):
        if(angle_deg_best is not None and
           abs(abs(angle_deg_best)-abs(angle_deg))>
           params.min_angle_between_solutions):
          angle_deg_good = angle_deg_best
        angle_deg_best = angle_deg
    if(angle_deg_best is not None):
      for atom in atoms:
        new_xyz = rotate_point_around_axis(
          axis_point_1 = rotamer_sites_cart[axis[0]],
          axis_point_2 = rotamer_sites_cart[axis[1]],
          point  = rotamer_sites_cart[atom],
          angle = angle_deg_best, deg=True)
        rotamer_sites_cart[atom] = new_xyz
    if(angle_deg_good is not None):
      for atom in atoms:
        new_xyz = rotate_point_around_axis(
          axis_point_1 = rotamer_sites_cart_[axis[0]],
          axis_point_2 = rotamer_sites_cart_[axis[1]],
          point  = rotamer_sites_cart_[atom],
          angle = angle_deg_best, deg=True)
        rotamer_sites_cart_[atom] = new_xyz
  for rsc in [rotamer_sites_cart, rotamer_sites_cart_]:
    if(residue_evaluator.is_better(sites_cart = rsc)):
      rotamer_id_best = rotamer_id
      residue_sites_best = rsc.deep_copy()
  return residue_sites_best, rotamer_id_best

class manager(object):

  def __init__(self,
               pdb_hierarchy,
               xray_structure,
               range_start=-10.0,
               range_stop=10.0,
               step=1.0,
               min_angle_between_solutions=0.5,
               name_hash=None,
               selection=None,
               log=None):
    if(log is None): log = sys.stdout
    self.log = log
    self.mon_lib_srv = mmtbx.monomer_library.server.server()
    self.unit_cell = xray_structure.unit_cell()
    self.exclude_free_r_reflections = False
    self.torsion_params = torsion_search_params().extract().torsion_search
    self.torsion_params.range_start = range_start
    self.torsion_params.range_stop = range_stop
    self.torsion_params.step = step
    self.torsion_params.min_angle_between_solutions = \
      min_angle_between_solutions
    self.selection=selection
    if self.selection is None:
      sites_cart = pdb_hierarchy.atoms().extract_xyz()
      self.selection = flex.bool(len(sites_cart), True)
    self.c_alpha_hinges = torsion_utils.get_c_alpha_hinges(
                            pdb_hierarchy=pdb_hierarchy,
                            xray_structure=xray_structure,
                            selection=self.selection)
    self.name_hash = name_hash
    if self.name_hash is None:
      self.name_hash = build_name_hash(pdb_hierarchy)
    from mmtbx.rotamer.sidechain_angles import SidechainAngles
    from mmtbx.rotamer import rotamer_eval
    self.sa = SidechainAngles(False)
    self.rotamer_id = rotamer_eval.RotamerID()
    self.rotamer_evaluator = rotamer_eval.RotamerEval(mon_lib_srv=self.mon_lib_srv)
    self.target_map_data = None
    self.residual_map_data = None

  def prepare_map(
        self,
        fmodel):
    target_map_data, residual_map_data = \
      torsion_utils.prepare_map(fmodel=fmodel)
    self.target_map_data = target_map_data
    self.residual_map_data = residual_map_data

  def search(
        self,
        atom_group,
        all_dict,
        m_chis,
        r_chis,
        rotamer,
        sites_cart_moving,
        xray_structure,
        key):
    include_ca_hinge = False
    axis_and_atoms_to_rotate, tardy_labels= \
      rotatable_bonds.axes_and_atoms_aa_specific(
          residue=atom_group,
          mon_lib_srv=self.mon_lib_srv,
          remove_clusters_with_all_h=True,
          include_labels=True,
          log=None)
    if (axis_and_atoms_to_rotate is None):
      print("Skipped %s rotamer (TARDY error)" % key, file=self.log)
      return False
    assert len(m_chis) == len(r_chis)
    #exclude H-only clusters if necessary
    while len(axis_and_atoms_to_rotate) > len(m_chis):
      axis_and_atoms_to_rotate = \
        axis_and_atoms_to_rotate[:-1]
    assert len(m_chis) == len(axis_and_atoms_to_rotate)
    counter = 0
    residue_iselection = atom_group.atoms().extract_i_seq()
    cur_ca = None
    ca_add = None
    ca_axes = []
    for atom in atom_group.atoms():
      if atom.name == " CA ":
        cur_ca = atom.i_seq
    if cur_ca is not None:
      cur_c_alpha_hinges = self.c_alpha_hinges.get(cur_ca)
      if cur_c_alpha_hinges is not None:
        residue_length = len(tardy_labels)
        for ca_pt in cur_c_alpha_hinges[0]:
          residue_iselection.append(ca_pt)
          tardy_labels.append(self.name_hash[ca_pt][0:4])
        for bb_pt in cur_c_alpha_hinges[1]:
          residue_iselection.append(bb_pt)
          tardy_labels.append(self.name_hash[bb_pt][0:4])
        end_pts = (residue_length, residue_length+1)
        group = []
        for i, value in enumerate(tardy_labels):
          if i not in end_pts:
            group.append(i)
        ca_add = [end_pts, group]
        ca_axes.append(ca_add)
        for ax in axis_and_atoms_to_rotate:
          ca_axes.append(ax)
    sites_cart_residue = \
      sites_cart_moving.select(residue_iselection)
    sites_cart_residue_start = sites_cart_residue.deep_copy()
    selection = flex.bool(
                  len(sites_cart_moving),
                  residue_iselection)
    rev_first_atoms = []

    rev_start = rotamer_evaluator(
      sites_cart_start = sites_cart_residue_start,
      unit_cell        = self.unit_cell,
      two_mfo_dfc_map  = self.target_map_data,
      mfo_dfc_map      = self.residual_map_data)

    sidechain_only_iselection = flex.size_t()
    for i_seq in residue_iselection:
      atom_name = self.name_hash[i_seq][0:4]
      if atom_name not in [' N  ', ' CA ', ' C  ', ' O  ']:
        sidechain_only_iselection.append(i_seq)
    sites_cart_sidechain = \
      sites_cart_moving.select(sidechain_only_iselection)
    sites_frac_residue = self.unit_cell.fractionalize(sites_cart_sidechain)
    sigma_cutoff = 1.0
    sigma_residue = []
    for rsf in sites_frac_residue:
      if self.target_map_data.eight_point_interpolation(rsf) < sigma_cutoff:
        sigma_residue.append(False)
      else:
        sigma_residue.append(True)
    sigma_count_start = 0
    for sigma_state in sigma_residue:
      if sigma_state:
        sigma_count_start += 1
      else:
        break

    for aa in axis_and_atoms_to_rotate:
      axis = aa[0]
      atoms = aa[1]
      new_xyz = flex.vec3_double()
      angle_deg = r_chis[counter] - m_chis[counter]
      #skip angle rotations that are close to zero
      if math.fabs(angle_deg) < 0.01:
        counter += 1
        continue
      if angle_deg < 0:
        angle_deg += 360.0
      for atom in atoms:
        new_xyz = rotate_point_around_axis(
                    axis_point_1=sites_cart_residue[axis[0]],
                    axis_point_2=sites_cart_residue[axis[1]],
                    point=sites_cart_residue[atom],
                    angle=angle_deg, deg=True)
        sites_cart_residue[atom] = new_xyz
      counter += 1

    #***** TEST *****
    sites_cart_moving.set_selected(
      residue_iselection, sites_cart_residue)
    cur_rotamer, cur_chis, cur_value = rotalyze.evaluate_rotamer(
      atom_group=atom_group,
      sidechain_angles=self.sa,
      rotamer_evaluator=self.rotamer_evaluator,
      rotamer_id=self.rotamer_id,
      all_dict=all_dict,
      sites_cart=sites_cart_moving)
    assert rotamer == cur_rotamer
    #****************

    if len(ca_axes) == 0:
      eval_axes = axis_and_atoms_to_rotate
    else:
      eval_axes = ca_axes
      include_ca_hinge = True
    for i_aa, aa in enumerate(eval_axes):
      if(i_aa == len(eval_axes)-1):
        sites_aa = flex.vec3_double()
        for aa_ in aa[1]:
          sites_aa.append(sites_cart_residue[aa_])
      elif i_aa == 0 and include_ca_hinge:
        sites_aa = flex.vec3_double()
        for aa_ in aa[1]:
          sites_aa.append(sites_cart_residue[aa_])
      else:
        sites_aa = flex.vec3_double([sites_cart_residue[aa[1][0]]])
      rev_i = rotamer_evaluator(
        sites_cart_start = sites_aa,
        unit_cell        = self.unit_cell,
        two_mfo_dfc_map  = self.target_map_data,
        mfo_dfc_map      = self.residual_map_data)
      rev_first_atoms.append(rev_i)

    rev = rotamer_evaluator(
      sites_cart_start = sites_cart_residue,
      unit_cell        = self.unit_cell,
      two_mfo_dfc_map  = self.target_map_data,
      mfo_dfc_map      = self.residual_map_data)

    residue_sites_best = sites_cart_residue.deep_copy()
    residue_sites_best, rotamer_id_best = \
      torsion_search(
        residue_evaluator=rev,
        cluster_evaluators=rev_first_atoms,
        axes_and_atoms_to_rotate=eval_axes,
        rotamer_sites_cart=sites_cart_residue,
        rotamer_id_best=rotamer,
        residue_sites_best=residue_sites_best,
        params = self.torsion_params,
        rotamer_id = rotamer,
        include_ca_hinge = include_ca_hinge)
    sites_cart_moving.set_selected(
        residue_iselection, residue_sites_best)
    xray_structure.set_sites_cart(sites_cart_moving)
    cur_rotamer, cur_chis, cur_value = rotalyze.evaluate_rotamer(
      atom_group=atom_group,
      sidechain_angles=self.sa,
      rotamer_evaluator=self.rotamer_evaluator,
      rotamer_id=self.rotamer_id,
      all_dict=all_dict,
      sites_cart=sites_cart_moving)
    rotamer_match = (cur_rotamer == rotamer)
    if rev_start.is_better(sites_cart=residue_sites_best,
                           percent_cutoff=0.15, verbose=True) and \
       rotamer_match:
      sidechain_only_iselection = flex.size_t()
      for i_seq in residue_iselection:
        atom_name = self.name_hash[i_seq][0:4]
        if atom_name not in [' N  ', ' CA ', ' C  ', ' O  ',
                             ' OXT', ' H  ', ' HA ']:
          sidechain_only_iselection.append(i_seq)
      selection = flex.bool(
                    len(sites_cart_moving),
                    sidechain_only_iselection)
      selection_within = xray_structure.selection_within(
      radius    = 1.0,
      selection = selection)
      #check for bad steric clashes
      created_clash = False
      for i, state in enumerate(selection_within):
        if state:
          if i not in sidechain_only_iselection:
            #print >> self.log, "atom clash: ", self.name_hash[i]
            created_clash = True
      if created_clash:
        sites_cart_moving.set_selected(
          residue_iselection, sites_cart_residue_start)
        xray_structure.set_sites_cart(sites_cart_moving)
        return False

      sidechain_only_iselection = flex.size_t()
      for i_seq in residue_iselection:
        atom_name = self.name_hash[i_seq][0:4]
        if atom_name not in [' N  ', ' CA ', ' C  ', ' O  ']:
          sidechain_only_iselection.append(i_seq)
      sites_cart_sidechain = \
        sites_cart_moving.select(sidechain_only_iselection)
      sites_frac_residue = self.unit_cell.fractionalize(sites_cart_sidechain)
      sigma_cutoff = 1.0
      sigma_residue = []
      for rsf in sites_frac_residue:
        if self.target_map_data.eight_point_interpolation(rsf) < sigma_cutoff:
          sigma_residue.append(False)
        else:
          sigma_residue.append(True)
      sigma_count = 0
      for sigma_state in sigma_residue:
        if sigma_state:
          sigma_count += 1
        else:
          break
      if sigma_count < sigma_count_start:
        sites_cart_moving.set_selected(
          residue_iselection, sites_cart_residue_start)
        xray_structure.set_sites_cart(sites_cart_moving)
        return False
      return True
    else:
      sites_cart_moving.set_selected(
        residue_iselection, sites_cart_residue_start)
      xray_structure.set_sites_cart(sites_cart_moving)
      return False


 *******************************************************************************


 *******************************************************************************
mmtbx/geometry_restraints/torsion_restraints/torsion_ncs.py
from __future__ import absolute_import, division, print_function
import cctbx.geometry_restraints
from mmtbx.validation import rotalyze
from mmtbx.validation import ramalyze
from mmtbx.validation import analyze_peptides
from mmtbx.rotamer.sidechain_angles import SidechainAngles
from cctbx.array_family import flex
import iotbx.phil
from libtbx.str_utils import make_sub_header
import sys, math
from libtbx.utils import Sorry
from mmtbx.geometry_restraints.torsion_restraints import utils, rotamer_search
from libtbx import Auto
from libtbx.str_utils import line_breaker
from six.moves import zip

# Refactoring notes 11 May 2015
# Torsion NCS restraints should use the same procedure to find NCS groups
# as other NCS restraints. Therefore all search code will be avoided and
# NCS groups should be provided via ncs_obj which is instance of
# cctbx_project.iotbx.ncs.ncs_preprocess.ncs_group_object

TOP_OUT_FLAG = True

torsion_ncs_params = iotbx.phil.parse("""
 sigma = 2.5
   .type = float
   .short_caption = Restraint sigma (degrees)
 limit = 15.0
   .type = float
   .short_caption = Restraint limit (degrees)
 fix_outliers = False
   .type = bool
   .short_caption = Fix rotamer outliers first
 check_rotamer_consistency = Auto
   .type = bool
   .short_caption = Check for consistency between NCS-related sidechains
   .help = Check for rotamer differences between NCS matched \
     sidechains and search for best fit amongst candidate rotamers
 target_damping = False
   .type = bool
   .expert_level = 1
 damping_limit = 10.0
   .type = float
   .expert_level = 1
 filter_phi_psi_outliers = True
   .type = bool
   .expert_level = 4
 restrain_to_master_chain = False
   .type = bool
   .expert_level = 4
 silence_warnings = False
   .type = bool
   .expert_level = 4
""")

def target(sites_cart_residue, unit_cell, m):
  sites_frac_residue = unit_cell.fractionalize(sites_cart_residue)
  result = 0
  for rsf in sites_frac_residue:
    result += m.eight_point_interpolation(rsf)
  return result

def all_sites_above_sigma_cutoff(sites_cart_residue,
                                 unit_cell,
                                 m,
                                 sigma_cutoff):
  sites_frac_residue = unit_cell.fractionalize(sites_cart_residue)
  for rsf in sites_frac_residue:
    if m.eight_point_interpolation(rsf) < sigma_cutoff:
      return False
  return True

class torsion_ncs(object):
  def __init__(self,
               model,
               fmodel=None,
               params=None,
               selection=None,
               ncs_groups=None,
               alignments=None,
               ncs_dihedral_proxies=None,
               log=None):
    assert model is not None
    if(log is None): log = sys.stdout
    if params is None:
      params = torsion_ncs_params.extract()
    #parameter initialization
    if params.sigma is None or params.sigma < 0:
      raise Sorry("torsion NCS sigma parameter must be >= 0.0")
    self.sigma = params.sigma
    if params.limit is None or params.limit < 0:
      raise Sorry("torsion NCS limit parameter must be >= 0.0")
    # assert ncs_obj is not None
    self.limit = params.limit
    self.selection = selection
    self.model = model
    self.pdb_hierarchy = None
    self.pdb_hierarchy = self.model.get_hierarchy()
    self.ncs_obj = self.model.get_ncs_obj()
    # self.cache = self.model.get_atom_selection_cache()
    assert self.ncs_obj is not None

    #slack is not a user parameter for now
    self.slack = 0.0
    self.filter_phi_psi_outliers = params.filter_phi_psi_outliers
    self.restrain_to_master_chain = params.restrain_to_master_chain
    self.fmodel = fmodel
    self.ncs_restraints_group_list = self.ncs_obj.get_ncs_restraints_group_list()
    self.ncs_groups_selection_string_list = self.ncs_restraints_group_list.get_array_of_str_selections()
    self.log = log
    self.params = params
    self.dp_ncs = None
    self.rotamer_search_manager = None
    self.ncs_dihedral_proxies = ncs_dihedral_proxies
    self.alignments = alignments
    self.sa = SidechainAngles(False)
    #sanity check
    # if self.pdb_hierarchy is not None:
    #   self.pdb_hierarchy.reset_i_seq_if_necessary()
    #   self.cache = self.pdb_hierarchy.atom_selection_cache()
    if self.alignments is None:
      self.find_ncs_groups(pdb_hierarchy=self.pdb_hierarchy)
    if self.pdb_hierarchy is not None:
      self.find_ncs_matches_from_hierarchy(model=self.model)

  def get_alignments(self):
    # This function should use something like common_res_dict already available
    # in ncs_obj or something similar instead of aligning residues itself.
    def get_key(rg):
      resname = rg.atoms()[0].pdb_label_columns()[5:8]
      if resname.upper() == "MSE":
        resname = "MET"
      updated_resname = utils.modernize_rna_resname(resname)
      return rg.atoms()[0].pdb_label_columns()[4:5]+\
          updated_resname+rg.atoms()[0].pdb_label_columns()[8:]+\
          rg.atoms()[0].segid
    alignments = {}
    # for group in self.ncs_groups:
    for i_group, group in enumerate(self.ncs_restraints_group_list):
      for i, isel in enumerate(group.get_iselections_list()):
        for j, jsel in enumerate(group.get_iselections_list()):
          if i <= j:
            continue
          # isel_plus = isel
          # jsel_plus = jsel
          # if self.ncs_obj.exclude_selection is not None:
          #   isel_plus += " and not (%s)" % self.ncs_obj.exclude_selection
          #   jsel_plus += " and not (%s)" % self.ncs_obj.exclude_selection
          # sel_i = self.cache.selection(isel_plus)
          # sel_j = self.cache.selection(jsel_plus)
          h_i = self.pdb_hierarchy.select(isel)
          h_j = self.pdb_hierarchy.select(jsel)
          # chain matching procedure
          # matching_chain_numbers = []
          matching_chains = []
          for ii, i_chain in enumerate(h_i.chains()):
            for jj, j_chain in enumerate(h_j.chains()):
              # print "Checking chains:", i_chain.id, j_chain.id
              # print "  ", i_chain.atoms_size(), j_chain.atoms_size()
              # print "  ", i_chain.is_similar_hierarchy(j_chain)
              # print "  ", i_chain.as_sequence(), j_chain.as_sequence(), i_chain.as_sequence() == j_chain.as_sequence()
              if (i_chain.atoms_size() == j_chain.atoms_size()
                  # and i_chain.is_similar_hierarchy(j_chain)
                  and i_chain.as_sequence() == j_chain.as_sequence()):
                # matching_chain_numbers.append((ii, jj))
                matching_chains.append((i_chain, j_chain))
                break
          # residue matching
          i_chains = h_i.chains()
          j_chains = h_j.chains()
          residue_match_map1 = {}
          residue_match_map2 = {}
          if len(matching_chains) == 0:
            msg = "Failed to find matching chains. "
            msg += "No NCS restraints will be applied.\n"
            msg += "Try to use phenix.simple_ncs_from_pdb or leave ncs_groups "
            msg += "blank to allow \nautomatic search for NCS copies."
            print(msg, file=self.log)
          for ic, jc in matching_chains:
            for rg1, rg2 in zip(ic.residue_groups(), jc.residue_groups()):
              resname1 = rg1.atom_groups()[0].resname
              resname2 = rg2.atom_groups()[0].resname
              if (resname1 != resname2 and
                  # This excludes the case when in one NCS copy residue is MET
                  # and in another - MSE. They will be excluded without
                  # raising Sorry. They could matched, but it is difficult
                  # to figure out in this code how to make it happen.
                  not (resname1 in ["MET", "MSE"] and resname2 in ["MET", "MSE"])):
                msg = "Error in matching procedure: matching "
                msg += "'%s %s' and '%s %s'.\n" % (
                    resname1, rg1.id_str(), resname2, rg2.id_str())
                msg += "Please tell developers about this error"
                msg += " (with files to reproduce it)! "
                msg += "If you need to proceed try to disable NCS."
                raise Sorry(msg)
              residue_match_map1[get_key(rg1)] = get_key(rg2)
              residue_match_map2[get_key(rg2)] = get_key(rg1)
          # This duplication won't be necessary when all the rest code would
          # be able to work without it. 2x less memory...
          ikey = self.ncs_groups_selection_string_list[i_group][i]
          jkey = self.ncs_groups_selection_string_list[i_group][j]
          key1 = (ikey, jkey)
          key2 = (jkey, ikey)
          alignments[key1] = residue_match_map1
          alignments[key2] = residue_match_map2
    return alignments

  def find_ncs_groups(self, pdb_hierarchy):
    print("Determining NCS matches...", file=self.log)
    self.use_segid = False
    chains = pdb_hierarchy.models()[0].chains()
    n_ncs_groups = self.ncs_obj.number_of_ncs_groups
    if n_ncs_groups > 0:
      new_alignments = self.get_alignments()
      self.alignments = new_alignments
      return
    else:
      # ================================================
      # Should never be executed because I'm disabling search functionality
      # in this module
      # ================================================
      assert 0

  def as_cif_block(self, cif_block, hierarchy, scattering_type):
    self.ncs_restraints_group_list.as_cif_block(
        cif_block=cif_block,
        hierarchy=hierarchy,
        scattering_type=scattering_type,
        ncs_type='Torsion NCS')
    return cif_block

  def as_pdb(self, out):
    assert out is not None
    torsion_counts=self.get_number_of_restraints_per_group()
    sites_cart = self.model.get_sites_cart()
    self.get_torsion_rmsd(sites_cart=sites_cart)
    pr = "REMARK   3  "
    print(pr+"TORSION NCS DETAILS.", file=out)
    print(pr+" NUMBER OF NCS GROUPS : %-6d"%len(self.ncs_groups_selection_string_list), file=out)
    for i_group, ncs_group in enumerate(self.ncs_groups_selection_string_list):
      count = 0
      print(pr+" NCS GROUP : %-6d"%(i_group+1), file=out)
      selection_strings = ncs_group
      for selection in selection_strings:
        lines = line_breaker(selection, width=34)
        for i_line, line in enumerate(lines):
          if (i_line == 0):
            print(pr+"   SELECTION          : %s"%line, file=out)
          else:
            print(pr+"                      : %s"%line, file=out)
        count += torsion_counts[selection]
      print(pr+"   RESTRAINED TORSIONS: %-d" % count, file=out)
      if self.torsion_rmsd is not None:
        print(pr+"   BELOW LIMIT RMSD   : %-10.3f" % \
          self.torsion_rmsd, file=out)
      if self.all_torsion_rmsd is not None:
        print(pr+"   ALL RESTRAINT RMSD : %-10.3f" % \
          self.all_torsion_rmsd, file=out)
    if self.histogram_under_limit is not None:
      print(pr + "  Histogram of differences under limit:", file=out)
      self.histogram_under_limit.show(
        f=out,
        prefix=pr+"  ",
        format_cutoffs="%8.3f")
    if self.histogram_over_limit is not None:
      print(pr + "  Histogram of differences over limit:", file=out)
      self.histogram_over_limit.show(
        f=out,
        prefix=pr+"  ",
        format_cutoffs="%8.3f")

  def find_ncs_matches_from_hierarchy(self, model):
    # This is list of dp_match, see below
    self.dp_ncs = []
    self.cb_dp_ncs = []
    self.dihedral_proxies_backup = None
    pdb_hierarchy = model.get_hierarchy()
    self.name_hash = utils.build_name_hash(pdb_hierarchy)
    self.segid_hash = utils.build_segid_hash(pdb_hierarchy)
    self.sym_atom_hash = utils.build_sym_atom_hash(pdb_hierarchy)
    self.sa = SidechainAngles(False)
    self.sidechain_angle_hash = self.build_sidechain_angle_hash()
    self.r = rotalyze.rotalyze(pdb_hierarchy=pdb_hierarchy)
    self.unit_cell = None
    sites_cart = pdb_hierarchy.atoms().extract_xyz()
    if self.selection is None:
      self.selection = flex.bool(len(sites_cart), True)

    # XXX Update. Due to possible changes in number of atoms in hierarchy
    # during refinement we have to construct again all internal stuff
    # on every macro-cycle.
    complete_dihedral_proxies = utils.get_complete_dihedral_proxies_2(
        model = self.model)
    # print "Number of complete_dihedral_proxies in find_ncs_matches_from_hierarchy", complete_dihedral_proxies.size()

    if len(self.ncs_restraints_group_list) > 0:
      element_hash = utils.build_element_hash(pdb_hierarchy)
      i_seq_hash = utils.build_i_seq_hash(pdb_hierarchy)
      dp_hash = {}
      for dp in complete_dihedral_proxies:
        h_atom = False
        for i_seq in dp.i_seqs:
          if element_hash[i_seq] == " H":
            h_atom = True
        if not h_atom:
          complete = True
          for i_seq in dp.i_seqs:
            if not self.selection[i_seq]:
              complete = False
          if complete:
            dp_hash[dp.i_seqs] = dp

      super_hash = {}
      res_match_master = {}
      res_to_selection_hash = {}
      # This is for cache/hash generation....
      # print pdb_hierarchy.as_pdb_string()
      for i, group in enumerate(self.ncs_groups_selection_string_list):
        for isel, chain_i in zip(self.ncs_restraints_group_list[i].get_iselections_list(), group):
          # print i, "isel,", list(isel)
          c_atoms = pdb_hierarchy.select(isel).atoms()
          for atom in c_atoms:
            for chain_j in group:
              if chain_i == chain_j:
                continue
              res_key = self.name_hash[atom.i_seq][4:]
              atom_key = self.name_hash[atom.i_seq][0:4]
              j_match = None
              key = (chain_i, chain_j)
              cur_align = self.alignments.get(key)
              if cur_align is not None:
                j_match = cur_align.get(res_key)
              if j_match is not None:
                j_i_seq = i_seq_hash.get(atom_key+j_match)
                if j_i_seq is None:
                  continue
                if super_hash.get(atom.i_seq) is None:
                  super_hash[atom.i_seq] = dict()
                if super_hash.get(j_i_seq) is None:
                  super_hash[j_i_seq] = dict()
                super_hash[atom.i_seq][chain_j] = j_i_seq
                super_hash[j_i_seq][chain_i] = atom.i_seq
                if res_match_master.get(res_key) is None:
                  res_match_master[res_key] = []
                if res_match_master.get(j_match) is None:
                  res_match_master[j_match] = []
                if j_match not in res_match_master[res_key]:
                  res_match_master[res_key].append(j_match)
                if res_key not in res_match_master[j_match]:
                  res_match_master[j_match].append(res_key)
                res_to_selection_hash[res_key] = chain_i
                res_to_selection_hash[j_match] = chain_j

      self.res_match_master = res_match_master
      resname = None
      atoms_key = None
      for dp in complete_dihedral_proxies:
        temp = dict()
        #filter out unwanted torsions
        atoms = []
        for i_seq in dp.i_seqs:
          atom = self.name_hash[i_seq][:4]
          atoms.append(atom)
          atoms_key = ",".join(atoms)
          resname = self.get_torsion_resname(dp)
        if resname is not None:
          if ( (resname.lower() == 'arg') and
               (atoms_key == ' CD , NE , CZ , NH2') ):
            continue
          elif ( (resname.lower() == 'tyr') and
               (atoms_key == ' CD1, CE1, CZ , OH ' or
                atoms_key == ' CE1, CZ , OH , HH ') ):
            continue
          elif ( (resname.lower() == 'ser') and
               (atoms_key == ' CA , CB , OG , HG ') ):
            continue
          elif ( (resname.lower() == 'thr') and
               (atoms_key == ' CA , CB , OG1, HG1') ):
            continue
          elif ( (resname.lower() == 'cys') and
               (atoms_key == ' CA , CB , SG , HG ') ):
            continue
          elif ( (resname.lower() == 'met') and
               (atoms_key == ' CG , SD , CE ,1HE ' or
                atoms_key == ' CG , SD , CE , HE1') ):
            continue
        ################
        for i_seq in dp.i_seqs:
          cur_matches = super_hash.get(i_seq)
          if cur_matches is None:
            continue
          for key in list(cur_matches.keys()):
            try:
              temp[key].append(cur_matches[key])
            except Exception:
              temp[key] = []
              temp[key].append(cur_matches[key])
        # This is [[dp,bool,bool,bool],[dp, bool,bool,bool],...]
        # where dp - dihedral proxy from complete_dihedral_proxies
        # bool, bool, bool - is phi/psi/omega angle
        dp_match = []
          # cctbx.geometry_restraints.shared_dihedral_proxy()
        dp_match.append([dp, False, False, False])
        for key in list(temp.keys()):
          cur_dp_hash = dp_hash.get(tuple(temp[key]))
          if cur_dp_hash is not None:
            dp_match.append([cur_dp_hash, False, False, False])
            dp_hash[tuple(temp[key])] = None
        dp_hash[dp.i_seqs] = None
        if len(dp_match) > 1:
          self.dp_ncs.append(dp_match)
      #initialize tracking hashes
      for dp_set in self.dp_ncs:
        for dp in dp_set:
          angle_atoms = self.get_torsion_atoms(dp[0])
          angle_resname = self.get_torsion_resname(dp[0])
          angle_id = utils.get_torsion_id(dp=dp[0], name_hash=self.name_hash)
          #phi
          if angle_atoms == ' C  '+' N  '+' CA '+' C  ':
            dp[1] = True
          #psi
          elif angle_atoms == ' N  '+' CA '+' C  '+' N  ':
            dp[2] = True
          #omega
          elif angle_atoms == ' CA '+' C  '+' N  '+' CA ':
            dp[3] = True

      match_counter = {}
      inclusive_range = {}
      for group in self.ncs_groups_selection_string_list:
        cur_len = len(group)
        for chain in group:
          match_counter[chain] = cur_len
          inclusive_range[chain] = []

      matched = []
      ncs_match_hash = {}
      for dp_set in self.dp_ncs:
        if len(dp_set) > 1:
          key_set = []
          for dp in dp_set:
            cur_key = ""
            for i_seq in dp[0].i_seqs:
              cur_key += self.name_hash[i_seq]
            if cur_key[4:19] == cur_key[23:38] and \
               cur_key[4:19] == cur_key[42:57]:
              key_set.append(cur_key[4:19])
          if len(dp_set) == len(key_set): # probably always True
            key_set.sort()
            master_key = None
            skip = False
            for i, key in enumerate(key_set):
              if i == 0:
                master_key = key
                if master_key in matched:
                  skip = True
                elif ncs_match_hash.get(key) is None:
                  ncs_match_hash[key] = []
                elif len(key_set) <= len(ncs_match_hash[key]):
                  skip = True
                else:
                  ncs_match_hash[key] = []
              elif not skip:
                ncs_match_hash[master_key].append(key)
                matched.append(key)
      self.ncs_match_hash = ncs_match_hash
      self.reduce_redundancies()

      for res in list(self.ncs_match_hash.keys()):
        resnum = res[6:10]
        hash_key = res_to_selection_hash[res]
        cur_len = match_counter[hash_key]
        if len(self.ncs_match_hash[res]) == (cur_len - 1):
          inclusive_range[hash_key].append(int(resnum))
          for res2 in self.ncs_match_hash[res]:
            resnum2 = res2[6:10]
            hash_key = res_to_selection_hash[res2]
            inclusive_range[hash_key].append(int(resnum2))

      #determine ranges
      self.master_ranges = {}
      for key in list(inclusive_range.keys()):
        current = None
        previous = None
        start = None
        stop = None
        self.master_ranges[key] = []
        inclusive_range[key].sort()
        for num in inclusive_range[key]:
          if previous == None:
            start = num
            previous = num
          elif num > (previous + 1):
            finish = previous
            self.master_ranges[key].append( (start, finish) )
            start = num
            finish = None
            previous = num
          else:
            previous = num
        if previous != None:
          finish = previous
          self.master_ranges[key].append( (start, finish) )

      if self.ncs_dihedral_proxies is None:
        self.show_ncs_summary(log=self.log)
      if self.ncs_dihedral_proxies is None: #first time run
        print("Initializing torsion NCS restraints...", file=self.log)
      else:
        print("Verifying torsion NCS restraints...", file=self.log)
      self.rama = ramalyze.ramalyze(pdb_hierarchy=pdb_hierarchy)
      self.generate_dihedral_ncs_restraints(
        sites_cart=sites_cart,
        pdb_hierarchy=pdb_hierarchy,
        log=self.log)
    elif(not self.params.silence_warnings):
      # ================================================
      # Should never be executed
      # ================================================
      assert 0
      print("** WARNING: No torsion NCS found!!" + \
        "  Please check parameters. **", file=self.log)

  def show_ncs_summary(self, log=None):
    if(log is None): log = sys.stdout
    def get_key_chain_num(res):
      return res[4:]
    sorted_keys = sorted(self.ncs_match_hash, key=get_key_chain_num)
    print("--------------------------------------------------------", file=log)
    print("Torsion NCS Matching Summary:", file=log)
    for key in sorted_keys:
      if key.endswith("    "):
        print_line = key[:-4]
      else:
        print_line = key
      for match in self.ncs_match_hash[key]:
        if match.endswith("    "):
          print_line += " <=> %s" % (match[:-4])
        else:
          print_line += " <=> %s" % (match)
      print(print_line, file=log)
    print("--------------------------------------------------------", file=log)

  def reduce_redundancies(self):
    #clear out redundancies
    for key in list(self.ncs_match_hash.keys()):
      for key2 in list(self.ncs_match_hash.keys()):
        if key == key2:
          continue
        if key in self.ncs_match_hash[key2]:
          del self.ncs_match_hash[key]

  def get_torsion_atoms(self, dp):
    atoms = ''
    for i_seq in dp.i_seqs:
      atom_name = self.name_hash[i_seq][0:4]
      atoms += atom_name
    return atoms

  def get_torsion_resname(self, dp):
    resname = None
    for i_seq in dp.i_seqs:
      cur_resname = self.name_hash[i_seq][5:8]
      if resname == None:
        resname = cur_resname
      elif cur_resname != resname:
        return None
    return resname

  def get_chi_id(self, dp):
    atoms = []
    for i_seq in dp.i_seqs:
      atom = self.name_hash[i_seq][:4]
      atoms.append(atom)
    atoms_key = ",".join(atoms)
    resname = self.get_torsion_resname(dp)
    resAtomsToChi = self.sa.resAtomsToChi.get(resname.lower())
    if resAtomsToChi is None:
      chi_id = None
    else:
      chi_id = resAtomsToChi.get(atoms_key)
    return chi_id

  def build_chi_tracker(self, pdb_hierarchy):
    self.current_chi_restraints = {}
    #current_rotamers = self.r.current_rotamers
    current_rotamers = {}
    for rot in self.r.results:
      current_rotamers[rot.id_str()] = rot.rotamer_name
    for key in list(self.ncs_match_hash.keys()):
      search_key = key[4:11]+key[0:4] # SEGIDs?
      rotamer = current_rotamers.get(search_key)
      if rotamer is not None:
        split_rotamer = rotalyze.split_rotamer_names(rotamer=rotamer)
        self.current_chi_restraints[key] = split_rotamer
      key_list = self.ncs_match_hash.get(key)
      for key2 in key_list:
        search_key2 = key2[4:11]+key2[0:4] # SEGIDs?
        rotamer = current_rotamers.get(search_key2)
        if rotamer is not None:
          split_rotamer = rotalyze.split_rotamer_names(rotamer=rotamer)
          self.current_chi_restraints[key2] = split_rotamer

  def generate_dihedral_ncs_restraints(
        self,
        sites_cart,
        pdb_hierarchy,
        log):
    model_hash, model_score, all_rotamers, model_chis = \
      self.get_rotamer_data(pdb_hierarchy=pdb_hierarchy)
    self.build_chi_tracker(pdb_hierarchy)
    self.ncs_dihedral_proxies = \
      cctbx.geometry_restraints.shared_dihedral_proxy()
    target_map_data = None
    #if self.fmodel is not None and self.use_cc_for_target_angles:
    #  target_map_data, residual_map_data = self.prepare_map(
    #                                         fmodel=self.fmodel)
    #rama_outliers = None
    rama_outlier_list = []
    omega_outlier_list = []
    if self.filter_phi_psi_outliers:
      rama_outlier_list = \
        self.get_ramachandran_outliers(pdb_hierarchy)
      #rama_outliers = \
      #  self.get_ramachandran_outliers(pdb_hierarchy)
      #for outlier in rama_outliers.splitlines():
      #  temp = outlier.split(':')
      #  rama_outlier_list.append(temp[0])
      omega_outlier_list = \
        self.get_omega_outliers(pdb_hierarchy)
    torsion_counter = 0

    for dp_set in self.dp_ncs:
      if len(dp_set) < 2:
        continue
      angles = []
      #cc_s = []
      is_rama_outlier = []
      is_omega_outlier = []
      rotamer_state = []
      chi_ids = []
      wrap_hash = {}
      for i, dp in enumerate(dp_set):
        di = cctbx.geometry_restraints.dihedral(
               sites_cart=sites_cart, proxy=dp[0])
        angle = di.angle_model
        wrap_chis = self.is_symmetric_torsion(dp[0])
        if wrap_chis:
          if angle > 90.0 or angle < -90.0:
            sym_i_seq = dp[0].i_seqs[3] #4th atom
            swap_i_seq = self.sym_atom_hash.get(sym_i_seq)
            if swap_i_seq is not None:
              swap_i_seqs = (dp[0].i_seqs[0],
                             dp[0].i_seqs[1],
                             dp[0].i_seqs[2],
                             swap_i_seq)
              dp_temp = cctbx.geometry_restraints.dihedral_proxy(
                i_seqs=swap_i_seqs,
                angle_ideal=0.0,
                weight=1/self.sigma**2,
                limit=self.limit,
                top_out=TOP_OUT_FLAG,
                slack=self.slack)
              wrap_hash[i] = dp_temp
              di = cctbx.geometry_restraints.dihedral(
                     sites_cart=sites_cart, proxy=dp_temp)
              angle = di.angle_model
            else:
              angle = None
        angles.append(angle)
        rama_out = False
        if dp[1] or dp[2]:
          angle_id = utils.get_torsion_id(
                       dp=dp[0],
                       name_hash=self.name_hash,
                       phi_psi=True)
          key = angle_id[4:11]+angle_id[0:4] #segid?
          if key in rama_outlier_list:
            rama_out = True
        is_rama_outlier.append(rama_out)

        omega_out = False
        if dp[3]:
          angle_id = utils.get_torsion_id(
                       dp=dp[0],
                       name_hash=self.name_hash,
                       omega=True)
          key1 = \
            angle_id[0][4:6].strip()+angle_id[0][6:10]+' '+angle_id[0][0:4]
          key2 = \
            angle_id[1][4:6].strip()+angle_id[1][6:10]+' '+angle_id[1][0:4]
          if (key1, key2) in omega_outlier_list:
            omega_out = True
        is_omega_outlier.append(omega_out)
        #if target_map_data is not None:
        #  tor_iselection = flex.size_t()
        #  for i_seq in dp.i_seqs:
        #    tor_iselection.append(i_seq)
        #  tor_sites_cart = \
        #    sites_cart.select(tor_iselection)
        #  di_cc = self.get_sites_cc(sites_cart=tor_sites_cart,
        #                            target_map_data=target_map_data)
        #  cc_s.append(di_cc)

        angle_id = utils.get_torsion_id(
                     dp=dp[0],
                     name_hash=self.name_hash,
                     chi_only=True)
        if angle_id is not None:
          split_rotamer_list = self.current_chi_restraints.get(angle_id)
          which_chi = self.get_chi_id(dp[0])
          rotamer_state.append(split_rotamer_list)
          if which_chi is not None:
            chi_ids.append(which_chi)
      target_angles = self.get_target_angles(
                        angles=angles,
                        #cc_s=cc_s,
                        is_rama_outlier=is_rama_outlier,
                        is_omega_outlier=is_omega_outlier,
                        rotamer_state=rotamer_state,
                        chi_ids=chi_ids)
      #if angle_id is not None: # and which_chi is None:
      #print angles
      #print target_angles
      for i, dp in enumerate(dp_set):
        target_angle = target_angles[i]
        angle_atoms = self.get_torsion_atoms(dp[0])
        angle_resname = self.get_torsion_resname(dp[0])
        angle_id = utils.get_torsion_id(dp=dp[0], name_hash=self.name_hash)
        cur_dict = self.sidechain_angle_hash.get(angle_resname)
        angle_name = None
        if cur_dict != None:
          angle_name = \
            cur_dict.get(angle_atoms)
        if target_angle is not None:
          angle_atoms = self.get_torsion_atoms(dp[0])
          angle_resname = self.get_torsion_resname(dp[0])
          angle_id = utils.get_torsion_id(dp=dp[0], name_hash=self.name_hash)
          cur_dict = self.sidechain_angle_hash.get(angle_resname)
          angle_name = None
          dp_sym = wrap_hash.get(i)
          if dp_sym is not None:
            dp_add = cctbx.geometry_restraints.dihedral_proxy(
              i_seqs=dp_sym.i_seqs,
              angle_ideal=target_angle,
              weight=1/self.sigma**2,
              limit=self.limit,
              top_out=TOP_OUT_FLAG,
              slack=self.slack)
          else:
            dp_add = cctbx.geometry_restraints.dihedral_proxy(
              i_seqs=dp[0].i_seqs,
              angle_ideal=target_angle,
              weight=1/self.sigma**2,
              limit=self.limit,
              top_out=TOP_OUT_FLAG,
              slack=self.slack)
          self.ncs_dihedral_proxies.append(dp_add)
          torsion_counter += 1

    if len(self.ncs_dihedral_proxies) == 0:
      if (not self.params.silence_warnings):
        print("** WARNING: No torsion NCS found!!" + \
          "  Please check parameters. **", file=log)
    else:
      print("Number of torsion NCS restraints: %d\n" \
          % len(self.ncs_dihedral_proxies), file=log)

  def show_sorted(self,
        by_value,
        sites_cart,
        site_labels,
        proxy_label="NCS torsion angle",
        f=sys.stdout):
    self.ncs_dihedral_proxies.show_sorted(
        by_value=by_value,
        sites_cart=sites_cart,
        site_labels=site_labels,
        proxy_label=proxy_label,
        f=f)

  def update_dihedral_ncs_restraints(self,
                                     model,
                                     log=None):
    self.model = model
    if log is None:
      log = sys.stdout
    make_sub_header(
      "Updating torsion NCS restraints",
      out=log)
    self.dp_ncs = None
    if self.dp_ncs is None:
      self.find_ncs_matches_from_hierarchy(model=model)
    else:
      self.generate_dihedral_ncs_restraints(sites_cart=self.model.get_sites_cart(),
                                            pdb_hierarchy=self.model.get_hierarchy(),
                                            log=log)
    # self.add_ncs_dihedral_proxies(geometry=geometry)

  def is_symmetric_torsion(self, dp):
    i_seqs = dp.i_seqs
    resname = self.name_hash[i_seqs[0]][5:8].upper()
    if resname not in \
      ['ASP', 'GLU', 'PHE', 'TYR']: #, 'ASN', 'GLN', 'HIS']:
      return False
    torsion_atoms = []
    for i_seq in i_seqs:
      name = self.name_hash[i_seq]
      atom = name[0:4]
      torsion_atoms.append(atom)
    if resname == 'ASP':
      if torsion_atoms == [' CA ', ' CB ', ' CG ', ' OD1'] or \
         torsion_atoms == [' CA ', ' CB ', ' CG ', ' OD2']:
        return True
    elif resname == 'GLU':
      if torsion_atoms == [' CB ', ' CG ', ' CD ', ' OE1'] or \
         torsion_atoms == [' CB ', ' CG ', ' CD ', ' OE2']:
        return True
    elif resname == 'PHE' or resname == 'TYR':
      if torsion_atoms == [' CA ', ' CB ',' CG ',' CD1'] or \
         torsion_atoms == [' CA ', ' CB ',' CG ',' CD2']:
        return True
    #elif resname == 'ASN':
    #  if torsion_atoms == [' CA ', ' CB ',' CG ',' OD1'] or \
    #     torsion_atoms == [' CA ', ' CB ',' CG ',' ND2']:
    #    return True
    #elif resname == 'GLN':
    #  if torsion_atoms == [' CB ', ' CG ',' CD ',' OE1'] or \
    #     torsion_atoms == [' CB ', ' CG ',' CD ',' NE2']:
    #    return True
    #elif resname == 'HIS':
    #  if torsion_atoms == [' CA ', ' CB ',' CG ',' ND1'] or \
    #     torsion_atoms == [' CA ', ' CB ',' CG ',' CD2']:
    #    return True
    return False

  def get_target_angles(self,
                        angles,
                        #cc_s,
                        is_rama_outlier,
                        is_omega_outlier,
                        rotamer_state,
                        chi_ids):
    assert (len(rotamer_state) == len(angles)) or \
           (len(rotamer_state) == 0)
    chi_num = None
    # print "chi_ids", chi_ids
    if len(chi_ids) > 0:
      assert len(chi_ids) == chi_ids.count(chi_ids[0])
      if ('oh' not in chi_ids and
          'sh' not in chi_ids and
          'me' not in chi_ids):
        chi_num = chi_ids[0][-1:]
    clusters = {}
    used = []
    target_angles = [None] * len(angles)

    #check for all outliers for current target
    if ( (is_rama_outlier.count(False)  == 0) or
         (is_omega_outlier.count(False) == 0) or
         ( ( (len(rotamer_state)-rotamer_state.count(None)) < 2 and
              len(rotamer_state) > 0)) ):
      for i, target in enumerate(target_angles):
        target_angles[i] = None
      return target_angles
    ###########

    max_i = None
    #for i, cc in enumerate(cc_s):
    #  if is_rama_outlier[i]:
    #    continue
    #  if max_i is None:
    #    max_i = i
    #  elif max < cc:
    #    max_i = i
    for i, ang_i in enumerate(angles):
      if i in used:
        continue
      if ang_i is None:
        continue
      for j, ang_j in enumerate(angles):
        if i == j:
          continue
        elif j in used:
          continue
        elif ang_j is None:
          continue
        else:
          if len(rotamer_state)> 0:
            if rotamer_state[i] is None:
              continue
            elif rotamer_state[j] is None:
              continue
          nonstandard_chi = False
          is_proline = False
          chi_matching = True
          if len(rotamer_state) > 0:
            if rotamer_state[i][0] in ['UNCLASSIFIED', 'OUTLIER',
                                       'Cg_exo', 'Cg_endo']:
              nonstandard_chi = True
            elif rotamer_state[j][0] in ['UNCLASSIFIED', 'OUTLIER',
                                         'Cg_exo', 'Cg_endo']:
              nonstandard_chi = True
            if rotamer_state[i][0] in ['Cg_exo', 'Cg_endo'] or \
               rotamer_state[j][0] in ['Cg_exo', 'Cg_endo']:
              is_proline = True
          if (chi_num is not None) and not nonstandard_chi:
            chi_counter = int(chi_num)
            while chi_counter > 0:
              if (rotamer_state[i][chi_counter-1] !=
                  rotamer_state[j][chi_counter-1]):
                chi_matching = False
              chi_counter -= 1
          if not chi_matching:
            continue
          if is_proline and \
             rotamer_state[i][0] != rotamer_state[j][0]:
            continue
          if i not in used:
            clusters[i] = []
            clusters[i].append(i)
            clusters[i].append(j)
            used.append(i)
            used.append(j)
          else:
            clusters[i].append(j)
            used.append(j)
      if i not in used:
        clusters[i] = None
    for key in list(clusters.keys()):
      cluster = clusters[key]
      if cluster is None:
        target_angles[key] = None
      else:
        cluster_angles = []
        cluster_outliers = 0
        for i in cluster:
          if is_rama_outlier[i]:
            cluster_angles.append(None)
          elif is_omega_outlier[i]:
            cluster_angles.append(None)
          elif len(rotamer_state) > 0:
            if rotamer_state[i][0] == 'OUTLIER':
              cluster_angles.append(None)
              cluster_outliers += 1
            else:
              cluster_angles.append(angles[i])
          else:
            cluster_angles.append(angles[i])
        if max_i is not None:
          target_angle = angles[max_i]
        else:
          target_angle = utils.get_angle_average(cluster_angles)
        if self.params.target_damping:
          for c in cluster:
            if target_angle is None:
              target_angles[c] = None
            else:
              c_dist = utils.angle_distance(angles[c], target_angle)
              if c_dist > self.params.damping_limit:
                d_target = \
                  utils.get_angle_average([angles[c], target_angle])
                target_angles[c] = d_target
              else:
                target_angles[c] = target_angle
        else:
          if (len(cluster) - cluster_outliers) == 1:
            for c in cluster:
              if rotamer_state[c][0] == 'OUTLIER':
                target_angles[c] = target_angle
              else:
                target_angles[c] = None
          else:
            for c in cluster:
              target_angles[c] = target_angle
        if (self.restrain_to_master_chain):
          if target_angles[cluster[0]] is not None:
            for i,c in enumerate(cluster):
              if i == 0:
                target_angles[c] = None
              else:
                target_angles[c] = angles[cluster[0]]
    return target_angles

  def get_ramachandran_outliers(self, pdb_hierarchy):
    rama_outliers = []
    self.rama = ramalyze.ramalyze(pdb_hierarchy=pdb_hierarchy,
                                  outliers_only=True)
    for r in self.rama.results:
      rama_outliers.append(r.id_str())
    return rama_outliers

  def get_omega_outliers(self, pdb_hierarchy):
    cis_peptides, trans_peptides, omega_outliers = \
      analyze_peptides.analyze(pdb_hierarchy=pdb_hierarchy)
    return omega_outliers

  def get_rotamer_data(self, pdb_hierarchy):
    self.r = rotalyze.rotalyze(pdb_hierarchy=pdb_hierarchy)
    model_hash = {}
    model_score = {}
    all_rotamers = {}
    model_chis = {}
    for rot in self.r.results:
      model_hash[rot.id_str()] = rot.rotamer_name
      model_score[rot.id_str()] = rot.score
    for key in list(self.res_match_master.keys()):
      res_key = key[4:10]+' '+key[0:4]
      all_rotamers[res_key] = []
      model_rot = model_hash.get(res_key)
      if model_rot is not None and model_rot != "OUTLIER":
        all_rotamers[res_key].append(model_rot)
      for match_res in self.res_match_master[key]:
        j_key = match_res[4:10]+' '+match_res[0:4]
        j_rot = model_hash.get(j_key)
        if j_rot is not None and j_rot != "OUTLIER":
          if j_rot not in all_rotamers[res_key]:
            all_rotamers[res_key].append(j_rot)

    for model in pdb_hierarchy.models():
      for chain in model.chains():
        for residue_group in chain.residue_groups():
            all_dict = \
              rotalyze.construct_complete_sidechain(residue_group)
            for atom_group in residue_group.atom_groups():
              #try:
                atom_dict = all_dict.get(atom_group.altloc)
                chis = \
                  self.sa.measureChiAngles(atom_group, atom_dict)
                if chis is not None:
                  key = utils.id_str(
                          chain_id=chain.id,
                          resseq=residue_group.resseq,
                          resname=atom_group.resname,
                          icode=residue_group.icode,
                          altloc=atom_group.altloc)
                  #key = '%s%5s %s' % (
                  #    chain.id, residue_group.resid(),
                  #    atom_group.altloc+atom_group.resname)
                  model_chis[key] = chis
    return model_hash, model_score, all_rotamers, model_chis

  def fix_rotamer_outliers(self,
                           xray_structure,
                           geometry_restraints_manager,
                           pdb_hierarchy,
                           outliers_only=False,
                           log=None,
                           quiet=False):
    self.last_round_outlier_fixes = 0
    if self.rotamer_search_manager is None:
      self.rotamer_search_manager = rotamer_search.manager(
                                      pdb_hierarchy=pdb_hierarchy,
                                      xray_structure=xray_structure,
                                      name_hash=self.name_hash,
                                      selection=self.selection,
                                      log=self.log)
    if self.unit_cell is None:
      self.unit_cell = xray_structure.unit_cell()
    sites_cart = xray_structure.sites_cart()
    for atom in pdb_hierarchy.atoms():
      i_seq = atom.i_seq
      atom.xyz = sites_cart[i_seq]
    selection_radius = 5
    fmodel = self.fmodel
    if(log is None): log = self.log
    make_sub_header(
      "Correcting NCS rotamer outliers",
      out=log)

    self.rotamer_search_manager.prepare_map(fmodel=fmodel)

    model_hash, model_score, all_rotamers, model_chis = \
      self.get_rotamer_data(pdb_hierarchy=pdb_hierarchy)

    fix_list = {}
    rotamer_targets = {}

    for key in list(self.res_match_master.keys()):
      res_key = key[4:11]+key[0:4]
      model_rot = model_hash.get(res_key)
      if model_rot == "OUTLIER":
        rotamer = None
        score = 0.0
        for match_res in self.res_match_master[key]:
          j_key = match_res[4:11]+match_res[0:4]
          j_rot = model_hash.get(j_key)
          j_score = model_score.get(j_key)
          if j_rot is not None and j_score is not None:
            if j_rot != "OUTLIER":
              if rotamer == None:
                rotamer = j_key
                score = j_score
                target = j_rot
              else:
                if j_score > score:
                  rotamer = j_key
                  score = j_score
                  target = j_rot
        if rotamer != None:
          fix_list[res_key] = rotamer
          rotamer_targets[res_key] = target

    sites_cart_moving = xray_structure.sites_cart()
    for model in pdb_hierarchy.models():
      for chain in model.chains():
        if not chain.is_protein():
          continue
        for residue_group in chain.residue_groups():
          all_dict = \
            rotalyze.construct_complete_sidechain(residue_group)
          for atom_group in residue_group.atom_groups():
            if atom_group.resname in ["PRO", "GLY"]:
              continue
            key = utils.id_str(
                    chain_id=chain.id,
                    resseq=residue_group.resseq,
                    resname=atom_group.resname,
                    icode=residue_group.icode,
                    altloc=atom_group.altloc)
            #key = '%s%5s %s' % (
            #          chain.id, residue_group.resid(),
            #          atom_group.altloc+atom_group.resname)
            if key in list(fix_list.keys()):
              model_rot, m_chis, value = rotalyze.evaluate_rotamer(
                atom_group=atom_group,
                sidechain_angles=self.sa,
                rotamer_evaluator=self.model.get_rotamer_manager(),
                rotamer_id=self.model.get_rotamer_id(),
                all_dict=all_dict,
                sites_cart=sites_cart_moving)
              residue_name = key[-3:]
              cur_rotamer = rotamer_targets[key]
              r_chis = self.sa.get_rotamer_angles(
                         residue_name=residue_name,
                         rotamer_name=cur_rotamer)
              if m_chis is not None and r_chis is not None:
                status = self.rotamer_search_manager.search(
                  atom_group=atom_group,
                  all_dict=all_dict,
                  m_chis=m_chis,
                  r_chis=r_chis,
                  rotamer=cur_rotamer,
                  sites_cart_moving=sites_cart_moving,
                  xray_structure=xray_structure,
                  key=key)
                if status:
                  print("Set %s to %s rotamer" % \
                    (key, cur_rotamer), file=log)
                  self.last_round_outlier_fixes += 1

  def get_sites_cc(self,
                   sites_cart,
                   target_map_data):
    t = target(sites_cart, self.unit_cell, target_map_data)
    return t


  def get_sidechain_map_correlation(self,
                                    xray_structure,
                                    pdb_hierarchy):
    map_cc_hash = {}
    sigma_cutoff_hash = {}
    fmodel = self.fmodel
    target_map_data, residual_map_data = \
      utils.prepare_map(fmodel=fmodel)
    sites_cart_moving = xray_structure.sites_cart()
    for model in pdb_hierarchy.models():
      for chain in model.chains():
        #only works with protein sidechains
        if not chain.is_protein():
          continue
        for residue_group in chain.residue_groups():
          all_dict = rotalyze.construct_complete_sidechain(residue_group)
          for atom_group in residue_group.atom_groups():
            if atom_group.resname in ["PRO", "GLY"]:
              continue
            key = atom_group.atoms()[0].pdb_label_columns()[4:]+\
                  atom_group.atoms()[0].segid
            residue_iselection = atom_group.atoms().extract_i_seq()
            residue_elements = atom_group.atoms().extract_element()
            sidechain_only_iselection = flex.size_t()
            for i, i_seq in enumerate(residue_iselection):
              atom_name = self.name_hash[i_seq][0:4]
              if atom_name not in [' N  ', ' CA ', ' C  ', ' O  '] and \
                 residue_elements[i].strip() not in ['H','D']:
                sidechain_only_iselection.append(i_seq)
            sites_cart_residue = \
              sites_cart_moving.select(sidechain_only_iselection)
            t_test = self.get_sites_cc(sites_cart_residue,
                                       target_map_data)
            map_cc_hash[key] = t_test
            sigma_state = all_sites_above_sigma_cutoff(
                            sites_cart_residue,
                            self.unit_cell,
                            target_map_data,
                            1.0)
            sigma_cutoff_hash[key] = sigma_state
    return map_cc_hash, sigma_cutoff_hash

  def fix_rotamer_consistency(self,
                              xray_structure,
                              geometry_restraints_manager,
                              pdb_hierarchy,
                              log=None,
                              quiet=False):
    self.last_round_rotamer_changes = 0
    # Removed check for existence to prevent a bug. See commit
    # 67af93785e4 for more info.
    self.rotamer_search_manager = rotamer_search.manager(
                                    pdb_hierarchy=pdb_hierarchy,
                                    xray_structure=xray_structure,
                                    name_hash=self.name_hash,
                                    selection=self.selection,
                                    log=self.log)
    if self.unit_cell is None:
      self.unit_cell = xray_structure.unit_cell()
    sites_cart = xray_structure.sites_cart()
    for atom in pdb_hierarchy.atoms():
      i_seq = atom.i_seq
      atom.xyz = sites_cart[i_seq]
    fmodel = self.fmodel
    if(log is None): log = self.log
    make_sub_header(
      "Checking NCS rotamer consistency",
      out=log)

    self.rotamer_search_manager.prepare_map(fmodel=fmodel)

    model_hash, model_score, all_rotamers, model_chis = \
      self.get_rotamer_data(pdb_hierarchy=pdb_hierarchy)

    sites_cart_moving = xray_structure.sites_cart()
    map_cc_hash, sigma_cutoff_hash = \
      self.get_sidechain_map_correlation(xray_structure, pdb_hierarchy)
    cc_candidate_list = []
    for key in list(self.ncs_match_hash.keys()):
      whole_set = []
      value = map_cc_hash.get(key)
      max = None
      max_key = None
      if value is not None:
        whole_set.append( (key, value) )
        max = value
        max_key = key
      for member in self.ncs_match_hash[key]:
        value = map_cc_hash.get(member)
        if value is not None:
          whole_set.append( (member, value) )
          if max is None:
            max = value
            max_key = member
          else:
            if value > max:
              max = value
              max_key = member
      if max is None or max <= 0.0:
        continue
      for set in whole_set:
        cur_key = set[0]
        cur_value  = set[1]
        #fudge factor to account for zero cur_value
        if cur_value <= 0.0:
          cur_value = 0.0001
        percentage = (max - cur_value) / cur_value
        if percentage > 0.2:
          if not sigma_cutoff_hash[cur_key]:
            cc_candidate_list.append(cur_key)

    for model in pdb_hierarchy.models():
      for chain in model.chains():
        if not chain.is_protein():
          continue
        for residue_group in chain.residue_groups():
          all_dict = rotalyze.construct_complete_sidechain(residue_group)
          for atom_group in residue_group.atom_groups():
            if atom_group.resname in ["PRO", "GLY"]:
              continue
            key = utils.id_str(
                    chain_id=chain.id,
                    resseq=residue_group.resseq,
                    resname=atom_group.resname,
                    icode=residue_group.icode,
                    altloc=atom_group.altloc)
            #key = '%s%5s %s' % (
            #          chain.id, residue_group.resid(),
            #          atom_group.altloc+atom_group.resname)
            if key in all_rotamers:
              if (len(all_rotamers[key]) >= 2):
                cc_key = atom_group.atoms()[0].pdb_label_columns()[4:]+\
                  atom_group.atoms()[0].segid
                if cc_key not in cc_candidate_list:
                  continue
                model_rot, m_chis, value = rotalyze.evaluate_rotamer(
                  atom_group=atom_group,
                  sidechain_angles=self.sa,
                  rotamer_evaluator=self.model.get_rotamer_manager(),
                  rotamer_id=self.model.get_rotamer_id(),
                  all_dict=all_dict,
                  sites_cart=sites_cart_moving)
                residue_name = key[-3:]
                # why do I not try to fix outliers here?
                if model_rot == "OUTLIER":
                  continue
                current_best = model_rot
                #C-alpha prep
                cur_ca = None
                for atom in atom_group.atoms():
                  if atom.name == " CA ":
                    cur_ca = atom.i_seq
                for cur_rotamer in all_rotamers.get(key):
                  if cur_rotamer == model_rot:
                    continue
                  r_chis = self.sa.get_rotamer_angles(
                             residue_name=residue_name,
                             rotamer_name=cur_rotamer)
                  if m_chis is not None and r_chis is not None:
                    status = self.rotamer_search_manager.search(
                      atom_group=atom_group,
                      all_dict=all_dict,
                      m_chis=m_chis,
                      r_chis=r_chis,
                      rotamer=cur_rotamer,
                      sites_cart_moving=sites_cart_moving,
                      xray_structure=xray_structure,
                      key=key)
                    if status:
                      current_best = cur_rotamer
                      atom_dict = all_dict.get(atom_group.altloc)
                      m_chis = \
                        self.sa.measureChiAngles(atom_group,
                                                 atom_dict,
                                                 sites_cart_moving)
                if current_best != model_rot:
                  print("Set %s to %s rotamer" % \
                    (key,
                     current_best), file=self.log)
                  self.last_round_rotamer_changes += 1
                else:
                  rotamer, chis, value = rotalyze.evaluate_rotamer(
                    atom_group=atom_group,
                    sidechain_angles=self.sa,
                    rotamer_evaluator=self.model.get_rotamer_manager(),
                    rotamer_id=self.model.get_rotamer_id(),
                    all_dict=all_dict,
                    sites_cart=sites_cart_moving)
                  assert rotamer == model_rot

  def build_sidechain_angle_hash(self):
    sidechain_angle_hash = {}
    for key in list(self.sa.atomsForAngle.keys()):
      resname = key[0:3].upper()
      if sidechain_angle_hash.get(resname) is None:
        sidechain_angle_hash[resname] = {}
      new_key = ''
      for atom in self.sa.atomsForAngle[key]:
        new_key += atom
      new_value = key[4:]
      sidechain_angle_hash[resname][new_key] = new_value
    #modifications
    sidechain_angle_hash['ILE'][' N   CA  CB  CG2'] = 'chi1'
    sidechain_angle_hash['THR'][' N   CA  CB  CG2'] = 'chi1'
    sidechain_angle_hash['VAL'][' N   CA  CB  CG2'] = 'chi1'
    return sidechain_angle_hash

  def get_number_of_restraints_per_group(self):
    torsion_counts = {}
    for i_gr, group in enumerate(self.ncs_restraints_group_list):
      for i_sel, selection in enumerate(group.get_iselections_list()):
        key = self.ncs_groups_selection_string_list[i_gr][i_sel]
        torsion_counts[key] = self.ncs_dihedral_proxies.\
            proxy_select(n_seq=self.model.get_number_of_atoms(),
                         iselection=selection).\
                size()
    return torsion_counts

  def get_torsion_rmsd(self, sites_cart):
    self.histogram_under_limit = None
    self.histogram_over_limit = None
    self.torsion_rmsd = None
    self.all_torsion_rmsd = None
    dp_proxies_under_limit = cctbx.geometry_restraints.shared_dihedral_proxy()
    dp_proxies_over_limit = cctbx.geometry_restraints.shared_dihedral_proxy()
    for dp in self.ncs_dihedral_proxies:
      di = cctbx.geometry_restraints.dihedral(
             sites_cart=sites_cart, proxy=dp)
      delta = abs(di.delta)
      if delta <= self.limit:
        dp_proxies_under_limit.append(dp)
      else:
        dp_proxies_over_limit.append(dp)
    torsion_deltas_under_limit = cctbx.geometry_restraints.dihedral_deltas(
                       sites_cart = sites_cart,
                       proxies = dp_proxies_under_limit)
    torsion_deltas_over_limit = cctbx.geometry_restraints.dihedral_deltas(
                       sites_cart = sites_cart,
                       proxies = dp_proxies_over_limit)
    torsion_deltas_all = cctbx.geometry_restraints.dihedral_deltas(
                       sites_cart = sites_cart,
                       proxies = self.ncs_dihedral_proxies)
    if len(torsion_deltas_under_limit) > 0:
      self.histogram_under_limit = \
        flex.histogram(
          data=flex.abs(torsion_deltas_under_limit),
          data_min=0.0,
          data_max=self.limit,
          n_slots=10)
      self.torsion_rmsd = self.calculate_torsion_rmsd(
                            deltas=torsion_deltas_under_limit)
    if ( (len(torsion_deltas_over_limit) > 0) and
         (self.limit < 180.0) ):
      self.histogram_over_limit = \
        flex.histogram(
          data=flex.abs(torsion_deltas_over_limit),
          data_min=self.limit,
          data_max=math.ceil(
          max(flex.abs(torsion_deltas_over_limit))),
          n_slots=10)
    if len(torsion_deltas_all) > 0:
      self.all_torsion_rmsd = self.calculate_torsion_rmsd(
                                deltas=torsion_deltas_all)

  def calculate_torsion_rmsd(self, deltas):
    assert len(deltas) > 0
    delta_sq_sum = 0.0
    for delta in deltas:
      delta_sq_sum += ( abs(delta)**2 )
    return math.sqrt(delta_sq_sum / len(deltas))

  def proxy_select(self, nseq, iselection):
    #
    # This is still not proper manager selection. A lot of stuff remains old.
    # It still works because it is being updated every macro-cycle via
    # update_dihedral_ncs_restraints
    #
    import copy
    assert (self.ncs_dihedral_proxies is not None)
    new_ncs_dihedral_proxies = \
        self.ncs_dihedral_proxies.proxy_select(nseq, iselection)
    new_manager = copy.copy(self)
    new_manager.ncs_dihedral_proxies = new_ncs_dihedral_proxies
    new_manager.ncs_restraints_group_list = \
        self.ncs_restraints_group_list.select(flex.bool(nseq, iselection))
    return new_manager

  def remove_reference_dihedrals_in_place(self):
    self.ncs_dihedral_proxies = None

  def get_n_proxies(self):
    if self.ncs_dihedral_proxies is not None:
      return self.ncs_dihedral_proxies.size()
    else:
      return 0

  def size(self):
    return self.get_n_proxies()

  def target_and_gradients(self, sites_cart, unit_cell, gradient_array):
    if unit_cell is None:
      return cctbx.geometry_restraints.dihedral_residual_sum(
        sites_cart=sites_cart,
        proxies=self.ncs_dihedral_proxies,
        gradient_array=gradient_array)
    else:
      return cctbx.geometry_restraints.dihedral_residual_sum(
          unit_cell=unit_cell,
          sites_cart=sites_cart,
          proxies=self.ncs_dihedral_proxies,
          gradient_array=gradient_array)

# XXX wrapper for running in Phenix GUI
class _run_iotbx_ncs_input(object):
  def __init__(self, params, pdb_hierarchy):
    self.params = params
    self.pdb_hierarchy = pdb_hierarchy

  def __call__(self, *args, **kwds):
    return iotbx.ncs.input(hierarchy=self.pdb_hierarchy).\
      print_ncs_phil_param()


 *******************************************************************************
