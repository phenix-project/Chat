

 *******************************************************************************
fable/__init__.py
from __future__ import absolute_import, division, print_function
try:
  import boost_adaptbx.boost.python as bp
except Exception:
  ext = None
else:
  ext = bp.import_ext("fable_ext", optional=True)
from six.moves import range

# compare with fem/utils/string.hpp
def py_fem_utils_unsigned_integer_scan(code, start=0, stop=-1):
  i = start
  while (i < stop):
    c = code[i]
    if (not c.isdigit()): break
    i += 1
  if (i == start): return -1
  return i

# compare with ext.cpp
def py_ext_get_code_stop(code, stop):
  len_code = len(code)
  if (stop < 0): return len_code
  assert stop <= len_code
  return stop

# compare with ext.cpp
def py_unsigned_integer_scan(code, start=0, stop=-1):
  return py_fem_utils_unsigned_integer_scan(
    code=code, start=start, stop=py_ext_get_code_stop(code, stop))

# compare with ext.cpp
def py_floating_point_scan_after_exponent_char(code, start=0, stop=-1):
  code_stop = py_ext_get_code_stop(code=code, stop=stop)
  i = start
  if (i < code_stop):
    c = code[i]
    if (c == '+' or c == '-'):
      i += 1
    return py_unsigned_integer_scan(code=code, start=i, stop=stop)
  return -1

# compare with ext.cpp
def py_floating_point_scan_after_dot(code, start=0, stop=-1):
  code_stop = py_ext_get_code_stop(code=code, stop=stop)
  i = py_unsigned_integer_scan(code=code, start=start, stop=stop)
  if (i < 0): i = start
  if (i < code_stop):
    c = code[i]
    if (c == 'e' or c == 'd'):
      return py_floating_point_scan_after_exponent_char(
        code=code, start=i+1, stop=stop)
  return i

# compare with ext.cpp
def py_identifier_scan(code, start=0, stop=-1):
  code_stop = py_ext_get_code_stop(code=code, stop=stop)
  i = start
  if (i < code_stop):
    c = code[i]; i += 1
    if ((c < 'a' or c > 'z') and c != '_'): return -1
    while (i < code_stop):
      c = code[i]; i += 1
      if (    (c < 'a' or c > 'z')
          and (c < '0' or c > '9') and c != '_'): return i-1
    return i
  return -1

def py_find_closing_parenthesis(code, start=0, stop=-1):
  code_stop = py_ext_get_code_stop(code=code, stop=stop)
  n_inner = 0
  for i in range(start, code_stop):
    c = code[i]
    if (c == ')'):
      if (n_inner == 0): return i
      n_inner -= 1
    elif (c == '('):
      n_inner += 1
  return -1

if (ext is not None):
  from fable_ext import *
else:
  unsigned_integer_scan = py_unsigned_integer_scan
  floating_point_scan_after_exponent_char = \
    py_floating_point_scan_after_exponent_char
  floating_point_scan_after_dot = py_floating_point_scan_after_dot
  identifier_scan = py_identifier_scan
  find_closing_parenthesis = py_find_closing_parenthesis

class SemanticError(Exception): pass


 *******************************************************************************


 *******************************************************************************
fable/command_line/__init__.py


 *******************************************************************************


 *******************************************************************************
fable/command_line/cout.py
from __future__ import absolute_import, division, print_function
import fable.cout

import hashlib
import optparse
import os
import sys

def compute_hexdigest(text):
  m = hashlib.md5()
  m.update(text.encode("utf-8"))
  return m.hexdigest()

def check_fingerprint(file_name):
  with open(file_name) as f:
    lines = f.read().splitlines()
  if (len(lines) == 0): return None
  flds = lines[0].split()
  if (len(flds) < 2 or flds[-2] != "fingerprint"): return None
  orig_hexdigest = flds[-1]
  curr_text = "\n".join(lines[1:])+"\n"
  curr_hexdigest = compute_hexdigest(text=curr_text)
  if (len(orig_hexdigest) != len(curr_hexdigest)): return None
  return (orig_hexdigest == curr_hexdigest)

def write_only_if_safe(file_name, text):
  from libtbx.str_utils import show_string
  if (os.path.exists(file_name)):
    if (not os.path.isfile(file_name)):
      raise RuntimeError(
        "Not a regular file: %s" % show_string(file_name))
    stat = check_fingerprint(file_name=file_name)
    if (stat is None or not stat):
      raise RuntimeError(
        "File appears to be manually modified: %s" % show_string(file_name))
  hexdigest = compute_hexdigest(text=text)
  with open(file_name, "w") as f:
    f.write("// fingerprint %s\n" % hexdigest)
    f.write(text)

class process(object):

  __slots__ = ["options", "dynamic_parameters", "n_calls"]

  def __init__(O, options):
    O.options = options
    if (options.dynamic_parameter is None):
      O.dynamic_parameters = None
    else:
      from fable.cout import dynamic_parameter_props
      from libtbx.utils import Sorry
      O.dynamic_parameters = []
      for opt_dp in options.dynamic_parameter:
        flds = opt_dp.replace("=", " ").split()
        if (len(flds) != 3):
          raise Sorry('Invalid --dynamic-parameter="%s"' % opt_dp)
        if (flds[1] in O.dynamic_parameters):
          raise Sorry('Duplicate --dynamic-parameter="%s"' % opt_dp)
        O.dynamic_parameters.append(dynamic_parameter_props(
          name=flds[1],
          ctype=flds[0],
          default=flds[2]))
    O.n_calls = 0

  def __call__(O, file_names):
    if (O.n_calls != 0):
      print()
    O.n_calls += 1
    opts = O.options
    lines = fable.cout.process(
      file_names=file_names,
      top_procedures=opts.top_procedure,
      include_guard_suffix=opts.include_guard_suffix,
      dynamic_parameters=O.dynamic_parameters,
      fortran_file_comments=opts.fortran_file_comments,
      fem_do_safe=not opts.no_fem_do_safe,
      arr_nd_size_max=opts.arr_nd_size_max,
      inline_all=opts.inline_all,
      common_equivalence_simple=set(opts.common_equivalence_simple.split(",")),
      namespace=opts.namespace,
      separate_cmn_hpp=opts.separate_cmn_hpp,
      number_of_function_files=opts.number_of_function_files,
      debug=opts.debug)
    text = "\n".join(lines)+"\n"
    if (opts.top_procedure is None or not opts.debug):
      sys.stdout.write(text)
    if (len(file_names) != 0 and opts.compile):
      print()
      write_only_if_safe(file_name="fable_cout.cpp", text=text)
      from fable import simple_compilation
      comp_env = simple_compilation.environment()
      out_name = comp_env.build(exe_name=opts.exe_name,
        link=opts.link, file_name_cpp="fable_cout.cpp", show_command=True)
      print()
      if (opts.run):
        from libtbx import easy_run
        cmd = os.path.join(".", out_name)
        if (opts.valgrind):
          cmd = "valgrind " + cmd
        print(cmd)
        easy_run.call(command=cmd)

def run(args):
  import libtbx.load_env
  if (len(args) == 0):
    args = ["--help"]
  elif (args == ["--example"]):
    args = [
      libtbx.env.under_dist(module_name="fable", path="test/valid/sf.f"),
      "--namespace", "example",
      "--run"]
  parser = optparse.OptionParser(usage="%s [options] fortran_file ..." % libtbx.env.dispatcher_name)
  parser.add_option("-?", action="help", help=optparse.SUPPRESS_HELP)
  parser.add_option("--compile", action="store_true", default=False)
  parser.add_option("--link", action="store_true", default=False)
  parser.add_option("--run", action="store_true", default=False)
  parser.add_option("--valgrind", action="store_true", default=False)
  parser.add_option("--each", action="store_true", default=False)
  parser.add_option("--top_procedure", action="append", type="str", metavar="IDENTIFIER")
  parser.add_option("--top-procedure", action="append", type="str", help=optparse.SUPPRESS_HELP)
  parser.add_option("--include_guard_suffix", action="store", type="str", metavar="STRING")
  parser.add_option("--include-guard-suffix", action="store", type="str", help=optparse.SUPPRESS_HELP)
  parser.add_option("--dynamic_parameter", action="append", type="str", metavar="STRING", help='example: --dynamic_parameter="int array_size=100"')
  parser.add_option("--dynamic-parameter", action="append", type="str", help=optparse.SUPPRESS_HELP)
  parser.add_option("--fortran_file_comments", action="store_true", default=False)
  parser.add_option("--fortran-file-comments", action="store_true", help=optparse.SUPPRESS_HELP)
  parser.add_option("--no_fem_do_safe", action="store_true", default=False)
  parser.add_option("--no-fem-do-safe", action="store_true", help=optparse.SUPPRESS_HELP)
  parser.add_option("--arr_nd_size_max", action="store", type="int", default=fable.cout.default_arr_nd_size_max, metavar='INTEGER (default: %d)' % fable.cout.default_arr_nd_size_max)
  parser.add_option("--arr-nd-size-max", action="store", type="int", help=optparse.SUPPRESS_HELP)
  parser.add_option("--inline_all", action="store_true", default=False)
  parser.add_option("--inline-all", action="store_true", help=optparse.SUPPRESS_HELP)
  parser.add_option("--common_equivalence_simple", action="store", type="str", default="", metavar="STRING", help='comma-separated list of common names')
  parser.add_option("--common-equivalence-simple", action="store", type="str", help=optparse.SUPPRESS_HELP)
  parser.add_option("--namespace", action="store", type="str")
  parser.add_option("--separate_cmn_hpp", action="store_true", default=False)
  parser.add_option("--separate-cmn-hpp", action="store_true", help=optparse.SUPPRESS_HELP)
  parser.add_option("--number_of_function_files", action="store", type="int", metavar="INTEGER")
  parser.add_option("--number-of-function-files", action="store", type="int", help=optparse.SUPPRESS_HELP)
  parser.add_option("--example", action="store_true", default=False)
  parser.add_option("--debug", action="store_true", default=False)
  parser.add_option("--exe_name", action="store", type="str")
  parser.add_option("--exe-name", action="store", type="str",help=optparse.SUPPRESS_HELP)

  co, files = parser.parse_args(args)
  if co.valgrind: co.run = True
  if co.run: co.link = True
  if co.link: co.compile = True
  if not co.each:
    process(options=co)(file_names=files)
  else:
    from fable.command_line.read import process_each
    process_each(process=process(options=co), file_names=files)

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
fable/command_line/fem_include_search_paths.py
from __future__ import absolute_import, division, print_function
def run(args):
  if (args not in [["--with-quotes"], ["--no-quotes"]]):
    from libtbx.utils import Usage
    import libtbx.load_env
    raise Usage("%s --with-quotes|--no-quotes" % libtbx.env.dispatcher_name)
  from fable import simple_compilation
  comp_env = simple_compilation.environment()
  print(comp_env.assemble_include_search_paths(
    no_quotes=(args[0]=="--no-quotes")))

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
fable/command_line/insert_write_at_start_of_each_procedure.py
"Minimalistic, pragmatic implementation. Absolutely no bells and whistles."
from __future__ import absolute_import, division, print_function

def run(args):
  assert args[0] == "--yes-i-know-this-overwrites-the-original-files"
  import fable.read
  import os
  op = os.path
  n_files_changed = 0
  for file_name in args[1:]:
    file_name = op.abspath(file_name)
    all_fprocs = fable.read.process(file_names=[file_name])
    insert_info = []
    for fproc in all_fprocs.all_in_input_order:
      if (fproc.fproc_type == "blockdata"): continue
      if (len(fproc.executable) == 0):
        print("WARNING: no executable statements in %s" % fproc.name.value)
      else:
        sl0 = fproc.executable[0].ssl.source_line_cluster[0]
        assert sl0.file_name == file_name
        insert_info.append((fproc.name.value, sl0.line_number))
    if (len(insert_info) != 0):
      insert_info.reverse()
      lines = open(file_name).read().splitlines()
      for name,line_number in insert_info:
        lines.insert(line_number-1,
          "      write(6, '(a)') 'PROCEDURE_START: %s'" % name)
      print("\n".join(lines), file=open(file_name, "w"))
      n_files_changed += 1
  print("Number of files changed:", n_files_changed)

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
fable/command_line/read.py
from __future__ import absolute_import, division, print_function

import optparse
import sys

def process_each(process, file_names, report_success=False):
  import traceback
  n_fail = 0
  n_succ = 0
  for file_name in file_names:
    try:
      process(file_names=[file_name])
    except Exception:
      n_fail += 1
      print("FAILING:", file_name)
      print(traceback.format_exc(limit=None))
    else:
      if (report_success):
        print("SUCCESS:", file_name)
      n_succ += 1
  if (n_fail != 0):
    print("Failing:", n_fail)
  if (n_succ != 0):
    print("Success:", n_succ)

def report_equivalence_clusters_with_mixed_data_types(fproc):
  for equiv_tok_cluster in fproc.equivalence_info().equiv_tok_clusters:
    data_types_list = []
    data_types_set = set()
    for equiv_tok in equiv_tok_cluster:
      for tok_seq in equiv_tok.value:
        identifier = tok_seq.value[0].value
        fdecl = fproc.fdecl_by_identifier[identifier]
        dt = fdecl.data_type
        if (dt is not None):
          data_types_list.append((identifier,dt.value))
          data_types_set.add(dt.value)
    if (len(data_types_set) > 1):
      print(equiv_tok_cluster[0].value[0].value[0].format_error(
        msg="Warning: EQUIVALENCE cluster with mixed data types: %s" %
          ", ".join(sorted(data_types_set))))
      for identifier,dtv in data_types_list:
        print("  %s: %s" % (identifier, dtv))

def run(args):
  if (len(args) == 0): args = ["--help"]
  import libtbx.load_env
  parser = optparse.OptionParser(usage="%s [options] fortran_file ..."%libtbx.env.dispatcher_name)
  parser.add_option("-?", action="help", help=optparse.SUPPRESS_HELP)
  parser.add_option("--each", action="store_true", default=False)
  parser.add_option("--report_success", action="store_true", default=False)
  parser.add_option("--report-success", action="store_true", help=optparse.SUPPRESS_HELP)
  parser.add_option("--warnings", action="store_true", default=False)
  co, files = parser.parse_args(args)

  def sorry_exclusive(opt_name):
    from libtbx.utils import Sorry
    raise Sorry(
      "%s: options are mutually exclusive: --each, --%s"
        % (libtbx.env.dispatcher_name, opt_name))
  if (co.each):
    if (co.warnings): sorry_exclusive("warnings")
  from fable.read import process
  if (co.each):
    process_each(
      process=process,
      file_names=files,
      report_success=co.report_success)
  else:
    all_fprocs = process(file_names=files)
    if (co.warnings):
      for fproc in all_fprocs.all_in_input_order:
        report_equivalence_clusters_with_mixed_data_types(fproc=fproc)

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
fable/command_line/show_calls.py
from __future__ import absolute_import, division, print_function
import optparse
import sys

def run(args):
  if (len(args) == 0): args = ["--help"]
  import libtbx.load_env
  parser = optparse.OptionParser(usage="%s [options] fortran_file ..."%libtbx.env.dispatcher_name)
  parser.add_option("-?", action="help", help=optparse.SUPPRESS_HELP)
  parser.add_option("--top_procedure", action="append", type="str")
  parser.add_option("--top-procedure", action="append", type="str", help=optparse.SUPPRESS_HELP)
  parser.add_option("--write_graphviz_dot", action="store", type="str")
  parser.add_option("--write-graphviz-dot", action="store", type="str", help=optparse.SUPPRESS_HELP)
  option, files = parser.parse_args(args)

  from fable.read import process
  all_fprocs = process(file_names=files)
  topological_fprocs = all_fprocs.build_bottom_up_fproc_list_following_calls(
    top_procedures=option.top_procedure)
  dep_cycles = topological_fprocs.dependency_cycles
  if (len(dep_cycles) != 0):
    print("Dependency cycles:", len(dep_cycles))
    for cycle in dep_cycles:
      print(" ", " ".join(cycle))
    print()
  print("Top-down procedure list:")
  print()
  digraph_lhs_rhs = []
  for fproc in reversed(topological_fprocs.bottom_up_list):
    if (fproc.name is None):
      lhs = fproc.fproc_type
      print(lhs)
    else:
      lhs = fproc.name.value
      print(fproc.fproc_type, fproc.name.value)
    fwds = set(
      topological_fprocs.forward_uses_by_identifier.get(
        fproc.name.value, []))
    for identifier in sorted(fproc.fdecl_by_identifier.keys()):
      fdecl = fproc.fdecl_by_identifier[identifier]
      if (fdecl.is_fproc_name()): continue
      if (not fdecl.is_user_defined_callable()):
        continue
      called_name = fdecl.id_tok.value
      passed = fproc.externals_passed_by_arg_identifier.get(called_name)
      if (passed is None):
        digraph_lhs_rhs.append((lhs, called_name))
      else:
        called_name += "->" + ",".join(sorted(passed))
        for indirectly_called_name in passed:
          digraph_lhs_rhs.append((lhs, indirectly_called_name))
      if (fdecl.is_function()):
        sz = ""
        if (fdecl.size_tokens is not None):
          if (len(fdecl.size_tokens) == 1
                and fdecl.size_tokens[0].is_integer()):
            sz = "*%s" % fdecl.size_tokens[0].value
          else:
            sz = "*(*)"
        s = "%s (%s%s)" % (called_name, fdecl.data_type.value, sz)
      else:
        s = called_name
      if (called_name in fwds):
        s += " (dependency cycle)"
      print("  %s" % s)
  print()
  if (option.write_graphviz_dot is not None):
    with open(option.write_graphviz_dot, "w") as f:
      print("digraph G {", file=f)
      for lhs_rhs in digraph_lhs_rhs:
        print("  %s -> %s;" % lhs_rhs, file=f)
      print("}", file=f)

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
fable/command_line/split.py
from __future__ import absolute_import, division, print_function
def run(args):
  import fable.read
  out_names_used = set()
  for file_name in args:
    all_fprocs = fable.read.process(
      file_names=[file_name],
      basic_only=True,
      skip_load_includes=True)
    for fproc in all_fprocs.all_in_input_order:
      out_name = fproc.name.value
      i = 2
      while (out_name in out_names_used):
        out_name = "%s_%d" % (fproc.name.value, i)
        i += 1
      out_names_used.add(out_name)
      with open(out_name+".f", "w") as out:
        print(out.name)
        first_line = True
        empty_lines = []
        for ssl in fproc.all_ssl():
          for sl in ssl.source_line_cluster:
            line = sl.text
            if (len(line.strip()) == 0):
              empty_lines.append(line)
            else:
              if (not first_line):
                for prev_line in empty_lines:
                  print(prev_line, file=out)
              print(line, file=out)
              first_line = False
              empty_lines = []

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
fable/cout.py
from __future__ import absolute_import, division, print_function
from six.moves import range
from libtbx.utils import product
from libtbx import group_args
from libtbx import mutable
from libtbx import Auto
import os.path
from six.moves import zip

fmt_comma_placeholder = chr(255)

def break_line_if_necessary(callback, line, max_len=80, min_len=70):
  def cb_finalize(line):
    callback(line.replace(fmt_comma_placeholder, ","))
  nc = len(line)
  if (nc <= max_len):
    cb_finalize(line)
    return
  for i_start in range(nc):
    if (line[i_start] != " "):
      break
  else:
    raise AssertionError
  lsw = line.startswith
  if (lsw("//", i_start)):
    cb_finalize(line)
    return
  potential_break_points = []
  ic = i_start
  while (ic < nc):
    c = line[ic]
    if ("\"'".find(c) >= 0):
      q = c
      ic_q = ic
      ic += 1
      while (ic < nc):
        prev_c = c
        c = line[ic]
        ic += 1
        if (c == q and prev_c != "\\"):
          break
      else:
        raise AssertionError
    elif (c == "("):
      ic += 1
      potential_break_points.append((0, ic))
    elif (lsw(", ", ic)):
      ic += 2
      potential_break_points.append((1, ic))
    elif (   lsw(" = ", ic)
          or lsw("), ", ic)):
      ic += 3
      potential_break_points.append((1, ic))
    elif (   lsw(" + ", ic)
          or lsw(" - ", ic)
          or lsw(" * ", ic)
          or lsw(" / ", ic)):
      ic += 3
      potential_break_points.append((0, ic))
    elif (   lsw(" && ", ic)
          or lsw(" || ", ic)):
      ic += 4
      potential_break_points.append((0, ic))
    elif (lsw("//", ic)):
      break
    else:
      ic += 1
  potential_break_points.append((0, nc))
  n = nc - i_start
  from libtbx.math_utils import iround, iceil
  l = max(min_len, iround(n / iceil(n / (max_len - i_start - 2))))
  b = 0
  f = 0
  def break_more_if_necessary(s):
    while (f+len(s) > max_len and s.startswith('"')):
      i = max_len-2-f
      j = s.rfind(fmt_comma_placeholder, 0, i)
      if (j > 4): # ad-hoc value
        i = j+1
      else:
        for j in range(i-1,-1,-1):
          if (s[j] != "\\"):
            if ((i - j ) % 2 == 0):
              i -= 1
            break
        else:
          raise AssertionError
      cb_finalize(" "*f + s[:i] + '"')
      s = '"' + s[i:]
    cb_finalize(" "*f + s)
  if (lsw("if (", i_start)): indent_width = 4
  else:                      indent_width = 2
  pprio = 0
  pp = 0
  for ip in range(len(potential_break_points)):
    prio,p = potential_break_points[ip]
    def following_point_is_better():
      for jp in range(ip,len(potential_break_points)):
        prio,p = potential_break_points[jp]
        if (prio == 1 and p-b+f <= max_len):
          return True
      return False
    if (    p-b+f > l
        and b != pp
        and (pprio == 1 or not following_point_is_better())):
      s = line[b:pp].rstrip()
      if (f == 0):
        cb_finalize(s)
        f = i_start + indent_width
      else:
        break_more_if_necessary(s=s)
      b = pp
    pprio = prio
    pp = p
  if (b < nc):
    break_more_if_necessary(s=line[b:])

def break_lines(cpp_text, prev_line=None):
  prev_line = [prev_line]
  result = []
  def callback(line):
    if (   prev_line[0] is None
        or line != prev_line[0]
        or not line.lstrip().startswith("//C")):
      result.append(line)
      prev_line[0] = line
  for line in "\n".join(cpp_text).splitlines():
    break_line_if_necessary(callback=callback, line=line)
  return result

class dynamic_parameter_props(object):

  __slots__ = ["name", "ctype", "default"]

  def __init__(O, name, ctype, default):
    O.name = name
    O.ctype = ctype
    O.default = default

def create_buffer_blocks(
      target_number_of_blocks,
      buffers,
      min_lines_per_block=100):
  if (target_number_of_blocks >= len(buffers)):
    return [[buffer] for buffer in buffers]
  numbers_of_lines = [len(lines) for lines in buffers]
  sum_lines = sum(numbers_of_lines)
  lines_per_block = max(
    min_lines_per_block,
    sum_lines / target_number_of_blocks)
  result = []
  block_sum_lines = 0
  j = 0
  for i,n in enumerate(numbers_of_lines):
    if (block_sum_lines + n > lines_per_block):
      if (i == j or block_sum_lines <= min_lines_per_block):
        result.append(buffers[j:i+1])
        block_sum_lines = 0
        j = i+1
      else:
        result.append(buffers[j:i])
        block_sum_lines = n
        j = i
    else:
      block_sum_lines += n
  if (j < len(buffers)):
    result.append(buffers[j:])
  assert sum([len(block) for block in result]) == len(buffers)
  return result

def show_traceback():
  import traceback
  print(traceback.format_exc(limit=None))

def strip_leading_zeros(string):
  for i in range(len(string)):
    if (string[i] != "0"):
      return string[i:]
  if (len(string) == 0):
    return ""
  return "0"

def escape_string_literal(s):
  return (s
    .replace("\\","\\\\")
    .replace('"','\\"')
    .replace("\t", "\\t")
    .replace("??", "\\?\\?"))

def convert_complex_literal(vmap, tok):
  assert len(tok.value) == 4
  cc = []
  for part in tok.value[1:3]:
    c = []
    sign_tok, val_tok = part
    if (sign_tok is not None):
      c.append(sign_tok.value)
    c.append(convert_token(vmap=vmap, leading=None, tok=val_tok))
    cc.append("".join(c))
  return "fem::cmplx(%s)" % ", ".join(cc)

def convert_token(vmap, leading, tok, had_str_concat=None):
  tv = tok.value
  if (tok.is_identifier()):
    return vmap.get(tv, tv)
  if (tok.is_op()):
    if (tv == ".not."):
      return "!"
    if (tv == ".and."):
      return " && "
    if (tv == ".or."):
      return " || "
    if (tv == ".eqv."):
      return " == "
    if (tv == ".neqv."):
      return " != "
    if (tv in ["+", "-"]):
      if (leading):
        return tv
      return " "+tv+" "
    if (tv == "*"):
      if (leading):
        return "star "
      return " "+tv+" "
    if (tv == "/"):
      return " "+tv+" "
    if (tv == "//"):
      if (had_str_concat is None): tok.raise_internal_error()
      had_str_concat.value = True
      return " + "
    if (tv == ":"):
      if (leading):
        return "1, "
      return ", "
    if (tv == ".eq." or tv == "=="):
      return " == "
    if (tv == ".ne." or tv == "/="):
      return " != "
    if (tv == ".lt." or tv == "<"):
      return " < "
    if (tv == ".le." or tv == "<="):
      return " <= "
    if (tv == ".gt." or tv == ">"):
      return " > "
    if (tv == ".ge." or tv == ">="):
      return " >= "
    tok.raise_not_supported()
  if (tok.is_string()):
    s = '"' + escape_string_literal(tok.value) + '"'
    if (had_str_concat is None or not had_str_concat.value):
      return s
    return "str_cref(%s)" % s
  if (tok.is_logical()):
    if (tv == ".false."):
      return "false"
    return "true"
  if (tok.is_integer()):
    return tv
  if (tok.is_hexadecimal()):
    return "0x"+tv
  if (tok.is_real()):
    return tv+"f"
  if (tok.is_double_precision()):
    return tv.replace("d", "e")
  if (tok.is_complex()):
    return convert_complex_literal(vmap=vmap, tok=tok)
  tok.raise_not_supported()

class major_types_cache(object):

  __slots__ = ["identifiers"]

  def __init__(O):
    O.identifiers = None

  def __contains__(O, value):
    if (O.identifiers is None):
      O.identifiers = set()
      import libtbx.load_env
      hpp = libtbx.env.under_dist(
        module_name="fable", path="fem/major_types.hpp", test=os.path.isfile)
      using_fem = "  using fem::"
      with open(hpp) as f:
        lines = f.read().splitlines()
      for line in lines:
        if (line.startswith(using_fem)):
          assert line.endswith(";")
          O.identifiers.add(line[len(using_fem):-1])
    return value in O.identifiers

major_types = major_types_cache()

cpp_keywords = set("""\
and and_eq asm auto bitand bitor bool break case catch char class compl const
const_cast continue default delete do double dynamic_cast else enum explicit
export extern false float for friend goto if inline int long mutable namespace
new not not_eq operator or or_eq private protected public register
reinterpret_cast return short signed sizeof static static_cast struct switch
template this throw true try typedef typeid typename union unsigned using
virtual void volatile wchar_t while xor xor_eq argv argc
""".split())

def prepend_identifier_if_necessary(identifier):
  if (identifier in major_types or identifier in cpp_keywords):
    return "identifier_" + identifier
  return identifier

def produce_comment_given_sl(callback, sl):
  if (sl.stmt_offs is None):
    t = sl.text[1:]
  elif (sl.index_of_exclamation_mark is not None):
    t = sl.stmt[sl.index_of_exclamation_mark+1:]
  else:
    t = None
  if (t is not None):
    callback("//C%s" % t.expandtabs().rstrip())

def produce_comment_given_ssl(callback, ssl):
  if (ssl is None): return
  for sl in ssl.source_line_cluster:
    produce_comment_given_sl(callback=callback, sl=sl)
  return

def produce_comments(callback, ssl_list):
  for ssl in ssl_list:
    produce_comment_given_ssl(callback=callback, ssl=ssl)

def flush_comments_if_non_trivial(callback, buffer):
  for line in buffer:
    if (line != "//C"):
      for line in buffer:
        callback(line)
      return

def produce_leading_comments(callback, fproc):
  buffer = []
  produce_comments(callback=buffer.append, ssl_list=fproc.leading_comments)
  produce_comment_given_ssl(
    callback=buffer.append, ssl=fproc.top_ssl)
  flush_comments_if_non_trivial(callback=callback, buffer=buffer)

def produce_trailing_comments(callback, fproc):
  buffer = []
  produce_comment_given_ssl(callback=buffer.append, ssl=fproc.end_ssl)
  produce_comments(
    callback=buffer.append, ssl_list=fproc.trailing_comments)
  flush_comments_if_non_trivial(callback=callback, buffer=buffer)

class comment_manager(object):

  __slots__ = ["sl_list", "index"]

  def __init__(O, fproc):
    O.sl_list = []
    for ssl in fproc.body_lines:
      if (ssl is not None):
        for sl in ssl.source_line_cluster:
          O.sl_list.append(sl)
    O.sl_list.sort(key=lambda source_line: source_line.global_line_index)
    O.index = 0

  def produce(O, callback):
    produce_comment_given_sl(callback=callback, sl=O.sl_list[O.index])
    O.index += 1

  def insert_before(O, executable_info, callback):
    i = executable_info.ssl.source_line_cluster[-1].global_line_index
    while (O.index != len(O.sl_list)):
      j = O.sl_list[O.index].global_line_index
      if (j > i):
        break
      O.produce(callback=callback)

  def flush_remaining(O, callback):
    while (O.index != len(O.sl_list)):
      O.produce(callback=callback)

class conv_hook_info(object):

  __slots__ = [
    "ignore_common_and_save",
    "needs_sve_dynamic_parameters",
    "variant_common_names",
    "needs_is_called_first_time",
    "needs_variant_bind",
    "data_init_after_variant_bind"]

  def __init__(O):
    O.ignore_common_and_save = False
    O.needs_sve_dynamic_parameters = False
    O.variant_common_names = None
    O.needs_is_called_first_time = None
    O.needs_variant_bind = None
    O.data_init_after_variant_bind = None

class global_conversion_info(object):

  __slots__ = [
    "topological_fprocs",
    "dynamic_parameters",
    "fortran_file_comments",
    "fem_do_safe",
    "arr_nd_size_max",
    "inline_all",
    "fprocs_by_name",
    "converted_commons_info",
    "separate_namespaces",
    "data_values_block_size",
    "data_specializations"]

  def __init__(O,
        topological_fprocs,
        dynamic_parameters,
        fortran_file_comments,
        fem_do_safe,
        arr_nd_size_max,
        inline_all,
        converted_commons_info,
        separate_namespaces,
        data_values_block_size,
        data_specializations):
    O.topological_fprocs = topological_fprocs
    O.dynamic_parameters = dynamic_parameters
    O.fortran_file_comments = fortran_file_comments
    O.fem_do_safe = fem_do_safe
    O.arr_nd_size_max = arr_nd_size_max
    O.inline_all = inline_all
    O.fprocs_by_name = topological_fprocs.all_fprocs.fprocs_by_name()
    O.converted_commons_info = converted_commons_info
    O.separate_namespaces = separate_namespaces
    O.data_values_block_size = data_values_block_size
    O.data_specializations = data_specializations

  def specialized(O, fproc):
    return conversion_info(global_conv_info=O, fproc=fproc)

class conversion_info(global_conversion_info):

  __slots__ = global_conversion_info.__slots__ + [
    "fproc",
    "comment_manager",
    "vmap"]

  def __init__(O,
        global_conv_info=None,
        fproc=None,
        vmap=None):
    val = None
    for slot in global_conversion_info.__slots__:
      if (global_conv_info is not None):
        val = getattr(global_conv_info, slot)
      setattr(O, slot, val)
    O.fproc = fproc
    if (O.fproc is None):
      O.comment_manager = None
    else:
      O.comment_manager = comment_manager(fproc=O.fproc)
    if (vmap is None):
      O.vmap = {}
    else:
      O.vmap = vmap

  def set_vmap_force_local(O, fdecl):
    identifier = fdecl.id_tok.value
    O.vmap[identifier] = prepend_identifier_if_necessary(identifier)

  def set_vmap_for_callable(O, identifier):
    if (O.separate_namespaces is not None):
      ns = O.separate_namespaces.get(identifier)
      if (ns is not None):
        O.vmap[identifier] \
          = ns + "::" + prepend_identifier_if_necessary(identifier)
        return True
    if (identifier in ["getargc", "iargc"]):
      O.vmap[identifier] = "cmn.%s" % identifier
      return True
    from fable import intrinsics
    if (identifier in intrinsics.extra_set_lower):
      O.vmap[identifier] = "fem::" + identifier
      return True
    return False

  def set_vmap_from_fdecl(O, fdecl):
    identifier = fdecl.id_tok.value
    if (fdecl.is_common()):
      O.vmap[identifier] = "cmn." + prepend_identifier_if_necessary(identifier)
    elif (fdecl.is_save()):
      O.vmap[identifier] = "sve." + prepend_identifier_if_necessary(identifier)
    elif (fdecl.is_intrinsic()):
      if (identifier in ["float", "int", "char"]):
        O.vmap[identifier] = "fem::f" + identifier
      elif (identifier == "iargc"):
        O.vmap[identifier] = "cmn.iargc"
      else:
        O.vmap[identifier] = "fem::" + identifier
    elif (not O.set_vmap_for_callable(identifier=fdecl.id_tok.value)):
      O.set_vmap_force_local(fdecl=fdecl)
      return False
    return True

  def vmapped(O, fdecl):
    identifier = fdecl.id_tok.value
    result = O.vmap.get(identifier)
    if (result is None):
      O.set_vmap_from_fdecl(fdecl=fdecl)
      result = O.vmap[identifier]
    return result

  def vmapped_callable(O, identifier):
    result = O.vmap.get(identifier)
    if (result is None):
      if (not O.set_vmap_for_callable(identifier=identifier)):
        O.vmap[identifier] = prepend_identifier_if_necessary(identifier)
      result = O.vmap[identifier]
    return result

def called_fproc_needs_cmn(conv_info, called_name):
  called_names = conv_info.fproc.externals_passed_by_arg_identifier.get(
    called_name)
  if (called_names is None):
    called_names = [called_name]
  for called_name in called_names:
    sub_fproc = conv_info.fprocs_by_name.get(called_name)
    if (    sub_fproc is not None
        and sub_fproc.needs_cmn
        and not sub_fproc.conv_hook.ignore_common_and_save):
      return True
  return False

def cmn_needs_to_be_inserted(conv_info, prev_tok):
  if (    prev_tok is not None
      and prev_tok.is_identifier()
      and conv_info.fprocs_by_name is not None
      and conv_info.fproc is not None):
    fdecl = conv_info.fproc.get_fdecl(id_tok=prev_tok)
    if (fdecl.is_user_defined_callable()):
      if (called_fproc_needs_cmn(
            conv_info=conv_info,
            called_name=prev_tok.value)):
        return True
  return False

def convert_power(conv_info, tokens):
  fun = "fem::pow"
  pow_tok = tokens[1]
  if (pow_tok.is_integer()):
    if (pow_tok.value == "1"):
      fun = ""
      tokens = tokens[:1]
    elif (pow_tok.value in ["2","3","4"]):
      fun = "fem::pow%s" % pow_tok.value
      tokens = tokens[:1]
  return fun + "(" + convert_tokens(
    conv_info=conv_info, tokens=tokens, commas=True) + ")"

def convert_tokens(conv_info, tokens, commas=False, had_str_concat=None):
  result = []
  rapp = result.append
  prev_tok = None
  if (had_str_concat is None):
    had_str_concat = mutable(value=False)
  from fable.tokenization import group_power
  for tok in group_power(tokens=tokens):
    if (tok.is_seq()):
      if (    len(tok.value) == 2
          and tok.value[0].is_op_with(value="*")
          and tok.value[1].is_integer()):
        rapp("star /* %s UNHANDLED */" % tok.value[1].value)
      else:
        rapp(convert_tokens(
          conv_info=conv_info,
          tokens=tok.value,
          commas=False,
          had_str_concat=had_str_concat))
    elif (tok.is_parentheses()):
      if (cmn_needs_to_be_inserted(conv_info=conv_info, prev_tok=prev_tok)):
        if (len(tok.value) != 0) and (len(tok.value[0].value) != 0):
          op = "(cmn, "
        else:
          op = "(cmn"
      else:
        op = "("
      rapp(op + convert_tokens(
        conv_info=conv_info,
        tokens=tok.value,
        commas=True,
        had_str_concat=had_str_concat) + ")")
    elif (tok.is_implied_do()):
      raise AssertionError
    elif (tok.is_power()):
      rapp(convert_power(conv_info=conv_info, tokens=tok.value))
    else:
      rapp(convert_token(
        vmap=conv_info.vmap,
        leading=(len(result)==0),
        tok=tok,
        had_str_concat=had_str_concat))
    prev_tok = tok
  if (commas):
    return ", ".join(result)
  return "".join(result)

def convert_to_int_literal(tokens):
  assert tokens is not None and len(tokens) != 0
  if (len(tokens) != 1 or not tokens[0].is_integer()):
    tokens[0].raise_not_supported()
  return int(strip_leading_zeros(string=tokens[0].value))

def convert_data_type(conv_info, fdecl, crhs):
  if (fdecl.data_type is None):
    assert conv_info.fproc is not None
    fdecl.data_type = conv_info.fproc.implicit.get(fdecl.id_tok.value[0])
    if (fdecl.data_type is None):
      raise fdecl.id_tok.raise_semantic_error(msg="Missing data type")
  if (isinstance(fdecl.data_type, str)):
    data_type_code = fdecl.data_type
  else:
    data_type_code = fdecl.data_type.value
  size_tokens = fdecl.size_tokens
  dim_tokens = fdecl.dim_tokens
  if (data_type_code == "character"):
    if (size_tokens is None):
      csize = "1"
    else:
      csize = convert_tokens(conv_info=conv_info, tokens=size_tokens)
    ctype = "fem::str<%s>" % csize
    if (crhs is None):
      crhs = "fem::char0"
  else:
    def convert_to_ctype_with_size(ctype):
      if (size_tokens is None):
        return ctype
      return "fem::%s_star_%d" % (data_type_code, convert_to_int_literal(
        tokens=size_tokens))
    if (data_type_code == "logical"):
      ctype = convert_to_ctype_with_size(ctype="bool")
    elif (data_type_code == "integer"):
      ctype = convert_to_ctype_with_size(ctype="int")
    elif (data_type_code == "real"):
      ctype = convert_to_ctype_with_size(ctype="float")
    elif (data_type_code == "doubleprecision"):
      if (size_tokens is not None):
        size_tokens[0].raise_syntax_error()
      ctype = "double"
    elif (data_type_code == "byte"):
      if (size_tokens is not None):
        size_tokens[0].raise_syntax_error()
      ctype = "char"
    elif (data_type_code == "complex"):
      if (size_tokens is None):
        ctype = "std::complex<float>"
        if (crhs is None):
          crhs = "fem::float0"
      else:
        sz = convert_to_int_literal(tokens=size_tokens)
        if (sz == 8):
          ctype = "std::complex<float>"
          if (crhs is None):
            crhs = "fem::float0"
        elif (sz == 16):
          ctype = "std::complex<double>"
          if (crhs is None):
            crhs = "fem::double0"
        elif (sz == 32):
          ctype = "std::complex<long double>"
          if (crhs is None):
            crhs = "fem::long_double0"
        else:
          size_tokens[0].raise_not_supported()
    elif (data_type_code == "doublecomplex"):
      if (size_tokens is not None):
        size_tokens[0].raise_not_supported()
      ctype = "std::complex<double>"
      if (crhs is None):
        crhs = "fem::double0"
    else:
      raise RuntimeError(
        "Not implemented: data_type_code = %s" % data_type_code)
  return ctype, crhs

def convert_dims(conv_info, dim_tokens):
  need_origin = False
  for tokens in dim_tokens:
    for tok in tokens.value:
      if (tok.is_op_with(value=":")):
        need_origin = True
        break
  dims = []
  for i_dim,tokens in enumerate(dim_tokens):
    cdim = convert_tokens(conv_info=conv_info, tokens=tokens.value)
    if (cdim == "star "):
      cdim = "star"
    else:
      cdim = cdim.replace(",  * ", ", star") # XXX
    if (need_origin):
      dims.append("dim%d(%s)" % (i_dim+1, cdim))
    else:
      dims.append(cdim)
  if (need_origin):
    result = ".".join(dims)
  else:
    result = "dimension(" + ", ".join(dims) + ")"
  return result

def parenthesize_if_necessary(expr):
  from fable import unsigned_integer_scan, identifier_scan
  if (   unsigned_integer_scan(code=expr) == len(expr)
      or identifier_scan(code=expr) == len(expr)):
    return expr
  return "(" + expr + ")"

def convert_dim_to_static_size(conv_info, tokens):
  def conv(toks):
    return convert_tokens(conv_info=conv_info, tokens=toks)
  for i,tok in enumerate(tokens):
    if (tok.is_op_with(value=":")):
      f = parenthesize_if_necessary(expr=conv(toks=tokens[:i]))
      l = parenthesize_if_necessary(expr=conv(toks=tokens[i+1:]))
      return "%s-%s+1" % (l, f)
  return "%s" % conv(toks=tokens)

def convert_dims_to_static_size(conv_info, dim_tokens):
  terms = []
  for tokens in dim_tokens:
    terms.append(convert_dim_to_static_size(conv_info, tokens=tokens.value))
  if (len(terms) == 1):
    return terms[0]
  return " * ".join([parenthesize_if_necessary(expr=expr) for expr in terms])

def convert_data_type_and_dims(conv_info, fdecl, crhs, force_arr=False):
  ctype, crhs = convert_data_type(conv_info=conv_info, fdecl=fdecl, crhs=crhs)
  dt = fdecl.dim_tokens
  cdims = None
  cfill0 = "fem::fill0"
  if (dt is not None):
    atype = None
    if (    not force_arr
        and conv_info.arr_nd_size_max is not None
        and len(dt) <= 3):
      vals = conv_info.fproc.eval_dimensions_simple(
        dim_tokens=dt, allow_power=False)
      if (vals.count(None) == 0):
        sz = product(vals)
        if (sz <= abs(conv_info.arr_nd_size_max)):
          from fable.read import dimensions_are_simple
          if (dimensions_are_simple(dim_tokens=dt)):
            cdims = Auto
            t = convert_tokens(conv_info=conv_info, tokens=dt, commas=True)
          else:
            t = ", ".join(["%d" % v for v in vals])
          t = "%s, %s" % (t, ctype)
          if (t.endswith(">")): templs = " "
          else:                 templs = ""
          atype = "arr_%dd<%s%s>" % (len(dt), t, templs)
          if (conv_info.arr_nd_size_max < 0):
            cfill0 = "fem::no_fill0"
    if (atype is None):
      if (len(dt) != 1):
        t = "%s, %d" % (ctype, len(dt))
      else:
        t = ctype
      if (t.endswith(">")): templs = " "
      else:                 templs = ""
      atype = "arr<%s%s>" % (t, templs)
    ctype = atype
    if (cdims is None):
      cdims = convert_dims(conv_info=conv_info, dim_tokens=dt)
  return ctype, cdims, crhs, cfill0

def ad_hoc_change_arr_to_arr_ref(ctype, cconst=""):
  return ctype.replace("arr<", "arr_%sref<" % cconst, 1)

def zero_shortcut_if_possible(ctype):
  if (ctype.startswith("fem::")):
    if (ctype.endswith(">")): s = " "
    else:                     s = ""
    return "fem::zero<%s%s>()" % (ctype, s)
  return "fem::%s0" % ctype

def convert_declaration(rapp, conv_info, fdecl, crhs, const):
  ctype, cdims, crhs, cfill0 = convert_data_type_and_dims(
    conv_info=conv_info, fdecl=fdecl, crhs=crhs)
  vname = conv_info.vmapped(fdecl=fdecl)
  if (cdims is None):
    if (crhs is None): crhs = zero_shortcut_if_possible(ctype=ctype)
    def const_qualifier():
      if (const): return "const "
      return ""
    rapp("%s%s %s = %s;" % (const_qualifier(), ctype, vname, crhs))
    return False
  if (cdims is Auto):
    rapp("%s %s(%s);" % (ctype, vname, cfill0))
  else:
    rapp("%s %s(%s, %s);" % (ctype, vname, cdims, cfill0))
  return True

class scope(object):

  __slots__ = [
    "parent",
    "opening_text",
    "auto_close_parent",
    "closing_text",
    "data",
    "insert_point",
    "trailing_statement_label_index",
    "tail"]

  def __init__(O, parent, opening_text=None, auto_close_parent=False):
    O.parent = parent
    O.opening_text = opening_text
    O.auto_close_parent = auto_close_parent
    O.closing_text = None
    O.data = []
    O.insert_point = None
    O.trailing_statement_label_index = None
    O.tail = None

  def current_point(O):
    return len(O.data)

  def point_is_current(O, point):
    return (point == len(O.data))

  def remember_insert_point(O):
    O.insert_point = len(O.data)

  def insert_point_is_current(O):
    return O.point_is_current(point=O.insert_point)

  def top_append(O, obj):
    assert O.insert_point is not None
    O.data.insert(O.insert_point, obj)
    O.insert_point += 1

  def append(O, obj):
    O.data.append(obj)
    O.trailing_statement_label_index = None

  def append_statement_label(O, label):
    O.trailing_statement_label_index = len(O.data)
    O.data.append("statement_%s:" % label)

  def append_comment(O, line):
    O.data.append(line)

  def open_nested_scope(O, opening_text, auto_close_parent=False):
    O.trailing_statement_label_index = None
    return scope(
      parent=O, opening_text=opening_text, auto_close_parent=auto_close_parent)

  def finalize(O):
    if (O.trailing_statement_label_index is not None):
      O.data[O.trailing_statement_label_index] += ";"

  def close_nested_scope(O):
    assert O.opening_text is not None
    assert O.closing_text is None
    assert O.tail is None
    O.finalize()
    O.closing_text = ["}"]
    head = O
    while (head.parent.tail is head):
      head = head.parent
    head.parent.data.append(head)
    if (head.auto_close_parent):
      return head.parent.close_nested_scope()
    return head.parent

  def attach_tail(O, opening_text):
    assert O.opening_text is not None
    assert O.closing_text is None
    assert O.tail is None
    O.finalize()
    O.closing_text = ["}"]
    O.tail = scope(parent=O, opening_text=opening_text)
    return O.tail

  def collect_text(O, callback, indent="  "):
    for obj in O.data:
      if (isinstance(obj, scope)):
        curr = obj
        while (curr is not None):
          for text in curr.opening_text:
            callback(indent+text)
          curr.collect_text(callback=callback, indent=indent+"  ")
          for text in curr.closing_text:
            callback(indent+text)
          curr = curr.tail
      else:
        callback(indent+obj)

def convert_io_statement_with_err(
      conv_info,
      curr_scope,
      io_function,
      io_function_specialization,
      io_call_args,
      iolist):
  if (iolist.err is None):
    io_scope = curr_scope
  else:
    io_scope = curr_scope.open_nested_scope(opening_text=["try {"])
  io_scope.append("cmn.io.%s%s(%s)" % (
    io_function, io_function_specialization, io_call_args))
  for slot in iolist.chain:
    tokens = getattr(iolist, slot)
    if (tokens is not None):
      carg = convert_tokens(conv_info=conv_info, tokens=tokens)
      io_scope.append("  .%s(%s)" % (slot, carg))
  io_scope.data[-1] += ";"
  if (io_scope is not curr_scope):
    io_scope.close_nested_scope()
    catch_scope = curr_scope.open_nested_scope(
      opening_text=["catch (fem::io_err const&) {"])
    clabel = convert_tokens(conv_info=conv_info, tokens=iolist.err)
    catch_scope.append("goto statement_%s;" % clabel)
    catch_scope.close_nested_scope()

def is_simple_do_last(tokens):
  i = 0
  if (len(tokens) == 2 and tokens[0].is_unary_plus_or_minus()):
    i = 1
  if (i+1 == len(tokens)):
    tok = tokens[i]
    return tok.is_identifier() or tok.is_integer()
  return False

def convert_to_fem_do(conv_info, parent_scope, i_tok, fls_tokens):
  assert 2 <= len(fls_tokens) <= 3
  i = convert_token(vmap=conv_info.vmap, leading=True, tok=i_tok)
  f = convert_tokens(conv_info=conv_info, tokens=fls_tokens[0].value)
  l = convert_tokens(conv_info=conv_info, tokens=fls_tokens[1].value)
  if (len(fls_tokens) == 3):
    s = convert_tokens(conv_info=conv_info, tokens=fls_tokens[2].value)
    return parent_scope.open_nested_scope(
      opening_text=["FEM_DOSTEP(%s, %s, %s, %s) {" % (i, f, l, s)])
  if (conv_info.fem_do_safe):
    return parent_scope.open_nested_scope(
      opening_text=["FEM_DO_SAFE(%s, %s, %s) {" % (i, f, l)])
  if (is_simple_do_last(tokens=fls_tokens[1].value)):
    return parent_scope.open_nested_scope(
      opening_text=["FEM_DO(%s, %s, %s) {" % (i, f, l)])
  scope_for_last = parent_scope.open_nested_scope(opening_text=["{"])
  scope_for_last.append("int fem_do_last = %s;" % l)
  return scope_for_last.open_nested_scope(
    opening_text=["FEM_DO(%s, %s, fem_do_last) {" % (i, f)],
    auto_close_parent=True)

def find_implied_dos(result, tokens):
  assert isinstance(tokens, list)
  for i,tok in enumerate(tokens):
    if (tok.is_seq_or_parentheses()):
      find_implied_dos(result=result, tokens=tok.value)
    elif (tok.is_implied_do()):
      result.append(tok)

def convert_io_loop(
      io_scope, io_op, conv_info, tokens, cbuf=None, had_str_concat=None):
  class cbuffer(object):
    __slots__ = ["strings", "leading"]
    def __init__(O):
      O.strings = []
      O.leading = True
    def append(O, string):
      O.strings.append(string)
      O.leading = False
    def append_comma(O):
      if (len(O.strings) != 0 and O.strings[-1] != ", "):
        O.strings.append(", ")
      O.leading = True
    def remove_trailing_comma(O):
      if (len(O.strings) != 0):
        assert O.strings[-1] == ", "
        O.strings.pop()
        assert O.leading
        O.leading = False
    def append_opening_parenthesis(O):
      O.strings.append("(")
      O.leading = True
    def append_closing_parenthesis(O):
      assert len(O.strings) != 0
      if (O.strings[-1] == ", "):
        O.remove_trailing_comma()
      O.strings.append(")")
    def flush(O):
      O.remove_trailing_comma()
      if (len(O.strings) != 0):
        io_scope.append("%s, %s;" % (io_op, "".join(O.strings)))
        O.strings = []
  if (cbuf is None):
    cbuf = cbuffer()
    owning_cbuf = True
  else:
    owning_cbuf = False
  prev_tok = None
  if (had_str_concat is None):
    had_str_concat = mutable(value=False)
  from fable.tokenization import group_power
  for tok in group_power(tokens=tokens):
    if (tok.is_seq()):
      convert_io_loop(
        io_scope,
        io_op,
        conv_info,
        tokens=tok.value,
        cbuf=cbuf,
        had_str_concat=had_str_concat)
      cbuf.append_comma()
    elif (tok.is_parentheses()):
      cbuf.append_opening_parenthesis()
      if (cmn_needs_to_be_inserted(conv_info=conv_info, prev_tok=prev_tok)):
        cbuf.append("cmn")
        if (len(tok.value) != 0):
          cbuf.append_comma()
      convert_io_loop(
        io_scope,
        io_op,
        conv_info,
        tokens=tok.value,
        cbuf=cbuf,
        had_str_concat=had_str_concat)
      cbuf.append_closing_parenthesis()
    elif (tok.is_implied_do()):
      cbuf.flush()
      from fable.tokenization import implied_do_info
      idi = implied_do_info(tokens=tok.value)
      do_scope = convert_to_fem_do(
        conv_info=conv_info,
        parent_scope=io_scope,
        i_tok=idi.id_tok,
        fls_tokens=idi.fls_tokens)
      convert_io_loop(
        io_scope=do_scope,
        io_op=io_op,
        conv_info=conv_info,
        tokens=tok.value[:idi.dlist_size],
        had_str_concat=had_str_concat)
      do_scope.close_nested_scope()
      return
    elif (tok.is_power()):
      cbuf.append(convert_power(conv_info=conv_info, tokens=tok.value))
    else:
      cbuf.append(convert_token(
        vmap=conv_info.vmap,
        leading=cbuf.leading,
        tok=tok,
        had_str_concat=had_str_concat))
    prev_tok = tok
  if (owning_cbuf):
    cbuf.flush()

def equivalence_align_with_arg(conv_info, top_scope, identifier, tok_seq):
  assert tok_seq.is_seq()
  tokens = tok_seq.value
  assert len(tokens) > 0
  if (len(tokens) == 1):
    return ""
  cindices = []
  for i in range(1,len(tokens)):
    tok = tokens[i]
    if (i == 3 or not tok.is_parentheses()):
      tok.raise_semantic_error()
    declare_identifiers_parameter_recursion(
      conv_info=conv_info,
      top_scope=top_scope,
      curr_scope=top_scope,
      tokens=tokens[i].value)
    cindices.append(convert_tokens(
      conv_info=conv_info, tokens=tokens[i].value, commas=True))
  fdecl = conv_info.fproc.fdecl_by_identifier[identifier]
  if (len(cindices) == 1):
    if (fdecl.dim_tokens is not None):
      return "arr_index(%s)" % cindices[0]
    if (fdecl.data_type.value != "character"):
      tok_seq.raise_semantic_error()
    return "str_index(%s)" % cindices[0]
  if (   len(cindices) != 2
      or fdecl.data_type.value != "character"
      or fdecl.dim_tokens is None):
    tok_seq.raise_semantic_error()
  return "arr_index(%s)(%s)" % tuple(cindices)

def cconst(fdecl, short):
  if (fdecl.is_modified): return ""
  if (short): return "c"
  return " const"

def convert_to_mbr_bind(
      conv_info,
      top_scope,
      variant_bind_chain,
      mbr_buffer,
      bind_buffer,
      identifier):
  fdecl = conv_info.fproc.fdecl_by_identifier[identifier]
  ctype = convert_data_type(conv_info=conv_info, fdecl=fdecl, crhs=None)[0]
  if (fdecl.dim_tokens is None):
    cdims_parens = ""
  else:
    declare_identifiers_parameter_recursion(
      conv_info=conv_info,
      top_scope=top_scope,
      curr_scope=top_scope,
      tokens=fdecl.dim_tokens)
    cdims = convert_dims(conv_info=conv_info, dim_tokens=fdecl.dim_tokens)
    cdims_parens = "(" + cdims + ")"
  identifier = fdecl.id_tok.value
  ctype_targ = ctype
  if (ctype_targ.endswith(">")):
    ctype_targ += " "
  mbr_buffer.append("mbr<%s> %s%s;" % (ctype_targ, identifier, cdims_parens))
  conv_info.set_vmap_force_local(fdecl=fdecl)
  vname = conv_info.vmapped(fdecl=fdecl)
  if (fdecl.use_count == 0):
    pr = "/* "
    eq = "*/"
    clm = " */ "
    prm = " /* "
  else:
    pr = ""
    eq = "="
    clm = ""
    prm = ""
  if (fdecl.dim_tokens is None):
    if (fdecl.data_type.value == "character"):
      binding = "%sstr_%sref %s %s %s.bind_str();" % (
        pr, cconst(fdecl=fdecl, short=True), vname, eq, variant_bind_chain)
    else:
      binding = "%s%s%s& %s %s %s.bind<%s>();" % (
        pr, ctype, cconst(fdecl=fdecl, short=False), vname,
        eq, variant_bind_chain, ctype_targ)
  else:
    if (fdecl.data_type.value == "character"):
      ref_dim = "%d" % len(fdecl.dim_tokens)
      if (ref_dim == "1"): ref_dim = ""
      binding = "%sstr_arr_%sref<%s> %s(%s%s.bind_str()%s, %s)%s;" % (
        pr, cconst(fdecl=fdecl, short=True), ref_dim, vname,
        clm, variant_bind_chain, prm, cdims, clm)
    else:
      ref_dim = ", %d" % len(fdecl.dim_tokens)
      if (ref_dim == ", 1"): ref_dim = ""
      binding = "%sarr_%sref<%s%s> %s(%s%s.bind<%s>()%s, %s)%s;" % (
        pr, cconst(fdecl=fdecl, short=True), ctype, ref_dim, vname,
        clm, variant_bind_chain, ctype, prm, cdims, clm)
  bind_buffer.append(binding)

def assemble_allocate_line_lists(
      conv_info,
      top_scope,
      variant_bind_chain,
      mbr_buffer,
      bind_buffer,
      allocate_line_lists,
      equiv_tok_cluster,
      identifier):
  if (allocate_line_lists[-1] == [" "]):
    allocate_line_lists.pop()
  i_mbr_by_identifer = {identifier: 0}
  eq_identifiers = [identifier]
  i_block = len(allocate_line_lists)
  allocate_line_lists.append(None)
  for equiv_tok in equiv_tok_cluster:
    align_with = ".align"
    for tok_seq in equiv_tok.value:
      eq_identifier = tok_seq.value[0].value
      i_mbr = i_mbr_by_identifer.get(eq_identifier)
      if (i_mbr is None):
        i_mbr_by_identifer[eq_identifier] = i_mbr = len(eq_identifiers)
        eq_identifiers.append(eq_identifier)
        if (bind_buffer is not None):
          convert_to_mbr_bind(
            conv_info=conv_info,
            top_scope=top_scope,
            variant_bind_chain=variant_bind_chain,
            mbr_buffer=mbr_buffer,
            bind_buffer=bind_buffer,
            identifier=eq_identifier)
      allocate_line_lists.append([
        "    %s<%d>(%s)" % (
          align_with,
          i_mbr+1,
          equivalence_align_with_arg(
            conv_info=conv_info,
            top_scope=top_scope,
            identifier=eq_identifier,
            tok_seq=tok_seq))])
      align_with = " .with"
  allocate_line_lists[i_block] = \
    ["  equivalence(%s)" % (", ".join(eq_identifiers))]
  allocate_line_lists[-1][-1] += ","
  allocate_line_lists.append([" "])

def add_allocate_lines_to_mbr_scope(allocate_line_lists, mbr_buffer):
  if (allocate_line_lists[-1] == [" "]):
    allocate_line_lists.pop()
  if (allocate_line_lists[-1][-1][-1] == ","):
    allocate_line_lists[-1][-1] = allocate_line_lists[-1][-1][:-1]
  if (len(allocate_line_lists) == 1):
    allocate_line_lists[-1][-1] += ";"
  else:
    allocate_line_lists.append([";"])
  for line_list in allocate_line_lists:
    mbr_buffer.append(" ".join(line_list))

def convert_variant_allocate_and_bindings(conv_info, top_scope):
  result_buffers = group_args(
    first_time=[],
    loc_equivalences=[],
    bindings=[])
  equiv_info = conv_info.fproc.equivalence_info()
  equiv_tok_clusters = equiv_info.equiv_tok_clusters
  for common_name,common_fdecl_list in conv_info.fproc.common.items():
    vcn = conv_info.fproc.conv_hook.variant_common_names
    if (vcn is None or common_name not in vcn):
      continue
    top_scope.append(
      "common_variant %s(cmn.common_%s, sve.%s_bindings);" % (
        (common_name,)*3))
    mbr_buffer = []
    result_buffers.first_time.append(mbr_buffer)
    allocate_line_lists = [["%s.allocate()," % common_name]]
    for fdecl in common_fdecl_list:
      identifier = fdecl.id_tok.value
      convert_to_mbr_bind(
        conv_info=conv_info,
        top_scope=top_scope,
        variant_bind_chain=common_name,
        mbr_buffer=mbr_buffer,
        bind_buffer=result_buffers.bindings,
        identifier=identifier)
      equiv_tok_cluster = equiv_info.equiv_tok_cluster_by_identifier.get(
        identifier)
      if (equiv_tok_cluster is None):
        allocate_line_lists[-1].append(identifier+",")
      else:
        assemble_allocate_line_lists(
          conv_info=conv_info,
          top_scope=top_scope,
          variant_bind_chain=common_name,
          mbr_buffer=mbr_buffer,
          bind_buffer=result_buffers.bindings,
          allocate_line_lists=allocate_line_lists,
          equiv_tok_cluster=equiv_tok_cluster,
          identifier=identifier)
    add_allocate_lines_to_mbr_scope(
      allocate_line_lists=allocate_line_lists, mbr_buffer=mbr_buffer)
  #
  cei = conv_info.fproc.classified_equivalence_info()
  if (len(cei.save.equiv_tok_clusters) != 0):
    top_scope.append(
      "save_equivalences sve_equivalences(sve.save_equivalences);")
    mbr_buffer = []
    result_buffers.first_time.append(mbr_buffer)
    mbr_defined_already = set()
    for equiv_tok_cluster in cei.save.equiv_tok_clusters:
      for equiv_tok in equiv_tok_cluster:
        for tok_seq in equiv_tok.value:
          identifier = tok_seq.value[0].value
          if (identifier in mbr_defined_already):
            continue
          mbr_defined_already.add(identifier)
          convert_to_mbr_bind(
            conv_info=conv_info,
            top_scope=top_scope,
            variant_bind_chain="sve_equivalences",
            mbr_buffer=mbr_buffer,
            bind_buffer=result_buffers.bindings,
            identifier=identifier)
    allocate_line_lists = [["sve_equivalences.allocate(),"]]
    for equiv_tok_cluster in cei.save.equiv_tok_clusters:
      assemble_allocate_line_lists(
        conv_info=conv_info,
        top_scope=top_scope,
        variant_bind_chain=None,
        mbr_buffer=mbr_buffer,
        bind_buffer=None,
        allocate_line_lists=allocate_line_lists,
        equiv_tok_cluster=equiv_tok_cluster,
        identifier=equiv_tok_cluster[0].value[0].value[0].value)
    add_allocate_lines_to_mbr_scope(
        allocate_line_lists=allocate_line_lists, mbr_buffer=mbr_buffer)
  #
  if (len(cei.local.equiv_tok_clusters) != 0):
    mbr_defined_already = set()
    for equiv_tok_cluster in cei.local.equiv_tok_clusters:
      for equiv_tok in equiv_tok_cluster:
        for tok_seq in equiv_tok.value:
          identifier = tok_seq.value[0].value
          if (identifier in mbr_defined_already):
            continue
          mbr_defined_already.add(identifier)
          convert_to_mbr_bind(
            conv_info=conv_info,
            top_scope=top_scope,
            variant_bind_chain="loc_equivalences",
            mbr_buffer=result_buffers.loc_equivalences,
            bind_buffer=result_buffers.bindings,
            identifier=identifier)
    allocate_line_lists = [["loc_equivalences.allocate(),"]]
    for equiv_tok_cluster in cei.local.equiv_tok_clusters:
      assemble_allocate_line_lists(
        conv_info=conv_info,
        top_scope=top_scope,
        variant_bind_chain=None,
        mbr_buffer=result_buffers.loc_equivalences,
        bind_buffer=None,
        allocate_line_lists=allocate_line_lists,
        equiv_tok_cluster=equiv_tok_cluster,
        identifier=equiv_tok_cluster[0].value[0].value[0].value)
    add_allocate_lines_to_mbr_scope(
      allocate_line_lists=allocate_line_lists,
      mbr_buffer=result_buffers.loc_equivalences)
  #
  return result_buffers

def convert_data(conv_info, data_init_scope):
  for nlist,clist in conv_info.fproc.data:
    ccs = []
    have_repetitions = False
    tok_types = set()
    for repetition_tok,ctoks in clist:
      i = 0
      if (ctoks[0].is_unary_plus_or_minus() and len(ctoks) > 1):
        i = 1
      tok_types.add(ctoks[i].type())
      cc = convert_tokens(conv_info=conv_info, tokens=ctoks)
      if (repetition_tok is not None):
        have_repetitions = True
        cr = convert_tokens(conv_info=conv_info, tokens=[repetition_tok])
        cc = "%s*datum(%s)" % (cr, cc)
      ccs.append(cc)
    homogeneous_ctype = None
    if (    conv_info.data_specializations
        and not have_repetitions
        and len(tok_types) == 1):
      homogeneous_ctype = {
        "integer": "int",
        "hexadecimal": "int",
        "real": "float",
        "double_precision": "double",
        "logical": "bool",
        "string": "char*",
        "complex": None # TODO
      }.get(list(tok_types)[0])
    def data_values_blocked():
      data_scope.append("fem::data_values data;")
      for i_block in range(0, len(ccs), conv_info.data_values_block_size):
        data_scope.append(
          "data.values, %s;"
            % ", ".join(ccs[i_block:i_block+conv_info.data_values_block_size]))
    def values_for_data_of_type():
      data_scope.append("static const %s values[] = {" % homogeneous_ctype)
      data_scope.append("  %s" % ", ".join(ccs))
      data_scope.append("};")
      if (homogeneous_ctype == "char*"): s = "_str"
      else:                              s = "<%s>" % homogeneous_ctype
      return s
    def have_no_array_targets():
      for tok_seq in nlist:
        if (len(tok_seq.value) == 1):
          fdecl = conv_info.fproc.get_fdecl(id_tok=tok_seq.value[0])
          if (fdecl.dim_tokens is not None):
            return False
      return True
    implied_dos = []
    find_implied_dos(result=implied_dos, tokens=nlist)
    if (len(implied_dos) == 0):
      if (    conv_info.data_specializations
          and len(nlist) == len(ccs)
          and have_no_array_targets()):
        for tok_seq,cc in zip(nlist, ccs):
          cn = convert_tokens(conv_info=conv_info, tokens=tok_seq.value)
          data_init_scope.append("%s = %s;" % (cn, cc))
      else:
        cn = convert_tokens(conv_info=conv_info, tokens=nlist, commas=True)
        if (homogeneous_ctype is None):
          if (len(ccs) <= conv_info.data_values_block_size):
            data_init_scope.append(
              "fem::data((values, %s)), %s;" % (", ".join(ccs), cn))
          else:
            data_scope = data_init_scope.open_nested_scope(opening_text=["{"])
            data_values_blocked()
            data_scope.append("data, %s;" % cn)
            data_scope.close_nested_scope()
        elif (len(ccs) != 1):
          if (    len(conv_info.fproc.data) == 1
              and len(conv_info.fproc.conv_hook.variant_common_names) == 0):
            data_scope = data_init_scope
          else:
            data_scope = data_init_scope.open_nested_scope(opening_text=["{"])
          s = values_for_data_of_type()
          data_scope.append("fem::data_of_type%s(FEM_VALUES_AND_SIZE)," % s)
          data_scope.append("  %s;" % cn)
          if (data_scope is not data_init_scope):
            data_scope.close_nested_scope()
        else:
          data_init_scope.append("%s = %s;" % (cn, ccs[0]))
    else:
      if (    len(conv_info.fproc.data) == 1
          and len(conv_info.fproc.conv_hook.variant_common_names) == 0
          and len(ccs) <= conv_info.data_values_block_size):
        data_scope = data_init_scope
      else:
        data_scope = data_init_scope.open_nested_scope(opening_text=["{"])
      if (homogeneous_ctype is None):
        if (len(ccs) <= conv_info.data_values_block_size):
          data_scope.append(
            "fem::data_values data((values, %s));" % ", ".join(ccs))
        else:
          data_values_blocked()
      else:
        s = values_for_data_of_type()
        data_scope.append("fem::data_of_type%s data(FEM_VALUES_AND_SIZE);" % s)
      convert_io_loop(
        io_scope=data_scope,
        io_op="data",
        conv_info=conv_info,
        tokens=nlist)
      if (data_scope is not data_init_scope):
        data_scope.close_nested_scope()

def declare_identifiers_parameter_recursion(
      conv_info, top_scope, curr_scope, tokens):
  from fable.tokenization import extract_identifiers
  for id_tok in extract_identifiers(tokens=tokens):
    if (id_tok.value in conv_info.vmap):
      continue
    conv_info.vmap[id_tok.value] = None
    fdecl = conv_info.fproc.get_fdecl(id_tok=id_tok)
    declare_identifiers_parameter_recursion(
      conv_info=conv_info, top_scope=top_scope, curr_scope=curr_scope,
      tokens=fdecl.required_parameter_assignment_tokens())
    declare_identifier(
      conv_info=conv_info,
      top_scope=top_scope,
      curr_scope=curr_scope,
      id_tok=id_tok)

def declare_size_dim_identifiers(conv_info, top_scope, curr_scope, fdecl):
  for sd_tokens in [fdecl.size_tokens, fdecl.dim_tokens]:
    if (sd_tokens is None):
      continue
    from fable.tokenization import extract_identifiers
    sd_id_tokens = extract_identifiers(tokens=sd_tokens)
    for sd_id_tok in sd_id_tokens:
      if (sd_id_tok.value == fdecl.id_tok.value):
        sd_id_tok.raise_semantic_error(msg="Recursion in declaration")
      if (sd_id_tok.value in conv_info.vmap):
        continue
      sd_fdecl = conv_info.fproc.get_fdecl(id_tok=sd_id_tok)
      if (sd_fdecl.parameter_assignment_tokens is None):
        sd_crhs = None
      else:
        declare_identifiers_parameter_recursion(
          conv_info=conv_info, top_scope=top_scope, curr_scope=curr_scope,
          tokens=sd_fdecl.parameter_assignment_tokens)
        if (sd_id_tok.value in conv_info.fproc.dynamic_parameters):
          sd_crhs = "cmn.dynamic_params." + sd_id_tok.value
        else:
          sd_crhs = convert_tokens(
            conv_info=conv_info, tokens=sd_fdecl.parameter_assignment_tokens)
      if (not conv_info.set_vmap_from_fdecl(fdecl=sd_fdecl)):
        have_goto = (len(conv_info.fproc.target_statement_labels()) != 0)
        if (have_goto):
          rapp = top_scope.top_append
        else:
          rapp = top_scope.append
        convert_declaration(
          rapp=rapp,
          conv_info=conv_info,
          fdecl=sd_fdecl,
          crhs=sd_crhs,
          const=True)

def simple_equivalence(
      conv_info,
      top_scope,
      curr_scope,
      target_fdecl,
      equiv_tok_cluster):
  assert len(equiv_tok_cluster) != 0
  for equiv_tok in equiv_tok_cluster:
    target_tok_seq = None
    source_tok_seq = None
    source_fdecl = None
    for tok_seq in equiv_tok.value:
      identifier = tok_seq.value[0].value
      if (identifier == target_fdecl.id_tok.value):
        assert target_tok_seq is None
        target_tok_seq = tok_seq
      else:
        fdecl = conv_info.fproc.get_fdecl(id_tok=tok_seq.value[0])
        if (fdecl is not None and fdecl.is_common()):
          assert source_tok_seq is None
          source_tok_seq = tok_seq
          source_fdecl = fdecl
    if (    target_tok_seq is not None
        and source_tok_seq is not None):
      break
  else:
    raise AssertionError
  conv_info.set_vmap_force_local(fdecl=target_fdecl)
  if (conv_info.vmap.get(source_fdecl.id_tok.value) is None):
    declare_identifier(
      conv_info=conv_info,
      top_scope=top_scope,
      curr_scope=curr_scope,
      id_tok=source_fdecl.id_tok)
  crhs = convert_tokens(conv_info=conv_info, tokens=[source_tok_seq])
  se = "// SIMPLE EQUIVALENCE"
  if (target_fdecl.data_type.value == "character"):
    clen = convert_tokens(
      conv_info=conv_info, tokens=target_fdecl.size_tokens)
    if (target_fdecl.dim_tokens is None):
      return "str_%sref %s(%s, %s); %s" % (
        cconst(fdecl=target_fdecl, short=True),
        target_fdecl.id_tok.value, crhs, clen, se)
    cdims = convert_dims(
      conv_info=conv_info, dim_tokens=target_fdecl.dim_tokens)
    return "str_arr_%sref<%d> %s(%s, %s, %s); %s" % (
      cconst(fdecl=target_fdecl, short=True),
      len(target_fdecl.dim_tokens),
      target_fdecl.id_tok.value, crhs, clen, cdims, se)
  ctype, cdims = convert_data_type_and_dims(
    conv_info=conv_info, fdecl=target_fdecl, crhs=None, force_arr=True)[:2]
  if (cdims is None):
    return "%s%s& %s = %s; %s" % (
      ctype, cconst(fdecl=target_fdecl, short=False),
      target_fdecl.id_tok.value, crhs, se)
  return "%s %s(%s, %s); %s" % (
    ad_hoc_change_arr_to_arr_ref(
      ctype=ctype, cconst=cconst(fdecl=target_fdecl, short=True)),
    target_fdecl.id_tok.value, crhs, cdims, se)

def declare_identifier(conv_info, top_scope, curr_scope, id_tok, crhs=None):
  fdecl = conv_info.fproc.get_fdecl(id_tok=id_tok)
  conv_info.set_vmap_from_fdecl(fdecl=fdecl)
  have_goto = (len(conv_info.fproc.target_statement_labels()) != 0)
  def get_rapp():
    if (have_goto):
      return top_scope.top_append
    return top_scope.append
  if (not fdecl.is_common()):
    equiv_tok_cluster = conv_info.fproc.equivalence_info() \
      .equiv_tok_cluster_by_identifier.get(id_tok.value)
    if (equiv_tok_cluster is not None):
      rapp = get_rapp()
      rapp(simple_equivalence(
        conv_info=conv_info,
        top_scope=top_scope,
        curr_scope=curr_scope,
        target_fdecl=fdecl,
        equiv_tok_cluster=equiv_tok_cluster))
      return crhs is not None
  if (fdecl is not None
        and (   fdecl.is_local()
             or fdecl.is_parameter())):
    const = False
    have_crhs = (crhs is not None)
    if (have_goto or curr_scope != top_scope):
      crhs = None
    if (crhs is None):
      if (fdecl.parameter_assignment_tokens is not None):
        declare_identifiers_parameter_recursion(
          conv_info=conv_info, top_scope=top_scope, curr_scope=curr_scope,
          tokens=fdecl.parameter_assignment_tokens)
        if (id_tok.value in conv_info.fproc.dynamic_parameters):
          crhs = "cmn.dynamic_params." + prepend_identifier_if_necessary(
            id_tok.value)
        else:
          crhs = convert_tokens(
            conv_info=conv_info, tokens=fdecl.parameter_assignment_tokens)
        const = True
    elif (fdecl.parameter_assignment_tokens is not None):
      id_tok.raise_semantic_error(
        msg="Assignment to PARAMETER %s" % id_tok.value)
    rapp = get_rapp()
    declare_size_dim_identifiers(
      conv_info=conv_info, top_scope=top_scope, curr_scope=curr_scope,
      fdecl=fdecl)
    result = convert_declaration(
      rapp=rapp,
      conv_info=conv_info,
      fdecl=fdecl,
      crhs=crhs,
      const=const)
    if (have_crhs and (have_goto or curr_scope != top_scope)):
      result = True
    return result
  identifier = id_tok.value
  def get_common_name_if_cast_is_needed():
    if (not fdecl.is_common()): return None
    if (conv_info.converted_commons_info is None): return None
    common_names = conv_info.converted_commons_info.member_registry.get(
      identifier)
    if (common_names is None): return None
    if (len(common_names) < 2): return None
    return conv_info.fproc.common_name_by_identifier().get(identifier)
  common_name = get_common_name_if_cast_is_needed()
  if (common_name is not None):
    src_var = "static_cast<common_%s&>(cmn).%s" % (
      common_name, prepend_identifier_if_necessary(identifier))
  else:
    src_var = conv_info.vmap[identifier]
  if (fdecl.dim_tokens is not None):
    conv_info.vmap[identifier] = prepend_identifier_if_necessary(identifier)
    if (fdecl.data_type.value == "character"):
      ctype = "str_arr_%sref<%d>" % (
        cconst(fdecl=fdecl, short=True), len(fdecl.dim_tokens))
    else:
      ctype = convert_data_type_and_dims(
        conv_info=conv_info, fdecl=fdecl, crhs=None, force_arr=True)[0]
      ctype = ad_hoc_change_arr_to_arr_ref(
        ctype=ctype, cconst=cconst(fdecl=fdecl, short=True))
    declare_size_dim_identifiers(
      conv_info=conv_info,
      top_scope=top_scope,
      curr_scope=top_scope,
      fdecl=fdecl)
    cdims = convert_dims(conv_info=conv_info, dim_tokens=fdecl.dim_tokens)
    if (common_name is not None):
      src_var = "static_cast<common_%s&>(cmn).%s" % (
        common_name, prepend_identifier_if_necessary(identifier))
    rapp = get_rapp()
    rapp("%s %s(%s, %s);" % (
      ctype, prepend_identifier_if_necessary(identifier), src_var, cdims))
  elif (   common_name is not None
        or (fdecl.use_count > 1 and (fdecl.is_common() or fdecl.is_save()))):
    conv_info.vmap[identifier] = prepend_identifier_if_necessary(identifier)
    ctype = convert_data_type(conv_info=conv_info, fdecl=fdecl, crhs=None)[0]
    rapp = get_rapp()
    rapp("%s& %s = %s;" % (
      ctype, prepend_identifier_if_necessary(identifier), src_var))
  if (crhs is not None):
    return True
  return False

def convert_executable(
      callback, conv_info, args_fdecl_with_dim=None, blockdata=None):
  top_scope = scope(parent=None)
  if (conv_info.fproc.uses_save):
    macro = "FEM_CMN_SVE"
    if (conv_info.fproc.conv_hook.needs_sve_dynamic_parameters):
      macro += "_DYNAMIC_PARAMETERS"
    top_scope.append("%s(%s);" % (macro, conv_info.fproc.name.value))
  top_scope.remember_insert_point()
  curr_scope = top_scope
  if (args_fdecl_with_dim is not None):
    for fdecl in args_fdecl_with_dim:
      declare_size_dim_identifiers(
        conv_info=conv_info,
        top_scope=top_scope,
        curr_scope=top_scope,
        fdecl=fdecl)
      cdims = convert_dims(conv_info=conv_info, dim_tokens=fdecl.dim_tokens)
      top_scope.append("%s(%s);" % (fdecl.id_tok.value, cdims))
  if (blockdata is not None):
    for fproc in blockdata:
      callback("  %s(cmn);" % fproc.name.value)
  if (conv_info.fproc.uses_read):
    top_scope.append("common_read read(cmn);")
  if (conv_info.fproc.uses_write):
    top_scope.append("common_write write(cmn);")
  top_scope_point_before_common = top_scope.current_point()
  for common_name,fdecl_list in conv_info.fproc.common.items():
    if (common_name in conv_info.fproc.conv_hook.variant_common_names):
      continue
    top_scope.remember_insert_point()
    for common_fdecl in fdecl_list:
      fdecl = conv_info.fproc.fdecl_by_identifier.get(
        common_fdecl.id_tok.value)
      if (    fdecl.use_count != 0
          and fdecl.id_tok.value not in conv_info.vmap):
        declare_identifier(
          conv_info=conv_info,
          top_scope=top_scope,
          curr_scope=top_scope,
          id_tok=fdecl.id_tok)
    if (not top_scope.insert_point_is_current()):
      top_scope.top_append("// COMMON %s" % common_name)
  if (not top_scope.point_is_current(point=top_scope_point_before_common)):
    top_scope.append("//")
  top_scope.remember_insert_point()
  def declare_identifiers(id_tokens):
    for id_tok in id_tokens:
      if (id_tok.value not in conv_info.vmap):
        declare_identifier(
          conv_info=conv_info,
          top_scope=top_scope,
          curr_scope=curr_scope,
          id_tok=id_tok)
  from fable.tokenization import extract_identifiers
  variant_buffers = convert_variant_allocate_and_bindings(
    conv_info=conv_info, top_scope=top_scope)
  top_scope.remember_insert_point()
  cei = conv_info.fproc.classified_equivalence_info()
  sve_equivalences = cei.save.equiv_tok_cluster_by_identifier
  for identifier in sorted(conv_info.fproc.fdecl_by_identifier.keys()):
    fdecl = conv_info.fproc.fdecl_by_identifier[identifier]
    if (    fdecl.is_save()
        and fdecl.use_count > 1
        and not identifier in sve_equivalences
        and not identifier in conv_info.vmap):
      declare_identifier(
        conv_info=conv_info,
        top_scope=top_scope,
        curr_scope=top_scope,
        id_tok=fdecl.id_tok)
  if (not top_scope.insert_point_is_current()):
    top_scope.top_append("// SAVE")
    top_scope.append("//")
  if (conv_info.fproc.conv_hook.needs_is_called_first_time):
    first_time_scope = top_scope.open_nested_scope(
      opening_text=["if (is_called_first_time) {"])
    if (len(variant_buffers.first_time) != 0):
      first_time_scope.append(
        "using fem::mbr; // member of variant common or equivalence")
      for mbr_buffer in variant_buffers.first_time:
        mbr_scope = first_time_scope.open_nested_scope(opening_text=["{"])
        for line in mbr_buffer:
          mbr_scope.append(line)
        mbr_scope.close_nested_scope()
    for nlist,clist in conv_info.fproc.data:
      declare_identifiers(
        id_tokens=extract_identifiers(tokens=nlist))
      for repetition_tok,ctoks in clist:
        if (repetition_tok is not None):
          declare_identifiers(
            id_tokens=extract_identifiers(tokens=[repetition_tok]))
        declare_identifiers(
          id_tokens=extract_identifiers(tokens=ctoks))
    if (not conv_info.fproc.conv_hook.data_init_after_variant_bind):
      convert_data(conv_info=conv_info, data_init_scope=first_time_scope)
    first_time_scope.close_nested_scope()
    top_scope.remember_insert_point()
  if (len(variant_buffers.loc_equivalences) != 0):
    top_scope.append("local_equivalences loc_equivalences;")
    mbr_scope = top_scope.open_nested_scope(opening_text=["{"])
    mbr_scope.append("using fem::mbr; // member")
    for line in variant_buffers.loc_equivalences:
      mbr_scope.append(line)
    mbr_scope.close_nested_scope()
  for line in variant_buffers.bindings:
    top_scope.append(line)
  top_scope.remember_insert_point()
  if (conv_info.fproc.conv_hook.data_init_after_variant_bind):
    data_init_scope = top_scope.open_nested_scope(
      opening_text=["if (is_called_first_time) {"])
    convert_data(conv_info=conv_info, data_init_scope=data_init_scope)
    data_init_scope.close_nested_scope()
  top_scope.remember_insert_point()
  from fable.tokenization import fmt_tokens_as_string
  def get_cfmt_from_format(stmt_label):
    fmt_tokens = conv_info.fproc.format.get(stmt_label)
    if (fmt_tokens is None):
      tok.raise_semantic_error(
        "Unknown FORMAT statement label: %s" % tok.value)
    return '"(' + escape_string_literal(fmt_tokens_as_string(
      tokens=fmt_tokens, comma=fmt_comma_placeholder)) + ')"'
  fmt_counts_by_statement_label = \
    conv_info.fproc.fmt_counts_by_statement_label()
  for stmt_label in sorted(fmt_counts_by_statement_label.keys()):
    if (fmt_counts_by_statement_label[stmt_label] > 1):
      cfmt = get_cfmt_from_format(stmt_label=stmt_label)
      top_scope.append(
        "static const char* format_%s = %s;" % (stmt_label, cfmt))
  def curr_scope_append_return_function():
    curr_scope.append(
      "return %s;" % conv_info.vmap[conv_info.fproc.name.value])
  close_scope_after_next_executable = False
  dos_to_close_by_label = {}
  from fable.read import Error
  from fable import SemanticError
  for ei in conv_info.fproc.executable:
    conv_info.comment_manager.insert_before(
      executable_info=ei, callback=curr_scope.append_comment)
    lbl = ei.ssl.label
    if (    lbl is not None
        and lbl in conv_info.fproc.target_statement_labels()
        and not close_scope_after_next_executable):
      curr_scope.append_statement_label(label=lbl)
    def search_for_id_tokens_and_declare_identifiers():
      id_tokens = []
      def callback(tok, next_tok):
        id_tokens.append(tok)
      ei.search_for_id_tokens(callback=callback)
      declare_identifiers(id_tokens=id_tokens)
      return id_tokens
    try:
      if (ei.key == "assignment"):
        lhs_id_tokens = extract_identifiers(tokens=ei.lhs_tokens)
        assert len(lhs_id_tokens) != 0
        rhs_id_tokens = extract_identifiers(tokens=ei.rhs_tokens)
        for id_tokens in lhs_id_tokens[1:], rhs_id_tokens:
          declare_identifiers(id_tokens=id_tokens)
        crhs = convert_tokens(
          conv_info=conv_info, tokens=ei.rhs_tokens)
        id_tok = lhs_id_tokens[0]
        assign_here = id_tok.value in conv_info.vmap
        if (not assign_here):
          assign_here = declare_identifier(
            conv_info=conv_info,
            top_scope=top_scope,
            curr_scope=curr_scope,
            id_tok=id_tok,
            crhs=crhs)
        clhs = convert_tokens(conv_info=conv_info, tokens=ei.lhs_tokens)
        if (assign_here):
          def in_place_op_left():
            if (not crhs.startswith(clhs)): return False
            i = len(clhs)
            if (i == len(crhs)): return False
            if (crhs[i] != " "): return False
            i += 1
            if (i == len(crhs)): return False
            op = crhs[i]
            if (op != "+"): return False
            i += 1
            if (i == len(crhs)): return False
            if (crhs[i] != " "): return False
            i += 1
            if (i == len(crhs)): return False
            if (crhs[i:] == "1"):
              curr_scope.append("%s++;" % clhs)
            else:
              curr_scope.append("%s %s= %s;" % (clhs, op, crhs[i:]))
            return True
          def in_place_op_right():
            if (not crhs.endswith(clhs)): return False
            i = len(crhs) - len(clhs)
            if (i == 0): return False
            i -= 1
            if (crhs[i] != " "): return False
            if (i == 0): return False
            i -= 1
            op = crhs[i]
            if (op != "+"): return False
            if (i == 0): return False
            i -= 1
            if (crhs[i] != " "): return False
            if (i == 0): return False
            if (crhs[:i] == "1"):
              curr_scope.append("%s++;" % clhs)
            else:
              curr_scope.append("%s %s= %s;" % (clhs, op, crhs[:i]))
            return True
          if (not in_place_op_left() and not in_place_op_right()):
            curr_scope.append("%s = %s;" % (clhs, crhs))
      elif (ei.key == "inquire"):
        search_for_id_tokens_and_declare_identifiers()
        iuflist = ei.iuflist
        if (iuflist.unit is not None):
          if (iuflist.file is not None):
            ei.ssl.raise_semantic_error(
              "Conflicting UNIT vs. FILE in INQUIRE statement"
              " (exactly one is needed)", i=ei.start)
          io_function_specialization = "_unit"
          uf_tokens = iuflist.unit
        elif (iuflist.file is not None):
          io_function_specialization = "_file"
          uf_tokens = iuflist.file
        else:
          ei.ssl.raise_semantic_error(
            "Missing UNIT or FILE in INQUIRE statement", i=ei.start)
        io_call_args = convert_tokens(conv_info=conv_info, tokens=uf_tokens)
        convert_io_statement_with_err(
          conv_info=conv_info,
          curr_scope=curr_scope,
          io_function="inquire",
          io_function_specialization=io_function_specialization,
          io_call_args=io_call_args,
          iolist=iuflist)
      elif (ei.key == "file_positioning"):
        search_for_id_tokens_and_declare_identifiers()
        io_call_args = convert_tokens(
          conv_info=conv_info, tokens=ei.alist.unit)
        convert_io_statement_with_err(
          conv_info=conv_info,
          curr_scope=curr_scope,
          io_function=ei.io_function,
          io_function_specialization="",
          io_call_args=io_call_args,
          iolist=ei.alist)
      elif (ei.key == "open"):
        search_for_id_tokens_and_declare_identifiers()
        olist = ei.olist
        if (olist.unit is None):
          ei.ssl.raise_semantic_error(
            "Missing UNIT in OPEN statement", i=ei.start)
        cunit = convert_tokens(conv_info=conv_info, tokens=olist.unit)
        if (olist.file is None):
          cfile = "fem::file_not_specified"
        else:
          cfile = convert_tokens(conv_info=conv_info, tokens=olist.file)
        convert_io_statement_with_err(
          conv_info=conv_info,
          curr_scope=curr_scope,
          io_function="open",
          io_function_specialization="",
          io_call_args="%s, %s" % (cunit, cfile),
          iolist=olist)
      elif (ei.key == "close"):
        search_for_id_tokens_and_declare_identifiers()
        cllist = ei.cllist
        if (cllist.unit is None):
          ei.ssl.raise_semantic_error(
            "Missing UNIT in CLOSE statement", i=ei.start)
        cunit = convert_tokens(conv_info=conv_info, tokens=cllist.unit)
        convert_io_statement_with_err(
          conv_info=conv_info,
          curr_scope=curr_scope,
          io_function="close",
          io_function_specialization="",
          io_call_args=cunit,
          iolist=cllist)
      elif (ei.key in ["read", "write", "print"]):
        search_for_id_tokens_and_declare_identifiers()
        cilist = ei.cilist
        if (ei.key == "print"):
          work_key = "write"
          cunit = "6"
        else:
          work_key = ei.key
          assert cilist.unit is not None
          cunit = convert_tokens(conv_info=conv_info, tokens=cilist.unit)
          if (cunit == "star "): cunit = "6"
        def conv_fmt():
          if (ei.fmt_tokens is not None):
            return '"(' + escape_string_literal(fmt_tokens_as_string(
              tokens=ei.fmt_tokens, comma=fmt_comma_placeholder)) + ')"'
          tl = cilist.fmt
          if (tl is None):
            return None
          if (len(tl) == 1):
            tok = tl[0]
            if (tok.is_op_with(value="*")):
              return "star"
            if (tok.is_integer()):
              stmt_label = tok.value
              if (fmt_counts_by_statement_label[stmt_label] > 1):
                return "format_%s" % stmt_label
              return get_cfmt_from_format(stmt_label=stmt_label)
          return convert_tokens(conv_info=conv_info, tokens=tl)
        cfmt = conv_fmt()
        cchain = []
        has_iostat = False
        for slot in ["rec", "iostat"]:
          tokens = getattr(cilist, slot)
          if (tokens is not None):
            cchain.append("%s(%s)" % (
              slot, convert_tokens(conv_info=conv_info, tokens=tokens)))
            if slot == "iostat":
              has_iostat = True
        if (len(cchain) == 0):
          cchain = ""
        else:
          cchain = "." + ".".join(cchain)
        iolist_id_tokens = extract_identifiers(tokens=ei.iolist)
        declare_identifiers(id_tokens=iolist_id_tokens)
        if (cfmt is None):
          cargs = "%s, fem::unformatted" % cunit
        else:
          cargs = "%s, %s" % (cunit, cfmt)
        implied_dos = []
        find_implied_dos(result=implied_dos, tokens=ei.iolist)
        if (len(implied_dos) == 0):
          if (    cilist.end is None
              and cilist.err is None
              and not has_iostat):
            io_scope = curr_scope
          else:
            io_scope = curr_scope.open_nested_scope(opening_text=["try {"])
          io_op = "%s(%s)%s" % (work_key, cargs, cchain)
          if (len(ei.iolist) == 0):
            io_scope.append(io_op+";")
          else:
            convert_io_loop(
              io_scope=io_scope,
              io_op=io_op,
              conv_info=conv_info,
              tokens=ei.iolist)
        else:
          is_internal_file = False
          if (cilist.unit is not None):
            unit_id_tokens = extract_identifiers(tokens=cilist.unit)
            if (len(unit_id_tokens) >= 1):
              unit_fdecl = conv_info.fproc.get_fdecl(id_tok=unit_id_tokens[0])
              if (    unit_fdecl.data_type is not None
                  and unit_fdecl.data_type.value == "character"):
                is_internal_file = True
          if (   cilist.end is not None
              or cilist.err is not None
              or has_iostat):
            opening_line = "try {"
          else:
            opening_line = "{"
          io_scope = curr_scope.open_nested_scope(opening_text=[opening_line])
          if (is_internal_file): cmn = ""
          else:                  cmn = "cmn, "
          io_scope.append("%s_loop %sloop(%s%s);" % (
            work_key, work_key[0], cmn, cargs))
          if (len(cchain) != 0):
            io_scope.append("%sloop%s;" % (work_key[0], cchain))
          convert_io_loop(
            io_scope=io_scope,
            io_op=work_key[0]+"loop",
            conv_info=conv_info,
            tokens=ei.iolist)
        if (io_scope is not curr_scope):
          io_scope.close_nested_scope()
        for slot,cexception in [("end", "read_end"), ("err", "io_err")]:
          tokens = getattr(cilist, slot)
          if (tokens is not None):
            catch_scope = curr_scope.open_nested_scope(
              opening_text=["catch (fem::%s const&) {" % cexception])
            clabel = convert_tokens(conv_info=conversion_info(), tokens=tokens)
            catch_scope.append("goto statement_%s;" % clabel)
            catch_scope.close_nested_scope()
          else:
            if has_iostat:
              catch_scope = curr_scope.open_nested_scope(
                opening_text=["catch (fem::%s const&) {" % cexception])
              catch_scope.close_nested_scope()
      elif (ei.key == "do"):
        if (ei.id_tok.value not in conv_info.vmap):
          declare_identifier(
            conv_info=conv_info,
            top_scope=top_scope,
            curr_scope=curr_scope,
            id_tok=ei.id_tok)
        for token in ei.tokens:
          declare_identifiers(
            id_tokens=extract_identifiers(tokens=token.value))
        curr_scope = convert_to_fem_do(
          conv_info=conv_info,
          parent_scope=curr_scope,
          i_tok=ei.id_tok,
          fls_tokens=ei.tokens)
        if (ei.label is not None):
          dos_to_close_by_label.setdefault(ei.label, []).append(curr_scope)
      elif (ei.key == "dowhile"):
        declare_identifiers(
          id_tokens=extract_identifiers(tokens=ei.cond_tokens))
        c = convert_tokens(conv_info=conv_info, tokens=ei.cond_tokens)
        curr_scope = curr_scope.open_nested_scope(
          opening_text=["while %s {" % c])
        if (ei.label is not None):
          dos_to_close_by_label.setdefault(ei.label, []).append(curr_scope)
      elif (ei.key == "cycle"):
        curr_scope.append("continue;")
      elif (ei.key == "exit"):
        curr_scope.append("break;")
      elif (ei.key == "enddo"):
        if (dos_to_close_by_label.get(ei.ssl.label) is None):
          curr_scope = curr_scope.close_nested_scope()
      elif (ei.key == "if"):
        declare_identifiers(
          id_tokens=extract_identifiers(tokens=ei.cond_tokens))
        c = convert_tokens(conv_info=conv_info, tokens=ei.cond_tokens)
        curr_scope = curr_scope.open_nested_scope(
          opening_text=["if (%s) {" % c])
        close_scope_after_next_executable = True
        continue
      elif (ei.key == "if_then"):
        declare_identifiers(
          id_tokens=extract_identifiers(tokens=ei.cond_tokens))
        c = convert_tokens(conv_info=conv_info, tokens=ei.cond_tokens)
        curr_scope = curr_scope.open_nested_scope(
          opening_text=["if (%s) {" % c])
      elif (ei.key == "elseif_then"):
        declare_identifiers(
          id_tokens=extract_identifiers(tokens=ei.cond_tokens))
        c = convert_tokens(conv_info=conv_info, tokens=ei.cond_tokens)
        curr_scope = curr_scope.attach_tail(
          opening_text=["else if (%s) {" % c])
      elif (ei.key == "else"):
        curr_scope = curr_scope.attach_tail(opening_text=["else {"])
      elif (ei.key == "endif"):
        curr_scope = curr_scope.close_nested_scope()
      elif (ei.key == "if_arithmetic"):
        declare_identifiers(
          id_tokens=extract_identifiers(tokens=ei.cond_tokens))
        c = convert_tokens(conv_info=conv_info, tokens=ei.cond_tokens)
        curr_scope = curr_scope.open_nested_scope(
          opening_text=["switch (fem::if_arithmetic(%s)) {" % c])
        def lbl(i): return "statement_" + ei.labels[i].value
        curr_scope.append("case -1: goto %s;" % lbl(0))
        curr_scope.append("case  0: goto %s;" % lbl(1))
        curr_scope.append("default: goto %s;" % lbl(2))
        curr_scope = curr_scope.close_nested_scope()
      elif (ei.key == "call"):
        fdecl = conv_info.fproc.get_fdecl(id_tok=ei.subroutine_name)
        if (fdecl.is_intrinsic()):
          from fable import intrinsics
          cmn = ""
          if (ei.subroutine_name.value == "getarg"):
            called = "cmn.getarg"
          elif (ei.subroutine_name.value in intrinsics.io_set_lower):
            called = "cmn.io.%s" % ei.subroutine_name.value
          else:
            called = "fem::%s" % ei.subroutine_name.value
        else:
          if (called_fproc_needs_cmn(
                conv_info=conv_info,
                called_name=ei.subroutine_name.value)):
            cmn = "cmn"
          else:
            cmn = ""
          called = conv_info.vmapped_callable(
            identifier=ei.subroutine_name.value)
        if (ei.arg_token is None):
          curr_scope.append("%s(%s);" % (called, cmn))
        else:
          id_tokens = extract_identifiers(tokens=ei.arg_token.value)
          declare_identifiers(id_tokens=id_tokens)
          a = convert_tokens(
            conv_info=conv_info, tokens=ei.arg_token.value, commas=True)
          def cmn_a():
            if (len(cmn) == 0): return a
            if (len(a) == 0): return cmn
            return cmn + ", " + a
          curr_scope.append("%s(%s);" % (called, cmn_a()))
      elif (ei.key == "return"):
        if (conv_info.fproc.fproc_type == "function"):
          curr_scope_append_return_function()
        elif (ei is not conv_info.fproc.executable[-1]):
          curr_scope.append("return;")
      elif (ei.key == "continue"):
        pass
      elif (ei.key == "goto"):
        curr_scope.append("goto statement_%s;" % ei.label.value)
      elif (ei.key == "goto_computed"):
        search_for_id_tokens_and_declare_identifiers()
        ccond = convert_tokens(conv_info=conv_info, tokens=ei.tokens)
        switch_scope = curr_scope.open_nested_scope(
          opening_text=["switch (%s) {" % ccond])
        for i,label in enumerate(ei.labels):
          switch_scope.append(
            "case %d: goto statement_%s;" % (i+1, label.value))
        switch_scope.append("default: break;")
        switch_scope.close_nested_scope()
      elif (ei.key == "stop"):
        if (ei.arg_token is None):
          cmsg = "0"
        elif (ei.arg_token.is_integer()):
          cmsg = strip_leading_zeros(string=ei.arg_token.value)
        else:
          cmsg = convert_token(vmap={}, leading=True, tok=ei.arg_token)
        curr_scope.append("FEM_STOP(%s);" % cmsg)
      elif (ei.key == "entry"):
        curr_scope.append(
          "// UNHANDLED: ENTRY %s" % ei.ssl.code_with_strings()[5:])
      else:
        curr_scope.append(
          'FEM_THROW_UNHANDLED("executable %s: %s");' % (
            ei.key, ei.ssl.code_with_strings()))
      if (close_scope_after_next_executable):
        close_scope_after_next_executable = False
        curr_scope = curr_scope.close_nested_scope()
      if (ei.ssl.label is not None):
        dos_to_close = dos_to_close_by_label.get(ei.ssl.label)
        if (dos_to_close is not None):
          for do_scope in reversed(dos_to_close):
            curr_scope = do_scope.close_nested_scope()
    except (Error, SemanticError):
      raise
    except Exception:
      print("*"*80)
      print(ei.ssl.format_error(
        i=None,
        msg="Sorry: fable internal error"))
      print("*"*80)
      print()
      raise
  assert curr_scope.parent is None
  if (    conv_info.fproc.fproc_type == "function"
      and len(conv_info.fproc.executable) != 0
      and conv_info.fproc.executable[-1].key != "return"):
    curr_scope_append_return_function()
  conv_info.comment_manager.flush_remaining(
    callback=curr_scope.append_comment)
  curr_scope.finalize()
  curr_scope.collect_text(callback=callback)

def export_save_struct(callback, conv_info):
  cci = conv_info.converted_commons_info
  if (cci is not None):
    buffer = cci.save_struct_buffers.get(conv_info.fproc.name.value)
    if (buffer is not None):
      for line in buffer:
        callback(line)

def produce_fortran_file_comment(conv_info, callback):
  if (conv_info.fortran_file_comments):
    callback("// Fortran file: %s"
      % conv_info.fproc.body_lines[0].source_line_cluster[0].file_name)

def convert_to_cpp_function(
      cpp_callback,
      hpp_callback,
      conv_info,
      declaration_only=False,
      force_not_implemented=False):
  if (not declaration_only):
    export_save_struct(callback=cpp_callback, conv_info=conv_info)
  fptr = []
  cargs = []
  def cargs_append(ctype, name):
    fptr.append(ctype)
    cargs.append(ctype + " " + name)
  if (    conv_info.fproc.needs_cmn
      and not conv_info.fproc.conv_hook.ignore_common_and_save):
    cargs_append("common&", "cmn")
  args_fdecl_with_dim = []
  for id_tok in conv_info.fproc.args:
    if (id_tok.value == "*"):
      cargs_append("fem::star_type const&", "/* UNHANDLED: star argument */")
      continue
    assert id_tok.value not in conv_info.vmap
    fdecl = conv_info.fproc.get_fdecl(id_tok=id_tok)
    conv_info.set_vmap_from_fdecl(fdecl=fdecl)
    assert fdecl.parameter_assignment_tokens is None
    if (fdecl.use_count == 0):
      arg_name = "/* %s */" % prepend_identifier_if_necessary(id_tok.value)
    else:
      arg_name = prepend_identifier_if_necessary(id_tok.value)
    if (    fdecl.data_type is not None
        and fdecl.data_type.value == "character"):
      if (fdecl.dim_tokens is None):
        cargs_append("str_%sref" % cconst(fdecl=fdecl, short=True), arg_name)
      else:
        if (len(fdecl.dim_tokens) == 1):
          cdim = ""
        else:
          cdim = "%d" % len(fdecl.dim_tokens)
        cargs_append("str_arr_%sref<%s>" % (
          cconst(fdecl=fdecl, short=True), cdim), arg_name)
    elif (not fdecl.is_user_defined_callable()):
      ctype = convert_data_type(conv_info=conv_info, fdecl=fdecl, crhs=None)[0]
      if (fdecl.dim_tokens is None):
        cargs_append("%s%s&" % (
          ctype,
          cconst(fdecl=fdecl, short=False)),
          prepend_identifier_if_necessary(arg_name))
      else:
        if (len(fdecl.dim_tokens) == 1):
          t = ctype
        else:
          t = "%s, %d" % (ctype, len(fdecl.dim_tokens))
        if (t.endswith(">")): templs = " "
        else:                 templs = ""
        cargs_append("arr_%sref<%s%s>" % (
          cconst(fdecl=fdecl, short=True), t, templs), arg_name)
    else:
      passed = conv_info.fproc.externals_passed_by_arg_identifier.get(
        fdecl.id_tok.value)
      if (passed is None or len(passed) == 0):
        ctype = "UNHANDLED"
      else:
        ctype = sorted(passed)[0]
      cargs_append(
        ctype=ctype+"_function_pointer",
        name=arg_name)
    if (fdecl.dim_tokens is not None and fdecl.use_count != 0):
      args_fdecl_with_dim.append(fdecl)
  cdecl = "void"
  if (conv_info.fproc.name is not None):
    fdecl = conv_info.fproc.get_fdecl(id_tok=conv_info.fproc.name)
    if (fdecl.data_type is not None):
      cdecl = convert_data_type(conv_info=conv_info, fdecl=fdecl, crhs=None)[0]
      conv_info.vmap[conv_info.fproc.name.value] = "return_value"
  if (declaration_only):
    cpp_callback("")
    cpp_callback("// forward declaration (dependency cycle)")
    if (conv_info.inline_all):
      cpp_callback("inline")
    cpp_callback("%s %s(%s);" % (
      cdecl,
      prepend_identifier_if_necessary(conv_info.fproc.name.value),
      ", ".join(fptr)))
    return
  if (conv_info.fproc.is_passed_as_external):
    if (hpp_callback is None): cb = cpp_callback
    else:                      cb = hpp_callback
    cb("")
    cb("typedef %s (*%s_function_pointer)(%s);" % (
      cdecl,
      prepend_identifier_if_necessary(conv_info.fproc.name.value),
      ", ".join(fptr)))
  for callback in [hpp_callback, cpp_callback]:
    if (callback is None): continue
    callback("")
    if (callback is cpp_callback):
      produce_leading_comments(callback=callback, fproc=conv_info.fproc)
      produce_fortran_file_comment(conv_info=conv_info, callback=callback)
    if (conv_info.inline_all):
      callback("inline")
    callback(cdecl)
    if (callback is hpp_callback): last = ";"
    else:                          last = ""
    cname = prepend_identifier_if_necessary(conv_info.fproc.name.value)
    if (len(cargs) == 0):
      callback(cname+"()" + last)
    else:
      callback(cname + "(\n  " + ",\n  ".join(cargs) + ")" + last)
  cpp_callback("{")
  if (cdecl != "void"):
    cpp_callback("  %s %s = %s;" % (
      cdecl,
      conv_info.vmap[conv_info.fproc.name.value],
      zero_shortcut_if_possible(ctype=cdecl)))
  if (force_not_implemented):
    cpp_callback("  throw TBXX_NOT_IMPLEMENTED();")
  else:
    convert_executable(
      callback=cpp_callback,
      conv_info=conv_info,
      args_fdecl_with_dim=args_fdecl_with_dim)
  cpp_callback("}")
  produce_trailing_comments(callback=callback, fproc=conv_info.fproc)

def convert_to_struct(
      callback,
      separate_cmn_hpp,
      fproc,
      struct_type,
      struct_name,
      equivalence_simple,
      id_tok_list):
  assert struct_type in ["common", "save"]
  need_dynamic_parameters = False
  conv_info = conversion_info(fproc=fproc)
  callback("")
  callback("struct %s" % struct_name)
  callback("{")
  sve_equivalences = {}
  cmn_equivalences = {}
  have_variant_block = False
  if (    struct_type == "save"
      and conv_info.fproc.conv_hook.needs_is_called_first_time):
    for common_name in sorted(conv_info.fproc.conv_hook.variant_common_names):
      callback("  fem::variant_bindings %s_bindings;" % common_name)
      have_variant_block = True
    #
    cei = conv_info.fproc.classified_equivalence_info()
    sve_equivalences = cei.save.equiv_tok_cluster_by_identifier
    if (len(sve_equivalences) != 0):
      callback("  fem::variant_core_and_bindings save_equivalences;")
      have_variant_block = True
    cmn_equivalences = cei.common.equiv_tok_cluster_by_identifier
  #
  from fable.tokenization import extract_identifiers
  const_identifiers = {}
  const_id_toks = []
  remaining_id_tok_list = []
  for id_tok in id_tok_list:
    if (id_tok.value in sve_equivalences):
      continue
    if (id_tok.value in cmn_equivalences):
      continue
    remaining_id_tok_list.append(id_tok)
    fdecl = conv_info.fproc.get_fdecl(id_tok=id_tok)
    for tokens in [fdecl.size_tokens, fdecl.dim_tokens]:
      if (tokens is None):
        continue
      def parameter_recursion(tokens):
        have_dynamic_dependency = False
        for id_tok in extract_identifiers(tokens=tokens):
          if (id_tok.value in const_identifiers):
            continue
          const_identifiers[id_tok.value] = None
          fdecl = conv_info.fproc.get_fdecl(id_tok=id_tok)
          hdp = parameter_recursion(
            tokens=fdecl.required_parameter_assignment_tokens())
          if (hdp or id_tok.value in conv_info.fproc.dynamic_parameters):
            have_dynamic_dependency = True
          const_identifiers[id_tok.value] = have_dynamic_dependency
          const_id_toks.append(id_tok)
        return have_dynamic_dependency
      parameter_recursion(tokens=tokens)
  initializers = []
  const_definitions = []
    # ISO C++ 9.4.2-4:
    #   "The member shall still be defined in a namespace scope if it is used
    #   in the program and the namespace scope definition shall not contain
    #   an initializer."
  if (len(const_id_toks) != 0):
    if (have_variant_block):
      callback("")
    append_empty_line = False
    for id_tok in const_id_toks:
      fdecl = conv_info.fproc.get_fdecl(id_tok=id_tok)
      ctype = convert_data_type(conv_info=conv_info, fdecl=fdecl, crhs=None)[0]
      if (const_identifiers[id_tok.value]):
        need_dynamic_parameters = True
        callback("  const %s %s;" % (
          ctype, prepend_identifier_if_necessary(id_tok.value)))
        if (id_tok.value in conv_info.fproc.dynamic_parameters):
          crhs = "dynamic_params." + prepend_identifier_if_necessary(
            id_tok.value)
        else:
          crhs = convert_tokens(
            conv_info=conv_info, tokens=fdecl.parameter_assignment_tokens)
        initializers.append((id_tok.value, crhs))
      else:
        crhs = convert_tokens(
          conv_info=conv_info, tokens=fdecl.parameter_assignment_tokens)
        callback("  static const %s %s = %s;" % (
          ctype, prepend_identifier_if_necessary(id_tok.value), crhs))
        const_definitions.append(
          "const %s %s::%s;" % (
            ctype, struct_name, prepend_identifier_if_necessary(id_tok.value)))
        append_empty_line = True
    if (append_empty_line):
      callback("")
  #
  deferred_arr_members = []
  deferred_arr_initializers = []
  for id_tok in remaining_id_tok_list:
    fdecl = conv_info.fproc.get_fdecl(id_tok=id_tok)
    if (fdecl.id_tok.value in const_identifiers):
      continue
    ctype, cdims, crhs = convert_data_type_and_dims(
      conv_info=conv_info, fdecl=fdecl, crhs=None, force_arr=True)[:3]
    if (cdims is None):
      callback("  %s %s;" % (
        ctype, prepend_identifier_if_necessary(id_tok.value)))
      if (crhs is None):
        crhs = zero_shortcut_if_possible(ctype=ctype)
      initializers.append((id_tok.value, crhs))
    elif (not equivalence_simple or need_dynamic_parameters):
      callback("  %s %s;" % (
        ctype, prepend_identifier_if_necessary(id_tok.value)))
      initializers.append((id_tok.value, "%s, fem::fill0" % cdims))
    else:
      ctype_core = convert_data_type(
        conv_info=conv_info, fdecl=fdecl, crhs=None)[0]
      cstatic_size = convert_dims_to_static_size(
        conv_info=conv_info, dim_tokens=fdecl.dim_tokens)
      callback("  %s %s_memory[%s];" % (
        ctype_core,
        prepend_identifier_if_necessary(id_tok.value),
        cstatic_size))
      if (fdecl.data_type.value == "character"):
        deferred_arr_members.append("  str_arr_ref<%d> %s;" % (
          len(fdecl.dim_tokens),
          prepend_identifier_if_necessary(id_tok.value)))
      else:
        deferred_arr_members.append("  %s %s;" % (
          ad_hoc_change_arr_to_arr_ref(ctype=ctype),
          prepend_identifier_if_necessary(id_tok.value)))
      deferred_arr_initializers.append((
        id_tok.value,
        "*%s_memory, %s, fem::fill0" % (
          prepend_identifier_if_necessary(id_tok.value), cdims)))
  if (len(deferred_arr_members) != 0):
    callback("")
    for line in deferred_arr_members:
      callback(line)
    initializers.extend(deferred_arr_initializers)
  n = len(initializers)
  if (n != 0):
    callback("")
    if (not need_dynamic_parameters):
      callback("  %s() :" % struct_name)
    else:
      callback("  %s(" % struct_name)
      callback("    dynamic_parameters const& dynamic_params)")
      callback("  :")
    for i in range(n):
      ii = initializers[i]
      if (i+1 == n): comma = ""
      else:          comma = ","
      callback("    %s(%s)%s" % (
        prepend_identifier_if_necessary(ii[0]), ii[1], comma))
    callback("  {}")
  callback("};")
  #
  if (len(const_definitions) != 0):
    callback("")
    need_ifdef = (separate_cmn_hpp and struct_type == "common")
    if (need_ifdef):
      callback("#ifdef FEM_TRANSLATION_UNIT_WITH_MAIN")
    for cd in const_definitions:
      callback(cd)
    if (need_ifdef):
      callback("#endif")
  #
  return group_args(
    need_dynamic_parameters=need_dynamic_parameters)

def generate_common_report(
      common_fdecl_list_sizes,
      common_equiv_tok_seqs,
      ccode_registry,
      member_registry,
      variant_due_to_equivalence_common_names,
      stringio):
  from six.moves import StringIO
  variant_common_names = set()
  if (stringio is None):
    report = StringIO()
  else:
    report = stringio
  for common_name,fproc_cpp_pairs in ccode_registry.items():
    fprocs_by_cpp = {}
    for fproc,cpp in fproc_cpp_pairs:
      fprocs_by_cpp.setdefault("\n".join(cpp), []).append(fproc)
    if (len(fprocs_by_cpp) != 1):
      variant_common_names.add(common_name)
      fprocs_by_cpp_items = list(fprocs_by_cpp.items())
      def size_key(a):
        return len(a[0])
      fprocs_by_cpp_items.sort(key=size_key, reverse=True)
      import difflib
      diff_function = getattr(difflib, "unified_diff", difflib.ndiff)
      def show_fprocs(label, cpp_fprocs):
        print("procedures %s:" % label,
          " ".join(sorted([fproc.name.value for fproc in cpp_fprocs[1]])), file=report)
      main_cpp_fprocs = fprocs_by_cpp_items[0]
      print("common name:", common_name, file=report)
      print("number of variants:", len(fprocs_by_cpp_items), file=report)
      print("total number of procedures using the common block:",
        sum([len(fprocs) for cpp,fprocs in fprocs_by_cpp_items]), file=report)
      show_fprocs("first", main_cpp_fprocs)
      for other_cpp_fprocs in fprocs_by_cpp_items[1:]:
        show_fprocs("second", other_cpp_fprocs)
        print(" ".join([line for line in diff_function(
                      (main_cpp_fprocs[0]+"\n").splitlines(1),
                      (other_cpp_fprocs[0]+"\n").splitlines(1))]), file=report)
  #
  need_empty_line = False
  for identifier in sorted(member_registry.keys()):
    common_names = member_registry[identifier]
    if (len(common_names) != 1):
      print("Name clash: %s in COMMONs: %s" % (
        identifier, ", ".join(sorted(common_names))), file=report)
      need_empty_line = True
  if (need_empty_line):
    print(file=report)
  #
  vv = list(variant_due_to_equivalence_common_names - variant_common_names)
  if (len(vv) != 0):
    print("common variants due to equivalence:", len(vv), file=report)
    size_sums = {}
    for common_name,sizes in common_fdecl_list_sizes.items():
      size_sums[common_name] = sum(sizes)

    vv.sort(key=lambda element: (-size_sums[element], element))
    print("  %-20s   procedures    sum of members" % "common name", file=report)
    for common_name in vv:
      print("  %-20s   %8d         %8d" % (
        common_name,
        len(common_fdecl_list_sizes[common_name]),
        size_sums[common_name]), file=report)
    print(file=report)
    print("Locations of equivalence statements:", file=report)
    reported_already = set()
    for common_name in vv:
      print("  %s" % common_name, file=report)
      prev_loc = ""
      tab = []
      max_len_col1 = 6
      for tok_seq in common_equiv_tok_seqs[common_name]:
        sl, i = tok_seq.stmt_location()
        tag = (sl.file_name, sl.line_number, i)
        if (tag in reported_already):
          break
        reported_already.add(tag)
        vn = tok_seq.value[0].value
        dn, bn = os.path.split(sl.file_name)
        loc = ("%s(%s) %s" % (bn, sl.line_number, dn)).rstrip()
        if (loc == prev_loc): loc = ""
        else: prev_loc = loc
        tab.append((vn, loc))
        max_len_col1 = max(max_len_col1, len(vn))
      if (len(tab) != 0):
        fmt = "    %%-%ds %%s" % max_len_col1
        for row in tab:
          print(fmt % row, file=report)
  #
  if (len(report.getvalue()) != 0 and stringio is None):
    import sys
    report_file_name = "fable_cout_common_report"
    from libtbx.str_utils import show_string
    print("Writing file:", show_string(report_file_name), file=sys.stderr)
    open(report_file_name, "w").write(report.getvalue())
  #
  return variant_common_names

def convert_commons(
      callback,
      separate_cmn_hpp,
      topological_fprocs,
      dynamic_parameters,
      common_equivalence_simple,
      common_report_stringio):
  if (dynamic_parameters is not None):
    callback("")
    callback("struct dynamic_parameters")
    callback("{")
    for dp_props in dynamic_parameters:
      callback("  %s %s;" % (dp_props.ctype, dp_props.name))
    callback("""
  dynamic_parameters(
    fem::command_line_arguments const& command_line_args)
  :""")
    for dp_props in dynamic_parameters:
      if (dp_props is not dynamic_parameters[-1]): c = ","
      else:                                        c = ""
      callback("    %s(%s)%s" % (
        prepend_identifier_if_necessary(dp_props.name),
        str(dp_props.default),
        c))
    callback("""\
  {
    fem::dynamic_parameters_from(command_line_args, %d)"""
      % len(dynamic_parameters))
    for dp_props in dynamic_parameters:
      callback("      .reset_if_given(%s)"
        % prepend_identifier_if_necessary(dp_props.name))
    callback("    ;")
    callback("  }")
    callback("};")
    callback("")
    callback("typedef")
    callback("  fem::dynamic_parameters_capsule<dynamic_parameters>")
    callback("    dynamic_parameters_capsule;")
  #
  common_fdecl_list_sizes = {}
  common_equiv_tok_seqs = {}
  common_ccode_registry = {}
  member_registry = {}
  variant_common_names = set()
  bottom_up_filtered = []
  for fproc in topological_fprocs.bottom_up_list:
    if (not fproc.conv_hook.ignore_common_and_save):
      bottom_up_filtered.append(fproc)
  struct_commons_need_dynamic_parameters = set()
  for fproc in bottom_up_filtered:
    fproc.conv_hook.needs_variant_bind = False
    for common_name,common_fdecl_list in fproc.common.items():
      common_fdecl_list_sizes.setdefault(common_name, []).append(
        len(common_fdecl_list))
      id_tok_list = []
      for common_fdecl in common_fdecl_list:
        assert common_fdecl.size_tokens is None
        id_tok_list.append(common_fdecl.id_tok)
        member_registry.setdefault(
          common_fdecl.id_tok.value, set()).add(common_name)
        if (common_name not in common_equivalence_simple):
          equiv_tok_cluster = fproc.equivalence_info() \
            .equiv_tok_cluster_by_identifier.get(common_fdecl.id_tok.value)
          if (equiv_tok_cluster is not None):
            fproc.conv_hook.needs_variant_bind = True
            variant_common_names.add(common_name)
            for equiv_tok in equiv_tok_cluster:
              for tok_seq in equiv_tok.value:
                common_equiv_tok_seqs.setdefault(common_name, []).append(
                  tok_seq)
      struct_name = "common_" + common_name
      buffer = []
      info = convert_to_struct(
        callback=buffer.append,
        separate_cmn_hpp=separate_cmn_hpp,
        fproc=fproc,
        struct_type="common",
        struct_name=struct_name,
        equivalence_simple=(common_name in common_equivalence_simple),
        id_tok_list=id_tok_list)
      if (info.need_dynamic_parameters):
        struct_commons_need_dynamic_parameters.add(struct_name)
      common_ccode_registry.setdefault(common_name, []).append(
        (fproc, buffer))
  variant_common_names.update(generate_common_report(
    common_fdecl_list_sizes=common_fdecl_list_sizes,
    common_equiv_tok_seqs=common_equiv_tok_seqs,
    ccode_registry=common_ccode_registry,
    member_registry=member_registry,
    variant_due_to_equivalence_common_names=variant_common_names,
    stringio=common_report_stringio))
  commons_defined_already = set()
  struct_commons = []
  variant_commons = []
  for fproc in bottom_up_filtered:
    fproc.conv_hook.variant_common_names = set()
    for common_name,common_fdecl_list in fproc.common.items():
      if (common_name in variant_common_names):
        fproc.conv_hook.variant_common_names.add(common_name)
        if (common_name not in commons_defined_already):
          commons_defined_already.add(common_name)
          variant_commons.append(common_name)
      else:
        if (common_name not in commons_defined_already):
          commons_defined_already.add(common_name)
          struct_commons.append("common_"+common_name)
          for line in common_ccode_registry[common_name][0][1]:
            callback(line)
  #
  for fproc in bottom_up_filtered:
    if (not fproc.conv_hook.needs_variant_bind):
      fproc.conv_hook.needs_variant_bind = (
           len(fproc.conv_hook.variant_common_names) != 0
        or fproc.classified_equivalence_info().has_save())
    fproc.conv_hook.needs_is_called_first_time = (
         fproc.conv_hook.needs_variant_bind
      or len(fproc.data) != 0)
    fproc.conv_hook.data_init_after_variant_bind = (
          fproc.conv_hook.needs_variant_bind
      and len(fproc.data) != 0)
    if (fproc.conv_hook.needs_is_called_first_time):
      fproc.uses_save = True
  topological_fprocs.each_fproc_update_is_modified()
  topological_fprocs.each_fproc_update_needs_cmn()
  #
  save_struct_buffers = {}
  save_struct_names = []
  for fproc in bottom_up_filtered:
    id_tok_list = []
    for fdecl in fproc.fdecl_by_identifier.values():
      if (fdecl.is_save()):
        id_tok_list.append(fdecl.id_tok)
    if (    len(id_tok_list) == 0
        and not fproc.conv_hook.needs_is_called_first_time):
      continue
    id_tok_list.sort(key=lambda token: token.value)
    struct_name = "%s_save" % fproc.name.value
    buffer = []
    info = convert_to_struct(
      callback=buffer.append,
      separate_cmn_hpp=separate_cmn_hpp,
      fproc=fproc,
      struct_type="save",
      struct_name=struct_name,
      equivalence_simple=False,
      id_tok_list=id_tok_list)
    save_struct_buffers[fproc.name.value] = buffer
    if (info.need_dynamic_parameters):
      fproc.conv_hook.needs_sve_dynamic_parameters = True
    save_struct_names.append(struct_name)
  if (    len(commons_defined_already) == 0
      and len(save_struct_names) == 0
      and dynamic_parameters is None):
    callback("")
    callback("using fem::common;")
    return
  callback("")
  callback("struct common :")
  leading_bases = ["fem::common"]
  if (dynamic_parameters is not None):
    leading_bases.append("dynamic_parameters_capsule")
  callback("  " + ",\n  ".join(leading_bases + struct_commons))
  callback("{")
  need_empty_line = False
  for common_name in variant_commons:
    callback("  fem::variant_core common_%s;" % common_name)
    need_empty_line = True
  def save_as_sve(struct_name): return struct_name[:-3]+"ve"
  for struct_name in save_struct_names:
    callback("  fem::cmn_sve %s;" % save_as_sve(struct_name))
    need_empty_line = True
  if (need_empty_line):
    callback("")
  initializations = ["fem::common(argc, argv)"]
  if (dynamic_parameters is not None):
    initializations.append(
      "dynamic_parameters_capsule(command_line_args)")
    for struct_name in struct_commons:
      if (struct_name in struct_commons_need_dynamic_parameters):
        initializations.append("%s(dynamic_params)" % struct_name)
  callback("""\
  common(
    int argc,
    char const* argv[])
  :
    %s
  {}""" % ",\n    ".join(initializations))
  callback("};")
  #
  return group_args(
    member_registry=member_registry,
    save_struct_buffers=save_struct_buffers)

include_fem_hpp = \
  "#include <fem.hpp> // Fortran EMulation library of fable module"

def include_guard(callback, namespace, suffix):
  s = namespace.upper().replace("::", "_") + suffix
  callback("#ifndef %s" % s)
  callback("#define %s" % s)
  callback("")

def open_namespace(callback, namespace, using_namespace_major_types=True):
  ns = namespace.split("::")
  for component in ns:
    callback("namespace %s {" % component)
  if (using_namespace_major_types):
    callback("""
using namespace fem::major_types;""")
  return ns

def close_namespace(callback, namespace, hpp_guard):
  callback("")
  ns = namespace.split("::")
  callback("%s // namespace %s" % ("}"*len(ns), namespace))
  if (hpp_guard):
    callback("")
    callback("#endif // GUARD")
  return ns

class hpp_cpp_buffers(object):

  __slots__ = ["hpp", "cpp"]

  def __init__(O):
    O.hpp = []
    O.cpp = []

def convert_program(callback, global_conv_info, namespace, hpp_guard, debug):
  main_calls = []
  for fproc in global_conv_info.topological_fprocs.bottom_up_list:
    if (not fproc.is_program()): continue
    conv_info = global_conv_info.specialized(fproc=fproc)
    export_save_struct(callback=callback, conv_info=conv_info)
    cname = fproc.name.value
    main_calls.append(cname)
    callback("")
    produce_leading_comments(callback=callback, fproc=fproc)
    produce_fortran_file_comment(conv_info=conv_info, callback=callback)
    callback("""\
void
%s(
  int argc,
  char const* argv[])
{""" % cname)
    if (not fproc.needs_cmn):
      callback("""\
  if (argc != 1) {
    throw std::runtime_error("Unexpected command-line arguments.");
  }""")
    result_buffer = []
    try:
      convert_executable(
        callback=result_buffer.append,
        conv_info=conv_info,
        blockdata=global_conv_info.topological_fprocs.all_fprocs.blockdata)
    except Exception:
      if (not debug): raise
      show_traceback()
    else:
      if (fproc.needs_cmn and not fproc.conv_hook.ignore_common_and_save):
        callback("  common cmn(argc, argv);")
      for line in result_buffer:
        callback(line)
      callback("}")
    produce_trailing_comments(callback=callback, fproc=fproc)
  #
  ns = close_namespace(
    callback=callback, namespace=namespace, hpp_guard=hpp_guard)
  #
  if (len(main_calls) != 0):
    callback("")
    callback("""\
int
main(
  int argc,
  char const* argv[])
{
  return fem::main_with_catch(
    argc, argv,
    %s);
}""" % "::".join(ns + [main_calls[0]]))

def get_missing_external_return_type(fdecls):
  for fdecl in fdecls:
    if (fdecl.data_type is not None):
      return convert_data_type(
        conv_info=conversion_info(), fdecl=fdecl, crhs=None)[0]
  return "void"

default_arr_nd_size_max = 256

def process(
      file_names=None,
      all_fprocs=None,
      top_procedures=None,
      namespace="please_specify",
      include_prefix=None,
      include_guard_suffix=None,
      top_cpp_file_name=None,
      dynamic_parameters=None,
      fortran_file_comments=False,
      fem_do_safe=True,
      arr_nd_size_max=default_arr_nd_size_max,
      inline_all=False,
      common_equivalence_simple=set(),
      suppress_program=False,
      suppress_common=False,
      separate_cmn_hpp=False,
      number_of_function_files=None,
      separate_files_main_namespace={},
      write_separate_files_main_namespace="All",
      separate_files_separate_namespace={},
      write_separate_files_separate_namespace="All",
      ignore_common_and_save=set(),
      force_not_implemented=set(),
      ignore_missing=set(),
      suppress_functions=set(),
      suppress_function_definitions=set(),
      common_report_stringio=None,
      data_values_block_size=8,
      data_specializations=True,
      debug=False):
  assert [file_names, all_fprocs].count(None) == 1
  if (namespace is None or namespace == "please_specify"):
    namespace = "placeholder_please_replace"
  import fable.read
  if (all_fprocs is None):
    all_fprocs = fable.read.process(file_names=file_names)
  for fproc in all_fprocs.all_in_input_order:
    fproc.conv_hook = conv_hook_info()
    fproc.conv_hook.ignore_common_and_save = (
      fproc.name.value in ignore_common_and_save)
  result = []
  def callback(line):
    if (len(result) == 0): prev_line = None
    else:                  prev_line = result[-1]
    lines = break_lines(cpp_text=[line+"\n"], prev_line=prev_line)
    if (len(lines) != 0):
      if (debug):
        print("\n".join(lines))
      result.extend(lines)
  #
  need_function_hpp = False
  if (len(separate_files_main_namespace) != 0):
    need_function_hpp = True
  if (number_of_function_files is not None):
    assert number_of_function_files > 0
    need_function_hpp = True
  if (need_function_hpp):
    separate_cmn_hpp = True
  #
  if (include_guard_suffix is not None):
    include_guard(
      callback=callback, namespace=namespace, suffix=include_guard_suffix)
  #
  if (separate_cmn_hpp):
    callback("#define FEM_TRANSLATION_UNIT_WITH_MAIN")
    callback("")
  #
  def include_separate(callback):
    if (len(separate_files_separate_namespace) == 0):
      return False
    for name in sorted(separate_files_separate_namespace.keys()):
      callback('#include "%s.hpp"' % name)
    return True
  #
  def include_with_prefix(name):
    if (include_prefix is None):
      return '#include "%s.hpp"' % name
    return '#include <%s/%s.hpp>' % (include_prefix, name)
  #
  need_using_major_types = False
  if (need_function_hpp):
    callback(include_with_prefix("functions"))
  elif (separate_cmn_hpp):
    callback(include_with_prefix("cmn"))
  else:
    callback(include_fem_hpp)
    need_using_major_types = True
  callback("")
  if (not need_function_hpp):
    if (include_separate(callback=callback)):
      callback("")
  open_namespace(
    callback=callback,
    namespace=namespace,
    using_namespace_major_types=need_using_major_types)
  #
  topological_fprocs = all_fprocs.build_bottom_up_fproc_list_following_calls(
    top_procedures=top_procedures)
  missing = topological_fprocs.missing_external_fdecls_by_identifier
  if (len(missing) != 0):
    for identifier in sorted(missing.keys()):
      if (identifier in ignore_missing):
        continue
      return_type = get_missing_external_return_type(
        fdecls=missing[identifier])
      callback("""
%s
%s(...)
{
  throw std::runtime_error(
    "Missing function implementation: %s");
}""" % (return_type, identifier, identifier))
  #
  dep_cycles = topological_fprocs.dependency_cycles
  if (len(dep_cycles) != 0):
    callback("")
    callback("/* Dependency cycles: %d" % len(dep_cycles))
    for cycle in dep_cycles:
      callback("     " + " ".join(cycle))
    callback(" */")
  #
  if (dynamic_parameters is not None):
    assert len(dynamic_parameters) != 0
    for fproc in topological_fprocs.bottom_up_list:
      for dp_props in dynamic_parameters:
        fdecl = fproc.fdecl_by_identifier.get(dp_props.name)
        if (fdecl is not None):
          fproc.dynamic_parameters.add(dp_props.name)
  #
  if (separate_cmn_hpp):
    cmn_buffer = []
    cmn_callback = cmn_buffer.append
    include_guard(
      callback=cmn_callback, namespace=namespace, suffix="_CMN_HPP")
    cmn_callback(include_fem_hpp)
    cmn_callback("")
    open_namespace(callback=cmn_callback, namespace=namespace)
  elif (suppress_common):
    def cmn_callback(line): pass
  else:
    cmn_callback = callback
  try:
    converted_commons_info = convert_commons(
      callback=cmn_callback,
      separate_cmn_hpp=separate_cmn_hpp,
      topological_fprocs=topological_fprocs,
      dynamic_parameters=dynamic_parameters,
      common_equivalence_simple=common_equivalence_simple,
      common_report_stringio=common_report_stringio)
  except Exception:
    if (not debug): raise
    show_traceback()
    common_commons_info = None
  if (separate_cmn_hpp):
    close_namespace(callback=cmn_callback, namespace=namespace, hpp_guard=True)
    with open("cmn.hpp", "w") as f:
      print("\n".join(break_lines(cpp_text=cmn_buffer)), file=f)
  #
  separate_function_buffers = []
  separate_function_buffer_by_function_name = {}
  for name,identifiers in separate_files_main_namespace.items():
    if (len(identifiers) == 0):
      raise RuntimeError(
        "separate_files_main_namespace: empty list: %s" % name)
    buffer = []
    buffer.append(include_with_prefix("functions"))
    buffer.append("")
    separate_function_buffers.append((name, buffer))
    open_namespace(callback=buffer.append, namespace=namespace)
    for identifier in identifiers:
      if (identifier in separate_function_buffer_by_function_name):
        raise RuntimeError(
          "separate_files_main_namespace:"
          " ambiguous assignment: %s" % identifier)
      separate_function_buffer_by_function_name[identifier] = buffer
  #
  separate_namespaces = {}
  separate_namespaces_buffers = {}
  for name,identifiers in separate_files_separate_namespace.items():
    if (len(identifiers) == 0):
      raise RuntimeError(
        "separate_files_separate_namespace: empty list: %s" % name)
    buffers = hpp_cpp_buffers()
    for ext in ["hpp", "cpp"]:
      buffer = getattr(buffers, ext)
      if (ext == "hpp"):
        include_guard(callback=buffer.append, namespace=name, suffix="_HPP")
        buffer.append(include_fem_hpp)
      else:
        buffer.append('#include "%s.hpp"' % name)
      buffer.append("")
      open_namespace(callback=buffer.append, namespace=name)
    for identifier in identifiers:
      if (identifier in separate_namespaces):
        raise RuntimeError(
          "separate_files_separate_namespace:"
          " ambiguous assignment: %s" % identifier)
      separate_namespaces[identifier] = name
      separate_namespaces_buffers[identifier] = buffers
  #
  if (not need_function_hpp):
    function_declarations = None
    function_definitions = None
  else:
    function_declarations = []
    function_definitions = []
  #
  global_conv_info = global_conversion_info(
    topological_fprocs=topological_fprocs,
    dynamic_parameters=dynamic_parameters,
    fortran_file_comments=fortran_file_comments,
    fem_do_safe=fem_do_safe,
    arr_nd_size_max=arr_nd_size_max,
    inline_all=inline_all,
    converted_commons_info=converted_commons_info,
    separate_namespaces=separate_namespaces,
    data_values_block_size=data_values_block_size,
    data_specializations=data_specializations)
  #
  for fproc in topological_fprocs.bottom_up_list:
    if (fproc.is_program()):
      continue
    if (fproc.name.value in suppress_functions):
      continue
    hpp_callback = None
    cpp_callback = None
    suppress_cpp = (fproc.name.value in suppress_function_definitions)
    buffers = separate_namespaces_buffers.get(fproc.name.value)
    if (buffers is None):
      if (not need_function_hpp):
        if (not suppress_cpp):
          cpp_callback = callback
      else:
        function_hpp_buffer = []
        function_declarations.append(function_hpp_buffer)
        hpp_callback = function_hpp_buffer.append
        if (not suppress_cpp):
          buffer = separate_function_buffer_by_function_name.get(
            fproc.name.value)
          if (buffer is None):
            if (number_of_function_files is None):
              cpp_callback = callback
            else:
              function_cpp_buffer = []
              function_definitions.append(function_cpp_buffer)
              cpp_callback = function_cpp_buffer.append
          else:
            cpp_callback = buffer.append
    else:
      hpp_callback = buffers.hpp.append
      if (not suppress_cpp):
        cpp_callback = buffers.cpp.append
    if (cpp_callback is None):
      cpp_diverted = []
      cpp_callback = cpp_diverted.append
      if (hpp_callback is None):
        hpp_callback = callback
    if (not need_function_hpp):
      fwds = topological_fprocs.forward_uses_by_identifier.get(
        fproc.name.value)
      if (fwds is not None):
        for fwd_identifier in fwds:
          fwd_fproc = all_fprocs.fprocs_by_name()[fwd_identifier]
          try:
            convert_to_cpp_function(
              hpp_callback=None,
              cpp_callback=cpp_callback,
              conv_info=global_conv_info.specialized(fproc=fwd_fproc),
              declaration_only=True)
          except Exception:
            if (not debug): raise
            show_traceback()
    try:
      convert_to_cpp_function(
        hpp_callback=hpp_callback,
        cpp_callback=cpp_callback,
        conv_info=global_conv_info.specialized(fproc=fproc),
        force_not_implemented=(fproc.name.value in force_not_implemented))
    except Exception:
      if (not debug): raise
      show_traceback()
  #
  for name,buffer in separate_function_buffers:
    close_namespace(
      callback=buffer.append, namespace=namespace, hpp_guard=False)
    if (write_separate_files_main_namespace == "All"
          or name in write_separate_files_main_namespace):
      with open(name+".cpp", "w") as f:
        print("\n".join(break_lines(cpp_text=buffer)), file=f)
  #
  for name,identifiers in separate_files_separate_namespace.items():
    buffers = separate_namespaces_buffers[identifiers[0]]
    for ext in ["hpp", "cpp"]:
      buffer = getattr(buffers, ext)
      close_namespace(
        callback=buffer.append, namespace=name, hpp_guard=(ext=="hpp"))
      if (write_separate_files_separate_namespace == "All"
            or name in write_separate_files_separate_namespace):
        with open(name+"."+ext, "w") as f:
          print("\n".join(break_lines(cpp_text=buffer)), file=f)
  #
  if (function_declarations is not None):
    def write_functions(buffers, serial=None):
      if (buffers is function_declarations):
        assert serial is None
        fn = "functions.hpp"
      elif (serial is None):
        fn = "functions.cpp"
      else:
        fn = "functions_%03d.cpp" % serial
      f = open(fn, "w")
      def fcb(line): print(line, file=f)
      if (buffers is function_declarations):
        include_guard(
          callback=fcb, namespace=namespace, suffix="_FUNCTIONS_HPP")
        fcb(include_with_prefix("cmn"))
        include_separate(callback=fcb)
      else:
        fcb(include_with_prefix("functions"))
      fcb("")
      open_namespace(
        callback=fcb, namespace=namespace, using_namespace_major_types=False)
      for lines in buffers:
        for line in break_lines(cpp_text=lines): fcb(line)
      close_namespace(
        callback=fcb,
        namespace=namespace,
        hpp_guard=(buffers is function_declarations))
      f.close()
    write_functions(function_declarations)
    if (function_definitions is not None and len(function_definitions) != 0):
      buffer_blocks = create_buffer_blocks(
        target_number_of_blocks=number_of_function_files,
        buffers=function_definitions)
      if (len(buffer_blocks) == 1):
        write_functions(buffers=buffer_blocks[0])
      else:
        serial = 0
        for buffers in buffer_blocks:
          serial += 1
          write_functions(buffers=buffers, serial=serial)
  #
  hpp_guard = (include_guard_suffix is not None)
  if (suppress_program):
    close_namespace(
      callback=callback, namespace=namespace, hpp_guard=hpp_guard)
  else:
    try:
      convert_program(
        callback=callback,
        global_conv_info=global_conv_info,
        namespace=namespace,
        hpp_guard=hpp_guard,
        debug=debug)
    except Exception:
      if (not debug): raise
      show_traceback()
  #
  if (top_cpp_file_name is not None):
    with open(top_cpp_file_name, "w") as f:
      print("\n".join(result), file=f)
  #
  return result


 *******************************************************************************


 *******************************************************************************
fable/equivalence.py
from __future__ import absolute_import, division, print_function
from six.moves import range
def array_alignment(members_size, i_mbr_byte_offset_pairs):
  n = members_size
  diff_matrix = [None] * (n*(n-1))
  msg_prefix = "equivalence.array_alignment(): "
  msg_directly_conflicting = msg_prefix + "directly conflicting input"
  for p0,p1 in i_mbr_byte_offset_pairs:
    i0,a0 = p0
    i1,a1 = p1
    if (i0 == i1):
      if (a0 != a1):
        raise RuntimeError(msg_directly_conflicting)
    else:
      if (i0 < i1):
        i = i0 * n + i1
        d = a0 - a1
      else:
        i = i1 * n + i0
        d = a1 - a0
      dd = diff_matrix[i]
      if (dd is None):
        diff_matrix[i] = d
      elif (dd != d):
        raise RuntimeError(msg_directly_conflicting)
  cluster_indices = list(range(n))
  clusters = []
  for i in range(n):
    clusters.append([])
  for i0 in range(n-1):
    for i1 in range(i0+1,n):
      i = i0 * n + i1
      d = diff_matrix[i]
      if (d is not None):
        ci0 = cluster_indices[i0]
        ci1 = cluster_indices[i1]
        if (ci0 == ci1):
          continue
        if (ci0 > ci1):
          ci0, ci1 = ci1, ci0
          d *= -1
          i0, i1 = i1, i0
        if (ci1 != i1):
          continue
        c0 = clusters[ci0]
        c1 = clusters[ci1]
        if (ci0 != i0):
          for i,o in c0:
            if (i == i0):
              d += o
              break
        c0.append((ci1, d))
        cluster_indices[ci1] = ci0
        for i,o in c1:
          c0.append((i, o+d))
          cluster_indices[i] = ci0
        clusters[ci1] = []
  if (cluster_indices.count(0) != n):
    raise RuntimeError(msg_prefix + "insufficient input")
  assert len(clusters[0]) == n-1
  diffs0 = [None] * n
  diffs0[0] = 0
  for i,o in clusters[0]:
    assert i != 0
    assert diffs0[i] is None
    diffs0[i] = o
  for i0 in range(n-1):
    for i1 in range(i0+1,n):
      i = i0 * n + i1
      d = diff_matrix[i]
      if (    d is not None
          and diffs0[i1] - diffs0[i0] != d):
        raise RuntimeError(msg_prefix + "indirectly conflicting input")
  return diffs0

class cluster_unions(object):

  __slots__ = ["unions", "indices"]

  def __init__(O):
    O.unions = []
    O.indices = {}

  def add(O, key_cluster):
    curr_index = None
    for key in key_cluster:
      prev_index = O.indices.get(key)
      if (curr_index is None):
        if (prev_index is None):
          O.indices[key] = curr_index = len(O.unions)
          O.unions.append([key])
        else:
          curr_index = prev_index
      elif (prev_index is None):
        O.indices[key] = curr_index
        O.unions[curr_index].append(key)
      elif (prev_index != curr_index):
        if (prev_index < curr_index):
          curr_index, prev_index = prev_index, curr_index
        for key in O.unions[prev_index]:
          O.indices[key] = curr_index
          O.unions[curr_index].append(key)
        O.unions[prev_index] = None

  def tidy(O):
    unions = []
    indices = {}
    for union in O.unions:
      if (union is not None):
        for key in union:
          indices[key] = len(unions)
        unions.append(union)
    O.unions = unions
    O.indices = indices


 *******************************************************************************


 *******************************************************************************
fable/intrinsics.py
from __future__ import absolute_import, division, print_function
set_lower = set("""\
abs
acos
aimag
aint
alog
alog10
amax0
amax1
amin0
amin1
amod
anint
asin
atan
atan2
cabs
cdabs
char
cmplx
conjg
cos
cosh
dabs
dacos
dasin
datan2
dble
dcmplx
dconjg
dcos
dexp
dim
dimag
dlog
dlog10
dmax1
dmin1
dprod
dsign
dsin
dsqrt
dtan
exp
float
iabs
iargc
iand
ichar
idnint
index
int
ishft
isign
len
len_trim
lge
lgt
lle
llt
lnblnk
log
log10
max
max0
max1
maxloc
min
min0
min1
mod
nint
real
sign
sin
sinh
sngl
sqrt
system
tan
tanh
transfer
""".splitlines())

extra_set_lower = set("""\
cpu_time
date
getarg
getenv
time
""".splitlines())

io_set_lower = set("""\
flush
""".splitlines())

is_modified_info_by_name = {
  "cpu_time": (0,),
  "date": (0,),
  "getarg": (1,),
  "getenv": (1,),
  "time": (0,)
}


 *******************************************************************************


 *******************************************************************************
fable/read.py
from __future__ import absolute_import, division, print_function
from six.moves import range
from fable \
  import unsigned_integer_scan, \
  identifier_scan, \
  find_closing_parenthesis, \
  SemanticError
from fable import tokenization
from fable import intrinsics
from fable import equivalence
from fable import utils
import sys
from six.moves import zip

class Error(Exception): pass

class raise_errors_mixin(object):

  __slots__ = []

  def text_location(O, i):
    sl, i = O.stmt_location(i)
    if (i is not None and sl.stmt_offs is not None):
      i += sl.stmt_offs
    return sl, i

  def format_error(O, i, msg, prefix=""):
    sl, i = O.stmt_location(i)
    from libtbx.str_utils import expandtabs_track_columns
    t, js = expandtabs_track_columns(s=sl.text)
    if (i is None):
      ptr = ""
    else:
      if (i < 0):
        j = -i - 1
        t += " " * (j - len(t) + 1)
      else:
        j = js[sl.stmt_offs + i]
      ptr = "\n" + "-"*(3+j) + "^"
    if (msg is None): intro = ""
    else:             intro = "%s:\n  at " % msg
    result = "%s%s:\n  |%s|%s" % (
      intro, sl.format_file_name_and_line_number(), t, ptr)
    if (prefix is None or prefix == ""):
      return result
    return "\n".join([(prefix + line).rstrip()
      for line in result.splitlines()])

  def raise_error(O, msg, i=None, ErrorType=None):
    if (ErrorType is None): ErrorType = Error
    raise ErrorType(O.format_error(i=i, msg=msg))

  def raise_syntax_error(O, i=None):
    O.raise_error(msg="Syntax error", i=i)

  def raise_syntax_error_or_not_implemented(O, i=None):
    O.raise_error(msg="Syntax error or not implemented", i=i)

  def raise_semantic_error(O, msg=None, i=None):
    O.raise_error(msg=msg, i=i, ErrorType=SemanticError)

  def raise_internal_error(O, i=None):
    O.raise_error(
      msg="Sorry: fable internal error", i=i, ErrorType=AssertionError)

class source_line(raise_errors_mixin):

  __slots__ = [
    "global_line_index",
    "file_name",
    "line_number",
    "text",
    "label",
    "stmt",
    "stmt_offs",
    "is_cont",
    "index_of_exclamation_mark"]

  def format_file_name_and_line_number(O):
    return "%s(%d)" % (O.file_name, O.line_number)

  def stmt_location(O, i):
    return O, i

  def __init__(O, global_line_index_generator, file_name, line_number, text):
    O.global_line_index = next(global_line_index_generator)
    O.file_name = file_name
    O.line_number = line_number
    O.text = text
    O.label = None
    O.stmt = ""
    O.stmt_offs = None
    i = text.find("\t", 0, 6)
    if (i >= 0):
      soff = i + 1
      O.is_cont = False
      l = text[:i].strip()
      s = text[soff:72]
    else:
      soff = 6
      c = text[5:6]
      O.is_cont = (c != " " and c != "\t" and c != "")
      l = text[:5].strip()
      s = text[6:72]
    if (len(l) == 0):
      if (len(s) != 0):
        O.stmt = s
        O.stmt_offs = soff
    else:
      i = unsigned_integer_scan(code=l)
      if (i < 0 or i != len(l)):
        O.is_cont = False
      else:
        if (O.is_cont):
          O.raise_error(
            msg="A continuation character is illegal on a line with"
                " a statement label",
            i=-6)
        O.label = l
        if (len(s) == 0):
          O.raise_error(msg="Labelled statement is empty", i=-7)
        O.stmt = s
        O.stmt_offs = soff
    if (not O.is_cont and len(O.stmt.rstrip()) == 0):
      O.stmt_offs = None
    O.index_of_exclamation_mark = None

class stripped_source_line(raise_errors_mixin):

  __slots__ = [
    "source_line_cluster",
    "label",
    "code0_locations",
    "start",
    "code",
    "strings",
    "strings_locs",
    "string_indices"]

  def __init__(O,
        source_line_cluster,
        code0_locations,
        code,
        start,
        strings,
        strings_locs,
        string_indices):
    if (source_line_cluster is None):
      assert code0_locations is None
    else:
      assert len(source_line_cluster) != 0
      assert len(code0_locations) >= start + len(code)
    assert len(strings) == len(string_indices)
    O.source_line_cluster = source_line_cluster
    O.label = None
    for sl in O.source_line_cluster:
      if (sl.label is not None):
        O.label = sl.label
        break
    O.code0_locations = code0_locations
    O.start = start
    O.code = code
    O.strings = strings
    O.strings_locs = strings_locs
    O.string_indices = string_indices

  def code_with_strings(O):
    result = []
    j = 0
    for c in O.code:
      if (c == "'"):
        result.append("'" + O.strings[j].replace("'","''") + "'")
        j += 1
      else:
        result.append(c)
    assert j == len(O.strings)
    return "".join(result)

  def stmt_location(O, i):
    if (i is None):
      return O.source_line_cluster[0], None
    if (i < 0):
      return O.source_line_cluster[0], i
    return O.code0_locations[O.start + i]

  def is_comment(O):
    return (O.source_line_cluster[0].stmt_offs is None)

  def __getitem__(O, key):
    if (isinstance(key, slice)):
      start, stop, step = key.indices(len(O.code))
      assert step == 1
      del step
    else:
      start = key
      stop = key + 1
    slice_strings = []
    slice_strings_locs = []
    slice_string_indices = []
    for s,locs,si in zip(O.strings, O.strings_locs, O.string_indices):
      if (si < start): continue
      if (si >= stop): break
      slice_strings.append(s)
      slice_strings_locs.append(locs)
      slice_string_indices.append(si-start)
    return stripped_source_line_slice(
      source_line_cluster=O.source_line_cluster,
      code0_locations=O.code0_locations,
      start=O.start+start,
      code=O.code[key],
      strings=slice_strings,
      strings_locs=slice_strings_locs,
      string_indices=slice_string_indices)

  def raise_if_not_identifier(O):
    i = identifier_scan(code=O.code)
    if (i < 0 or i != len(O.code)):
      O.raise_error("Not an identifier: %s" % repr(O.code), i=0)

  def extract_identifier(O):
    O.raise_if_not_identifier()
    return O.code

  def index_of_closing_parenthesis(O, start=0):
    i = find_closing_parenthesis(code=O.code, start=start)
    if (i < 0):
      O.raise_error(msg='Missing a closing ")"', i=max(0, start-1))
    return i

  def comma_scan(O, start=0):
    code = O.code
    n = len(code)
    i = start
    while (i < n):
      c = code[i]
      if (c == ","):
        return i
      i += 1
      if (c == "("):
        i = O.index_of_closing_parenthesis(start=i) + 1
    return -1

def get_hollerith_count_index(code):
  i = len(code)
  while (i != 0):
    i -= 1
    c = code[i]
    digit = "0123456789".find(c)
    if (digit < 0):
      if (i+1 == len(code)):
        return None
      if (",(/$".find(c) >= 0):
        return i+1
      return None
  return None

class stripped_source_line_slice(stripped_source_line):

  __slots__ = stripped_source_line.__slots__

def strip_spaces_separate_strings(source_line_cluster):
  code = []
  locs = []
  strings = []
  strings_locs = []
  string_indices = []
  ca = code.append
  la = locs.append
  n_sl = len(source_line_cluster)
  i_sl = 0
  while (i_sl < n_sl):
    sl = source_line_cluster[i_sl]
    s = sl.stmt
    n = len(s)
    i = 0
    while (i < n):
      c = s[i]
      if (c == "!"):
        sl.index_of_exclamation_mark = i
        break
      if (c == "'" or c == '"'):
        opening_quote = c
        string_indices.append(len(code))
        ca("'")
        la((sl,i))
        i += 1
        string_chars = []
        string_chars_locs = []
        in_string = True
        while in_string:
          while (i < n):
            c = s[i]
            ci = i
            i += 1
            if (c == opening_quote):
              if (not s.startswith(opening_quote, i)):
                in_string = False
                break
              i += 1
            string_chars.append(c)
            string_chars_locs.append((sl,ci))
          else:
            i_sl += 1
            if (i_sl == n_sl):
              locs[-1][0].raise_error(
                msg="Missing terminating %s character" % opening_quote,
                i=locs[-1][1])
            sl = source_line_cluster[i_sl]
            s = sl.stmt
            n = len(s)
            i = 0
        strings.append("".join(string_chars))
        strings_locs.append(string_chars_locs)
      elif (" \t".find(c) < 0):
        c = c.lower()
        if (c == 'h'):
          j = get_hollerith_count_index(code)
        else:
          j = None
        if (j is None):
          ca(c.lower())
          la((sl,i))
          i += 1
        else:
          hollerith_count = int("".join(code[j:]))
          del code[j:]
          del locs[j:]
          string_indices.append(len(code))
          ca("'")
          la((sl,i))
          i += 1
          string_chars = []
          string_chars_locs = []
          while True:
            if (i < n):
              string_chars.append(s[i])
              string_chars_locs.append((sl,i))
              i += 1
              if (len(string_chars) == hollerith_count):
                break
            else:
              i_sl += 1
              if (i_sl == n_sl):
                break
              sl = source_line_cluster[i_sl]
              s = sl.stmt
              n = len(s)
              i = 0
          if (len(string_chars) != hollerith_count):
            locs[-1][0].raise_error(
              msg="Missing characters for Hollerith constant",
              i=locs[-1][1])
          strings.append("".join(string_chars))
          strings_locs.append(string_chars_locs)
      else:
        i += 1
    i_sl += 1
  return stripped_source_line(
    source_line_cluster=source_line_cluster,
    code0_locations=locs,
    code="".join(code),
    start=0,
    strings=strings,
    strings_locs=strings_locs,
    string_indices=string_indices)

class fmt_string_stripped(raise_errors_mixin):

  __slots__ = ["code", "locs", "strings", "strings_locs", "string_indices"]

  def __init__(O, fmt_tok):
    ssl = fmt_tok.ssl
    i = ssl.string_indices.index(fmt_tok.i_code)
    fmt_string = ssl.strings[i]
    fmt_string_locs = ssl.strings_locs[i]
    assert len(fmt_string) == len(fmt_string_locs)
    code = []
    O.locs = []
    O.strings = []
    O.strings_locs = []
    O.string_indices = []
    ca = code.append
    la = O.locs.append
    n = len(fmt_string)
    have_leading_parenthesis = False
    i = 0
    while (i < n):
      c = fmt_string[i]
      loc = fmt_string_locs[i]
      if (c == "'" or c == '"'):
        if (not have_leading_parenthesis):
          raise_must_start()
        opening_quote = c
        O.string_indices.append(len(code))
        ca("'")
        la(loc)
        i += 1
        string_chars = []
        string_chars_locs = []
        in_string = True
        while in_string:
          while (i < n):
            c = fmt_string[i]
            loc = fmt_string_locs[i]
            i += 1
            if (c == opening_quote):
              if (not fmt_string.startswith(opening_quote, i)):
                in_string = False
                break
              i += 1
            string_chars.append(c)
            string_chars_locs.append(loc)
          else:
            loc = O.locs[-1]
            loc[0].raise_error(
              msg='Missing terminating %s within character format'
                  ' specifier "%s"' % (opening_quote, fmt_string),
              i=loc[1])
        O.strings.append("".join(string_chars))
        O.strings_locs.append(string_chars_locs)
      else:
        if (" \t".find(c) < 0):
          if (have_leading_parenthesis):
            ca(c.lower())
            la(loc)
          else:
            if (c != "("):
              raise_must_start()
            have_leading_parenthesis = True
        i += 1
    def raise_must_start():
      fmt_tok.raise_error(msg='Format string must start with "("')
    def raise_must_end():
      fmt_tok.raise_error(msg='Format string must end with ")"')
    if (len(code) == 0):
      if (have_leading_parenthesis):
        raise_must_end()
      raise_must_start()
    elif (code[-1] != ")"):
      raise_must_end()
    code.pop()
    O.locs.pop()
    O.code = "".join(code)

  def stmt_location(O, i):
    if (i is None): i = 0
    return O.locs[i]

def combine_continuation_lines_and_strip_spaces(source_lines):
  result = []
  rapp = result.append
  n_sl = len(source_lines)
  i_sl = 0
  while (i_sl < n_sl):
    sl = source_lines[i_sl]
    if (sl.stmt_offs is None):
      rapp(strip_spaces_separate_strings(source_line_cluster=[sl]))
      i_sl += 1
    else:
      assert not sl.is_cont
      code_sls = [sl]
      k_sl = i_sl
      for j_sl in range(i_sl+1, n_sl):
        sl = source_lines[j_sl]
        if (sl.is_cont):
          code_sls.append(sl)
          k_sl = j_sl
        elif (sl.stmt_offs is not None):
          break
      for j_sl in range(i_sl+1, k_sl):
        sl = source_lines[j_sl]
        if (not sl.is_cont):
          rapp(strip_spaces_separate_strings(source_line_cluster=[sl]))
      rapp(strip_spaces_separate_strings(source_line_cluster=code_sls))
      i_sl = k_sl + 1
  return result

def load_includes(global_line_index_generator, stripped_source_lines):
  import os.path as op
  result = []
  for ssl in stripped_source_lines:
    if (ssl.code == "include'"):
      assert len(ssl.strings) == 1
      file_name = ssl.strings[0]
      if (op.isabs(file_name)):
        file_path = file_name
      else:
        sl = ssl.code0_locations[-1][0]
        file_path = op.join(op.dirname(sl.file_name), file_name)
      if (not op.isfile(file_path)):
        ssl.raise_semantic_error(msg="Missing include file", i=7)
      # TODO potential performance problem if deeply nested includes
      result.extend(load(
        global_line_index_generator=global_line_index_generator,
        file_name=file_path))
    else:
      result.append(ssl)
  return result

def load(global_line_index_generator, file_name, skip_load_includes=False):
  source_lines = []
  with open(file_name) as f:
    lines = f.read().splitlines()
  for i_line,line in enumerate(lines):
    source_lines.append(source_line(
      global_line_index_generator=global_line_index_generator,
      file_name=file_name,
      line_number=i_line+1,
      text=line))
  stripped_source_lines = combine_continuation_lines_and_strip_spaces(
    source_lines=source_lines)
  if (skip_load_includes):
    return stripped_source_lines
  return load_includes(
    global_line_index_generator=global_line_index_generator,
    stripped_source_lines=stripped_source_lines)

def tokenize_expression(
      ssl,
      start=0,
      stop=None,
      allow_commas=False,
      allow_equal_signs=False):
  result = []
  if (stop is None): stop = len(ssl.code)
  tokenize_expression_impl(
    tokens=result,
    tokenizer=tokenization.ssl_iterator(ssl=ssl, start=start, stop=stop),
    allow_commas=allow_commas,
    allow_equal_signs=allow_equal_signs,
    tok_opening_parenthesis=None)
  return result

def tokenize_expression_impl(
      tokens,
      tokenizer,
      allow_commas,
      allow_equal_signs,
      tok_opening_parenthesis):
  from fable.tokenization import tk_seq, tk_parentheses
  if (allow_commas):
    tlist = []
    tokens.append(tk_seq(ssl=tokenizer.ssl, i_code=tokenizer.i, value=tlist))
  else:
    tlist = tokens
  tapp = tlist.append
  for tok in tokenizer:
    if (tok.is_op()):
      tv = tok.value
      if (tv == "("):
        nested_tokens = []
        tokenize_expression_impl(
          tokens=nested_tokens,
          tokenizer=tokenizer,
          allow_commas=True,
          allow_equal_signs=allow_equal_signs,
          tok_opening_parenthesis=tok)
        tapp(tk_parentheses(
          ssl=tok.ssl, i_code=tok.i_code, value=nested_tokens))
        continue
      if (tv == ")"):
        if (tok_opening_parenthesis is None):
          tok.raise_missing_opening()
        return
      if (tv == ","):
        if (not allow_commas):
          tok.ssl.raise_syntax_error(i=tok.i_code)
        tlist = []
        tokens.append(tk_seq(
          ssl=tokenizer.ssl, i_code=tokenizer.i, value=tlist))
        tapp = tlist.append
        continue
      if (tv == "="):
        if (not allow_equal_signs):
          tok.ssl.raise_syntax_error(i=tok.i_code)
        tapp(tok)
        continue
    tapp(tok)
    continue
  if (tok_opening_parenthesis is not None):
    tok_opening_parenthesis.raise_missing_closing()

def indices_of_tokenized_equal_signs(tokens):
  result = []
  for i,tok in enumerate(tokens):
    if (tok.is_op() and tok.value == "="):
      result.append(i)
  return result

# variable types
class vt_used(object): pass
class vt_scalar(object): pass
class vt_string(object): pass
class vt_array(object): pass
class vt_intrinsic(object): pass
class vt_external(object): pass
class vt_function(object): pass
class vt_subroutine(object): pass

# variable storage
class vs_fproc_name(object): pass
class vs_argument(object): pass
class vs_common(object): pass
class vs_save(object): pass
class vs_local(object): pass
class vs_parameter(object): pass

class fdecl_info(object):

  __slots__ = [
    "id_tok",
    "var_type",
    "var_storage",
    "data_type",
    "size_tokens",
    "dim_tokens",
    "parameter_assignment_tokens",
    "f90_decl",
    "is_modified",
    "use_count",
    "passed_as_arg",
    "passed_as_arg_plain"]

  def __init__(O,
        id_tok,
        var_type,
        var_storage,
        data_type,
        size_tokens,
        dim_tokens,
        f90_decl=None):
    assert size_tokens is None or isinstance(size_tokens, list)
    assert dim_tokens is None or isinstance(dim_tokens, list)
    O.id_tok = id_tok
    O.var_type = var_type
    O.var_storage = var_storage
    O.data_type = data_type
    O.size_tokens = size_tokens
    O.dim_tokens = dim_tokens
    O.parameter_assignment_tokens = None
    O.f90_decl = f90_decl
    O.is_modified = False
    O.use_count = 0
    O.passed_as_arg = {}
    O.passed_as_arg_plain = {}

  def is_used(O): return O.var_type is vt_used
  def is_scalar(O): return O.var_type is vt_scalar
  def is_string(O): return O.var_type is vt_string
  def is_array(O): return O.var_type is vt_array
  def is_intrinsic(O): return O.var_type is vt_intrinsic
  def is_external(O): return O.var_type is vt_external
  def is_function(O): return O.var_type is vt_function
  def is_subroutine(O): return O.var_type is vt_subroutine
  def is_user_defined_callable(O):
    vt = O.var_type
    return (vt is vt_external or vt is vt_function or vt is vt_subroutine)

  def is_fproc_name(O): return O.var_storage is vs_fproc_name
  def is_argument(O): return O.var_storage is vs_argument
  def is_common(O): return O.var_storage is vs_common
  def is_save(O): return O.var_storage is vs_save
  def is_local(O): return O.var_storage is vs_local
  def is_parameter(O): return O.var_storage is vs_parameter

  def required_parameter_assignment_tokens(O):
    result = O.parameter_assignment_tokens
    if (result is None):
      O.id_tok.raise_internal_error()
    return result

def extract_size_tokens(ssl, start):
  code = ssl.code
  c = code[start]
  if (c == "("):
    i_clp = ssl.index_of_closing_parenthesis(start=start+1)
    return i_clp+1, tokenize_expression(
      ssl=ssl,
      start=start+1,
      stop=i_clp)
  i_size = unsigned_integer_scan(code=code, start=start)
  if (i_size < 0):
    ssl.raise_syntax_error(i=start)
  return \
    i_size, \
    [tokenization.tk_integer(ssl=ssl, i_code=start, value=code[start:i_size])]

data_types = """\
byte
character
complex
doublecomplex
doubleprecision
integer
logical
real
""".splitlines()

def extract_data_type(ssl, start=0, optional=False):
  sw = ssl.code.startswith
  for data_type in data_types:
    if (sw(data_type, start)):
      return (
        start + len(data_type),
        tokenization.tk_identifier(ssl=ssl, i_code=start, value=data_type))
  if (not optional):
    ssl.raise_syntax_error()
  return None, None

def extract_data_type_and_size(ssl, start=0, optional=False):
  i_code, data_type = extract_data_type(
    ssl=ssl, start=start, optional=optional)
  if (optional and i_code is None):
    return None, None, None
  if (not ssl.code.startswith("*", i_code)):
    return i_code, data_type, None
  i_code, size_tokens = extract_size_tokens(ssl=ssl, start=i_code+1)
  return i_code, data_type, size_tokens

def extract_f90_decl(ssl, start):
  code = ssl.code
  if (start == len(code)):
    ssl.raise_syntax_error(i=start)
  i_cc = code.find("::", start)
  if (i_cc >= 0):
    return i_cc+2, ssl[start:i_cc]
  if (code.startswith("(", start)):
    i_clp = ssl.index_of_closing_parenthesis(start=start+1)
    return i_clp+1, ssl[start+1:i_clp]
  return start, None

def extract_fdecl(
      result,
      ssl,
      start,
      data_type,
      size_tokens,
      allow_size,
      f90_decl=None):
  code = ssl.code
  stop = len(code)
  def parse_decl(start):
    item_size_tokens = None
    dim_tokens = None
    i_id = identifier_scan(code=code, start=start)
    if (i_id < 0):
      ssl.raise_syntax_error(i=start)
    i_code = i_id
    while True:
      if (i_code == stop):
        break
      c = code[i_code]
      if (c == ","):
        i_code += 1
        break
      if (c == "("):
        if (dim_tokens is not None):
          ssl.raise_syntax_error(i=i_code)
        i_clp = ssl.index_of_closing_parenthesis(start=i_code+1)
        dim_tokens = tokenize_expression(
          ssl=ssl,
          start=i_code+1,
          stop=i_clp,
          allow_commas=True)
        i_code = i_clp + 1
      elif (c == "*"):
        if (not allow_size or item_size_tokens is not None):
          ssl.raise_syntax_error(i=i_code)
        i_code, item_size_tokens = extract_size_tokens(ssl=ssl, start=i_code+1)
      else:
        ssl.raise_syntax_error(i=i_code)
    if (item_size_tokens is None):
      item_size_tokens = size_tokens
    result.append(fdecl_info(
      id_tok=tokenization.tk_identifier(
        ssl=ssl, i_code=start, value=code[start:i_id]),
      var_type=None,
      var_storage=None,
      data_type=data_type,
      size_tokens=item_size_tokens,
      dim_tokens=dim_tokens,
      f90_decl=f90_decl))
    return i_code
  if (ssl.code.startswith(",", start)):
    start += 1
  while (start < stop):
    start = parse_decl(start=start)

def dimensions_are_simple(dim_tokens):
  is_star = tokenization.tok_seq_is_star
  for tok_seq in dim_tokens:
    if (is_star(tok_seq=tok_seq)):
      return False
    for tok in tok_seq.value:
      if (tok.is_op_with(value=":")):
        return False
  return True

def process_labels_list(ssl, start, stop, len_min, len_max):
  if (start == stop):
    ssl.raise_syntax_error(i=start)
  result = []
  code = ssl.code
  i = start
  while True:
    if (len_max is not None and len(result) >= len_max):
      ssl.raise_syntax_error(i=i)
    j = unsigned_integer_scan(code=code, start=i, stop=stop)
    if (j < 0):
      ssl.raise_syntax_error(i=i)
    result.append(
      tokenization.tk_integer(ssl=ssl, i_code=i, value=code[i:j]))
    if (j == stop):
      break
    if (code[j] != ","):
      ssl.raise_syntax_error(i=j)
    i = j + 1
  if (len(result) < len_min):
    ssl.raise_syntax_error(i=i)
  return result

class executable_info(object):

  __slots__ = []

  def __init__(O, **ks):
    O.key = O.__class__.__name__[3:]
    O.ssl = ks["ssl"]
    O.start = ks["start"]
    for k,v in ks.items():
      setattr(O, k, v)

  def s4it(O, callback, tokens):
    tokenization.search_for_id_tokens(
      callback=callback, tokens=tokens, with_next_token=True)

  def s4it_slots(O, callback, obj_with_slots):
    for s in obj_with_slots.__slots__:
      attr = getattr(obj_with_slots, s)
      if (attr is not None):
        O.s4it(callback, attr)

  def set_is_modified(O, fdecl_by_identifier):
    pass

def mksl(*names): return ("key", "ssl", "start") + names

class ei_allocate(executable_info):
  __slots__ = mksl()

  def search_for_id_tokens(O, callback):
    pass # TODO

class ei_assign(executable_info):
  __slots__ = mksl()

  def search_for_id_tokens(O, callback):
    pass # TODO

class ei_assignment(executable_info):
  __slots__ = mksl("lhs_tokens", "rhs_tokens")

  def search_for_id_tokens(O, callback):
    O.s4it(callback, O.lhs_tokens)
    O.s4it(callback, O.rhs_tokens)

  def set_is_modified(O, fdecl_by_identifier):
    assert len(O.lhs_tokens) != 0
    id_tok = O.lhs_tokens[0]
    if (not id_tok.is_identifier()):
      id_tok.raise_syntax_error()
    tf = fdecl_by_identifier.get(id_tok.value)
    assert tf is not None
    tf.is_modified = True

class ei_file_positioning(executable_info):
  __slots__ = mksl("io_function", "alist")

  def search_for_id_tokens(O, callback):
    if (O.alist is not None):
      O.s4it_slots(callback, O.alist)

class ei_call(executable_info):
  __slots__ = mksl("subroutine_name", "arg_token")

  def search_for_id_tokens(O, callback):
    callback(O.subroutine_name, O.arg_token)
    if (O.arg_token is not None):
      O.s4it(callback, O.arg_token.value)

class ei_close(executable_info):
  __slots__ = mksl("cllist")

  def search_for_id_tokens(O, callback):
    O.s4it_slots(callback, O.cllist)

class ei_continue(executable_info):
  __slots__ = mksl()

  def search_for_id_tokens(O, callback):
    pass

class ei_cycle(executable_info):
  __slots__ = mksl()

  def search_for_id_tokens(O, callback):
    pass

class ei_deallocate(executable_info):
  __slots__ = mksl()

  def search_for_id_tokens(O, callback):
    pass # TODO

class ei_do(executable_info):
  __slots__ = mksl("label", "id_tok", "tokens")

  def search_for_id_tokens(O, callback):
    callback(O.id_tok, None)
    O.s4it(callback, O.tokens)

  def set_is_modified(O, fdecl_by_identifier):
    fdecl = fdecl_by_identifier[O.id_tok.value]
    fdecl.is_modified = True

class ei_dowhile(executable_info):
  __slots__ = mksl("label", "cond_tokens")

  def search_for_id_tokens(O, callback):
    O.s4it(callback, O.cond_tokens)

class ei_else(executable_info):
  __slots__ = mksl()

  def search_for_id_tokens(O, callback):
    pass

class ei_elseif_then(executable_info):
  __slots__ = mksl("cond_tokens")

  def search_for_id_tokens(O, callback):
    O.s4it(callback, O.cond_tokens)

class ei_enddo(executable_info):
  __slots__ = mksl()

  def search_for_id_tokens(O, callback):
    pass

class ei_endif(executable_info):
  __slots__ = mksl()

  def search_for_id_tokens(O, callback):
    pass

class ei_entry(executable_info):
  __slots__ = mksl()

  def search_for_id_tokens(O, callback):
    pass # TODO

class ei_exit(executable_info):
  __slots__ = mksl()

  def search_for_id_tokens(O, callback):
    pass

class ei_goto(executable_info):
  __slots__ = mksl("label")

  def search_for_id_tokens(O, callback):
    pass

class ei_goto_computed(executable_info):
  __slots__ = mksl("labels", "tokens")

  def search_for_id_tokens(O, callback):
    O.s4it(callback, O.tokens)

class ei_if(executable_info):
  __slots__ = mksl("cond_tokens")

  def search_for_id_tokens(O, callback):
    O.s4it(callback, O.cond_tokens)

class ei_if_then(executable_info):
  __slots__ = mksl("cond_tokens")

  def search_for_id_tokens(O, callback):
    O.s4it(callback, O.cond_tokens)

class ei_if_arithmetic(executable_info):
  __slots__ = mksl("cond_tokens", "labels")

  def search_for_id_tokens(O, callback):
    O.s4it(callback, O.cond_tokens)

class ei_inquire(executable_info):
  __slots__ = mksl("iuflist")

  def search_for_id_tokens(O, callback):
    O.s4it_slots(callback, O.iuflist)

class ei_open(executable_info):
  __slots__ = mksl("olist")

  def search_for_id_tokens(O, callback):
    O.s4it_slots(callback, O.olist)

class ei_print(executable_info):
  __slots__ = mksl("cilist", "iolist", "fmt_tokens")

  def search_for_id_tokens(O, callback):
    O.s4it_slots(callback, O.cilist)
    O.s4it(callback, O.iolist)

class ei_read(executable_info):
  __slots__ = mksl("cilist", "iolist", "fmt_tokens")

  def search_for_id_tokens(O, callback):
    if (O.cilist is not None):
      O.s4it_slots(callback, O.cilist)
    if (O.iolist is not None):
      O.s4it(callback, O.iolist)

  def set_is_modified(O, fdecl_by_identifier):
    if (O.iolist is not None):
      def callback(tok):
        fdecl = fdecl_by_identifier[tok.value]
        fdecl.is_modified = True
      tokenization.search_for_data_or_read_target_tokens(
        callback=callback, tokens=O.iolist)

class ei_return(executable_info):
  __slots__ = mksl("return_label")

  def search_for_id_tokens(O, callback):
    pass

class ei_stop(executable_info):
  __slots__ = mksl("arg_token")

  def search_for_id_tokens(O, callback):
    pass

class ei_write(executable_info):
  __slots__ = mksl("cilist", "iolist", "fmt_tokens")

  def search_for_id_tokens(O, callback):
    O.s4it_slots(callback, O.cilist)
    O.s4it(callback, O.iolist)

  def set_is_modified(O, fdecl_by_identifier):
    if (    O.cilist is not None
        and O.cilist.unit is not None
        and len(O.cilist.unit) != 0):
      first_tok = O.cilist.unit[0]
      if (first_tok.is_identifier()):
        fdecl = fdecl_by_identifier[first_tok.value]
        if (    fdecl.data_type is not None
            and fdecl.data_type.value == "character"):
          fdecl.is_modified = True

del mksl

class fproc_p_methods(object):
  "Separated from class fproc for clarity and a minor getattr speed gain."

  __slots__ = []

  def p_allocate(O, ssl, start):
    O.executable.append(ei_allocate(ssl=ssl, start=start)) # TODO

  def p_assign(O, ssl, start):
    O.executable.append(ei_assign(ssl=ssl, start=start)) # TODO

  def p_file_positioning(O, ssl, start, io_function):
    liof = len(io_function)
    if (ssl.code.startswith("(", start+liof)):
      tz = tokenization.ssl_iterator(ssl=ssl, start=start+liof)
      alist = collect_io_alist(tz=tz, unit=None)
      if (alist.unit is None):
        ssl.raise_semantic_error(
          msg="Required UNIT information is not defined", i=start)
    else:
      alist = collect_io_alist(
        tz=None,
        unit=tokenize_expression(ssl=ssl, start=start+liof))
    O.executable.append(ei_file_positioning(
      ssl=ssl, start=start, io_function=io_function, alist=alist))

  def p_backspace(O, ssl, start):
    O.p_file_positioning(ssl=ssl, start=start, io_function="backspace")

  def p_call(O, ssl, start):
    tokens = tokenize_expression(ssl=ssl, start=start+4)
    if (   len(tokens) == 0
        or len(tokens) > 2
        or not tokens[0].is_identifier()):
      ssl.raise_syntax_error()
    subroutine_name = tokens[0]
    if (len(tokens) == 1):
      arg_token = None
    else:
      if (not tokens[1].is_parentheses()):
        ssl.raise_syntax_error()
      arg_token = tokens[1]
    O.executable.append(ei_call(ssl=ssl, start=start,
      subroutine_name=subroutine_name,
      arg_token=arg_token))

  def p_close(O, ssl, start):
    tz = tokenization.ssl_iterator(ssl=ssl, start=start+5)
    cllist = collect_io_cllist(tz=tz)
    tok = tz.look_ahead(optional=True)
    if (tok is not None):
      tok.raise_syntax_error()
    O.executable.append(ei_close(ssl=ssl, start=start, cllist=cllist))
    O.uses_io = True

  def p_common(O, ssl, start):
    assert start == 0
    code = ssl.code
    if (len(code) == 6):
      ssl.raise_syntax_error()
    c = code[6]
    if (c == "/"):
      i = code.find("/", 7)
      if (i < 0):
        ssl.raise_syntax_error_or_not_implemented()
      if (i == 7):
        common_name = "commonymous"
        i_code = 8
      else:
        common_name = ssl[7:i].extract_identifier()
        i_code = i + 1
    else:
      common_name = "commonymous"
      i_code = 6
    extract_fdecl(
      result=O.common.get(key=common_name),
      ssl=ssl,
      start=i_code,
      data_type=None,
      size_tokens=None,
      allow_size=False)

  def p_continue(O, ssl, start):
    O.executable.append(ei_continue(ssl=ssl, start=start))

  def p_cycle(O, ssl, start):
    if (len(ssl.code) != start+5):
      ssl.raise_syntax_error(i=start+5)
    O.executable.append(ei_cycle(ssl=ssl, start=start))

  def p_data(O, ssl, start):
    assert start == 0
    tz = tokenization.ssl_iterator(ssl=ssl, start=4)
    tok = None
    while True: # loop over nlist, clist pairs
      nlist = []
      while True:
        if (tok is None):
          tok = tz.get()
        if (tok.is_identifier()):
          ntoks = [tok]
          nlist.append(
            tokenization.tk_seq(ssl=tz.ssl, i_code=tz.i, value=ntoks))
          tok = tz.get()
          if (tok.is_op_with(value="(")):
            tz.collect_to_matching_parenthesis(
              callback=ntoks.append, opening_token=tok)
            tok = tz.get()
            if (tok.is_op_with(value="(")):
              tz.collect_to_matching_parenthesis(
                callback=ntoks.append, opening_token=tok)
              tok = tz.get()
        elif (tok.is_op_with(value="(")):
          ntoks = []
          nlist.append(
            tokenization.tk_seq(ssl=tz.ssl, i_code=tz.i, value=ntoks))
          ntoks.append(tz.get_implied_do(opening_token=tok))
          tok = tz.get()
        else:
          tok.raise_syntax_error()
        if (not tok.is_op_with(value=",")):
          break
        tok = None
      if (not tok.is_op_with(value="/")):
        tok.raise_syntax_error()
      clist = []
      repetition_tok = None
      sign_count = 0
      ctoks = []
      while True:
        tok = tz.get()
        if (    len(ctoks) == 0
            and repetition_tok is None
            and (tok.is_integer() or tok.is_identifier())
            and tz.look_ahead().is_op_with(value="*")):
          repetition_tok = tok
          tz.get()
          tok = tz.get()
        if (tok.is_op()):
          if (tok.value in ["+", "-"]):
            if (sign_count != 0 or len(ctoks) != 0):
              tok.raise_syntax_error()
            sign_count = 1
            ctoks.append(tok)
          elif (tok.value == "("):
            if (len(ctoks) != sign_count):
              tok.raise_syntax_error()
            ctoks.append(tz.get_complex_literal(opening_token=tok))
          elif (tok.value == "/"):
            if (len(ctoks) == sign_count):
              tok.raise_syntax_error()
            clist.append((repetition_tok, ctoks))
            break
          elif (tok.value == ","):
            if (len(ctoks) == sign_count):
              tok.raise_syntax_error()
            clist.append((repetition_tok, ctoks))
            repetition_tok = None
            sign_count = 0
            ctoks = []
          else:
            tok.raise_syntax_error()
        else:
          if (len(ctoks) != sign_count):
            tok.raise_syntax_error()
          ctoks.append(tok)
      O.data.append((nlist, clist))
      tok = tz.get(optional=True)
      if (tok is None):
        break
      if (tok.is_op_with(value=",")):
        tok = None

  def p_deallocate(O, ssl, start):
    O.executable.append(ei_deallocate(ssl=ssl, start=start)) # TODO

  def p_dimension(O, ssl, start):
    assert start == 0
    extract_fdecl(
      result=O.dimension,
      ssl=ssl,
      start=9,
      data_type=None,
      size_tokens=None,
      allow_size=False)

  def p_do(O, ssl, start):
    assert start == 0
    code = ssl.code
    i = unsigned_integer_scan(code=code, start=2)
    if (i < 3):
      i = 2
      label = None
    else:
      label = code[2:i]
      if (code[i] == ","):
        i += 1
    j = identifier_scan(code=code, start=i)
    assert j >= 3
    assert code[j] == "="
    tokens = tokenize_expression(ssl=ssl, start=j+1, allow_commas=True)
    if (not (2 <= len(tokens) <= 3)):
      ssl.raise_syntax_error(i=j+1)
    O.executable.append(ei_do(ssl=ssl, start=start,
      label=label,
      id_tok=tokenization.tk_identifier(ssl=ssl, i_code=i, value=code[i:j]),
      tokens=tokens))

  def p_dowhile(O, ssl, start, label_end=None):
    assert start == 0
    if (label_end is None):
      i = 7
      label = None
    else:
      i = label_end + 5
      label = ssl.code[2:label_end]
    cond_tokens = tokenize_expression(ssl=ssl, start=i)
    if (len(cond_tokens) != 1):
      ssl.raise_syntax_error(i=i)
    O.executable.append(ei_dowhile(ssl=ssl, start=start,
      label=label,
      cond_tokens=cond_tokens))

  def p_else(O, ssl, start):
    assert start == 0
    O.executable.append(ei_else(ssl=ssl, start=start))

  def p_elseif(O, ssl, start):
    assert start == 0
    O.p_if_elseif(ssl=ssl, keyword="elseif", start=0)

  def p_enddo(O, ssl, start):
    assert start == 0
    O.executable.append(ei_enddo(ssl=ssl, start=start))

  def p_endfile(O, ssl, start):
    O.p_file_positioning(ssl=ssl, start=start, io_function="endfile")

  def p_endif(O, ssl, start):
    assert start == 0
    O.executable.append(ei_endif(ssl=ssl, start=start))

  def p_entry(O, ssl, start):
    assert start == 0
    O.executable.append(ei_entry(ssl=ssl, start=start)) # TODO

  def p_equivalence(O, ssl, start):
    assert start == 0
    buffer = []
    tz = tokenization.ssl_iterator(ssl=ssl, start=11)
    while True:
      tok = tz.get()
      if (not tok.is_op_with(value="(")):
        tok.raise_syntax_error()
      def callback(tok):
        if (len(tok.value) == 0):
          tok.raise_syntax_error()
        for tok_seq in tok.value:
          if (len(tok_seq.value) == 0):
            tok.raise_syntax_error()
          id_tok = tok_seq.value[0]
          if (not id_tok.is_identifier()):
            id_tok.raise_syntax_error()
        O.equivalence.append(tok)
      tz.collect_to_matching_parenthesis(
        callback=callback,
        opening_token=tok)
      tok = tz.get(optional=True)
      if (tok is None):
        break
      if (not tok.is_op_with(value=",")):
        tok.raise_syntax_error()

  def p_exit(O, ssl, start):
    if (len(ssl.code) != start+4):
      ssl.raise_syntax_error(i=start+4)
    O.executable.append(ei_exit(ssl=ssl, start=start))

  def p_external(O, ssl, start):
    assert start == 0
    tokenization.ssl_iterator(
      ssl=ssl, start=8).collect_comma_separated_identifiers(
        callback=O.external.append, one_required=True)

  def p_format(O, ssl, start):
    assert start == 0
    code = ssl.code
    assert code.startswith("format(")
    assert code.endswith(")")
    if (ssl.label is None):
      ssl.raise_error(
        msg="FORMAT without a statement label in columns 1-5", i=0)
    if (ssl.label in O.format):
      ssl.raise_error(
        msg="Duplicate statement label in columns 1-5", i=-1)
    O.format[ssl.label] = list(tokenization.fss_iterator(fss=ssl[7:-1]))

  def p_goto(O, ssl, start):
    code = ssl.code
    i = start + 4
    if (i == len(code)):
      ssl.raise_syntax_error(i=i)
    j = unsigned_integer_scan(code=code, start=i)
    if (j == len(code)):
      O.executable.append(ei_goto(ssl=ssl, start=start,
        label=tokenization.tk_integer(ssl=ssl, i_code=i, value=code[i:])))
      return
    if (j > 0):
      ssl.raise_syntax_error(i=i)
    if (code[i] == "("):
      # GO TO (s [,s]...)[,] i
      j = ssl.index_of_closing_parenthesis(start=i+1)
      labels = process_labels_list(
        ssl=ssl, start=i+1, stop=j, len_min=1, len_max=None)
      j += 1
      if (j == len(code)):
        ssl.raise_syntax_error(i=j)
      if (code[j] == ","):
        j += 1
        if (j == len(code)):
          ssl.raise_syntax_error(i=j)
      tokens = tokenize_expression(ssl=ssl, start=j)
      O.executable.append(ei_goto_computed(ssl=ssl, start=start,
        labels=labels,
        tokens=tokens))
      return
    # GO TO i [[,](s [,s]...)]
    if (code[-1] != ")"):
      ssl.raise_syntax_error()
    k = code.rfind("(")
    if (k < 0):
      ssl.raise_syntax_error()
    j = k - 1
    if (code[j] == ","):
      j -= 1
    tokens = tokenize_expression(ssl=ssl, start=i+1, stop=j+1)
    labels = process_labels_list(
      ssl=ssl, start=k+1, stop=len(code)-1, len_min=1, len_max=None)
    O.executable.append(ei_goto_computed(ssl=ssl, start=start,
      labels=labels,
      tokens=tokens))

  def p_if(O, ssl, start):
    i = O.p_if_elseif(ssl=ssl, keyword="if", start=start)
    if (i is not None):
      O.process_body_line(ssl=ssl, start=i)

  def p_if_elseif(O, ssl, keyword, start):
    i_open = start + len(keyword) + 1
    i_clp = ssl.index_of_closing_parenthesis(start=i_open)
    cond_tokens = tokenize_expression(ssl=ssl, start=i_open, stop=i_clp)
    if (len(cond_tokens) == 0):
      ssl.raise_syntax_error(i=i_open)
    code = ssl.code
    if (code.startswith("then", i_clp+1) and len(code) == i_clp+5):
      if (start != 0):
        ssl.raise_syntax_error()
      if (keyword == "if"): ei = ei_if_then
      else:                 ei = ei_elseif_then
      O.executable.append(ei(ssl=ssl, start=start, cond_tokens=cond_tokens))
      return None
    if (keyword != "if"):
      ssl.raise_syntax_error()
    i = i_clp + 1
    if (i == len(code)):
      ssl.raise_syntax_error(i=i)
    j = unsigned_integer_scan(code=code, start=i, stop=i+1)
    if (j < 0):
      if (start != 0):
        ssl.raise_syntax_error()
      O.executable.append(ei_if(ssl=ssl, start=start, cond_tokens=cond_tokens))
      return i
    labels = process_labels_list(
      ssl=ssl, start=i, stop=len(code), len_min=3, len_max=3)
    O.executable.append(ei_if_arithmetic(ssl=ssl, start=start,
      cond_tokens=cond_tokens,
      labels=labels))
    return None

  def p_implicit(O, ssl, start):
    assert start == 0
    if (ssl.code == "implicitnone"):
      O.implicit = {}
      return
    i_code, data_type = extract_data_type(ssl=ssl, start=8)
    if (   not ssl.code.startswith("(", i_code)
        or not ssl.code.endswith(")")):
      ssl.raise_syntax_error_or_not_implemented()
    letters = "abcdefghijklmnopqrstuvwxyz"
    def get(c):
      i = letters.find(c)
      if (i < 0):
        ssl.raise_syntax_error_or_not_implemented()
      return i
    for part in ssl.code[i_code+1:-1].split(","):
      if (len(part) == 3 and part[1] == "-"):
        i = get(part[0])
        j = get(part[2])
        for c in letters[i:j+1]:
          O.implicit[c] = data_type
      else:
        for c in part:
          if (c not in "abcdefghijklmnopqrstuvwxyz"):
            ssl.raise_syntax_error_or_not_implemented()
          O.implicit[c] = data_type

  def p_inquire(O, ssl, start):
    tz = tokenization.ssl_iterator(ssl=ssl, start=start+7)
    iuflist = collect_io_iuflist(tz=tz)
    tok = tz.look_ahead(optional=True)
    if (tok is not None):
      tok.raise_syntax_error()
    O.executable.append(ei_inquire(ssl=ssl, start=start, iuflist=iuflist))
    O.uses_io = True

  def p_intrinsic(O, ssl, start):
    assert start == 0
    tokenization.ssl_iterator(
      ssl=ssl, start=9).collect_comma_separated_identifiers(
        callback=O.intrinsic.append, one_required=True)

  def p_open(O, ssl, start):
    tz = tokenization.ssl_iterator(ssl=ssl, start=start+4)
    olist = collect_io_olist(tz=tz)
    tok = tz.look_ahead(optional=True)
    if (tok is not None):
      tok.raise_syntax_error()
    O.executable.append(ei_open(ssl=ssl, start=start, olist=olist))
    O.uses_io = True

  def p_parameter(O, ssl, start):
    assert start == 0
    code = ssl.code
    if (   not code.startswith("(", 9)
        or not code.endswith(")")):
      ssl.raise_syntax_error()
    tokens_ll = tokenize_expression(
      ssl=ssl,
      start=10,
      stop=len(code)-1,
      allow_commas=True,
      allow_equal_signs=True)
    for tokens_l in tokens_ll:
      i_equal_signs = indices_of_tokenized_equal_signs(tokens=tokens_l.value)
      if (len(i_equal_signs) != 1 or i_equal_signs[0] != 1):
        ssl.raise_syntax_error()
      key_token = tokens_l.value[0]
      if (not key_token.is_identifier()):
        key_token.raise_syntax_error()
      O.parameter.append((key_token, tokens_l.value[2:]))

  def p_print(O, ssl, start):
    tz = tokenization.ssl_iterator(ssl=ssl, start=start+5)
    fmt_buffer = []
    tz.collect_comma_separated_expressions(
      callback=fmt_buffer.append,
      first_get_optional=False,
      stop_after_given_number_of_commas=1)
    assert len(fmt_buffer) == 1
    cilist = collect_io_cilist(tz=None, fmt=fmt_buffer[0].value)
    fmt_tokens = None
    if (len(cilist.fmt) == 1 and cilist.fmt[0].is_string()):
      fmt_tokens = list(tokenization.fss_iterator(
        fss=fmt_string_stripped(fmt_tok=cilist.fmt[0])))
    iolist = collect_iolist(tz=tz)
    O.executable.append(ei_print(ssl=ssl, start=start,
      cilist=cilist, fmt_tokens=fmt_tokens, iolist=iolist))
    O.uses_io = True
    O.uses_write = True

  def p_read_write(O, ssl, start, ei_type):
    tz = tokenization.ssl_iterator(ssl=ssl, start=start)
    cilist = collect_io_cilist(tz=tz)
    if (cilist.unit is None):
      ssl.raise_semantic_error(
        msg="Required UNIT information is not defined", i=start)
    fmt_tokens = None
    if (cilist.fmt is not None):
      if (len(cilist.fmt) == 1 and cilist.fmt[0].is_string()):
        fmt_tokens = list(tokenization.fss_iterator(
          fss=fmt_string_stripped(fmt_tok=cilist.fmt[0])))
    if (ei_type is ei_write and cilist.end is not None):
      cilist.end[0].raise_semantic_error(
        msg="END is invalid for WRITE statements")
    iolist = collect_iolist(tz=tz)
    O.executable.append(ei_type(ssl=ssl, start=start,
      cilist=cilist, fmt_tokens=fmt_tokens, iolist=iolist))

  def p_read(O, ssl, start):
    code = ssl.code
    if (code.startswith("*", start+4)):
      if (code.startswith(",", start+5)):
        tz = tokenization.ssl_iterator(ssl=ssl, start=start+6)
        iolist = []
        tz.collect_comma_separated_expressions(
          callback=iolist.append,
          enable_implied_do=1)
        iolist = tokenization.remove_redundant_parentheses(tokens=iolist)
        if (len(iolist) == 0):
          ssl.raise_syntax_error(i=start+5)
      elif (len(code) == start+5):
        iolist = None
      else:
        ssl.raise_syntax_error(i=start+5)
      O.executable.append(ei_read(ssl=ssl, start=start,
        cilist=None, fmt_tokens=None, iolist=iolist))
    elif (code.startswith("(", start+4)):
      O.p_read_write(ssl=ssl, start=start+4, ei_type=ei_read)
    else:
      ssl.raise_syntax_error(i=start+4)
    O.uses_io = True
    O.uses_read = True

  def p_return(O, ssl, start):
    O.executable.append(ei_return(ssl=ssl, start=start,
      return_label=ssl[start:]))

  def p_rewind(O, ssl, start):
    O.p_file_positioning(ssl=ssl, start=start, io_function="rewind")

  def p_save(O, ssl, start):
    assert start == 0
    if (O.save is not None):
      if (tokenization.ssl_iterator(
            ssl=ssl, start=4).collect_comma_separated_identifiers(
              callback=O.save.append, enable_common=True) == 0):
        O.save = None

  def p_stop(O, ssl, start):
    tz = tokenization.ssl_iterator(ssl=ssl, start=start+4)
    tok = tz.get(optional=True)
    if (tok is not None):
      if (not (tok.is_integer() or tok.is_string())):
        tok.raise_syntax_error()
      next_tok = tz.get(optional=True)
      if (next_tok is not None):
        next_tok.raise_syntax_error()
    O.executable.append(ei_stop(ssl=ssl, start=start, arg_token=tok))

  def p_write(O, ssl, start):
    O.p_read_write(ssl=ssl, start=start+5, ei_type=ei_write)
    O.uses_io = True
    O.uses_write = True

def collect_keyword_arguments(O, tz, n_implied):
  for known in O.__slots__:
    setattr(O, known, None)
  tok = tz.get()
  if (not tok.is_op()):
    tok.raise_syntax_error()
  if (tok.value == "*"):
    tok = tz.get()
    if (not tok.is_op_with(value=",")):
      tok.raise_syntax_error()
    O.fmt = [tok]
  else:
    if (tok.value != "("):
      tok.raise_syntax_error()
    while True: # loop over comma-separated arguments
      tok = tz.get()
      if (tok.is_op_with(value=")")):
        break
      value_tokens = []
      next_tok = tz.look_ahead()
      if (next_tok.is_op_with(value="=")):
        tz.get()
        if (not tok.is_identifier()):
          tok.raise_syntax_error()
        key = tok.value
        if (key not in O.__slots__):
          tok.raise_syntax_error()
      else:
        value_tokens.append(tok)
        for key in O.__slots__[:n_implied]:
          if (getattr(O, key) is None):
            break
        else:
          tok.raise_syntax_error()
      while True:
        tok = tz.look_ahead()
        if (tok.is_op_with(value=")")):
          break
        tz.get()
        if (tok.is_op_with(value=",")):
          break
        if (tok.is_op_with(value="(")):
          nested_tokens = []
          tz.collect_comma_separated_expressions(
            callback=nested_tokens.append,
            opening_token=tok)
          value_tokens.append(tokenization.tk_parentheses(
            ssl=tok.ssl, i_code=tok.i_code, value=nested_tokens))
        else:
          value_tokens.append(tok)
      setattr(O, key, value_tokens)

class collect_io_cilist(object):
  "Control Information List f77_std 12.8"

  __slots__ = ["unit", "fmt", "rec", "iostat", "err", "end"]

  def __init__(O, tz, fmt=None):
    if (fmt is None):
      collect_keyword_arguments(O=O, tz=tz, n_implied=2)
    else:
      for known in O.__slots__:
        setattr(O, known, None)
      O.fmt = fmt

class collect_io_olist(object):
  "Open List f77_std 12.10.1"

  chain = ["access", "form", "recl", "blank", "status", "iostat"]

  __slots__ = ["unit", "file", "err"] + chain

  def __init__(O, tz):
    collect_keyword_arguments(O=O, tz=tz, n_implied=1)

class collect_io_cllist(object):
  "Close List f77_std 12.10.2"

  chain = ["iostat", "status"]

  __slots__ = ["unit", "err"] + chain

  def __init__(O, tz):
    collect_keyword_arguments(O=O, tz=tz, n_implied=1)

class collect_io_iuflist(object):
  "iulist or iflist f77_std 12.10.3"

  chain = [
    "iostat", "exist", "opened", "number", "named", "name", "access",
    "sequential", "direct", "form", "formatted", "unformatted", "recl",
    "nextrec", "blank"]

  __slots__ = ["unit", "file", "err"] + chain

  def __init__(O, tz):
    collect_keyword_arguments(O=O, tz=tz, n_implied=1)

class collect_io_alist(object):
  "f77_std 12.10.4"

  chain = ["iostat"]

  __slots__ = ["unit", "err"] + chain

  def __init__(O, tz, unit):
    if (tz is not None):
      assert unit is None
      collect_keyword_arguments(O=O, tz=tz, n_implied=1)
    else:
      O.unit = unit
      O.iostat = None
      O.err = None

def collect_iolist(tz):
  result = []
  tok = tz.look_ahead(optional=True)
  if (tok is not None):
    if (tok.is_op_with(value=",")):
      tz.get()
    tz.collect_comma_separated_expressions(
      callback=result.append,
      enable_implied_do=1)
    result = tokenization.remove_redundant_parentheses(tokens=result)
  return result

class fproc(fproc_p_methods):

  __slots__ = [
    "leading_comments",
    "trailing_comments",
    "top_ssl", "fproc_type", "data_type", "size_tokens",
    "body_lines", "end_ssl",
    "name_plain", "name", "args",
    "body_lines_processed_already",
    "common",
    "data",
    "declarations",
    "dimension",
    "equivalence",
    "executable",
    "external",
    "format",
    "implicit",
    "intrinsic",
    "parameter",
    "save",
    "fdecl_by_identifier",
    "args_fdecl",
    "uses_common",
    "uses_save",
    "uses_io",
    "uses_read",
    "uses_write",
    "uses_iargc_getarg",
    "_fmt_counts_by_statement_label",
    "_common_name_by_identifier",
    "_equivalence_info",
    "_classified_equivalence_info",
    "_target_statement_labels",
    "dynamic_parameters",
    "needs_cmn",
    "is_passed_as_external",
    "externals_passed_by_arg_identifier",
    "conv_hook"]

  def __init__(O,
        leading_comments,
        top_ssl,
        fproc_type,
        i_code,
        data_type,
        size_tokens,
        body_lines,
        end_ssl):
    assert fproc_type in ["program", "function", "subroutine", "blockdata"]
    O.leading_comments = leading_comments
    O.trailing_comments = []
    O.top_ssl = top_ssl
    O.fproc_type = fproc_type
    O.body_lines = body_lines
    O.end_ssl = end_ssl
    O.data_type = data_type
    O.size_tokens = size_tokens
    O.set_name_and_args(i_code=i_code)
    O.body_lines_processed_already = False
    O.common = utils.keyed_lists()
    O.data = []
    O.declarations = []
    O.dimension = []
    O.equivalence = []
    O.executable = []
    O.external = []
    O.format = {}
    O.init_implicit()
    O.intrinsic = []
    O.parameter = []
    O.save = []
    O.fdecl_by_identifier = None
    O.args_fdecl = None
    O.uses_common = None
    O.uses_save = None
    O.uses_io = False
    O.uses_read = False
    O.uses_write = False
    O.uses_iargc_getarg = False
    O._fmt_counts_by_statement_label = None
    O._common_name_by_identifier = None
    O._equivalence_info = None
    O._classified_equivalence_info = None
    O._target_statement_labels = None
    O.dynamic_parameters = set()
    O.needs_cmn = None
    O.is_passed_as_external = False
    O.externals_passed_by_arg_identifier = {}
    O.conv_hook = None

  def is_program(O): return (O.fproc_type == "program")
  def is_function(O): return (O.fproc_type == "function")
  def is_subroutine(O): return (O.fproc_type == "subroutine")
  def is_blockdata(O): return (O.fproc_type == "blockdata")

  def first_body_source_line(O):
    assert len(O.body_lines) != 0
    assert len(O.body_lines[0].source_line_cluster) != 0
    return O.body_lines[0].source_line_cluster[0]

  def set_name_and_args(O, i_code):
    O.name_plain = None
    O.name = None
    O.args = []
    if (O.top_ssl is None):
      assert O.is_program()
      assert i_code == 0
      O.name = tokenization.tk_identifier(
        ssl=None, i_code=None, value=O.fproc_type+"_unnamed")
      return
    j_code = i_code + len(O.fproc_type)
    pat = 'recursive'
    if O.top_ssl.code.startswith(pat, i_code):
      j_code += len(pat)
    tz = tokenization.ssl_iterator(ssl=O.top_ssl, start=j_code)
    O.name = tz.get(optional=True)
    if (O.name is None):
      if (not O.is_program() and not O.is_blockdata()):
        O.top_ssl.raise_syntax_error(i=j_code-1)
      O.name = tokenization.tk_identifier(
        ssl=O.top_ssl, i_code=0, value=O.fproc_type+"_unnamed")
      return
    opening_token = tz.get(optional=True)
    if (opening_token is None):
      if (O.is_program() or O.is_blockdata()):
        O.name_plain = O.name
        O.name = tokenization.tk_identifier(
          ssl=O.name.ssl,
          i_code=O.name.i_code,
          value=O.fproc_type+"_"+O.name.value)
      return
    if (not opening_token.is_op_with(value="(") or O.is_blockdata()):
      opening_token.raise_syntax_error()
    need_arg = False
    while True:
      tok = tz.get_inside_parentheses(opening_token)
      if (tok.is_identifier()):
        O.args.append(tok)
      elif (tok.is_op_with(value="*")):
        if (O.fproc_type != "subroutine"):
          tok.raise_syntax_error()
        O.args.append(tok)
      elif (need_arg):
        tok.raise_syntax_error()
      elif (tok.is_op_with(value=")")):
        break
      else:
        tok.raise_syntax_error()
      tok = tz.get_inside_parentheses(opening_token)
      if (tok.is_op_with(value=")")):
        break
      if (not tok.is_op_with(value=",")):
        tok.raise_syntax_error()
      need_arg = True
    tok = tz.get(optional=True)
    if (tok is not None):
      tok.raise_syntax_error()

  def all_ssl(O):
    result = list(O.leading_comments)
    if (O.top_ssl is not None):
      result.append(O.top_ssl)
    result.extend(O.body_lines)
    result.append(O.end_ssl)
    result.extend(O.trailing_comments)
    return result

  def init_implicit(O):
    O.implicit = {}
    data_type = tokenization.tk_identifier(
      ssl=None, i_code=None, value="real")
    for c in "abcdefghopqrstuvwxyz":
      O.implicit[c] = data_type
    data_type = tokenization.tk_identifier(
      ssl=None, i_code=None, value="integer")
    for c in "ijklmn":
      O.implicit[c] = data_type

  def process_body_line(O, ssl, start):
    code = ssl.code
    if (len(code) == start): return
    i_lid = identifier_scan(code, start=start) # i_leading_identifier
    if (i_lid < 0):
      ssl.raise_syntax_error()
    if (i_lid == len(code)):
      if (code.endswith("continue", start)):
        O.p_continue(ssl=ssl, start=start)
        return
      for s in [
            "assign",
            "backspace",
            "call",
            "cycle",
            "endfile",
            "exit",
            "goto",
            "print",
            "return",
            "rewind",
            "stop"]:
        if (code.startswith(s, start)):
          p = getattr(fproc_p_methods, "p_"+s)
          p(O, ssl=ssl, start=start)
          return
      if (start != 0):
        ssl.raise_syntax_error(i=start)
      if (code in ["else", "enddo", "endif"]):
        p = getattr(fproc_p_methods, "p_"+code)
        p(O, ssl=ssl, start=start)
        return
      for s in [
            "common",
            "external",
            "entry",
            "implicit",
            "intrinsic",
            "save"]:
        if (code.startswith(s)):
          p = getattr(fproc_p_methods, "p_"+s)
          p(O, ssl=ssl, start=start)
          return
      O.process_declaration(ssl=ssl, start=start, enable_size=False)
      return
    c = code[i_lid]
    if (c == "="):
      i = ssl.comma_scan(start=i_lid+1)
      if (i < 0):
        O.process_assignment(ssl=ssl, start=start, i_equal_sign=i_lid)
        return
      if (start != 0):
        ssl.raise_syntax_error()
      if (code.startswith("do")):
        O.p_do(ssl=ssl, start=start)
        return
      ssl.raise_syntax_error()
    if (c == "("):
      i_clp = ssl.index_of_closing_parenthesis(start=i_lid+1)
      if (i_clp+1 == len(code)):
        cid = code[start:i_lid]
        if (cid in [
              "allocate",
              "backspace",
              "close",
              "deallocate",
              "endfile",
              "inquire",
              "open",
              "read",
              "rewind",
              "write"]):
          p = getattr(fproc_p_methods, "p_"+cid)
          p(O, ssl=ssl, start=start)
          return
        for s in ["call", "goto"]:
          if (code.startswith(s, start)):
            p = getattr(fproc_p_methods, "p_"+s)
            p(O, ssl=ssl, start=start)
            return
        if (start != 0):
          ssl.raise_syntax_error(i=start)
        if (cid.startswith("do") and cid.endswith("while")):
          label_end = unsigned_integer_scan(code=cid, start=2)
          if (label_end == len(cid)-5):
            O.p_dowhile(ssl=ssl, start=start, label_end=label_end)
            return
        for s in [
              "common",
              "dimension",
              "dowhile",
              "entry",
              "equivalence",
              "format",
              "implicit",
              "parameter"]:
          if (code.startswith(s)):
            p = getattr(fproc_p_methods, "p_"+s)
            p(O, ssl=ssl, start=start)
            return
        O.process_declaration(ssl=ssl, start=start, enable_size=True)
        return
      c = code[i_clp+1]
      if (c == "="):
        O.process_assignment(ssl=ssl, start=start, i_equal_sign=i_clp+1)
        return
      if (c == "("):
        i_clp2 = ssl.index_of_closing_parenthesis(start=i_clp+2)
        if (i_clp2+1 < len(code) and code[i_clp2+1] == "="):
          O.process_assignment(ssl=ssl, start=start, i_equal_sign=i_clp2+1)
          return
        for s in ["allocate(", "backspace(", "deallocate(", "read(", "write("]:
          if (code.startswith(s, start)):
            p = getattr(fproc_p_methods, "p_"+s[:-1])
            p(O, ssl=ssl, start=start)
            return
        if (code.startswith("data", start)):
          O.p_data(ssl=ssl, start=start)
          return
        ssl.raise_syntax_error_or_not_implemented()
      if (c == ","):
        cid = code[start:i_lid]
        if (cid == "goto"):
          O.p_goto(ssl=ssl, start=start)
          return
        if (cid in [
              "allocate",
              "backspace",
              "equivalence",
              "deallocate",
              "read",
              "write"]):
          p = getattr(fproc_p_methods, "p_"+cid)
          p(O, ssl=ssl, start=start)
          return
        if (start != 0):
          ssl.raise_syntax_error(i=start)
        for s in ["common", "data", "dimension", "print"]:
          if (code.startswith(s)):
            p = getattr(fproc_p_methods, "p_"+s)
            p(O, ssl=ssl, start=start)
            return
        O.process_declaration(ssl=ssl, start=start, enable_size=True)
        return
      for s in [
            "allocate(",
            "backspace(",
            "deallocate(",
            "goto(",
            "if(",
            "read(",
            "write("]:
        if (code.startswith(s, start)):
          p = getattr(fproc_p_methods, "p_"+s[:-1])
          p(O, ssl=ssl, start=start)
          return
      if (start != 0):
        ssl.raise_syntax_error(i=start)
      if (code.startswith("elseif(")):
        O.p_elseif(ssl=ssl, start=start)
        return
      if (code.startswith("data")):
        O.p_data(ssl=ssl, start=start)
        return
      O.process_declaration(ssl=ssl, start=start, enable_size=True)
      return
    if (c == "/"):
      if (start != 0):
        ssl.raise_syntax_error(i=start)
      for s in ["common", "data", "save"]:
        if (code.startswith(s)):
          p = getattr(fproc_p_methods, "p_"+s)
          p(O, ssl=ssl, start=start)
          return
      ssl.raise_syntax_error_or_not_implemented()
    if (c == ","):
      if (code.startswith("goto", start)):
        O.p_goto(ssl=ssl, start=start)
        return
      if (code.startswith("print", start)):
        O.p_print(ssl=ssl, start=start)
        return
      if (start != 0):
        ssl.raise_syntax_error(i=start)
      for s in ["common", "data", "external", "intrinsic", "save"]:
        if (code.startswith(s)):
          p = getattr(fproc_p_methods, "p_"+s)
          p(O, ssl=ssl, start=start)
          return
      if (    code.startswith("do")
          and unsigned_integer_scan(code=code, start=2) == i_lid):
        O.p_do(ssl=ssl, start=start)
        return
      O.process_declaration(ssl=ssl, start=start, enable_size=False)
      return
    if (code.endswith("stop'", start)):
      O.p_stop(ssl=ssl, start=start)
      return
    for s in ["backspace", "print", "read", "rewind"]:
      if (code.startswith(s, start)):
        p = getattr(fproc_p_methods, "p_"+s)
        p(O, ssl=ssl, start=start)
        return
    if (start != 0):
      ssl.raise_syntax_error(i=start)
    O.process_declaration(ssl=ssl, start=start, enable_size=True)

  def process_declaration(O, ssl, start, enable_size):
    assert start == 0
    if (enable_size):
      i_code, data_type, size_tokens = extract_data_type_and_size(ssl=ssl)
    else:
      i_code, data_type = extract_data_type(ssl=ssl)
      size_tokens = None
    code = ssl.code
    if (i_code == len(code)):
      ssl.raise_syntax_error(i=start)
    i_code, f90_decl = extract_f90_decl(ssl=ssl, start=i_code)
    extract_fdecl(
      result=O.declarations,
      ssl=ssl,
      start=i_code,
      data_type=data_type,
      size_tokens=size_tokens,
      allow_size=True,
      f90_decl=f90_decl)

  def process_assignment(O, ssl, start, i_equal_sign):
    if (i_equal_sign+1 == len(ssl.code)):
      ssl.raise_syntax_error()
    lhs_tokens = tokenize_expression(ssl=ssl, start=start, stop=i_equal_sign)
    rhs_tokens = tokenize_expression(ssl=ssl, start=i_equal_sign+1)
    O.executable.append(ei_assignment(ssl=ssl, start=start,
      lhs_tokens=lhs_tokens, rhs_tokens=rhs_tokens))

  def process_body_lines(O):
    assert not O.body_lines_processed_already
    O.body_lines_processed_already = True
    for ssl in O.body_lines:
      O.process_body_line(ssl=ssl, start=0)

  def show_fdecl(O):
    "for debugging; not exercised"
    assert O.fdecl_by_identifier is not None
    print(O.name.value)
    for key in sorted(O.fdecl_by_identifier.keys()):
      fdecl = O.fdecl_by_identifier[key]
      print(" ", fdecl.id_tok.value)
      print("   ", fdecl.var_type)
      if (fdecl.var_storage is not None):
        print("   ", fdecl.var_storage)
      if (fdecl.data_type is not None):
        print("   ", fdecl.data_type.value)
      if (fdecl.parameter_assignment_tokens is not None):
        print("    parameter")
    print()

  def build_fdecl_by_identifier(O):
    if (not O.body_lines_processed_already):
      O.process_body_lines()
    assert O.fdecl_by_identifier is None
    O.fdecl_by_identifier = {}
    def make_fdecl(
         id_tok,
         var_type=None,
         var_storage=None,
         data_type=None,
         size_tokens=None,
         dim_tokens=None):
      O.fdecl_by_identifier[id_tok.value] = result = fdecl_info(
        id_tok=id_tok,
        var_type=var_type,
        var_storage=var_storage,
        data_type=data_type,
        size_tokens=size_tokens,
        dim_tokens=dim_tokens)
      return result
    if (O.is_function()):
      vt = vt_function
    elif (O.is_subroutine() or O.is_blockdata()):
      vt = vt_subroutine
    else:
      vt = None
    if (vt is not None):
      make_fdecl(
        id_tok=O.name,
        var_type=vt,
        var_storage=vs_fproc_name,
        data_type=O.data_type,
        size_tokens=O.size_tokens)
    def raise_confl_decl(id_tok):
      id_tok.raise_semantic_error(
        msg="Conflicting declaration: %s" % id_tok.value)
    def raise_confl_or_repeated_decl(id_tok):
      id_tok.raise_semantic_error(
        msg="Conflicting or repeated declaration: %s" % id_tok.value)
    for fdecl in O.declarations:
      id_tok = fdecl.id_tok
      tf = O.fdecl_by_identifier.get(id_tok.value)
      if (tf is None):
        make_fdecl(
          id_tok=id_tok,
          data_type=fdecl.data_type,
          size_tokens=fdecl.size_tokens,
          dim_tokens=fdecl.dim_tokens)
      elif (tf.var_storage is vs_fproc_name):
        if (tf.data_type is not None):
          raise_confl_or_repeated_decl(id_tok=id_tok)
        if (fdecl.dim_tokens is not None):
          raise_confl_or_repeated_decl(id_tok=id_tok)
        tf.data_type = fdecl.data_type
        tf.size_tokens = fdecl.size_tokens
      elif (tf.data_type is not None):
        raise_confl_or_repeated_decl(id_tok=id_tok)
    for id_tok in O.args:
      if (id_tok.value == "*"): continue
      tf = O.fdecl_by_identifier.get(id_tok.value)
      if (tf is not None):
        if (tf.var_storage is not None):
          raise_confl_or_repeated_decl(id_tok=id_tok)
        tf.var_storage = vs_argument
      else:
        make_fdecl(id_tok=id_tok, var_storage=vs_argument)
    for id_tok,assignment_tokens in O.parameter:
      tf = O.fdecl_by_identifier.get(id_tok.value)
      if (tf is None):
        tf = make_fdecl(id_tok=id_tok, var_storage=vs_parameter)
      else:
        if (tf.var_storage is not None):
          raise_confl_or_repeated_decl(id_tok=id_tok)
        if (tf.dim_tokens is not None):
          raise_confl_or_repeated_decl(id_tok=fdecl.id_tok)
        tf.var_storage = vs_parameter
      tf.parameter_assignment_tokens = assignment_tokens
    def get_implicit_data_type(id_tok, optional=False):
      result = O.implicit.get(id_tok.value[0])
      if (result is None and not optional):
        id_tok.raise_semantic_error("Unknown data type: %s" % id_tok.value)
      return result
    def set_dim_tokens(fdecl):
      tf = O.fdecl_by_identifier.get(fdecl.id_tok.value)
      if (tf is None):
        tf = make_fdecl(
          id_tok=fdecl.id_tok,
          size_tokens=fdecl.size_tokens,
          dim_tokens=fdecl.dim_tokens)
      elif (fdecl.dim_tokens is not None):
        if (tf.dim_tokens is not None):
          fdecl.id_tok.raise_semantic_error(
            msg="Conflicting or repeated dimension: %s" % fdecl.id_tok.value)
        tf.dim_tokens = fdecl.dim_tokens
      return tf
    for fdecl in O.dimension:
      set_dim_tokens(fdecl=fdecl)
    for fdecl_list in O.common.lists:
      for fdecl in fdecl_list:
        tf = set_dim_tokens(fdecl=fdecl)
        if (tf.var_storage is not None):
          raise_confl_or_repeated_decl(id_tok=fdecl.id_tok)
        tf.var_storage = vs_common
        if (tf.data_type is None):
          tf.data_type = get_implicit_data_type(id_tok=fdecl.id_tok)
    if (O.save is not None):
      for id_tok in O.save:
        tf = O.fdecl_by_identifier.get(id_tok.value)
        if (tf is None):
          make_fdecl(id_tok=id_tok, var_storage=vs_save)
        else:
          vs = tf.var_storage
          if (vs is None):
            tf.var_storage = vs_save
          elif (vs is not vs_common):
            raise_confl_or_repeated_decl(id_tok=id_tok)
    for id_tok in O.external:
      tf = O.fdecl_by_identifier.get(id_tok.value)
      if (tf is None):
        make_fdecl(id_tok=id_tok, var_type=vt_external)
      elif (tf.dim_tokens is not None):
        raise_confl_or_repeated_decl(id_tok=id_tok)
      else:
        vs = tf.var_storage
        if (vs is not None and vs is not vs_argument):
          raise_confl_or_repeated_decl(id_tok=id_tok)
        vt = tf.var_type
        if (    vt is not None
            and vt is not vs_external
            and vt is not vs_function):
          raise_confl_or_repeated_decl(id_tok=id_tok)
        if (tf.data_type is None):
          tf.var_type = vt_external
        else:
          tf.var_type = vt_function
    for id_tok in O.intrinsic:
      tf = O.fdecl_by_identifier.get(id_tok.value)
      if (tf is None):
        make_fdecl(id_tok=id_tok, var_type=vt_intrinsic)
      elif (tf.dim_tokens is not None):
        raise_confl_or_repeated_decl(id_tok=id_tok)
      else:
        vs = tf.var_storage
        if (vs is not None):
          raise_confl_or_repeated_decl(id_tok=id_tok)
    #
    for nlist,clist in O.data:
      id_toks = tokenization.extract_identifiers(tokens=nlist)
      for id_tok in id_toks:
        tf = O.fdecl_by_identifier.get(id_tok.value)
        if (tf is None):
          make_fdecl(id_tok=id_tok, var_type=vt_scalar)
      def callback(tok):
        tf = O.fdecl_by_identifier.get(tok.value)
        if (tf is not None):
          if (tf.var_type is None):
            tf.var_type = vt_scalar
          if (tf.var_storage is None or tf.var_storage is vs_local):
            tf.var_storage = vs_save
          tf.is_modified = True
          tf.use_count += 1
      tokenization.search_for_data_or_read_target_tokens(
        callback=callback, tokens=nlist)
    #
    for id_tok in O.args:
      tf = O.fdecl_by_identifier.get(id_tok.value)
      if (tf is not None and tf.dim_tokens is not None):
        dim_id_toks = tokenization.extract_identifiers(tokens=tf.dim_tokens)
        for dim_id_tok in dim_id_toks:
          dim_tf = O.fdecl_by_identifier.get(dim_id_tok.value)
          if (dim_tf is not None and dim_tf.var_type is None):
            dim_tf.var_type = vt_used
            dim_tf.use_count += 1
    #
    for equiv_tok in O.equivalence:
      for tok_seq in equiv_tok.value:
        id_tok = tok_seq.value[0]
        tf = O.fdecl_by_identifier.get(id_tok.value)
        if (tf is None):
          make_fdecl(
            id_tok=id_tok,
            data_type=get_implicit_data_type(id_tok=id_tok))
    #
    for ei in O.executable:
      if (ei.key == "call"):
        id_tok = ei.subroutine_name
        tf = O.fdecl_by_identifier.get(id_tok.value)
        if (tf is None):
          if (id_tok.value in intrinsics.extra_set_lower):
            make_fdecl(id_tok=id_tok, var_type=vt_intrinsic)
          elif (id_tok.value in intrinsics.io_set_lower):
            make_fdecl(id_tok=id_tok, var_type=vt_intrinsic)
            O.uses_io = True
          else:
            make_fdecl(id_tok=id_tok, var_type=vt_subroutine)
        else:
          vt = tf.var_type
          if (vt is None or vt is vt_external):
            if (tf.data_type is not None):
              raise_confl_decl(id_tok=id_tok)
            if (tf.dim_tokens is not None):
              raise_confl_decl(id_tok=id_tok)
            tf.var_type = vt_subroutine
            tf.use_count += 1
          elif (    vt is vt_intrinsic
                and id_tok.value in intrinsics.extra_set_lower):
            pass
          elif (vt is not vt_subroutine):
            raise_confl_decl(id_tok=id_tok)
      def search_for_id_tokens_callback(id_tok, next_tok):
        followed_by_parenthesis = (
          next_tok is not None and next_tok.is_parentheses())
        tf = O.fdecl_by_identifier.get(id_tok.value)
        if (tf is None):
          if (not followed_by_parenthesis):
            tf = make_fdecl(id_tok=id_tok, var_type=vt_used)
          elif (id_tok.value in intrinsics.set_lower):
            tf = make_fdecl(id_tok=id_tok, var_type=vt_intrinsic)
          else:
            tf = make_fdecl(id_tok=id_tok, var_type=vt_external)
          tf.use_count += 1
          return
        tf.use_count += 1
        if (tf.var_type is vt_intrinsic):
          if (    id_tok.value not in intrinsics.set_lower
              and id_tok.value not in intrinsics.extra_set_lower
              and id_tok.value not in intrinsics.io_set_lower):
            id_tok.raise_semantic_error(
              msg="Unknown intrinsic: %s" % id_tok.value)
          if (not followed_by_parenthesis):
            id_tok.raise_semantic_error(
              msg="Improper use of intrinsic: %s" % id_tok.value)
        elif (followed_by_parenthesis):
          vt = tf.var_type
          vs = tf.var_storage
          if (tf.dim_tokens is not None):
            if (tf.var_type is None):
              tf.var_type = vt_used
            if (tf.data_type is None):
              tf.data_type = get_implicit_data_type(id_tok=id_tok)
          elif (    tf.data_type is not None
                and tf.data_type.value == "character"):
            if (tf.var_type is None):
              tf.var_type = vt_used
          elif (vs is vs_argument):
            if (vt is None):
              tf.var_type = vt_external
            elif (    vt is not vt_external
                  and vt is not vt_function
                  and vt is not vt_subroutine):
              raise_confl_decl(id_tok=id_tok)
          elif (   vt is vt_external
                or vt is vt_function
                or vt is vt_subroutine):
            pass
          elif (vt is vt_intrinsic):
            if (id_tok.value not in intrinsics.set_lower):
              id_tok.raise_semantic_error(
                msg="Unknown intrinsic: %s" % id_tok.value)
          elif (vt is vt_used):
            raise_confl_decl(id_tok=id_tok)
          else:
            if (tf.var_storage is not None):
              pass # XXX should be error; ignored due to
                   #     lack of proper handling of f90 declarations
            tf.var_storage = None
            if (   id_tok.value in intrinsics.extra_set_lower
                or id_tok.value in intrinsics.set_lower):
              tf.var_type = vt_intrinsic
            else:
              tf.var_type = vt_function
        else:
          if (tf.var_type is None):
            tf.var_type = vt_used
          if (tf.data_type is None
                and tf.var_type is not vt_external
                and tf.var_type is not vt_subroutine):
            tf.data_type = get_implicit_data_type(
              id_tok=tf.id_tok, optional=True)
      ei.search_for_id_tokens(callback=search_for_id_tokens_callback)
      ei.set_is_modified(fdecl_by_identifier=O.fdecl_by_identifier)
    #
    O.uses_common = False
    for tf in O.fdecl_by_identifier.values():
      vt = tf.var_type
      vs = tf.var_storage
      if (   vt is vt_external
          or vt is vt_function
          or vt is vt_subroutine):
        if (not (vs is None or vs is vs_fproc_name or vs is vs_argument)):
          tf.id_tok.raise_internal_error()
      elif (vt is vt_intrinsic):
        if (vs is not None):
          tf.id_tok.raise_internal_error()
      else:
        if (vs is None):
          if (O.save is None):
            tf.var_storage = vs_save
          else:
            tf.var_storage = vs_local
        if (vt is vt_used):
          tf.var_type = vt_scalar
          if (tf.data_type is None):
            tf.data_type = get_implicit_data_type(id_tok=tf.id_tok)
        elif (vt is None and vs is vs_argument and tf.data_type is None):
          tf.data_type = get_implicit_data_type(id_tok=tf.id_tok)
      if (tf.is_common()):
        O.uses_common = True
    #
    for ei in O.executable:
      def search_for_id_tokens_callback(id_tok, next_tok):
        if (   next_tok is None
            or not next_tok.is_parentheses()):
          return
        tf = O.fdecl_by_identifier.get(id_tok.value)
        assert tf is not None
        if (tf.is_intrinsic()):
          intrinsic_is_modified_info = intrinsics.is_modified_info_by_name.get(
            id_tok.value)
          if (intrinsic_is_modified_info is None):
            return
        elif (not tf.is_user_defined_callable()):
          return
        else:
          intrinsic_is_modified_info = None
        called_identifier = id_tok.value
        for i_arg,tok_seq in enumerate(next_tok.value):
          assert tok_seq.is_seq()
          if (len(tok_seq.value) == 0):
            continue
          first_arg_tok = tok_seq.value[0]
          if (not first_arg_tok.is_identifier()):
            continue
          tf_arg = O.fdecl_by_identifier.get(first_arg_tok.value)
          assert tf_arg is not None
          if (tf_arg.is_fproc_name()):
            return
          if (intrinsic_is_modified_info is None):
            tf_arg.passed_as_arg.setdefault(
              called_identifier, set()).add(i_arg)
            if (len(tok_seq.value) == 1):
              tf_arg.passed_as_arg_plain.setdefault(
                called_identifier, set()).add(i_arg)
          elif (i_arg in intrinsic_is_modified_info):
            tf_arg.is_modified = True
      ei.search_for_id_tokens(callback=search_for_id_tokens_callback)
    #
    assert O.args_fdecl is None
    O.args_fdecl = []
    for id_tok in O.args:
      if (id_tok.value == "*"): continue
      tf = O.fdecl_by_identifier.get(id_tok.value)
      assert tf is not None
      O.args_fdecl.append(tf)
    #
    for identifier in ["iargc", "getarg"]:
      tf = O.fdecl_by_identifier.get(identifier)
      if (tf is not None and tf.is_intrinsic()):
        O.uses_iargc_getarg = True
        break
    #
    equiv_info = O.equivalence_info()
    for equiv_tok_cluster in equiv_info.equiv_tok_clusters:
      cluster_is_modified = False
      tf_cluster = []
      for equiv_tok in equiv_tok_cluster:
        for tok_seq in equiv_tok.value:
          id_tok = tok_seq.value[0]
          tf = O.fdecl_by_identifier[id_tok.value]
          tf_cluster.append(tf)
          if (tf.is_modified):
            cluster_is_modified = tf.is_modified
      if (cluster_is_modified):
        for tf in tf_cluster:
          tf.is_modified = True

  def get_fdecl(O, id_tok):
    return O.fdecl_by_identifier[id_tok.value]

  def fmt_counts_by_statement_label(O):
    assert O.body_lines_processed_already
    result = O._fmt_counts_by_statement_label
    if (result is None):
      from libtbx import dict_with_default_0
      result = dict_with_default_0()
      for ei in O.executable:
        if (ei.key in ["read", "write", "print"] and ei.fmt_tokens is None):
          tl = ei.cilist.fmt
          if (tl is not None and len(tl) == 1):
            tok = tl[0]
            if (tok.is_integer()):
              result[tok.value] += 1
    return result

  def common_name_by_identifier(O):
    result = O._common_name_by_identifier
    if (result is None):
      result = {}
      for common_name,fdecl_list in O.common.items():
        for fdecl in fdecl_list:
          identifier = fdecl.id_tok.value
          if (identifier in result):
            fdecl.id_tok.raise_semantic_error(
              msg="Identifier appears in multiple COMMON statements: %s" %
                identifier)
          result[identifier] = common_name
      O._common_name_by_identifier = result
    return result

  def equivalence_info(O):
    result = O._equivalence_info
    if (result is None):
      cu = equivalence.cluster_unions()
      for equiv_tok in O.equivalence:
        cu.add(
          key_cluster=[tok_seq.value[0].value for tok_seq in equiv_tok.value])
      cu.tidy()
      result = equivalence_info()
      for i in range(len(cu.unions)):
        result.equiv_tok_clusters.append([])
      for equiv_tok in O.equivalence:
        result.equiv_tok_clusters[
          cu.indices[equiv_tok.value[0].value[0].value]].append(
            equiv_tok)
      result.set_derived()
      O._equivalence_info = result
    return result

  def classified_equivalence_info(O):
    assert O.fdecl_by_identifier is not None
    result = O._classified_equivalence_info
    if (result is None):
      result = classified_equivalence_info()
      equiv_info = O.equivalence_info()
      for equiv_tok_cluster in equiv_info.equiv_tok_clusters:
        highest_priority = 0
        for equiv_tok in equiv_tok_cluster:
          for tok_seq in equiv_tok.value:
            identifier = tok_seq.value[0].value
            fdecl = O.fdecl_by_identifier[identifier]
            if (fdecl.is_common()):
              priority = 3
            elif (fdecl.is_save()):
              priority = 2
            elif (fdecl.is_local()):
              priority = 1
            else:
              tok_seq.raise_semantic_error(msg="Invalid EQUIVALENCE")
            highest_priority = max(highest_priority, priority)
        assert highest_priority != 0
        slot = getattr(result, ["local", "save", "common"][highest_priority-1])
        slot.equiv_tok_clusters.append(
          equiv_info.equiv_tok_cluster_by_identifier[identifier])
      result.set_derived()
      O._classified_equivalence_info = result
    return result

  def set_uses_save(O):
    cei = O.classified_equivalence_info()
    O.uses_save = (len(O.data) != 0)
    if (not O.uses_save):
      for fdecl in O.fdecl_by_identifier.values():
        if (fdecl.is_save()):
         equiv_tok_cluster = cei.common.equiv_tok_cluster_by_identifier.get(
           fdecl.id_tok.value)
         if (equiv_tok_cluster is None):
           O.uses_save = True
           break

  def target_statement_labels(O):
    result = O._target_statement_labels
    if (O._target_statement_labels is None):
      result = {}
      for ei in O.executable:
        if (ei.key == "goto"):
          result.setdefault(ei.label.value, []).append(ei.label)
        elif (ei.key in ["goto_computed", "if_arithmetic"]):
          for tok in ei.labels:
            result.setdefault(tok.value, []).append(tok)
        elif (ei.key == "open"):
          if (ei.olist.err is not None):
            tok = tokenization.get_statement_label_token(tokens=ei.olist.err)
            result.setdefault(tok.value, []).append(tok)
        elif (ei.key == "close"):
          if (ei.cllist.err is not None):
            tok = tokenization.get_statement_label_token(tokens=ei.cllist.err)
            result.setdefault(tok.value, []).append(tok)
        elif (ei.key == "inquire"):
          if (ei.iuflist.err is not None):
            tok = tokenization.get_statement_label_token(tokens=ei.iuflist.err)
            result.setdefault(tok.value, []).append(tok)
        elif (ei.key == "file_positioning"):
          if (ei.alist.err is not None):
            tok = tokenization.get_statement_label_token(tokens=ei.alist.err)
            result.setdefault(tok.value, []).append(tok)
        elif (ei.key in ["read", "write"]):
          cilist = ei.cilist
          if (cilist is not None):
            for slot in ["end", "err"]:
              tokens = getattr(cilist, slot)
              if (tokens is not None):
                tok = tokenization.get_statement_label_token(tokens=tokens)
                result.setdefault(tok.value, []).append(tok)
      O._target_statement_labels = result
    return result

  def _eval_const_expression_simple_identifier(O,
        identifier, buffer, allow_power):
    if (identifier in O.dynamic_parameters):
      return False
    fdecl = O.fdecl_by_identifier.get(identifier)
    if (fdecl is None):
      return False
    tokens = fdecl.parameter_assignment_tokens
    if (tokens is None):
      return False
    code = tokenization.tokens_as_python_code(
      tokens=tokens, allow_power=allow_power)
    if (code is None):
      return False
    expr = "%s = %s" % (identifier, code)
    buffer.append(expr)
    return O._eval_const_expression_simple_tokens(
      tokens=tokens, buffer=buffer, allow_power=allow_power)

  def _eval_const_expression_simple_tokens(O,
        tokens, buffer, allow_power):
    for id_tok in tokenization.extract_identifiers(tokens=tokens):
      if (not O._eval_const_expression_simple_identifier(
        identifier=id_tok.value, buffer=buffer, allow_power=allow_power)):
          return False
    return True

  def eval_const_expression_simple(O,
        identifier=None, tokens=None, allow_power=True):
    assert O.fdecl_by_identifier is not None
    assert "_" not in O.fdecl_by_identifier # not supported
    assert [identifier, tokens].count(None) == 1
    buffer = []
    if (identifier is None):
      code = tokenization.tokens_as_python_code(
        tokens=tokens, allow_power=allow_power)
      if (code is None):
        return None
      buffer.append("_ = %s" % code)
      if (not O._eval_const_expression_simple_tokens(
            tokens=tokens, buffer=buffer, allow_power=allow_power)):
        return None
    else:
      if (not O._eval_const_expression_simple_identifier(
            identifier=identifier, buffer=buffer, allow_power=allow_power)):
        return None
    buffer.reverse()
    code = "\n".join(buffer)
    exec_globals = {}
    exec_locals = {}
    exec(code, exec_globals, exec_locals)
    if (identifier is None):
      result = exec_locals["_"]
    else:
      result = exec_locals[identifier]
    if (isinstance(result, float) and int(result) == result):
      result = int(result)
    return result

  def eval_dimensions_simple(O, dim_tokens, allow_power=True):
    vals = []
    for tok_seq in dim_tokens:
      if (tokenization.tok_seq_is_star(tok_seq=tok_seq)):
        vals.append(None)
      else:
        for i,tok in enumerate(tok_seq.value):
          if (tok.is_op_with(value=":")):
            fl = []
            for tokens in (tok_seq.value[:i], tok_seq.value[i+1:]):
              fl.append(O.eval_const_expression_simple(
                tokens=tokens, allow_power=allow_power))
            f,l = fl
            if (f is None or l is None):
              vals.append(None)
            else:
              vals.append(l-f+1)
            break
        else:
          vals.append(O.eval_const_expression_simple(
            tokens=tok_seq.value, allow_power=allow_power))
    return vals

class equivalence_info(object):

  __slots__ = [
    "equiv_tok_clusters",
    "equiv_tok_cluster_by_identifier",
    "identifier_clusters",
    "identifier_cluster_by_identifier"]

  def __init__(O):
    O.equiv_tok_clusters = []

  def set_derived(O):
    O.equiv_tok_cluster_by_identifier = {}
    O.identifier_clusters = []
    O.identifier_cluster_by_identifier = {}
    for equiv_tok_cluster in O.equiv_tok_clusters:
      identifier_cluster = []
      O.identifier_clusters.append(identifier_cluster)
      for equiv_tok in equiv_tok_cluster:
        for tok_seq in equiv_tok.value:
          identifier = tok_seq.value[0].value
          O.equiv_tok_cluster_by_identifier[identifier] = equiv_tok_cluster
          identifier_cluster.append(identifier)
          O.identifier_cluster_by_identifier[identifier] = identifier_cluster

class classified_equivalence_info(object):

  __slots__ = ["common", "save", "local"]

  def __init__(O):
    for slot in O.__slots__:
      setattr(O, slot, equivalence_info())

  def set_derived(O):
    for slot in O.__slots__:
      getattr(O, slot).set_derived()

  def has_save(O):
    return (len(O.save.equiv_tok_clusters) != 0)

class split_fprocs(object):

  __slots__ = [
    "program",
    "subroutine",
    "function",
    "blockdata",
    "all_in_input_order",
    "_fprocs_by_name",
    "_fprocs_by_name_plain"]

  def __init__(O):
    O.program = []
    O.subroutine = []
    O.function = []
    O.blockdata = []
    O.all_in_input_order = []
    O._fprocs_by_name = None
    O._fprocs_by_name_plain = None

  def by_type(O):
    return [O.program, O.blockdata, O.subroutine, O.function]

  def process(O, stripped_source_lines):
    ssls = iter(stripped_source_lines)
    leading_comments = []
    for curr_ssl in ssls:
      if (curr_ssl.is_comment()):
        leading_comments.append(curr_ssl)
        continue
      assert len(curr_ssl.code) != 0
      def collect_until_end(
            fproc_type, top_ssl, i_code, data_type, size_tokens,
            first_body_line=None):
        body_lines = []
        if (first_body_line is not None):
          body_lines.append(first_body_line)
        specific_end = "end"+fproc_type
        for ssl in ssls:
          if (ssl.code in ["end", specific_end]):
            result = fproc(
              leading_comments=leading_comments,
              top_ssl=top_ssl,
              fproc_type=fproc_type,
              i_code=i_code,
              data_type=data_type,
              size_tokens=size_tokens,
              body_lines=body_lines,
              end_ssl=ssl)
            O.all_in_input_order.append(result)
            return result
          body_lines.append(ssl)
        if (top_ssl is None):
          top_ssl = first_body_line
        top_ssl.raise_error(msg="Missing END for %s" % (fproc_type.upper()))
      for fproc_type in ["program", "blockdata", "subroutine", "function"]:
        if (fproc_type == "subroutine" and \
             curr_ssl.code.startswith('recursivesubroutine') ) \
               or curr_ssl.code.startswith(fproc_type):
          getattr(O, fproc_type).append(collect_until_end(
            fproc_type=fproc_type,
            top_ssl=curr_ssl,
            i_code=0,
            data_type=None,
            size_tokens=None))
          break
      else:
        i_code, data_type, size_tokens = extract_data_type_and_size(
          ssl=curr_ssl, optional=True)
        if (i_code is None or
              not curr_ssl.code.startswith("function", i_code)):
          O.program.append(collect_until_end(
            fproc_type="program",
            top_ssl=None,
            i_code=0,
            data_type=None,
            size_tokens=None,
            first_body_line=curr_ssl))
        else:
          O.function.append(collect_until_end(
            fproc_type="function",
            top_ssl=curr_ssl,
            i_code=i_code,
            data_type=data_type,
            size_tokens=size_tokens))
      leading_comments = []
    if (len(leading_comments) != 0 and len(O.all_in_input_order) != 0):
      O.all_in_input_order[-1].trailing_comments = leading_comments

  def show_counts_by_type(O, out=None, prefix=""):
    if (out is None): out = sys.stdout
    print(prefix + "Counts by Fortran procedure type:", file=out)
    for attr in O.__slots__[:4]:
      print(prefix + "  %s: %s" % (attr, len(getattr(O, attr))), file=out)

  def process_body_lines(O):
    for fproc in O.all_in_input_order:
      fproc.process_body_lines()

  def build_fdecl_by_identifier(O):
    for fproc in O.all_in_input_order:
      fproc.build_fdecl_by_identifier()

  def fprocs_by_name(O, plain=False):
    if (O._fprocs_by_name is None):
      O._fprocs_by_name = {}
      O._fprocs_by_name_plain = {}
      for fprocs in O.by_type():
        for fproc in fprocs:
          other = O._fprocs_by_name.get(fproc.name.value)
          if (other is not None):
            msg = ["Fortran procedure name conflict:"]
            for name in [other.name, fproc.name]:
              if (name.ssl is None):
                msg.append(
                  "  %d. definition: %s (implied)\n"
                  "    before %s" % (
                    len(msg),
                    fproc.name.value,
                    fproc.first_body_source_line()
                      .format_file_name_and_line_number()))
              else:
                msg.append(name.format_error(
                  msg="%d. definition" % len(msg), prefix="  "))
            from libtbx.utils import Sorry
            raise Sorry("\n".join(msg))
          O._fprocs_by_name[fproc.name.value] = fproc
          if (fproc.name_plain is not None):
            O._fprocs_by_name_plain[fproc.name_plain.value] = fproc
    if (plain):
      return O._fprocs_by_name_plain
    return O._fprocs_by_name

  def build_bottom_up_fproc_list_following_calls(O, top_procedures=None):
    return build_bottom_up_fproc_list_following_calls(
      all_fprocs=O, top_procedures=top_procedures)

class build_bottom_up_fproc_list_following_calls(object):

  __slots__ = [
    "all_fprocs",
    "top_procedures",
    "deps_by_fproc_identifier",
    "bottom_up_list",
    "forward_uses_by_identifier",
    "dependency_cycles",
    "missing_external_fdecls_by_identifier"]

  def __init__(O, all_fprocs, top_procedures=None):
    O.all_fprocs = all_fprocs
    O.top_procedures = top_procedures
    fprocs_by_name = O.all_fprocs.fprocs_by_name()
    #
    for fproc in O.all_fprocs.all_in_input_order:
      for fdecl in fproc.fdecl_by_identifier.values():
        if (    fdecl.is_user_defined_callable()
            and not fdecl.var_storage is vs_argument
            and len(fdecl.passed_as_arg_plain) != 0):
          def recursively_update_externals_passed(
                primary_external_identifier,
                procs_visited_already,
                caller_fdecl):
            for called_name,i_arg_set in \
                  caller_fdecl.passed_as_arg_plain.items():
              called_fproc = fprocs_by_name.get(called_name)
              if (called_fproc is None):
                continue
              for i_arg in i_arg_set:
                arg_identifier = called_fproc.args[i_arg].value
                primaries = called_fproc.externals_passed_by_arg_identifier \
                  .setdefault(arg_identifier, set())
                if (not primary_external_identifier in primaries):
                  primaries.add(primary_external_identifier)
                  if (called_name not in procs_visited_already):
                    procs_visited_already.add(called_name)
                    recursively_update_externals_passed(
                      primary_external_identifier=primary_external_identifier,
                      procs_visited_already=procs_visited_already,
                      caller_fdecl=called_fproc.fdecl_by_identifier[
                        arg_identifier])
          primary_external_identifier = fdecl.id_tok.value
          primary_fproc = fprocs_by_name.get(primary_external_identifier)
          if (primary_fproc is not None):
            primary_fproc.is_passed_as_external = True
          recursively_update_externals_passed(
            primary_external_identifier=primary_external_identifier,
            procs_visited_already=set([fproc.name.value]),
            caller_fdecl=fdecl)
    #
    O.deps_by_fproc_identifier = {}
    external_fdecls = {}
    def get_dependencies(fproc):
      deps = set()
      for primaries in fproc.externals_passed_by_arg_identifier.values():
        deps.update(primaries)
      for identifier in sorted(fproc.fdecl_by_identifier.keys()):
        if (identifier == fproc.name.value): continue
        fdecl = fproc.fdecl_by_identifier[identifier]
        if (    fdecl.is_user_defined_callable()
            and fdecl.var_storage is not vs_argument):
          deps.add(fdecl.id_tok.value)
          external_fdecls.setdefault(identifier, []).append(fdecl)
      if (fproc.is_program()):
        for b in O.all_fprocs.blockdata:
          deps.add(b.name.value)
      result = sorted(deps)
      O.deps_by_fproc_identifier[fproc.name.value] = result
      return result
    if (O.top_procedures is None or len(O.top_procedures) == 0):
      connections_for_topological_sort = []
      for fproc in O.all_fprocs.all_in_input_order:
        connections_for_topological_sort.append(
          (fproc.name.value, get_dependencies(fproc=fproc)))
    else:
      top_procedures_tidy = []
      for top_procedure_or_procedures in O.top_procedures:
        for top_procedure in top_procedure_or_procedures.split(","):
          top_fproc = fprocs_by_name.get(top_procedure)
          if (top_fproc is None):
            top_fproc = fprocs_by_name.get("program_"+top_procedure)
          if (top_fproc is None):
            raise RuntimeError(
              "Unknown Fortran procedure name: %s" % top_procedure)
          top_procedures_tidy.append(top_procedure)
          def recurse(fproc):
            for identifier in get_dependencies(fproc=fproc):
              if (identifier in O.deps_by_fproc_identifier):
                continue
              next_fproc = fprocs_by_name.get(identifier)
              if (next_fproc is not None):
                recurse(fproc=next_fproc)
          recurse(fproc=top_fproc)
      O.top_procedures = top_procedures_tidy
      connections_for_topological_sort = []
      for fproc in O.all_fprocs.all_in_input_order:
        if (fproc.name.value in O.deps_by_fproc_identifier):
          connections_for_topological_sort.append(
            (fproc.name.value, get_dependencies(fproc=fproc)))
    #
    from libtbx import topological_sort
    successors_by_node = dict(connections_for_topological_sort)
    O.bottom_up_list = []
    bottom_up_set = set()
    O.forward_uses_by_identifier = {}
    forward_uses_set = set()
    O.missing_external_fdecls_by_identifier = {}
    for identifier in topological_sort.stable(
                        connections=connections_for_topological_sort):
      fproc = fprocs_by_name.get(identifier)
      if (fproc is not None):
        O.bottom_up_list.append(fproc)
        bottom_up_set.add(identifier)
        for dep in successors_by_node[identifier]:
          if (    dep in successors_by_node
              and dep not in bottom_up_set
              and dep not in forward_uses_set):
            O.forward_uses_by_identifier.setdefault(identifier, []).append(dep)
            forward_uses_set.add(dep)
      elif (identifier not in all_fprocs.fprocs_by_name(plain=True)):
        O.missing_external_fdecls_by_identifier[identifier] = \
          external_fdecls[identifier]
    O.dependency_cycles = topological_sort.strongly_connected_components(
      successors_by_node=successors_by_node)

  def each_fproc_update_is_modified(O):
    fprocs_by_name = O.all_fprocs.fprocs_by_name()
    for caller_fproc in O.bottom_up_list:
      for caller_fdecl in caller_fproc.fdecl_by_identifier.values():
        for called_identifier, i_args in caller_fdecl.passed_as_arg.items():
          primaries = caller_fproc.externals_passed_by_arg_identifier.get(
            called_identifier)
          if (primaries is None):
            primaries = [called_identifier]
          for called_identifier in primaries:
            called_fproc = fprocs_by_name.get(called_identifier)
            if (called_fproc is not None):
              for i_arg in sorted(i_args):
                if (i_arg >= len(called_fproc.args_fdecl)):
                  continue
                arg_fdecl = called_fproc.args_fdecl[i_arg]
                if (arg_fdecl.is_modified):
                  caller_fdecl.is_modified = True
    return O

  def each_fproc_update_needs_cmn(O):
    fprocs_by_name = O.all_fprocs.fprocs_by_name()
    have_blockdata = (len(O.all_fprocs.blockdata) != 0)
    for caller_fproc in O.bottom_up_list:
      caller_fproc.needs_cmn = (
           caller_fproc.uses_common
        or caller_fproc.uses_save
        or caller_fproc.uses_io
        or caller_fproc.uses_iargc_getarg
        or (have_blockdata and caller_fproc.is_program())
        or len(caller_fproc.dynamic_parameters) != 0)
      if (not caller_fproc.needs_cmn):
        for dependency in O.deps_by_fproc_identifier.get(
                            caller_fproc.name.value, []):
          called_fproc = fprocs_by_name.get(dependency)
          if (called_fproc is not None and called_fproc.needs_cmn):
            caller_fproc.needs_cmn = True
            break
    return O

def process(file_names, basic_only=False, skip_load_includes=False):
  assert not skip_load_includes or basic_only
  all_fprocs = split_fprocs()
  import itertools
  global_line_index_generator = itertools.count()
  for file_name in file_names:
    all_fprocs.process(stripped_source_lines=load(
      global_line_index_generator=global_line_index_generator,
      file_name=file_name,
      skip_load_includes=skip_load_includes))
  if (not basic_only):
    all_fprocs.build_fdecl_by_identifier()
    for fproc in all_fprocs.all_in_input_order:
      fproc.common_name_by_identifier()
      fproc.set_uses_save()
      fproc.target_statement_labels()
  return all_fprocs


 *******************************************************************************


 *******************************************************************************
fable/run_tests.py
from __future__ import absolute_import, division, print_function
from libtbx import test_utils
import libtbx.load_env

tst_list = (
  "$D/tst_ext.py",
  "$D/tst_equivalence.py",
  "$D/tst_read.py",
  "$D/tst_cout.py",
  "$D/test/tst_show_calls.py",
  "$D/test/tst_command_line.py",
  "$D/test/tst_separate_files.py",
  ["$D/tst_cout_compile.py", "stop"],
  )

tst_list_expected_unstable = [
  "$D/test/tst_io.py",
]

def run():
  build_dir = libtbx.env.under_build("fable")
  dist_dir = libtbx.env.dist_path("fable")

  test_utils.run_tests(build_dir, dist_dir, tst_list)

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
fable/simple_compilation.py
from __future__ import absolute_import, division, print_function
import os
op = os.path

def quote(s):
  assert s.find('"') < 0
  return '"'+s+'"'

def quote_list(l):
  return " ".join([quote(s) for s in l])

class environment(object):

  __slots__ = [
    "compiler",
    "obj_suffix",
    "exe_suffix",
    "pch_suffix",
    "compiler_path",
    "gcc_version",
    "fable_dist",
    "tbxx_root",
    "__have_pch"]

  def __init__(O, compiler=None):
    if (os.name == "nt"):
      O.compiler = "cl"
      O.obj_suffix = ".obj"
      O.exe_suffix = ".exe"
      O.pch_suffix = None
    else:
      O.compiler = "g++"
      O.obj_suffix = ".o"
      O.exe_suffix = ""
      O.pch_suffix = ".gch"
    if (compiler is not None):
      O.compiler = compiler
    compiler_from_os_environ = os.environ.get("FABLE_COMPILER")
    if (compiler_from_os_environ is not None):
      O.compiler = compiler_from_os_environ
    from libtbx.path import full_command_path
    O.compiler_path = full_command_path(command=O.compiler+O.exe_suffix)
    import libtbx.load_env
    if (O.compiler == "g++" and O.compiler_path is not None):
      O.gcc_version = libtbx.env_config.get_gcc_version(
        command_name=O.compiler)
    else:
      O.gcc_version = None
    O.fable_dist = libtbx.env.dist_path(module_name="fable")
    if (op.isdir(op.join(O.fable_dist, "tbxx"))):
      O.tbxx_root = None
    else:
      O.tbxx_root = op.dirname(libtbx.env.dist_path(module_name="tbxx"))
    O.__have_pch = False

  def set_have_pch(O):
    O.__have_pch = True

  def assemble_include_search_paths(O, no_quotes=False):
    if (O.compiler == "cl"):
      sw = "/"
    else:
      sw = "-"
    def add_to_include_search_path(path):
      if (path is None): return ""
      if (not no_quotes):
        path = quote(path)
      return " %sI%s" % (sw, path)
    return "%s%s" % (
      add_to_include_search_path(O.fable_dist),
      add_to_include_search_path(O.tbxx_root))

  def assemble_command(O,
        link,
        disable_warnings,
        file_names,
        out_name):
    qon = quote(out_name)
    import libtbx.load_env
    if (O.compiler == "cl"):
      if (not link): part = "/c /Fo%s" % qon
      else:          part = "/Fe%s" % qon
      result = "%s /nologo /EHsc %s%s %s" % (
        O.compiler,
        part,
        O.assemble_include_search_paths(),
        quote_list(file_names))
    else:
      if (not link): opt_c = "-c "
      else:          opt_c = ""
      if (disable_warnings or O.gcc_version < 30400):
        opt_w = "-w"
      else:
        opt_w = "-Wall -Wno-sign-compare -Winvalid-pch -Wno-deprecated-declarations"
      if (out_name.endswith(O.pch_suffix)):
        assert not O.__have_pch
        opt_x = " -x c++-header"
      else:
        opt_x = ""
      if (not O.__have_pch):
        opt_i = O.assemble_include_search_paths()
      else:
        opt_i = " -I."
      if libtbx.env.build_options.enable_cxx11:
        opt_11 = " -std=c++11"
      else:
        opt_11 = ""
      result = "%s -o %s %s%s -g -O0%s%s%s %s" % (
        O.compiler, qon, opt_c, opt_w, opt_i, opt_x, opt_11, quote_list(file_names))
      print(result)
    return result

  def file_name_obj(O, file_name_cpp):
    assert file_name_cpp.endswith(".cpp")
    return file_name_cpp[:-4] + O.obj_suffix

  def file_name_exe(O, exe_root):
    return exe_root + O.exe_suffix

  def compilation_command(O, file_name_cpp, disable_warnings=False):
    return O.assemble_command(
      link=False,
      disable_warnings=disable_warnings,
      file_names=[file_name_cpp],
      out_name=O.file_name_obj(file_name_cpp=file_name_cpp))

  def link_command(O, file_names_obj, exe_root):
    return O.assemble_command(
      link=True,
      disable_warnings=False,
      file_names=file_names_obj,
      out_name=O.file_name_exe(exe_root=exe_root))

  def build(O,
        link,
        file_name_cpp,
        obj_name=None,
        exe_name=None,
        pch_name=None,
        disable_warnings=False,
        show_command=False,
        Error=RuntimeError):
    assert [obj_name, exe_name, pch_name].count(None) >= 2
    if (link):
      out_name = exe_name
      out_suffix = O.exe_suffix
    elif (pch_name is None):
      out_name = obj_name
      out_suffix = O.obj_suffix
    else:
      assert O.pch_suffix is not None
      out_name = pch_name + O.pch_suffix
      out_suffix = None
    if (out_name is None):
      assert file_name_cpp.endswith(".cpp")
      out_name = file_name_cpp[:-4] + out_suffix
    from libtbx.utils import remove_files
    remove_files(out_name)
    cmd = O.assemble_command(
      link=link,
      disable_warnings=disable_warnings,
      file_names=[file_name_cpp],
      out_name=out_name)
    if (show_command):
      print(cmd)
    from libtbx import easy_run
    buffers = easy_run.fully_buffered(command=cmd)
    if (O.compiler != "cl" or buffers.stderr_lines != [file_name_cpp]):
      buffers.raise_if_errors(Error=Error)
    return out_name


 *******************************************************************************


 *******************************************************************************
fable/test/sf_times.py
from __future__ import absolute_import, division, print_function
from libtbx.test_utils import approx_equal
from libtbx.utils import Usage
from libtbx import easy_run
import libtbx.load_env
import platform
import time
import sys, os
from six.moves import range
from six.moves import zip
op = os.path

__this_script__ = "cctbx_project/fable/test/sf_times.py"
       # based on  cctbx_project/compcomm/newsletter09/sf_times.py

setup_dir = "/net/cci/setup/Linux"

ifort_versions = ["intel121.sh", "intel111.sh", "ifort91.sh"]

icc_versions = [
  "intel121.sh",
  "intel111.sh",
  "icc101.sh",
  "icc91.sh"]

gcc_versions = [
  "gcc-4.6.1_fc8.sh",
  "gcc-4.5.3_fc8.sh",
  "gcc-4.4.6_fc8.sh",
  "gcc-4.3.6_fc8.sh",
  "gcc-4.2.4_fc8.sh"]

fortran_template = r"""C %(this_script)s

      subroutine cos_wrapper(result, arg)
      REAL result
      REAL arg
      result = COS(arg)
      return
      end

      subroutine exp_wrapper(result, arg)
      REAL result
      REAL arg
      result = EXP(arg)
      return
      end

      subroutine sf(abcss, n_scatt, xyz, b_iso, n_refl, hkl, f_calc)
      implicit none
      REAL abcss(3)
      integer n_scatt
      REAL xyz(3, *)
      REAL b_iso(*)
      integer n_refl
      integer hkl(3, *)
      REAL f_calc(2, *)
      integer i_refl, i_scatt, j, h
      REAL phi, cphi, sphi, dss, ldw, dw, a, b
      DO i_refl=1,n_refl
        a = 0
        b = 0
        DO i_scatt=1,n_scatt
          phi = 0
          DO j=1,3
            phi = phi + hkl(j,i_refl) * xyz(j,i_scatt)
          enddo
          phi = phi * 2 * 3.1415926535897931
          call cos_wrapper(cphi, phi)
          call cos_wrapper(sphi, phi - 3.1415926535897931*0.5)
          dss = 0
          DO j=1,3
            h = hkl(j,i_refl)
            dss = dss + h*h * abcss(j)
          enddo
          ldw = -0.25 * dss * b_iso(i_scatt)
          call exp_wrapper(dw, ldw)
          a = a + dw * cphi
          b = b + dw * sphi
        enddo
        f_calc(1, i_refl) = a
        f_calc(2, i_refl) = b
      enddo
      return
      end

      program run
      implicit none
      REAL abcss(3)
      integer n_scatt
      parameter(n_scatt=%(n_scatt)s)
      REAL xyz(3, n_scatt)
      REAL b_iso(n_scatt)
      integer n_refl
      parameter(n_refl=%(n_refl)s)
      integer hkl(3, n_refl)
      REAL f_calc(2, n_refl)
      integer i, j, jr
      REAL a, b, max_a, max_b
      abcss(1) = 1/(11.0*11.0)
      abcss(2) = 1/(12.0*12.0)
      abcss(3) = 1/(13.0*13.0)
      jr = 0
      DO i=1,n_scatt
        DO j=1,3
          jr = mod(jr*1366+150889, 714025)
          xyz(j,i) = (mod(jr, 20000) - 10000) / 10000.0
        enddo
      enddo
      DO i=1,n_scatt
        jr = mod(jr*1366+150889, 714025)
        b_iso(i) = mod(jr, 10000) / 100.0
      enddo
      if (n_scatt .le. 10) then
        DO i=1,n_scatt
          write(6, '(4(1x,f9.6))')
     &      xyz(1,i), xyz(2,i), xyz(3, i), b_iso(i)
        enddo
      endif
      DO i=1,n_refl
        DO j=1,3
          jr = mod(jr*1366+150889, 714025)
          hkl(j,i) = mod(jr, 10) - 5
        enddo
      enddo
      call sf(abcss, n_scatt, xyz, b_iso, n_refl, hkl, f_calc)
      if (n_refl .le. 100) then
        DO i=1,n_refl
          write(6, '(3(1x,i3),1x,f12.6,1x,f12.6)')
     &      hkl(1,i), hkl(2,i), hkl(3,i),
     &      f_calc(1,i), f_calc(2,i)
        enddo
      else
        max_a = 0
        max_b = 0
        DO i=1,n_refl
          a = f_calc(1,i)
          b = f_calc(2,i)
          if (max_a .lt. a) max_a = a
          if (max_b .lt. b) max_b = b
        enddo
        write(6, '(2(1x,f12.6))') max_a, max_b
      endif
      end
"""

def compare_with_cctbx_structure_factors(n_scatt, n_refl, output_lines):
  from cctbx import xray
  from cctbx import miller
  from cctbx import crystal
  from cctbx.array_family import flex
  crystal_symmetry = crystal.symmetry(
    unit_cell=(11,12,13,90,90,90),
    space_group_symbol="P1")
  scatterers = flex.xray_scatterer()
  miller_indices = flex.miller_index()
  f_calc = flex.complex_double()
  for line in output_lines:
    flds = line.split()
    assert len(flds) in [4,5]
    if (len(flds) == 4):
      x,y,z,b_iso = [float(s) for s in flds]
      scatterers.append(
        xray.scatterer(site=(x,y,z), b=b_iso, scattering_type="const"))
    else:
      miller_indices.append([int(s) for s in flds[:3]])
      f_calc.append(complex(float(flds[3]), float(flds[4])))
  assert scatterers.size() == n_scatt
  assert miller_indices.size() == n_refl
  xs = xray.structure(
    crystal_symmetry=crystal_symmetry,
    scatterers=scatterers)
  fc = miller_array = miller.set(
    crystal_symmetry=crystal_symmetry,
    indices=miller_indices,
    anomalous_flag=False).array(data=f_calc)
  fc2 = fc.structure_factors_from_scatterers(
    xray_structure=xs,
    algorithm="direct",
    cos_sin_table=False).f_calc()
  for f1,f2 in zip(fc.data(), fc2.data()):
    assert approx_equal(f1, f2, eps=1e-5)

def build_run(
      setup_cmd, ld_preload_flag, n_scatt, n_refl, build_cmd, check_max_a_b):
  if (op.isfile("a.out")):
    os.remove("a.out")
  assert not op.isfile("a.out")
  print(build_cmd)
  buffers = easy_run.fully_buffered(command=build_cmd)
  msg = buffers.format_errors_if_any()
  if (msg is not None):
    if (0):
      print(build_cmd)
      print()
      print(msg)
      print()
      STOP()
    return None
  assert op.isfile("a.out")
  run_cmd = setup_cmd
  if (ld_preload_flag):
    run_cmd += 'env LD_PRELOAD='\
    '"/net/marbles/raid1/rwgk/dist/opt_resources/linux64/libimf.so:"'\
    '"/net/marbles/raid1/rwgk/dist/opt_resources/linux64/libirc.so" '
  utimes = []
  run_cmd += '/usr/bin/time -p ./a.out'
  def run_once():
    buffers = easy_run.fully_buffered(command=run_cmd)
    if (len(buffers.stderr_lines) != 3):
      print("v"*79)
      print("\n".join(buffers.stderr_lines))
      print("^"*79)
      raise RuntimeError(
        "Unexpected number of output lines"
        " (3 expected; acutal output see above).")
    if (n_scatt == 0):
      pass
    elif (n_scatt <= 10 and n_refl <= 100):
      assert len(buffers.stdout_lines) == n_scatt + n_refl
    else:
      assert len(buffers.stdout_lines) == 1
      max_a, max_b = [float(s) for s in buffers.stdout_lines[0].split()]
    if (check_max_a_b):
      if (n_scatt == 2000 and n_refl == 20000):
        assert approx_equal(max_a, 35.047157, eps=1e-4)
        assert approx_equal(max_b, 25.212738, eps=1e-4)
      elif (n_scatt == 100 and n_refl == 1000):
        assert approx_equal(max_a,  4.493645, eps=1e-4)
        assert approx_equal(max_b, 10.515532, eps=1e-4)
      elif (n_scatt <= 10 and n_refl <= 100):
        if (libtbx.env.has_module(name="cctbx")):
          compare_with_cctbx_structure_factors(
            n_scatt=n_scatt,
            n_refl=n_refl,
            output_lines=buffers.stdout_lines)
      else:
        raise RuntimeError(max_a, max_b)
    utime = float(buffers.stderr_lines[1].split()[1])
    utimes.append(utime)
    print("sample utime: %.2f" % utime)
    sys.stdout.flush()
  for _ in range(8):
    run_once()
  return min(utimes)

def finalize_cpp_build_cmd(source_cpp):
  from fable import simple_compilation
  comp_env = simple_compilation.environment()
  return comp_env.assemble_include_search_paths(no_quotes=False) \
    + " " + source_cpp

def write_build_run(
      setup_cmd, ld_preload_flag, n_scatt, n_refl, real, lang, build_cmd,
      replace_cos, replace_exp):
  this_script = __this_script__
  for_txt = fortran_template % vars()
  if (replace_cos):
    for_txt = for_txt.replace(
      "COS(arg)",
      "arg / (abs(arg)+1.0)")
  if (replace_exp):
    for_txt = for_txt.replace(
      "EXP(arg)",
      "max(0.0, 1.0 - arg*arg)")
  for_txt = for_txt.replace("REAL", real)
  open("tmp.f", "w").write(for_txt)
  from fable import cout
  cpp_txt = cout.process(
    file_names=["tmp.f"],
    namespace="sf_test",
    fem_do_safe=False,
    inline_all=True)
  open("tmp.cpp", "w").write("\n".join(cpp_txt)+"\n")
  if (lang.lower() == "f"):
    build_cmd += " tmp.f"
  elif (lang.lower() == "c"):
    build_cmd += finalize_cpp_build_cmd("tmp.cpp")
  else:
    raise RuntimeError('Unknown lang: "%s"' % lang)
  return build_run(
    setup_cmd=setup_cmd,
    ld_preload_flag=ld_preload_flag,
    n_scatt=n_scatt,
    n_refl=n_refl,
    build_cmd=build_cmd,
    check_max_a_b=(not (replace_cos or replace_exp)))

def run_combinations(
      compiler_versions,
      all_utimes,
      n_scatt,
      n_refl,
      compiler_build_opts_list,
      real_list):
  for lang,setup_sh_list,compiler,build_opts in compiler_build_opts_list:
    for setup_sh in setup_sh_list:
      if (setup_sh is None):
        setup_cmd = ""
      else:
        setup_cmd = ". %s/%s; " % (setup_dir, setup_sh)
      compiler_version = easy_run.fully_buffered(
        command=setup_cmd+compiler+" --version",
        join_stdout_stderr=True).stdout_lines[0]
      if (lang in ["f", "c"]):
        ld_preload_flags = [False, True]
      else:
        ld_preload_flags = [False]
      for ld_preload_flag in ld_preload_flags:
        iml = ["", " Intel Math Lib"][int(ld_preload_flag)]
        compiler_versions.append(compiler_version + iml)
        build_cmd = " ".join([setup_cmd+compiler, build_opts])
        print(build_cmd)
        utimes = []
        if (n_scatt != 0):
          for real in real_list:
            print("  %s" % real)
            for replace_cos in [False, True]:
              print("    replace_cos", replace_cos)
              for replace_exp in [False, True]:
                print("      replace_exp", replace_exp)
                sys.stdout.flush()
                if (compiler_version != "n/a"):
                  utime = write_build_run(
                    setup_cmd=setup_cmd,
                    ld_preload_flag=ld_preload_flag,
                    n_scatt=n_scatt,
                    n_refl=n_refl,
                    real=real,
                    lang=lang,
                    build_cmd=build_cmd,
                    replace_cos=replace_cos,
                    replace_exp=replace_exp)
                  if (utime is not None):
                    print("        %4.2f" % utime)
                  else:
                    utime = -1.0
                    print("        err")
                else:
                  utime = -1.0
                  print("        n/a")
                utimes.append(utime)
                sys.stdout.flush()
        else:
          if (lang.lower() == "f"):
            f_source = libtbx.env.find_in_repositories(
              relative_path="lapack_fem/dsyev_test.f",
              test=op.isfile,
              optional=False)
            build_cmd_compl = build_cmd + " " + f_source
          else:
            cpp_source = libtbx.env.find_in_repositories(
              relative_path="lapack_fem/dsyev_test.cpp",
              test=op.isfile,
              optional=False)
            build_cmd_compl = build_cmd + finalize_cpp_build_cmd(cpp_source)
          utime = build_run(
            setup_cmd=setup_cmd,
            ld_preload_flag=ld_preload_flag,
            n_scatt=n_scatt,
            n_refl=n_refl,
            build_cmd=build_cmd_compl,
            check_max_a_b=False)
          if (utime is None):
            print("err")
            utime = -1.0
          else:
            print("min utime: %.2f" % utime)
          sys.stdout.flush()
          utimes.append(utime)
        all_utimes.append((utimes, build_cmd + iml))

def usage():
  raise Usage("fable.python sf_times.py unit_test|quick|production")

def run(args):
  if (len(args) != 1): usage()
  t_start = time.time()
  build_platform = platform.platform()
  build_node = platform.node()
  compiler_versions = []
  if (args[0] == "unit_test"):
    n_scatt, n_refl = 10, 100
  elif (args[0] == "quick"):
    n_scatt, n_refl = 100, 1000
  elif (args[0] == "production"):
    n_scatt, n_refl = 2000, 20000
  elif (args[0] == "dsyev"):
    n_scatt, n_refl = 0, 0
  else:
    usage()
  gcc_sh = gcc_versions + [None]
  icc_sh = icc_versions
  if (args[0] == "quick"):
    gcc_sh = gcc_sh[:2]
    icc_sh = icc_sh[:1]
  all_utimes = []
  run_combinations(
    compiler_versions,
    all_utimes,
    n_scatt=n_scatt,
    n_refl=n_refl,
    compiler_build_opts_list=[
      ("F", ifort_versions, "ifort", "-O"),
      ("f", gcc_sh, "gfortran", "-O3 -ffast-math"),
      ("f", gcc_sh, "gfortran", "-O3 -ffast-math -march=native"),
      ("C", icc_sh, "icpc", "-O"),
      ("c", gcc_sh, "g++", "-O3 -ffast-math"),
      ("c", gcc_sh, "g++", "-O3 -ffast-math -march=native"),
      ("c", [None], "clang++",
        "-O3 -U__GXX_WEAK__ -Wno-logical-op-parentheses -ffast-math"),
      ("c", [None], "clang++",
        "-O3 -U__GXX_WEAK__ -Wno-logical-op-parentheses -ffast-math"
        " -march=native")],
    real_list=["real*4", "real*8"])
  print()
  print("current_platform:", platform.platform())
  print("current_node:", platform.node())
  print("build_platform:", build_platform)
  print("build_node:", build_node)
  for compiler_version in compiler_versions:
    print("compiler:", compiler_version)
  if (n_scatt != 0):
    print("n_scatt * n_refl: %d * %d" % (n_scatt, n_refl))
    print('''\
"s" or "d": single-precision or double-precision floating-point variables
"E" or "e": using the library exp(arg) function or "max(0.0, 1.0 - arg*arg)"
"C" or "c": using the library cos(arg) function or "arg / (abs(arg)+1.0)"''')
    print("  sEC    seC    sEc    sec    dEC    deC    dEc    dec")
  else:
    print("dsyev times:")
  useful_utimes = []
  for utimes,build_cmd in all_utimes:
    if (max(utimes) != -1.0):
      print(" ".join(["%6.2f" % u for u in utimes]), build_cmd)
      useful_utimes.append((utimes,build_cmd))
  if (len(useful_utimes) > 1):
    print("Relative to first:")
    for utimes,build_cmd in useful_utimes:
      print(" ".join(["%6.2f" % (u/max(u0,0.01))
        for u,u0 in zip(utimes,useful_utimes[0][0])]), build_cmd)
  print("Wall clock time: %.2f s" % (time.time()-t_start))

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
fable/test/tst_command_line.py
from __future__ import absolute_import, division, print_function
def run(args):
  assert len(args) == 0
  from libtbx import easy_run
  import libtbx.load_env
  import os
  op = os.path
  t_dir = libtbx.env.under_dist(
    module_name="fable", path="test/valid", test=op.isdir)
  assert t_dir.find('"') < 0
  n_errors = 0
  for command,expected_output_fragment in [
        ('fable.split "%ssubroutine_1.f"', 'program_prog.f'),
        ('fable.read --each "%swrite_star.f"', 'Success: 1'),
        ('fable.read --warnings "%sequivalence_mixed.f"',
          'Warning: EQUIVALENCE cluster with mixed data types: integer, real:'),
        ('fable.show_calls --write-graphviz-dot=tmp.dot'
          ' --top-procedure=sub "%sexternal_arg_layers.f"',
            'exch->exch_imp'),
        ('fable.show_calls "%sdependency_cycle.f"', 'sub1 sub2'),
        ('fable.fem_include_search_paths --with-quotes', 'fable'),
        ('fable.cout --each "%swrite_star.f"', 'return fem::main_with_catch'),
        ('fable.cout "%scommon_variants.f"',
          'Writing file: "fable_cout_common_report"'),
        ('fable.cout "%ssubroutine_3.f" --top-procedure=sub3'
         ' --fortran-file-comments',
          'nums(i) = i * 20;'),
        ('fable.cout --compile "%swrite_star.f"',
          'placeholder_please_replace::program_prog);'),
        ('fable.cout --namespace=test --run "%swrite_star.f"',
          'test::program_prog);'),
        ('fable.cout --example', '  -3   1  -5'),
        ('fable.cout %ssf.f --namespace example --run', '  -3   1  -5'),
        ('fable.cout "%sdynamic_parameters_1.f"'
          ' --dynamic-parameter="int root_size=1"',
            "const int root_size = cmn.dynamic_params.root_size;")]:
    if (expected_output_fragment.find("fable_cout_common_report") >= 0):
      join_stdout_stderr = True
    else:
      join_stdout_stderr = False
    if (command.find("%s") >= 0):
      command = command % (t_dir + os.sep)
    print(command)
    run_buffers = easy_run.fully_buffered(
      command=command,
      join_stdout_stderr=join_stdout_stderr)
    class SpecificError(RuntimeError): pass
    try:
      if (not join_stdout_stderr):
        run_buffers.raise_if_errors(Error=SpecificError)
    except SpecificError as e:
      n_errors += 1
      print("ERROR:")
      print( str(e) )
      print()
    else:
      stdout_buffer = "\n".join(run_buffers.stdout_lines)
      if (expected_output_fragment is None):
        if (len(stdout_buffer) != 0):
          n_errors += 1
          print(stdout_buffer)
          print("ERROR: unexpected output above.")
          print()
      elif (stdout_buffer.find(expected_output_fragment) < 0):
        n_errors += 1
        print(stdout_buffer)
        print("ERROR: not found in output above:")
        print([expected_output_fragment])
        print()
  if (n_errors != 0):
    print("Number of errors:", n_errors)
    print("Done.")
  else:
    print("OK")

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
fable/test/tst_io.py
from __future__ import absolute_import, division, print_function
from libtbx.test_utils import show_diff
from libtbx import easy_run
import os
op = os.path

def remove_file(path):
  if (op.exists(path)):
    os.remove(path)
  assert not op.exists(path)

class build_cmds_class(object):
 def __init__(self):
  # prevent race condition by naming each executable uniquely
  self.iteration = 0
 def __call__(self,tst_f, opts, ignore_ifort=False):
  self.iteration += 1
  from fable import simple_compilation
  comp_env = simple_compilation.environment()
  exe = comp_env.exe_suffix
  result = []
  if (opts.ifort and not ignore_ifort):
    remove_file("a.out")
    cmd = "ifort -diag-disable 7951 %s" % tst_f
    if (opts.verbose): print(cmd)
    easy_run.fully_buffered(command=cmd).raise_if_errors()
    assert op.exists("a.out")
    result.append("a.out")
  #remove_file("fable_cout")
  cmd = "fable.cout %s --link --exe_name=fable_cout%02d" %(tst_f,self.iteration)
  if (opts.verbose): print(cmd)
  easy_run.fully_buffered(command=cmd).raise_if_errors()
  assert op.exists("fable_cout%02d"%self.iteration+exe)
  result.append("fable_cout%02d"%self.iteration+exe)
  return [op.join(".", cmd) for cmd in result]

build_cmds = build_cmds_class()

def exercise_open(opts):
  for status in ["old", "new", "unknown", "scratch"]:
    tst_f = "exercise_open_%s.f" % status
    with open(tst_f, "w") as f:
      f.write("""\
        program prog
        open(1, file='exercise_open.tmp', status='%s', iostat=ios)
        write(6, '(l1)') (ios .eq. 0)
        end
""" % status)
    #
    for cmd in build_cmds(tst_f=tst_f, opts=opts):
      remove_file("exercise_open.tmp")
      stdout_1 = easy_run.fully_buffered(
        command=cmd).raise_if_errors().stdout_lines
      exists_1 = op.exists("exercise_open.tmp")
      #
      f = open("exercise_open.tmp", "w")
      f.close()
      assert op.exists("exercise_open.tmp")
      stdout_2 = easy_run.fully_buffered(
        command=cmd).raise_if_errors().stdout_lines
      exists_2 = op.exists("exercise_open.tmp")
      #
      with open("exercise_open.tmp", "w") as f:
        f.write("X")
      stdout_3 = easy_run.fully_buffered(
        command=cmd).raise_if_errors().stdout_lines
      exists_3 = op.exists("exercise_open.tmp")
      if (exists_3):
        size_3 = op.getsize("exercise_open.tmp")
      else:
        size_3 = None
      #
      results = [
        stdout_1, exists_1, stdout_2, exists_2, stdout_3, exists_3, size_3]
      if (opts.verbose): print("%-12s" % cmd, results)
      expected = {
        "old": [['F'], False, ['T'], True, ['T'], True, 1],
        "new": [['T'], True, ['F'], True, ['F'], True, 1],
        "unknown": [['T'], True, ['T'], True, ['T'], True, 1],
        "scratch": [['T'], False, ['T'], True, ['T'], True, 1]}
      assert results == expected[status]

def exercise_mixed_read_write(opts):
  tmp = "exercise_mixed_read_write.tmp"
  tst_f = "exercise_mixed_read_write.f"
  with open(tst_f, "w") as f:
    f.write("""\
      program prog
      open(
     &  unit=1,
     &  file='%s',
     &  status='old')
      read(1, '(i2)') num
      write(6, '(i2)') num*2
      write(1, '(i2)') 78
      end
""" % tmp)
  for cmd in build_cmds(tst_f=tst_f, opts=opts):
    if (opts.verbose): print(cmd)
    with open(tmp, "w") as f:
      f.write("""\
12
34
56
""")
    stdout = easy_run.fully_buffered(
      command=cmd).raise_if_errors().stdout_lines
    assert stdout == ["24"]
    with open(tmp, "rb") as f:
      tmp_text = f.read()
    assert not show_diff(tmp_text, b"""\
12
78
""".replace(b"\n", os.linesep.encode("latin-1")))

def exercise_read_from_non_existing_file(opts):
  tst_f = "exercise_read_from_non_existing_file.f"
  remove_file("fem_io_unit_001")
  with open(tst_f, "w") as f:
    f.write("""\
      program prog
      read(1, *) num
      end
""")
  for cmd in build_cmds(tst_f=tst_f, opts=opts, ignore_ifort=True):
    stdout = easy_run.fully_buffered(
      command=cmd, join_stdout_stderr=True).stdout_lines
    assert not show_diff(stdout, """\
std::exception what(): End of input during read
""")

def run(args):
  from libtbx.option_parser import option_parser
  command_line = (option_parser(
    usage="fable.python %s [options]" % __file__)
    .option(None, "--ifort",
      action="store_true",
      default=False)
    .option(None, "--verbose",
      action="store_true",
      default=False)
  ).process(args=args)
  keys = set(command_line.args)
  exercises = set()
  for key in globals().keys():
    if (key.startswith("exercise_")):
      exercises.add(key[9:])
  assert len(keys) == 0 or keys.issubset(exercises)
  co = command_line.options
  from libtbx.utils import show_times_at_exit
  show_times_at_exit()
  if (len(keys) == 0 or "open" in keys):
    exercise_open(opts=co)
  if (len(keys) == 0 or "mixed_read_write" in keys):
    exercise_mixed_read_write(opts=co)
  if (len(keys) == 0 or "read_from_non_existing_file" in keys):
    exercise_read_from_non_existing_file(opts=co)
  print("OK")

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
fable/test/tst_separate_files.py
from __future__ import absolute_import, division, print_function
import os
op = os.path

def remove_file_if_necessary(file_name):
  if (op.isfile(file_name)): os.remove(file_name)
  if (op.exists(file_name)):
    from libtbx.str_utils import show_string
    raise RuntimeError(
      "Unable to remove file: %s" % show_string(file_name))

def exercise(
      verbose,
      file_names_cpp,
      number_of_function_files=None,
      separate_files_main_namespace={},
      separate_files_separate_namespace={}):
  if (verbose): print("next exercise")
  import libtbx.load_env
  test_valid = libtbx.env.under_dist(
    module_name="fable", path="test/valid", test=op.isdir)
  import fable.cout
  top_cpp = fable.cout.process(
    file_names=[op.join(test_valid, "subroutine_3.f")],
    top_procedures=["prog"],
    namespace="tst_separate_files",
    top_cpp_file_name=file_names_cpp[0],
    number_of_function_files=number_of_function_files,
    separate_files_main_namespace=separate_files_main_namespace,
    separate_files_separate_namespace=separate_files_separate_namespace)
  from fable import simple_compilation
  comp_env = simple_compilation.environment()
  from libtbx import easy_run
  file_names_obj = []
  for file_name_cpp in file_names_cpp:
    obj = comp_env.file_name_obj(file_name_cpp=file_name_cpp)
    remove_file_if_necessary(file_name=obj)
    cmd = comp_env.compilation_command(file_name_cpp=file_name_cpp)
    if (verbose): print(cmd)
    assert not easy_run.call(command=cmd)
    assert op.exists(obj)
    file_names_obj.append(obj)
  exe_root = "tst_separate_files"
  exe = comp_env.file_name_exe(exe_root=exe_root)
  remove_file_if_necessary(file_name=exe)
  cmd = comp_env.link_command(file_names_obj=file_names_obj, exe_root=exe_root)
  if (verbose): print(cmd)
  assert not easy_run.call(command=cmd)
  cmd = op.join(".", exe)
  if (verbose): print(cmd)
  assert op.exists(cmd)
  stdout = easy_run.fully_buffered(command=cmd).raise_if_errors().stdout_lines
  text = "\n".join(stdout)
  if (verbose):
    print(text)
  from fable.tst_cout_compile import read_file_names_and_expected_cout
  info = read_file_names_and_expected_cout(test_valid=test_valid).get(
    "subroutine_3.f")[0]
  from libtbx.test_utils import show_diff
  assert not show_diff(text, "\n".join(info.out_lines))
  if (verbose): print()

def run(args):
  assert args in [[], ["--verbose"]]
  verbose = (args == ["--verbose"])
  from libtbx.utils import show_times_at_exit
  show_times_at_exit()
  all = True
  if (0 or all):
    exercise(verbose,
      file_names_cpp=["top.cpp", "functions.cpp"],
      number_of_function_files=1)
  if (0 or all):
    exercise(verbose,
      file_names_cpp=["top.cpp", "subs.cpp"],
      separate_files_separate_namespace={"subs": ["sub1", "sub2"]})
  if (0 or all):
    exercise(verbose,
      file_names_cpp=["top.cpp", "subs.cpp", "functions.cpp"],
      number_of_function_files=1,
      separate_files_separate_namespace={"subs": ["sub1", "sub2"]})
  if (0 or all):
    exercise(verbose,
      file_names_cpp=["top.cpp", "subs.cpp"],
      separate_files_main_namespace={"subs": ["sub1", "sub2"]})
  if (0 or all):
    exercise(verbose,
      file_names_cpp=["top.cpp", "subs.cpp", "functions.cpp"],
      number_of_function_files=1,
      separate_files_main_namespace={"subs": ["sub1", "sub2"]})
  print("OK")

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
fable/test/tst_show_calls.py
from __future__ import absolute_import, division, print_function
def run(args):
  assert len(args) == 0
  import libtbx.load_env
  from six.moves import StringIO
  import os
  op = os.path
  t_dir = libtbx.env.under_dist(
    module_name="fable", path="test/valid", test=op.isdir)
  excluded_file_names = set("""\
blockdata_unnamed.f
""".splitlines())
  from fable.command_line import show_calls
  for file_name in os.listdir(t_dir):
    if (not file_name.endswith(".f")): continue
    if (file_name in excluded_file_names): continue
    sys.stdout = StringIO()
    show_calls.run(args=[op.join(t_dir, file_name)])
    sys.stdout = sys.__stdout__
  print ("OK")

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
fable/tokenization.py
from __future__ import absolute_import, division, print_function
from fable \
  import unsigned_integer_scan, \
  identifier_scan, \
  floating_point_scan_after_exponent_char, \
  floating_point_scan_after_dot

class token(object):

  __slots__ = ["typeid", "ssl", "i_code", "value"]

  def __init__(O, typeid, ssl, i_code, value):
    O.typeid = typeid
    O.ssl = ssl
    O.i_code = i_code
    O.value = value

  def type(O):
    return [
      "identifier",
      "integer",
      "hexadecimal",
      "real",
      "double_precision",
      "logical",
      "string",
      "op",
      "complex",
      "seq",
      "parentheses",
      "implied_do",
      "power",
      "format"][O.typeid]

  def is_identifier(O): return O.typeid == 0
  def is_integer(O): return O.typeid == 1
  def is_hexadecimal(O): return O.typeid == 2
  def is_real(O): return O.typeid == 3
  def is_double_precision(O): return O.typeid == 4
  def is_logical(O): return O.typeid == 5
  def is_string(O): return O.typeid == 6
  def is_op(O): return O.typeid == 7
  def is_complex(O): return O.typeid == 8
  def is_seq(O): return O.typeid == 9
  def is_parentheses(O): return O.typeid == 10
  def is_implied_do(O): return O.typeid == 11
  def is_power(O): return O.typeid == 12
  def is_format(O): return O.typeid == 13

  def is_identifier_or_scalar_number(O):
    return O.typeid <= 4

  def is_op_with(O, value):
    return O.typeid == 7 and O.value == value

  def is_unary_plus_or_minus(O):
    return O.typeid == 7 and O.value in ["+", "-"]

  def is_seq_or_parentheses(O):
    return 9 <= O.typeid <= 10

  def is_seq_or_parentheses_or_implied_do(O):
    return 9 <= O.typeid <= 11

  def stmt_location(O):
    return O.ssl.stmt_location(i=O.i_code)

  def format_error(O, msg, prefix=""):
    return O.ssl.format_error(msg=msg, i=O.i_code, prefix=prefix)

  def raise_error(O, msg, ErrorType=None):
    O.ssl.raise_error(msg=msg, i=O.i_code, ErrorType=ErrorType)

  def raise_syntax_error(O):
    O.ssl.raise_syntax_error(i=O.i_code)

  def raise_semantic_error(O, msg=None):
    O.ssl.raise_semantic_error(msg=msg, i=O.i_code)

  def raise_not_supported(O):
    O.raise_error(
      msg="Sorry: not supported",
      ErrorType=RuntimeError)

  def raise_internal_error(O):
    O.ssl.raise_internal_error(i=O.i_code)

  def raise_if_not_identifier(O):
    i = identifier_scan(code=O.value)
    if (i < 0 or i != len(O.value)):
      O.raise_error(msg="Not an identifier: %s" % repr(O.value))

  def raise_missing_closing(O):
    O.raise_error(msg='Missing a closing ")"')

  def raise_missing_opening(O):
    O.raise_error(msg='Closing ")" without a matching opening parenthesis')

  def fquote(O):
    return "'" + O.value.replace("'", "''") + "'"

def tk_identifier(ssl, i_code, value): return token(0, ssl, i_code, value)
def tk_integer(ssl, i_code, value): return token(1, ssl, i_code, value)
def tk_hexadecimal(ssl, i_code, value): return token(2, ssl, i_code, value)
def tk_real(ssl, i_code, value): return token(3, ssl, i_code, value)
def tk_double_precision(ssl, i_code, value): return token(4, ssl, i_code, value)
def tk_logical(ssl, i_code, value): return token(5, ssl, i_code, value)
def tk_string(ssl, i_code, value): return token(6, ssl, i_code, value)
def tk_op(ssl, i_code, value): return token(7, ssl, i_code, value)
def tk_complex(ssl, i_code, value): return token(8, ssl, i_code, value)
def tk_seq(ssl, i_code, value): return token(9, ssl, i_code, value)
def tk_parentheses(ssl, i_code, value): return token(10, ssl, i_code, value)
def tk_implied_do(ssl, i_code, value): return token(11, ssl, i_code, value)
def tk_power(ssl, i_code, value): return token(12, ssl, i_code, value)
def tk_format(ssl, i_code, value): return token(13, ssl, i_code, value)

class ssl_iterator(object):
  "stripped source line iterator"

  __slots__ = ["ssl", "start", "stop", "i", "buffer"]

  def __init__(O, ssl, start, stop=None):
    O.ssl = ssl
    O.start = start
    if (stop is None): O.stop = len(ssl.code)
    else:              O.stop = stop
    O.i = start
    O.buffer = []

  def __iter__(O): return O

  def __next__(self):
    tok = self.get(optional=True)
    if (tok is None):
      raise StopIteration
    return tok

  def next(self):
    return self.__next__()

  def get(O, optional=False):
    ssl = O.ssl
    code = ssl.code
    stop = O.stop
    def return_none():
      if (not optional):
        if (stop == 0): ssl.raise_syntax_error()
        else:           ssl.raise_syntax_error(i=stop-1)
      O.i = None
      return None
    if (len(O.buffer) != 0):
      O.i, result = O.buffer.pop(0)
      if (result is None):
        return_none()
      return result
    if (O.i is None):
      if (optional):
        return None
      ssl.raise_internal_error(i=stop-1)
    while (O.i < stop):
      i_code = O.i
      c = code[i_code]
      if ("=<>".find(c) >= 0):
        if (code.startswith("=", i_code+1)):
          O.i += 2
          return tk_op(ssl=ssl, i_code=i_code, value=code[i_code:i_code+2])
        O.i += 1
        return tk_op(ssl=ssl, i_code=i_code, value=c)
      if ("(),:+-".find(c) >= 0):
        O.i += 1
        return tk_op(ssl=ssl, i_code=i_code, value=c)
      if (c == "'"):
        O.i += 1
        return tk_string(
          ssl=ssl,
          i_code=i_code,
          value=ssl.strings[ssl.string_indices.index(i_code)])
      if (c == "x" and code.startswith("'", i_code+1)):
        O.i += 2
        return tk_hexadecimal(
          ssl=ssl,
          i_code=i_code,
          value=ssl.strings[ssl.string_indices.index(i_code+1)])
      j = identifier_scan(code=code, start=i_code)
      if (j > 0):
        O.i = j
        return tk_identifier(ssl=ssl, i_code=i_code, value=code[i_code:j])
      if (c == "*"):
        if (code.startswith("*", i_code+1)):
          O.i += 2
          return tk_op(ssl=ssl, i_code=i_code, value="**")
        O.i += 1
        return tk_op(ssl=ssl, i_code=i_code, value="*")
      if (c == "/"):
        if (code.startswith("/", i_code+1)):
          O.i += 2
          return tk_op(ssl=ssl, i_code=i_code, value="//")
        if (code.startswith("=", i_code+1)):
          O.i += 2
          return tk_op(ssl=ssl, i_code=i_code, value="/=")
        O.i += 1
        return tk_op(ssl=ssl, i_code=i_code, value="/")
      if (c == "."):
        return O.__after_dot(i_fld=i_code, i_dot=i_code)
      j = unsigned_integer_scan(code=code, start=i_code, stop=stop)
      if (j > 0):
        if (j == stop):
          O.i = j
          return tk_integer(ssl=ssl, i_code=i_code, value=code[i_code:j])
        cj = code[j]
        if (cj == "."):
          if (j + 1 == stop):
            O.i = stop
            return tk_real(ssl=ssl, i_code=i_code, value=code[i_code:stop])
          return O.__after_dot(i_fld=i_code, i_dot=j)
        if (cj == "e" or cj == "d"):
          k = floating_point_scan_after_exponent_char(
            code=code, start=j+1, stop=stop)
          if (k < 0):
            ssl.raise_error(
              msg="Invalid floating-point literal", i=j+1)
          O.i = k
          if (cj == "d"):
            return tk_double_precision(
              ssl=ssl, i_code=i_code, value=code[i_code:k])
          return tk_real(ssl=ssl, i_code=i_code, value=code[i_code:k])
        O.i = j
        return tk_integer(ssl=ssl, i_code=i_code, value=code[i_code:j])
      ssl.raise_syntax_error(i=i_code)
    return_none()

  def __after_dot(O, i_fld, i_dot):
    ssl = O.ssl
    stop = O.stop
    if (i_dot + 1 == stop):
      ssl.raise_error(
        msg="Expression unexpectedly ends with a dot", i=i_dot)
    code = ssl.code
    csw = code.startswith
    c = code[i_dot+1]
    if (c == "a"):
      if (not csw("nd.", i_dot+2)):
        ssl.raise_syntax_error(i=i_dot+2)
      tok = tk_op(ssl=ssl, i_code=i_dot, value=".and.")
      if (i_dot == i_fld):
        O.i = i_dot+5
        return tok
      O.buffer.append((i_dot+5, tok))
      O.i = i_dot
      return tk_integer(ssl=ssl, i_code=i_fld, value=code[i_fld:i_dot])
    if (c == "o"):
      if (not csw("r.", i_dot+2)):
        ssl.raise_syntax_error(i=i_dot+2)
      tok = tk_op(ssl=ssl, i_code=i_dot, value=".or.")
      if (i_dot == i_fld):
        O.i = i_dot+4
        return tok
      O.buffer.append((i_dot+4, tok))
      O.i = i_dot
      return tk_integer(ssl=ssl, i_code=i_fld, value=code[i_fld:i_dot])
    if (c == "e" or c == "d"):
      if (c == "e"):
        if (csw("q.", i_dot+2)):
          tok = tk_op(ssl=ssl, i_code=i_dot, value=".eq.")
          if (i_dot == i_fld):
            O.i = i_dot+4
            return tok
          O.buffer.append((i_dot+4, tok))
          O.i = i_dot
          return tk_integer(ssl=ssl, i_code=i_fld, value=code[i_fld:i_dot])
        if (csw("qv.", i_dot+2)):
          tok = tk_op(ssl=ssl, i_code=i_dot, value=".eqv.")
          if (i_dot == i_fld):
            O.i = i_dot+5
            return tok
          O.buffer.append((i_dot+5, tok))
          return tk_integer(ssl=ssl, i_code=i_fld, value=code[i_fld:i_dot])
      if (i_dot == i_fld):
        ssl.raise_syntax_error(i=i_dot+1)
      j = floating_point_scan_after_exponent_char(
        code=code, start=i_dot+2, stop=stop)
      if (j < 0):
        ssl.raise_syntax_error(i=i_dot+1)
      O.i = j
      if (c == "d"):
        return tk_double_precision(
          ssl=ssl, i_code=i_fld, value=code[i_fld:j])
      return tk_real(ssl=ssl, i_code=i_fld, value=code[i_fld:j])
    if (c == "f"):
      if (not csw("alse.", i_dot+2) or i_dot != i_fld):
        ssl.raise_syntax_error(i=i_dot+1)
      O.i = i_dot+7
      return tk_logical(ssl=ssl, i_code=i_dot, value=".false.")
    if (c == "t"):
      if (not csw("rue.", i_dot+2) or i_dot != i_fld):
        ssl.raise_syntax_error(i=i_dot+1)
      O.i = i_dot+6
      return tk_logical(ssl=ssl, i_code=i_dot, value=".true.")
    if (c == "n"):
      if (csw("ot.", i_dot+2)):
        if (i_dot != i_fld):
          ssl.raise_syntax_error(i=i_dot+1)
        O.i = i_dot+5
        return tk_op(ssl=ssl, i_code=i_dot, value=".not.")
      if (csw("e.", i_dot+2)):
        tok = tk_op(ssl=ssl, i_code=i_dot, value=".ne.")
        if (i_dot == i_fld):
          O.i = i_dot+4
          return tok
        O.buffer.append((i_dot+4, tok))
        O.i = i_dot
        return tk_integer(ssl=ssl, i_code=i_fld, value=code[i_fld:i_dot])
      if (csw("eqv.", i_dot+2)):
        tok = tk_op(ssl=ssl, i_code=i_dot, value=".neqv.")
        if (i_dot == i_fld):
          O.i = i_dot+6
          return tok
        O.buffer.append((i_dot+6, tok))
        O.i = i_dot
        return tk_integer(ssl=ssl, i_code=i_fld, value=code[i_fld:i_dot])
      ssl.raise_syntax_error(i=i_dot+1)
    if (c == "g" or c == "l"):
      if (not csw("t.", i_dot+2) and not csw("e.", i_dot+2)):
        ssl.raise_syntax_error(i=i_dot+1)
      tok = tk_op(ssl=ssl, i_code=i_dot, value=code[i_dot:i_dot+4])
      if (i_dot == i_fld):
        O.i = i_dot+4
        return tok
      O.buffer.append((i_dot+4, tok))
      O.i = i_dot
      return tk_integer(ssl=ssl, i_code=i_fld, value=code[i_fld:i_dot])
    j = floating_point_scan_after_dot(code=code, start=i_dot+1, stop=stop)
    if (j < 0):
      ssl.raise_syntax_error(i=i_dot+1)
    O.i = j
    if (code.find("d", i_dot+1, O.i) < 0): tk_type = tk_real
    else:                                  tk_type = tk_double_precision
    return tk_type(ssl=ssl, i_code=i_fld, value=code[i_fld:j])

  def look_ahead(O, optional=False):
    if (len(O.buffer) != 0):
      return O.buffer[0][1]
    prev_i = O.i
    tok = O.get(optional=optional)
    O.buffer.append((O.i, tok))
    O.i = prev_i
    return tok

  def get_complex_literal(O, opening_token):
    assert opening_token.ssl is O.ssl
    invalid_message = "Invalid complex number literal"
    result = [opening_token]
    def get_part():
      tok = O.get()
      sign_tok = None
      if (tok.is_op()):
        if (tok.value not in ["+", "-"]):
          tok.raise_error(msg=invalid_message)
        sign_tok = tok
        tok = O.get()
      if (not tok.is_identifier_or_scalar_number()):
        tok.raise_error(msg=invalid_message)
      return (sign_tok, tok)
    result.append(get_part())
    tok = O.get()
    if (not tok.is_op_with(value=",")):
      tok.raise_error(msg=invalid_message)
    result.append(get_part())
    tok = O.get()
    if (not tok.is_op_with(value=")")):
      tok.raise_error(msg=invalid_message)
    result.append(tok)
    return tk_complex(ssl=O.ssl, i_code=opening_token.i_code, value=result)

  def get_inside_parentheses(O, opening_token):
    tok = O.get(optional=True)
    if (tok is None):
      opening_token.raise_missing_closing()
    return tok

  def collect_comma_separated_identifiers(O,
        callback,
        one_required=False,
        enable_common=False):
    n_list = 0
    while True:
      tok = O.get(optional=not one_required)
      if (tok is None):
        break
      if (tok.is_identifier()):
        callback(tok)
      elif (not enable_common):
        tok.raise_syntax_error()
      else:
        if (not tok.is_op_with("/")):
          tok.raise_syntax_error()
        tok = O.get()
        if (not tok.is_identifier()):
          tok.raise_syntax_error()
        tok = O.get()
        if (not tok.is_op_with("/")):
          tok.raise_syntax_error()
        # SAVE of COMMON are ignored (considered redundant)
      n_list += 1
      tok = O.get(optional=True)
      if (tok is None):
        break
      if (not tok.is_op_with(value=",")):
        tok.raise_syntax_error()
      one_required = True
    return n_list

  def collect_comma_separated_expressions(O,
        callback,
        opening_token=None,
        first_get_optional=True,
        stop_after_given_number_of_commas=None,
        enable_implied_do=0):
    tokens = tk_seq(ssl=O.ssl, i_code=O.i, value=[])
    tapp = tokens.value.append
    last_comma = None
    n_callbacks = 0
    i_assignment_op = None
    get_optional = first_get_optional
    while True:
      tok = O.get(optional=get_optional)
      get_optional = True
      if (tok is None):
        if (opening_token is not None):
          opening_token.raise_missing_closing()
        if (len(tokens.value) == 0):
          if (last_comma is None):
            return None
          last_comma.raise_syntax_error()
        callback(tokens)
        return None
      if (tok.is_op()):
        tv = tok.value
        if (tv ==")"):
          if (opening_token is None):
            tok.raise_missing_opening()
          if (i_assignment_op is None):
            if (enable_implied_do == 2):
              tok.raise_syntax_error()
          elif (i_assignment_op == n_callbacks):
            tok.raise_syntax_error()
          if (len(tokens.value) == 0):
            if (last_comma is None):
              return i_assignment_op
            last_comma.raise_syntax_error()
          callback(tokens)
          return i_assignment_op
        if (tv == ","):
          if (len(tokens.value) == 0):
            tok.raise_syntax_error()
          callback(tokens)
          n_callbacks += 1
          if (stop_after_given_number_of_commas is not None
                and n_callbacks == stop_after_given_number_of_commas):
            return
          tokens = tk_seq(ssl=O.ssl, i_code=O.i, value=[])
          tapp = tokens.value.append
          last_comma = tok
        elif (tv == "("):
          nested_tokens = []
          if (O.collect_comma_separated_expressions(
                callback=nested_tokens.append,
                opening_token=tok,
                enable_implied_do=int(enable_implied_do!=0)) is None):
            tk_type = tk_parentheses
          else:
            tk_type = tk_implied_do
          tapp(tk_type(
            ssl=tok.ssl, i_code=tok.i_code, value=nested_tokens))
        elif (tv == "="):
          if (   opening_token is None
              or enable_implied_do == 0
              or n_callbacks == 0
              or i_assignment_op is not None
              or len(tokens.value) != 1
              or not tokens.value[0].is_identifier()):
            tok.raise_syntax_error()
          i_assignment_op = n_callbacks
          tapp(tok)
        else:
          tapp(tok)
      else:
        tapp(tok)

  def collect_to_matching_parenthesis(O, callback, opening_token):
    nested_tokens = []
    O.collect_comma_separated_expressions(
      callback=nested_tokens.append,
      opening_token=opening_token)
    callback(tk_parentheses(
      ssl=opening_token.ssl, i_code=opening_token.i_code, value=nested_tokens))

  def get_implied_do(O, opening_token):
    result = []
    O.collect_comma_separated_expressions(
      callback=result.append,
      opening_token=opening_token,
      enable_implied_do=2)
    return tk_implied_do(ssl=O.ssl, i_code=opening_token.i_code, value=result)

def remove_redundant_parentheses(tokens):
  result = []
  for tok in tokens:
    def handle_seq_with_one_parentheses():
      if (tok.is_seq()):
        tv = tok.value
        if (len(tv) == 1):
          inner_tok = tv[0]
          if (inner_tok.is_parentheses()):
            result.extend(
              remove_redundant_parentheses(tokens=inner_tok.value))
            return
      return result.append(tok)
    handle_seq_with_one_parentheses()
  return result

def group_power(tokens):
  result = []
  i_tok = 0
  n_toks = len(tokens)
  while (i_tok < n_toks):
    tok = tokens[i_tok]; i_tok += 1
    if (tok.is_op_with(value="**")):
      if (len(result) == 0):
        tok.raise_syntax_error()
      if (i_tok == len(tokens)):
        tok.raise_syntax_error()
      if (    result[-1].is_parentheses()
          and len(result) != 1
          and result[-2].is_identifier()):
        base_tok = tk_seq(
          ssl=result[-2].ssl,
          i_code=result[-2].i_code,
          value=result[-2:])
        result.pop()
      else:
        base_tok = result[-1]
      result.pop()
      exponent_tok = tokens[i_tok]; i_tok += 1
      if (    exponent_tok.is_identifier()
          and i_tok < len(tokens)
          and tokens[i_tok].is_parentheses()):
        next_tok = tokens[i_tok]; i_tok += 1
        exponent_tok = tk_seq(
          ssl=exponent_tok.ssl,
          i_code=exponent_tok.i_code,
          value=[exponent_tok, next_tok])
      result.append(tk_power(
        ssl=exponent_tok.ssl,
        i_code=exponent_tok.i_code,
        value=[base_tok, exponent_tok]))
    else:
      result.append(tok)
  return result

class implied_do_info(object):

  __slots__ = ["dlist_size", "id_tok", "fls_tokens"]

  def __init__(O, tokens):
    assert len(tokens) >= 3
    def get_first_tokens(i):
      tok = tokens[i]
      if (not tok.is_seq()): return False
      tv = tok.value
      if (len(tv) < 3): return False
      if (not tv[0].is_identifier()): return False
      if (not tv[1].is_op_with(value="=")): return False
      O.dlist_size = len(tokens) + i
      O.id_tok = tv[0]
      O.fls_tokens = [tk_seq(ssl=tv[2].ssl, i_code=tv[2].i_code, value=tv[2:])]
      return True
    if (get_first_tokens(i=-2)):
      O.fls_tokens.append(tokens[-1])
    else:
      assert get_first_tokens(i=-3)
      O.fls_tokens.extend(tokens[-2:])

def tok_seq_is_star(tok_seq):
  return (len(tok_seq.value) == 1 and tok_seq.value[0].is_op_with(value="*"))

def tokens_as_strings(tokens, result=None):
  if (result is None):
    result = []
  for tok in tokens:
    if (tok.is_seq()):
      result.append("[")
      tokens_as_strings(tokens=tok.value, result=result)
      result.append("]")
    elif (tok.is_parentheses()):
      result.append("(")
      tokens_as_strings(tokens=tok.value, result=result)
      result.append(")")
    elif (tok.is_implied_do()):
      result.append("{")
      tokens_as_strings(tokens=tok.value, result=result)
      result.append("}")
    elif (tok.is_string()):
      result.append(tok.fquote())
    elif (tok.is_power()):
      result.append("power(")
      tokens_as_strings(tokens=tok.value, result=result)
      result.append(")")
    elif (tok.is_format()):
      result.append("format(" + tok.fquote() + ")")
    else:
      result.append(tok.value)
  return result

def tokens_as_string(tokens):
  return " ".join(tokens_as_strings(tokens=tokens))

def tokens_as_python_code(tokens, result=None, allow_power=True):
  join_result = (result is None)
  if (join_result):
    result = []
  for tok in tokens:
    if (tok.is_seq()):
      if (tokens_as_python_code(tokens=tok.value, result=result) is None):
        return None
    elif (tok.is_parentheses()):
      result.append("(")
      if (tokens_as_python_code(tokens=tok.value, result=result) is None):
        return None
      result.append(")")
    elif (tok.is_implied_do()):
      return None
    elif (tok.is_string()):
      return None
    elif (tok.is_power()):
      return None
    elif (tok.is_format()):
      return None
    elif (not allow_power and tok.is_op_with(value="**")):
      return None
    else:
      result.append(tok.value)
  if (join_result):
    return " ".join(result)
  return result

def search_for_id_tokens(callback, tokens, with_next_token):
  for i_tok,tok in enumerate(tokens):
    if (tok.is_seq_or_parentheses_or_implied_do()):
      search_for_id_tokens(
        callback=callback, tokens=tok.value, with_next_token=with_next_token)
    elif (tok.is_identifier()):
      if (not with_next_token):
        callback(tok)
      else:
        next_tok = None
        j_tok = i_tok + 1
        if (j_tok != len(tokens)):
          next_tok = tokens[j_tok]
        callback(tok, next_tok)

def extract_identifiers(tokens, result=None):
  if (result is None): result = []
  search_for_id_tokens(
    callback=result.append, tokens=tokens, with_next_token=False)
  return result

def search_for_data_or_read_target_tokens(callback, tokens):
  for tok in tokens:
    assert tok.is_seq()
    if (len(tok.value) == 0):
      continue
    first_target_tok = tok.value[0]
    if (first_target_tok.is_identifier()):
      callback(tok=first_target_tok)
    elif (first_target_tok.is_implied_do()):
      idi = implied_do_info(tokens=first_target_tok.value)
      search_for_data_or_read_target_tokens(
        callback=callback, tokens=first_target_tok.value[:idi.dlist_size])

class fss_iterator(object):
  "format string stripped iterator"

  __slots__ = ["fss", "i"]

  def __init__(O, fss):
    O.fss = fss
    O.i = 0

  def __iter__(O): return O

  def __next__(self):
    tok = self.get()
    if (tok is None):
      raise StopIteration
    return tok

  def next(self):
    return self.__next__()

  def get(O):
    fss = O.fss
    code = fss.code
    stop = len(code)
    assert O.i is not None
    def raise_invalid():
      fss.raise_error(msg="Invalid FORMAT specification", i=min(stop-1, O.i))
    while (O.i < stop):
      i_code = O.i
      c = code[i_code]
      if (c == ","):
        O.i += 1
        continue
      if (c == "x"):
        O.i += 1
        return tk_format(ssl=fss, i_code=i_code, value="1x")
      if ("():/$".find(c) >= 0):
        O.i += 1
        return tk_op(ssl=fss, i_code=i_code, value=c)
      if (c == "'"):
        O.i += 1
        return tk_string(
          ssl=fss,
          i_code=i_code,
          value=fss.strings[fss.string_indices.index(i_code)])
      if (c == "+" or c == "-"):
        j = unsigned_integer_scan(code=code, start=i_code+1, stop=stop)
        if (j < 0 or not code.startswith("p", j)):
          raise_invalid()
        O.i = j + 1
        return tk_format(
          ssl=fss,
          i_code=i_code,
          value=code[i_code:O.i])
      j = unsigned_integer_scan(code=code, start=i_code, stop=stop)
      if (j > 0):
        O.i = j
        if (code.startswith("h", O.i)):
          # extract Hollerith edit descriptor if it did not confuse the
          # previous ignorant parsing algorithms
          sl, i_text = fss.text_location(i=O.i)
          assert sl.text[i_text].lower() == "h"
          i_text += 1
          nh = int(code[i_code:j])
          j_text = i_text + nh
          tv = sl.text[i_text:j_text]
          if (len(tv) != nh):
            raise RuntimeError(fss.format_error(
              i=i_code,
              msg="FATAL: Not supported: FORMAT Hollerith edit descriptor"
                  " spanning continuation lines"))
          if (tv.find("'") >= 0 or tv.find('"') >= 0):
            raise RuntimeError(fss.format_error(
              i=i_code,
              msg="FATAL: Not supported:"
                  " FORMAT Hollerith edit descriptor with quotes"))
          while (O.i < stop):
            sl, i_text = fss.text_location(i=O.i)
            if (i_text >= j_text):
              break
            O.i += 1
          return tk_string(ssl=fss, i_code=i_code, value=tv)
        if (code.startswith("x", O.i) or code.startswith("p", O.i)):
          O.i += 1
          return tk_format(ssl=fss, i_code=i_code, value=code[i_code:O.i])
        return tk_integer(ssl=fss, i_code=i_code, value=code[i_code:j])
      if ("defgiz".find(c) >= 0):
        j = unsigned_integer_scan(code=code, start=i_code+1, stop=stop)
        if (j > 0):
          O.i = j
          if (code.startswith(".", j)):
            j = unsigned_integer_scan(code=code, start=j+1, stop=stop)
            if (j < 0):
              raise_invalid()
            O.i = j
        return tk_format(ssl=fss, i_code=i_code, value=code[i_code:O.i])
      if (c == "a" or c == "l"):
        O.i += 1
        j = unsigned_integer_scan(code=code, start=i_code+1, stop=stop)
        if (j > 0):
          O.i = j
        return tk_format(ssl=fss, i_code=i_code, value=code[i_code:O.i])
      if (code.startswith("bn", i_code) or code.startswith("bz", i_code)):
        O.i += 2
        return tk_format(ssl=fss, i_code=i_code, value=code[i_code:O.i])
      if (c == "s"):
        O.i += 1
        if (code.startswith("p", O.i) or code.startswith("s", O.i)):
          O.i += 1
        return tk_format(ssl=fss, i_code=i_code, value=code[i_code:O.i])
      if (c == "t"):
        O.i += 1
        if (code.startswith("l", O.i) or code.startswith("r", O.i)):
          O.i += 1
        j = unsigned_integer_scan(code=code, start=O.i, stop=stop)
        if (j < 0):
          raise_invalid()
        O.i = j
        return tk_format(ssl=fss, i_code=i_code, value=code[i_code:O.i])
      raise_invalid()
    O.i = None
    return None

def get_statement_label_token(tokens):
  assert len(tokens) != 0
  tok = tokens[0]
  if (len(tokens) != 1 or not tok.is_integer()):
    tok.raise_error(msg="Invalid statement label")
  return tok

def fmt_tokens_as_string(tokens, comma=","):
  result = []
  def result_ends_with_comma():
    return (len(result) != 0 and result[-1] == comma)
  for tok in tokens:
    if (tok.is_integer()):
      result.append(tok.value)
    elif (tok.is_string()):
      result.append("'" + tok.value.replace("'","''") + "'")
      result.append(comma)
    elif (tok.is_format()):
      result.append(tok.value)
      result.append(comma)
    elif (tok.is_op()):
      tv = tok.value
      if (tv == "(" or tv == ")"):
        if (result_ends_with_comma()):
          result.pop()
        result.append(tv)
        if (tv == ")"): result.append(comma)
      else:
        result.append(tv)
        result.append(comma)
    else:
      raise AssertionError
  if (result_ends_with_comma()):
    result.pop()
  return "".join(result)


 *******************************************************************************


 *******************************************************************************
fable/tst_cout.py
from __future__ import absolute_import, division, print_function
from fable import cout
from libtbx.test_utils import \
  Exception_expected, show_diff, anchored_block_show_diff as absd
import libtbx.load_env
from six.moves import StringIO
import os
op = os.path

def head_off(i): return i + 5
def tail_off(i): return -(i + 12) - 1

common_argc_argv = """\
  common(
    int argc,
    char const* argv[])
  :
    fem::common(argc, argv)
  {}"""

def exercise_simple(verbose):
  t_dir = libtbx.env.under_dist(
    module_name="fable", path="test/valid", test=op.isdir)
  def get(
        file_name,
        top_procedures=None,
        data_specializations=True,
        arr_nd_size_max=None,
        inline_all=False):
    if (verbose):
      print("exercise_simple:", file_name)
    file_names = [op.join(t_dir, file_name)]
    common_report_stringio = StringIO()
    return cout.process(
      file_names=file_names,
      top_procedures=top_procedures,
      data_specializations=data_specializations,
      fem_do_safe=False,
      arr_nd_size_max=arr_nd_size_max,
      inline_all=inline_all,
      common_report_stringio=common_report_stringio)
  #
  assert not show_diff(get("add_reals.f"), """\
#include <fem.hpp> // Fortran EMulation library of fable module

namespace placeholder_please_replace {

using namespace fem::major_types;

using fem::common;

void
program_prog(
  int argc,
  char const* argv[])
{
  if (argc != 1) {
    throw std::runtime_error("Unexpected command-line arguments.");
  }
  float a = fem::float0;
  float b = fem::float0;
  float c = a + b;
}

} // namespace placeholder_please_replace

int
main(
  int argc,
  char const* argv[])
{
  return fem::main_with_catch(
    argc, argv,
    placeholder_please_replace::program_prog);
}
""")
  #
  assert not absd(get("add_real_integer.f"), tail_off(1), """\
  float a = fem::float0;
  int i = fem::int0;
  float c = a + i;
""")
  #
  assert not absd(get("logical_a_or_b.f"), tail_off(1), """\
  bool a = fem::bool0;
  bool b = fem::bool0;
  bool c = a || b;
""")
  #
  assert not absd(get("add_dp_integer.f"), tail_off(1), """\
  double a = fem::double0;
  int i = fem::int0;
  double c = a + i;
""")
  #
  assert not absd(get("add_strings.f"), tail_off(17), """\
  fem::str<3> a = "x\\"z";
  fem::str<4> b = "i\\\\'l";
  fem::str<7> c = a + b;
""")
  #
  lines = get("real_array_sum.f")
  assert not absd(lines, tail_off(1), """\
  arr<float> a(dimension(2), fem::fill0);
  float sum_a = a(1) + a(2);
""")
  lines = get("real_array_sum.f", arr_nd_size_max=2)
  assert not absd(lines, tail_off(2), """\
  arr_1d<2, float> a(fem::fill0);
""")
  #
  assert not absd(get("write_star.f"), tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  fem::str<1> c = "x";
  write(6, star), c;
  write(6, star), "i is zero.";
  bool l = fem::bool0;
  write(6, star), l;
  int i = fem::int0;
  write(6, star), i;
  fem::integer_star_8 j = fem::zero<fem::integer_star_8>();
  write(6, star), j;
  float r = fem::float0;
  write(6, star), r;
  double d = fem::double0;
  write(6, star), d;
  write(6, star), 1.e111;
  write(6, star), -1.e111;
  write(6, star);
  write(6, star), c, c, c, c, c, c, c, c, c, c, c, c;
  write(6, star), "i is ", "zero", ".";
  write(6, star), l, l, l, l, l, l, l, l, l, l, l, l;
  write(6, star), i, i, i, i, i, i, i, i, i, i, i, i;
  write(6, star), j, j, j, j, j, j, j, j, j, j, j, j;
  write(6, star), r, r, r, r, r, r, r, r, r, r, r, r;
  write(6, star), d, d, d, d, d, d, d, d, d, d, d, d;
  fem::str<1> s1 = "x";
  fem::str<2> s2 = "yz";
  write(6, star), s1, s1;
  write(6, star), s1, s2;
  write(6, star), s2, s1;
  write(6, star), s2, s2;
  write(6, star), s1, 12;
  write(6, star), s2, 34;
  write(6, star), 56, s1;
  write(6, star), 78, s2;
  write(6, star), "aBcD ", 12, " eFgHi ", 345;
""")
  #
  assert not absd(get("tab_syndrome.f"), tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  int i = 1;
  write(6, star), i;
  i = 3;
  write(6, star), i;
  i = 5;
  write(6, star), i;
  i = 7;
  write(6, star), i;
  i = 123456;
  write(6, star), i;
""")
  #
  assert not absd(get("ops.f"), tail_off(1), """\
  bool la = fem::bool0;
  bool lb = !la;
  write(6, star), la && lb;
  write(6, star), la || lb;
  float b = 1;
  float a = fem::float0;
  write(6, star), a + b;
  write(6, star), a - b;
  write(6, star), a * b;
  write(6, star), a / b;
  fem::str<2> sa = "x";
  fem::str<3> sb = "abc";
  write(6, star), sa + sb;
  write(6, star), a == b;
  write(6, star), a != b;
  write(6, star), a < b;
  write(6, star), a <= b;
  write(6, star), a > b;
  write(6, star), a >= b;
  write(6, star), a == b;
  write(6, star), a != b;
  write(6, star), a < b;
  write(6, star), a <= b;
  write(6, star), a > b;
  write(6, star), a >= b;
""")
  #
  assert not absd(get("mod_integers.f"), tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  write(6, star), fem::mod(13, 5);
""")
  #
  assert not absd(get("do_enddo.f"), tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  int i = fem::int0;
  FEM_DO(i, 1, 2) {
    write(6, star), i;
  }
  {
    int fem_do_last = 2 * 3;
    FEM_DO(i, 1, fem_do_last) {
      write(6, star), i;
    }
  }
  int j = fem::int0;
  FEM_DOSTEP(j, 3, 5, 2) {
    write(6, star), j;
  }
""")
  #
  assert not absd(get("if_endif.f"), tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  int i = fem::int0;
  if (i == 0) {
    write(6, star), "i is zero.";
  }
""")
  #
  assert not absd(get("if_else_endif.f"), tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  int i = fem::int0;
  FEM_DO(i, 0, 1) {
    if (i == 0) {
      write(6, star), "i is zero.";
    }
    else {
      write(6, star), "i is not zero.";
    }
  }
""")
  #
  assert not absd(get("if_elseif_else_endif.f"), tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  int i = fem::int0;
  FEM_DO(i, 0, 2) {
    if (i == 0) {
      write(6, star), "i is zero.";
    }
    else if (i == 1) {
      write(6, star), "i is one.";
    }
    else {
      write(6, star), "i is not zero or one.";
    }
  }
""")
  #
  assert not absd(get("if_write.f"), tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  int i = fem::int0;
  FEM_DO(i, 3, 4) {
    if (i < 4) {
      write(6, star), "i is less than four.";
    }
    if (i >= 4) {
      write(6, star), "i is greater than or equal to four.";
    }
  }
""")
  #
  assert not absd(get("assign_to_array_elements.f"), tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  arr<float> abc(dimension(2), fem::fill0);
  abc(1) = 10;
  abc(2) = 20;
  write(6, star), abc(1), abc(2);
""")
  #
  assert not absd(get("parameter_n.f"), tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  int i = fem::int0;
  const int n = 2;
  FEM_DO(i, 1, n) {
    write(6, star), i;
  }
""")
  #
  assert not absd(get("do_ix_num.f"), tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  int ix = fem::int0;
  const int num = 2;
  FEM_DO(ix, 1, num) {
    write(6, star), ix;
  }
""")
  #
  assert not absd(get("scopes_1.f"), tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  int ix = fem::int0;
  int ix_sum = fem::int0;
  FEM_DO(ix, 1, 2) {
    ix_sum += ix;
  }
  write(6, star), ix_sum;
""")
  #
  assert not absd(get("scopes_2.f"), tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  int ix = fem::int0;
  int ix_sum = fem::int0;
  FEM_DO(ix, 1, 3) {
    if (ix == 1) {
      write(6, star), "ix is one.";
    }
    else {
      ix_sum += ix;
    }
    write(6, star), ix_sum;
  }
  int ix_sum_sq = fem::int0;
  FEM_DO(ix, 2, 3) {
    ix_sum_sq += ix * ix;
  }
  write(6, star), ix_sum_sq;
""")
  #
  assert not absd(get("scopes_3.f"), tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  const int n_data = 10;
  float d_max = fem::float0;
  int i = fem::int0;
  arr<float> data(dimension(n_data), fem::fill0);
  float d = fem::float0;
  if (n_data <= 100) {
    write(6, star), "branch 1.";
  }
  else {
    d_max = 0;
    FEM_DO(i, 1, n_data) {
      d = data(i);
      if (d_max < d) {
        d_max = d;
      }
    }
  }
""")
  #
  assert not absd(get("scopes_4.f"), tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  const int n_data = 10;
  float d_max = fem::float0;
  int i = fem::int0;
  arr<float> data(dimension(n_data), fem::fill0);
  arr<float> d(dimension(1), fem::fill0);
  if (n_data <= 100) {
    write(6, star), "branch 1.";
  }
  else {
    d_max = 0;
    FEM_DO(i, 1, n_data) {
      d(1) = data(i);
      if (d_max < d(1)) {
        d_max = d(1);
      }
    }
  }
""")
  #
  assert not absd(get("arr_float_2.f"), tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  int i = fem::int0;
  int j = fem::int0;
  arr<float, 2> data(dimension(2, 3), fem::fill0);
  FEM_DO(i, 1, 2) {
    FEM_DO(j, 1, 3) {
      data(i, j) = i + 10 * j;
    }
  }
  FEM_DO(j, 1, 3) {
    FEM_DO(i, 1, 2) {
      write(6, star), data(i, j);
    }
  }
""")
  lines = get("arr_float_2.f", arr_nd_size_max=6)
  assert not absd(lines, tail_off(11), """\
  arr_2d<2, 3, float> data(fem::fill0);
""")
  lines = get("arr_float_2.f", arr_nd_size_max=5)
  assert not absd(lines, tail_off(11), """\
  arr<float, 2> data(dimension(2, 3), fem::fill0);
""")
  #
  lines = get("subroutine_1.f")
  assert not absd(lines, head_off(3), """\
void
sub1(
  common& cmn)
{
  common_write write(cmn);
  write(6, star), "output from sub1.";
}

void
sub2(
  common& cmn)
{
  common_write write(cmn);
  write(6, star), "output from sub2.";
}
""")
  assert not absd(lines, tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  write(6, star), "first line in prog.";
  sub1(cmn);
  sub1(cmn);
  sub2(cmn);
  sub2(cmn);
  write(6, star), "last line in prog.";
""")
  #
  lines = get("subroutine_2.f", inline_all=True)
  assert not absd(lines, head_off(3), expected="""\
inline
void
sub1(
  common& cmn,
  int& i)
{
  common_write write(cmn);
  i = 3;
  write(6, star), "sub1", i;
  i = 7;
}

inline
void
sub2(
  common& cmn,
  int& i,
  int& j)
{
  common_write write(cmn);
  j = 4;
  write(6, star), "sub2", i, j;
  i = 8;
  j = 5;
}
""")
  assert not absd(lines, tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  write(6, star), "first line in prog.";
  int i = fem::int0;
  sub1(cmn, i);
  write(6, star), "prog", i;
  int j = fem::int0;
  sub2(cmn, i, j);
  write(6, star), "prog", i, j;
  write(6, star), "last line in prog.";
""")
  #
  lines = get("subroutine_3.f")
  assert not absd(lines, head_off(3), """\
void
sub1(
  int& num)
{
  num = 9;
}

void
sub2(
  arr_ref<int> nums,
  int const& nums_size)
{
  nums(dimension(star));
  int i = fem::int0;
  FEM_DO(i, 1, nums_size) {
    nums(i) = i * 10;
  }
}

void
sub3(
  arr_ref<int> nums,
  int const& nums_size)
{
  nums(dimension(star));
  int i = fem::int0;
  FEM_DO(i, 1, nums_size) {
    nums(i) = i * 20;
  }
}
""")
  assert not absd(lines, tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  int num = fem::int0;
  sub1(num);
  write(6, star), "num after sub1:", num;
  int n = 1;
  sub2(num, n);
  write(6, star), "num after sub2", num;
  arr<int> nums(dimension(2), fem::fill0);
  sub1(nums);
  write(6, star), "nums after sub1:", nums(1), nums(2);
  n = 2;
  sub2(nums, n);
  write(6, star), "nums after sub2:", nums(1), nums(2);
  sub3(nums, n);
  write(6, star), "nums after sub3:", nums(1), nums(2);
""")
  #
  assert not absd(get("combine_decl_1.f"), tail_off(1), """\
  arr<int> vals(dimension(2), fem::fill0);
  write(6, star), vals(1);
  arr<float> abc(dimension(4), fem::fill0);
  write(6, star), abc(3);
""")
  #
  assert not absd(get("implied_program.f"), tail_off(0), """\
//C1
void
program_unnamed(
  int argc,
  char const* argv[])
{
  common cmn(argc, argv);
  common_write write(cmn);
  int num = fem::int0;
  write(6, star), num;
}
//C2
""")
  #
  lines = get("implied_trailing_program.f")
  assert not absd(lines, head_off(3), expected="""\
void
sub(
  common& cmn)
{
  common_write write(cmn);
  write(6, star), "write sub";
}
""")
  assert not absd(lines, tail_off(1), """\
  sub(cmn);
""")
  #
  lines = get("common_0.f")
  assert not absd(lines, head_off(0), expected="""\

struct common_com
{
  int num;

  common_com() :
    num(fem::int0)
  {}
};

""")
  assert not absd(lines, tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  write(6, star), cmn.num;
""")
  #
  lines = get("common_1.f")
  assert not absd(lines, head_off(1), expected="""\
struct common_com
{
  int num;

  common_com() :
    num(fem::int0)
  {}
};

struct common :
  fem::common,
  common_com
{
%s
};

void
sub(
  common& cmn)
{
  common_write write(cmn);
  write(6, star), cmn.num;
}
""" % common_argc_argv)
  assert not absd(lines, tail_off(1), """\
  common cmn(argc, argv);
  sub(cmn);
  cmn.num = 7;
  sub(cmn);
""")
  #
  lines = get("common_2.f")
  assert not absd(lines, head_off(1), expected="""\
struct common_com
{
  int num;
  float val;

  common_com() :
    num(fem::int0),
    val(fem::float0)
  {}
};

struct common :
  fem::common,
  common_com
{
%s
};

void
sub(
  common& cmn)
{
  common_write write(cmn);
  write(6, star), cmn.num;
  write(6, star), cmn.val;
}
""" % common_argc_argv)
  assert not absd(lines, tail_off(1), """\
  common cmn(argc, argv);
  cmn.num = 3;
  cmn.val = 9;
  sub(cmn);
""")
  #
  lines = get("common_3.f")
  assert not absd(lines, head_off(1), expected="""\
struct common_com
{
  arr<int> vals;

  common_com() :
    vals(dimension(2), fem::fill0)
  {}
};

struct common :
  fem::common,
  common_com
{
%s
};

void
sub(
  common& cmn)
{
  // COMMON com
  arr_ref<int> vals(cmn.vals, dimension(2));
  //
  vals(1) = vals(2) + 1;
}
""" % common_argc_argv)
  assert not absd(lines, tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  // COMMON com
  arr_ref<int> vals(cmn.vals, dimension(2));
  //
  vals(2) = 4;
  sub(cmn);
  write(6, star), vals(1);
""")
  #
  lines = get("common_4.f")
  assert not absd(lines, head_off(1), expected="""\
struct common_com
{
  arr<int> n;

  common_com() :
    n(dimension(2), fem::fill0)
  {}
};

struct common :
  fem::common,
  common_com
{
%s
};

void
sub(
  common& cmn,
  int const& num)
{
  // COMMON com
  arr_ref<int> n(cmn.n, dimension(2));
  //
  n(1) = num + 1;
  n(2) = num + 3;
}
""" % common_argc_argv)
  assert not absd(lines, tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  // COMMON com
  arr_cref<int> n(cmn.n, dimension(2));
  //
  write(6, star), n(1), n(2);
  sub(cmn, 5);
  write(6, star), n(2), n(1);
""")
  #
  for file_name in ["save_0.f", "save_1.f"]:
    lines = get(file_name)
    assert not absd(lines, head_off(0), expected="""\

struct common :
  fem::common
{
  fem::cmn_sve program_prog_sve;

%s
};

struct program_prog_save
{
  int num;

  program_prog_save() :
    num(fem::int0)
  {}
};

""" % common_argc_argv)
    assert not absd(lines, tail_off(1), """\
  common cmn(argc, argv);
  FEM_CMN_SVE(program_prog);
  common_write write(cmn);
  write(6, star), sve.num;
""")
  #
  lines = get("save_2.f")
  assert not absd(lines, head_off(0), expected="""\

struct common :
  fem::common
{
  fem::cmn_sve sub_sve;

%s
};

struct sub_save
{
  int num;

  sub_save() :
    num(fem::int0)
  {}
};

void
sub(
  common& cmn)
{
  FEM_CMN_SVE(sub);
  common_write write(cmn);
  // SAVE
  int& num = sve.num;
  //
  write(6, star), num;
  num++;
}

""" % common_argc_argv)
  assert not absd(lines, tail_off(1), """\
  common cmn(argc, argv);
  sub(cmn);
  sub(cmn);
""")
  #
  lines = get("conv_recipe.f")
  assert not absd(lines, head_off(0), expected="""\

struct common_abc
{
  float a;
  float b;
  float c;

  common_abc() :
    a(fem::float0),
    b(fem::float0),
    c(fem::float0)
  {}
};

struct common :
  fem::common,
  common_abc
{
  fem::cmn_sve show_resolution_sve;

%s
};

struct show_resolution_save
{
  float ass;
  float bss;
  float css;
  bool first;

  show_resolution_save() :
    ass(fem::float0),
    bss(fem::float0),
    css(fem::float0),
    first(fem::bool0)
  {}
};

//C cctbx_project/compcomm/newsletter09/conv_recipe.py, svn rev. 9983
//C
void
show_resolution(
  common& cmn,
  int const& h,
  int const& k,
  int const& l)
{
  FEM_CMN_SVE(show_resolution);
  common_write write(cmn);
  // COMMON abc
  float& a = cmn.a;
  float& b = cmn.b;
  float& c = cmn.c;
  //
  // SAVE
  float& ass = sve.ass;
  float& bss = sve.bss;
  float& css = sve.css;
  bool& first = sve.first;
  //
  if (is_called_first_time) {
    first = true;
  }
  if (first) {
    first = false;
    if (a <= 0 || b <= 0 || c <= 0) {
      write(0, "(1x,a)"), "invalid unit cell constants.";
      FEM_STOP(0);
    }
    ass = 1 / (a * a);
    bss = 1 / (b * b);
    css = 1 / (c * c);
  }
  float dss = h * h * ass + k * k * bss + l * l * css;
  if (dss == 0) {
    write(6, "(3(1x,i3),1x,a)"), h, k, l, "    infinity";
  }
  else {
    write(6, "(3(1x,i3),1x,f12.6)"), h, k, l, fem::sqrt(1 / dss);
  }
}

""" % common_argc_argv)
  assert not absd(lines, tail_off(1), """\
  common cmn(argc, argv);
  cmn.a = 11.0f;
  cmn.b = 12.0f;
  cmn.c = 13.0f;
  show_resolution(cmn, 0, 0, 0);
  show_resolution(cmn, 1, 2, 3);
""")
  #
  assert not absd(get("read_star_integer.f"), tail_off(1), """\
  common_read read(cmn);
  common_write write(cmn);
  int num = fem::int0;
  read(5, star), num;
  write(6, star), num + 1;
""")
  #
  assert not absd(get("write_implied_do_1.f"), tail_off(1), """\
  int i = fem::int0;
  {
    write_loop wloop(cmn, 6, "(2i4)");
    FEM_DO(i, 1, 2) {
      wloop, nums(i);
    }
  }
  int j = fem::int0;
  {
    write_loop wloop(cmn, 6, "(3i4)");
    FEM_DO(i, 1, 2) {
      wloop, nums(i);
      FEM_DO(j, 1, 2) {
        wloop, nums(j);
      }
    }
  }
  {
    write_loop wloop(cmn, 6, "(5i4)");
    FEM_DO(i, 1, 2) {
      wloop, nums(i);
      FEM_DO(j, 1, 2) {
        wloop, nums(j);
      }
      FEM_DO(j, 1, 2) {
        wloop, nums(j);
      }
    }
  }
  int k = fem::int0;
  {
    write_loop wloop(cmn, 6, "(7i4)");
    FEM_DO(i, 1, 2) {
      wloop, nums(i);
      FEM_DO(j, 1, 2) {
        wloop, nums(j);
        FEM_DO(k, 1, 2) {
          wloop, nums(k);
        }
      }
    }
  }
""")
  #
  lines = get("write_extra_parentheses.f")
  assert not absd(lines, tail_off(32), """\
int
i1(
  int const& i)
{
  int return_value = fem::int0;
  return_value = 7 * i;
  return return_value;
}

int
i2(
  int const& i,
  int const& j)
{
  int return_value = fem::int0;
  return_value = i * 8 + j;
  return return_value;
}

int
i3(
  int const& i,
  int const& j,
  int const& k)
{
  int return_value = fem::int0;
  return_value = i * 9 + j * 29 + k;
  return return_value;
}
""")
  assert not absd(lines, tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  int i = 3;
  int j = 4;
  int k = 5;
  int l = 6;
  int m = 7;
  write(6, "(1i5)"), -i * 3;
  write(6, "(1i5)"), -i * 3;
  write(6, "(2i5)"), -i * 3, -j * 4;
  write(6, "(3i5)"), -i * 3, -j * 4, -k * 7;
  write(6, "(3i5)"), -i * 3, -j * 4, -k * 7;
  write(6, "(3i5)"), -i * 3, -j * 4, -k * 7;
  write(6, "(4i5)"), -i * 3, -j * 4, -k * 7, -l * 8;
  write(6, "(4i5)"), -i * 3, -j * 4, -k * 7, -l * 8;
  write(6, "(4i5)"), -i * 3, -j * 4, -k * 7, -l * 8;
  write(6, "(5i5)"), -i * 3, -j * 4, -k * 7, -l * 8, -m * 9;
  write(6, "(4i5)"), i1(-i * 3), -j * 4, -k * 7, -l * 8;
  write(6, "(4i5)"), i1(-i * 3), -j * 4, -k * 7, -l * 8;
  write(6, "(4i5)"), i1(-i * 3), -j * 4, -k * 7, -l * 8;
  write(6, "(4i5)"), i1(-i * 3), -j * 4, -k * 7, -l * 8;
  write(6, "(4i5)"), i1(-i * 3), -j * 4, -k * 7, -l * 8;
  write(6, "(2i5)"), i1(-i * 3), i3(-j * 4, -k * 7, -l * 8);
  write(6, "(2i5)"), i1(-i * 3), i3(-j * 4, -k * 7, -l * 8);
  write(6, "(2i5)"), i1(-i * 3), i3(-j * 4, -k * 7, -l * 8);
""")
  #
  for file_name in [
        "function_two_returns_1.f",
        "function_two_returns_2.f"]:
    lines = get(file_name)
  assert not absd(lines, tail_off(11), """\
int
fun(
  int const& i)
{
  int return_value = fem::int0;
  if (i < 3) {
    return_value = i * 4;
    return return_value;
  }
  return_value = -i;
  return return_value;
}
""")
  assert not absd(lines, tail_off(1), """\
  common cmn(argc, argv);
  common_write write(cmn);
  write(6, star), fun(2);
  write(6, star), fun(3);
""")
  #
  assert not absd(get("do_label.f"), tail_off(1), """\
  int num = fem::int0;
  FEM_DO(num, 1, 2) {
    write(6, star), num;
  }
  int num2 = fem::int0;
  FEM_DO(num, 1, 2) {
    FEM_DO(num2, 3, 4) {
      write(6, star), num, num2;
    }
  }
  FEM_DO(num, 1, 2) {
    FEM_DO(num2, 3, 4) {
      write(6, star), num, num2;
      write(6, star), num * 10, num2 * 10;
    }
  }
""")
  #
  assert not absd(get("label_format.f"), tail_off(1), """\
  int num = 102;
  write(6, "(2(i4,1x,2i5,/,'_^'))"), num, num + 1, num + 2, num + 3,
    num + 4, num + 5;
""")
  #
  assert not absd(get("write_internal_file.f"), tail_off(1), """\
  int num = -2;
  fem::str<5> buf = fem::char0;
  write(buf, "(i3)"), num;
  write(6, "('num = (',a,')')"), buf;
""")
  #
  assert not absd(get("open_chain.f"), tail_off(1), """\
  cmn.io.open(10, "fable_tmp_661de075");
  cmn.io.close(10);
  cmn.io.open(10, "fable_tmp_661de075")
    .form("formatted")
    .status("unknown");
  cmn.io.close(10);
  try {
    cmn.io.open(10, "fable_tmp_661de075")
      .access("sequential")
      .form("formatted")
      .status("new");
  }
  catch (fem::io_err const&) {
    goto statement_10;
  }
  goto statement_20;
  statement_10:
  write(6, "(a)"), "open err statement";
  statement_20:
  try {
    cmn.io.close(10)
      .status("keep");
  }
  catch (fem::io_err const&) {
    goto statement_30;
  }
  goto statement_40;
  statement_30:
  write(6, "(a)"), "close err statement";
  statement_40:
  write(6, "(a)"), "Done.";
""")
  #
  assert not absd(get("goto_spaghetti.f"), tail_off(1), """\
  int i = fem::int0;
  int j = fem::int0;
  write(6, star), "start";
  goto statement_20;
  statement_10:
  i = 3;
  write(6, star), "stmt 10";
  goto statement_30;
  statement_20:
  write(6, star), "stmt 20";
  i = 2;
  statement_30:
  write(6, star), "stmt 30", i;
  if (i == 2) {
    goto statement_10;
  }
  FEM_DO(j, 1, 2) {
    if (j == 2) {
      goto statement_40;
    }
    write(6, star), "loop j is", j;
    statement_40:;
  }
  write(6, star), "end";
""")
  #
  lines = get("sub_nums_size_capacity.f")
  assert not absd(lines, head_off(3), """\
void
sub(
  common& cmn,
  arr_cref<int> nums,
  int const& nums_size,
  int const& nums_capacity)
{
  nums(dimension(nums_capacity));
  common_write write(cmn);
  int i = fem::int0;
  FEM_DO(i, 1, nums_size) {
    write(6, "(i3)"), nums(i);
  }
}
""")
  assert not absd(lines, tail_off(1), """\
  arr<int> nums(dimension(3), fem::fill0);
  nums(1) = 12;
  nums(2) = 34;
  sub(cmn, nums, 2, 3);
""")
  #
  lines = get("passing_arrays.f")
  assert not absd(lines, head_off(3), """\
void
sub(
  common& cmn,
  int const& num,
  arr_cref<int> nums1,
  arr_cref<int, 2> nums2)
{
  nums1(dimension(6));
  nums2(dimension(2, 3));
  common_write write(cmn);
  write(6, "(i1)"), num;
  int i = fem::int0;
  FEM_DO(i, 1, 6) {
    write(6, "(i2)"), nums1(i);
  }
  int j = fem::int0;
  FEM_DO(i, 1, 2) {
    FEM_DO(j, 1, 3) {
      write(6, "(i2)"), nums2(i, j);
    }
  }
}
""")
  assert not absd(lines, tail_off(1), """\
  arr<int> nums(dimension(6), fem::fill0);
  nums(1) = 3;
  int i = fem::int0;
  FEM_DO(i, 2, 6) {
    nums(i) = nums(i - 1) + i;
  }
  sub(cmn, nums, nums, nums);
""")
  #
  lines = get("unused_args.f")
  assert not absd(lines, head_off(3), """\
void
sub(
  int const& /* num */,
  arr_cref<int> /* nums1 */,
  arr_cref<int, 2> /* nums2 */)
{
}
""")
  assert not absd(lines, tail_off(1), """\
  sub(1, 2, 3);
""")
  #
  lines = get("passing_arrays_2.f")
  assert not absd(lines, head_off(3), """\
void
sub(
  arr_ref<int> nums1,
  arr_ref<int, 2> nums2)
{
  nums1(dim1(0, 1));
  nums2(dim1(2, 4).dim2(-1, 2));
  nums1(0) = 23;
  nums1(1) = 45;
  nums2(4, -1) = 67;
  int i = fem::int0;
  int j = fem::int0;
  FEM_DO(i, 2, 4) {
    FEM_DO(j, 0, 2) {
      nums2(i, j) = i * 10 + j;
    }
  }
}
""")
  assert not absd(lines, tail_off(1), """\
  arr<int> nums(dimension(12), fem::fill0);
  sub(nums, nums);
  int i = fem::int0;
  {
    write_loop wloop(cmn, 6, "(6i3)");
    FEM_DO(i, 1, 12) {
      wloop, nums(i);
    }
  }
""")
  #
  lines = get("array_origin.f")
  assert not absd(lines, head_off(11), """\
  arr<int> nums1(dim1(0, 1), fem::fill0);
  int k = fem::int0;
  arr<int, 2> nums2(dim1(0, 1).dim2(-1, 2), fem::fill0);
  int j = fem::int0;
  arr<int, 3> nums3(dim1(0, 1).dim2(3).dim3(-1, 2), fem::fill0);
""")
  lines = get("array_origin.f", arr_nd_size_max=24)
  assert not absd(lines, head_off(11), """\
  arr_1d<2, int> nums1(dim1(0, 1), fem::fill0);
  int k = fem::int0;
  arr_2d<2, 4, int> nums2(dim1(0, 1).dim2(-1, 2), fem::fill0);
  int j = fem::int0;
  arr_3d<2, 3, 4, int> nums3(dim1(0, 1).dim2(3).dim3(-1, 2), fem::fill0);
""")
  #
  lines = get("power.f")
  assert not absd(lines, tail_off(1), """\
  const float val = fem::pow(1.2f, 3.4f);
  write(6, "(f5.3)"), val;
  float x = 1.2f + fem::pow(3.4f, 5.6f) / 7.8f;
  write(6, "(f5.1)"), x;
  x = fem::pow((1.2f + 3.4f), 5.6f) / 7.8f;
  write(6, "(f5.1)"), x;
  x = fem::pow((1.2f + 3.4f), (5.6f / 7.8f));
  write(6, "(f5.3)"), x;
  x = -fem::pow2(1.3f);
  write(6, "(f5.2)"), x;
  x = fem::pow2((-1.3f));
  write(6, "(f4.2)"), x;
  x = ((-1.4f));
  write(6, "(f5.2)"), x;
  x = fem::pow3((-1.5f));
  write(6, "(f5.2)"), x;
  x = fem::pow4((-1.6f));
  write(6, "(f4.2)"), x;
""")
  #
  lines = get("stop_bare.f")
  assert not absd(lines, tail_off(2), """\
    if (i == 2) {
      FEM_STOP(0);
    }
    write(6, "(a,i2)"), "iteration", i;
""")
  #
  lines = get("stop_integer.f")
  assert not absd(lines, tail_off(2), """\
    if (i == 2) {
      FEM_STOP(2345);
    }
    write(6, "(a,i2)"), "iteration", i;
""")
  #
  lines = get("stop_string.f")
  assert not absd(lines, tail_off(2), """\
    if (i == 2) {
      FEM_STOP("Break");
    }
    write(6, "(a,i2)"), "iteration", i;
""")
  #
  lines = get("passing_strings.f")
  assert not absd(lines, head_off(3), """\
void
sub1(
  common& cmn,
  str_cref str)
{
  common_write write(cmn);
  write(6, "(i1)"), fem::len(str);
  write(6, "(a)"), str;
}
""")
  assert not absd(lines, tail_off(1), """\
  fem::str<2> str2 = "Pq";
  fem::str<3> str3 = "rSt";
  sub1(cmn, str2);
  sub1(cmn, str3);
  sub2(cmn, "a");
""")
  #
  lines = get("write_internal_file_2.f")
  assert not absd(lines, head_off(31), """\
    write_loop wloop(bufs(i), "(i1,i2)");
""")
  assert not absd(lines, tail_off(3), """\
  arr<int> nums(dimension(2), fem::fill0);
  nums(1) = -2;
  nums(2) = 3;
  fem::str<8> buf = fem::char0;
  int i = fem::int0;
  {
    write_loop wloop(buf, "(2i3)");
    FEM_DO(i, 1, 2) {
      wloop, nums(i);
    }
  }
  write(6, "('nums = (',a,')')"), buf;
""")
  #
  lines = get("open_write_read.f")
  assert not absd(lines, head_off(16), """\
  cmn.io.open(10, buf)
    .form("formatted");
  int num = fem::int0;
  read(10, "(i6)"), num;
  cmn.io.close(10);
""")
  #
  lines = get("write_internal_file_3.f")
  assert not absd(lines, tail_off(1), """\
  int num = -2;
  fem::str<6> buf = "AbCdEf";
  write(buf(2, 4), "(i3)"), num;
  write(6, "('num = (',a,')')"), buf;
""")
  #
  lines = get("open_write_read_2.f")
  assert not absd(lines, tail_off(1), """\
  cmn.io.open(10, "fable_tmp_7895777d")
    .form("unformatted")
    .status("unknown");
  write(10, fem::unformatted), -123;
  cmn.io.close(10);
  cmn.io.open(10, "fable_tmp_7895777d")
    .form("unformatted")
    .status("old");
  int num = fem::int0;
  read(10, fem::unformatted), num;
  cmn.io.close(10);
  if (num !=  - 123) {
    write(6, "(a)"), "FAILURE int", num;
  }
  else {
    write(6, "(a)"), "OK";
  }
""")
  #
  lines = get("read_err.f")
  assert not absd(lines, head_off(15), """\
  try {
    read(10, "(i1)"), num;
  }
  catch (fem::io_err const&) {
    goto statement_10;
  }
  write(6, "(a)"), "FAILURE exercise_file_fmt";
  goto statement_20;
  statement_10:
  write(6, "(a)"), "success exercise_file_fmt";
  statement_20:;
""")
  #
  lines = get("read_end.f")
  assert not absd(lines, tail_off(6), """\
  try {
    read(10, "(i1)"), num1, num2;
  }
  catch (fem::read_end const&) {
    goto statement_10;
  }
""")
  #
  lines = get("read_end_err.f")
  assert not absd(lines, tail_off(6), """\
  try {
    read(10, "(i1)"), num1, num2;
  }
  catch (fem::read_end const&) {
    goto statement_10;
  }
  catch (fem::io_err const&) {
    goto statement_20;
  }
""")
  #
  lines = get("write_err.f")
  assert not absd(lines, tail_off(7), """\
  try {
    write(10, "(i1)"), num;
  }
  catch (fem::io_err const&) {
    goto statement_10;
  }
""")
  #
  lines = get("write_read_end_err_implied_do.f")
  assert not absd(lines, tail_off(25), """\
  try {
    write_loop wloop(cmn, 10, "(2i3)");
    FEM_DO(i, 8, 9) {
      wloop, i + 23;
    }
  }
  catch (fem::io_err const&) {
    goto statement_10;
  }
  statement_10:
""")
  assert not absd(lines, tail_off(8), """\
  try {
    read_loop rloop(cmn, 10, "(2i3)");
    FEM_DO(i, 1, 2) {
      rloop, nums(i);
    }
  }
  catch (fem::read_end const&) {
    goto statement_20;
  }
  catch (fem::io_err const&) {
    goto statement_30;
  }
  statement_20:
  statement_30:
""")
  #
  lines = get("goto_last_do.f")
  assert not absd(lines, head_off(10), """\
  if (num == 1) {
    num = 2;
    goto statement_10;
  }
  num = 3;
  statement_10:
  FEM_DO(i, 1, num) {
    write(6, "(i2)"), i;
  }
""")
  #
  lines = get("inquire.f")
  assert not absd(lines, head_off(9), """\
  FEM_DOSTEP(i, fem::len(s), 1, -1) {
""")
  assert not absd(lines, head_off(30), """\
  cmn.io.inquire_unit(10)
    .name(cvar);
""")
  assert not absd(lines, tail_off(13), """\
  try {
    cmn.io.inquire_file("fable_tmp_5d70aa2a")
      .exist(lvar);
  }
  catch (fem::io_err const&) {
    goto statement_10;
  }
  write(6, "(a,l1,a)"), "(", lvar, ")";
  goto statement_20;
  statement_10:
""")
  #
  lines = get("data_type_star.f")
  assert not absd(lines, tail_off(1), """\
  fem::logical_star_1 l1 = false;
  fem::integer_star_2 i2 = 4;
  fem::integer_star_4 i4 = 8;
  fem::integer_star_8 i8 = fem::zero<fem::integer_star_8>();
  if (i2 * 2 == i4) {
    i8 = 16;
    if (i4 * 2 == i8) {
      write(6, "(a)"), "OK integers";
      l1 = true;
    }
  }
  if (!l1) {
    write(6, "(a)"), "FAILURE integers";
  }
  fem::real_star_4 r4 = 3.14f;
  fem::real_star_8 r8 = 6.28f;
  if (fem::abs(r4 * 2 - r8) < 1.e-5f) {
    write(6, "(a)"), "OK reals";
  }
  else {
    write(6, "(a)"), "FAILURE reals";
  }
""")
  #
  lines = get("integer_star_2_array.f")
  assert not absd(lines, tail_off(1), """\
  arr<fem::integer_star_2> nums(dimension(2), fem::fill0);
  nums(1) = 9;
  nums(2) = -6;
  int num_sum = nums(1) + nums(2);
  write(6, "(i1)"), num_sum;
""")
  #
  lines = get("power_2.f")
  assert not absd(lines, tail_off(8), """\
  vals(1) = 1.2f;
  vals(2) = fem::pow2(vals(1));
  vals(3) = fem::pow(2, vals(2));
  vals(4) = fem::pow(vals(2), vals(3));
""")
  #
  lines = get("subroutine_5.f")
  assert not absd(lines, head_off(3), """\
void
sub(
  common& cmn,
  str_cref str)
{
  common_write write(cmn);
  if (str(1, 1) == " ") {
    write(6, "(a)"), "str starts with a blank";
  }
  else {
    write(6, "(a)"), "str does not start with a blank";
  }
}
""")
  #
  lines = get("string_compare.f")
  assert not absd(lines, tail_off(2), """\
  str2 = " y";
  write(6, "(a,2l1)"), "p", str2 == " y", str2 != " y";
  write(6, "(a,2l1)"), "q", str2 == " y ", str2 != " y ";
  write(6, "(a,2l1)"), "r", str2 == " yz", str2 != " yz";
  write(6, "(a,2l1)"), "s", " y" == str2, " y" != str2;
  //C
""")
  #
  lines = get("decl_before_if.f")
  assert not absd(lines, head_off(9), """\
  int num = fem::int0;
  if (num_max > 41) {
    num = 41;
  }
  else {
    num = num_max;
  }
""")
  #
  lines = get("const_analysis_1.f", top_procedures=["prog"])
  assert not absd(lines, head_off(3), """\
void
sub1(
  int& num)
{
  num = 12;
}

void
sub2(
  int& num)
{
  sub1(num);
}
""")
  #
  lines = get("const_analysis_2.f", top_procedures=["prog"])
  assert not absd(lines, head_off(3), """\
void
sub1(
  common& cmn,
  int& num)
{
  common_read read(cmn);
  read(5, "(i2)"), num;
}

void
sub2(
  common& cmn,
  int& num)
{
  sub1(cmn, num);
}
""")
  #
  lines = get("double_literal.f")
  assert not absd(lines, tail_off(1), """\
  write(6, star), 1.2e2, 3.4e2f, 5.6e2;
""")
  #
  lines = get("read_implied_do_1.f")
  assert not absd(lines, head_off(3), """\
void
sub(
  common& cmn,
  arr_ref<int> nums)
{
  nums(dimension(star));
  common_read read(cmn);
  int i = fem::int0;
  {
    read_loop rloop(cmn, 5, "(2i3)");
    FEM_DO(i, 1, 2) {
      rloop, nums(i);
    }
  }
}
""")
  #
  lines = get("dim_with_parameter.f")
  assert not absd(lines, tail_off(4), """\
  const int num = 2;
  arr<int> nums1(dimension(num), fem::fill0);
  nums1(1) = 12;
  nums1(2) = 34;
  arr<int> nums2(dimension(num), fem::fill0);
""")
  #
  lines = get("data_10.f", data_specializations=False)
  assert not absd(lines, head_off(14), """\
struct program_prog_save
{
  arr<int> num;

  program_prog_save() :
    num(dimension(2), fem::fill0)
  {}
};
""")
  assert not absd(lines, tail_off(1), """\
  const int one = 1;
  if (is_called_first_time) {
    fem::data_values data((values, 12, 34));
    {
      int fem_do_last = one + one;
      FEM_DO(ind, 1, fem_do_last) {
        data, num(ind);
      }
    }
  }
  write(6, star), num(1), num(2);
""")
  #
  lines = get("data_16.f")
  assert not absd(lines, head_off(14), """\
struct program_unnamed_save
{
  static const int num = 2;

  arr<float> vals;

  program_unnamed_save() :
    vals(dimension(num), fem::fill0)
  {}
};

const int program_unnamed_save::num;
""")
  assert not absd(lines, tail_off(8), """\
  if (is_called_first_time) {
    fem::data((values, num*datum(1.2f))), vals;
  }
""")
  #
  lines = get("data_22.f")
  assert not absd(lines, head_off(14), """\
struct program_prog_save
{
  arr<int> nums;
  arr<fem::str<2> > s2s;

  program_prog_save() :
    nums(dimension(2), fem::fill0),
    s2s(dimension(2), fem::fill0)
  {}
};
""")
  assert not absd(lines, tail_off(5), """\
    fem::data_values data((values, 12, "Xy", 34, "Za"));
    FEM_DO(i, 1, 2) {
      data, nums(i), s2s(i);
    }
""")
  #
  lines = get("data_23.f")
  assert not absd(lines, tail_off(7), """\
    fem::data_values data((values, 12, "Xy", 34, "Za", 56, "cD", 78, "eF"));
    FEM_DO(j, 1, 2) {
      FEM_DO(i, 1, 2) {
        data, nums(i, j), s2s(i, j);
      }
    }
""")
  #
  lines = get("data_24.f")
  assert not absd(lines, tail_off(7), """\
    fem::data_values data((values, 12, "Xy", 34, "Za", 56, "cD", 78, "eF"));
    FEM_DO(j, 1, 2) {
      FEM_DOSTEP(i, 1, 2, 2) {
        data, nums(i, j), s2s(i, j);
      }
    }
    FEM_DO(j, 1, 2) {
      FEM_DOSTEP(i, 2, 2, 2) {
        data, nums(i, j), s2s(i, j);
      }
    }
""")
  #
  lines = get("data_25.f", data_specializations=False)
  assert not absd(lines, tail_off(2), """\
  const fem::str<2> s12 = "xy";
  const fem::str<2> s34 = "ab";
  if (is_called_first_time) {
    fem::data((values, s12)), s4(1, 2);
    fem::data((values, s34)), s4(3, 4);
  }
""")
  #
  lines = get("data_26.f", data_specializations=False)
  assert not absd(lines, head_off(62), """\
    fem::data((values, 1, 2, 3)), num1, num2, num3;
""")
  #
  lines = get("data_27.f", data_specializations=False)
  assert not absd(lines, tail_off(3), """\
    fem::data((values, "A")), s2s(1)(1, 1);
    fem::data((values, "b")), s2s(2)(2, 2);
    fem::data((values, "C")), s2s(1)(2, 2);
    fem::data((values, "d")), s2s(2)(1, 1);
""")
  #
  lines = get("data_28.f", data_specializations=False)
  assert not absd(lines, tail_off(11), """\
    fem::data_values data((values, 1, 2, 3, 4));
    FEM_DO(i, 1, 2) {
      data, nums1(i);
    }
    FEM_DO(i, 1, 2) {
      data, nums2(i);
    }
""")
  #
  lines = get("data_29.f", data_specializations=False)
  assert not absd(lines, tail_off(3), """\
    {
      fem::data_values data((values, 12, 34));
      FEM_DOSTEP(i, 1, 4, 2) {
        data, nums(i);
      }
    }
    {
      fem::data_values data((values, 56, 78));
      FEM_DOSTEP(i, 2, 4, 2) {
        data, nums(i);
      }
    }
""")
  #
  lines = get("parameter_save.f")
  assert not absd(lines, tail_off(1), """\
  FEM_CMN_SVE(program_prog);
  common_write write(cmn);
  const int size = 2;
  arr<int> nums_local(dimension(size), fem::fill0);
  write(6, star), nums_local;
  arr_cref<int> nums_save(sve.nums_save, dimension(size));
  write(6, star), nums_save;
""")
  #
  lines = get("function_write.f")
  assert not absd(lines, tail_off(1), """\
  FEM_DO(i, 1, 3) {
    num = fun(cmn, num);
  }
""")
  #
  lines = get("parameters_recursive.f")
  assert not absd(lines, tail_off(5), """\
  const int num1 = 2;
  const int num2 = num1 + 3;
  arr<int> nums(dimension(num2), fem::fill0);
""")
  #
  lines = get("strings_size_dim_data.f")
  assert not absd(lines, head_off(14), """\
struct program_prog_save
{
  static const int base = 4;
  static const int size = base - 1;
  static const int dim = base - 2;

  arr<fem::str<size> > strings;

  program_prog_save() :
    strings(dimension(dim), fem::fill0)
  {}
};

const int program_prog_save::base;
const int program_prog_save::size;
const int program_prog_save::dim;
""")
  #
  lines = get("format_escape.f")
  assert not absd(lines, tail_off(1), """\
  write(6, "('Text with \\"quote\\" \\\\ and \\\\ backslashes.')");
""")
  #
  lines = get("main_cmn_indirect.f")
  assert not absd(lines, tail_off(1), """\
  common cmn(argc, argv);
  sub_main(cmn);
""")
  lines = get("main_cmn_indirect.f", top_procedures=["sub_main"])
  assert not absd(lines, -4, """\
  write(6, "(a)"), "sub_main";
""")
  #
  lines = get("subroutine_7.f")
  assert not absd(lines, head_off(3), """\
void
sub(
  int const& num1,
  fem::star_type const& /* UNHANDLED: star argument */,
  int const& num2,
  fem::star_type const& /* UNHANDLED: star argument */)
{
  if (num1 + num2 == 2) {
    return;
  }
  if (num1 == 3) {
    return;
  }
  if (num1 == 4) {
    return;
  }
  if (num1 == 5) {
    return;
  }
}
""")
  assert not absd(lines, tail_off(1), """\
  FEM_DO(i, 0, 5) {
    sub(i, star /* 10 UNHANDLED */, 1, star /* 20 UNHANDLED */);
    write(6, "(a)"), "regular";
    goto statement_30;
    write(6, "(a)"), "goto 10";
    goto statement_30;
    write(6, "(a)"), "goto 20";
    statement_30:;
  }
""")
  #
  lines = get("parameters_recursive_2.f")
  assert not absd(lines, tail_off(1), """\
  const int num1 = 1;
  const int num2 = num1 + 1;
  arr<int> nums(dimension(num2), fem::fill0);
  write(6, star), nums, num1;
""")
  #
  lines = get("data_30.f", data_specializations=False)
  assert not absd(lines, tail_off(11), """\
  if (is_called_first_time) {
    fem::data((values, 12, 34)), nums;
  }
  arr<float> data(dimension(2), fem::fill0);
""")
  #
  lines = get("string_array.f")
  assert not absd(lines, head_off(3), """\
void
sub(
  common& cmn,
  str_arr_cref<> strings)
{
  strings(dimension(star));
  common_write write(cmn);
  int i = fem::int0;
  FEM_DO(i, 1, 2) {
    write(6, "(a)"), strings(i);
  }
}
""")
  #
  lines = get("string_sub_array_passing.f")
  assert not absd(lines, head_off(3), """\
void
sub1(
  common& cmn,
  str_arr_cref<> strs1)
""")
  assert not absd(lines, head_off(16), """\
void
sub2(
  str_arr_ref<> strs1)
""")
  #
  lines = get("write_pow.f")
  assert not absd(lines, tail_off(1), """\
  write(6, star), fem::pow3(2);
""")
  #
  lines = get("subroutine_8.f")
  assert not absd(lines, head_off(14), """\
struct sub_save
{
  int i;

  sub_save() :
    i(fem::int0)
  {}
};
""")
  assert not absd(lines, head_off(23), """\
void
sub(
  common& cmn,
  int const& sz,
  arr_cref<int> nums)
{
  FEM_CMN_SVE(sub);
  nums(dimension(sz));
  common_write write(cmn);
  // SAVE
  int& i = sve.i;
  //
  FEM_DO(i, 1, sz) {
    write(6, star), nums(i);
  }
}
""")
  #
  lines = get("subroutine_9.f")
  assert not absd(lines, head_off(3), """\
void
sub(
  common& cmn,
  int const& n2,
  arr_cref<int, 2> nums)
{
  const int n1 = 2;
  nums(dimension(n1, n2));
  common_write write(cmn);
  write(6, star), nums;
}
""")
  #
  lines = get("parameter_save_common.f")
  assert not absd(lines, head_off(1), """\
struct common_cmn
{
  static const int ld = 2;

  arr<int> nums_cmn;

  common_cmn() :
    nums_cmn(dimension(ld), fem::fill0)
  {}
};

const int common_cmn::ld;

struct common :
  fem::common,
  common_cmn
{
  fem::cmn_sve program_prog_sve;

%s
};

struct program_prog_save
{
  static const int ld = 2;

  arr<int> nums_sve;

  program_prog_save() :
    nums_sve(dimension(ld), fem::fill0)
  {}
};

const int program_prog_save::ld;
""" % common_argc_argv)
  #
  lines = get("equivalence_01.f")
  assert not absd(lines, tail_off(5), """\
  local_equivalences loc_equivalences;
  {
    using fem::mbr; // member
    mbr<int> num1;
    mbr<int> num2;
    loc_equivalences.allocate(),
      equivalence(num1, num2)
        .align<1>()
         .with<2>()
    ;
  }
  int& num1 = loc_equivalences.bind<int>();
  int& num2 = loc_equivalences.bind<int>();
""")
  #
  lines = get("subroutine_write_iunit.f")
  assert not absd(lines, head_off(3), """\
void
sub(
  common& cmn,
  int const& iunit)
{
  common_write write(cmn);
  write(iunit, "(a)"), "ABc";
}
""")
  #
  lines = get("common_variants.f")
  assert not absd(lines, head_off(1), """\
struct common :
  fem::common
{
  fem::variant_core common_scr;
  fem::cmn_sve sub1a_sve;
  fem::cmn_sve sub1b_sve;
  fem::cmn_sve sub2a_sve;
  fem::cmn_sve sub2b_sve;
  fem::cmn_sve sub3_sve;
  fem::cmn_sve sub4_sve;

%s
};

struct sub1a_save
{
  fem::variant_bindings scr_bindings;
};

void
sub1a(
  common& cmn)
{
  FEM_CMN_SVE(sub1a);
  common_variant scr(cmn.common_scr, sve.scr_bindings);
  if (is_called_first_time) {
    using fem::mbr; // member of variant common or equivalence
    {
      mbr<int> i;
      mbr<int> j(dimension(2));
      scr.allocate(), i, j;
    }
  }
  int& i = scr.bind<int>();
  arr_ref<int> j(scr.bind<int>(), dimension(2));
  i = 12;
  j(1) = 34;
  j(2) = 65;
}
""" % common_argc_argv)
  assert not absd(lines, tail_off(42), """\
  /* int const& i */ scr.bind<int>();
  int& j = scr.bind<int>();
""")
  assert not absd(lines, tail_off(18), """\
  /* arr_cref<int> i( */ scr.bind<int>() /* , dimension(2)) */ ;
  int& j = scr.bind<int>();
""")
  #
  lines = get("common_equivalence_1.f")
  assert not absd(lines, tail_off(7), """\
  if (is_called_first_time) {
    using fem::mbr; // member of variant common or equivalence
    {
      mbr<int> nums(dimension(2));
      mbr<int> numse(dimension(4));
      mbr<int> numx;
      scr.allocate(),
        equivalence(nums, numse)
          .align<1>()
           .with<2>(),
        numx
      ;
    }
  }
  arr_ref<int> nums(scr.bind<int>(), dimension(2));
  arr_ref<int> numse(scr.bind<int>(), dimension(4));
  int const& numx = scr.bind<int>();
""")
  #
  lines = get("common_equivalence_2.f")
  assert not absd(lines, tail_off(14), """\
      scr.allocate(),
        equivalence(nc, nl)
          .align<1>(arr_index(2))
           .with<2>(arr_index(1))
      ;
""")
  #
  lines = get("common_equivalence_3.f")
  assert not absd(lines, tail_off(19), """\
      mbr<int> nums3(dimension(4));
      mbr<int> nums1(dimension(5));
      mbr<int> nums2(dimension(3));
      scr.allocate(),
        equivalence(nums3, nums1, nums2)
          .align<2>(arr_index(2))
           .with<3>(arr_index(3))
           .with<1>(arr_index(4))
      ;
""")
  assert not absd(lines, tail_off(14), """\
  arr_ref<int> nums3(scr.bind<int>(), dimension(4));
  arr_ref<int> nums1(scr.bind<int>(), dimension(5));
  arr_ref<int> nums2(scr.bind<int>(), dimension(3));
""")
  #
  lines = get("common_equivalence_4.f")
  assert not absd(lines, tail_off(19), """\
      mbr<int> nums1(dimension(6));
      mbr<int> nums2(dimension(3));
      mbr<int> nums3(dimension(5));
      scr.allocate(),
        equivalence(nums1, nums2, nums3)
          .align<1>(arr_index(3))
           .with<2>(arr_index(2))
          .align<1>(arr_index(6))
           .with<3>(arr_index(4))
      ;
""")
  #
  lines = get("common_equivalence_5.f")
  assert not absd(lines, head_off(31), """\
      mbr<int> inside(dimension(2));
      mbr<int> data(dimension(4));
      scr.allocate(),
        equivalence(inside, data)
          .align<2>()
           .with<1>()
      ;
""")
  assert not absd(lines, head_off(41), """\
  arr_ref<int> data(scr.bind<int>(), dimension(4));
""")
  assert not absd(lines, tail_off(16), """\
      mbr<int> inside(dimension(3));
      scr.allocate(), inside;
""")
  #
  lines = get("equivalence_09.f")
  assert not absd(lines, head_off(15), """\
struct program_prog_save
{
  fem::variant_bindings scr_bindings;
  fem::variant_core_and_bindings save_equivalences;
};
""")
  assert not absd(lines, tail_off(6), """\
  common_variant scr(cmn.common_scr, sve.scr_bindings);
  save_equivalences sve_equivalences(sve.save_equivalences);
  if (is_called_first_time) {
    using fem::mbr; // member of variant common or equivalence
    {
      mbr<int> nc;
      mbr<int> nce;
      scr.allocate(),
        equivalence(nc, nce)
          .align<1>()
           .with<2>()
      ;
    }
    {
      mbr<int> ns;
      mbr<int> nse;
      sve_equivalences.allocate(),
        equivalence(ns, nse)
          .align<1>()
           .with<2>()
      ;
    }
  }
  local_equivalences loc_equivalences;
  {
    using fem::mbr; // member
    mbr<int> nl;
    mbr<int> nle;
    loc_equivalences.allocate(),
      equivalence(nl, nle)
        .align<1>()
         .with<2>()
    ;
  }
  int& nc = scr.bind<int>();
  int& nce = scr.bind<int>();
  int& ns = sve_equivalences.bind<int>();
  int& nse = sve_equivalences.bind<int>();
  int& nl = loc_equivalences.bind<int>();
  int& nle = loc_equivalences.bind<int>();
""")
  #
  lines = get("equivalence_10.f")
  assert not absd(lines, tail_off(9), """\
  local_equivalences loc_equivalences;
  {
    using fem::mbr; // member
    mbr<int> nl(dimension(2));
    mbr<int> nle(dimension(2));
    loc_equivalences.allocate(),
      equivalence(nl, nle)
        .align<1>()
         .with<2>()
    ;
  }
  arr_ref<int> nc(scr.bind<int>(), dimension(2));
  arr_ref<int> nce(scr.bind<int>(), dimension(2));
  arr_ref<int> ns(sve_equivalences.bind<int>(), dimension(2));
  arr_ref<int> nse(sve_equivalences.bind<int>(), dimension(2));
  arr_ref<int> nl(loc_equivalences.bind<int>(), dimension(2));
  arr_ref<int> nle(loc_equivalences.bind<int>(), dimension(2));
""")
  #
  lines = get("equivalence_05.f")
  assert not absd(lines, tail_off(8), """\
    loc_equivalences.allocate(),
      equivalence(s1, s2)
        .align<1>(str_index(1, 1))
         .with<2>(str_index(2, 2))
    ;
""")
  #
  lines = get("equivalence_06.f")
  assert not absd(lines, head_off(17), """\
    loc_equivalences.allocate(),
      equivalence(s1, s2, s3, s4)
        .align<1>(arr_index(1)(1, 1))
         .with<2>(arr_index(2)(3, 3))
""")
  assert not absd(lines, head_off(29), """\
  /* str_arr_ref<> s3( */ loc_equivalences.bind_str() /* , dimension(2)) */ ;
  /* str_ref s4 */ loc_equivalences.bind_str();
""")
  #
  lines = get("equivalence_repeated.f")
  assert not absd(lines, tail_off(12), """\
  const int itwo = 2;
  const int ione = 1;
  local_equivalences loc_equivalences;
  {
    using fem::mbr; // member
    mbr<int> nums1(dimension(2));
    mbr<int> nums2(dimension(itwo));
    loc_equivalences.allocate(),
      equivalence(nums1, nums2)
        .align<1>(arr_index(1))
         .with<2>(arr_index(ione))
        .align<1>(arr_index(ione))
         .with<2>(arr_index(1))
    ;
  }
""")
  #
  lines = get("equivalence_data.f", data_specializations=False)
  assert not absd(lines, head_off(15), """\
struct program_prog_save
{
  fem::variant_bindings scr_bindings;
};
""")
  assert not absd(lines, tail_off(3), """\
  if (is_called_first_time) {
    fem::data((values, 12, 34, 56)), numse;
  }
""")
  #
  lines = get("common_name_clash.f")
  assert not absd(lines, head_off(36), """\
void
sub1init(
  common& cmn)
{
  // COMMON cmn1
  int& num2 = static_cast<common_cmn1&>(cmn).num2;
  //
  cmn.num1 = 12;
  num2 = 34;
}

void
sub2init(
  common& cmn)
{
  // COMMON cmn2
  arr_ref<int> num2(static_cast<common_cmn2&>(cmn).num2, dimension(2));
  //
  num2(1) = 56;
  num2(2) = 78;
  cmn.num3 = 90;
}
""")
  #
  lines = get("external_arg_simple.f")
  assert not absd(lines, head_off(3), """\
typedef void (*show1_function_pointer)(common&, int const&);

void
show1(
  common& cmn,
  int const& i)
{
  common_write write(cmn);
  write(6, star), 10 + i;
}
""")
  assert not absd(lines, head_off(25), """\
void
show(
  common& cmn,
  show1_function_pointer which,
  int const& i)
{
  which(cmn, i);
}
""")
  #
  lines = get("external_arg_function.f")
  assert not absd(lines, head_off(37), """\
void
sub1(
  common& cmn,
  fun_function_pointer func)
{
  FEM_CMN_SVE(sub1);
  common_write write(cmn);
  // SAVE
  int& i = sve.i;
  //
  i = func(cmn, i);
  write(6, star), i;
}
""")
  #
  lines = get("function_calls_with_its_name_as_arg.f")
  assert not absd(lines, head_off(13), """\
int
ifun(
  common& cmn,
  int const& iarg)
{
  int return_value = fem::int0;
  return_value = 12;
  sub(cmn, return_value, iarg);
  return return_value;
}
""")
  assert not absd(lines, tail_off(1), """\
  write(6, star), ifun(cmn, 34);
""")
  #
  lines = get("function_no_arg.f")
  assert not absd(lines, tail_off(1), """\
  write(6, star), ifun();
  write(6, star), jfun(cmn);
""")
  #
  lines = get("function_no_arg_with_common_in_expression.f")
  assert not absd(lines, tail_off(1), """\
  write(6, star), jfun(cmn);
  i = 2;
  int j = jfun(cmn);
  write(6, star), "j =", j;
  i = 7;
  if (jfun(cmn) == 137) {
    write(6, star), "jfun() == 137";
  }
""")
  #
  lines = get("if_arithmetic.f")
  assert not absd(lines, head_off(9), """\
  switch (fem::if_arithmetic(iarg - 2)) {
    case -1: goto statement_10;
    case  0: goto statement_20;
    default: goto statement_30;
  }
""")
  #
  lines = get("if_spaghetti.f")
  assert not absd(lines, head_off(19), """\
      statement_10:
      if (i == j) {
        goto statement_14;
      }
""")
  #
  lines = get("common_name_clash_2.f")
  assert not absd(lines, head_off(75), """\
  // COMMON cmn2
  arr_cref<int> num2(static_cast<common_cmn2&>(cmn).num2, dimension(2));
  int& num3 = cmn.num3;
  //
  int i = fem::int0;
  FEM_DO(i, 1, 2) {
    write(6, star), i, num2, num3;
  }
  FEM_DO(i, 3, 4) {
    write(6, star), i, num2, num3;
  }
""")
  #
  lines = get("dependency_cycle.f")
  assert not absd(lines, head_off(1), """\
/* Dependency cycles: 1
     sub1 sub2
 */
""")
  assert not absd(lines, head_off(7), """\
// forward declaration (dependency cycle)
void sub1(common&, int const&);
""")
  #
  lines = get("common_name_clash_3.f")
  assert not absd(lines, head_off(75), """\
  arr_cref<int> num2(static_cast<common_cmn2&>(cmn).num2, dimension(2));
  int& num3 = cmn.num3;
  //
  int j = fem::int0;
  int i = fem::int0;
  j = 0;
""")
  #
  lines = get("external_arg_non_const.f")
  assert not absd(lines, head_off(3), """\
typedef void (*exch_imp_function_pointer)(common&, arr_cref<int>, arr_ref<int>);

void
exch_imp(
  common& cmn,
  arr_cref<int> nc,
  arr_ref<int> nm)
""")
  #
  lines = get("parameter_for_arg_and_cmn_dim.f")
  assert not absd(lines, head_off(1), """\
struct common_scr
{
  static const int isz = 2;
""")
  assert not absd(lines, head_off(31), """\
  const int isz = 2;
  nums_arg(dimension(isz));
""")
  #
  lines = get("character_1_array_passing.f")
  assert not absd(lines, head_off(3), """\
void
sub(
  common& cmn,
  str_arr_cref<> strs1)
{
  strs1(dimension(2));
  common_write write(cmn);
  write(6, star), strs1;
}
""")
  assert not absd(lines, tail_off(2), """\
  arr<fem::str<1> > strs1(dimension(2), fem::fill0);
  strs1(1) = "X";
  strs1(2) = "y";
""")
  #
  lines = get("do_variable_passed.f")
  assert not absd(lines, head_off(3), """\
void
sub(
  common& cmn,
  int& iarg)
{
  common_write write(cmn);
  FEM_DO(iarg, 1, 2) {
    write(6, star), iarg + 13;
  }
}
""")
  #
  lines = get("intrinsics_extra.f")
  assert not absd(lines, head_off(1), """\
using fem::common;
""")
  assert not absd(lines, tail_off(2), """\
  fem::str<9> d = fem::char0;
  fem::date(d);
  write(6, "(a)"), d;
  fem::str<8> t = fem::char0;
  fem::time(t);
  write(6, "(a)"), t;
  fem::str<70> e = fem::char0;
  fem::getenv(" PATH ", e);
  write(6, "(a)"), e;
  float tm = fem::float0;
  fem::cpu_time(tm);
  write(6, "(f6.2)"), tm;
  fem::str<8> c = "echo YkD";
  int i = fem::system(c);
""")
  #
  lines = get("blockdata_unnamed.f", data_specializations=False)
  assert not absd(lines, head_off(28), """\
void
blockdata_unnamed(
  common& cmn)
{
  FEM_CMN_SVE(blockdata_unnamed);
  if (is_called_first_time) {
    fem::data((values, 3)), cmn.i;
  }
}
""")
  assert not absd(lines, tail_off(3), """\
  common cmn(argc, argv);
  blockdata_unnamed(cmn);
""")
  #
  lines = get("read_end_empty.f")
  assert not absd(lines, tail_off(8), """\
  statement_10:
  try {
    read(5, "()");
  }
""")
  #
  lines = get("rewind.f")
  assert not absd(lines, tail_off(18), """\
  cmn.io.rewind(1);
  read(1, "(i3)"), num;
  write(6, star), num;
  try {
    cmn.io.rewind(1);
  }
  catch (fem::io_err const&) {
    goto statement_10;
  }
  goto statement_20;
  statement_10:
""")
  #
  lines = get("read_rec_iostat.f")
  assert not absd(lines, tail_off(1), """\
  try {
    read(11, fem::unformatted).rec(21).iostat(ios), num;
  }
  catch (fem::read_end const&) {
  }
  catch (fem::io_err const&) {
  }
  try {
    read(12, fem::unformatted).iostat(ios), num;
  }
  catch (fem::read_end const&) {
    goto statement_20;
  }
  catch (fem::io_err const&) {
    goto statement_10;
  }
  try {
    read_loop rloop(cmn, 13, fem::unformatted);
    rloop.rec(23).iostat(ios);
    FEM_DO(i, 1, 2) {
      rloop, nums(i);
    }
  }
  catch (fem::read_end const&) {
  }
  catch (fem::io_err const&) {
  }
  try {
    read_loop rloop(cmn, 14, fem::unformatted);
    rloop.iostat(ios);
    FEM_DO(i, 1, 2) {
      rloop, nums(i);
    }
  }
  catch (fem::read_end const&) {
    goto statement_40;
  }
  catch (fem::io_err const&) {
    goto statement_30;
  }
  statement_10:
  statement_20:
  statement_30:
  statement_40:;
""")
  #
  lines = get("goto_computed.f")
  assert not absd(lines, tail_off(5), """\
      else {
        switch (i) {
          case 1: goto statement_10;
          case 2: goto statement_20;
          default: break;
        }
      }
      statement_10:
      write(6, star), "statement 10", j;
      goto statement_30;
      statement_20:
""")
  #
  lines = get("unformatted_experiments.f")
  assert not absd(lines, head_off(9), """\
  cmn.io.open(1, fem::file_not_specified)
    .form("unformatted")
    .status("unknown");
""")
  #
  lines = get("data_31.f", data_specializations=False)
  assert not absd(lines, tail_off(13), """\
    {
      fem::data_values data;
      data.values, 1, 2, 3, 4, 5, 6, 7, 8;
      data.values, 9, 10, 11, 12, 13, 14, 15, 16;
      data.values, 17, 18, 19, 20, 21, 22, 23, 24;
      data.values, 25, 26, 27, 28, 29, 30, 31, 32;
      data, nums1;
    }
    {
      fem::data_values data;
      data.values, 2, 3, 4, 5, 6, 7, 8, 9;
      data.values, 10, 11, 12, 13, 14, 15, 16, 17;
      data.values, 18, 19, 20, 21, 22, 23, 24, 25;
      data.values, 26, 27, 28, 29, 30, 31, 32, 33;
      data.values, 34;
      FEM_DO(i, 1, 33) {
        data, nums2(i);
      }
    }
""")
  #
  lines = get("data_32.f")
  assert not absd(lines, tail_off(14), """\
    num = -34;
    str = "YuIo";
    {
      static const int values[] = {
        +12, -34
      };
      fem::data_of_type<int>(FEM_VALUES_AND_SIZE),
        nums;
    }
    {
      static const int values[] = {
        -56, +78
      };
      fem::data_of_type<int> data(FEM_VALUES_AND_SIZE);
      FEM_DO(i, 1, 2) {
        data, numsi(i);
      }
    }
    {
      static const char* values[] = {
        "Cde", "FgH"
      };
      fem::data_of_type_str(FEM_VALUES_AND_SIZE),
        strs;
    }
    {
      static const char* values[] = {
        "IjkL", "MNOp"
      };
      fem::data_of_type_str data(FEM_VALUES_AND_SIZE);
      FEM_DO(i, 1, 2) {
        data, strsi(i);
      }
    }
    numj = 91;
    numsj(1) = 23;
    strsj(1) = "Hjklo";
    numsj(2) = 45;
    strsj(2) = "ASdfg";
""")
  assert not absd(lines, head_off(36), """\
    static const int values[] = {
      -24, +35
    };
    fem::data_of_type<int>(FEM_VALUES_AND_SIZE),
      nums;
""")
  assert not absd(lines, head_off(97), """\
    sc = fem::cmplx(1.2f, -3.4f);
    dc = fem::cmplx(-5.6e0, +7.8e0);
""")
  #
  lines = get("const_expressions.f", arr_nd_size_max=6)
  assert not absd(lines, tail_off(10), """\
  arr_2d<n2 - 5, n3 - 48, int> nums1(fem::fill0);
""")
  assert not absd(lines, tail_off(3), """\
  const int n6 = fem::pow2(n1);
  arr<int> nums3(dimension(n6), fem::fill0);
""")
  lines = get("const_expressions.f", arr_nd_size_max=-6)
  assert not absd(lines, tail_off(10), """\
  arr_2d<n2 - 5, n3 - 48, int> nums1(fem::no_fill0);
""")
  #
  lines = get("common_save_members.f")
  assert not absd(lines, tail_off(9), """\
  // COMMON globals
  int& ci = cmn.ci;
  fem::str<8>& cc = cmn.cc;
  arr_ref<int> cai(cmn.cai, dimension(2));
  str_arr_ref<1> cas(cmn.cas, dimension(2));
  //
  // SAVE
  int& i = sve.i;
  arr_ref<int> sai(sve.sai, dimension(2));
  str_arr_ref<1> sas(sve.sas, dimension(2));
  fem::str<5>& sc = sve.sc;
  int& si = sve.si;
  //
  si = 12;
  ci = 34;
  sc = "WeRtY";
  cc = "uIoPqWeR";
  FEM_DO(i, 1, 2) {
    sai(i) = i + 37;
    cai(i) = i + 41;
  }
  sas(1) = "xYz";
  sas(2) = "EfG";
  cas(1) = "uvWx";
  cas(2) = "PqrS";
""")
  #
  lines = get("subroutine_4.f")
  assert not absd(lines, head_off(3), """\
//C1
//C c2
void
sub1(
  str_cref letter,
  int& num)
{
  //C3
  if (letter(1, 1) == "x") {
    num += 10;
  }
  //C4
}
//C c5

//C
//C6
void
sub2(
  str_cref letter,
  int& num)
{
  //C7
  sub1(letter, num);
  if (letter(1, 1) == "x") {
    num++;
  }
  else {
    num += 2;
  }
  //C8
}

//C
//C9
""")
  #
  lines = get("comments.f")
  assert not absd(lines, head_off(3), """\
//C
//C1
//Cc2
void
program_prog(
  int argc,
  char const* argv[])
{
  common cmn(argc, argv);
  common_write write(cmn);
  int i = fem::int0;
  arr<int> nums(dimension(2), fem::fill0);
  //C3
  //C c4
  //C5
  //Cc6
  //C7
  //C c8
  FEM_DO(i, 1, 2) {
    //C9
    //Cc10
    //C
    //C12
    //C
    //C c13
    //Cc14
    //C
    //C c15
    nums(i) = i + 47;
    //C16
    //Cc17
  }
  //C
  //C c18
  try {
    write(6, star), nums;
  }
  catch (fem::io_err const&) {
    goto statement_10;
  }
  //C19
  //Cc20
  goto statement_20;
  //C21
  //C c22
  statement_10:
  FEM_STOP("write error");
  //C23
  //Cc24
  statement_20:;
  //C25
}
//C  c26
//C27
//C
""")
  #
  lines = get("long_lines.f")
  assert not absd(lines, tail_off(15), """\
  write(6, star), numbers(1), numbers(2), numbers(3), numbers(4),
    numbers(5), numbers(6), numbers(7), numbers(8);
  write(6, star), numbers(1), numbers(2), numbers(3), numbers(4),
    numbers(5), numbers(6), numbers(7), numbers(8), numbers(9),
    numbers(10);
  write(6, star), numbers(1), numbers(2), numbers(3), numbers(4),
    numbers(5), numbers(6), numbers(7), numbers(8), numbers(9),
    numbers(10), numbers(11), numbers(12);
  write(6, star), numbers(1), numbers(2), numbers(3), numbers(4),
    numbers(5), numbers(6), numbers(7), numbers(8), numbers(9),
    numbers(10), numbers(11), numbers(12), numbers(13), numbers(14);
  write(6, star), numbers(1), numbers(2), numbers(3), numbers(4),
    numbers(5), numbers(6), numbers(7), numbers(8), numbers(9),
    numbers(10), numbers(11), numbers(12), numbers(13), numbers(14),
    numbers(15), numbers(16);
  write(6, star), numbers(1), numbers(2), numbers(3), numbers(4),
    numbers(5), numbers(6), numbers(7), numbers(8), numbers(9),
    numbers(10), numbers(11), numbers(12), numbers(13), numbers(14),
    numbers(15), numbers(16), numbers(17), numbers(18);
  write(6, star), numbers(1), numbers(2), numbers(3), numbers(4),
    numbers(5), numbers(6), numbers(7), numbers(8), numbers(9),
    numbers(10), numbers(11), numbers(12), numbers(13), numbers(14),
    numbers(15), numbers(16), numbers(17), numbers(18), numbers(19),
    numbers(20);
  write(6, "(a)"),
    "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz)!@#$%^&*(`"
    "~-_+=[{]}\\\\|;:'\\",<.>/?";
  write(6, "(a)"),
    "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz)!@#$%^&*\\\\"
    "`~-_+=[{]}(|;:'\\",<.>/?";
  write(6, "(a)"),
    "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz)!@#$%^&*("
    "\\\\~-_+=[{]}`|;:'\\",<.>/?";
  fem::str<127> s =
    "qwertyuiopasdfghjklzxcvbnmqwertyuiopasdfghjklzxcvbnmqwertyuioasdfghjkzxcv"
    "bnmqwerjkdfghjkertyjkxcghidfbndtyuiklmbvftyuiknbvdtyuh";
  write(6, "(a)"), s;
  write(6,
    "(/,' Sorry, your unit cell, range of hkl, size of map,',"
    "' and resolution will require ',/,' redimensioning of the program.',/,/,"
    "' This is quite easy:  You need to edit the source file ',"
    "' for the program',/,' and increase the value of \\"base_size\\" from ',i2,"
    "' to ',' a larger value',/,/,"
    "'  Then recompile the program and try again.',/,/,"
    "' If you do not have the source code, then you can obtain',/,"
    "' a version with a larger dimension from ',/,' our web site.',/)"),
    12;
  write(6,
    "(' first = ',f8.4,/,/,' second:              ',f5.2,/,"
    "' third:               ',f5.2,/,' fourth:              ',f5.2,/,"
    "' fifth:               ',f5.2,/,' sixth:               ',f5.1)"),
    1.2f, 3.4f, 5.6f, 7.8f, 9.1f, 2.3f;
""")
  assert not absd(lines, tail_off(1), """\
  if (nnnnn1 < 0 || nnnnn2 < 0 || nnnnn3 < 0 || nnnnn4 < 0 ||
      nnnnn5 < 0 || nnnnn6 <= 0) {
    write(6, "(a)"), "or ok";
  }
  if (nnnnn1 == 0 && nnnnn2 == 0 && nnnnn3 == 0 && nnnnn4 == 0 &&
      nnnnn5 == 0 && nnnnn6 <= 0) {
    write(6, "(a)"), "and ok";
  }
""")
  #
  lines = get("format_used_twice.f")
  assert not absd(lines, tail_off(1), """\
  static const char* format_10 = "(i2)";
  write(6, format_10), 12;
  write(6, "(i3)"), 345;
  write(6, format_10), 67;
""")
  #
  lines = get("blockdata_named.f")
  assert "\n".join(lines).find("Missing function implementation") < 0
  assert not absd(lines, head_off(1), """\
struct common_com
""")
  #
  lines = get("do_while.f")
  assert not absd(lines, tail_off(1), """\
  int i = 123;
  while (i < 169) {
    write(6, star), i;
    i += 45;
  }
  while (i < 281) {
    write(6, star), i;
    i += 67;
  }
""")
  #
  lines = get("len_trim.f")
  assert not absd(lines, tail_off(1), """\
  write(6, "(2a)"), s(1, fem::len_trim(s)), "X";
""")
  #
  lines = get("cycle_exit.f")
  assert not absd(lines, tail_off(1), """\
  FEM_DO(i, 1, 5) {
    if (i == 2) {
      continue;
    }
    if (i == 4) {
      break;
    }
    write(6, "(i1)"), i;
  }
""")
  #
  lines = get("identifier_prefix.f")
  assert not absd(lines, head_off(1), """\
struct common_vars
{
  int identifier_template;

  common_vars() :
    identifier_template(fem::int0)
  {}
};
""")
  assert not absd(lines, head_off(23), """\
identifier_switch(
""")
  assert not absd(lines, head_off(35), """\
  // COMMON vars
  int& identifier_template = cmn.identifier_template;
  //
  identifier_template = 123;
  write(6, star), identifier_template;
  identifier_switch(cmn);
""")
  assert not absd(lines, tail_off(2), """\
  int identifier_xor_eq = identifier_xor + 100;
  write(6, star), identifier_xor_eq;
""")
  #
  lines = get("hollerith.f")
  assert not absd(lines, tail_off(1), """\
  if (is_called_first_time) {
    static const char* values[] = {
      "X", "Yz", "PqR", "STuv"
    };
    fem::data_of_type_str(FEM_VALUES_AND_SIZE),
      hols;
  }
  write(6, "('a','cD','eFg','HijK','LMnOPqRstUvWxyZ@#','   ','$')");
  write(6, "(4('[',a,']'))"), hols;
  show(cmn, "x", 1);
  show(cmn, "Us", 2);
  show(cmn, "PdW", 3);
  show(cmn, "rTiTGBrDYtATTSwDkSw", 19);
""")
  #
  lines = get("commonymous.f")
  assert not absd(lines, head_off(1), """\
struct common_commonymous
""")
  #
  lines = get("print.f")
  assert not absd(lines, tail_off(1), """\
  write(6, star), 12, "Zpq";
  write(6, "(i2,a3)"), 34, "Jel";
  write(6, "(a3,i2)"), "OwM", 56;
  fem::str<7> fmt = "(a4,i1)";
  write(6, fmt), "TvDp", 7;
  int i = fem::int0;
  FEM_DO(i, 1, 2) {
    write(6, dynfmt(i)), i + 8;
  }
  write(6, star);
  write(6, "('XuW')");
  {
    write_loop wloop(cmn, 6, "(i2,i3)");
    FEM_DO(i, 3, 4) {
      wloop, i * 3;
    }
  }
""")
  #
  lines = get("hexadecimal.f")
  assert not absd(lines, tail_off(1), """\
  if (is_called_first_time) {
    static const int values[] = {
      0xfe, 0xdcba
    };
    fem::data_of_type<int>(FEM_VALUES_AND_SIZE),
      nums;
  }
  write(6, star), 0xA;
  write(6, star), 0xAB;
  write(6, star), 0xABC;
  write(6, star), 0xABCD;
  write(6, star), 0x7FFFFFFF;
  write(6, star), nums;
""")
  #
  lines = get("data_types.f")
  assert not absd(lines, tail_off(4), """\
  std::complex<float> vcomplex = fem::cmplx(1.f, 2.e10f);
  write(6, star), vcomplex;
  std::complex<float> vcomplex8 = fem::cmplx(-3.e10f, -4.f);
  write(6, star), vcomplex8;
  std::complex<double> vcomplex16 = fem::dcmplx(5.e0, 6.e10);
  write(6, star), vcomplex16;
  std::complex<double> vdc = fem::dcmplx(-7.e10, -8.e0);
  write(6, star), vdc;
""")
  #
  lines = get("write_format.f")
  assert not absd(lines, tail_off(15), """\
  write(6, "(a)"), msg(1, 3);
""")
  #
  lines = get("flush_intrinsic.f")
  assert not absd(lines, tail_off(1), """\
  cmn.io.flush(2 * 5 - 4);
""")
  #
  lines = get("flush_external.f")
  assert not absd(lines, tail_off(1), """\
  flush(cmn, 2 * 5 - 4);
""")
  #
  lines = get("string_concat.f")
  assert not absd(lines, head_off(10), """\
  fem::str<2> s1 = "x" + str_cref("Y");
""")
  assert not absd(lines, tail_off(1), """\
  write(6, "(a)"), ("v" + (str_cref("cX"))) + str_cref("yz");
""")
  #
  lines = get("intrinsics_iargc_getarg.f")
  assert not absd(lines, head_off(3), """\
void
sub1(
  common& cmn,
  int& n,
  str_arr_ref<> buf)
{
  buf(dimension(star));
  n = cmn.iargc();
  int i = fem::int0;
  FEM_DO(i, 1, n) {
    cmn.getarg(i, buf(i));
  }
}
""")

def exercise_syntax_error(verbose):
  t_dir = libtbx.env.under_dist(
    module_name="fable", path="test/syntax_error", test=op.isdir)
  from fable.read import Error
  def fail(file_name):
    if (verbose):
      print("exercise_syntax_error:", file_name)
    cout.process(file_names=[op.join(t_dir, file_name)])
  try:
    fail("bad_open_err_label.f")
  except Error as e:
    assert str(e).startswith("Invalid statement label:")
    assert str(e).endswith("""\
  |      open(1, file=name, err=1.3)|
--------------------------------^""")
  else: raise Exception_expected
  try:
    fail("power_no_base.f")
  except Error as e:
    assert str(e).startswith("Syntax error:")
    assert str(e).endswith("""\
  |      x = **3.4|
-------------^""")
  else: raise Exception_expected
  try:
    fail("power_no_exponent.f")
  except Error as e:
    assert str(e).startswith("Syntax error:")
    assert str(e).endswith("""\
  |      x = 1.2**|
----------------^""")
  else: raise Exception_expected

def exercise_semantic_error(verbose):
  t_dir = libtbx.env.under_dist(
    module_name="fable", path="test/semantic_error", test=op.isdir)
  from fable import SemanticError
  def fail(file_name):
    if (verbose):
      print("exercise_semantic_error:", file_name)
    cout.process(file_names=[op.join(t_dir, file_name)])
  try:
    fail("assignment_to_parameter.f")
  except SemanticError as e:
    assert str(e).startswith("Assignment to PARAMETER n:")
    assert str(e).endswith("""\
  |      n = 1|
---------^""")
  else: raise Exception_expected
  try:
    fail("inquire_no_unit_no_file.f")
  except SemanticError as e:
    assert str(e).startswith("Missing UNIT or FILE in INQUIRE statement:")
    assert str(e).endswith("""\
  |      inquire(exist=lexist)|
---------^""")
  else: raise Exception_expected
  try:
    fail("inquire_both_unit_and_file.f")
  except SemanticError as e:
    assert str(e).startswith(
      "Conflicting UNIT vs. FILE in INQUIRE statement"
      " (exactly one is needed):")
    assert str(e).endswith("""\
  |      inquire(10, file='fable_tmp')|
---------^""")
  else: raise Exception_expected
  try:
    fail("recursion_in_declaration.f")
  except SemanticError as e:
    assert str(e).startswith("Recursion in declaration:")
    assert str(e).endswith("""\
  |      dimension nums(nums)|
------------------------^""")
  else: raise Exception_expected

def exercise_unsupported(verbose):
  t_dir = libtbx.env.under_dist(
    module_name="fable", path="test/unsupported", test=op.isdir)
  def get(file_name):
    if (verbose):
      print("exercise_unsupported:", file_name)
    return cout.process(file_names=[op.join(t_dir, file_name)])
  #
  assert not absd(get("goto_into_loop.f"), tail_off(1), """\
  int i = fem::int0;
  FEM_DO_SAFE(i, 1, 2) {
    statement_10:
    write(6, star), i;
  }
  goto statement_10;
""")

def exercise_dynamic_parameters(verbose):
  t_dir = libtbx.env.under_dist(
    module_name="fable", path="test/valid", test=op.isdir)
  def get(file_name, dynamic_parameters):
    if (verbose):
      print("exercise_dynamic_parameter:", file_name)
    file_names = [op.join(t_dir, file_name)]
    return cout.process(
      file_names=file_names,
      top_procedures=["prog"],
      dynamic_parameters=dynamic_parameters)
  #
  lines = get("dynamic_parameters_1.f", [
    cout.dynamic_parameter_props(
      name="root_size", ctype="int", default="3")])
  assert not absd(lines, head_off(0), """\

struct dynamic_parameters
{
  int root_size;

  dynamic_parameters(
    fem::command_line_arguments const& command_line_args)
  :
    root_size(3)
  {
    fem::dynamic_parameters_from(command_line_args, 1)
      .reset_if_given(root_size)
    ;
  }
};

typedef
  fem::dynamic_parameters_capsule<dynamic_parameters>
    dynamic_parameters_capsule;

struct common :
  fem::common,
  dynamic_parameters_capsule
{
  common(
    int argc,
    char const* argv[])
  :
    fem::common(argc, argv),
    dynamic_parameters_capsule(command_line_args)
  {}
};

void
sub(
  common& cmn,
  arr_ref<int> nums)
{
  const int root_size = cmn.dynamic_params.root_size;
""")
  assert not absd(lines, tail_off(7), """\
  common cmn(argc, argv);
""")
  #
  lines = get("dynamic_parameters_2.f", [
    cout.dynamic_parameter_props(
      name="nums_size", ctype="int", default="2")])
  assert not absd(lines, head_off(20), """\
struct common_com
{
  const int nums_size;
  arr<int> nums;

  common_com(
    dynamic_parameters const& dynamic_params)
  :
    nums_size(dynamic_params.nums_size),
    nums(dimension(nums_size), fem::fill0)
  {}
};

struct common :
""")
  assert not absd(lines, head_off(44), """\
    common_com(dynamic_params)
""")
  #
  lines = get("dynamic_parameters_3.f", [
    cout.dynamic_parameter_props(
      name="base_size", ctype="int", default="3")])
  assert not absd(lines, head_off(20), """\
struct common_com
{
  const int base_size;
  const int nums_size;
  arr<int> nums;

  common_com(
    dynamic_parameters const& dynamic_params)
  :
    base_size(dynamic_params.base_size),
    nums_size(base_size * 2),
    nums(dimension(nums_size), fem::fill0)
  {}
};

""")
  #
  lines = get("dynamic_parameters_4.f", [
    cout.dynamic_parameter_props(
      name="base_size", ctype="int", default="3")])
  assert not absd(lines, head_off(35), """\
struct sub_save
{
  const int base_size;
  arr<int> nums;

  sub_save(
    dynamic_parameters const& dynamic_params)
  :
    base_size(dynamic_params.base_size),
    nums(dimension(base_size * 2), fem::fill0)
  {}
};

""")
  assert not absd(lines, head_off(53), """\
  FEM_CMN_SVE_DYNAMIC_PARAMETERS(sub);
""")
  #
  lines = get("dynamic_parameters_5.f", [
    cout.dynamic_parameter_props(
      name="base_size", ctype="int", default="3")])
  assert not absd(lines, head_off(38), """\
  const int base_size = cmn.dynamic_params.base_size;
  nums(dimension(base_size * 2));
""")

def exercise_common_equivalence_simple(verbose):
  t_dir = libtbx.env.under_dist(
    module_name="fable", path="test/valid", test=op.isdir)
  def get(file_name, common_names, expected_common_report=None):
    if (verbose):
      print("exercise_common_equivalence_simple:", file_name)
    file_names = [op.join(t_dir, file_name)]
    common_report_stringio = StringIO()
    lines = cout.process(
      file_names=file_names,
      top_procedures=["prog"],
      common_equivalence_simple=set(common_names.split(",")),
      common_report_stringio=common_report_stringio)
    if (expected_common_report is None):
      assert common_report_stringio.getvalue() == ""
    else:
      assert not show_diff(
        common_report_stringio.getvalue(),
        expected_common_report)
    return lines
  #
  for i in [1,2]:
    lines = get("common_equivalence_simple_%d.f" % i, "info")
    assert not absd(lines, tail_off(2), """\
  common cmn(argc, argv);
  common_write write(cmn);
  // COMMON info
  arr_ref<int> nums(cmn.nums, dimension(2));
  //
  int& n1 = nums(1); // SIMPLE EQUIVALENCE
  n1 = 12;
  int& n2 = nums(2); // SIMPLE EQUIVALENCE
  n2 = 34;
""")
  #
  lines = get("common_equivalence_simple_3.f", "tab")
  assert not absd(lines, head_off(1), """\
struct common_tab
{
  int na;
  int nb_memory[2];
  int nc_memory[1-0+1];
  int nd_memory[(2-(-1)+1) * 3];

  arr_ref<int> nb;
  arr_ref<int> nc;
  arr_ref<int, 2> nd;

  common_tab() :
    na(fem::int0),
    nb(*nb_memory, dimension(2), fem::fill0),
    nc(*nc_memory, dim1(0, 1), fem::fill0),
    nd(*nd_memory, dim1(-1, 2).dim2(3), fem::fill0)
  {}
};
""")
  assert not absd(lines, tail_off(5), """\
  arr_ref<int> nums(cmn.na, dimension(17)); // SIMPLE EQUIVALENCE
""")
  #
  lines = get("common_equivalence_simple_4.f", "first",
    expected_common_report="""\
Name clash: n2 in COMMONs: first, second

""")
  assert not absd(lines, tail_off(6), """\
  arr_ref<int> nums(cmn.n1, dimension(3)); // SIMPLE EQUIVALENCE
""")
  assert not absd(lines, tail_off(2), """\
  int& m2 = n2; // SIMPLE EQUIVALENCE
""")
  #
  lines = get("common_equivalence_simple_5.f", "all")
  assert not absd(lines, tail_off(2), """\
  arr_ref<int> m1a(n1(1), dimension(2)); // SIMPLE EQUIVALENCE
  write(6, star), m1a;
  arr_ref<int> m1b(n1, dimension(2)); // SIMPLE EQUIVALENCE
  write(6, star), m1b;
  arr_ref<int> m1c(n1(1), dimension(2)); // SIMPLE EQUIVALENCE
  write(6, star), m1c;
  arr_cref<int> m2(n2, dimension(6)); // SIMPLE EQUIVALENCE
  write(6, star), m2;
  arr_cref<int> m2a(n2(1, 1), dimension(6)); // SIMPLE EQUIVALENCE
  write(6, star), m2a;
  arr_cref<int> m2b(n2, dimension(6)); // SIMPLE EQUIVALENCE
  write(6, star), m2b;
  arr_cref<int> m2c(n2(1, 1), dimension(6)); // SIMPLE EQUIVALENCE
""")
  #
  lines = get("common_equivalence_simple_6.f", "com")
  assert not absd(lines, head_off(3), """\
  fem::str<3> s3_memory[2];
  fem::str<8> s8;

  str_arr_ref<1> s3;
""")
  assert not absd(lines, tail_off(24), """\
  str_ref s6(s3, 6); // SIMPLE EQUIVALENCE
""")
  assert not absd(lines, tail_off(20), """\
  str_arr_ref<1> s2(s3, 2, dimension(3)); // SIMPLE EQUIVALENCE
""")
  assert not absd(lines, tail_off(10), """\
  str_ref s8e(cmn.s8, 8); // SIMPLE EQUIVALENCE
""")
  assert not absd(lines, tail_off(8), """\
  str_arr_ref<1> s4(cmn.s8, 4, dimension(2)); // SIMPLE EQUIVALENCE
""")
  assert not absd(lines, tail_off(4), """\
  str_arr_ref<1> s1(s3(2), 1, dimension(5)); // SIMPLE EQUIVALENCE
""")

def run(args):
  assert args in [[], ["--verbose"]]
  verbose = (len(args) != 0)
  exercise_simple(verbose=verbose)
  exercise_syntax_error(verbose=verbose)
  exercise_semantic_error(verbose=verbose)
  exercise_unsupported(verbose=verbose)
  exercise_dynamic_parameters(verbose=verbose)
  exercise_common_equivalence_simple(verbose=verbose)
  print("OK")

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************
