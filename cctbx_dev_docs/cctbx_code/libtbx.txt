

 *******************************************************************************
libtbx/__init__.py
from __future__ import absolute_import, division, print_function
import libtbx.forward_compatibility
import os
import sys

from libtbx.forward_compatibility import object

manual_date_stamp = 20090819

def _STOP(exit_status=0):
  f = sys._getframe(1)
  print("STOP: %s(%d)" % (f.f_code.co_filename, f.f_lineno))
  sys.exit(exit_status)
__builtins__["STOP"] = _STOP

def _numstr(
      values,
      fmt="%.6g",
      sep=", ",
      brackets=("[","]"),
      zero_threshold=None):
  flds = []
  for v in values:
    if (v is None):
      s = " "*(max(0,len(fmt % 0)-4)) + "None"
    else:
      if (zero_threshold is not None and abs(v) <= zero_threshold):
        v = 0
      s = fmt % v
      if (s.strip().replace("0", "") in ["-", "-."]):
        s = fmt % 0
    flds.append(s)
  return brackets[0] + sep.join(flds) + brackets[1]
__builtins__["numstr"] = _numstr

class AutoType(object):
  """
  Class for creating the Auto instance, which mimics the behavior of None
  with respect to the 'is' and '==' operators; this is used throughout
  CCTBX to indicate parameters that should be determined automatically.

  Examples
  --------
  >>> def f(optional=libtbx.Auto)
  ...    if optional is libtbx.Auto:
  ...        optional = 5
  ...    return optional
  ...
  >>> print(f())
  5
  >>> print(f(optional=10))
  10
  """
  singleton = None

  def __str__(self): return "Auto"
  def __eq__(self, other):
    return isinstance(other, self.__class__)
  def __ne__(self, other):
    return not self.__eq__(other)
  def __hash__(self):
    '''AutoType behaves as a singleton, so return the same hash value for all instances.'''
    return hash(AutoType)
  def __new__(cls):
    if cls.singleton is None:
      cls.singleton = super(AutoType, cls).__new__(cls)
    return cls.singleton

Auto = AutoType()

class mpi_import_guard:
  disable_mpi = False

class slots_getstate_setstate(object):
  """
  Implements getstate and setstate for classes with __slots__ defined. Allows an
  object to easily pickle only certain attributes.

  Examples
  --------
  >>> class sym_pair(libtbx.slots_getstate_setstate):
  ...     __slots__ = ["i_seq", "j_seq"]
  ...     def __init__(self, i_seq, j_seq):
  ...         self.i_seq = i_seq
  ...         self.j_seq = j_seq
  ...
  """

  __slots__ = []

  def __getstate__(self):
    """
    The name of some attributes may start with a double underscore such as
    cif_types.comp_comp_id.__rotamer_info. Python name mangling will rename such
    an attribute to _comp_comp_id_rotamer_info. Our __getstate__ function would then
    complain that the __slots__ list contains the non-existent attribute __rotamer_info.
    To fix this we manually mangle attributes with the compiler.misc.mangle function
    which does the right name mangling.
    """
    import warnings
    warning_filters = warnings.filters[:]
    show_warning = warnings.showwarning

    try:
      # avoid printing deprecation warning to stderr when loading mangle
      warnings.simplefilter("ignore")
      from libtbx.utils import mangle

    finally:
      warnings.showwarning = show_warning
      warnings.filters = warning_filters

    mnames = [ mangle(name, self.__class__.__name__) for name in self.__slots__ ]

    return dict([(name, getattr(self, name)) for name in mnames])

  def __setstate__(self, state):
    for name,value in state.items():
      if isinstance(name, bytes):
        name = name.decode('utf8')
      setattr(self, name, value)

class mutable(slots_getstate_setstate):
  __slots__ = ["value"]

  def __init__(O, value):
    O.value = value

class slots_getstate_setstate_default_initializer(slots_getstate_setstate):
  """
  Merges together functionality from slots_getstate_setstate with
  adopt_optional_init_args.

  Examples
  --------
  >>> class sym_pair(libtbx.slots_getstate_setstate_default_initializer):
  ...     __slots__ = ["i_seq", "j_seq"]
  ...
  >>> svm_pair(i_seq=1, j_seq=2)
  >>> print(svm_pair.i_seq)
  1
  """
  def __init__(self, **kwds):
    kwds = dict(kwds)
    for key in kwds :
      setattr(self, key, kwds.get(key, None))

class unpicklable(object):
  """
  An inheritable class that raises a runtime exception that an object is
  unpicklable.
  """

  def _raise_error(O):
    raise RuntimeError(
      "pickling of %s objects is disabled." % O.__class__.__name__)

  def __getinitargs__(O): O._raise_error()
  def __getstate__(O): O._raise_error()
  def __setstate__(O, state): O._raise_error()

class dict_with_default_0(dict):
  def __missing__(self, key):
    return 0

def adopt_init_args(obj, args, exclude=(), hide=False):
  """
  Adopts the initial arguments passed to an object, allowing developers to skip
  the tedious task of assigning each attribute of an instance in its __init__
  method.

  Parameters
  ----------
  obj : object
  args : list
  exclude : list of str
  hide : bool, optional

  Examples
  --------
  >>> class foo(object):
  ...     def __init__(self, x, y=1, z=None):
  ...         adopt_init_args(self, locals())
  ...
  >>> a = foo('a', z=10)
  >>> assert a.x == 'a'
  >>> assert a.y == 1
  >>> assert a.z == 10
  """
  if ("self" in args): del args["self"]
  else:                del args["O"]
  for param in exclude:
    del args[param]
  if (hide == False):
    for key in args.keys():
      if key.startswith("__") and key.endswith("__"):
        continue
      assert not hasattr(obj.__dict__, key)
    obj.__dict__.update(args)
  else:
    for key in args.keys():
      _key = "_" + key
      assert not hasattr(obj.__dict__, _key)
      obj.__dict__[_key] = args[key]

def adopt_optional_init_args(obj, kwds):
  """
  Easy management of long list of arguments with default value
  passed to __init__.

  Parameters
  ----------
  obj : object
  kwds : dict

  Examples
  --------
  >>> class foo(object):
  ...     z = 1
  ...     def __init__(self, **kwds):
  ...       libtbx.adopt_optional_init_args(self, kwds)
  ...
  >>> a = foo()
  >>> assert a.z == 1
  >>> a = foo(z=10)
  >>> assert a.z == 10
  """
  for k,v in kwds.items():
    if not hasattr(obj.__class__, k):
      raise RuntimeError("%s must be a class attribute of %s to "
                         "be adopted as optional init argument "
                         "by an instance of that class."
                         % (k, obj.__class__))
    setattr(obj, k, v)

class dda(object):
  dynamic_attributes_disabled = False
  def __setattr__(self, k, v):
    if(self.dynamic_attributes_disabled and not hasattr(self, k)):
      raise TypeError("Dynamic attributes disabled.")
    object.__setattr__(self, k, v)

  def stop_dynamic_attributes(self):
      self.dynamic_attributes_disabled = True

class group_args(dda):
  """
  Class to build an arbitrary object from a list of keyword arguments.

  Examples
  --------
  >>> from libtbx import group_args
  >>> obj = group_args(a=1, b=2, c=3)
  >>> print(obj.a, obj.b, obj.c)
  1 2 3

  Once stop_dynamic_attributes is called, adding new attributes won't be
  possible, that is this:

  obj.tmp=10

  will fail.
  """

  def __init__(self, **keyword_arguments):
    self.__dict__.update(keyword_arguments)

  def __call__(self):
    return self.__dict__

  def get(self,kw, default_value = None):
    return self.__dict__.get(kw, default_value)

  def keys(self):
    return self.__dict__.keys()

  def __repr__(self):
    outl = "group_args"
    from libtbx.utils import to_str,sys
    for attr in sorted(self.__dict__.keys()):
      tmp=getattr(self, attr)
      if (sys.version_info.major < 3) and (isinstance(tmp,unicode)):
        tmp = to_str(tmp)
      if str(tmp).find("ext.atom ")>-1:
        outl += "\n  %-30s : %s" % (attr, tmp.quote())
      else:
        outl += "\n  %-30s : %s" % (attr, tmp)
    return outl

  def merge(self, other):
    """ To merge other group_args into self.
    Overwrites matching fields!!!"""
    self.__dict__.update(other.__dict__)

  def add_if_missing(self, other, add_if_self_is_none = False):
    """ takes values from other only if not present at all in self
      Optionally add if value in self is None"""
    self_keys = list(self.keys())
    for key in other.keys():
      if key.startswith("__"): continue
      if (not (key in self_keys)) or (add_if_self_is_none and
          (self.get(key) is None)):
        self.add(key,other.get(key))

  def add(self,key=None,value=None):
    self.__dict__[key]=value

  def delete(self, key = None):
    if key in self.keys():
      self.__dict__[key] = None
  def copy(self):
    """ produce shallow copy of self by converting to dict and back"""
    return group_args(**self().copy())

if os.environ.get("LIBTBX_PRINT_TRACE"):
  import libtbx.start_print_trace

if sys.platform == "cygwin":
  # work around cygwin problem: open() doesn't work on symbolic links
  builtin_open = __builtins__["open"]
  def open_realpath(name, mode="r", buffering=-1):
    try: return builtin_open(name, mode, buffering)
    except KeyboardInterrupt: raise
    except Exception: pass
    name = os.path.realpath(name)
    return builtin_open(name, mode, buffering)
  __builtins__["open"] = open_realpath
  __builtins__["file"] = open_realpath


 *******************************************************************************


 *******************************************************************************
libtbx/assert_utils.py
""" Functions useful to write assertions, especially preconditions """
from __future__ import absolute_import, division, print_function

def is_numeric(x):
  try: x+1.
  except KeyboardInterrupt: raise
  except Exception: return False
  else: return True

def is_string(s):
  try: s+""
  except KeyboardInterrupt: raise
  except Exception: return False
  else: return True

class shall_raise(object):

  def __init__(self, func, *exceptions):
    self.func = func
    self.exceptions = exceptions

  def __call__(self, *args, **kwds):
    try: self.func(*args, **kwds)
    except KeyboardInterrupt: raise
    except Exception:
      import sys
      return sys.exc_info()[0] in self.exceptions
    else: return False


if __name__ == '__main__':
  assert is_numeric(1)
  assert is_numeric(1.)
  assert not is_numeric("1")
  assert not is_numeric([1])
  assert not is_numeric((1,))
  try:
    from scitbx.array_family import flex
  except ImportError:
    import sys
    print("scitbx library not available:" \
                         "some tests were skipped", file=sys.stderr)
  else:
    assert is_numeric(flex.double((1,2,3)))

  def f(x,y,z):
    z//(x-y)
  assert shall_raise(f, ZeroDivisionError)(1,1,1)
  assert not shall_raise(f, ZeroDivisionError)(x=1, y=0, z=0)

  print('OK')


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/__init__.py


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/bootstrap.py
#!/usr/bin/env python
# -*- mode: python; coding: utf-8; indent-tabs-mode: nil; python-indent: 2 -*-

# Running bootstrap requires a minimum Python version of 2.6.

# To download this file:
# wget https://raw.githubusercontent.com/cctbx/cctbx_project/master/libtbx/auto_build/bootstrap.py
# or
# curl https://raw.githubusercontent.com/cctbx/cctbx_project/master/libtbx/auto_build/bootstrap.py > bootstrap.py

# Environment variables:
#   CCTBX_SKIP_CHEMDATA_CACHE_REBUILD - if this exists, the rotarama and cablam caches are not rebuilt

from __future__ import absolute_import, division, print_function

import ntpath
import os
import os.path
import platform
import posixpath
import re
import shutil
import socket as pysocket
import stat
import subprocess
import sys
import tarfile
import tempfile
import textwrap
import time
import traceback
try: # Python 3
    from urllib.parse import urlparse
    from urllib.request import urlopen, Request
    from urllib.error import HTTPError, URLError
except ImportError: # Python 2
    from urlparse import urlparse
    from urllib2 import urlopen, Request, HTTPError, URLError
import zipfile

try:
  import argparse
except ImportError:
  raise RuntimeError("""
The argparse module is required. If you are using Python 2.6, you may
need to install it separately. On CentOS 6, you can run

  yum install python-argpase

with administrative privileges.
""")

_BUILD_DIR = "build"  # set by arg parser further on down

windows_remove_list = []

rosetta_version_tar_bundle='rosetta_src_2018.33.60351_bundle'
rosetta_version_directory=rosetta_version_tar_bundle
# LICENSE REQUIRED
afitt_version="AFITT-2.4.0.4-redhat-RHEL7-x64" #binary specific to cci-vm-1
envs = {
  "PHENIX_ROSETTA_PATH" : ["modules", "rosetta"],
  "OE_EXE"              : ["modules", "openeye", "bin"],
  "OE_LICENSE"          : ["oe_license.txt"], # needed for license
}

# Utility function to be executed on slave machine or called directly by standalone bootstrap script
def tar_extract(workdir, archive, modulename=None):
  try:
    # delete tar target folder if it exists
    if modulename and os.path.exists(modulename):
      def remShut(*args):
        func, path, _ = args # onerror returns a tuple containing function, path and exception info
        os.chmod(path, stat.S_IREAD | stat.S_IWRITE)
        os.remove(path)
      shutil.rmtree(modulename, onerror=remShut)
      # hack to work around possible race condition on Windows where deleted files may briefly
      # exist as phantoms and result in "access denied" error by subsequent IO operations
      cnt=0
      while os.path.exists(modulename):
        time.sleep(1)
        cnt = cnt + 1
        if cnt > 5:
          break
    # using tarfile module rather than unix tar command which is not platform independent
    tar = tarfile.open(os.path.join(workdir, archive), errorlevel=2)
    tar.extractall(path=workdir)
    tarfoldername = os.path.join(workdir, os.path.commonprefix(tar.getnames()).split('/')[0])
    tar.close()
    # take full permissions on all extracted files
    module = os.path.join(workdir, tarfoldername)
    for root, dirs, files in os.walk(module):
      for fname in files:
        full_path = os.path.join(root, fname)
        os.chmod(full_path, stat.S_IREAD | stat.S_IWRITE | stat.S_IRGRP | stat.S_IROTH)
    # rename to expected folder name, e.g. boost_hot -> boost
    # only rename if folder names differ
    if modulename:
      if modulename != tarfoldername:
        os.rename(tarfoldername, modulename)
  except Exception as e:
    raise Exception("Extracting tar archive resulted in error: " + str(e) + "\n" \
      + traceback.format_exc())
    return 1
  return 0

# Mock commands to run standalone, without buildbot.
class ShellCommand(object):
  def __init__(self, **kwargs):
    self.kwargs = kwargs

  def get_command(self):
    return self.kwargs['command']

  def get_description(self):
    if 'description' in self.kwargs:
      return self.kwargs['description']
    return None

  def get_workdir(self):
    return self.kwargs.get('workdir', _BUILD_DIR)

  def get_environment(self):
    # gets environment from kwargs
    env = self.kwargs.get('env', None)
    if env:
      for key, item in env.items():
        if item is None:
          env[key] = ''
        else:
          env[key] = os.path.abspath(item)
      rc = os.environ
      rc.update(env)
      env=rc
    return env

  def run(self):
    t0=time.time()
    command = self.get_command()
    description = self.get_description()
    workdir = self.get_workdir()
    env = self.get_environment()
    if not self.kwargs.get("quiet", False):
      if description:
        print("===== Running in %s:"%workdir, description)
      else:
        print("===== Running in %s:"%workdir, " ".join(command))
    if workdir:
      try:
        os.makedirs(workdir)
      except OSError:
        pass
    if command[0] == 'tar':
      # don't think any builders explicitly calls tar but leave it here just in case
      modname = None
      if len(command) > 3 and command[3]:
        modname = command[3]
      return tar_extract(workdir, command[2], modname)
    if command[0] == 'rm':
      # XXX use shutil rather than rm which is not platform independent
      for directory in command[2:]:
        if os.path.exists(directory):
          print('Deleting directory : %s' % directory)
          try: shutil.rmtree(directory)
          except OSError:
            print("Strangely couldn't delete %s" % directory)
      return 0
    if 0:
      print('command',command)
      print('workdir',workdir)
      print('env',env)
      print(os.environ.get("PATH", None))
    try:
      #if not os.path.isabs(command[0]):
        # executable path isn't located relative to workdir
      #  command[0] = os.path.join(workdir, command[0])
      stderr, stdout = None, None
      if self.kwargs.get("silent", False):
        stderr = stdout = open(os.devnull, 'wb')
      p = subprocess.Popen(
        args=command,
        cwd=workdir,
        stdout=stdout,
        stderr=stderr,
        env=env,
      )
    except Exception as e: # error handling
      if not self.kwargs.get('haltOnFailure'):
        return 1
      if isinstance(e, OSError):
        if e.errno == 2:
          executable = os.path.normpath(os.path.join(workdir, command[0]))
          raise RuntimeError("Could not run %s: File not found" % executable)
      if 'child_traceback' in dir(e):
        print("Calling subprocess resulted in error; ", e.child_traceback)
      raise e

    p.wait()
    if p.returncode != 0 and self.kwargs.get('haltOnFailure'):
      print("Process failed with return code %s"%(p.returncode))
      sys.exit(1)
    if 0:
      if description:
        outl = "%s - %s" % (workdir, description)
      else:
        outl = "%s - %s" % (workdir, " ".join(command))
      print('===== Time to %s : %0.1f' % (outl, time.time()-t0))
    return p.returncode

class Toolbox(object):
  @staticmethod
  def download_to_file(url, file, log=sys.stdout, status=True, cache=True):
    """Downloads a URL to file. Returns the file size.
       Returns -1 if the downloaded file size does not match the expected file
       size
       Returns -2 if the download is skipped due to the file at the URL not
       being newer than the local copy (identified by A. matching timestamp and
       size, or B. matching etag).
    """

    # Create directory structure if necessary
    if os.path.dirname(file):
      try:
        os.makedirs(os.path.dirname(file))
      except Exception:
        pass

    localcopy = os.path.isfile(file)

    # Get existing ETag, if present
    etag = None
    tagfile = '%s/.%s.etag' % os.path.split(os.path.abspath(file))
    if cache and os.path.isfile(tagfile):
      if not localcopy:
        # Having an ETag without a file is pointless
        os.remove(tagfile)
      else:
        tf = open(tagfile, 'r')
        etag = tf.readline()
        tf.close()

    try:
      import ssl
      from ssl import SSLError
    except ImportError:
      ssl = None
      SSLError = None

    # Open connection to remote server
    try:
      if sys.platform == "win32" and 'lbl.gov' in url:
# Downloading from http://cci.lbl.gov/cctbx_dependencies caused
# SSL: CERTIFICATE_VERIFY_FAILED error on Windows only as of today (why?).
# Quick and dirty hack to disable ssl certificate verification.
        try:
          _create_unverified_https_context = ssl._create_unverified_context
        except AttributeError:
          # Legacy Python that doesn't verify HTTPS certificates by default
          pass
        except NameError:
          # ssl module was not loaded
          pass
        else:
          # Handle target environment that doesn't support HTTPS verification
          ssl._create_default_https_context = _create_unverified_https_context
      url_request = Request(url)
      if etag:
        url_request.add_header("If-None-Match", etag)
      if localcopy:
        # Shorten timeout to 7 seconds if a copy of the file is already present
        socket = urlopen(url_request, None, 7)
      else:
        socket = urlopen(url_request)
    except SSLError as e:
      # This could be a timeout
      if localcopy:
        # Download failed for some reason, but a valid local copy of
        # the file exists, so use that one instead.
        log.write("%s\n" % str(e))
        return -2
      # otherwise pass on the error message
      raise
    except (pysocket.timeout, HTTPError) as e:
      if isinstance(e, HTTPError) and etag and e.code == 304:
        # When using ETag. a 304 error means everything is fine
        log.write("local copy is current (etag)\n")
        return -2
      if localcopy:
        # Download failed for some reason, but a valid local copy of
        # the file exists, so use that one instead.
        log.write("%s\n" % str(e))
        return -2
      # otherwise pass on the error message
      raise
    except URLError as e:
      if localcopy:
        # Download failed for some reason, but a valid local copy of
        # the file exists, so use that one instead.
        log.write("%s\n" % str(e))
        return -2
      # if url fails to open, try using curl
      # temporary fix for old OpenSSL in system Python on macOS
      # https://github.com/cctbx/cctbx_project/issues/33
      command = ['/usr/bin/curl', '--http1.0', '-fLo', file, '--retry', '5', url]
      subprocess.call(command, shell=False)
      socket = None     # prevent later socket code from being run
      try:
        received = os.path.getsize(file)
      except OSError:
        raise RuntimeError("Download failed")

    if (socket is not None):
      try:
        file_size = int(socket.info().get('Content-Length'))
      except Exception:
        file_size = 0

      if os.path.isfile(tagfile):
        # ETag did not match, so delete any existing ETag.
        os.remove(tagfile)

      remote_mtime = 0
      try:
        remote_mtime = time.mktime(socket.info().getdate('last-modified'))
      except Exception:
        pass

      if (file_size > 0):
        if (remote_mtime > 0):
          # check if existing file matches remote size and timestamp
          try:
            (mode, ino, dev, nlink, uid, gid, size, atime, mtime, ctime) = os.stat(file)
            if (size == file_size) and (remote_mtime == mtime):
              log.write("local copy is current\n")
              socket.close()
              return -2
          except Exception:
            # proceed with download if timestamp/size check fails for any reason
            pass

        hr_size = (file_size, "B")
        if (hr_size[0] > 500): hr_size = (hr_size[0] / 1024, "kB")
        if (hr_size[0] > 500): hr_size = (hr_size[0] / 1024, "MB")
        log.write("%.1f %s\n" % hr_size)
        if status:
          log.write("    [0%")
          log.flush()

      received = 0
      block_size = 8192
      progress = 1
      # Allow for writing the file immediately so we can empty the buffer
      tmpfile = file + '.tmp'

      f = open(tmpfile, 'wb')
      while True:
        block = socket.read(block_size)
        received += len(block)
        f.write(block)
        if status and (file_size > 0):
          while (100 * received / file_size) > progress:
            progress += 1
            if (progress % 20) == 0:
              log.write("%d%%" % progress)
            elif (progress % 2) == 0:
              log.write(".")
            log.flush()

        if not block: break
      f.close()
      socket.close()

      if status and (file_size > 0):
        log.write("]\n")
      else:
        log.write("%d kB\n" % (received / 1024))
      log.flush()

      # Do not overwrite file during the download. If a download temporarily fails we
      # may still have a clean, working (yet older) copy of the file.
      shutil.move(tmpfile, file)

      if (file_size > 0) and (file_size != received):
        return -1

      if remote_mtime > 0:
        # set file timestamp if timestamp information is available
        from stat import ST_ATIME
        st = os.stat(file)
        atime = st[ST_ATIME] # current access time
        os.utime(file,(atime,remote_mtime))

      if cache and socket.info().get('ETag'):
        # If the server sent an ETAG, then keep it alongside the file
        open(tagfile, 'w').write(socket.info().get('ETag'))

    return received

  @staticmethod
  def unzip(archive, directory, trim_directory=0, verbose=False):
    '''unzip a file into a directory.'''
    if verbose:
      print("===== Installing %s into %s" % (archive, directory))
    if not zipfile.is_zipfile(archive):
      raise Exception("%s is not a valid .zip file" % archive)
    z = zipfile.ZipFile(archive, 'r')
    for member in z.infolist():
      is_directory = member.filename.endswith('/')
      filename = os.path.join(*member.filename.split('/')[trim_directory:])
      if filename != '':
        filename = os.path.normpath(filename)
        if '../' in filename:
          raise Exception('Archive %s contains invalid filename %s' % (archive, filename))
        filename = os.path.join(directory, filename)
        upperdirs = os.path.dirname(filename)
        try:
          if is_directory and not os.path.exists(filename):
            os.makedirs(filename)
          elif upperdirs and not os.path.exists(upperdirs):
            os.makedirs(upperdirs)
        except Exception: pass
        if not is_directory:
          source = z.open(member)
          target = open(filename, "wb")
          shutil.copyfileobj(source, target)
          target.close()
          source.close()

          # Preserve executable permission, if set
          unix_executable = member.external_attr >> 16 & 0o111
          # rwxrwxrwx => --x--x--x => 0o111
          if unix_executable:
            mode = os.stat(filename).st_mode
            mode |= (mode & 0o444) >> 2 # copy R bits to X
             # r--r--r-- => 0o444
            os.chmod(filename, mode)
    z.close()

  @staticmethod
  def set_git_repository_config_to_rebase(config):
    with open(config, 'r') as fh:
      cfg = fh.readlines()

    branch, remote, rebase = False, False, False
    insertions = []
    for n, line in enumerate(cfg):
      if line.startswith('['):
        if branch and remote and not rebase:
          insertions.insert(0, (n, branch))
        if line.startswith('[branch'):
          branch = line.split('"')[1]
        else:
          branch = False
        remote, rebase = False, False
      if re.match(r'remote\s*=', line.strip()):
        remote = True
      if re.match(r'rebase\s*=', line.strip()):
        rebase = True
    if branch and remote and not rebase:
      insertions.insert(0, (n + 1, branch))
    for n, branch in insertions:
      print("  setting branch %s to rebase" % branch)
      cfg.insert(n, '\trebase = true\n')
    with open(config, 'w') as fh:
      fh.write("".join(cfg))

  @staticmethod
  def git(module, parameters, destination=None, use_ssh=False, verbose=False, reference=None):
    '''Retrieve a git repository, either by running git directly
       or by downloading and unpacking an archive.'''
    git_available = True
    try:
      subprocess.call(['git', '--version'], stdout=open(os.devnull, 'wb'), stderr=open(os.devnull, 'wb'))
    except OSError:
      git_available = False

    # put molprobity repository at same level as "modules" to reproduce svn behavior
    if module == 'molprobity':
      destination = os.path.join('.', module)

    if destination is None:
      destination = os.path.join('modules', module)
    destpath, destdir = os.path.split(destination)

    # default to using ssh for private phenix repositories
    if module in ['elbow',
                  'ksdssp',
                  'labelit',
                  'muscle',
                  'opt_resources',
                  'phenix',
                  'phenix_pathwalker',
                  'Plex',
                  'PyQuante',
                  'pulchra',
                  'reel',
                  'solve_resolve',
                  ]:
      use_ssh = True

    if os.path.exists(destination):
      if git_available and os.path.exists(os.path.join(destination, '.git')):
        if not open(os.path.join(destination, '.git', 'HEAD'), 'r').read().startswith('ref:'):
          print("WARNING: Can not update existing git repository! You are not on a branch.")
          print("This may be legitimate when run eg. via Jenkins, but be aware that you cannot commit any changes")
          return

        else:
          # This may fail for unclean trees and merge problems. In this case manual
          # user intervention will be required.
          # For the record, you can clean up the tree and *discard ALL changes* with
          #   git reset --hard origin/master
          #   git clean -dffx
          return ShellCommand(
            command=['git', 'pull', '--rebase'], workdir=destination, silent=False, haltOnFailure=True).run()

      print("Existing non-git directory -- don't know what to do. skipping: %s" % module)
      if ('cctbx_project.git' in parameters[0]):
        print('\n' + '=' * 80 + '\nCCTBX moved to git on November 22, 2016.\n\nTo update cctbx_project to the last available subversion revision please run "svn update" while in the cctbx_project directory.\n' + '*'*80 + '\n')
      return
    if isinstance(parameters, str):
      parameters = [ parameters ]
    git_parameters = []
    for source_candidate in parameters:
      if source_candidate.startswith('-'):
        git_parameters = source_candidate.split(' ')
        continue
      if (not source_candidate.lower().startswith('http') and not use_ssh):
        continue
      if source_candidate.lower().endswith('.git'):
        if not git_available:
          continue
        reference_parameters = []
        if reference is not None:
          if os.path.exists(reference) and os.path.exists(os.path.join(reference, '.git')):
            reference_parameters = [ '--reference', reference ]
        cmd = [ 'git', 'clone', '--recursive' ] + git_parameters + [ source_candidate, destdir ] + reference_parameters
        if verbose:
          cmd = cmd + [ '--progress', '--verbose' ]
        returncode = ShellCommand(
          command=cmd, workdir=destpath, silent=False
        ).run()
        if returncode:
          return returncode # no point trying to continue on error
        if reference_parameters:
          # Sever the link between checked out and reference repository
          cmd = [ 'git', 'repack', '-a', '-d' ]
          returncode = ShellCommand(
            command=cmd, workdir=destination, silent=False
          ).run()
          try:
            os.remove(os.path.join(destination, '.git', 'objects', 'info', 'alternates'))
          except OSError:
            returncode = 1
        Toolbox.set_git_repository_config_to_rebase(os.path.join(destination, '.git', 'config'))
        if returncode:
          return returncode # no point trying to continue on error
        # Show the hash for the checked out commit for debugging purposes, ignore any failures.
        ShellCommand(
          command=[ 'git', 'rev-parse', 'HEAD' ], workdir=destination, silent=False
        ).run()
        return returncode
      filename = "%s-%s" % (module,
                            urlparse(source_candidate)[2].split('/')[-1])
      filename = os.path.join(destpath, filename)
      if verbose:
        print("===== Downloading %s: " % source_candidate, end=' ')
      Toolbox.download_to_file(source_candidate, filename)
      Toolbox.unzip(filename, destination, trim_directory=1, verbose=verbose)
      return

    error = "Cannot satisfy git dependency for module %s: None of the sources are available." % module
    if not git_available:
      print(error)
      error = "A git installation has not been found."
    raise Exception(error)

class cleanup_ext_class(object):
  def __init__(self, filename_ext, workdir=None, walk=True):
    self.filename_ext = filename_ext
    self.workdir = workdir
    self.walk = walk

  def get_command(self):
    return "delete *%s in %s" % (self.filename_ext, self.workdir).split()

  def remove_ext_files(self):
    cwd=os.getcwd()
    if self.workdir is not None:
      if os.path.exists(self.workdir):
        os.chdir(self.workdir)
      else:
        return
    print("\n  removing %s files in %s, walk? %s" % (self.filename_ext,
                                                     os.getcwd(),
                                                     self.walk,
      ))
    i=0
    if self.walk:
      for root, dirs, files in os.walk(".", topdown=False):
        for name in files:
          if name.endswith(self.filename_ext):
            os.remove(os.path.join(root, name))
            i+=1
    else:
      for name in os.listdir(os.getcwd()):
        if name.endswith(self.filename_ext):
          os.remove(os.path.join(name))
          i+=1
    os.chdir(cwd)
    print("  removed %d files" % i)

  def run(self):
    self.remove_ext_files()

class cleanup_dirs(object):
  """Command to remove unwanted subdirectories"""

  def __init__(self, dirs, workdir=None):
    """
    :param dirs:    List of subdirectories to remove from workdir
    :param workdir: The root directory for everything in dirs. If None, then
                    the command will be run in the current working directory.
    """
    self.dirs = dirs
    self.workdir = workdir

  def get_command(self):
    return "cleanup dirs in %s" % (self.workdir).split()

  def remove_dirs(self):
    cwd=os.getcwd()
    try:
      # Move to the workdir
      if self.workdir is not None:
        if os.path.exists(self.workdir):
          os.chdir(self.workdir)
        else:
          return

      # Don't notify the user if we aren't doing anything
      if any(os.path.exists(d) for d in self.dirs):
        print("===== Removing directories in %s" % (os.getcwd()))

        for d in self.dirs:
          if os.path.exists(d):
            print("      removing %s" % (os.path.join(os.getcwd(),d)))
            shutil.rmtree(d)
    finally:
      # Leave the directory untouched even if we failed
      os.chdir(cwd)

  def run(self):
    self.remove_dirs()

##### Modules #####
class SourceModule(object):
  _modules = {}
  module = None
  authenticated = None
  authentarfile = None
  anonymous = None
  def __init__(self):
    if not self._modules:
      self.update_subclasses()

  def items(self):
    return list(self._modules.items())

  @classmethod
  def update_subclasses(cls):
    for i in cls.__subclasses__():
      cls._modules[i.module] = i

  def get_module(self, module):
    if module in self._modules:
      return self._modules[module]
    raise KeyError("Unknown module: %s"%module)

  def get_url(self, auth=None):
    repo = None
    try:
      repo = self.get_authenticated(auth=auth)
    except KeyError as e:
      repo = self.get_anonymous()
      if not repo:
        raise Exception('No anonymous access method defined for module: %s. Try with --%s'%(self.module, e.args[0]))
    repo = repo or self.get_anonymous()
    if not repo:
      raise Exception('No access method defined for module: %s'%self.module)
    return repo

  def get_authenticated(self, auth=None):
    auth = auth or {}
    if not self.authenticated:
      return None
    return [self.authenticated[0], self.authenticated[1]%auth]

  def get_tarauthenticated(self, auth=None):
    auth = auth or {}
    if self.authentarfile:
      return [self.authentarfile[0]%auth, self.authentarfile[1], self.authentarfile[2]]
    return None, None, None

  def get_anonymous(self):
    return self.anonymous

# Core external repositories
# The trailing slashes ARE significant.
# These must all provide anonymous access.
# On Windows due to absence of rsync we use pscp from the Putty programs.
class ccp4io_module(SourceModule):
  module = 'ccp4io'
  anonymous = ['git',
               'git@github.com:cctbx/ccp4io.git',
               'https://github.com/cctbx/ccp4io.git',
               'https://github.com/cctbx/ccp4io/archive/master.zip']

class annlib_module(SourceModule):
  module = 'annlib'
  anonymous = ['git',
               'git@github.com:cctbx/annlib.git',
               'https://github.com/cctbx/annlib.git',
               'https://github.com/cctbx/annlib/archive/master.zip']

class scons_module(SourceModule):
  module = 'scons'
  anonymous = ['git', '-b 3.1.1',
               'https://github.com/SCons/scons/archive/3.1.1.zip']

# external modules
class rosetta_class(SourceModule):
  module = 'rosetta'
  authenticated = [
    'rsync',
    '%(cciuser)s@boa.lbl.gov:/net/cci/auto_build/externals/'+rosetta_version_tar_bundle+'/',
  ]
  authenticated = [
    'scp',
    '%(cciuser)s@boa.lbl.gov:/net/cci-filer2/raid1/auto_build/externals/'+rosetta_version_tar_bundle+'.tgz']

class afitt_class(SourceModule):
  module = 'afitt'
  authenticated = [
    'scp',
    '%(cciuser)s@boa.lbl.gov:/net/cci-filer2/raid1/auto_build/externals/'+afitt_version+'.gz']

# Core CCTBX repositories
# These must all provide anonymous access.
class cctbx_module(SourceModule):
  module = 'cctbx_project'
  anonymous = ['git',
               'git@github.com:cctbx/cctbx_project.git',
               'https://github.com/cctbx/cctbx_project.git',
               'https://github.com/cctbx/cctbx_project/archive/master.zip']

class amber_adaptbx_module(SourceModule):
  module = 'amber_adaptbx'
  anonymous = ['git',
               'git@github.com:phenix-project/amber_adaptbx.git',
               'https://github.com/phenix-project/amber_adaptbx.git',
               ]

class amber_library_module(SourceModule):
  module = 'amber_library'
  anonymous = ['git',
               'git@github.com:phenix-project/amber_library.git',
               'https://github.com/phenix-project/amber_library.git',
               ]

class aimnet2calc_module(SourceModule):
  module = 'aimnet2calc'
  anonymous = ['git',
               'git@github.com:zubatyuk/aimnet2calc.git',
               'https://github.com/zubatyuk/aimnet2calc.git',
               ]

class qrefine_module(SourceModule):
  module = 'qrefine'
  anonymous = ['git',
               'git@github.com:qrefine/qrefine.git',
               'https://github.com/qrefine/qrefine.git',
               ]

class pydiscamb_module(SourceModule):
  module = 'pyDiSCaMB'
  anonymous = ['git',
               'git@github.com:viljarjf/pyDiSCaMB.git',
               'https://github.com/viljarjf/pyDiSCaMB.git',
               ]

class molstar_adaptbx(SourceModule):
  module = 'molstar_adaptbx'
  anonymous = ['git',
               'https://github.com/phenix-project/molstar_adaptbx.git']

class molstar_module(SourceModule):
  module = 'molstar'
  anonymous = ['git',
               '-b v4.11.0',
               'https://github.com/molstar/molstar.git']

class mon_lib_module(SourceModule):
  module = 'mon_lib'
  anonymous = ['curl', 'http://boa.lbl.gov/repositories/mon_lib.gz']
  authentarfile = ['%(cciuser)s@boa.lbl.gov', 'mon_lib.tar.gz', '/net/cci/auto_build/repositories/mon_lib']
  #authenticated = ['rsync', '%(cciuser)s@boa.lbl.gov:/net/cci/auto_build/repositories/annlib/']

class geostd_module(SourceModule):
  module = 'geostd'
  anonymous = ['git',
               'git@github.com:phenix-project/geostd.git',
               'https://github.com/phenix-project/geostd.git'
               ]

class boost_module(SourceModule):
  module = 'boost'
  anonymous = ['git',
               'git@github.com:cctbx/boost.git',
               'https://github.com/cctbx/boost.git',
               'https://github.com/cctbx/boost/archive/master.zip']

class cbflib_module(SourceModule):
  module = 'cbflib'
  anonymous = ['git',
               'git@github.com:dials/cbflib.git',
               'https://github.com/dials/cbflib.git',
               'https://github.com/dials/cbflib/archive/main.zip']

class ccp4io_adaptbx(SourceModule):
  module = 'ccp4io_adaptbx'
  anonymous = ['git',
               'git@github.com:cctbx/ccp4io_adaptbx.git',
               'https://github.com/cctbx/ccp4io_adaptbx.git',
               'https://github.com/cctbx/ccp4io_adaptbx/archive/master.zip']

class annlib_adaptbx(SourceModule):
  module = 'annlib_adaptbx'
  anonymous = ['git',
               'git@github.com:cctbx/annlib_adaptbx.git',
               'https://github.com/cctbx/annlib_adaptbx.git',
               'https://github.com/cctbx/annlib_adaptbx/archive/master.zip']

class tntbx_module(SourceModule):
  module = 'tntbx'
  anonymous = ['git',
               'git@github.com:cctbx/tntbx.git',
               'https://github.com/cctbx/tntbx.git',
               'https://github.com/cctbx/tntbx/archive/master.zip']

class clipper_module(SourceModule):
  module = 'clipper'
  anonymous = ['git',
               'git@github.com:cctbx/clipper.git',
               'https://github.com/cctbx/clipper.git',
               'https://github.com/cctbx/clipper/archive/master.zip']

class gui_resources_module(SourceModule):
  module = 'gui_resources'
  anonymous = ['git',
               'git@github.com:cctbx/gui_resources.git',
               'https://github.com/cctbx/gui_resources.git',
               'https://github.com/cctbx/gui_resources/archive/master.zip']

class opt_resources_module(SourceModule):
  module = 'opt_resources'
  authenticated = ['git', 'git@github.com:phenix-project/opt_resources.git']

class eigen_module(SourceModule):
  module = 'eigen'
  anonymous = ['git', '-b 3.4.0',
               'https://gitlab.com/libeigen/eigen.git']

# Phenix repositories
class phenix_module(SourceModule):
  module = 'phenix'
  anonymous = ['git', 'git@github.com:phenix-project/phenix.git']

class phenix_html(SourceModule):
  module = 'phenix_html'
  anonymous = ['git',
               'git@github.com:phenix-project/phenix_html.git',
               'https://github.com/phenix-project/phenix_html.git']

class phenix_dev_doc(SourceModule):
  module = 'phenix_dev_doc'
  anonymous = ['git',
               'git@github.com:phenix-project/phenix_dev_doc.git',
               'https://github.com/phenix-project/phenix_dev_doc.git']

class phenix_examples(SourceModule):
  module = 'phenix_examples'
  anonymous = ['git',
               'git@gitlab.com:phenix_project/phenix_examples.git',
               'https://gitlab.com/phenix_project/phenix_examples.git']

class phenix_regression(SourceModule):
  module = 'phenix_regression'
  anonymous = ['git',
               'git@gitlab.com:phenix_project/phenix_regression.git',
               'https://gitlab.com/phenix_project/phenix_regression.git']

class phenix_colabs(SourceModule):
  module = 'Colabs'
  anonymous = ['git',
               'git@github.com:phenix-project/Colabs.git',
               'https://github.com/phenix-project/Colabs.git']

class plex_module(SourceModule):
  module = 'Plex'
  authenticated = ['git', 'git@github.com:phenix-project/Plex.git']

class pyquante_module(SourceModule):
  module = 'PyQuante'
  authenticated = ['git', 'git@github.com:phenix-project/PyQuante.git']

class chem_data_module(SourceModule):
  module = 'chem_data'
  anonymous = ['git',
               'git@gitlab.com:phenix_project/chem_data.git',
               'https://gitlab.com/phenix_project/chem_data.git']

class elbow_module(SourceModule):
  module = 'elbow'
  authenticated = ['git', 'git@github.com:phenix-project/elbow.git']

class ksdssp_module(SourceModule):
  module = 'ksdssp'
  authenticated = ['git', 'git@github.com:phenix-project/ksdssp.git']

class pulchra_module(SourceModule):
  module = 'pulchra'
  authenticated = ['git', 'git@github.com:phenix-project/pulchra.git']

class solve_resolve_module(SourceModule):
  module = 'solve_resolve'
  anonymous = ['git', 'git@github.com:phenix-project/solve_resolve.git']

class reel_module(SourceModule):
  module = 'reel'
  authenticated = ['git', 'git@github.com:phenix-project/reel.git']

class muscle_module(SourceModule):
  module = 'muscle'
  authenticated = ['git', 'git@github.com:phenix-project/muscle.git']

class cxi_xdr_xes_module(SourceModule):
  module = 'cxi_xdr_xes'
  authenticated = ['svn', 'svn+ssh://%(cciuser)s@boa.lbl.gov/cxi_xdr_xes/trunk']

class buildbot_module(SourceModule):
  module = 'buildbot'
  authenticated = ['git', 'git@github.com:cci-lbl/buildbot.git']

class phenix_pathwalker_module(SourceModule):
  module = 'phenix_pathwalker'
  anonymous = ['git', 'git@github.com:phenix-project/phenix_pathwalker.git']

class alphafold_module(SourceModule):
  module = 'alphafold'
  anonymous = ['git',
               'git@github.com:google-deepmind/alphafold.git',
               'https://github.com/google-deepmind/alphafold.git']

# Phaser repositories
class phaser_module(SourceModule):
  module = 'phaser'
  anonymous = ['git',
               'git@gitlab.developers.cam.ac.uk:scm/haematology/readgroup/phaser.git',
               'https://gitlab.developers.cam.ac.uk/scm/haematology/readgroup/phaser.git']

class phasertng_module(SourceModule):
  module = 'phasertng'
  anonymous = ['git',
               'git@gitlab.developers.cam.ac.uk:scm/haematology/readgroup/phasertng.git',
               'https://gitlab.developers.cam.ac.uk/scm/haematology/readgroup/phasertng.git']

class phaser_voyager_module(SourceModule):
  module = 'phaser_voyager'
  anonymous = ['git',
               'git@gitlab.developers.cam.ac.uk:scm/haematology/readgroup/phaser_voyager.git',
               'https://gitlab.developers.cam.ac.uk/scm/haematology/readgroup/phaser_voyager.git']

class phaser_regression_module(SourceModule):
  module = 'phaser_regression'
  anonymous = ['git',
               'git@gitlab.developers.cam.ac.uk:scm/haematology/readgroup/phaser_regression.git',
               'https://gitlab.developers.cam.ac.uk/scm/haematology/readgroup/phaser_regression.git']

class voyager_regression_module(SourceModule):
  module = 'voyager_regression'
  anonymous = ['git',
               'git@gitlab.developers.cam.ac.uk:scm/haematology/readgroup/voyager_regression.git',
               'https://gitlab.developers.cam.ac.uk/scm/haematology/readgroup/voyager_regression.git']

# DIALS repositories
class labelit_module(SourceModule):
  module = 'labelit'
  anonymous = ['git', 'git@github.com:phenix-project/labelit.git']

class labelit_regression_module(SourceModule):
  module = 'labelit_regression'
  anonymous = ['git',
               'git@gitlab.com:phenix_project/labelit_regression.git',
               'https://gitlab.com/phenix_project/labelit_regression.git']

class dials_module(SourceModule):
  module = 'dials'
  anonymous = ['git',
               'git@github.com:dials/dials.git',
               'https://github.com/dials/dials.git',
               'https://github.com/dials/dials/archive/main.zip']

class dxtbx_module(SourceModule):
  module = 'dxtbx'
  anonymous = ['git',
               'git@github.com:cctbx/dxtbx.git',
               'https://github.com/cctbx/dxtbx.git',
               'https://github.com/cctbx/dxtbx/archive/main.zip']

class dials_regression_module(SourceModule):
  module = 'dials_regression'
  authenticated = ['svn',
                   'svn+ssh://%(cciuser)s@boa.lbl.gov/dials_regression/trunk']

class iota_module(SourceModule):
  module = 'iota'
  anonymous = ['git',
               'git@github.com:ssrl-px/iota.git',
               'https://github.com/ssrl-px/iota.git',
               'https://github.com/ssrl-px/iota/archive/master.zip']

class msgpack_module(SourceModule):
  module = 'msgpack'
  anonymous = ['curl', [
    "https://github.com/dials/dependencies/raw/dials-1.13/msgpack-3.1.1.tar.gz",
  ]]

class xfel_regression_module(SourceModule):
  module = 'xfel_regression'
  authenticated = ['git',
                   'git@gitlab.com:cctbx/xfel_regression.git',
                   'https://gitlab.com/cctbx/xfel_regression.git']

class xia2_module(SourceModule):
  module = 'xia2'
  anonymous = ['git',
               'git@github.com:xia2/xia2.git',
               'https://github.com/xia2/xia2.git',
               'https://github.com/xia2/xia2/archive/main.zip']

class kokkos_module(SourceModule):
  module = 'kokkos'
  anonymous = ['git', '-b 4.2.00',
               'git@github.com:kokkos/kokkos.git',
               'https://github.com/kokkos/kokkos.git',
               'https://github.com/kokkos/kokkos/archive/refs/tags/4.2.00.zip']

class kokkos_kernels_module(SourceModule):
  module = 'kokkos-kernels'
  anonymous = ['git', '-b 4.2.00',
               'git@github.com:kokkos/kokkos-kernels.git',
               'https://github.com/kokkos/kokkos-kernels.git',
               'https://github.com/kokkos/kokkos-kernels/archive/refs/tags/4.2.00.zip']

# Duke repositories
class probe_module(SourceModule):
  module = 'probe'
  anonymous = ['git', 'https://github.com/rlabduke/probe.git']

class reduce_module(SourceModule):
  # Version 4.14 or later should be used to avoid mmtbx_reduce_ext name conflict.
  module = 'reduce'
  anonymous = ['git', 'https://github.com/rlabduke/reduce.git']

class king_module(SourceModule):
  module = 'king'
  anonymous = ['git',
               'https://github.com/rlabduke/phenix_king_binaries.git']

class molprobity_module(SourceModule):
  module = 'molprobity'
  anonymous = ['git', 'https://github.com/rlabduke/MolProbity.git']

class uc_metrics_module(SourceModule):
  module = 'uc_metrics'
  anonymous = ['git',
               'git@gitlab.com:cctbx/uc_metrics.git',
               'https://gitlab.com/cctbx/uc_metrics.git']

class ncdist_module(SourceModule):
  module = 'ncdist'
  anonymous = ['git',
               'git@github.com:yayahjb/ncdist.git',
               'https://github.com/yayahjb/ncdist.git',
               'https://github.com/yayahjb/ncdist/archive/master.zip']

MODULES = SourceModule()

###################################
##### Base Configuration      #####
###################################

class Builder(object):
  """Create buildbot configurations for CCI and CCTBX-like software."""
  # Base packages
  BASE_PACKAGES = 'all'
  # Checkout these codebases
  CODEBASES = ['cctbx_project']
  CODEBASES_EXTRA = []
  # Copy these sources from cci.lbl.gov
  HOT = []
  HOT_EXTRA = []
  # Configure for these cctbx packages
  LIBTBX = ['cctbx']
  LIBTBX_EXTRA = []

  def __init__(
      self,
      category=None,
      subcategory=None,
      platform=None,
      sep=None,
      python_base=None,
      cleanup=False,
      hot=True,
      update=True,
      revert=None,
      base=True,
      build=True,
      tests=True,
      doc=True,
      distribute=False,
      auth=None,
      with_python=None,
      nproc=1,
      verbose=False,
      download_only=False,
      skip_base="",
      force_base_build=False,
      enable_shared=False,
      mpi_build=False,
      python3=False,
      wxpython4=False,
      config_flags=[],
      use_conda=None,
      python='27',
      no_boost_src=False,
    ):
    if nproc is None:
      self.nproc=1
    else:
      self.nproc=nproc
    """Create and add all the steps."""
    # self.cciuser = cciuser or getpass.getuser()
    self.set_auth(auth)
    self.steps = []
    self.category = category
    self.subcategory = subcategory
    if self.subcategory: self.EXTERNAL_CODEBASES = [self.subcategory]
    self.platform = platform
    if self.isPlatformWindows():
      self.op = ntpath
    else:
      self.op = os.path
    self.name = '%s-%s'%(self.category, self.platform)
    # Platform configuration.
    python_executable = 'python'
    self.python3 = python.startswith('3')
    if python3:
      python_executable = 'python3'
    self.wxpython4 = wxpython4
    if self.platform and ('windows' in self.platform or self.platform == 'win32'):
      python_executable = python_executable + '.exe'
    if self.platform and 'windows' in self.platform:
      self.python_base = self.opjoin(*['..', 'base', 'bin', 'python', python_executable])
    elif sys.platform == "win32": # assuming we run standalone without buildbot
      self.python_base = self.opjoin(*[os.getcwd(), 'base', 'bin', 'python', python_executable])
    else:
      self.python_base = self.opjoin(*['..', 'base', 'bin', python_executable])
    self.with_python = with_python
    if self.with_python:
      self.python_base = with_python
    self.verbose = verbose
    self.download_only = download_only
    self.skip_base = skip_base
    self.force_base_build = force_base_build
    # self.config_flags are only from the command line
    # get_libtbx_configure can still be used to always set flags specific to a
    # builder
    self.config_flags = config_flags
    self.use_conda = use_conda
    self.python = python
    self.no_boost_src = no_boost_src
    self.add_init()

    # Cleanup
    if cleanup:
      self.cleanup(['dist', 'tests', 'doc', 'tmp', 'base', 'base_tmp', _BUILD_DIR,
                    'conda_base'])
    else:
      self.cleanup(['dist', 'tests', 'tmp'])

    if self.platform and 'windows' in self.platform: # only executed by buildbot master
      from buildbot.steps.transfer import FileDownload
      # download us to folder above modules on slave so we can run the utility functions defined above
      self.add_step(FileDownload(mastersrc="bootstrap.py", slavedest="../bootstrap.py"))

    # Add 'hot' sources
    if hot:
      # conda builds do not need eigen (disabled), scons
      hot = self.get_hot()
      if self.use_conda is not None:
        for module in ['scons']:
          # SCons conda package may cause issues with procrunner on Python 2.7
          # https://stackoverflow.com/questions/24453387/scons-attributeerror-builtin-function-or-method-object-has-no-attribute-disp
          if module == 'scons' and self.python == '27':
            continue
          try:
            hot.remove(module)
          except ValueError:
            pass
      list(map(self.add_module, hot))

    # Add svn sources.
    self.revert=revert
    if update:
      # check if boost needs to be downloaded
      codebases = self.get_codebases()
      if self.no_boost_src:
        try:
          codebases.remove('boost')
        except ValueError:
          pass
      list(map(self.add_module, codebases))

    # always remove .pyc files
    self.remove_pyc()

    # Build base packages
    if base:
      extra_opts = ["--nproc=%s" % str(self.nproc)]
      if enable_shared:
        extra_opts.append("--python-shared")
      if mpi_build:
        extra_opts.append("--mpi-build")
      self.add_base(extra_opts=extra_opts)

    # Configure, make, get revision numbers
    if build and not self.download_only:
      self.add_configure()
      self.add_make()
      self.add_install()

    # Tests, tests
    if tests and not self.download_only:
      self.add_tests()

    # docs
    if doc:
      self.rebuild_docs()

    # Distribute
    if distribute and not self.download_only:
      self.add_distribute()

    # Distribute does this but uses correct PHENIX_VERSION
    if build and not self.download_only:
      self.add_dispatchers()
      self.add_refresh()

    if self.platform and 'windows' in self.platform: # only executed by buildbot master
      self.add_rm_bootstrap_on_slave()

  def isPlatformWindows(self):
    if self.platform and 'windows' in self.platform:
        return True
    else:
      if self.platform == "dev" and sys.platform == "win32":
        return True
    return False

  def isPlatformLinux(self):
    if self.platform and 'linux' in self.platform:
        return True
    else:
      if self.platform == "dev" and sys.platform.startswith("linux"):
        return True
    return False

  def isPlatformMacOSX(self):
    if self.platform and 'mac' in self.platform:
        return True
    else:
      if self.platform == "dev" and sys.platform.startswith("darwin"):
        return True
    return False

  def add_auth(self, account, username):
    self.auth[account] = username

  def set_auth(self, auth):
    self.auth = auth or {}

  def get_auth(self):
    return self.auth

  def remove_pyc(self):
    self.add_step(cleanup_ext_class(".pyc", "modules"))

  def shell(self, **kwargs):
    # Convenience for ShellCommand
    kwargs['haltOnFailure'] = kwargs.pop('haltOnFailure', True)
    kwargs['description'] = kwargs.get('description') or kwargs.get('name')
    kwargs['timeout'] = 60*60*2 # 2 hours
    if 'workdir' in kwargs:
      kwargs['workdir'] = self.opjoin(*kwargs['workdir'])
    return ShellCommand(**kwargs)

  def run(self):
    for i in self.steps:
      i.run()

  def opjoin(self, *args):
    return self.op.join(*args)

  def get_codebases(self):
    if self.isPlatformWindows():
      rc = set(self.CODEBASES+self.CODEBASES_EXTRA)
      for r in windows_remove_list: rc = rc - set([r])
      return list(rc)
    rc = self.CODEBASES + self.CODEBASES_EXTRA
    if hasattr(self, "EXTERNAL_CODEBASES"):
      rc = self.EXTERNAL_CODEBASES + rc
    return rc

  def get_hot(self):
    return self.HOT + self.HOT_EXTRA

  def get_libtbx_configure(self): # modified in derived class PhenixBuilder
    return self.LIBTBX + self.LIBTBX_EXTRA

  def add_init(self):
    pass

  def cleanup(self, dirs=None):
    dirs = dirs or []
    if self.isPlatformWindows():
      # Delete folders by copying an empty folder with ROBOCOPY is more reliable on Windows
      # If ROBOCOPY fails i.e. ERRORLEVEL>0 then bail to stop bootstrap. Start cmd.exe with
      cmd = ['cmd', '/C', 'mkdir', 'empty', '&',
         '(FOR', '%b', 'IN', '('] + dirs + [')', 'DO',
              '((ROBOCOPY', 'empty', '%b', '/MIR', '/COPYALL', '>', 'nul)',
                 '&', 'rmdir', '/S', '/Q', '%b\\', # remove directory after robocopy
                 '&', '@IF', 'EXIST', '%b\\', # backslash indicates it's a directory and not a file
                         '(echo.', '&', 'echo', 'Error', 'deleting', '%b',
                          '&', 'echo.', '&', 'exit', '/B', '42', ')))',
          '&', 'rmdir', 'empty'
       ]
      self.add_step(self.shell(
        name='Removing directories ' + ', '.join(dirs),
        command =cmd,
        workdir=['.'],
        description="deleting " + ", ".join(dirs),
      ))
    else:
      self.add_step(cleanup_dirs(dirs, "modules"))

  def add_rm_bootstrap_on_slave(self):
    # if file is not found error flag is set. Mask it with cmd shell
    cmd=['cmd', '/c', 'del', '/Q', "bootstrap.py*", '&', 'set', 'ERRORLEVEL=0']
    self.add_step(self.shell(
      name='removing bootstrap utilities',
      command =cmd,
      workdir=['.'],
      description="remove temporary bootstrap.py*",
    ))

  def add_step(self, step):
    """Add a step."""
    self.steps.append(step)
    if 0:
      print("commands "*8)
      for step in self.steps:
        print(step)
        #try:    print " ".join(step.get_command())
        #except: print '????'
      print("commands "*8)

  def add_module(self, module, workdir=None, module_directory=None):
    action = MODULES.get_module(module)().get_url(auth=self.get_auth())
    method, parameters = action[0], action[1:]
    if len(parameters) == 1: parameters = parameters[0]
    tarurl, arxname, dirpath = None, None, None
    if self.isPlatformWindows() and (method == "authenticated" or method == "rsync"):
      tarurl, arxname, dirpath = MODULES.get_module(module)().get_tarauthenticated(auth=self.get_auth())
    if self.isPlatformWindows():
      if module in windows_remove_list:
        return
    if method == 'rsync' and not self.isPlatformWindows():
      self._add_rsync(module,
                      parameters, # really the url
                      workdir=workdir,
                      module_directory=module_directory)
    elif self.isPlatformWindows() and tarurl:
      # if more bootstraps are running avoid potential race condition on
      # remote server by using unique random filenames
      randarxname = next(tempfile._get_candidate_names()) + "_" + arxname
      self._add_remote_make_tar(module, tarurl, randarxname, dirpath)
      self._add_scp(module, tarurl + ':' + randarxname)
      self._add_remote_rm_tar(module, tarurl, randarxname)
    elif method == 'scp':
      self._add_scp(module, parameters)
    elif method == 'curl':
      self._add_curl(module, parameters)
    elif method == 'svn':
      self._add_svn(module, parameters)
    elif method == 'git':
      self._add_git(module, parameters)
    else:
      raise Exception('Unknown access method: %s %s'%(method, str(parameters)))

  def _add_rsync(self, module, url, workdir=None, module_directory=None):
    """Add packages not in source control."""
    # rsync the hot packages.
    if not workdir: workdir=["modules"]
    if not module_directory: module_directory=module
    self.add_step(self.shell(
      name='hot %s'%module,
      command=[
        'rsync',
        '-rptgoDLK', #'-aL',
        '--delete',
        url,
        module_directory,
      ],
      workdir=workdir,
    ))

  def _add_remote_make_tar(self, module, tarurl, arxname, dirpath):
    """Windows: tar up hot packages for quick file transfer since there's no rsync and pscp is painfully slow"""
    if dirpath[-1] == '/':
      dirpath = dirpath[:-1]
    basename = posixpath.basename(dirpath)
    cmd=[
        'ssh',
        tarurl,
        '"' + 'cd',
        posixpath.split(dirpath)[0],
        '&&',
        'tar',
        'cfzh',
        '~/' + arxname,
        basename + '"'
      ]
    mstr= " ".join(cmd)
    self.add_step(self.shell( # pack directory with tar on remote system
      name='hot %s'%module,
      command=mstr,
      workdir=['modules'],
      description="create remote temporary archive %s:%s" %(tarurl, arxname),
    ))

  def _add_remote_rm_tar(self, module, tarurl, arxname):
    """Windows: Delete tar file on remote system, unpack tar file locally, then delete tar file locally"""
    self.add_step(self.shell( # delete the tarfile on remote system
      name='hot %s'%module,
      command=[
        'ssh',
        tarurl,
        'rm ',
        arxname
      ],
      workdir=['modules'],
      description="delete remote temporary archive of %s" %module,
    ))
    self.add_step(self.shell(command=[
      sys.executable,"-c","import sys; sys.path.append('..'); import bootstrap; \
      bootstrap.tar_extract('','%s', '%s')" %(arxname, module) ],
      workdir=['modules'],
      description="extracting archive files to %s" %module,
    ))
    self.add_step(self.shell( # delete the tarfile locally
      # use 'cmd', '/c' as a substitute for shell=True in the subprocess.Popen call
      command=['cmd', '/c', 'del', arxname],
      workdir=['modules'],
      description="delete local temporary archive of %s" %module,
    ))

  def _add_scp(self, module, url):
    self.add_step(self.shell(
      name='hot %s'%module,
      command=[
        'scp',
        '-r',
        url,
        '.',
      ],
      workdir=['modules'],
      description="getting remote file %s" %url.split("/")[-1],
    ))

  def _add_download(self, url, to_file):
    if not isinstance(url, list):
      url = [url]
    class _download(object):
      def run(self):
        for _url in url:
          for retry in (3,3,0):
            print("===== Downloading %s: " % _url, end=' ')
            try:
              Toolbox().download_to_file(_url, to_file)
              return
            except Exception as e:
              print("Download failed with", e)
              if retry:
                print("Retrying in %d seconds" % retry)
                time.sleep(retry)
        raise RuntimeError("Could not download " + to_file)
    self.add_step(_download())

  def _add_curl(self, module, url):
    if isinstance(url, list):
      filename = urlparse(url[0])[2].split('/')[-1]
    else:
      filename = urlparse(url)[2].split('/')[-1]
    # Google Drive URL does not contain the module name
    if filename == 'uc':
      filename = module + '.gz'
    self._add_download(url, os.path.join('modules', filename))
    self.add_step(self.shell(
      name="extracting files from %s" %filename,
      command=[
       sys.executable,"-c","import sys; sys.path.append('..'); import bootstrap; \
       bootstrap.tar_extract('','%s')" %filename],
      workdir=['modules'],
      description="extracting files from %s" %filename,
    ))

  def _add_unzip(self, archive, directory, trim_directory=0):
    class _indirection(object):
      def run(self):
        print("===== Installing %s into %s" % (archive, directory))
        Toolbox().unzip(archive, directory, trim_directory)
    self.add_step(_indirection())

  def _add_svn(self, module, url):
    update_list = ['update']
    if module in ["reduce", "probe", "king"]:
      pass
    elif self.revert:
      update_list = ['update', '-r', self.revert]
    thisworkdir = 'modules'
    if module == 'molprobity' : thisworkdir = '.'
    # avoid stalling bootstrap with prompts
    # or when encountering unknown server certificates
    svnflags = ['--non-interactive', '--trust-server-cert']
    if module == 'chem_data':  # stop pulling geostd from SourceForge
      svnflags.append('--ignore-externals')
    if os.path.exists(self.opjoin(*[thisworkdir, module, '.svn'])):
      self.add_step(self.shell(
          command=['svn'] + update_list +[module] + svnflags,
          workdir=[thisworkdir]
      ))
      self.add_step(self.shell(
          command=['svn', 'status', module] + svnflags,
          workdir=[thisworkdir],
          quiet=True,
      ))
    elif os.path.exists(self.opjoin(*[thisworkdir, module])):
      print("Existing non-svn directory -- don't know what to do. skipping: %s"%module)
    else:
      # print "fresh checkout..."
      self.add_step(self.shell(
          command=['svn', 'co', url, module] + svnflags,
          workdir=[thisworkdir]
      ))
    # replace geostd (replace this once chem_data is moved)
    if module == 'chem_data':
      if not os.path.exists(self.opjoin(thisworkdir, module)) \
        or os.path.exists(self.opjoin(thisworkdir, module, 'geostd', '.svn')):
          self.add_step(cleanup_dirs(['geostd'], self.opjoin(thisworkdir, module)))
      action = MODULES.get_module('geostd')().get_url(auth=self.get_auth())
      method, parameters = action[0], action[1:]
      self._add_git('geostd', parameters, destination=self.opjoin(thisworkdir, 'chem_data', 'geostd'))

  def _add_git(self, module, parameters, destination=None):
    use_git_ssh = self.auth.get('git_ssh', False)
    reference_repository_path = self.auth.get('git_reference', None)
    if reference_repository_path is None:
      if os.name == 'posix' and 'diamond.ac.uk' in pysocket.gethostname():
        reference_repository_path = '/dls/science/groups/scisoft/DIALS/repositories/git-reference'
    if reference_repository_path:
      reference_repository_path = os.path.expanduser(os.path.join(reference_repository_path, module))
    class _indirection(object):
      def run(self):
        Toolbox().git(module, parameters, destination=destination,
            use_ssh=use_git_ssh, verbose=True, reference=reference_repository_path)
    self.add_step(_indirection())

    # Update version information
    if module == 'cctbx_project':
      workdir = ['modules', module]
      self.add_step(self.shell(command=[sys.executable, os.path.join('libtbx', 'version.py')], workdir=workdir))

    # add geostd to chem_data
    if module == 'chem_data':
      action = MODULES.get_module('geostd')().get_url(auth=self.get_auth())
      method, geostd_parameters = action[0], action[1:]
      self._add_git('geostd', geostd_parameters, destination=self.opjoin('modules', 'chem_data', 'geostd'))

    # Use dials-2.2 branches for Python 2
    if (module == 'dials' or module == 'dxtbx' or module == 'xia2') and not self.python3:
      workdir = ['modules', module]
      if module == 'dxtbx':
        self.add_step(self.shell(command=['git', 'remote', 'set-url', 'origin', 'https://github.com/dials/dxtbx.git'], workdir=workdir))
        self.add_step(self.shell(command=['git', 'fetch', 'origin'], workdir=workdir))
      self.add_step(self.shell(command=['git', 'checkout', 'dials-2.2'], workdir=workdir))
      self.add_step(self.shell(
        command=['git', 'branch', '--set-upstream-to=origin/dials-2.2', 'dials-2.2'],
        workdir=workdir))

  def _check_for_Windows_prerequisites(self):
    if self.isPlatformWindows():
      # platform specific checks cannot run on buildbot master so add to build steps to run on slaves
      self.add_step(self.shell(command=[
         sys.executable,"-c","import sys; sys.path.append('..'); import bootstrap; \
          bootstrap.CheckWindowsPrerequisites()"],
        workdir=['modules'],
        description="Checking Windows prerequisites",
      ))

  def _get_conda_manager(self):
    """
    Helper function for determining the location of the conda environment
    """
    if __package__ is None:
      root_path = os.path.dirname(os.path.abspath(__file__))
      paths = [root_path,
               os.path.join(root_path, 'modules', 'cctbx_project', 'libtbx',
                            'auto_build')]
      for path in paths:
        if os.path.isfile(os.path.join(path, 'install_conda.py')):
          if path not in sys.path:
            sys.path.append(path)
            break
      from install_conda import conda_manager
    else:
      from .install_conda import conda_manager

    # drop output
    log = open(os.devnull, 'w')

    # environment is provided, so do check that it exists
    if self.use_conda is not None and os.path.isdir(self.use_conda):
      check_file = True
      self.use_conda = os.path.abspath(self.use_conda)
    # no path provided or file provided
    else:
      check_file = False
      # base step has not run yet, so do not check if files exist
      self.use_conda = os.path.join('..', 'conda_base')
      if self.isPlatformWindows():
        self.use_conda = os.path.join(os.getcwd(), 'conda_base')
    # basic checks for python and conda
    m = conda_manager(root_dir=os.getcwd(), conda_env=self.use_conda,
                      check_file=check_file, log=log)

    return m

  def _get_conda_python(self):
    """
    Helper function for determining the location of Python for the base
    and build actions.
    """
    try:
      m = self._get_conda_manager()
      return m.get_conda_python()
    except ImportError:  # modules directory is not available

      # -----------------------------------------------------------------------
      # duplicate logic from get_conda_python function in install_conda.py
      # since install_conda.py may not be available
      def m_get_conda_python(self):
        m_conda_python = os.path.join('bin', 'python')
        if self.isPlatformWindows():
          m_conda_python = self.op.join('python.exe')
        elif self.isPlatformMacOSX():
          m_conda_python = os.path.join('python.app', 'Contents',
                                        'MacOS', 'python')
        return m_conda_python
      # -----------------------------------------------------------------------

      conda_python = None

      # (case 1)
      # use default location or file provided to --use-conda
      if self.use_conda == '' or os.path.isfile(self.use_conda):
        conda_python = self.op.join('..', 'conda_base',
                                    m_get_conda_python(self))
        if self.isPlatformWindows():
          conda_python = self.op.join(os.getcwd(), 'conda_base', m_get_conda_python(self))
      # (case 2)
      # use path provided to --use-conda
      elif os.path.isdir(self.use_conda):
        self.use_conda = os.path.abspath(self.use_conda)
        conda_python = os.path.join(self.use_conda, m_get_conda_python(self))
      else:
        raise RuntimeError("""
The --use-conda flag can accept a directory to a conda environment or a
file that defines a conda environment. Please make sure a valid conda
environment exists in or is defined by {conda_env}.
""".format(conda_env=self.use_conda))

      if conda_python is None:
        raise RuntimeError('A conda version of python could not be found.')

    return conda_python

  def add_command(self, command, name=None, workdir=None, args=None, **kwargs):
    if self.isPlatformWindows():
      command = command + '.bat'
    # Relative path to workdir.
    workdir = workdir or [_BUILD_DIR]
    dots = [".."]*len(workdir)
    if workdir[0] == '.':
      dots = []
    if sys.platform == "win32": # assuming we run standalone without buildbot
      dots.extend([os.getcwd(), _BUILD_DIR, 'bin', command])
    else:
      dots.extend([_BUILD_DIR, 'bin', command])
    self.add_step(self.shell(
      name=name or command,
      command=[self.opjoin(*dots)] + (args or []),
      workdir=workdir,
      **kwargs
    ))

  def add_test_command(self,
                       command,
                       name=None,
                       workdir=None,
                       args=None,
                       haltOnFailure=False,
                       **kwargs
                       ):
    if name is None: name='test %s'%command
    self.add_command(
      command,
      name=name,
      workdir=(workdir or ['tests', command]),
      args=args,
      haltOnFailure=haltOnFailure,
      **kwargs
    )

  def add_test_parallel(self, module=None, nproc=None, slow_tests=False, **kwargs):
    if nproc is None:
      nprocstr = 'nproc=auto'
    else:
      nprocstr = 'nproc=%d'%nproc
    args=['module=%s'%module, nprocstr, 'verbosity=1']
    if slow_tests:
      args.append('slow_tests=True')
    self.add_command(
      'libtbx.run_tests_parallel',
      name='test %s'%module,
      workdir=['tests', module],
      args=args,
      haltOnFailure=False,
      **kwargs
    )

  def add_refresh(self):
    self.add_command(
      'libtbx.refresh',
      name='libtbx.refresh',
      workdir=['.'],
    )

  # Override these methods.
  def add_base(self, extra_opts=[]):
    """Build the base dependencies, e.g. Python, HDF5, etc."""
    if self.with_python:
      extra_opts = ['--with-python', self.with_python]
    if self.verbose:
      extra_opts.append('-v')
    if self.download_only:
      extra_opts.append('--download-only')
    if self.auth.get('git_ssh',False):
      extra_opts.append('--git-ssh')
    if self.skip_base:
      extra_opts.append('--skip-base=%s' % self.skip_base)
    if self.python3:
      extra_opts.append('--python3')
    if self.wxpython4:
      extra_opts.append('--wxpython4')
    if not self.force_base_build:
      if "--skip-if-exists" not in extra_opts:
        extra_opts.append("--skip-if-exists")
    command=[
      sys.executable,
      self.opjoin('modules', 'cctbx_project', 'libtbx', 'auto_build', 'install_base_packages.py'),
      '--python-shared',
      '--%s'%self.BASE_PACKAGES
    ] + extra_opts

    # Override base with conda
    #
    # The use of conda is focused on 2 main groups
    #   1) Developers who do not actively use conda
    #      A basic conda installation will be created at the same level as the
    #      "modules" and "build" directories. The default environment for the
    #      builder will be created in the "conda_base" directory at the same
    #      level.
    #   2) Developers who do
    #      A path to a conda environment should be provided. No checks are done
    #      on the environment. The environment files for the build should be
    #      used to construct the starting environment and the developer is
    #      responsible for maintaining it.
    if self.use_conda is not None:  # --use-conda flag is set
      # reset command
      command = []

      # file or no path provided (case 1), case 2 handled in _get_conda_python
      if self.use_conda == '' or os.path.isfile(self.use_conda):
        flags = ['--builder={builder}'.format(builder=self.category)]
        # check if a file was an argument
        if os.path.isfile(self.use_conda):
          filename = os.path.abspath(self.use_conda)
          flags.append('--install_env={filename}'.format(filename=filename))
        # check for existing miniconda3 installation
        if not os.path.isdir('mc3'):
          flags.append('--install_conda')
        flags.append('--python={python}'.format(python=self.python))
        command = [
          sys.executable,
          self.opjoin('modules', 'cctbx_project', 'libtbx', 'auto_build',
                      'install_conda.py',)] + flags

    if len(command) > 0:
      print("Installing base packages using:\n  " + " ".join(command))
      self.add_step(self.shell(name='base', command=command, workdir=['.']))

  def add_dispatchers(self, product_name="phenix"):
    """Write dispatcher_include file."""
    """Generating Phenix environment additions for dispatchers..."""
    envcmd = "export"
    dispatcher = os.path.join("build",
                              "dispatcher_include_%s.sh" %
                              product_name)
    if self.isPlatformWindows():
      envcmd = "set"
      dispatcher = os.path.join("build",
                                "dispatcher_include_%s.bat" %
                                product_name)
    if (os.path.isfile(dispatcher)): os.remove(dispatcher)
    env_prefix = product_name.upper() # e.g. "Phenix" -> "PHENIX"
    prologue = "\n".join([
      "%s %s=\"%s\"" % (envcmd, env_prefix, os.getcwd()),
      "%s %s_VERSION=%s" % (envcmd, env_prefix, "dev-svn"),
      "%s %s_ENVIRONMENT=1" % (envcmd, env_prefix),
      #"%s %s_MTYPE=%s" % (envcmd, env_prefix, "none"),
    ] #+ self.product_specific_dispatcher_prologue())
                           )
    #epilogue = "\n".join(self.product_specific_dispatcher_epilogue())
    dispatcher_opts = [
      "--build_dir=%s" % ".",
      "--suffix=%s"    % "phenix",
    ]
    if self.use_conda is None:
      dispatcher_opts += [
        "--base_dir=%s"  % "../base",
        "--gtk_version=2.10.0", # XXX this can change!
        #"--quiet",
      ]
    else:
      # default
      base_dir = self.op.join('..', 'conda_base')
      # use path from --use-conda flag
      # error-checking done in _get_conda_python function
      if os.path.isdir(self.use_conda):
        base_dir = self.use_conda

      dispatcher_opts += [
      "--base_dir=%s" % base_dir,
      "--use_conda",
      "--ignore_missing_dirs"
      ]
    #if (not self.flag_build_gui):
    #  dispatcher_opts.append("--ignore_missing_dirs")
    # FIXME this will happen regardless of whether the GUI modules are being
    # distributed or not - will this be problematic?
    self.add_step(self.shell(
      name='gui dispatcher',
      command=[
        self.python_base, #'python',
        self.opjoin("..",
                    'modules',
                    'cctbx_project',
                    'libtbx',
                    'auto_build',
                    'write_gui_dispatcher_include.py'),
        '--prologue=%s' % prologue,
        #"--epilogue=%s"
      ] + dispatcher_opts,
      workdir=[_BUILD_DIR]
    ))

  def add_configure(self):

    env = None

    if self.use_conda is not None:
      if '--use_conda' not in self.config_flags:
        self.config_flags.append('--use_conda')
      self.python_base = self._get_conda_python()
      # conda python prefers no environment customizations
      # the get_environment function in ShellCommand updates the environment
      if os.environ.get('CCTBX_CONDA_USE_ENVIRONMENT_VARIABLES', None):
        env = {
          'PYTHONPATH': None,
          'LD_LIBRARY_PATH': None,
          'DYLD_LIBRARY_PATH': None,
          'DYLD_FALLBACK_LIBRARY_PATH': None
        }

    configcmd =[
        self.python_base, # default to using our python rather than system python
        self.opjoin('..', 'modules', 'cctbx_project', 'libtbx', 'configure.py')
        ] + self.get_libtbx_configure() + self.config_flags
    self.add_step(self.shell(command=configcmd, workdir=[_BUILD_DIR],
      description="run configure.py", env=env))
    # Prepare saving configure.py command to file should user want to manually recompile Phenix
    fname = self.opjoin("config_modules.cmd")
    ldlibpath = ''
    if self.isPlatformLinux() and self.use_conda is None:
      ldlibpath = 'export LD_LIBRARY_PATH=../base/lib\n'
      # because that was the environment when python and base components were built during bootstrap
    confstr = ldlibpath + subprocess.list2cmdline(configcmd)
    if not self.isPlatformWindows():
      fname = self.opjoin("config_modules.sh")
      confstr = '#!/bin/sh\n\n' + confstr
    # klonky way of writing file later on, but it works
    self.add_step(self.shell(command=[
         sys.executable,'-c','open(r\"%s\",\"w\").write(r\"\"\"%s\"\"\" + \"\\n\")' %(fname, confstr)
         ],
      workdir=[_BUILD_DIR],
      description="save configure command",
    ))
    if not self.isPlatformWindows():
      self.add_step(self.shell(command=[ 'chmod', '+x', fname ],
        workdir=[_BUILD_DIR],
        description="permit execution of config_modules.sh",
      ))

    # write extra setpaths script for conda
    if self.use_conda is not None:
      self.add_command('libtbx.install_conda', args=['--write_setpaths'],
                       description='Writing additional setup scripts for conda.')

  def add_make(self):
    self.add_command('libtbx.scons', args=['-j',
                                           str(self.nproc),
#                                          #"--skip-version", # for Phaser
                                           ])
    # run build again to make sure everything is built
    self.add_command('libtbx.scons', args=['-j',
                                           str(self.nproc),
#                                          #"--skip-version", # for Phaser
                                           ])

  def add_install(self):
    """Run after compile, before tests."""
    if os.getenv('CCTBX_SKIP_CHEMDATA_CACHE_REBUILD') is None:
      self.add_command('mmtbx.rebuild_rotarama_cache',
                      name="rebuild rotarama",
      )
      self.add_command('mmtbx.rebuild_cablam_cache',
                      name="rebuild cablam",
      )

  def add_tests(self):
    """Run the unit tests."""
    pass

  def rebuild_docs(self):
    self.add_command('phenix_html.rebuild_docs')

  def add_distribute(self):
    pass

##### Specific Configurations ######

class CCIBuilder(Builder):
  """Base class for packages that include CCTBX as a dependency."""
  # Base packages
  BASE_PACKAGES = 'all'
  # Checkout these codebases
  CODEBASES = [
    'boost',
    'cbflib',
    'cctbx_project',
    'dxtbx',
    'gui_resources',
    'ccp4io',
    'ccp4io_adaptbx',
    'annlib',
    'annlib_adaptbx',
    'tntbx',
    'clipper',
    'eigen',
    'reduce',
    'ksdssp',
  ]
  CODEBASES_EXTRA = []
  # Copy these sources from cci.lbl.gov
  HOT = [
    'scons',
  ]
  HOT_EXTRA = []
  # Configure for these cctbx packages
  LIBTBX = [
    'cctbx',
    'cctbx_website',
    'cbflib',
    'dxtbx',
    'scitbx',
    'crys3d',
    'libtbx',
    'iotbx',
    'mmtbx',
    'smtbx',
    'gltbx',
    'wxtbx',
    'ksdssp',
  ]
  LIBTBX_EXTRA = []

##### CCTBX-derived packages #####

class MOLPROBITYBuilder(Builder):
  BASE_PACKAGES = 'molprobity'
  # Checkout these codebases
  CODEBASES = [
    'boost',
    'cbflib',
    'cctbx_project',
    'ccp4io',
    'ccp4io_adaptbx',
    'annlib',
    'annlib_adaptbx',
    'tntbx',
  ]
  CODEBASES_EXTRA = [
    'molprobity',
    'chem_data',
    'reduce',
    'probe'
  ]
  # Copy these sources from cci.lbl.gov
  HOT = [
    'scons',
    #"libsvm",
  ]
  HOT_EXTRA = []
  # Configure for these cctbx packages
  LIBTBX = [
    'mmtbx',
  ]
  LIBTBX_EXTRA = [
  ]

  def add_tests(self):
    pass

# def add_base(self, extra_opts=[]):
#   super(MOLPROBITYBuilder, self).add_base(
#     extra_opts=['--molprobity',
#                ] + extra_opts)

  def add_dispatchers(self):
    pass

  def rebuild_docs(self):
    pass

class PhaserBuilder(CCIBuilder):
  BASE_PACKAGES = 'cctbx'
    # Checkout these codebases
  CODEBASES = [
    'boost',
    'cctbx_project',
    'ccp4io',
    'ccp4io_adaptbx',
    'annlib',
    'annlib_adaptbx',
    'eigen',
    'tntbx',
    'phaser_regression',
    'phaser',
    'reduce',
  ]
  # Configure for these cctbx packages
  LIBTBX = [
    'cctbx',
    'scitbx',
    'crys3d',
    'libtbx',
    'iotbx',
    'mmtbx',
    'smtbx',
    'phaser_regression',
    'phaser',
  ]

  def add_tests(self):
    self.add_test_parallel(module='phaser_regression') # run phaser_regression/run_tests.py file
    """
    self.add_test_command('phaser_regression.regression', # run Gabors tests
                          args=['all',
                                '-o',
                                'terse_failed',
                                '-n',
                                '%s' %self.nproc,
                                ],
    )
    """

  def add_base(self, extra_opts=[]):
    # skip unnecessary base packages when building phaser only
    if self.skip_base is None or len(self.skip_base) == 0:
      self.skip_base = "hdf5,lz4_plugin,py2app,wxpython,docutils,pyopengl,pillow,tiff," + \
        "cairo,fonts,render,fontconfig,pixman,png,sphinx,freetype,gtk,matplotlib," + \
        "cython,h5py,gettext,numpy,pythonextra,pytest,junitxml,libsvm,pyrtf,six,send2trash," + \
         "jinja2,orderedset,tabulate,scipy,scikit_learn,biopython,expat,glib,mrcfile"
    else:
      self.skip_base = ','.join(self.skip_base.split(',') + ['hdf5','lz4_plugin','py2app',
         'wxpython','docutils','pyopengl','pillow','tiff','cairo','fonts','pyrtf','six','send2trash',
         'fontconfig','render','pixman','png','sphinx','freetype','gtk', 'matplotlib',
         'cython', 'h5py', 'gettext', 'numpy', 'pythonextra', 'pytest', 'junitxml','libsvm',
         'jinja2', 'orderedset', 'tabulate', 'scipy', 'scikit_learn', 'biopython',
         'expat', 'glib', 'mrcfile'
         ])
    super(PhaserBuilder, self).add_base(
      extra_opts=['--cctbx',
                 ] + extra_opts)

  def add_dispatchers(self):
    pass

  def rebuild_docs(self):
    pass

  def get_libtbx_configure(self):
    configlst = super(PhaserBuilder, self).get_libtbx_configure()
    if not self.isPlatformMacOSX():
      configlst.append("--enable_openmp_if_possible=True")
    return configlst

class PhaserTNGBuilder(PhaserBuilder):
  CODEBASES = PhaserBuilder.CODEBASES + ['phasertng', 'phaser_voyager', 'voyager_regression']
  LIBTBX = PhaserBuilder.LIBTBX + ['phasertng', 'phaser_voyager', 'voyager_regression']

  def add_tests(self):
    self.add_test_parallel(module='voyager_regression') # run voyager_regression/run_tests.py file
    self.add_test_parallel(module='phaser_regression') # run phaser_regression/run_tests.py file

  def get_libtbx_configure(self):
    configlst = super(PhaserTNGBuilder, self).get_libtbx_configure()
    if '--enable_cxx11' in configlst:
      configlst.remove('--enable_cxx11')
    set_std = ['cxxstd' in conf for conf in configlst]
    if set_std.count(True) == 0:
      if platform.mac_ver()[-1] == 'arm64':
        configlst.append('--cxxstd=c++14')
      else:
        configlst.append('--cxxstd=c++11')
    if not self.isPlatformMacOSX():
      configlst.append("--enable_openmp_if_possible=True")
    return configlst

  def get_codebases(self):
    """
    Phaser uses Boost in the conda environment for Python 3 and Windows
    """
    codebases = super(PhaserTNGBuilder, self).get_codebases()
    if (self.python3 and self.use_conda is not None):
      try:
        codebases.remove('boost')
      except ValueError:
        pass
    return codebases

class CCTBXLiteBuilder(CCIBuilder):
  BASE_PACKAGES = 'cctbx'
    # Checkout these codebases
  CODEBASES = [
    'boost',
    'cctbx_project',
    'gui_resources',
    'ccp4io',
    'ccp4io_adaptbx',
    'annlib',
    'annlib_adaptbx',
    'tntbx',
    'clipper',
    'eigen'
  ]
  # Configure for these cctbx packages
  LIBTBX = [
    'cctbx',
    'cctbx_website',
    'scitbx',
    'serialtbx',
    'libtbx',
    'iotbx',
    'mmtbx',
    'smtbx',
    'gltbx',
    'wxtbx',
  ]

  def add_tests(self):
    self.add_test_command('libtbx.import_all_python', workdir=['modules', 'cctbx_project'])
    self.add_test_command('cctbx_regression.test_nightly')

  def add_base(self, extra_opts=[]):
    if self.skip_base is None or len(self.skip_base) == 0:
      self.skip_base = "hdf5,lz4_plugin,h5py"
    else:
      self.skip_base = ','.join(self.skip_base.split(',') + ['hdf5','lz4_plugin','h5py'])
    super(CCTBXLiteBuilder, self).add_base(
      extra_opts=['--cctbx',
                 ] + extra_opts)

  def add_dispatchers(self):
    pass

  def rebuild_docs(self):
    pass

class CCTBXBuilder(CCIBuilder):
  BASE_PACKAGES = 'cctbx'
  def add_tests(self):
    self.add_test_command('libtbx.import_all_python', workdir=['modules', 'cctbx_project'])
    self.add_test_command('cctbx_regression.test_nightly')

  def add_base(self, extra_opts=[]):
    super(CCTBXBuilder, self).add_base(
      extra_opts=['--cctbx',
                 ] + extra_opts)

  def add_dispatchers(self):
    pass

  def rebuild_docs(self):
    pass

  def _add_git(self, module, parameters, destination=None):
    super(CCTBXBuilder, self)._add_git(module, parameters, destination)
    # select dials-3.5 branch
    if (module == 'dials' or module == 'dxtbx' or module == 'xia2') and self.python3:
      workdir = ['modules', module]
      if module == 'dxtbx':
        self.add_step(self.shell(command=['git', 'remote', 'set-url', 'origin', 'https://github.com/dials/dxtbx.git'], workdir=workdir))
        self.add_step(self.shell(command=['git', 'fetch', 'origin'], workdir=workdir))
      self.add_step(self.shell(command=['git', 'checkout', 'dials-3.5'], workdir=workdir))
      self.add_step(self.shell(
        command=['git', 'branch', '--set-upstream-to=origin/dials-3.5', 'dials-3.5'],
        workdir=workdir))
    # switch eigen to 3.3.9 for CentOS 6
    if module == 'eigen':
      if sys.platform.startswith('linux') and '.el6.' in platform.platform():
        workdir = ['modules', module]
        self.add_step(self.shell(command=['git', 'checkout', '3.3.9'], workdir=workdir))

class DIALSBuilder(CCIBuilder):
  CODEBASES_EXTRA = ['dials', 'iota', 'xia2', 'kokkos', 'kokkos-kernels']
  LIBTBX_EXTRA = ['dials', 'xia2', 'prime', 'iota', '--skip_phenix_dispatchers']
  HOT_EXTRA = ['msgpack']
  def add_tests(self):
    self.add_test_command('libtbx.pytest',
                          args=['--regression', '-n', 'auto'],
                          workdir=['modules', 'dxtbx'],
                          haltOnFailure=True)
    self.add_test_command('libtbx.pytest',
                          args=['--regression', '-n', 'auto'],
                          workdir=['modules', 'dials'],
                          haltOnFailure=True)

  def add_base(self, extra_opts=[]):
    super(DIALSBuilder, self).add_base(
      extra_opts=['--dials', '--xia2',
                 ] + extra_opts)

  def add_dispatchers(self):
    pass

  def rebuild_docs(self):
    pass

  def get_libtbx_configure(self):
    configlst = super(DIALSBuilder, self).get_libtbx_configure()
    if '--enable_cxx11' in configlst: configlst.remove('--enable_cxx11')
    configlst.append('--cxxstd=c++14')
    return configlst

class LABELITBuilder(CCIBuilder):
  CODEBASES_EXTRA = ['labelit', 'dials']
  LIBTBX_EXTRA = ['labelit', 'dials']

  def add_base(self, extra_opts=[]):
    super(LABELITBuilder, self).add_base(
      extra_opts=['--labelit', 'dials'] + extra_opts)

  def add_tests(self):
    self.add_test_parallel('labelit', flunkOnFailure=False, warnOnFailure=True)

  def add_dispatchers(self):
    pass

  def rebuild_docs(self):
    pass

class XFELLegacyBuilder(CCIBuilder):
  CODEBASES_EXTRA = [
    'dials',
    'iota',
    'labelit',
    'cxi_xdr_xes'
  ]
  LIBTBX_EXTRA = [
    'dials',
    'labelit',
    'xfel',
    'cxi_xdr_xes',
    'prime',
    'iota'
  ]
  HOT_EXTRA = ['msgpack']

  def add_base(self, extra_opts=[]):
    super(XFELLegacyBuilder, self).add_base(
      extra_opts=['--labelit', '--dials'] + extra_opts)

  def add_tests(self):
    self.add_test_command('cctbx_regression.test_nightly')

  def add_dispatchers(self):
    pass

  def rebuild_docs(self):
    pass

class XFELBuilder(CCIBuilder):
  CODEBASES_EXTRA = [
    'dials',
    'iota',
    'uc_metrics',
    'ncdist',
    'kokkos',
    'kokkos-kernels',
  ]
  LIBTBX_EXTRA = [
    'dials',
    'xfel',
    'prime',
    'iota',
    'uc_metrics',
  ]
  HOT_EXTRA = ['msgpack']

  def add_base(self, extra_opts=[]):
    super(XFELBuilder, self).add_base(
      extra_opts=['--dials'] + extra_opts)

  def get_libtbx_configure(self):
    configlst = super(XFELBuilder, self).get_libtbx_configure()
    if '--enable_cxx11' in configlst: configlst.remove('--enable_cxx11')
    configlst.append('--cxxstd=c++14')
    if not self.isPlatformMacOSX():
      configlst.append("--enable_openmp_if_possible=True")
    return configlst

  def add_tests(self):
    self.add_test_command('cctbx_regression.test_nightly')
    self.add_test_parallel(module='uc_metrics')

  def add_dispatchers(self):
    pass

  def rebuild_docs(self):
    pass

class PhenixBuilder(CCIBuilder):
  HOT = []
  CODEBASES_EXTRA = [
    'chem_data',
    'phenix',
    'phenix_dev_doc',
    'phenix_regression',
    'phenix_html',
    'phenix_examples',
    'phenix_pathwalker',
    'Colabs',
    'labelit',
    'Plex',
    'PyQuante',
    'elbow',
    'amber_adaptbx',
    'amber_library',
    'pulchra',
    'qrefine',
    'solve_resolve',
    'reel',
    'gui_resources',
    'opt_resources',
    'muscle',
    'reduce',
    'probe',
    'king',
    'phaser',
    'phasertng',
    'phaser_regression',
    'voyager_regression',
    'phaser_voyager',
    # 'dials',
    # 'xia2',
    # 'iota',
  ]
  LIBTBX_EXTRA = [
    'chem_data',
    'phenix',
    'phenix_dev_doc',
    'phenix_regression',
    'phenix_examples',
    'phenix_pathwalker',
    'Colabs',
    'qrefine',
    'solve_resolve',
    'reel',
    'phaser',
    'phasertng',
    'phaser_regression',
    'voyager_regression',
    'phaser_voyager',
    'labelit',
    'elbow',
    'amber_adaptbx',
    'reduce',
    'probe',
    'cootbx',
    'qttbx',
    # 'dials',
    # 'xia2',
    # 'prime',
  ]

  # select dials-3.8 branch
  def _add_git(self, module, parameters, destination=None):
    super(PhenixBuilder, self)._add_git(module, parameters, destination)
    if module == 'boost':
      workdir = ['modules', module]
      if self.category == 'phenix_discamb':
        self.add_step(self.shell(command=['git', 'checkout', '1.86'], workdir=workdir))
      else:
        self.add_step(self.shell(command=['git', 'checkout', '1.74'], workdir=workdir))
    elif (module == 'dials' or module == 'dxtbx' or module == 'xia2') and self.python3:
      workdir = ['modules', module]
      if module == 'dxtbx':
        self.add_step(self.shell(command=['git', 'remote', 'set-url', 'origin', 'https://github.com/dials/dxtbx.git'], workdir=workdir))
        self.add_step(self.shell(command=['git', 'fetch', 'origin'], workdir=workdir))
      self.add_step(self.shell(command=['git', 'checkout', 'dials-3.8'], workdir=workdir))
      self.add_step(self.shell(
        command=['git', 'branch', '--set-upstream-to=origin/dials-3.8', 'dials-3.8'],
        workdir=workdir))

  def add_module(self, module, workdir=None, module_directory=None):
    """
    Add git-lfs command for phenix_examples and phenix_regression
    If the dev_env directory already exists, it is assumed that git-lfs
    is available in that directory
    """
    super(PhenixBuilder, self).add_module(module, workdir, module_directory)

    # update phenix_regression and phenix_examples with git-lfs
    if module == 'phenix_examples' or module == 'phenix_regression' or module == 'chem_data':
      # prepend path for check
      dev_env = os.path.join('.', 'dev_env', 'bin')
      if sys.platform == 'win32':
        dev_env = os.path.join('.', 'dev_env', 'Library', 'bin')
        os.environ['PATH'] = os.path.abspath(dev_env) + ';'  + os.environ['PATH']
      else:
        os.environ['PATH'] = os.path.abspath(dev_env) + ':'  + os.environ['PATH']

      svn_is_available = False
      git_lfs_is_available = False

      # check if git-lfs and svn are available
      log = open(os.devnull, 'w')

      try:
        returncode = subprocess.call(['svn', '--version'], stdout=log, stderr=log)
        if returncode == 0:
          svn_is_available = True
      except Exception:
        pass

      try:
        returncode = subprocess.call(['git', 'lfs', '--version'], stdout=log, stderr=log)
        if returncode == 0:
          git_lfs_is_available = True
      except Exception:
        pass

      log.close()

      # set if dev_env will be created in base step
      self.install_dev_env = False
      if not svn_is_available or not git_lfs_is_available:
        self.install_dev_env = True

      # get lfs files
      if self.install_dev_env:
        print('*'*79)
        print("""\
An environment containing git-lfs and/or svn will be installed during the "base"
step. Pleaser re-run the "update" step after "base" completes, so that git-lfs
files for {module} will be downloaded.""".format(module=module))
        print('*'*79)
      else:
        workdir = ['modules', module]
        self.add_step(self.shell(command=['git', 'lfs', 'install', '--local'], workdir=workdir))
        self.add_step(self.shell(command=['git', 'lfs', 'pull'], workdir=workdir))

  def add_base(self, extra_opts=[]):
    super(PhenixBuilder, self).add_base(
      extra_opts=['--phenix',
                  '--labelit',
                  '--dials',
                  '--xia2',
                 ] + extra_opts)

    # install extra development environment if necessary
    if hasattr(self, 'install_dev_env') and self.install_dev_env:
      if self.use_conda is None:
        raise RuntimeError("""
Conda is needed for creating the extra environment with git-lfs. Please add
"--use-conda" to your bootstrap.py command or make sure git-lfs is available
in your path. """)
      self.python_base = self._get_conda_python()
      if self.python_base.startswith('../conda_base'):
        self.python_base = self.python_base[1:]  # keep current directory
      env = {
        'PYTHONPATH': None,
        'LD_LIBRARY_PATH': None,
        'DYLD_LIBRARY_PATH': None
      }
      command = [self.python_base,
                 os.path.join('modules', 'cctbx_project', 'libtbx',
                              'auto_build', 'install_conda.py'),
                 '--install_dev_env', '--verbose']
      self.add_step(self.shell(command=command, workdir=['.']))

  def add_install(self):
    Builder.add_install(self)

  def get_libtbx_configure(self):
    configlst = super(PhenixBuilder, self).get_libtbx_configure()
    if '--enable_cxx11' in configlst:
      configlst.remove('--enable_cxx11')
    set_std = ['cxxstd' in conf for conf in configlst]
    if set_std.count(True) == 0:
      if platform.mac_ver()[-1] == 'arm64':
        configlst.append('--cxxstd=c++14')
      else:
        configlst.append('--cxxstd=c++11')
    if not self.isPlatformMacOSX():
      configlst.append("--enable_openmp_if_possible=True")
    return configlst

  def rebuild_docs(self):
    self.add_command('phenix_html.rebuild_docs')

  def add_tests(self):
    # Include cctbx tests.
    self.add_test_command('libtbx.import_all_ext')
    self.add_test_command('cctbx_regression.test_nightly')
    # Windows convenience hack.
    if self.isPlatformWindows():
      self.add_test_command('phenix_regression.test_nightly_windows')
    else:
      self.add_test_command('phenix_regression.test_nightly')
    # Other Phenix tests.
    self.add_test_parallel(module='elbow')
    self.rebuild_docs()
    self.add_test_command('phenix_regression.run_p9_sad_benchmark',
                          name="test p9 sad",
                         )
    self.add_test_command('phenix_regression.run_hipip_refine_benchmark',
                          name="test hipip",
                         )
    self.add_test_command('phenix_regression.wizards.test_all_parallel',
      args = ['nproc=8'],
      name="test wizards",
                         )
    run_dials_tests=True
    if self.isPlatformWindows():
      if 'dials' in windows_remove_list:
        run_dials_tests=False
    if run_dials_tests:
      self.add_test_parallel('dials', flunkOnFailure=False, warnOnFailure=True)

class PhenixDiscambBuilder(PhenixBuilder):
  CODEBASES_EXTRA = PhenixBuilder.CODEBASES_EXTRA + ['pyDiSCaMB']

  def get_libtbx_configure(self):
    configlst = super(PhenixDiscambBuilder, self).get_libtbx_configure()
    # switch to C++14 for new environments
    if '--cxxstd=c++14' not in configlst:
      configlst.append('--cxxstd=c++14')
    return configlst

  def add_make(self):
    super(PhenixDiscambBuilder, self).add_make()
    # install pyDiSCaMB
    python = os.path.normpath(os.path.join(os.getcwd(), 'build', self.python_base))
    self.add_step(self.shell(
      command=[python, '-m', 'pip', 'install', '.'],
        workdir=['modules', 'pyDiSCaMB'],
        description='pip installing pyDiSCaMB',
      ))

class PhenixMolstarBuilder(PhenixBuilder):
  CODEBASES_EXTRA = PhenixBuilder.CODEBASES_EXTRA + ['molstar','molstar_adaptbx']
  def add_make(self):
    super(PhenixMolstarBuilder, self).add_make()
    python = os.path.normpath(os.path.join(os.getcwd(), 'build', self.python_base))
    self.add_step(self.shell(
      command=[python, "install_molstar.py"],
        workdir=['modules', 'molstar_adaptbx',"command_line"],
        description='molstar adaptbx install script',
      ))

class PhenixExternalRegression(PhenixBuilder):
  EXTERNAL_CODEBASES = [
    "afitt",
    "rosetta",
    ]

  def cleanup(self, dirs=None):
    self.add_step(cleanup_ext_class(".bz2", "modules", walk=False))
    lt = time.localtime()
    cleaning = ['dist', 'tests', 'doc', 'tmp', 'base_tmp']
    if lt.tm_wday==5: # do a completer build on Saturday night
      cleaning += ['base', 'base_tmp', _BUILD_DIR, 'conda_base']
    # Preparation
    # AFITT
    if self.subcategory in [None, "afitt"]:
      self.add_step(cleanup_dirs(['openeye'], 'modules'))
    PhenixBuilder.cleanup(self, cleaning)

  def get_environment(self, add_build_python_to_path=True):
    environment = {}
    for env, dirs in envs.items():
      environment[env] = os.path.join(*dirs)
    if add_build_python_to_path:
      old_path = os.environ.get("PATH", "") # this is just another now
                                            # universal hack to get Amber to
                                            # compile...
      environment["PATH"] = '%s:%s' % (os.path.join(#os.getcwd(),
                                                    "build",
                                                    "bin",
                                                  ),
                                       old_path,
                                       )
    return environment

  def write_environment(self,
                        env,
                        filename="setpaths_externals",
                       ):
    # called by add_make which is called in build
    # this is a little funky as it seems to be very often in the wrong remote dir
    outl = ""
    for key, path in env.items():
      if key in ["PATH"]: continue
      outl += 'setenv %(key)s "%%(PWD)s/../%(path)s"\n' % locals()
    fname="%s.csh" % filename
    self.add_step(self.shell(command=[
      sys.executable,
      '-c',
      'import os; open("%s","w").write("""%s""" %% os.environ)' %(fname, outl)
      ],
      workdir=[_BUILD_DIR],
      description="save csh external paths",
    ))
    outl = ""
    for key, path in env.items():
      if key in ["PATH"]: continue
      outl += 'export %(key)s="%%(PWD)s/../%(path)s"\n' % locals()
    fname="%s.sh" % filename
    self.add_step(self.shell(command=[
      sys.executable,
      '-c',
      'import os; open("%s","w").write("""%s""" %% os.environ)' %(fname, outl)
      ],
      workdir=[_BUILD_DIR],
      description="save sh external paths",
    ))

  def add_make(self):
    # Phenix compile
    PhenixBuilder.add_make(self)
    # need to use the Phenix python for building
    # Rosetta
    # AFITT
    env = self.get_environment()
    self.write_environment(env)
    # not universal but works because only slave running this is same as master
    for name, command, workdir in [
        ['AFITT - untar',
         ['tar', 'xvf', '%s.gz' % afitt_version],
         ['modules']],
        ['Rosetta - untar',
         ['tar', 'xvf', '%s.tgz' % rosetta_version_tar_bundle],
         ['modules']],
        ['Rosetta - rm link',
         # not windows compatible
         ['rm', '-f', "rosetta"],
         ['modules']],
        ['Rosetta - link',
         # not windows compatible
         ['ln', '-sf', '%s' % rosetta_version_directory, "rosetta"],
         ['modules']],
        #['Rosetta compile', # not really needed
        # ["./scons.py",
        #  "-j",
        #  self.nproc,
        #  #"mode=release",
        # ],
        # ["modules", 'rosetta', "main", "source"]],
        ]:
      if self.subcategory:
        if name.lower().find(self.subcategory)==-1: continue
      haltOnFailure=True
      self.add_step(self.shell(
        name       = name,
        command    = command,
        workdir    = workdir,
        description= "",
        env        = env,
        haltOnFailure = haltOnFailure,
        ))

    self.add_refresh()
    # Rosetta
    if self.subcategory in [None, "rosetta"]:
      self.add_command(
        'rosetta.build_phenix_interface',
        args = ["nproc=%s" % self.nproc],
        name='rosetta.build_phenix_interface',
        workdir=['.'],
        env=env,
      )

  def add_tests(self):
    # timings
    if self.subcategory in [None, 'timings']:
      self.add_test_command(
        'mmtbx.python',
        args=[os.path.join('..',
                           '..',
                           'modules',
                           'phenix_regression',
                           'development',
                           'runtime_speed_regression_test.py',
                           )],
        name="timings test",
        )
    # amber
    if self.subcategory in [None, "amber"]:
      self.add_test_command('amber.run_tests',
                            env = self.get_environment(),
                            haltOnFailure=False,
                           )
    # rosetta refine
    if self.subcategory in [None, "rosetta"]:
      self.add_test_command('rosetta.run_tests',
                            env = self.get_environment()
                           )
    # MR rosetta
    if self.subcategory in [None, "rosetta"]:
      self.add_test_command(
        'phenix_regression.wizards.run_wizard_test',
        args=['test_prerefine'],
        name="test MR rosetta quick",
        env = self.get_environment()
      )
    # afitt
    if self.subcategory in [None, "afitt"]:
      self.add_test_command('afitt.run_tests',
                            env = self.get_environment()
                           )
    # GLR
    if self.subcategory in [None, "glr"]:
      self.add_test_command('elbow.run_glr_tests',
                            haltOnFailure=False,
                            )

class QRBuilder(PhenixBuilder):
  #
  # Designed to be run in Phenix build to add Q|R
  # and the entire PhenixBuilder if user is builder
  #
  EXTERNAL_CODEBASES = ["qrefine"]
  user = os.environ.get('USER', None)

  def add_make(self):
    if self.user=='builder': PhenixBuilder.add_make(self)
    #
    # XXX Use older ASE (the new one is only Python3)
    # XXX Do not get JPype1 as it fails. This makes QR work only with
    # XXX fast_interaction=True (=False won't work)
    #
    pip_installs = ['ase==3.22.1',]
    instructions = []
    # versioning
    cmd = [os.path.join('..', self.python_base),
           os.path.join('utils', 'make_version.py'),
           ]
    instructions.append(['Versioning', cmd, ['modules/qrefine']])
    for pi in pip_installs:
      instructions.append(['Q|R pip %s' % pi,
                           [self.python_base,
                            '-m',
                            'pip',
                            'install',
                            pi
                          ],
                           ['modules']])

    for name, command, workdir in instructions:
      self.add_step(self.shell(
        name       = name,
        command    = command,
        workdir    = workdir,
        description= "",
        haltOnFailure = 1, #haltOnFailure,
        ))
    self.add_refresh()

  def get_hot(self):
    if self.user=='builder': return PhenixBuilder.get_hot(self)
    return [] # don't have any HOT downloads and the difference between
              # anonymous and cciuser is making a mess

  def get_libtbx_configure(self): # modified in derived class PhenixBuilder
    return self.LIBTBX + self.LIBTBX_EXTRA + self.EXTERNAL_CODEBASES

  def get_codebases(self):
    if self.isPlatformWindows(): assert 0, 'not supported'
    if self.user=='builder':
      rc = PhenixBuilder.get_codebases(self)
    else:
      rc = self.EXTERNAL_CODEBASES #+ ['cctbx_project']
    return rc

  def add_tests(self):
    self.add_test_command('qr.build_interfaces',
                          haltOnFailure=False,
                          env = self.get_environment()
                          )
    self.add_test_command('qr.test',
                          # args=['--non_mopac_only'],
                          haltOnFailure=True,
                          env = self.get_environment()
                          )

  def add_dispatchers(self):
    pass

  def rebuild_docs(self):
    pass

  def get_environment(self, add_build_python_to_path=True):
    environment = {}
    mopac_envs = {
      "MOPAC_LICENSE"  : "/home/builder/software/mopac",
      "MOPAC_COMMAND"  : "/home/builder/software/mopac/mopac.csh",
    }
    for env, dirs in mopac_envs.items():
      environment[env] = dirs
    return environment

class PhenixReleaseBuilder(PhenixBuilder):
  '''
  Phenix with DIALS
  '''
  extra_codebases = ['dials', 'iota', 'xia2']
  extra_libtbx = extra_codebases + ['prime']
  CODEBASES_EXTRA = PhenixBuilder.CODEBASES_EXTRA + extra_codebases
  LIBTBX_EXTRA = PhenixBuilder.LIBTBX_EXTRA + extra_libtbx

def set_builder_defaults(options):
  '''
  Updates defaults for specific builders
  '''
  if options.builder == 'phenix_voyager':
    if not options.no_boost_src:
      options.no_boost_src = True
      # restore default for CentOS 7
      if sys.platform.startswith('linux') and '.el7.' in platform.platform():
        options.no_boost_src = False
  if options.builder == 'phenix' \
    or options.builder == 'phenix_discamb' \
    or options.builder == 'phenix_molstar' \
    or options.builder == 'phenix_voyager' \
    or options.builder == 'molprobity':
    # Apple Silicon uses Boost 1.78 in environment, Python 3.9
    if platform.mac_ver()[-1] == 'arm64':
      options.no_boost_src = True
      options.python = '39'
    if not options.no_boost_src:
      options.no_boost_src = True
      if sys.platform.startswith('linux') and '.el7.' in platform.platform():
        options.no_boost_src = False
    if options.use_conda is None:
      options.use_conda = ''
    if options.builder == 'phenix_discamb':
      options.python = '39'

  return options

def run(root=None):
  builders = {
    'cctbxlite': CCTBXLiteBuilder,
    'cctbx': CCTBXBuilder,
    'phenix': PhenixBuilder,
    'phenix_discamb': PhenixDiscambBuilder,
    'phenix_molstar': PhenixMolstarBuilder,
    'phenix_voyager': PhenixBuilder,
    'phenix_release': PhenixReleaseBuilder,
    'xfellegacy': XFELLegacyBuilder,
    'xfel': XFELBuilder,
    'labelit': LABELITBuilder,
    'dials': DIALSBuilder,
    'external': PhenixExternalRegression,
    'molprobity':MOLPROBITYBuilder,
    'qrefine': QRBuilder,
    'phaser': PhaserBuilder,
    'voyager': PhaserTNGBuilder
  }

  wrapper = textwrap.TextWrapper(width=80, initial_indent='  ',
                                 subsequent_indent='    ')
  builders_text = ', '.join(sorted(builders.keys()))
  builders_text = '\n'.join(wrapper.wrap(builders_text))

  prog = os.environ.get('LIBTBX_DISPATCHER_NAME')
  if prog is None or prog.startswith('python') or prog.endswith('python'):
    prog = os.path.basename(sys.argv[0])

  description = """
  You may specify one or more actions:
    hot - Update static sources (scons, etc.)
    update - Update source repositories (cctbx, cbflib, etc.)
    base - Build base dependencies (python, hdf5, wxWidgets, etc.)
    build - Build
    tests - Run tests
    doc - Build documentation

  The default action is to run: hot, update, base, build

  You can specify which package will be downloaded, configured,
  and built with "--builder". Current builders:
  {builders}

  You can provide your SourceForge username with "--sfuser", and
  your CCI SVN username with "--cciuser". These will checkout
  and update repositories with your credentials. Some builders,
  like phenix, require this argument for access to certain
  repositories.

  You can run the compilation step in parallel by providing a
  the number of processes using "--nproc".
  Complete build output is shown with "-v" or "--verbose".

  Finally, you may specify a specific Python interpreter
  using "--with-python".

  Example:

    python bootstrap.py --builder=cctbx --sfuser=metalheadd hot update build tests
  """.format(builders=builders_text)

  parser = argparse.ArgumentParser(
    prog=prog, description=description,
    formatter_class=argparse.RawDescriptionHelpFormatter)
  # parser.add_argument("--root", help="Root directory; this will contain base, modules, build, etc.")
  parser.add_argument('action', nargs='*', help="Actions for building")
  parser.add_argument(
    "--builder",
    help="Builder: " + ",".join(list(builders.keys())),
    default="cctbx")
  parser.add_argument("--cciuser", help="CCI SVN username.")
  parser.add_argument("--sfuser", help="SourceForge SVN username.")
  parser.add_argument("--revert", help="SVN string to revert all SVN trees")
  parser.add_argument("--sfmethod",
                    help="SourceForge SVN checkout method.",
                    default="svn+ssh")
  parser.add_argument(
    "--git-ssh",
    dest="git_ssh",
    action="store_true",
    help="Use ssh connections for git. This allows you to commit changes without changing remotes and use reference repositories.",
    default=False)
  parser.add_argument(
    "--git-reference",
    dest="git_reference",
    help="Path to a directory containing reference copies of repositories for faster checkouts.")
  parser.add_argument("--with-python",
                    dest="with_python",
                    help="Use specified Python interpreter")
  parser.add_argument("--nproc",
                    help="number of parallel processes in compile step.")
  parser.add_argument("--download-only",
                    dest="download_only",
                    action="store_true",
                    help="Do not build, only download prerequisites",
                    default=False)
  parser.add_argument("-v",
                    "--verbose",
                    dest="verbose",
                    action="store_true",
                    help="Verbose output",
                    default=False)
  parser.add_argument("--skip-base-packages",
                    dest="skip_base",
                    action="store",
                    default="")
  parser.add_argument("--force-base-build",
                    dest="force_base_build",
                    action="store_true",
                    default=False)
  parser.add_argument("--enable-shared",
                    dest="enable_shared",
                    action="store_true",
                    default=False)
  parser.add_argument("--mpi-build",
                    dest="mpi_build",
                    help="Builds software with mpi functionality",
                    action="store_true",
                    default=False)
  python_args = parser.add_mutually_exclusive_group(required=False)
  python_args.add_argument('--python',
                    default='37', type=str, nargs='?', const='37',
                    choices=['27', '37', '38', '39', '310', '311', '312', '313'],
                    help="""When set, a specific Python version of the
conda environment will be used. This only affects environments selected with
the --builder flag. For non-conda dependencies, any Python 3 implies
Python 3.7.""")
  parser.add_argument("--config-flags", "--config_flags",
                    dest="config_flags",
                    help="""Pass flags to the configuration step. Flags should
be passed separately with quotes to avoid confusion (e.g
--config_flags="--build=debug" --config_flags="--enable_cxx11")""",
                    action="append",
                    default=[])
  parser.add_argument("--use-conda", "--use_conda", metavar="ENVIRONMENT",
                    dest="use_conda",
                    help="""Use conda for dependencies. The directory to an
existing conda environment or a file defining a conda environment can be
provided. The build will use that environment instead of creating a default one
for the builder. If the currently active conda environment is to be used for
building, $CONDA_PREFIX should be the argument for this flag. Otherwise, a new
environment will be created. The --python flag will be ignored when there is
an argument for this flag. Specifying an environment is for developers that
maintain their own conda environment.""",
                    default=None, nargs='?', const='')
  parser.add_argument("--no-boost-src", "--no_boost_src",
                      dest="no_boost_src",
                      help="""When set, the reduced Boost source code is not
downloaded into the modules directory. This enables the usage of an existing
installation of Boost in the same directory as the Python for configuration.
For example, this flag should be used if the conda package for Boost is
available. This flag only affects the "update" step.""",
                      action="store_true",
                      default=False)
  parser.add_argument("--build-dir",
                     dest="build_dir",
                     help="directory where the build will be. Should be at the same level as modules! default is 'build'",
                     default="build", type=str)

  options = parser.parse_args()
  args = options.action

  global _BUILD_DIR
  _BUILD_DIR = options.build_dir  # TODO: this is probably ok way to go with globalvar, but check and see

  # process external
  options.specific_external_builder=None
  if options.builder.lower() in ["afitt",
                                 "rosetta",
                                 ]:
    options.specific_external_builder=options.builder.lower()
    options.builder="external"

  # Root dir
  # options.root = options.root or root

  # Check actions
  allowedargs = ['cleanup', 'hot', 'update', 'base', 'build', 'tests', 'doc']
  args = args or ['hot', 'update', 'base', 'build']
  actions = []
  for arg in args:
    if arg not in allowedargs:
      raise ValueError("Unknown action: %s"%arg)
  for arg in allowedargs:
    if arg in args:
      actions.append(arg)

  # Check if an action was an argument to --use-conda
  if options.use_conda in allowedargs:
    if len(options.action) == 0:
      actions = [options.use_conda]
    else:
      actions.append(options.use_conda)
    options.use_conda = ''

  # Check if the argument to --use-conda starts with '~'
  if options.use_conda is not None and options.use_conda.startswith('~'):
    options.use_conda = os.path.expanduser(options.use_conda)

  print("Performing actions:", " ".join(actions))

  # Check builder
  if options.builder not in builders:
    raise ValueError("Unknown builder: %s"%options.builder)

  auth = { 'git_ssh': options.git_ssh, 'git_reference': options.git_reference }
  if options.cciuser:
    auth['cciuser'] = options.cciuser
  if options.sfuser:
    auth['sfuser'] = options.sfuser
  if options.sfmethod:
    auth['sfmethod'] = options.sfmethod

  # Apply defaults for specific builders
  options = set_builder_defaults(options)

  # Build
  builder = builders[options.builder]
  builder(
    category=options.builder,
    subcategory=options.specific_external_builder,
    platform='dev',
    with_python=options.with_python,
    auth=auth,
    hot=('hot' in actions),
    update=('update' in actions),
    revert=options.revert,
    base=('base' in actions),
    build=('build' in actions),
    tests=('tests' in actions),
    doc=('doc' in actions),
    cleanup=("cleanup" in actions),
    nproc=options.nproc,
    verbose=options.verbose,
    download_only=options.download_only,
    skip_base=options.skip_base,
    force_base_build=options.force_base_build,
    enable_shared=options.enable_shared,
    mpi_build=options.mpi_build,
    python3=False,
    wxpython4=False,
    config_flags=options.config_flags,
    use_conda=options.use_conda,
    python=options.python,
    no_boost_src=options.no_boost_src,
  ).run()
  print("\nBootstrap success: %s" % ", ".join(actions))

if __name__ == "__main__":
  run()


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/conda_build/create_custom_bin.py
from __future__ import division, print_function
'''
Script for copying package-specific binaries to a custom directory to
avoid cluttering the user's path
'''

import argparse
import json
import os
import sys

from pathlib import Path
from shutil import copy

# =============================================================================
def copy_bin(prefix, custom_bin, packages=[]):
  '''
  Function to copy package-specific binaries to a custom directory to
  avoid cluttering the user's path

  A directory containing the binaries will be created in
  ${prefix}/${custom_bin}

  Parameters
  ----------
  prefix : str or Path
      The installation prefix
  custom_bin : str
      The name of the directory for the binaries you want copied
  packages : list of str
      The names of packages containing the binaries you want copied
  '''
  prefix = Path(os.path.abspath(prefix))
  bin_directories = ['bin', 'Library/bin', 'Scripts']
  meta = prefix/'conda-meta'
  if meta.exists():
    info = None
    bin_files = []
    for package in packages:
      for json_file in os.listdir(meta):
        if json_file.startswith(package) and json_file.endswith('.json'):
          with open(meta/json_file, 'r') as f:
            info = json.load(f)
      if info is not None:
        all_files = info.get('files', [])
        for file in all_files:
          for bin_dir in bin_directories:
            if file.startswith(bin_dir):
              bin_files.append(Path(file))
    if len(bin_files) > 0:
      new_prefix = prefix/custom_bin
      os.makedirs(new_prefix, exist_ok=True)
      for bin_file in bin_files:
        bin_name = bin_file.name
        if (new_prefix/bin_name).exists():
          print(f'{new_prefix/bin_name} already exists, skipping')
        else:
          if sys.platform == 'win32':
            print(f'Copying {prefix/bin_file} to {new_prefix/bin_name}')
            copy(prefix/bin_file, new_prefix/bin_name)
            if (new_prefix/bin_name).suffix == '.bat':
              print(f'Fixing LIBTBX_PREFIX in {new_prefix/bin_name}')
              with open(new_prefix/bin_name, 'r') as f:
                lines = f.readlines()
              with open(new_prefix/bin_name, 'w') as f:
                for line in lines:
                  line = line.strip()
                  if 'dp0' in line:  # make path relative to original location
                    line += '\\..\\Library\\bin'
                  f.write(line)
          else:
            print(f'Linking {prefix/bin_file} to {new_prefix/bin_name}')
            os.symlink(prefix/bin_file, new_prefix/bin_name)
          if (new_prefix/bin_name).exists():
            print(f'  {new_prefix/bin_name} created')
          else:
            print(f'Warning: {new_prefix/bin_name} was not created')
    else:
      print('No binary files were found, skipping copy')
  else:
    print('The conda-meta directory does not exist. Cannot find package json.')

# =============================================================================
if __name__ == '__main__':
  parser = argparse.ArgumentParser(description=__doc__,
                                   formatter_class=argparse.RawDescriptionHelpFormatter)
  parser.add_argument('--prefix', type=str,
    help='''The prefix of the installation. The conda-meta directory must exist in this directory.''',
    required=True)
  parser.add_argument('--custom_bin', type=str,
    help='''The name of the custom binary directory. It will exist in the prefix directory.''',
    required=True)
  parser.add_argument('--packages', type=str, nargs='*',
    help='''The packages to search.''',
    required=True)

  namespace = parser.parse_args()

  copy_bin(namespace.prefix, namespace.custom_bin.lower(), namespace.packages)

# =============================================================================
# end


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/conda_build/create_setup.py
"""
Installation script for Python components
The python used to call this script is the default location of the installation.
"""
from __future__ import absolute_import, division, print_function

import argparse
import glob
import os
import sys

import libtbx.load_env

# =============================================================================
def find_python_files(directory):
  """
  Function to find the Python files in a directory

  Parameters
  ----------
    directory: str
      The directory to search

  Returns
  -------
    file_list: list
      List of filenames
  """
  cwd = os.getcwd()
  file_list = list()
  for dirpath, dirnames, filenames in os.walk(directory):
    os.chdir(directory)
    filenames = glob.glob('*.py')
    file_list += [filename if dirpath == '.'
                  else os.path.join(dirpath, filename)
                  for filename in filenames]
    for dirname in dirnames:
      if not dirname.startswith('.'):
        file_list += find_python_files(dirname)
  os.chdir(cwd)

  return file_list

# =============================================================================
def create_setup_files(module_list, filename=None, file_template=None):
  """
  Function for creating the setup.py file

  If a filename is provided, all the modules are added to the same file.
  Otherwise, each module has a separate file. A file template for the setup.py
  file can also be provided. There should be fields for {module} and {version}

  Parameters
  ----------
    module_list: list
      List of modules for creating the setup.py file
    filename: str
      The common filename for all the modules
    file_template: str
      The setup.py template

  Returns
  -------
    Nothing
  """

  if file_template is None:
    file_template = """
from setuptools import setup, find_packages
setup(
    name='{module}',
    version='{version}',
    description='{module} module from CCTBX',
    url='https://github.com/cctbx/cctbx_project',
    packages=find_packages(include=['{module}', '{module}.*']),
)
"""


# =============================================================================
def run_setup(version='0.0', create_files=True, run_files=True, log=sys.stdout):
  """
  Function to iterate over each configured module and create a setup.py file to
  install the Python components.

  Parameters
  ----------
  create_files: bool
    If set, the setup.py files are created per module
  run_files: bool
    If set, the setup.py files are run to install the Python files
  log: file
    For storing the log output

  Returns
  -------
    0 for sucess, 1 for failure
  """

  cwd = os.getcwd()
  env = libtbx.env
  modules = env.module_list
  modules_path = abs(env.repository_paths[0])

  ignored_modules = [
    'chem_data',
    'phenix_examples',
    'phenix_regression',
  ]

  cctbx_file_template = """
from setuptools import setup, find_packages
setup(
    name='{module}',
    version='{version}',
    description='{module} module from CCTBX',
    url='https://github.com/cctbx/cctbx_project',
    packages=find_packages(include=[{packages}]),
)
"""

  file_template = """
from setuptools import setup, find_packages
setup(
    name='{module}',
    version='{version}',
    description='{module} module from CCTBX',
    url='https://github.com/cctbx/cctbx_project',
    packages=find_packages(include=['{module}', '{module}.*']),
)
"""

  # ---------------------------------------------------------------------------
  # create setup.py files
  if create_files:
    print('Creating setup.py files', file=log)
    print('=======================', file=log)

    os.chdir(modules_path)
    directory = None

    # separate cctbx_project modules
    cctbx_modules = list()
    other_modules = list()
    for module in modules:
      for name, directory in module.name_and_dist_path_pairs():
        if directory is not None:
          if 'cctbx_project' in abs(directory):
            cctbx_modules.append(module)
          else:
            other_modules.append(module)

    # cctbx_project first (main cctbx package)
    filename = os.path.join(env.under_dist('cctbx', '..'), 'cctbx_setup.py')
    packages = list()
    for module in cctbx_modules:
      for name, directory in module.name_and_dist_path_pairs():
        if directory is not None:
          module_has_python_files = len(find_python_files(abs(directory)))
          if module_has_python_files:
            packages.append("'{module}'".format(module=name))
            packages.append("'{module}.*'".format(module=name))

            # with open(filename.format(module=name), 'w') as f:
            #   f.write(file_template.format(module=name, version=version))
            # if os.path.isfile(filename.format(module=name)):
            #   print('Wrote {filename}'.format(
            #     filename=filename.format(module=name)), file=log)
            # else:
            #   raise RuntimeError("""{filename} failed to write.""".format(
            #     filename=filename))
          else:
            print('{module} does not have Python files'.format(module=name),
                  file=log)
    packages = ', '.join(packages)
    print(file=log)
    print('cctbx_setup.py will contain:', file=log)
    print(packages, file=log)
    with open(filename, 'w') as f:
      f.write(cctbx_file_template.format(module='cctbx', version=version,
                                         packages=packages))
    print('Wrote {filename}'.format(filename=filename), file=log)

    # other modules
    filename = '{module}_setup.py'

    print(file=log)

  # ---------------------------------------------------------------------------
  # install
  if run_files:
    print(namespace.prefix)

  print()
  os.chdir(cwd)

# =============================================================================
if __name__ == '__main__':
  parser = argparse.ArgumentParser(
    description=__doc__,
    formatter_class=argparse.RawDescriptionHelpFormatter)
  parser.add_argument(
    '--prefix', default=sys.prefix, type=str, nargs='?',
    help="""The installation directory. By default, the location is where
      Python is located (e.g. sys.prefix)""")
  parser.add_argument(
    '--version', default='0.0', type=str, nargs='?',
    help="""The version number of the package""")
  parser.add_argument(
    '--only-create-files', action='store_true',
    help="""When set, the setup.py files are only created (not run) for each
      configured module.""")
  parser.add_argument(
    '--only-run-files', action='store_true',
    help="""When set, the setup.py files are run for each configured
      module. The command will fail if the setup.py does not exist. Default
      is True.""")

  namespace = parser.parse_args()

  if namespace.only_create_files and namespace.only_run_files:
    raise RuntimeError("""
Only one of the --only-create-files or --only-run-files flags can be used.
""")

  create_files = True
  run_files = True
  if namespace.only_create_files:
    run_files = False
  elif namespace.only_run_files:
    create_files = False

  sys.exit(run_setup(version=namespace.version, create_files=create_files, run_files=run_files))


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/conda_build/install_build.py
"""
Script for copying or symbolically linking CCTBX builds into $PREFIX

The script assumes that the build directory has a complete build

By default, the installation will be placed into the sys.prefix
directory of the calling python.

Usage: libtbx.python install_modules.py
"""
from __future__ import absolute_import, division, print_function

import argparse
import glob
import os
import sys

from shutil import copy, copytree, ignore_patterns, rmtree
from subprocess import check_output

# =============================================================================
def copy_cmd(src, dst, link):
  """
  Copy or link

  Parameters
  ----------
    src: str
      The source path
    dst: str
      The destination path
    link: bool
      If True, linking is used instead of copying

  Returns
  -------
    Nothing
  """
  if not os.path.exists(src):
    print('  {src} does not exist, skipping'.format(src=src))
  elif os.path.exists(dst):
    print('  {dst} already exists'.format(dst=dst))
  else:
    print('  source:      ' + src)
    print('  destination: ' + dst)
    if link:
      os.symlink(src, dst)
    else:
      if os.path.isdir(src):
        copytree(src, dst, ignore=ignore_patterns('.git*', '.svn*'))
      else:
        copy(src, dst)

# =============================================================================
def remove_cmd(src):
  """
  Remove file, directory, or unlink

  Parameters
  ----------
    src: str
      The source path

  Returns
  -------
    Nothing
  """
  if os.path.islink(src):
    os.unlink(src)
  elif os.path.isdir(src):
    rmtree(src)
  else:
    os.remove(src)

# =============================================================================
def fix_rpath(src):
  """
  Fix relative paths for unix systems

  This is not necessary with conda-build.

  Parameters
  ----------
    src: str
      The source path

  Returns
  -------
    Nothing
  """

  platform = sys.platform
  if platform == 'win32':
    return
  if platform.startswith('linux'):
    libraries = []
    env = dict(os.environ)
    if env.get('LD_LIBRARY_PATH', None) is not None:
      del env['LD_LIBRARY_PATH']
    output = check_output(['ldd', src], env=env).decode('utf8').split('\n')
    for line in output:
      print(line)
      if 'not found' in line:
        libraries.append(line.split()[0])
    print(libraries)

# =============================================================================
def copy_build(env, prefix=None, ext_dir=None, sp_dir=None, copy_egg=False, link=False):
  """
  Copies the following items,
    1) Binaries from build/exe_dev and build/*/exe to $PREFIX/bin
    2) Headers from build/include to $PREFIX/include
    3) Libraries from build/lib to $PREFIX/lib
    4) Python extensions from build/lib to $PREFIX/lib/$PYTHON/lib-dynload

  Parameters
  ----------
    env: libtbx.env_config.environment
      The libtbx environment
    prefix: str
      The destination $PREFIX directory
    ext_dir: str
      The destination directory for Python extensions
    sp_dir: str
      The destination site-packages directory. This is only used if copy_egg is True
    copy_egg: bool
      If True, egg-info directories are copied to the site-packages directory.
      The sp_dir parameter needs to be set.
    link: bool
      If True, symbolic links are used instead of copying.

  Returns
  -------
    Nothing
  """

  # ---------------------------------------------------------------------------
  def loop_copy(src_path, dst_path, name, filenames):
    """
    Convenience function for looping over files to copy
    """
    cmd = 'Copying'
    if link:
      cmd = 'Linking'
    print(cmd + ' ' + name)
    print('-'*79)
    for src_file in filenames:
      src = os.path.join(src_path, src_file)
      if not os.path.exists(src):
        print('  {src} does not exist'.format(src=src))
        continue
      dst = os.path.join(dst_path, src_file)
      copy_cmd(src, dst, link)
    print('Done')
    print()
  # ---------------------------------------------------------------------------

  old_cwd = os.getcwd()

  # binaries and headers
  # may need to add rpath fixes for binaries when necessary
  # ---------------------------------------------------------------------------
  for name, name_dir in [('binaries', 'exe_dev'), ('headers', 'include')]:
    src_path = os.path.join(abs(env.build_path), name_dir)
    if name_dir == 'exe_dev':
      name_dir = 'bin'
    dst_path = os.path.join(prefix, name_dir)
    if os.path.isdir(src_path):
      filenames = os.listdir(src_path)
      loop_copy(src_path, dst_path, name, filenames)
  src_path = abs(env.build_path)
  dst_path = os.path.join(prefix, 'bin')
  os.chdir(src_path)
  all_names = glob.iglob('*/exe/*')
  module_names = set()
  for name in all_names:
    split_name = name.split(os.sep)
    module_names.add(split_name[0])
  for module_name in module_names:
    src_path = os.path.join(abs(env.build_path), module_name, 'exe')
    filenames = os.listdir(src_path)
    loop_copy(src_path, dst_path, '{} binaries'.format(module_name), filenames)

  # libraries
  # ---------------------------------------------------------------------------
  src_path = os.path.join(abs(env.build_path), 'lib')
  dst_path = os.path.join(prefix, 'lib')
  os.chdir(src_path)
  all_names = glob.glob('lib*') \
              + [f for f in glob.glob('*.lib') if not f.endswith('_ext.lib')]
  lib_names = []
  for name in all_names:
    if name.endswith('egg-info'):
      continue
    lib_names.append(name)
  loop_copy(src_path, dst_path, 'libraries', lib_names)

  # Python extensions
  # ---------------------------------------------------------------------------
  src_path = os.path.join(abs(env.build_path), 'lib')
  dst_path = ext_dir
  all_names = glob.iglob('*ext.*')
  ext_names = []
  for name in all_names:
    if name.endswith('egg-info'):
      continue
    ext_names.append(name)
  loop_copy(src_path, dst_path, 'Python extensions', ext_names)

  # .egg-info directories
  # ---------------------------------------------------------------------------
  if copy_egg:
    if sp_dir is None:
      raise RuntimeError('''\
The site-packages directory ("sp_dir") parameter must be set for copying egg directories.''')
    src_path = os.path.join(abs(env.build_path), 'lib')
    dst_path = sp_dir
    egg_names = glob.iglob('libtbx*egg-info')
    loop_copy(src_path, dst_path, 'egg-info directories', egg_names)

  # extra build stuff
  # ---------------------------------------------------------------------------
  share_dir = os.path.join(prefix, 'share', 'cctbx')
  if not os.path.exists(share_dir):
    os.mkdir(share_dir)
  directory_names = []
  for module in env.module_list:
    directory_names += module.names_active()
  loop_copy(abs(env.build_path), share_dir, 'extra build directories', directory_names)

  os.chdir(old_cwd)

# =============================================================================
def copy_modules(env, sp_dir=None, link=False):
  """
  Copies configured modules to site-packages directory

  Parameters
  ----------
    env: libtbx.env_config.environment
      The libtbx environment
    sp_dir: str
      The destination site-packages directory
    link: bool
      If True, symbolic links are used instead of copying.

  Returns
  -------
    Nothing
  """

  # copy each module directory
  for module in env.module_dict:
    cmd = 'Copying'
    if link:
      cmd = 'Linking'
    print(cmd + ' ' + module)
    print('-'*79)
    try:
      for dist_path in env.module_dict[module].dist_paths:
        if dist_path is not None:
          src = abs(dist_path)
          # skip boost
          if module == 'boost' and src.endswith('boost'):
            continue
          # copy subdirectories for some modules
          elif module in ['phenix', 'phaser_voyager']:
            if module == 'phenix':
              src_root = dist_path
              subdirs = ['phenix', 'wxGUI2']
            elif module == 'phaser_voyager':
              src_root = dist_path / 'src'
              subdirs = ['New_Voyager', 'Voyager']
            for subdir in subdirs:
              src = abs(src_root / subdir)
              dst = os.path.join(sp_dir, subdir)
              copy_cmd(src, dst, link)
              # phenix/wxGUI2 is also an expected path (fix upstream)
              if subdir == 'wxGUI2':
                dst = os.path.join(sp_dir, 'phenix', subdir)
                copy_cmd(src, dst, link)
            continue
          elif module in ['elbow', 'phaser', 'phasertng', 'PyQuante', 'reel']:
            if module == 'elbow':
              # yacc.py and resources
              for m in ['yacc.py', 'resources']:
                src = abs(dist_path / m)
                dst = os.path.join(sp_dir, m)
                copy_cmd(src, dst, link)
            src = abs(dist_path / module)
          dst = os.path.join(sp_dir, os.path.basename(src))
          copy_cmd(src, dst, link)
          if module == 'tntbx':
            for f in ['__init__.py', 'eigensystem.py']:
              src = abs(dist_path / module / f)
              dst = os.path.join(sp_dir, module, f)
              copy_cmd(src, dst, link)
    except KeyError:
      print(dist_path)

    print('Done')
    print()

# =============================================================================
def remove_build(env, prefix=None, ext_dir=None, sp_dir=None):
  """
  Remove configured modules from site-packages directory

  Parameters
  ----------
    env: libtbx.env_config.environment
      The libtbx environment
    prefix: str
      The destination $PREFIX directory
    ext_dir: str
      The destination directory for Python extensions
    sp_dir: str
      The destination site-pacakges directory

  Returns
  -------
    Nothing
  """

  # ---------------------------------------------------------------------------
  def loop_remove(dst_path, name, filenames):
    """
    Convenience function for looping over files to remove
    """
    print('Removing ' + name)
    print('-'*79)
    for src in filenames:
      src = os.path.join(dst_path, src)
      if os.path.exists(src):
        print('  source: ' + src)
        remove_cmd(src)
      else:
        print('  {src} not found.'.format(src=src))
    print('Done')
    print()
  # ---------------------------------------------------------------------------

  old_cwd = os.getcwd()

  # binaries and headers
  # ---------------------------------------------------------------------------
  for name, name_dir in [('binaries', 'exe_dev'), ('headers', 'include')]:
    src_path = os.path.join(abs(env.build_path), name_dir)
    if name_dir == 'exe_dev':
      name_dir = 'bin'
    dst_path = os.path.join(prefix, name_dir)
    filenames = os.listdir(src_path)
    loop_remove(dst_path, name, filenames)
  src_path = abs(env.build_path)
  dst_path = os.path.join(prefix, 'bin')
  os.chdir(src_path)
  all_names = glob.iglob('*/exe/*')
  module_names = set()
  for name in all_names:
    split_name = name.split(os.sep)
    module_names.add(split_name[0])
  for module_name in module_names:
    src_path = os.path.join(abs(env.build_path), module_name, 'exe')
    filenames = os.listdir(src_path)
    loop_remove(dst_path, '{} binaries'.format(module_name), filenames)

  # libraries
  # ---------------------------------------------------------------------------
  src_path = os.path.join(abs(env.build_path), 'lib')
  dst_path = os.path.join(prefix, 'lib')
  os.chdir(src_path)
  all_names = glob.glob('lib*') \
              + [f for f in glob.glob('*.lib') if not f.endswith('_ext.lib')]
  lib_names = []
  for name in all_names:
    lib_names.append(name)
  loop_remove(dst_path, 'libraries', lib_names)

  # extensions
  # ---------------------------------------------------------------------------
  dst_path = ext_dir
  all_names = glob.iglob('*ext.*')
  ext_names = []
  for name in all_names:
    ext_names.append(name)
  loop_remove(dst_path, 'Python extensions', ext_names)

  # .egg-info directories
  # ---------------------------------------------------------------------------
  dst_path = sp_dir
  egg_names = glob.iglob('libtbx*egg-info')
  loop_remove(dst_path, 'egg-info directories', egg_names)

  # extra build stuff
  # ---------------------------------------------------------------------------
  share_dir = os.path.join(prefix, 'share', 'cctbx')
  directory_names = []
  for module in env.module_list:
    directory_names += module.names_active()
  loop_remove(share_dir, 'extra build directories', directory_names)

  os.chdir(old_cwd)

# =============================================================================
def remove_modules(env, sp_dir=None):
  """
  Remove configured modules from site-packages directory

  Parameters
  ----------
    env: libtbx.env_config.environment
      The libtbx environment
    sp_dir: str
      The destination site-packages directory

  Returns
  -------
    Nothing
  """

  # load original libtbx_env
  if os.getenv('LIBTBX_BUILD') is None:
    raise RuntimeError('''\
The libtbx_env file must be in the original location specified \
by the LIBTBX_BUILD environment variable''')
  import libtbx.load_env
  env = libtbx.env

  for module in env.module_dict:
    src = os.path.join(sp_dir, module)
    cmd = 'Deleting'
    if os.path.islink(src):
      cmd = 'Unlinking'
    print(cmd + ' ' + module)
    print('-'*79)
    for name in [module, module + '_' + env.module_dict[module].mate_suffix]:
      src = os.path.join(sp_dir, name)
      if os.path.exists(src):
        print('  ' + src)
        remove_cmd(src)
      else:
        print('  {name} not found'.format(name=name))

    # extra stuff
    for module_name, extra_stuff in [
      ('elbow', 'yacc.py'),
      ('elbow', 'resources'),
      ('phenix', 'wxGUI2'),
      ('phaser_voyager', 'New_Voyager'),
      ('phaser_voyager', 'Voyager'),
      ]:
      if module == module_name:
        src = os.path.join(sp_dir, extra_stuff)
        if os.path.exists(src):
          print('  ' + src)
          remove_cmd(src)

    print('Done')
    print()

# =============================================================================
def run():
  parser = argparse.ArgumentParser(description=__doc__,
    formatter_class=argparse.RawDescriptionHelpFormatter)

  default_sys_prefix = sys.prefix
  if sys.platform == 'darwin' and 'python.app' in default_sys_prefix:
    default_sys_prefix = default_sys_prefix.split('python.app')[0]
  default_sys_prefix = os.path.abspath(default_sys_prefix)
  default_sp_dir = None
  default_lib_dynload_dir = None
  for p in sys.path:
    if default_sp_dir is None \
      and p.startswith(default_sys_prefix) \
      and p.endswith('site-packages'):
      default_sp_dir = p
    if default_lib_dynload_dir is None \
      and p.startswith(default_sys_prefix) \
      and p.endswith('lib-dynload'):
      default_lib_dynload_dir = p

  parser.add_argument(
    '--prefix', default=default_sys_prefix, type=str,
    help="""The $PREFIX location, by default the directory is the sys.prefix
      location of the calling python.""")
  parser.add_argument(
    '--sp-dir', '--sp_dir', default=default_sp_dir, type=str,
    help="""The location where the modules will be installed, by default
      the directory is the site-packages location of the calling python.""")
  parser.add_argument(
    '--ext-dir', '--ext_dir', default=default_lib_dynload_dir, type=str,
    help="""The location where the Python extensions will be installed, by
      default the directory is the lib-dynload location of the calling python.""")
  parser.add_argument('--preserve-egg-dir', '--preserve_egg_dir', action='store_true',
    help="""When set, the egg and egg-info directories are copied as well.""")
  parser.add_argument(
    '--fix-rpath', '--fix_rpath', action='store_true',
    help="""When set, the relative paths are fixed for library and extension
      files. NOT IMPLEMENTED YET""")
  parser.add_argument(
    '--link', action='store_true',
    help="""When set, instead of copying, symbolic links are created
      for directories and files.""")
  parser.add_argument(
    '--clean', action='store_true',
    help="""When set, directories and files are removed from the $PREFIX.""")

  namespace = parser.parse_args()

  # load original libtbx_env
  if os.getenv('LIBTBX_BUILD') is None:
    raise RuntimeError('''\
The libtbx_env file must be in the original location specified \
by the LIBTBX_BUILD environment variable''')
  import libtbx.load_env
  env = libtbx.env

  # copy or clean
  if namespace.clean:
    remove_build(env, prefix=namespace.prefix, ext_dir=namespace.ext_dir,
                 sp_dir=namespace.sp_dir)
    remove_modules(env, sp_dir=namespace.sp_dir)
  else:
    copy_build(env, prefix=namespace.prefix, ext_dir=namespace.ext_dir,
               sp_dir=namespace.sp_dir, copy_egg=namespace.preserve_egg_dir,
               link=namespace.link)
    copy_modules(env, sp_dir=namespace.sp_dir, link=namespace.link)

  if namespace.fix_rpath:
    raise NotImplementedError

  return 0

# =============================================================================
if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/conda_build/update_libtbx_env.py
"""
Script to copy and update libtbx_env contents

Usage: libtbx.python update_libtbx_env.py
"""
from __future__ import absolute_import, division, print_function

import argparse
import os
import shutil
import sys

from libtbx.path import absolute_path

# =============================================================================
def get_prefix_dir():
  '''
  Function that returns $PREFIX or sys.prefix

  Parameters
  ----------
    None

  Returns
  -------
    path to prefix
  '''
  prefix_dir = os.getenv('PREFIX')
  if prefix_dir is None:
    prefix_dir = sys.prefix
  if sys.platform == 'darwin':
    if 'python.app' in prefix_dir:
      prefix_dir = prefix_dir.split('python.app')[0]
  elif sys.platform == 'win32':
    prefix_dir = os.path.join(prefix_dir, 'Library')

  return prefix_dir

# =============================================================================
def get_default_dir():
  '''
  Function that returns the default location of libtbx_env in an installation.
  The default location is ${PREFIX}/share/cctbx

  Parameters
  ----------
    None

  Returns
  -------
    path of the default location
  '''
  prefix_dir = get_prefix_dir()
  default_dir = os.path.join(prefix_dir, 'share', 'cctbx')

  return default_dir

# =============================================================================
def copy_libtbx_env(default_dir=None):
  '''
  Function that copies libtbx_env from $LIBTBX_BUILD to $PREFIX
  If $LIBTBX_BUILD is not set, no copy is done. If libtbx_env does not
  exist, an IOError is raised.

  Parameters
  ----------
    default_dir: str
      The directory to copy libtbx_env

  Returns
  -------
    path or None: if the file is copied, the newly created path is returned
  '''
  value = None
  if default_dir is None:
    default_dir = get_default_dir()
  if os.getenv('LIBTBX_BUILD') is not None:
    src = os.path.join(os.getenv('LIBTBX_BUILD'), 'libtbx_env')
    dst = os.path.join(default_dir, 'libtbx_env')
    if not os.path.isfile(src):
      raise IOError(
        'The "libtbx_env" file does not exist in {src}.'.format(src=src))
    if not os.path.exists(default_dir):
      # assumes that only the last level needs to be created.
      os.mkdir(default_dir)
    value = shutil.copy(src, dst)
  return value

# =============================================================================
def update_libtbx_env(default_dir=None):
  '''
  Function that updates libtbx_env so that modules can be loaded from
  standard locations in $PREFIX

  Parameters
  ----------
    default_dir: str
    The directory to copy libtbx_env

  Returns
  -------
    None
  '''

  # unset LIBTBX_BUILD and load libtbx_env from $PREFIX
  if os.getenv('LIBTBX_BUILD') is not None:
    del os.environ['LIBTBX_BUILD']
  import libtbx.load_env

  if default_dir is None:
    default_dir = get_default_dir()

  sys_prefix = get_prefix_dir()

  # basic path changes
  env = libtbx.env
  env.build_path = absolute_path(sys_prefix)
  env.set_derived_paths()
  env.exe_path = env.bin_path
  env.pythonpath = list()
  sys_executable = sys.executable
  if sys.platform == 'darwin' and 'python.app' not in sys_executable:
    sys_executable = os.path.join(sys_prefix, 'python.app', 'Contents', 'MacOS', 'python')
  env.python_exe = env.as_relocatable_path(sys_executable)
  env.no_bin_python = True
  site_packages_path = None
  for path in sys.path:
    if path.endswith('site-packages'):
      site_packages_path = env.as_relocatable_path(path)
      break
  relocatable_sys_prefix = env.as_relocatable_path(sys_prefix)
  env.repository_paths = [relocatable_sys_prefix, site_packages_path]
  env.scons_dist_path = relocatable_sys_prefix

  # libtbx.python dispatcher
  env._write_dispatcher_in_bin(
    source_file=env.python_exe,
    target_file='libtbx.python',
    source_is_python_exe=True)

  # update module locations
  if sys.platform == 'win32':
    sys_prefix = get_prefix_dir() # has an extra "Library"
    relocatable_sys_prefix = env.as_relocatable_path(
      os.path.join(sys_prefix, '..', 'Lib', 'site-packages'))
  for name in env.module_dict:
    module = env.module_dict[name]
    new_paths = [relocatable_sys_prefix, relocatable_sys_prefix]
    for path in sys.path:
      check_this_path = path.startswith(sys_prefix)
      if sys.platform == 'win32':
        check_this_path = path.lower().startswith(abs(relocatable_sys_prefix).lower())
      if check_this_path:
        new_path = os.path.join(path, name)
        if os.path.isdir(new_path):
          new_paths[0] = env.as_relocatable_path(new_path)
          new_paths[1] = env.as_relocatable_path(new_path + '_' + module.mate_suffix)
          break
        if module.name == 'boost' and os.path.isdir(os.path.join(path, 'boost_adaptbx')):
          new_paths[1] = env.as_relocatable_path(new_path + '_' + module.mate_suffix)
          break
        if module.name == 'annlib' and os.path.isdir(os.path.join(path, 'annlib_adaptbx')):
          new_paths[0] = None
          new_paths[1] = env.as_relocatable_path(new_path + '_' + module.mate_suffix)
          break
        if module.name == 'phaser_voyager' and os.path.isdir(os.path.join(path, 'New_Voyager')):
          new_paths[0] = env.as_relocatable_path(os.path.join(path, 'New_Voyager'))
          new_paths[1] = None
          break
    dist_paths = module.dist_paths
    for i, path in enumerate(dist_paths):
      if path is not None:
        module.dist_paths[i] = new_paths[i]
    env.module_dist_paths[name] = new_paths[0]
    if name == 'boost':
      env.module_dist_paths[name] = relocatable_sys_prefix / 'include'
    name_adaptbx = name + '_' + module.mate_suffix
    if name_adaptbx in env.module_dist_paths:
      env.module_dist_paths[name_adaptbx] = new_paths[1]

    if name == 'libtbx':
      env.path_utility = env.as_relocatable_path(
        os.path.join(abs(new_paths[0]), 'command_line', 'path_utility.py'))

  # update dispatchers
  env.reset_dispatcher_bookkeeping()
  env.write_python_and_show_path_duplicates()
  for module in env.module_list:
    module.process_command_line_directories()

  # repickle
  env.build_path = absolute_path(default_dir)
  env.installed = True
  env.pickle()

  return 0

# =============================================================================
def run():
  parser = argparse.ArgumentParser(description=__doc__,
    formatter_class=argparse.RawDescriptionHelpFormatter)

  # default location is ${PREFIX}/share/cctbx
  default_dir = get_default_dir()

  parser.add_argument(
    '--default-dir', '--default_dir', default=default_dir, type=str,
    help="""The new default for the location of libtbx_env. By default,
      the new location is ${PREFIX}/share/cctbx. This feature is not
      fully supported yet.""")

  namespace = parser.parse_args()

  copy_libtbx_env(default_dir=namespace.default_dir)
  update_libtbx_env(default_dir=namespace.default_dir)

  return 0

# =============================================================================
if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/conda_build/write_env_files.py
'''
Script for creating the files for setting up a user's environemnt after
running a conda-based installer.
'''
from __future__ import absolute_import, division, print_function

import argparse
import os
import sys

# =============================================================================
# unix files
bash_template = '''\
#!/usr/bin/env bash

export {program}={prefix}
export {program}_PREFIX={prefix}
export {program}_VERSION={version}
export PATH={bin_dir}:$PATH
'''

csh_template = '''\
#!/usr/bin/env csh

setenv {program} {prefix}
setenv {program}_PREFIX {prefix}
setenv {program}_VERSION {version}
setenv PATH {bin_dir}:$PATH
'''

# Windows file
bat_template = '''\
@echo off
set {program}=%~dp0
set {program}_PREFIX=%~dp0
set {program}_VERSION={version}
set PATH={bin_dir};%PATH%
'''

# =============================================================================
def write_files(program=None, prefix=None, bin_dirs=None, version=None,
  destination=None):
  '''
  Populate template with arguments

  Parameters
  ----------
  program : str
      see parser arguments in run()
  prefix : str
      see parser arguments in run()
  bin_dir : str
      see parser arguments in run()
  version : str
      see parser arguments in run()
  destination : str
      see parser arguments in run()
  '''
  if version is None:
    version = ''

  program = program.upper()
  filename = '{program}_env'.format(program=program.lower())
  filename = os.path.join(destination, filename)
  if sys.platform == 'win32':
    with open('.'.join([filename, 'bat']), 'w') as f:
      f.write(bat_template.format(
        program=program,
        prefix=prefix,
        bin_dir=';'.join(bin_dirs),
        version=version
      ))
  else:
    for template, ext in zip((bash_template, csh_template), ('sh', 'csh')):
      with open('.'.join([filename, ext]), 'w') as f:
        f.write(template.format(
          program=program,
          prefix=prefix,
          bin_dir=':'.join(bin_dirs),
          version=version
        ))

# -----------------------------------------------------------------------------
def run():
  parser = argparse.ArgumentParser(description=__doc__,
    formatter_class=argparse.RawDescriptionHelpFormatter)

  default_prefix = os.path.normpath(sys.prefix)
  if sys.platform == 'win32':
    default_bin_dirs = [os.path.join(default_prefix, 'Library', 'bin')]
  default_bin_dirs = [os.path.join(default_prefix, 'bin')]

  parser.add_argument(
    '--program', default='cctbx', type=str,
    help='''The program name for constructing the filenames. For example,
      the filename for bash will be <program>_env.sh. (cctbx)'''
  )
  parser.add_argument(
    '--prefix', default=default_prefix, type=str,
    help='''The $PREFIX location, by default the directory is the sys.prefix
      location of the calling python. ({default_prefix})'''.format(default_prefix=default_prefix)
  )
  parser.add_argument(
    '--bin-dir', default=None, type=str, action='append',
    help='''The location to be added to $PATH, by default it is $PREFIX/bin.
      If the argument is a relative path, it will be appended to the
      --prefix argument. ({default_bin_dirs})'''.format(default_bin_dirs=default_bin_dirs)
  )
  parser.add_argument(
    '--version', default=None, type=str,
    help='''The version to be set (no default)'''
  )
  parser.add_argument(
    '--destination', default=os.getcwd(), type=str,
    help='''The directory to write the output ({destination})'''.format(destination=os.getcwd())
  )

  namespace = parser.parse_args()

  bin_dirs = namespace.bin_dir
  if bin_dirs is None:
    bin_dirs = default_bin_dirs
  for i in range(len(bin_dirs)):
    if not os.path.isabs(bin_dirs[i]):
      bin_dirs[i] = os.path.join(namespace.prefix, bin_dirs[i])
      bin_dirs[i] = os.path.abspath(bin_dirs[i])

  prefix = namespace.prefix
  if not os.path.isabs(prefix):
    prefix = os.path.abspath(prefix)

  try:
    write_files(
      program=namespace.program,
      prefix=prefix,
      bin_dirs=bin_dirs,
      version=namespace.version,
      destination=namespace.destination
    )
  except IOError:
    print('''
There was an issue with writing the files. Please make sure you have
permissions to write to {destination} and that there is enough disk space.
'''.format(destination=namespace.destination))
    raise

# =============================================================================
if __name__ == '__main__':
  sys.exit(run())


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/create_cctbx_bundle_for_installer.py
#!/usr/bin/python

"""
Package the CCTBX bundle used for various installers (Phenix, etc.) using
sources in the specified repositories directory.
"""

from __future__ import absolute_import, division, print_function

import optparse
import os
import os.path as op
import sys
import time

from . import package_defs
from .installer_utils import *

def run(args):
  datestamp = time.strftime("%Y_%m_%d", time.localtime())
  parser = optparse.OptionParser()
  parser.add_option("--tag", dest="tag", action="store",
    help="Bundle identifier", default=datestamp)
  parser.add_option("--ignore-missing", dest="ignore_missing",
    action="store_true", help="Skip missing secondary packages", default=False)
  parser.add_option("--require-all", dest="require_all", action="store_true",
    help="Require all listed packages, even optional ones", default=False)
  parser.add_option("--download", dest="download", action="store_true",
    help="Download any packages not found locally", default=False)
  parser.add_option("--tmp", dest="tmp_dir", action="store",
    help="Temporary directory", default=os.getcwd())
  parser.add_option("--tarfile", dest="tarfile", action="store",
    help="Output tarfile name", default="cctbx_bundle_for_installer.tar.gz")
  parser.add_option("--dest", dest="destination", action="store",
    help="Final destination for tarfile", default=None)
  options, args = parser.parse_args(args)
  if (len(args) == 1):
    repositories = op.abspath(args[0])
  else :
    assert (len(args) == 0)
    repositories = op.dirname(op.dirname(op.dirname(op.dirname(__file__))))
  print("Using '%s' as repository directory" % repositories)
  assert op.isdir(repositories)
  assert (repositories != op.abspath(options.tmp_dir))
  os.chdir(options.tmp_dir)
  if op.exists("cctbx_tmp"):
    shutil.rmtree("cctbx_tmp")
  os.mkdir("cctbx_tmp")
  os.chdir("cctbx_tmp")
  # Packages that are absolutely required for CCTBX installation
  required = [
    "boost",
    "cctbx_project",
    "scons",
  ]
  # Strongly recommended, but not essential
  recommended = [
    "cbflib",
    "ccp4io",
    "ccp4io_adaptbx",
  ]
  # Provided if available, but not especially important
  optional = [
    "gui_resources",
    "tntbx",
    "annlib",
    "annlib_adaptbx",
  ]
  # create tag file
  open("cctbx_bundle_TAG", "w").write(options.tag)
  have_modules = ["cctbx_bundle_TAG"]
  # copy over directories
  for module_name in required :
    module_path = op.join(repositories, module_name)
    tarfile_path = module_path + "_hot.tar.gz"
    if (not op.isdir(module_path)) and (not op.isfile(tarfile_path)):
      if (not options.download):
        raise OSError("Essential module '%s' not found in %s!" % (module_name,
          repositories))
      else :
        package_defs.fetch_remote_package(module_name)
    else :
      copy_dist(module_path, tarfile_path)
    have_modules.append(module_name)
  # recommended modules - can be skipped if necessary
  for module_name in recommended :
    module_path = op.join(repositories, module_name)
    tarfile_path = module_path + "_hot.tar.gz"
    if (not op.isdir(module_path)) and (not op.isfile(tarfile_path)):
      if (options.download):
        package_defs.fetch_remote_package(module_name)
      elif (options.ignore_missing):
        warnings.warn(("Skipping recommended module '%s' (not found in "+
          "repositories directory %s)") % (module_name, repositories))
        continue
      else :
        raise OSError(("Recommended module '%s' not found in %s!  If you want "+
          "to continue without this module, re-run with --ignore-missing.") %
          (module_name, repositories))
    else :
      copy_dist(module_path, tarfile_path)
    have_modules.append(module_name)
  # optional
  for module_name in optional :
    module_path = op.join(repositories, module_name)
    tarfile_path = module_path + "_hot.tar.gz"
    if (not op.isdir(module_path)) and (not op.isfile(tarfile_path)):
      if (options.download):
        package_defs.fetch_remote_package(module_name)
      elif (not options.require_all):
        warnings.warn(("Skipping optional module '%s' (not found in "+
          "repositories directory %s)") % (module_name, repositories))
        continue
      else :
        raise OSError(("Required module '%s' not found in %s!  If you want "+
          "to continue without this module, re-run without --require-all.") %
          (module_name, repositories))
    else :
      copy_dist(module_path, tarfile_path)
    have_modules.append(module_name)
  # create the archive
  call("tar -cvzf %s %s" % (options.tarfile, " ".join(have_modules)),
    log=sys.stdout)
  print("Wrote %s" % options.tarfile)
  if (options.destination is not None):
    assert op.isdir(options.destination)
    if op.exists(op.join(options.destination, options.tarfile)):
      os.remove(op.join(options.destination, options.tarfile))
    shutil.move(options.tarfile, options.destination)
  else :
    if op.exists(op.join(options.tmp_dir, options.tarfile)):
      os.remove(op.join(options.tmp_dir, options.tarfile))
    shutil.move(options.tarfile, options.tmp_dir)
  # cleanup
  os.chdir(options.tmp_dir)
  shutil.rmtree("cctbx_tmp")

def copy_dist(dir_name, file_name):
  if op.isfile(file_name):
    print("Untarring %s..." % file_name)
    call("tar zxf %s" % file_name, log=sys.stdout)
  else :
    print("Copying %s..." % dir_name)
    archive_dist(dir_name, create_tarfile=False)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/create_installer.py
#!/usr/bin/python

"""
Script to set up an installer directory tree and copy over most of the
necessary files.  We used to just keep the entire (Phenix) installer in a
separate SVN tree, but this is inconvenient when we have multiple packages
using the same system and also many third-party dependencies which need to be
kept up to date.  Note that this script provides only the bare minimum
functionality for building CCTBX installers, and other distributions will
probably need to perform additional modifications to the installer tree
before it can be tarred.
"""

from __future__ import absolute_import, division, print_function

import imp
import os
import shutil
import stat
import subprocess
import sys
import tarfile
import time
import zipfile
from optparse import OptionParser

import libtbx.auto_build.rpath

# XXX HACK
libtbx_path = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))
if (not libtbx_path in sys.path):
  sys.path.append(libtbx_path)

INSTALL_SH = """\
#!/bin/bash
if [ -z "$PYTHON_EXE" ]; then
  PYTHON_EXE='/usr/bin/python'
  if [ ! -f $PYTHON_EXE ]; then
    PYTHON_EXE='/usr/bin/python3'
  fi
  if [ -f "/usr/bin/python2.7" ]; then
    PYTHON_EXE='/usr/bin/python2.7'
  elif [ -f "/usr/bin/python2.6" ]; then
    PYTHON_EXE='/usr/bin/python2.6'
  elif [ -f "/usr/bin/python2" ]; then
    PYTHON_EXE='/usr/bin/python2'
  elif [ -f "./conda_base/bin/python" ]; then
    PYTHON_EXE='./conda_base/bin/python'
  fi
fi
$PYTHON_EXE ./bin/install.py $@
"""

BASHRC = """\
#!/bin/bash
export %(env_prefix)s=$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )
export %(env_prefix)s_VERSION=%(version)s
source $%(env_prefix)s/build/setpaths.sh
"""

CSHRC = """\
#!/bin/csh -f
set testpath=($_)
if ("$testpath" != "") then
    set testpath=$testpath[2]
else
    set testpath=$0
endif
set rootdir=`dirname $testpath`
set fullpath=`cd $rootdir && pwd -P`
setenv LIBTBX_BUILD_RELOCATION_HINT $fullpath
setenv %(env_prefix)s $fullpath
setenv %(env_prefix)s_VERSION %(version)s
source $%(env_prefix)s/build/setpaths.csh
"""

def makedirs(path):
  try:
    os.makedirs(path)
  except Exception:
    print("Directory already exists: %s"%path)

def archive(source, destination, tarfile=None):
  if source == destination:
    print("Source and destination are the same, skipping: %s"%source)
    return
  assert not os.path.exists(destination), "File exists: %s"%destination
  print("Copying: %s -> %s"%(source, destination))
  if not os.path.exists(source):
    print("Warning: source does not exist! Skipping: %s"%source)
    return
  try:
    if os.path.basename(source) != 'build': # don't delete lib files from python or modules
      shutil.copytree(
        source,
        destination,
        ignore=shutil.ignore_patterns('*.pyc', '*.pyo', '.svn', '.git', '.swp', '.sconsign', '.o', '*.obj', '*.ilk'),
        symlinks=True
        )
    else:
      shutil.copytree(
        source,
        destination,
        ignore=shutil.ignore_patterns('*.lib', '*.pyc', '*.pyo', '.svn', '.git', '.swp', '.sconsign', '.o', '*.obj', '*.ilk'),
        symlinks=True
        )
  except Exception as err:
    # workaround for possible very long path problem on Windows
    if sys.platform == "win32" and isinstance(err, shutil.Error):
      for e in err[0]:
        if len(e)==3: # if not then it's some other error
          (src, dst, errstr) = e
          # Prepending \\?\ to path tells Windows to accept paths longer than 260 character
          if len(src) > 260 or len(dst) > 260:
            ultdsrc = "\\\\?\\" + src
            ultddst = "\\\\?\\" + dst
            shutil.copy(ultdsrc, ultddst)
    else:
      raise Exception(err)



def tar(source, tarfile, cwd=None):
  assert not os.path.exists(tarfile), "File exists: %s"%tarfile
  print("Archiving: %s -> %s"%(source, tarfile))
  # TODO: replace system call to tar with platform independent python tarfile module
  #mytar = tarfile.open(tarfile, mode="r:gz")
  #mytar.add(source, arcname=tarfile)
  #tar.close()
  environment = os.environ.copy()
  environment['GZIP'] = '-9'
  subprocess.check_call([
      'tar',
      '-cz',
      '-f', tarfile,
      source
    ],
    cwd=cwd, env=environment)

class SetupInstaller(object):
  def __init__(self, **kwargs):
    self.install_script = kwargs.get('install_script')
    self.version = kwargs.get('version')
    self.script = kwargs.get('script')
    #
    self.dest_dir = os.path.abspath(kwargs.get('dest_dir'))
    self.root_dir = os.path.abspath(kwargs.get('root_dir') or os.getcwd())
    self.dist_dir = os.path.abspath(kwargs.get('dist_dir') or os.path.join(self.root_dir, 'dist'))

    self.license = kwargs.get('license')
    if self.license:
      self.license = os.path.abspath(self.license)
    self.readme = kwargs.get('readme') or [os.path.join(libtbx_path, 'COPYRIGHT_2_0.txt')]
    if self.readme:
      self.readme = [os.path.abspath(i) for i in self.readme]

    # Is this a source or binary installer?
    self.binary = kwargs.get('binary')

    # Load the installer class, get the list of modules.
    assert os.path.isfile(self.install_script)
    installer_module = imp.load_source('install_script', self.install_script)
    self.installer = installer_module.installer()

    # check for conda
    self.base_dir = 'base'
    if os.path.isdir(os.path.join(self.root_dir, 'conda_base')):
      self.base_dir = 'conda_base'

  def run(self):
    # Setup directory structure
    print("Installer will be %s"%self.dest_dir)
    assert not os.path.exists(self.dest_dir), "Installer dir exists: %s"%self.dest_dir
    makedirs(self.dest_dir)
    for i in ['bin', 'lib']:
      makedirs(os.path.join(self.dest_dir, i))
    self.copy_info()
    self.write_environment_files()
    self.copy_libtbx()
    self.copy_doc()
    self.copy_modules()
    if self.binary:
      self.copy_dependencies()
      self.copy_build()
    self.fix_permissions()
    self.installer.product_specific_prepackage_hook(directory=self.dest_dir)
    self.make_dist()
    if self.binary and sys.platform == "darwin":
      self.make_dist_pkg()
    if self.binary and sys.platform == "win32":
      if self.base_dir == 'base':
        vcredist = "vcredist_x64.exe"
        import platform
        if int(platform.architecture()[0][0:2]) < 64:
          vcredist = "vcredist_x86.exe"
        shutil.copyfile( os.path.join(self.root_dir, 'base_tmp', vcredist),
                        os.path.join(self.dest_dir, vcredist)
        )
      else:
        vcredist = "vcredist_x64.exe"
        shutil.copyfile(os.path.join(self.root_dir, 'conda_base', vcredist),
                        os.path.join(self.dest_dir, vcredist))
      self.make_windows_installer()

  def copy_info(self):
    # Basic setup #
    def copyfile(src, dest):
      # Introduce Windows line breaks when on Windows by read/write in ascii mode
      if sys.platform == "win32":
        open(dest,'w').write(open(src,'r').read())
      else:
        shutil.copyfile(src, dest)
    # Write VERSION
    with open(os.path.join(self.dest_dir, 'VERSION'), 'w') as f:
      f.write(self.version)
    # Write README
    for i in self.readme:
      copyfile(i, os.path.join(self.dest_dir, os.path.basename(i)))
    # Write LICENSE
    if os.path.isfile(self.license):
      copyfile(self.license, os.path.join(self.dest_dir, 'LICENSE'))
    # Actual Python installer script
    shutil.copyfile(self.install_script, os.path.join(self.dest_dir, 'bin', 'install.py'))
    if sys.platform != "win32":
      # Write executable Bash script wrapping Python script
      if self.base_dir == 'conda_base':
        # avoid conflicts with active conda environment during installation
        global INSTALL_SH
        INSTALL_SH = INSTALL_SH.replace(
          'fi\nfi\n$PYTHON_EXE','fi\nfi\nunset CONDA_PREFIX\n$PYTHON_EXE')
      with open(os.path.join(self.dest_dir, 'install'), 'w') as f:
        f.write(INSTALL_SH)
      st = os.stat(os.path.join(self.dest_dir, "install"))
      os.chmod(os.path.join(self.dest_dir, "install"), st.st_mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)

  def copy_libtbx(self):
    # Copy over libtbx for setup.
    archive(
      os.path.join(libtbx_path),
      os.path.join(self.dest_dir, 'lib', 'libtbx')
    )

  def copy_dependencies(self):
    # try conda-pack for conda_base for better portability
    # https://conda.github.io/conda-pack/
    conda_pack_is_available = False
    if self.base_dir == 'conda_base':
      env = dict()  # clean environment
      env['PATH'] = os.getenv('PATH')
      try:
        output = subprocess.check_output(
          ['conda', 'pack', '-h'],
          stderr=subprocess.STDOUT, env=env)
        conda_pack_is_available = True
      except Exception as e:
        print('Unable to find conda-pack.')
        print(str(e))  # WindowsError or OSError
        if isinstance(e, subprocess.CalledProcessError):
          print(e.output.decode('utf8'))
        print('Fallback to a regular copy.')

      if conda_pack_is_available:
        try:
          filename = 'conda_base.tar'
          output = subprocess.check_output(
            ['conda', 'pack', '--force', '-p', os.path.abspath('conda_base'),
             '-o', filename],
            stderr=subprocess.STDOUT, env=env)
          shutil.copy(os.path.join(self.root_dir, filename),
                      os.path.join(self.dest_dir))
        except Exception as e:
          print('Unable to run conda-pack.')
          print(str(e))  # WindowsError or OSError
          if isinstance(e, subprocess.CalledProcessError):
            print(e.output.decode('utf8'))
          print('Fallback to a regular copy.')
          conda_pack_is_available = False

    # Copy dependencies
    if not conda_pack_is_available:
      archive(
        os.path.join(self.root_dir, self.base_dir),
        os.path.join(self.dest_dir, self.base_dir)
      )
    if self.base_dir == 'base':
      libtbx.auto_build.rpath.run(
        ['--otherroot', os.path.join(self.root_dir, 'base'),
         os.path.join(self.dest_dir, 'base')])

  def copy_build(self):
    # Copy the entire build directory, minus .o files.
    archive(
      os.path.join(self.root_dir, 'build'),
      os.path.join(self.dest_dir, 'build')
    )
    libtbx.auto_build.rpath.run(['--otherroot', os.path.join(self.root_dir, self.base_dir), os.path.join(self.dest_dir, 'build')])

  def copy_modules(self):
    # Source modules #
    for module in set(self.installer.modules):
      archive(
        os.path.join(self.root_dir, 'modules', module),
        os.path.join(self.dest_dir, 'modules', module)
      )
    s = os.path.join(self.root_dir, 'modules', 'RevisionNumbers.txt')
    if os.path.exists(s):
      shutil.copyfile(s, os.path.join(self.dest_dir, 'modules', 'RevisionNumbers.txt'))

  def copy_doc(self):
    # Copy doc
    archive(
      os.path.join(self.root_dir, 'doc'),
      os.path.join(self.dest_dir, 'doc')
    )

  def fix_permissions(self):
    if sys.platform == "win32":
      return
    subprocess.check_call([
      'chmod',
      '-R',
      'u+rw,a+rX',
      self.dest_dir
      ])

  def write_environment_files(self):
    """Generate shell scripts in the top-level installation directory."""
    if sys.platform == "win32":
      return
    if self.install_script:
      print("Not generating environment setup scripts as installer is provided")
      return
    print("Generating %s environment setup scripts..."%self.installer.product_name)
    fmt = {'env_prefix':self.installer.product_name.upper(), 'version':self.version}
    # bash
    with open(os.path.join(self.dest_dir, '%s_env.sh'%self.installer.product_name.lower()), 'w') as f:
      f.write(BASHRC%fmt)
    # tcsh
    with open(os.path.join(self.dest_dir, '%s_env.csh'%self.installer.product_name.lower()), 'w') as f:
      f.write(CSHRC%fmt)

  def make_dist(self):
    makedirs(self.dist_dir)
    if sys.platform == "win32":
# Bake version number into the dispatchers and the help files and create rotarama db
# This is done during installation on other platforms
      from libtbx.auto_build import installer_utils
      python_exe = os.path.join(self.dest_dir,'base','bin','python','python.exe')
      # check for conda
      if self.base_dir == 'conda_base':
        python_exe = os.path.join(self.dest_dir, self.base_dir, 'python.exe')
      arg = [python_exe,
             os.path.join(self.dest_dir,'bin','install.py'), '--nopycompile']
      installer_utils.call(arg, cwd=self.dest_dir)

      print("Creating zip archive of distribution")
      fname = os.path.join(self.dist_dir, '%s.zip'%os.path.basename(self.dest_dir))
      myzip = zipfile.ZipFile(fname, 'w', zipfile.ZIP_DEFLATED, allowZip64=True )
      for dirpath,dirs,files in os.walk(self.dest_dir):
        for f in files:
          fname = os.path.join(dirpath, f)
          relfname = os.path.relpath(fname, os.path.join(os.getcwd(), "tmp"))
          # Prepending \\?\ to path tells Windows to accept paths longer than 260 character
          if len(fname) >= 260:
            fname = "\\\\?\\" + fname
          if len(relfname) >= 260:
            relfname = "\\\\?\\" + relfname
          myzip.write(filename=fname, arcname=relfname)
      myzip.close()
    else:
      print("Creating tar archive of distribution")
      tar(
        os.path.basename(self.dest_dir),
        os.path.join(self.dist_dir, '%s.tar.gz'%os.path.basename(self.dest_dir)),
        cwd=os.path.join(self.dest_dir, '..')
      )

  def make_dist_pkg(self):
    if (not os.access("/Applications", os.W_OK|os.X_OK)):
      print("Can't access /Applications - skipping .pkg build")
      return

    # This has to match other conventions...
    pkg_prefix = "/Applications"
    app_root_dir = os.path.join(pkg_prefix,
                                '%s-%s'%(self.installer.dest_dir_prefix,
                                         self.version))
    #app_root_dir = os.path.join(pkg_prefix,
    #                            '%s '% (self.installer.dest_dir_prefix))
    if os.path.exists(app_root_dir): shutil.rmtree(app_root_dir)
    subprocess.check_call([
      os.path.join(self.dest_dir, 'install'),
      '--prefix', pkg_prefix,
    ], cwd=self.dest_dir)

    # fix SSL_CERT_FILE location in dispatchers
    # command-line installation step (above) is using the location from the
    # current python, not the one in the newly installed location.
    # command-line installation works correctly outside of this script, though.
    try:
      import certifi
      from libtbx.auto_build.install_base_packages import installer
      file_list = os.listdir(os.path.join(app_root_dir, 'build', 'bin'))
      for filename in file_list:
        patch = '"$LIBTBX_BUILD/../base/Python.framework/Versions/2.7/lib/python2.7/site-packages/certifi/cacert.pem"'
        if self.base_dir == 'conda_base':
          patch = '"$LIBTBX_BUILD/../conda_base/lib/python2.7/site-packages/certifi/cacert.pem"'
        installer.patch_src(
          os.path.join(app_root_dir,'build', 'bin', filename),
          '"%s"' % certifi.where(),
          patch
        )
    except ImportError:
      pass

    tmp = os.path.join(self.root_dir, 'tmp')
    makedirs(tmp)
    makedirs(self.dist_dir)
    os.chdir(tmp) # UGH X 1000.
    from libtbx.auto_build import create_mac_pkg
    create_mac_pkg.run(args=[
        "--package_name", self.installer.product_name,
        "--organization", self.installer.organization,
        "--version", self.version,
        "--license", self.license,
        "--dist-dir", self.dist_dir,
        #"--no_compress",
        app_root_dir
    ])


  def make_windows_installer(self):
    makedirs(self.dist_dir)
    from libtbx.auto_build import create_windows_installer
    mainscript = os.path.join(self.dest_dir, "lib","libtbx",
                                "auto_build", "mainphenixinstaller.nsi")
    create_windows_installer.run(args=[
      "--productname", self.installer.product_name,
      "--version", self.version,
      "--company", self.installer.organization,
      "--website", "http://www.phenix-online.org/",
      "--sourcedir", os.path.basename(self.dest_dir),
      "--tmpdir", os.path.normpath(os.path.join(self.dist_dir, "..", "..","tmp")), # location of sourcedir
      "--outdir", self.dist_dir,
      "--mainNSISscript", mainscript
    ])


def run(args):
  parser = OptionParser()
  parser.add_option("--version", dest="version", action="store",
    help="Package version", default=time.strftime("%Y_%m_%d",time.localtime()))
  parser.add_option("--binary", dest="binary", action="store_true",
    help="Include base and build directories", default=False)
  parser.add_option("--root_dir", dest="root_dir", action="store",
    help="Environment root")
  parser.add_option("--dist_dir", dest="dist_dir", action="store",
    help="Archive output directory")
  parser.add_option("--readme", dest="readme", action="append",
    help="Readme file", default=[])
  parser.add_option("--license", dest="license", action="store",
    help="License file", default=os.path.join(libtbx_path, "LICENSE_2_0.txt"))
  parser.add_option("--install_script", dest="install_script",
    help="Final installation script", default=None, metavar="FILE")
  options, args_ = parser.parse_args(args=args)
  assert len(args_) == 1, "Destination directory required argument."
  setup = SetupInstaller(
    dest_dir=args_[0],
    root_dir=options.root_dir,
    dist_dir=options.dist_dir,
    version=options.version,
    readme=options.readme,
    license=options.license,
    install_script=options.install_script,
    binary=options.binary,
  )
  setup.run()


if (__name__ == "__main__"):
  sys.exit(run(sys.argv[1:]))


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/create_mac_app.py

# XXX this module is designed to be run independently of the rest of CCTBX if
# necessary, although it will use installed resources if found

from __future__ import absolute_import, division, print_function

import optparse
import os
import re
import shutil
import sys

try :
  import libtbx.load_env
# can be either ImportError or SyntaxError, depending on whether we're using
# the bundled Python version or something more ancient
except Exception:
  libtbx_env = None
else :
  libtbx_env = libtbx.env

def run(args, out=sys.stdout):
  if (sys.platform != "darwin"):
    print("This application will only run on Mac systems.", file=out)
    return 1
  parser = optparse.OptionParser(
    description="Utility for creating an iconified Mac launcher for the specified command, which must be present in $LIBTBX_BUILD/bin.")
  bin_path = icns_path = None
  if (libtbx_env is not None):
    bin_path = os.path.join(abs(libtbx_env.build_path), "bin")
    icns_path = libtbx_env.find_in_repositories(
      relative_path="gui_resources/icons/custom/phenix.icns",
      test=os.path.exists)
  parser.add_option("--bin_dir", dest="bin_dir", action="store",
    help="Directory containing target executable.", default=bin_path)
  parser.add_option("--app_name", dest="app_name", action="store",
    help="Name of iconified program", default=None)
  parser.add_option("--icon", dest="icon", action="store",
    help="Path to .icns file", default=icns_path)
  parser.add_option("--dest", dest="dest", action="store",
    help="Destination path", default=os.getcwd())
  parser.add_option("--alias_build", dest="alias_build", action="store_true",
    help="Generate alias build without Python interpreter", default=False)
  parser.add_option("--python_interpreter", dest="python_interpreter",
    action="store", help="Python interpreter to use for final app",
    default=None)
  parser.add_option("--extra_lines", dest="extra_lines", action="store",
    help="Extra line(s) to be added to the Python script that is run",
    default="")
  options, args = parser.parse_args(args)
  if (len(args) == 0):
    return parser.error("Executable name not specified.")
  if (options.bin_dir is None):
    return parser.error("Executables directory not specified.")
  program_name = args[-1]
  build_dir = abs(libtbx.env.build_path)
  bin_dir = os.path.join(build_dir, "bin")
  if libtbx.env.installed:
    bin_dir = abs(libtbx.env.bin_path)
  if (not program_name in os.listdir(bin_dir)):
    print("No program named '%s' found in %s." % (program_name,
      bin_dir), file=out)
    return 1
  try :
    import py2app.script_py2applet
  except ImportError:
    print("py2app not installed.", file=out)
    return 1
  app_name = program_name
  if (options.app_name is not None):
    app_name = options.app_name
  py2app_bin_dir = "py2app_tmp"
  if (options.alias_build):
    py2app_bin_dir = os.path.join("py2app_bin", app_name)
  if (os.path.isdir(py2app_bin_dir)):
    shutil.rmtree(py2app_bin_dir)
  os.makedirs(py2app_bin_dir)
  os.chdir(py2app_bin_dir)
  f = open("%s.py" % app_name, "w")
  f.write("""
import os
import sys
os.environ["PYTHONPATH"] = ""
%s
os.spawnv(os.P_NOWAIT, "%s", ["%s"])
""" % (options.extra_lines, os.path.join(bin_dir, program_name), app_name))
  f.close()
  script_name = re.sub(".pyc$", ".py", py2app.script_py2applet.__file__)
  import subprocess
  executable = sys.executable
  if (options.python_interpreter is not None):
    executable = options.python_interpreter
  elif (libtbx_env is not None):
    executable = abs(libtbx.env.python_exe)
  try :
    args = [executable, "-c", "'import py2app'"]
    rc = subprocess.call(args)
    if (rc != 0) : raise RuntimeError("oops!")
  except RuntimeError :
    print("py2app not available, aborting .app creation.", file=out)
    return 1
  args = [executable, script_name, "--make-setup", "%s.py" % app_name]
  if (options.icon is not None):
    args.append(options.icon)
  rc = subprocess.call(args)
  if (rc != 0):
    return rc
  args = [executable, "setup.py", "py2app"]
  if (options.alias_build):
    args.append("-A")
  rc = subprocess.call(args)
  if (rc != 0):
    return rc
  app_path = os.path.abspath(os.path.join("dist", "%s.app" % app_name))
  assert os.path.isdir(app_path), app_path
  os.chdir(options.dest)
  if (os.path.exists("%s.app" % app_name)):
    shutil.rmtree("%s.app" % app_name)
  shutil.move(app_path, os.getcwd())
  print("Created %s" % os.path.join(os.getcwd(), "%s.app" % app_name), file=out)
  return 0

if (__name__ == "__main__"):
  sys.exit(run(sys.argv[1:]))


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/create_mac_pkg.py

"""
Create a graphical Mac installer for a complete installation of CCTBX or
Phenix (or any other derived software).
"""

from __future__ import absolute_import, division, print_function

import os
import os.path as op
import shutil
import sys
import time
from optparse import SUPPRESS_HELP, OptionParser

from .installer_utils import *

# XXX HACK
libtbx_path = op.abspath(op.dirname(op.dirname(__file__)))
if (not libtbx_path in sys.path):
  sys.path.append(libtbx_path)

def run(args, out=sys.stdout):
  if (sys.platform != "darwin"):
    print("ERROR: this program can only be run on Macintosh systems.")
    return False
  # XXX this prevents tar on OS X from including resource fork files, which
  # break the object relocation.  thanks to Francis Reyes for pointing this out.
  os.environ["COPYFILE_DISABLE"] = "true"
  datestamp = time.strftime("%Y-%m-%d", time.localtime())
  parser = OptionParser()
  parser.add_option("--tmp_dir", dest="tmp_dir", action="store",
    help="Temporary (staging) directory", default=os.getcwd())
  parser.add_option("--dist-dir", dest="dist_dir", action="store",
    help="Distribution directory", default="dist")
  parser.add_option("--package_name", dest="package_name", action="store",
    help="Package name", default="CCTBX")
  parser.add_option("--version", dest="version", action="store",
    help="Software version", default=datestamp)
  parser.add_option("--license_file", dest="license_file", action="store",
    help="License file", default=None)
  parser.add_option("--background", dest="background", action="store",
    help="Background image", default=None)
  parser.add_option("--organization", dest="organization", action="store",
    help="Organization (domain name)", default="org.phenix-online")
  parser.add_option("--machine_type", dest="machine_type", action="store",
    help="Machine type (OS/architecture)", default=machine_type())
  parser.add_option("--overwrite", dest="overwrite", action="store_true",
    help="Overwrite temporary files")
  parser.add_option("--no_compression", dest="no_compression",
    action="store_true", help=SUPPRESS_HELP) # legacy parameter
    # .pkg files are already compressed. Double-compressing is pointless.
  options, args = parser.parse_args(args)
  arch_type = os.uname()[-1]
  system_type = "64-bit Intel Macs"
  if (arch_type != "x86_64"):
    system_type = "Intel Macs"
  system_type += " (OS %s or later)" % get_os_version()
  if (len(args) != 1):
    print("Usage: create_mac_pkg [options] PROGRAM_DIR")
    return False
  program_dir = args[0]
  if (not program_dir.startswith("/")):
    print("ERROR: absolute path required")
    return False
  if (not op.isdir(program_dir)):
    print("ERROR: '%s' is not a directory" % program_dir)
    return False
  dest_name = op.dirname(program_dir)
  if (dest_name == "/Applications"):
    dest_name = "the Applications folder"
  pkg_root = "pkg_root"
  if (op.exists(pkg_root)):
    if (not options.overwrite):
      print("ERROR: pkg_root already exists - run with --overwrite to ignore")
      return False
    shutil.rmtree(pkg_root)
  os.mkdir(pkg_root)

  base_name = "%s-%s" % (options.package_name.lower(), options.version)
  base_pkg = "%s.pkg"%base_name
  pkg_name = os.path.join(options.dist_dir, "%s-%s.pkg" %(base_name, options.machine_type))
  pkg_id = "%s.%s" % (options.organization, base_name)
  os.mkdir("resources")
  welcome = open("resources/welcome.txt", "w")
  welcome.write("""\
This package contains %(package)s version %(version)s compiled for %(arch)s. \
It will install the full command-line suite and graphical launcher(s) \
to %(dest_name)s.  If you need to install %(package)s to a different \
location, you must use the command-line installer (also available from \
our website).""" % { "package" : options.package_name,
                     "version" : options.version,
                     "arch"    : system_type,
                     "dest_name" : dest_name })
  # identify .app bundles in top-level directory
  app_bundle_xml = []
  for file_name in os.listdir(program_dir):
    if (file_name.endswith(".app")):
      full_path = op.join(program_dir, file_name)
      if (not op.isdir(full_path)) : continue
      app_bundle_xml.append("""\
  <dict>
    <key>BundleHasStrictIdentifier</key>
    <true/>
    <key>BundleIsRelocatable</key>
    <true/>
    <key>BundleIsVersionChecked</key>
    <true/>
    <key>BundleOverwriteAction</key>
    <string>upgrade</string>
    <key>RootRelativeBundlePath</key>
    <string>%s</string>
  </dict>
""" % full_path[1:])
  plist_file = "%s.plist" % options.package_name
  plist = open(plist_file, "w")
  plist.write("""\
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<array>
%s
</array>
</plist>
""" % "\n".join(app_bundle_xml))
  plist.close()
  # move directory
  # XXX os.path.relpath behavior is not consistent between Python versions -
  # the behavior we need here was not introduced until 2.7.  Since the program
  # directory is assumed to be absolute, we just chop off the leading '/'.
  rel_path = op.dirname(program_dir)[1:]
  pkg_path = op.join("pkg_root", rel_path)
  os.mkdir(pkg_path)
  shutil.move(program_dir, pkg_path)
  # write out distribution.xml
  misc_files = []
  if (options.background is not None):
    if (options.background.endswith(".jpg")):
      shutil.copyfile(options.background, "resources/background.jpg")
      misc_files.append(
        """<background file="background.jpg" mime-type="image/jpeg" """+
        """alignment="topleft" scaling="proportional"/>""")
    else :
      assert options.background.endswith(".png")
      shutil.copyfile(options.background, "resources/background.png")
      misc_files.append(
        """<background file="background.png" mime-type="image/png" """+
        """alignment="topleft" scaling="proportional"/>""")
  if (options.license_file is not None):
    shutil.copyfile(options.license_file, "resources/license.txt")
    misc_files.append(
      """<license    file="license.txt"    mime-type="text/plain" />""")
  distfile = open("distribution.xml", "w")
  distfile.write("""\
<?xml version="1.0" encoding="utf-8" standalone="no"?>
<installer-gui-script minSpecVersion="1">
    <title>%(package)s %(version)s</title>
    <organization>%(org)s</organization>
    <domains enable_localSystem="true"/>
    <options customize="never" require-scripts="true" rootVolumeOnly="true" />
    <!-- Define documents displayed at various steps -->
    <welcome    file="welcome.txt"    mime-type="text/plain" />
    %(misc_files)s
    <pkg-ref id="%(pkg_id)s"
             version="0"
             auth="root">%(base_pkg)s</pkg-ref>
    <choices-outline>
        <line choice="%(pkg_id)s"/>
    </choices-outline>
    <choice
        id="%(pkg_id)s"
        visible="false"
        title="%(package)s"
        description="%(package)s"
        start_selected="true">
      <pkg-ref id="%(pkg_id)s"/>
    </choice>
</installer-gui-script>
""" % { "package"  : options.package_name,
        "version"  : options.version,
        "pkg_id"   : pkg_id,
        "base_pkg" : base_pkg,
        "org"      : options.organization,
        "misc_files" : "\n".join(misc_files) })
  distfile.close()

  print("Fixing package permissions:", pkg_root, file=out)
  call(['chmod','-R','0755',pkg_root])

  # Run packaging commands
  pkg_args = [
    "pkgbuild",
    "--ownership", "recommended",
    "--root", "pkg_root",
    "--identifier", pkg_id,
    "--component-plist", plist_file,
    base_pkg,
  ]
  print("Calling pkgbuild:", pkg_args, file=out)
  call(pkg_args, out)
  product_args = [
    "productbuild",
    "--distribution", "distribution.xml",
    "--resources", "resources",
    "--package-path", ".",
    "--version", options.version,
    pkg_name,
  ]
  print("Calling productbuild:", product_args, file=out)
  call(product_args, out)
  assert op.exists(pkg_name)
  return True

if (__name__ == "__main__"):
  if (not run(sys.argv[1:])):
    sys.exit(1)


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/create_windows_exe.py
"""
This module is deprecated and no longer used as of Phenix Version 1.10.1-2155
where create_windows_installer.py supersedes it to invoke creating a NullSoft setup installer
"""


# XXX like the Mac equivalent, this module is designed to be run independently
# of the rest of CCTBX if necessary, although it will use installed resources
# if found

from __future__ import absolute_import, division, print_function
try :
  import libtbx.load_env
  libtbx_env = libtbx.env
except ImportError:
  libtbx_env = None
import optparse
import shutil
import stat
import os
import sys

def run(args, out=sys.stdout):
  if (sys.platform != "win32"):
    print("This application will only run on Windows systems.", file=out)
    return 1
  parser = optparse.OptionParser(
    description="Utility for creating an iconified Windows launcher for the specified command, which must be present in %LIBTBX_BUILD%\\bin.")
  bin_path = icns_path = None
  if (libtbx_env is not None):
    bin_path = os.path.join(abs(libtbx_env.build_path), "bin")
    ico_path = libtbx_env.find_in_repositories(
      relative_path="gui_resources/icons/custom/WinPhenix.ico",
      test=os.path.exists)
  else :
    bin_path = os.getcwd()
  parser.add_option("--bin_dir", dest="bin_dir", action="store",
    help="Directory containing target executable or batch script.",
    default=bin_path)
  parser.add_option("--exe_name", dest="exe_name", action="store",
    help="Name of iconified program", default=None)
  parser.add_option("--icon", dest="icon", action="store",
    help="Path to .ico file", default=ico_path)
  parser.add_option("--dest", dest="dest", action="store",
    help="Destination path", default=os.getcwd())
  parser.add_option("--bundle_all", dest="bundle_all", action="store_true",
    help="Bundle Python interpreter, etc. into .exe", default=False)
  options, args = parser.parse_args(args)
  if (len(args) == 0):
    return parser.error("Executable name not specified.")
  if (options.bin_dir is None):
    return parser.error("Executables directory not specified.")
  program_name = args[-1]
  bin_dir = options.bin_dir
  bin_files = os.listdir(bin_dir)
  program_cmd_file = None
  for file_name in bin_files :
    base, ext = os.path.splitext(file_name)
    if (base == program_name):
      if (ext == ".bat") : # preferred
        program_cmd_file = file_name
        break
      elif (ext == ".exe"):
        program_cmd_file = file_name
  if (program_cmd_file is None):
    print("No program named '%s' found in %s." % (program_name,
      bin_dir), file=out)
    return 1
  exe_name = program_name
  if (options.exe_name is not None):
    exe_name = options.exe_name
  if (os.path.isdir("py2exe_tmp")):
    shutil.rmtree("py2exe_tmp")
  os.mkdir("py2exe_tmp")
  os.chdir("py2exe_tmp")
  f = open("%s.py" % exe_name, "w")
  # XXX for reasons unknown to me, the method used on Mac (os.spawnv) will
  # not work for windows, but subprocess.call appears to do the job nicely,
  # with the minor complaint that it leaves the phenix.exe command running
  # (and visible in the taskbar) until the actual app closes.
  f.write("""
import subprocess
subprocess.call(r"%s")
""" % os.path.join(bin_dir, program_cmd_file))
  f.close()
  bundle_files = 3
  #zip_file = "'%s.zip'" %
  if (options.bundle_all):
    bundle_files = 1 # won't work on win64
    zip_file = None
  icon_rsrc = ""
  if (options.icon is not None):
    icon_rsrc = "'icon_resources':[(0,r'%s')]," % options.icon
  f2 = open("setup.py", "w")
  f2.write("""
from distutils.core import setup
import py2exe
setup(
  console=[
    {
      'script':'%s.py',
      %s
    },
  ],
  zipfile=None,
  options={
    'py2exe': {
       'includes': ['subprocess'],
       'dll_excludes' : ['w9xpopen.exe'],
       'bundle_files': %d,
    },
  })
""" % (exe_name, icon_rsrc, bundle_files))
  f2.close()
  # XXX use sys.executable to avoid -Qnew behavior (crashes py2exe)
  import subprocess
  rc = subprocess.call([sys.executable, "setup.py", "py2exe"])
  if (rc != 0):
    return rc
  dist_path = os.path.join(os.getcwd(), "dist")
  dist_files = os.listdir(dist_path)
  exe_file = os.path.join(dist_path, "%s.exe" % exe_name)
  assert (os.path.isfile(exe_file))
  os.chdir(options.dest)
  print("", file=out)
  for file_name in dist_files :
    if os.path.exists(file_name):
      print("WARNING: %s already exists" % file_name, file=out)
      continue
      # XXX Even for Windows, this is incredibly broken
      #full_path = os.path.join(options.dest, file_name)
      #print "removing %s" % file_name
      #subprocess.call("del /F /Q %s" % os.path.join(os.getcwd(), file_name))
      #os.chmod(full_path, stat.S_IWRITE)
      #os.unlink(full_path)
    print("moving %s..." % file_name, file=out)
    shutil.move(os.path.join(dist_path, file_name), os.getcwd())
    os.chmod(file_name, stat.S_IWRITE)
  return 0

if (__name__ == "__main__"):
  sys.exit(run(sys.argv[1:]))


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/create_windows_installer.py
from __future__ import absolute_import, division, print_function

import optparse
import os
import platform
import subprocess
import sys

# Script for compiling a Windows installer using the NSIS compiler which must be present on the PC.
# The main body of the script is immutable and stored in the file named by the mainNSISscript variable
# Just a few custom definitions are prepended to this file which is subsequently compiled as to
# create the Windows installer.



def WriteNSISpreamble(productname="Phenix",
                      version="dev-2015",
                      company="PHENIX Industrial Consortium",
                      website="http://www.phenix-online.org/",
                      sourcedir="phenix-installer-dev-2015-win_7_vc90",
                      tmpdir="tmp", # location of sourcedir
                      mainNSISscript = ""):

  # Makensis only generates a 32bit installer.
  # Such an installer defaults all users program folders to "C:\program files (x86)"
  # regardless of architecture. If we have a 64 bit program we must specify all users program
  # folders to be "C:\program files" according to architecture.
  bitness = platform.architecture()[0][0:2]
  NSIScustomdefs = """

  ; Custom definitions begin
  ; Written by libtbx\\auto_build\\create_windows_installer.WriteNSISpreamble()

  !define PRODUCT_NAME \"%s\"
  !define PRODUCT_VERSION \"%s\"
  !define PRODUCT_PUBLISHER \"%s\"
  !define PRODUCT_WEB_SITE \"%s\"
  !define SOURCEDIR \"%s\"
  !define COPYDIR \"\\\\?\\%s\"
  !define BITNESS %s

  ; Custom definitions end

  """ %(productname, version, company, website, sourcedir, tmpdir, bitness)

  NSISmainbodytext = open(mainNSISscript,"r").read()
  NSISinstallerscript = NSIScustomdefs + NSISmainbodytext
  scriptname = os.path.join(tmpdir,"tmpinstscript.nsi")
  open(scriptname,"w").write(NSISinstallerscript)
  return scriptname


def run(args, out=sys.stdout):
  if (sys.platform != "win32"):
    print("This application will only run on Windows systems.", file=out)
    return 1
  parser = optparse.OptionParser(
    description="Utility for creating a Windows installer for the specified command, which must be present in %LIBTBX_BUILD%\\bin.")

  parser.add_option("--productname", dest="productname", action="store",
    help="Name of program", default="")
  parser.add_option("--versionstring", dest="version", action="store",
    help="version string of program", default="")
  parser.add_option("--company", dest="company", action="store",
    help="company producing the program", default="")
  parser.add_option("--website", dest="website", action="store",
    help="company website", default="")
  parser.add_option("--sourcedir", dest="sourcedir", action="store",
    help="name of source directory of program", default="")
  parser.add_option("--tmpdir", dest="tmpdir", action="store",
    help="location of source directory", default="")
  parser.add_option("--outdir", dest="outdir", action="store",
    help="directory where installer is being written to", default="")
  parser.add_option("--mainNSISscript", dest="mainNSISscript", action="store",
    help="main NSISscript to be prepended by the custom definitions", default="")

  options, args = parser.parse_args(args)
  print("Creating windows installer in", options.outdir)
  logfname = os.path.join(options.outdir, "MakeWindowsInstaller.log")
  print("Writing log file to", logfname)
  #import code, traceback; code.interact(local=locals(), banner="".join( traceback.format_stack(limit=10) ) )
  if options.productname.lower() != "phenix":
    print("There is no NSIS installer script for " + options.productname.lower(), file=out)
    return 1 # currently we only have NSIS installer scripts for Phenix

  scriptname = WriteNSISpreamble(options.productname, options.version,
                    options.company, options.website, options.sourcedir,
                    options.tmpdir, options.mainNSISscript)

  cmd = ["makensis", "/OMakeWindowsInstaller.log", "/NOCD", "/V4", scriptname]
  print("args= ", str(cmd))
  try:
    p = subprocess.Popen(
      cmd,
      cwd=options.outdir,
      stdout=sys.stdout,
      stderr=sys.stderr
    )
  except Exception as e:
    raise e
  p.wait()

  mstr = "\nLast 25 lines of %s:\n\n" %logfname

  import codecs
  try: # unicode version of makensis produces unicode log file
    mfile = codecs.open(logfname, encoding='utf-8', mode="r" )
  except Exception: # not a unicode file if plain version of makensis is used
    mfile = open(logfname, "r" )

  lines = mfile.readlines()
  mfile.close()
  lastlines = lines[(len(lines) - 25): ]
  print(mstr + ''.join(lastlines))

  if p.returncode != 0:
    raise RuntimeError("create_windows_installer() failed with return code %s"%(p.returncode))

  print("Windows installer stored in", options.outdir)



if (__name__ == "__main__"):
  sys.exit(run(sys.argv[1:]))


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/install_base_packages.py

"""
Automated build of CCTBX dependencies for Linux and Mac platforms.
This script will download and install the current Python distribution provided
by LBL, plus any packages required for various CCTBX-dependent apps to
function.  In the future this will be used as the core of the CCI nightly build
system and the Phenix installer.
"""

from __future__ import absolute_import, division, print_function

import os
import os.path as op
import platform
import sys
import time
import zipfile
import subprocess
from optparse import OptionParser

if __name__ == '__main__' and __package__ is None:
  # Cannot use relative imports when run from bootstrap, so add this
  # directory to the path.
  sys.path.append(os.path.dirname(os.path.abspath(__file__)))
  from installer_utils import *
  from package_defs import *
else:
  from .installer_utils import *
  from .package_defs import *

python_dependencies = {"_ssl" : "Secure Socket Library",
                       "zlib" : "XCode command line tools",
                     }

# Turn off user site-packages directory to avoid conflicts
# https://www.python.org/dev/peps/pep-0370/
os.environ['PYTHONNOUSERSITE'] = '1'


class installer(object):
  def __init__(self, args=None, packages=None, log=sys.stdout):
    #assert (sys.platform in ["linux2", "linux3", "darwin"])
    # Check python version >= 2.7 or >= 3.4
    check_python_version()
    self.log = log
    print("""
  ****************************************************************************
                 Automated CCTBX dependencies build script
                 report problems to cctbx-dev@cci.lbl.gov
  ****************************************************************************
""", file=log)
    dist_dir = op.dirname(op.dirname(op.dirname(__file__)))
    parser = OptionParser()
    # Basic options
    parser.add_option("--build_dir", dest="build_dir", action="store",
      help="Build directory", default=os.getcwd())
    parser.add_option("--tmp_dir", dest="tmp_dir", action="store",
      help="Temporary directory",
      default=op.join(os.getcwd(), "base_tmp"))
    parser.add_option("--pkg_dir", dest="pkg_dirs", action="append",
      help="Directory with source packages", default=None)
    parser.add_option("-p", "--nproc", dest="nproc", action="store",
      type="int", help="Number of processors", default=1)
    parser.add_option("-v", "--verbose", dest="verbose", action="store_true",
      help="Verbose output", default=False)
    parser.add_option("--skip-if-exists", action="store_true",
      help="Exit if build_dir/base exists; used with automated builds.")
    parser.add_option("--no-download", dest="no_download", action="store_true",
      help="Use only local packages (no downloads)", default=False)
    parser.add_option("--download-only", dest="download_only", action="store_true",
      help="Only download missing packages, do not compile", default=False)
    parser.add_option("--skip-base", dest="skip_base", action="store",
      help="Comma-separated list of packages to skip", default="")
    parser.add_option("--continue-from", dest="continue_from", action="store",
      help="Skip all packages preceeding this one", default="")
    parser.add_option("--python-shared", dest="python_shared",
      action="store_true", default=False,
      help="Compile Python as shared library (Linux only)")
    parser.add_option("--with-python", dest="with_python",
      help="Use specified Python interpreter")
    parser.add_option("--with-system-python", dest="with_system_python",
      help="Use the system Python interpreter", action="store_true")
    parser.add_option("--python3", dest="python3", action="store_true", default=False,
      help="Install a Python3 interpreter. This is unsupported and purely for development purposes.")
    parser.add_option("--wxpython4", dest="wxpython4", action="store_true", default=False,
      help="Install wxpython4 instead of wxpython3. This is unsupported and purely for development purposes.")
    parser.add_option("--mpi-build", dest="mpi_build", action="store_true", default=False,
      help="Installs software with MPI functionality")
    parser.add_option("-g", "--debug", dest="debug", action="store_true",
      help="Build in debugging mode", default=False)
    # Package set options.
    parser.add_option("--molprobity", dest="molprobity", action="store_true",
      help="Build mmtbx dependencies - like --cctbx without gui dependencies")
    parser.add_option("--cctbx", dest="cctbx", action="store_true",
      help="Build CCTBX dependencies")
    parser.add_option("--phenix", dest="phenix", action="store_true",
      help="Build PHENIX dependencies")
    parser.add_option("--labelit", dest="labelit", action="store_true",
      help="Build LABELIT dependencies")
    parser.add_option("--xia2", dest="xia2", action="store_true",
      help="Build xia2 dependencies")
    parser.add_option("--dials", dest="dials", action="store_true",
      help="Build DIALS dependencies")
    parser.add_option("--gui", dest="build_gui", action="store_true",
      help="Build GUI dependencies")
    parser.add_option("-a", "--all", dest="build_all", action="store_true",
      help="Build all recommended dependencies", default=False)
    # Specific add-on packages.
    parser.add_option("--scipy", dest="build_scipy", action="store_true",
      help="Build SciPy", default=False)
    parser.add_option("--ipython", dest="build_ipython", action="store_true",
      help="Build IPython", default=False)
    parser.add_option("--git-ssh", dest="git_ssh", action="store_true",
      help="Use ssh connections for git. This allows you to commit changes without changing remotes.", default=False)

    # Basic setup.
    options, args = parser.parse_args(args)
    self.nproc = options.nproc
    self.verbose = options.verbose
    self.options = options
    self.include_dirs = []
    self.lib_dirs = []
    self.flag_is_linux = sys.platform.startswith("linux")
    self.flag_is_mac = (sys.platform == "darwin")
    self.cppflags_start = os.environ.get("CPPFLAGS", "")
    self.ldflags_start = os.environ.get("LDFLAGS", "")

    # set default macOS flags
    if (self.flag_is_mac):
      self.min_macos_version = '10.7'
      self.min_macos_version_flag = '-mmacosx-version-min=%s' %\
                                    self.min_macos_version
      self.base_macos_flags = ' -stdlib=libc++ %s' % self.min_macos_version_flag
      self.cppflags_start += self.base_macos_flags
      self.ldflags_start += self.base_macos_flags

    # Compilation flags for CentOS 5 (32-bit)
    if ( (self.flag_is_linux) and (platform.architecture()[0] == '32bit') ):
      old_cflags = os.environ.get('CFLAGS', '')
      os.environ['CFLAGS'] = old_cflags + ' -march=i686'

    # Directory setup.
    self.tmp_dir = options.tmp_dir
    self.build_dir = options.build_dir
    self.pkg_dirs = options.pkg_dirs
    self.base_dir = op.join(self.build_dir, "base")
    self.prefix = "--prefix=\"%s\""%self.base_dir
    if options.skip_if_exists and os.path.exists(self.base_dir) and os.listdir(self.base_dir):
      print("Base directory already exists and --skip-if-exists set; exiting.", file=log)
      return
    print("Setting up directories...", file=log)
    for dir_name in [self.tmp_dir,self.build_dir,self.base_dir]:
      if (not op.isdir(dir_name)):
        print("  creating %s" % dir_name, file=log)
        os.makedirs(dir_name)
    self.check_python_dependencies()

    # Configure package download
    self.fetch_package = fetch_packages(
      dest_dir=self.tmp_dir,
      log=log,
      pkg_dirs=options.pkg_dirs,
      no_download=options.no_download)
    # Shortcut: Extract HDF5 and python for Windows bundled with all preinstalled modules
    if sys.platform == "win32":
      if platform.architecture()[0] == '64bit':
        winpythonpkg = WIN64PYTHON_PKG
        hdf5pkg = WIN64HDF5_PKG
        vcredist = VCREDIST64
        libtiff = WINLIBTIFF64
      else:
        winpythonpkg = WIN32PYTHON_PKG
        hdf5pkg = WIN32HDF5_PKG
        vcredist = VCREDIST32
        libtiff = WINLIBTIFF32

      self.fetch_package(pkg_name=winpythonpkg, pkg_url=BASE_CCI_PKG_URL)
      winpython = zipfile.ZipFile(os.path.join(self.tmp_dir, winpythonpkg), 'r')
      members = winpython.namelist()
      for zipinfo in members:
        print("extracting", zipinfo, file=self.log)
        winpython.extract(zipinfo, path=os.path.join(self.base_dir,'bin'))
      winpython.close()

      self.fetch_package(pkg_name=hdf5pkg, pkg_url=BASE_CCI_PKG_URL)
      winhdf5 = zipfile.ZipFile(os.path.join(self.tmp_dir, hdf5pkg), 'r')
      members = winhdf5.namelist()
      for zipinfo in members:
        print("extracting", zipinfo, file=self.log)
        winhdf5.extract(zipinfo, path=self.base_dir)
      winhdf5.close()

      self.fetch_package(pkg_name=libtiff, pkg_url=BASE_CCI_PKG_URL)
      winlibtiff = zipfile.ZipFile(os.path.join(self.tmp_dir, libtiff), 'r')
      members = winlibtiff.namelist()
      for zipinfo in members:
        print("extracting", zipinfo, file=self.log)
        winlibtiff.extract(zipinfo, path=self.base_dir)
      winlibtiff.close()

      # Provide the VC++ redistributable libraries in case we are compiling with OpenMP
      self.fetch_package(pkg_name=vcredist, pkg_url=BASE_CCI_PKG_URL)
      # On Windows quit now as all required modules are in the precompiled python package
      # and HDF5 installation
      return

    # Which Python interpreter:
    self.python_exe = None
    python_executable = 'python'
    self.python3 = options.python3
    if self.python3: python_executable = 'python3'
    self.wxpython4 = options.wxpython4 # or self.python3 # Python3 should imply wxpython4, but
                                                         # wait until we can actually build it
    if (not self.wxpython4 and
        self.flag_is_mac and
        get_os_version().startswith('10.') and
        int(get_os_version().split('.')[1]) >= 14):
      print("Setting wxpython4=True as Mac OS X version >= 10.14", file=self.log)
      self.wxpython4 = True
    if os.path.exists(os.path.join(self.build_dir, 'base', 'bin', python_executable)):
      self.python_exe = os.path.join(self.build_dir, 'base', 'bin', python_executable)
    elif options.with_python:
      self.python_exe = options.with_python
    elif options.with_system_python:
      self.python_exe = sys.executable

    if self.python_exe:
      print("Using Python interpreter: %s" % self.python_exe, file=log)

    if not self.python_exe and 'SuSE' in platform.platform():
      if 'CONFIG_SITE' in os.environ:
        print('SuSE detected; clobbering CONFIG_SITE in environ', file=log)
        try:
          del(os.environ['CONFIG_SITE'])
        except: # intentional
          pass

    # Set package config.
    pkg_config_dir = op.join(self.base_dir, "lib", "pkgconfig")
    if (not op.isdir(pkg_config_dir) and not options.download_only):
      os.makedirs(pkg_config_dir)
    pkg_config_paths = [pkg_config_dir] + os.environ.get("PKG_CONFIG_PATH", "").split(":")
    os.environ['PKG_CONFIG_PATH'] = ":".join(pkg_config_paths)

    # Set BLAS/ATLAS/LAPACK
    for env_var in ["BLAS","ATLAS","LAPACK"]:
      os.environ[env_var] = "None"

    # Select packages to build.
    packages = self.configure_packages(options)
    # Override and specified packages if provided.
    if len(args) > 1:
      packages = args[1:]

    # Do the work!
    self.check_dependencies(packages=packages)
    self.build_dependencies(packages=packages)

    # On Mac OS X all of the Python-related executables located in base/bin
    # are actually symlinks to absolute paths inside the Python.framework, so
    # we replace them with symlinks to relative paths.
    if self.flag_is_mac and not self.options.download_only:
      print("Regenerating symlinks with relative paths...", file=log)
      regenerate_relative_symlinks(op.join(self.base_dir, "bin"), log=log)

  def configure_packages(self, options):
    packages = []
    # Package groups.
    if options.molprobity:
      options.build_gui = False
      options.build_all = False
      packages += ['tiff', 'psutil', 'mrcfile']
    if options.cctbx:
      options.build_gui = True
      options.build_all = True
      packages += ['pillow']
    if options.phenix:
      options.build_gui = True
      options.build_all = True
    if options.dials:
      options.build_gui = True
      options.build_all = True
      packages += ['pillow', 'jinja2', 'orderedset', 'scipy', 'scikit_learn', 'tqdm', 'msgpack']
    if options.xia2:
      options.build_gui = True
      options.build_all = True
      packages += ['pillow', 'jinja2', 'tabulate']
    if options.labelit:
      options.build_gui = True
      options.build_all = True
      packages += ['pillow', 'reportlab']

    # Use a specific Python interpreter if provided.
    if self.python_exe:
      self.set_python(self.python_exe)
    else:
      # for better platform independence, build OpenSSL for Linux and macOS
      # whenever Python is built
      packages += ['python', 'openssl', 'certifi']

    # Python 2-3 compatibility packages
    packages += ['python_compatibility']
    # Always build hdf5 and numpy.
    packages += ['cython', 'hdf5', 'h5py', 'numpy', 'pythonextra', 'docutils']
    packages += ['libsvm', 'lz4_plugin']
    # Development and testing packages.
    packages += ['pytest']
    # GUI packages.
    if options.build_gui or options.build_all or options.download_only:
      packages += [
        'png',
        'tiff',
        'pillow',
        'freetype',
        'matplotlib',
        'msgpack',
        'pyopengl',
        'wxpython',
      ]
      if self.flag_is_mac or options.download_only:
        packages += ['py2app']
      if self.flag_is_linux or options.download_only:
        packages += [
          'gettext',
          'glib',
          'expat',
          'fontconfig',
          'render',
          'pixman',
          'cairo',
          'gtk',
          'fonts',
        ]

    # Additional recommended dependencies.
    if options.build_all:
      packages += ['biopython', 'misc', 'sphinx', 'psutil', 'mrcfile']

    # Non-all packages.
    # Scipy
    if options.build_scipy:
      packages += ['scipy']

    # IPython
    if options.build_ipython:
      packages += ['ipython']

    # Package dependencies.
    if 'pillow' in packages:
      packages += ['freetype']

    # mpi4py installation
    if options.mpi_build:
      packages +=['mpi4py']

    return set(packages)

  def call(self, args, log=None, **kwargs):
    if (log is None) : log = self.log
    return call(args, log=log, verbose=self.verbose, **kwargs)

  def chdir(self, dir_name, log=None):
    if (log is None) : log = self.log
    print("cd \"%s\"" % dir_name, file=log)
    os.chdir(dir_name)

  def touch_file(self, file_name):
    f = open(file_name, "w")
    f.write("")
    f.close()
    assert op.isfile(file_name)

  def print_sep(self, char="-"):
    print("", file=self.log)
    print(char*80, file=self.log)
    print("", file=self.log)

  def start_building_package(self, pkg_name, pkg_info=None, pkg_qualifier=''):
    os.chdir(self.tmp_dir)
    install_log = op.join(self.tmp_dir, pkg_name + "_install_log")
    print("Installing %s%s..." % (pkg_name, pkg_qualifier), file=self.log)
    if pkg_info:
      print(pkg_info, file=self.log)
    print("  log file is %s" % install_log, file=self.log)
    return open(install_log, "w")

  def check_download_only(self, pkg_name=None):
    if pkg_name is not None:
      if self.options.download_only:
        print("  skipping installation of %s (--download-only)" % pkg_name, file=self.log)
      else:
        print("  installing %s..." % pkg_name, file=self.log)
    return self.options.download_only

  @staticmethod
  def patch_src(src_file, target, replace_with, output_file=None):
    from shutil import copymode
    if isinstance(target, str):
      assert isinstance(replace_with, str)
      target = [ target ]
      replace_with = [ replace_with ]
    assert len(target) == len(replace_with)
    in_file = src_file
    if (output_file is None):
      in_file += ".dist"
      os.rename(src_file, in_file)
    src_in = open(in_file)
    if (output_file is None):
      output_file = src_file
    src_out = open(output_file, "w")
    for line in src_in.readlines():
      for target_str, replacement_str in zip(target, replace_with):
        line = line.replace(target_str, replacement_str)
      src_out.write(line)
    src_in.close()
    src_out.close()
    copymode(in_file, output_file)

  def untar_and_chdir(self, pkg, log=None):
    if (log is None) : log = self.log
    pkg_dir = untar(pkg, log=log)
    os.chdir(pkg_dir)

  def check_python_version(self):
    try:
      python_version = check_output([
        self.python_exe,
        '-c',
        'import sys; print("%d:%d:%d:%s" % (sys.version_info[0], sys.version_info[1], sys.hexversion, sys.version))',
        ])
    except (OSError, RuntimeError):
      print("""
Error: Could not determine version of Python installed at:
  %s
Error: Python 2.7 or Python 3.4 or higher required. Python3 only supported for development purposes.
Found Python version:
  %s
""" % self.python_exe, file=self.log)
      sys.exit(1)
    if isinstance(python_version, bytes):
        python_version = python_version.decode("utf-8")
    python_version = python_version.strip().split('\n')[0].split(':', 3)
    if (int(python_version[0]) == 2 and int(python_version[1]) < 7) or \
       (int(python_version[0]) > 2 and int(python_version[2]) < 0x03040000):
      print("Error: Python 2.7 or 3.4+ required.\nFound Python version: %s" % python_version[3], file=self.log)
      sys.exit(1)

  def check_python_dependencies(self):
    for module, desc in python_dependencies.items():
      try:
        self.verify_python_module(module, module)
      except RuntimeError:
        print('\n\n\n%s\n\nThis python does not have %s installed\n\n%s\n\n\n' % (
          "*"*80,
          "%s - %s" % (module, desc),
          "*"*80,
        ))
        raise

  def set_python(self, python_exe):
    print("Using Python: %s"%python_exe, file=self.log)
    self.python_exe = python_exe
    # Just an arbitrary import (with .so)
    self.verify_python_module("Python", "socket")
    # check that certain modules are avaliable in python
    self.check_python_dependencies()
    # Check python version >= 2.7 or >= 3.4
    self.check_python_version()

    # Check that we have write access to site-packages dir
    # by creating a temporary file with write permissions.
    # Open with tempfile to auto-handle unlinking.
    import tempfile
    site_packages = check_output([self.python_exe, '-c', 'from distutils.sysconfig import get_python_lib; print(get_python_lib())'])
    site_packages = site_packages.strip()
    print("Checking for write permissions:", site_packages, file=self.log)
    try:
      f = tempfile.TemporaryFile(dir=site_packages)
    except (OSError, RuntimeError):
      print("""
Error: You don't appear to have write access to
the Python site-packages directory:
  %s
Installation of Python packages may fail.
      """%site_packages, file=self.log)
      raise e
    # Update paths.
    self.update_paths()

  def update_paths(self):
    os.environ["PATH"] = ("%s/bin:" % self.base_dir) + os.environ['PATH']
    lib_paths = [ op.join(self.base_dir, "lib") ]
    if self.flag_is_linux:
      if ("LD_LIBRARY_PATH" in os.environ):
        lib_paths.append(os.environ["LD_LIBRARY_PATH"])
      os.environ['LD_LIBRARY_PATH'] = ":".join(lib_paths)
    inc_dir = op.join(self.base_dir, "include")
    if (not op.isdir(inc_dir)):
      os.mkdir(inc_dir)
    self.include_dirs.append(inc_dir)
    self.lib_dirs.append(lib_paths[0])

  def set_cppflags_ldflags(self):
    # XXX ideally we would like to quote the paths to allow for spaces, but
    # the compiler doesn't like this
    inc_paths = ["-I%s" % p for p in self.include_dirs]
    lib_paths = ["-L%s" % p for p in self.lib_dirs]
    os.environ['CPPFLAGS'] = "%s %s"%(" ".join(inc_paths), self.cppflags_start)
    os.environ['LDFLAGS'] = "%s %s"%(" ".join(lib_paths), self.ldflags_start)

  def verify_python_module(self, pkg_name_label, module_name):
    os.chdir(self.tmp_dir) # very important for import to work!
    if hasattr(self, "python_exe"): python_exe = self.python_exe
    else:
      python_exe = sys.executable
    self.log.write("  verifying %s installation in %s" % (
      pkg_name_label,
      python_exe,
    ))
    if sys.platform == "win32": # Windows is picky about using double quotes rather than single quotes
      self.call('"%s" -c "import %s"' % (python_exe, module_name))
    else:
      self.call("%s -c 'import %s'" % (python_exe, module_name))
    print(" OK", file=self.log)

  def workarounds(self):
    '''Look at the directory I am in at the moment and the platform I am
    running on and (perhaps) mess with things to make the build work.'''

    # Ubuntu & Xrender - libtool is broken - replace with system one if
    # installed...

    if 'xrender' in os.path.split(os.getcwd())[-1] and \
      'Ubuntu' in platform.platform() and os.path.exists('libtool'):
      if os.path.exists(os.path.join('/', 'usr', 'bin', 'libtool')):
        self.log.write('Removing xrender libtool; replace with system\n')
        os.remove('libtool')
        os.symlink(os.path.join('/', 'usr', 'bin', 'libtool'), 'libtool')
      else:
        self.log.write('Cannot removing xrender libtool; not installed\n')

    # patch cairo for Ubuntu 12.04
    # issue: configure step does not find these functions from Xrender
    # https://lists.cairographics.org/archives/cairo/2014-September/025552.html
    # fix: manually set these functions to be present in config.h
    if ( ('cairo' in os.path.split(os.getcwd())[-1]) and
         ('Ubuntu' in platform.platform()) and
         ('precise' in platform.platform()) ):
      self.patch_src(src_file='config.h',
                     target="/* #undef HAVE_XRENDERCREATECONICALGRADIENT */",
                     replace_with="#define HAVE_XRENDERCREATECONICALGRADIENT 1")
      self.patch_src(src_file='config.h',
                     target="/* #undef HAVE_XRENDERCREATELINEARGRADIENT */",
                     replace_with="#define HAVE_XRENDERCREATELINEARGRADIENT 1")
      self.patch_src(src_file='config.h',
                     target="/* #undef HAVE_XRENDERCREATERADIALGRADIENT */",
                     replace_with="#define HAVE_XRENDERCREATERADIALGRADIENT 1")
      self.patch_src(src_file='config.h',
                     target="/* #undef HAVE_XRENDERCREATESOLIDFILL */",
                     replace_with="#define HAVE_XRENDERCREATESOLIDFILL 1")

    return

  def configure_and_build(self, config_args=(), log=None, make_args=(), limit_nproc=None):
    # case sensitive file system workaround
    configure = filter(os.path.exists, ('config', 'configure', 'Configure'))
    working_configure = False
    for c in configure:
      if ( os.path.isfile(c) and os.access(c, os.X_OK) ):
        configure = c
        working_configure = True
        break
    assert working_configure, 'No configure script found'
    self.call("./%s %s" % (configure, " ".join(list(config_args))), log=log)
    self.workarounds()
    nproc = self.nproc
    if limit_nproc is not None:
      nproc = min(nproc, limit_nproc)
    #print os.getcwd()
    #print "make -j %d %s" % (nproc, " ".join(list(make_args)))
    self.call("make -j %d %s" % (nproc, " ".join(list(make_args))), log=log)
    self.call("make install", log=log)

  def build_compiled_package_simple(self, pkg_name,pkg_name_label,
                                    pkg_url=None, extra_config_args=None):
    pkg_log = self.start_building_package(pkg_name_label)
    pkg = self.fetch_package(pkg_name=pkg_name, pkg_url=pkg_url)
    if self.check_download_only(pkg_name): return
    self.untar_and_chdir(pkg=pkg, log=pkg_log)
    config_args = [self.prefix]
    if (isinstance(extra_config_args,list)):
      config_args += extra_config_args
    self.configure_and_build(config_args=config_args, log=pkg_log)

  def build_python_module_simple(self,
      pkg_url,
      pkg_name,
      pkg_name_label,
      pkg_local_file=None,
      callback_before_build=None,
      callback_after_build=None,
      confirm_import_module=None):
    pkg_log = self.start_building_package(pkg_name_label)
    if pkg_local_file is None:
      pkg_local_file, size = self.fetch_package(pkg_name=pkg_name,
                                   pkg_url=pkg_url,
                                   return_file_and_status=True)
    if self.check_download_only(pkg_name): return
    self.untar_and_chdir(pkg=pkg_local_file, log=pkg_log)
    if (callback_before_build is not None):
      assert callback_before_build(pkg_log), pkg_name
    debug_flag = ""
    if (self.options.debug):
      debug_flag = "--debug"
    self.call("%s setup.py build %s" % (self.python_exe, debug_flag),
      log=pkg_log)
    self.call("%s setup.py install" % self.python_exe, log=pkg_log)
    if (callback_after_build is not None):
      assert callback_after_build(pkg_log), pkg_name
    os.chdir(self.tmp_dir)
    if (confirm_import_module is not None):
      self.verify_python_module(pkg_name_label, confirm_import_module)

  def build_python_module_pip(self, package_name, package_version=None, download_only=None,
      callback_before_build=None, callback_after_build=None, confirm_import_module=None,
      extra_options=None):
    '''Download and install a package using pip.'''
    if download_only is None:
      download_only = self.options.download_only

    pkg_info = get_pypi_package_information(package_name, information_only=True)
    pkg_info['package'] = package_name
    pkg_info['python'] = self.python_exe
    pkg_info['cachedir'] = self.fetch_package.dest_dir
    pkg_info['debug'] = ''
    if self.options.debug:
      pkg_info['debug'] = '-v'
    if package_version:
      if '=' in package_version or '>' in package_version or '<' in package_version:
        pkg_info['version'] = package_version
      else:
        pkg_info['version'] = '==' + package_version
    else:
      pkg_info['version'] = ''
    if extra_options:
      assert isinstance(extra_options, list), 'extra pip options must be passed as a list'
    if download_only:
      pip_version_cmd = ['python', '-c', 'import pip; print(pip.__version__)']
      pip_version_result = subprocess.run(pip_version_cmd, stdout=subprocess.PIPE)
      if pip_version_result.returncode != 0:
        print("Skipping download of python package %s %s" % \
              (pkg_info['name'], pkg_info['version']))
        print("Your current python environment does not include 'pip',")
        print("which is required to download prerequisites.")
        print("Please see https://pip.pypa.io/en/stable/installing/ for " \
              "more information.")
        print("*" * 75)
        return
    log = self.start_building_package(package_name,
             pkg_info=pkg_info['summary'],
             pkg_qualifier=' ' + (package_version or ''))
    if download_only:
      pip_cmd = filter(None, [sys.executable, '-m', 'pip', 'download',
                              pkg_info['package'] + pkg_info['version'],
                              '-d', pkg_info['cachedir'], pkg_info['debug']])
      if extra_options:
        pip_cmd.extend(extra_options)
      os.environ['PIP_REQ_TRACKER'] = pkg_info['cachedir']
      print("  Running with pip:", pip_cmd)

      assert subprocess.run(pip_cmd).returncode == 0, 'pip download failed'
      return
    if extra_options:
      extra_options = ' '.join(extra_options)
    else:
      extra_options = ''
    if callback_before_build:
      self.call(pkg_info['python'] + ' -m pip download ' + pkg_info['debug'] + \
                ' "' + pkg_info['package'] + pkg_info['version'] + '" -d "' + \
                pkg_info['cachedir'] + '" ' + extra_options,
                log=log)
      assert callback_before_build(log), package_name
      self.call(pkg_info['python'] + ' -m pip install ' + pkg_info['debug'] + \
                ' "' + pkg_info['package'] + pkg_info['version'] + \
                '" --no-index -f "' + pkg_info['cachedir'] + '" ' + extra_options,
                log=log)
    else:
      self.call(pkg_info['python'] + ' -m pip install ' + pkg_info['debug'] + \
                ' "' + pkg_info['package'] + pkg_info['version'] + '" ' + extra_options,
                log=log)
    if callback_after_build:
      assert callback_after_build(log), package_name
    if confirm_import_module:
      os.chdir(self.tmp_dir)
      self.verify_python_module(pkg_info['name'], confirm_import_module)

  def check_dependencies(self, packages=None):
    packages = packages or []

    # no-op

  def build_dependencies(self, packages=None):
    # Build in the correct dependency order.
    packages = packages or []
    order = [
      'openssl',
      'python',
      'python_compatibility',
      'certifi',
      'numpy',
      'cython',
      'png',
      'libsvm',
      'pytest',
      'pythonextra',
      'hdf5',
      'h5py',
      'biopython',
      'docutils',
      'sphinx',
      'ipython',
      'pyopengl',
      'scipy',
      'scikit_learn',
      'mpi4py',
      'py2app',
      'misc',
      'lz4_plugin',
      'jinja2',
      'orderedset',
      'tqdm',
      'tabulate',
      'psutil',
      'mrcfile',
      # ...
      'freetype',
      'matplotlib',
      'msgpack',
      'pillow',
      'reportlab',
      # START GUI PACKAGES
      'gettext',
      'glib',
      'expat',
      'fontconfig',
      'render',
      'pixman',
      'tiff',
      'cairo',
      'gtk',
      'fonts',
      'wxpython',
    ]
    self.options.skip_base = self.options.skip_base.split(",")
    packages_order = []
    for i in packages:
      assert i in order, "Installation order unknown for %s" % i
    for i in order:
      if i in packages:
        if i in self.options.skip_base: continue
        packages_order.append(i)
    if self.options.continue_from and self.options.continue_from in packages_order:
      packages_order = packages_order[packages_order.index(self.options.continue_from):]

    if self.options.download_only:
      print("Downloading dependencies: %s"%(" ".join(packages_order)), file=self.log)
      action = "download"
    else:
      print("Building dependencies: %s"%(" ".join(packages_order)), file=self.log)
      action = "install"

    os.chdir(self.tmp_dir)
    for i in packages_order:
      self.set_cppflags_ldflags() # up-to-date LDFLAGS/CPPFLAGS
      self.print_sep()
      t0=time.time()
      getattr(self, 'build_%s'%i)()
      print("  package %s took %0.1fs to %s" % (
        i,
        time.time()-t0,
        action
        ), file=self.log)

    if self.options.download_only:
      print("Dependencies finished downloading.", file=self.log)
    else:
      print("Dependencies finished building.", file=self.log)

  #######################################################
  ##### Build Individual Packages #######################
  #######################################################

  def build_python(self):
    if self.python3:
      return self.build_python3()

    if self.flag_is_mac and not op.exists('/usr/include/zlib.h'):
      print("zlib.h missing -- try running 'xcode-select --install' first", file=self.log)
      if get_os_version().startswith('10.') and int(get_os_version().split('.')[1]) >= 14:
        print("followed by 'sudo installer -pkg /Library/Developer/CommandLineTools/Packages/macOS_SDK_headers_for_macOS_10.14.pkg -target /", file=self.log)
      sys.exit(1)
    log = self.start_building_package("Python")
    os.chdir(self.tmp_dir)
    python_tarball = self.fetch_package(pkg_name=PYTHON_PKG, pkg_url=DEPENDENCIES_BASE)
    if self.check_download_only(PYTHON_PKG): return
    python_dir = untar(python_tarball)
    self.chdir(python_dir, log=log)

    # configure macOS and linux separately
    configure_args = [] # common flags should go here
    if self.flag_is_mac:
      configure_args += [
        self.prefix,
        'CPPFLAGS="-I%s/include %s"' %
        (self.base_dir, os.environ.get('CPPFLAGS', '')),
        'LDFLAGS="-L%s/lib %s"' %
        (self.base_dir, os.environ.get('LDFLAGS', '')),
        "--enable-framework=\"%s\"" % self.base_dir,
        ]
      self.call("./configure %s" % " ".join(configure_args), log=log)

      # patch Mac/Makefile to avoid cruft in /Applications
      targets = ['PYTHONAPPSDIR=/Applications/$(PYTHONFRAMEWORK) $(VERSION)',
                 'installapps: install_Python install_pythonw install_BuildApplet install_PythonLauncher \\',
                 'install_IDLE checkapplepython install_versionedtools']
      replacements = ['PYTHONAPPSDIR=',
                      'installapps: install_Python install_pythonw \\',
                      'checkapplepython install_versionedtools']
      for target,replacement in zip(targets,replacements):
        self.patch_src(src_file='Mac/Makefile',
                       target=target, replace_with=replacement)
    else:
      # Linux
      # Ian: Setup build to use rpath $ORIGIN to find libpython.so.
      # Also note that I'm using shell=False and passing args as list
      #   ... to minimize opportunities for mucking up the "\$$"
      configure_args += ["--prefix", self.base_dir]
      if (self.options.python_shared):
        configure_args.append("--enable-shared")
        configure_args.append("LDFLAGS=-Wl,-rpath=$ORIGIN/../lib")

      # patch Modules/Setup.dist to find custom OpenSSL
      targets = ['#SSL=/usr/local/ssl',
                 '#_ssl _ssl.c \\',
                 '#\t-DUSE_SSL -I$(SSL)/include -I$(SSL)/include/openssl \\',
                 '#\t-L$(SSL)/lib -lssl -lcrypto']
      replacements = ['SSL=%s' % self.base_dir,
                      '_ssl _ssl.c \\',
                      '  -DUSE_SSL -I$(SSL)/include -I$(SSL)/include/openssl \\',
                      '  -L$(SSL)/lib -lssl -lcrypto']
      for target,replacement in zip(targets,replacements):
        self.patch_src(src_file='Modules/Setup.dist',
                       target=target, replace_with=replacement)
      self.call([os.path.join(python_dir, 'configure')] + configure_args,
                log=log, cwd=python_dir, shell=False)

    # build (serial because of potential for race conditions)
    self.call('make', log=log, cwd=python_dir)
    self.call('make install', log=log, cwd=python_dir)
    python_exe = op.abspath(op.join(self.base_dir, "bin", "python"))

    # Install pip *separately* from the python install - this ensures that
    # we don't accidentally pick up the user-site pythonpath
    self.call([python_exe, "-mensurepip"], log=log, cwd=python_dir)

    # Make python relocatable
    python_sysconfig = check_output([ python_exe, '-c',
      'import sys; import os; print os.path.join(sys.exec_prefix, "lib", "python2.7", "_sysconfigdata.py")'
      ]).rstrip()
    try:
      fh = open(python_sysconfig, 'r')
      python_config = fh.read()
      fh.close()
      if 'relocatable' not in python_config:
        fh = open(python_sysconfig, 'a')
        fh.write("""
#
# Fix to make python installation relocatable
#

def _replace_sysconfig_paths(d):
  from os import environ
  from sys import executable
  path = environ.get('LIBTBX_PYEXE', executable)
  if '/base/' in path:
    path = path[:path.rfind('/base/')+5]
    for k, v in d.iteritems():
      if isinstance(v, basestring):
        d[k] = v.replace('%s', path)
_replace_sysconfig_paths(build_time_vars)
""" % self.base_dir)
        fh.close()
    except Exception as e:
      print("Could not make python relocatable:", file=log)
      print(e, file=log)

    # On macOS, base/Python.framework/Versions/2.7/Python (aka
    # libpython2.7.dylib) may be read-only. This affects the create-installer
    # step that makes Python relocatable. For applications (e.g. Rosetta) that
    # link to this library, this can cause crashes, so make it writeable.
    if (self.flag_is_mac):
      filename = os.path.join(self.base_dir, 'Python.framework', 'Versions',
                              '2.7', 'Python')
      os.chmod(filename, 0o755)  # set permissions to -rwxr-xr-x

    self.set_python(op.abspath(python_exe))
    log.close()

  def build_python3(self):
    if self.flag_is_mac and not op.exists('/usr/include/zlib.h'):
      print("zlib.h missing -- try running 'xcode-select --install' first", file=self.log)
      sys.exit(1)
    log = self.start_building_package("Python3")
    os.chdir(self.tmp_dir)
    python_tarball = self.fetch_package(pkg_name=PYTHON3_PKG, pkg_url=DEPENDENCIES_BASE)
    if self.check_download_only(PYTHON3_PKG): return
    python_dir = untar(python_tarball)
    self.chdir(python_dir, log=log)

    configure_args = ['--with-ensurepip=install', '--prefix=' + self.base_dir]
    if (self.options.python_shared):
      configure_args.append("--enable-shared")
    environment = os.environ.copy()
    environment['LDFLAGS'] = "-L{base}/lib/ -L{base}/lib64/".format(base=self.base_dir)
    environment['LDFLAGS'] += " -Wl,-rpath,{base}/lib".format(base=self.base_dir)
    environment['LD_LIBRARY_PATH'] = "{base}/lib/:{base}/lib64/".format(base=self.base_dir)
    environment['CPPFLAGS'] = "-I{base}/include -I{base}/include/openssl".format(base=self.base_dir)
    self.call([os.path.join(python_dir, 'configure')] + configure_args,
              log=log, cwd=python_dir, shell=False, env=environment)
    self.call(['make', '-j', str(self.nproc)],
              log=log, cwd=python_dir, shell=False, env=environment)
    self.call(['make', 'install', '-j', str(self.nproc)],
              log=log, cwd=python_dir, shell=False, env=environment)
    python_exe = op.abspath(op.join(self.base_dir, "bin", "python3"))
    self.set_python(op.abspath(python_exe))

    # Make python relocatable - unclear if required
#   python_sysconfig = check_output([ python_exe, '-c',
#     'import os; import sys; import sysconfig; print(os.path.join(os.path.dirname(sysconfig.__file__), sysconfig._get_sysconfigdata_name() + ".py"))'
#     ]).rstrip()
    if False: # try:
      with open(python_sysconfig, 'r') as fh:
        python_config = fh.read()
      if 'relocatable' not in python_config:
        with open(python_sysconfig, 'a') as fh:
          fh.write("""
#
# Fix to make python installation relocatable
#

def _replace_sysconfig_paths(d):
  from os import environ
  from sys import executable
  path = environ.get('LIBTBX_PYEXE', executable)
  if '/base/' in path:
    path = path[:path.rfind('/base/')+5]
    for k, v in d.iteritems():
      if isinstance(v, basestring):
        d[k] = v.replace('%s', path)
_replace_sysconfig_paths(build_time_vars)
""" % self.base_dir)
#   except Exception, e:
      print("Could not make python relocatable:", file=log)
      print(e, file=log)
    log.close()

  def build_python_compatibility(self):
    self.build_python_module_pip(
      'six', package_version=SIX_VERSION,
      confirm_import_module='six')
    self.build_python_module_pip(
      'future', package_version=FUTURE_VERSION,
      confirm_import_module='future')

  def build_pythonextra(self):
    '''install all python packages found in base_tmp/python_extra/'''

    python_extra_dir = 'python_extra'
    python_extra_full_path = os.path.join(self.tmp_dir, python_extra_dir)
    if os.path.exists(python_extra_full_path):
      print("Installing further python packages...\n", file=self.log)
    else:
      print("No further python packages to install.", file=self.log)
      return True

    files = [ f for f in os.listdir(python_extra_full_path) if f.endswith(".tar.gz") ]

    python_extra_order = os.path.join(python_extra_full_path, 'install.order')
    if os.path.exists(python_extra_order):
      f = open(python_extra_order)
      reorder = []
      for line in f.readlines():
        line = line.strip()
        if line in files:
          files.remove(line)
          reorder.append(line)
      reorder.extend(files)
      files = reorder
      f.close()

    for pkg in files:
      self.build_python_module_simple(
        pkg_url=None, pkg_local_file=os.path.join(python_extra_full_path, pkg),
        pkg_name=pkg, pkg_name_label=os.path.join(python_extra_dir, pkg[:-7]))

  def simple_log_parse_test(self, log_filename, line):
    if not os.path.exists(log_filename): return False
    f = file(log_filename, "rb")
    log_lines = f.read()
    f.close()
    if log_lines.find(line)>-1:
      return True
    return False

  def build_libsvm(self):
    self.build_python_module_simple(
      pkg_url=BASE_CCI_PKG_URL,
      pkg_name=LIBSVM_PKG,
      pkg_name_label="libsvm")

  def build_numpy(self):
    self.build_python_module_pip(
      package_name='numpy',
      package_version=NUMPY_VERSION,
      confirm_import_module="numpy",
    )

  def build_docutils(self):
    self.build_python_module_pip(
      package_name='docutils',
      package_version=DOCUTILS_VERSION,
      confirm_import_module="docutils",
    )

  def build_pytest(self):
    self.build_python_module_pip(
      'mock', package_version=MOCK_VERSION)
    self.build_python_module_pip(
      'pytest', package_version=PYTEST_VERSION)
    self.build_python_module_pip(
      'pytest-xdist', package_version=PYTEST_XDIST_VERSION)

  def build_biopython(self):
    self.build_python_module_simple(
      pkg_url=BASE_CCI_PKG_URL,
      pkg_name=BIOPYTHON_PKG,
      pkg_name_label="biopython",
      confirm_import_module="Bio")

  def build_lz4_plugin(self, patch_src=True):
    log = self.start_building_package("lz4_plugin")
    repos = ["hdf5_lz4", "bitshuffle"]
    for repo in repos:
      fetch_remote_package(repo, log=log, use_ssh=self.options.git_ssh)
    if self.check_download_only("lz4 plugin"): return
    if (patch_src):
      print("Patching hdf5_lz4/Makefile", file=log)
      self.patch_src(src_file="hdf5_lz4/Makefile",
                     target="HDF5_INSTALL = /home/det/hdf5-1.8.11/hdf5/",
                     replace_with="HDF5_INSTALL = %s"%self.base_dir)
      print("Patching bitshuffle/setup.py", file=log)
      self.patch_src(src_file="bitshuffle/setup.py",
                     target=["COMPILE_FLAGS = ['-O3', '-ffast-math', '-march=native', '-std=c99']",
                             'raise ValueError("pkg-config must be installed")',
                             "FALLBACK_CONFIG['include_dirs'] = [d for d in FALLBACK_CONFIG['include_dirs']", "if path.isdir(d)]",
                             "FALLBACK_CONFIG['library_dirs'] = [d for d in FALLBACK_CONFIG['library_dirs']", "if path.isdir(d)]",
                             "except subprocess.CalledProcessError:",
                            ],
                     replace_with=[
                             "COMPILE_FLAGS = ['-O3', '-std=c99']",
                             "pass",
                             "FALLBACK_CONFIG['include_dirs'] = ['%s/include']"%self.base_dir, "",
                             "FALLBACK_CONFIG['library_dirs'] = ['%s/lib']"%self.base_dir, "",
                             "except (subprocess.CalledProcessError, OSError):",
                             ])
    self.chdir("hdf5_lz4",log=log)
    self.call("make", log=log)
    self.chdir("../bitshuffle",log=log)
    site_file = open("setup.cfg", "w")
    site_file.write("[build_ext]\nomp = 0\n")
    site_file.close()
    self.call("CFLAGS='-std=c99' %s setup.py build"%self.python_exe,log=log)
    self.call("CFLAGS='-std=c99' %s setup.py install --h5plugin --h5plugin-dir=../hdf5_lz4"%(self.python_exe),log=log)
    self.chdir("../hdf5_lz4",log=log)
    print("Copying new libraries to base/lib/plugins folder", file=log)
    hdf5_plugin_dir = os.path.join(self.base_dir, "lib", "plugins")
    if not os.path.exists(hdf5_plugin_dir):
      os.mkdir(hdf5_plugin_dir)
    self.call("cp -v *.so %s"%hdf5_plugin_dir,log=log)

  def build_scipy(self):
    self.build_python_module_pip(
      package_name='scipy',
      package_version=SCIPY_VERSION,
      confirm_import_module="scipy")

  def build_scikit_learn(self):
    self.build_python_module_pip(
      package_name='scikit-learn',
      package_version=SCIKIT_LEARN_VERSION,
      confirm_import_module="sklearn")

  def build_mpi4py(self):
    self.build_python_module_pip(
      package_name='mpi4py',
      package_version=MPI4PY_VERSION,
      confirm_import_module="mpi4py")

  def build_py2app(self):
    self.build_python_module_pip(
      package_name='py2app',
      package_version=PY2APP_VERSION,
      confirm_import_module="py2app")

  def build_reportlab(self):
    self.build_python_module_simple(
      pkg_url=BASE_CCI_PKG_URL,
      pkg_name=REPORTLAB_PKG,
      pkg_name_label="reportlab",
      confirm_import_module="reportlab")

  def build_msgpack(self):
    self.build_python_module_pip(
      package_name='msgpack',
      package_version=MSGPACK_VERSION,
      confirm_import_module="msgpack",
    )

  def build_pillow(self):
    self.build_python_module_pip(
      package_name='Pillow',
      package_version=PILLOW_VERSION,
      confirm_import_module="PIL",
    )

  def build_sphinx(self):
    self.build_python_module_pip(
      package_name="Sphinx",
      package_version=SPHINX_VERSION,
      confirm_import_module="sphinx")

  def build_ipython(self):
    self.build_python_module_simple(
      pkg_url=BASE_CCI_PKG_URL,
      pkg_name=IPYTHON_PKG,
      pkg_name_label="IPython",
      confirm_import_module="IPython")

  def build_pyopengl(self):
      self.build_python_module_simple(
        pkg_url=BASE_CCI_PKG_URL,
        pkg_name=PYOPENGL_PKG,
        pkg_name_label="pyopengl",
        confirm_import_module="OpenGL")

  def build_cython(self):
    self.build_python_module_pip(
      'Cython', package_version=CYTHON_VERSION,
      confirm_import_module='cython')

  def build_jinja2(self):
    self.build_python_module_pip(
      'Jinja2', package_version=JINJA2_VERSION,
      confirm_import_module='jinja2')

  def build_orderedset(self):
    self.build_python_module_pip(
      'orderedset', package_version=ORDEREDSET_VERSION,
      confirm_import_module='orderedset')

  def build_tqdm(self):
    self.build_python_module_pip('tqdm', package_version=TQDM_VERSION)

  def build_tabulate(self):
    self.build_python_module_pip(
      'tabulate', package_version=TABULATE_VERSION,
      confirm_import_module='tabulate')

  def build_psutil(self):
    self.build_python_module_pip(
      'psutil', package_version=PSUTIL_VERSION,
      confirm_import_module='psutil')

  def build_mrcfile(self):
    self.build_python_module_pip(
      'mrcfile', package_version=MRCFILE_VERSION,
      confirm_import_module='mrcfile')

  def build_hdf5(self):
    pkg_log = self.start_building_package("HDF5")
    hdf5pkg = self.fetch_package(pkg_name=HDF5_PKG, pkg_url=BASE_HDF5_PKG_URL)
    if self.check_download_only(HDF5_PKG): return
    self.untar_and_chdir(pkg=hdf5pkg, log=pkg_log)
    print("Building base HDF5 library...", file=pkg_log)
    make_args = []
    # XXX the HDF5 library uses '//' for comments, which will break if the
    # compiler doesn't support C99 by default.  for some bizarre reason this
    # includes certain (relatively new) versions of gcc...
    if self.flag_is_linux:
      make_args.append("CFLAGS=\"-std=c99\"")
    self.configure_and_build(
      config_args=[self.prefix, "--enable-build-mode=production",],
      log=pkg_log,
      make_args=make_args)

  def build_h5py(self):
    os.environ['HDF5_DIR'] = self.base_dir
    self.build_python_module_pip(
      'h5py', package_version=H5PY_VERSION,
      confirm_import_module='h5py', extra_options=["--no-binary=h5py"])

  def build_openssl(self):
    # https://wiki.openssl.org/index.php/Compilation_and_Installation#Configure_.26_Config
    # http://stackoverflow.com/a/20740964

    pkg_url=DEPENDENCIES_BASE
    pkg_name=OPENSSL_PKG
    pkg_name_label="OpenSSL"
    pkg_log = self.start_building_package(pkg_name_label)
    pkg = self.fetch_package(pkg_name=pkg_name, pkg_url=pkg_url)
    if self.check_download_only(pkg_name): return
    self.untar_and_chdir(pkg=pkg, log=pkg_log)
    if (self.flag_is_mac):
      # help config select darwin64-x86_64-cc (required for 10.9)
      os.environ['KERNEL_BITS'] = '64'
    self.configure_and_build(
      config_args=[self.prefix, "-fPIC", "no-hw", "--openssldir=share"],
      log=pkg_log, limit_nproc=1) # openssl is not parallel buildable
    self.include_dirs.append(op.join(self.base_dir, "include", "openssl"))
    if (self.flag_is_mac):
      os.environ['KERNEL_BITS'] = ''

  def build_certifi(self):
    # No version specified - always take latest version
    self.build_python_module_pip(
      'certifi', confirm_import_module="certifi")
    if self.check_download_only(): return

    # set environment variable for root certificates
    # this affects future pip commands in the installation process and only
    # seems to be needed for macOS 10.11
    cert_file = check_output([self.python_exe, '-c',
                              'import certifi; print(certifi.where())'])
    cert_file = cert_file.strip()
    try:
      os.environ['SSL_CERT_FILE'] = cert_file
    except TypeError: # str is needed instead of bytes (Python 3)
      os.environ['SSL_CERT_FILE'] = cert_file.decode("utf-8")
    print('SSL_CERT_FILE environment variable set to %s' % \
      cert_file, file=self.log)

  def build_freetype(self):
    self.build_compiled_package_simple(
      pkg_url=BASE_CCI_PKG_URL,
      pkg_name=FREETYPE_PKG,
      pkg_name_label="Freetype")
    if self.check_download_only(): return
    self.include_dirs.append(op.join(self.base_dir, "include", "freetype2"))
    # copy ft2build.h from include/freetype2 to inculde/ (for matplotlib)
    from shutil import copy
    copy(op.join(self.base_dir, 'include', 'freetype2', 'ft2build.h'),
         op.join(self.base_dir, 'include'))

  def build_png(self):
    self.build_compiled_package_simple(
      pkg_url=BASE_CCI_PKG_URL,
      pkg_name=LIBPNG_PKG,
      pkg_name_label="libpng")

  def build_gettext(self):
    # gettext
    pkg_log = self.start_building_package("gettext")
    pkg = self.fetch_package(pkg_name=GETTEXT_PKG)
    if self.check_download_only(GETTEXT_PKG): return
    self.untar_and_chdir(pkg=pkg, log=pkg_log)
    os.chdir("gettext-runtime")
    gettext_conf_args = [self.prefix, "--disable-java", "--disable-csharp",
      "--disable-intl-java", "--disable-gcj"]
    self.configure_and_build(config_args=gettext_conf_args, log=pkg_log)

  def build_glib(self):
    # libffi dependency (for CentOS 5, especially)
    self.build_compiled_package_simple(pkg_url=BASE_CCI_PKG_URL,
                                       pkg_name=LIBFFI_PKG,
                                       pkg_name_label='libffi')

    # glib
    pkg_log = self.start_building_package("glib")
    pkg = self.fetch_package(pkg_name=GLIB_PKG)
    if self.check_download_only(GLIB_PKG): return

    # Mock executables.
    if (not op.isdir(op.join(self.base_dir, "bin"))):
      os.makedirs(op.join(self.base_dir, "bin"))
    msgfmt_bin = op.join(self.base_dir, "bin", "msgfmt")
    gettext_bin = op.join(self.base_dir, "bin", "xgettext")
    self.touch_file(msgfmt_bin)
    self.touch_file(gettext_bin)
    self.call("chmod 744 \"%s\""%msgfmt_bin)
    self.call("chmod 744 \"%s\""%gettext_bin)
    # glib
    self.untar_and_chdir(pkg=pkg, log=pkg_log)
    self.configure_and_build(
      config_args=[self.prefix, "--disable-selinux"],
      log=pkg_log)

  def build_expat(self):
    # expat
    pkg_log = self.start_building_package("expat")
    pkg = self.fetch_package(pkg_name=EXPAT_PKG)
    if self.check_download_only(EXPAT_PKG): return
    self.untar_and_chdir(pkg=pkg, log=pkg_log)
    self.configure_and_build(config_args=[self.prefix], log=pkg_log)
    header_files = ["./lib/expat_external.h", "./lib/expat.h"]
    for header in header_files :
      self.call("./conftools/install-sh -c -m 644 %s \"%s\"" % (header,
        op.join(self.base_dir, "include")), log=pkg_log)

  def build_fontconfig(self):
    # fontconfig
    pkg_log = self.start_building_package("fontconfig")
    pkg = self.fetch_package(pkg_name=FONTCONFIG_PKG)
    if self.check_download_only(FONTCONFIG_PKG): return
    self.untar_and_chdir(pkg=pkg, log=pkg_log)
    # Create font directories.
    if (not op.isdir(op.join(self.base_dir, "share", "fonts"))):
      os.makedirs(op.join(self.base_dir, "share", "fonts"))
    if (not op.isdir(op.join(self.base_dir,"etc","fonts"))):
      os.makedirs(op.join(self.base_dir,"etc","fonts"))
    fc_config_args = [ self.prefix,
      "--disable-docs",
      "--with-expat-includes=\"%s\"" % op.join(self.base_dir, "include"),
      "--with-expat-lib=\"%s\"" % op.join(self.base_dir, "lib"),
      "--with-add-fonts=\"%s\"" % op.join(self.base_dir,"share","fonts"),
      "--with-confdir=\"%s\"" % op.join(self.base_dir,"etc","fonts"),
      "--with-docdir=\"%s\"" % op.join(self.base_dir, "doc"),
      "--with-freetype-config=freetype-config", ]
    self.configure_and_build(config_args=fc_config_args, log=pkg_log)

    # replace symbolic links (full paths) in base/etc/fonts/conf.d
    # with actual files to make installation portable
    link_directory = op.join(self.base_dir, 'etc', 'fonts', 'conf.d')
    link_files = os.listdir(link_directory)
    actual_directory = op.join(self.base_dir, 'share', 'fontconfig',
                               'conf.avail')
    actual_files = os.listdir(actual_directory)
    print('\n  Fixing symbolic links in %s' % link_directory, file=self.log)
    for link in link_files:
      if ('conf' in link):     # ignore README
        link_file = op.join(link_directory, link)
        actual_file = op.join(actual_directory, link)
        print('    ', link, file=self.log)
        self.call('rm -f %s' % link_file)
        if (op.isfile(actual_file)):
          self.call('cp %s %s' % (actual_file, link_file))

    # remove hard-coded cache directory from base/etc/fonts/fonts.conf
    print('\n  Removing hard-coded cache directory from fonts.conf', file=self.log)
    cache_directory = op.join(self.base_dir, 'var', 'cache', 'fontconfig')
    fonts_directory = op.join(self.base_dir, 'etc', 'fonts')
    old_conf = open(op.join(fonts_directory, 'fonts.conf'), 'r')
    new_conf = open(op.join(fonts_directory, 'new.conf'), 'w')
    for line in old_conf.readlines():
      if (cache_directory not in line):
        new_conf.write(line)
    old_conf.close()
    new_conf.close()
    old_conf = op.join(fonts_directory, 'fonts.conf')
    new_conf = op.join(fonts_directory, 'new.conf')
    self.call('mv %s %s' % (new_conf, old_conf))

  def build_render(self):
    # render, xrender, xft
    for pkg, name in zip([RENDER_PKG,XRENDER_PKG,XFT_PKG], ["render","Xrender","Xft"]):
      self.build_compiled_package_simple(pkg_name=pkg, pkg_name_label=name)

  def build_pixman(self):

    # set CFLAGS for CentOS 5 (32-bit)
    if ( (self.flag_is_linux) and (platform.architecture()[0] == '32bit') ):
      old_cflags = os.environ.get('CFLAGS', '')
      os.environ['CFLAGS'] = old_cflags + ' -g -O2'

    # pixman
    pkg_log = self.start_building_package("pixman")
    pkg = self.fetch_package(pkg_name=PIXMAN_PKG)
    if self.check_download_only(PIXMAN_PKG): return
    self.untar_and_chdir(pkg=pkg, log=pkg_log)
    self.configure_and_build(
      config_args=[self.prefix, "--disable-gtk", "--disable-static" ],
      log=pkg_log)

    # reset CFLAGS for CentOS 5 32-bit
    if ( (self.flag_is_linux) and (platform.architecture()[0] == '32bit') ):
      os.environ['CFLAGS'] = old_cflags

  def build_cairo(self):
    #    self.include_dirs.append(op.join(self.base_dir, "include", "harfbuzz"))

    # set CXXFLAGS for CentOS 5 (32-bit), needed for harfbuzz
    if ( (self.flag_is_linux) and (platform.architecture()[0] == '32bit') ):
      old_cflags = os.environ.get('CXXFLAGS', '')
      os.environ['CXXFLAGS'] = old_cflags + ' -march=i686'

    for pkg, name in zip([CAIRO_PKG, HARFBUZZ_PKG],["cairo", "harfbuzz"]):
      self.build_compiled_package_simple(pkg_name=pkg, pkg_name_label=name)
    self.build_compiled_package_simple(
      pkg_name=PANGO_PKG, pkg_name_label="pango",
      extra_config_args=["--enable-introspection=no"])
    self.build_compiled_package_simple(
      pkg_name=ATK_PKG, pkg_name_label="atk",
      extra_config_args=["--enable-introspection=no"])

    # reset CXXFLAGS for CentOS 5 32-bit
    if ( (self.flag_is_linux) and (platform.architecture()[0] == '32bit') ):
      os.environ['CXXFLAGS'] = old_cflags

  def build_tiff(self):
    # tiff
    pkg_log = self.start_building_package("tiff")
    pkg = self.fetch_package(pkg_name=TIFF_PKG)
    if self.check_download_only(TIFF_PKG): return
    self.untar_and_chdir(pkg=pkg, log=pkg_log)
    os.environ['MANSCHEME'] = "bsd-source-cat"
    os.environ['DIR_MAN'] = op.join(self.base_dir, "man")
    # disable external codecs
    config_args = [self.prefix, '--disable-pixarlog', '--disable-jpeg',
                   '--disable-old-jpeg', '--disable-jbig', '--disable-lzma' ]
    self.configure_and_build(
      config_args=config_args,
      log=pkg_log)

  def build_gtk(self):
    # gdk-pixbuf, gtk+, clearlooks
    extra_config_args = ["--without-libjpeg", "--enable-relocations",
                         "--enable-introspection=no"]
    self.build_compiled_package_simple(pkg_name=GDK_PIXBUF_PKG,
                                       pkg_name_label='gdk-pixbuf',
                                       extra_config_args=extra_config_args)
    self.build_compiled_package_simple(
      pkg_name=GTK_PKG, pkg_name_label='gtk+',
      extra_config_args=["--enable-introspection=no"])
    self.build_compiled_package_simple(
      pkg_name=GTK_ENGINE_PKG, pkg_name_label='gtk-engine')

  def build_fonts(self):
    # fonts
    fonts_log = self.start_building_package("fonts")
    pkg = self.fetch_package(pkg_name=FONT_PKG)
    if self.check_download_only("fonts"): return

    share_dir = op.join(self.base_dir, "share")
    if (not op.isdir(share_dir)):
      os.makedirs(share_dir)
    os.chdir(share_dir)
    untar(pkg, log=fonts_log, verbose=True)
    os.chdir(self.tmp_dir)

  def build_wxpython(self):
    if self.wxpython4 or self.python3:
      self.build_python_module_pip(
        'wxPython', package_version="4.0.3",
        confirm_import_module='wx')
      return

    pkg_log = self.start_building_package("wxPython")
    pkg_name = WXPYTHON_PKG
    pkg = self.fetch_package(pkg_name)
    if self.check_download_only(pkg_name): return

    pkg_dir = untar(pkg, log=pkg_log)
    os.chdir(pkg_dir)

    # Unconditionally append Debian i386/x86_64 multilib directories
    # to wxPython's list of library search paths.
    line = "SEARCH_LIB=\"`echo \"$SEARCH_INCLUDE\" | " \
           "sed s@include@$wx_cv_std_libpath@g` /usr/$wx_cv_std_libpath"
    self.patch_src(src_file="configure",
                   target=(line, ),
                   replace_with=(line +
                                 " /usr/lib/i386-linux-gnu" +
                                 " /usr/lib/x86_64-linux-gnu", ))

    if self.flag_is_mac and get_os_version().startswith('10.') and int(get_os_version().split('.')[1]) >= 10:
      # Workaround wxwidgets 3.0.2 compilation error on Yosemite
      # This will be fixed in 3.0.3.
      # See:
      #   http://trac.wxwidgets.org/ticket/16329
      #   http://goharsha.com/blog/compiling-wxwidgets-3-0-2-mac-os-x-yosemite/
      print("  patching src/osx/webview_webkit.mm", file=self.log)
      self.patch_src(src_file="src/osx/webview_webkit.mm",
                     target=("#include <WebKit/WebKit.h>",),
                     replace_with=("#include <WebKit/WebKitLegacy.h>",))

    if self.flag_is_mac and get_os_version().startswith('10.') and int(get_os_version().split('.')[1]) >= 12:
      # Workaround wxwidgets 3.0.2 compilation error on Sierra
      # QuickTime Framework deprecated in OS X v10.9
      # See:
      #   http://trac.wxwidgets.org/ticket/17639
      #   http://trac.wxwidgets.org/changeset/f6a2d1caef5c6d412c84aa900cb0d3990b350938/git-wxWidgets
      #   https://developer.apple.com/library/content/documentation/MacOSX/Conceptual/OSX_Technology_Overview/SystemFrameworks/SystemFrameworks.html
      for src_file in ("src/osx/core/bitmap.cpp", "src/osx/carbon/dataobj.cpp"):
        print("  patching %s" %src_file, file=self.log)
        self.patch_src(src_file=src_file,
                       target=("#include <QuickTime/QuickTime.h>",),
                       replace_with=("",))

    # Stage 1: build wxWidgets libraries
    config_opts = [
      self.prefix,
      "--with-opengl",
      "--enable-unicode",
      "--without-libjbig",
      "--without-liblzma",
      "--with-libjpeg=builtin", # Prevents system version, https://github.com/dials/dials/issues/523
    ]

    if (self.options.debug):
      config_opts.extend(["--disable-optimize",
                          "--enable-debug"])
      if (self.flag_is_linux):
        config_opts.append("--disable-debug_gdb")
    else :
      config_opts.extend(["--enable-optimize",
                          "--disable-debugreport"])

    # if (cocoa):
    if (self.flag_is_mac):
      config_opts.extend([
        "--with-osx_cocoa",
        "--with-macosx-version-min=%s" % self.min_macos_version,
        "--with-mac",
        "--enable-monolithic",
        "--disable-mediactrl"
      ])
      if get_os_version().startswith('10.') and int(get_os_version().split('.')[1]) >= 12:
        # See https://trac.wxwidgets.org/ticket/17929 fixed for wxWidgets 3.0.4
        # Does not affect 10.12, but using macro does not hurt
        # Also, -stdlib flag breaks things on Xcode 9, so leave it out.
        config_opts.append('CPPFLAGS="-D__ASSERT_MACROS_DEFINE_VERSIONS_WITHOUT_UNDERSCORES=1 %s"' % self.min_macos_version_flag)
        config_opts.append('LDFLAGS="%s"' % self.min_macos_version_flag)

    elif (self.flag_is_linux):
      config_opts.extend([
        "--with-gtk",
        "--with-gtk-prefix=\"%s\"" % self.base_dir,
        "--with-gtk-exec-prefix=\"%s\"" % op.join(self.base_dir, "lib"),
        "--enable-graphics_ctx",
        "--disable-mediactrl",
        "--enable-display",
        "--without-libnotify"
      ])

    install_gizmos = False #True
    print("  building wxWidgets with options:", file=self.log)
    for opt in config_opts :
      print("    %s" % opt, file=self.log)
    self.call("./configure %s" % " ".join(config_opts), log=pkg_log)
    self.call("make -j %d" % self.nproc, log=pkg_log)
    self.call("make install", log=pkg_log)

    # Stage 2: build wxPython itself
    wxpy_build_opts = [
      "BUILD_GLCANVAS=1",
      "BUILD_DLLWIDGET=0",
      "UNICODE=1"
    ]
    if install_gizmos:
      wxpy_build_opts.append("BUILD_GIZMOS=1")
    if self.flag_is_mac:
      os.environ['CFLAGS'] = os.environ.get('CFLAGS', '') + " -arch x86_64"
      wxpy_build_opts.extend(["BUILD_STC=1",
                              "WXPORT=osx_cocoa"])
      # Xcode 9 fails with -stdlib flag
      if get_os_version().startswith('10.') and int(get_os_version().split('.')[1]) >= 12:
        os.environ['CPPFLAGS'] = self.min_macos_version_flag
        os.environ['LDFLAGS'] = self.min_macos_version_flag
    else :
      wxpy_build_opts.extend(["BUILD_STC=1", #"BUILD_STC=0",
                              #"BUILD_OGL=0",
                              "WX_CONFIG=%s/bin/wx-config" %self.base_dir])
    self.chdir("wxPython", log=pkg_log)
    debug_flag = ""
    if (self.options.debug):
      debug_flag = "--debug"
    print("  building wxPython with options:", file=self.log)
    for opt in wxpy_build_opts :
      print("    %s" % opt, file=self.log)
    self.call("%s setup.py %s build_ext %s" % (self.python_exe,
      " ".join(wxpy_build_opts), debug_flag), log=pkg_log)
    self.call("%s setup.py %s install" % (self.python_exe,
      " ".join(wxpy_build_opts)), log=pkg_log)
    self.verify_python_module("wxPython", "wx")

  def build_matplotlib(self):
    def patch_matplotlib_src(out):
      print("  patching setup.cfg", file=out)
      self.patch_src(src_file="setup.cfg.template",
                     output_file="setup.cfg",
                     target=("#backend = Agg", "#basedirlist = /usr"),
                     replace_with=("backend = WXAgg",
                                   "basedirlist = /usr, %s" % self.base_dir))
      return True

    # delete old font cache
    #if ( (self.flag_is_linux) or (self.flag_is_mac) ):
    #  home = os.path.expanduser('~')
    #  filename = 'fontList.cache'
    #  directories = ['.matplotlib', '.cache/matplotlib']
    #  for directory in directories:
    #    font_cache = os.path.join(home, directory, filename)
    #    print font_cache, os.path.exists(font_cache)
    #    if (os.path.exists(font_cache)):
    #      os.remove(font_cache)

    for dependency in MATPLOTLIB_DEPS:
      self.build_python_module_pip(dependency[0], package_version=dependency[1])

    self.build_python_module_simple(
      pkg_url=BASE_CCI_PKG_URL,
      pkg_name=MATPLOTLIB_PKG,
      pkg_name_label="Matplotlib",
      callback_before_build=patch_matplotlib_src,
      confirm_import_module="matplotlib")

  def build_misc(self):
    if not self.python3: # This module will never be Python3 compatible
     self.build_python_module_simple(
      pkg_url=BASE_CCI_PKG_URL,
      pkg_name=PYRTF_PKG,
      pkg_name_label="PyRTF",
      confirm_import_module="PyRTF")
      # TODO we are patching the source to force it to use the correct backend.
      # I'm not sure if this is truly necessary or if there's a cleaner way...

    self.build_python_module_pip(
      "send2trash", package_version=SEND2TRASH_VERSION,
    )

  # TODO
  def write_dispatcher_include(self):
    raise NotImplementedError()

def check_wxpython_build_dependencies(log=sys.stderr):
  try :
    call(["pkg-config", "--version"], log=log)
  except RuntimeError :
    return """
ERROR The GUI components require pkg-config to build
Please install pkg-config to compile these components or use the --no-gui
option to disable compilation of GUI components.
"""
  # TODO pkg-config version check
  try :
    call(["bash", "--version"], log=log)
  except RuntimeError :
    return """
ERROR: The GUI requires bash to be available to build
Please install bash to compile these components, or use the --no-gui option
to disable GUI compilation.
"""
  if (not op.exists("/usr/include/X11/X.h") and
      not op.exists("/usr/X11R6/include/X11/X.h")):
    return """
ERROR: The X-windows headers appear to be missing
Please install the X11 development packages to compile the GUI components,
or use the --no-gui option to disable GUI compilation.
"""
  return None

if __name__ == "__main__":
  installer(args=sys.argv, log=sys.stdout)


 *******************************************************************************


 *******************************************************************************
libtbx/auto_build/install_conda.py
"""
Manage conda environment for CCTBX programs

This is a minimal wrapper for conda functionality. It is meant to create
the minimum environment for building CCTBX programs and is aimed towards
developers that do not want to manage their own conda environments.
Advanced users should use conda natively so that they have full control.

This is called by bootstrap.py to set up a developer's conda
environment. If no conda installation is found, one will be downloaded.
It will be installed in the "mc3" directory at the same level as
"modules."

The minimum version for conda is 4.4. This is when conda moved towards
building packages with a set of common compilers.
"""
from __future__ import absolute_import, division, print_function

import argparse
import json
import os
import platform
import shutil
import sys
import time
import warnings

# Python 2/3 compatibility
py2 = False
py3 = True
try:
  from urllib.parse import urljoin
  from urllib.request import urlopen
except ImportError:
  from urlparse import urljoin
  from urllib2 import urlopen
  py2 = True
  py3 = False

# copied from install_base_packages.py
if __package__ is None:
  sys.path.append(os.path.dirname(os.path.abspath(__file__)))
  from installer_utils import check_output, call
else:
  from .installer_utils import check_output, call

# conda on Windows seems to need cmd and the wait() in Popen
if platform.system() == 'Windows':
  import subprocess
  import tempfile
  def check_output(command_list, *args, **kwargs):
    # check for "conda info" and "activate" commands and prepend cmd
    if 'conda.exe' in command_list[0] or 'activate' in command_list[0]:
      command_list = ['cmd', '/c'] + command_list
      output = ''
      with tempfile.TemporaryFile() as f:
        returncode = subprocess.check_call(command_list, stdout=f, *args, **kwargs)
        f.seek(0)
        output = f.read()
      return output
    # miniconda3 installation
    else:
      returncode = call(command_list, *args, **kwargs)
      return returncode

# =============================================================================
# Locations for the files defining the conda environments
# Generally, they should reside in the repository of the main program
# defined by the builder. For example, the environment file for Phenix
# will be in the Phenix source tree.
conda_platform = {
  'Darwin': 'osx-64',
  'Linux': 'linux-64',
  'Windows': 'win-64',
}

# check for Apple Silicon
if platform.system() == 'Darwin' and 'arm64' in platform.platform():
  conda_platform['Darwin'] = 'osx-arm64'

version = 'PYTHON_VERSION'
default_format = '{builder}_py{version}_{platform}.txt'
default_filename = default_format.format(builder='cctbx',
  version=version, platform=conda_platform[platform.system()])

root_dir = os.path.abspath(
  os.path.join(__file__, '..', '..', '..', '..', '..'))
default_file = os.path.join('cctbx_project', 'libtbx', 'auto_build',
                            'conda_envs', default_filename)

# =============================================================================
def download_file(url, filename):
  """
  Simple function for downloading a file from a URL
  No error checking is done since anything downloaded is necessary.

  Parameters
  ----------
  url: str
    The url pointing to the location of the file
  filename: str
    The name of the local file

  Returns
  -------
    Nothing
  """
  if py3:
    with urlopen(url) as response:
      with open(filename, 'wb') as local_file:
        shutil.copyfileobj(response, local_file)
  elif py2:
    with open(filename, 'wb') as local_file:
      response = urlopen(url).read()
      local_file.write(response)

# =============================================================================
class conda_manager(object):
  """
  Class for managing conda environments

  Attributes
  ----------
  env_locations: dict
    Dictionary for determining which environment to use for each builder.
    The keys are the builder names and must match those in bootstrap.py
    The values are the relative path from "modules" to the file. Builders
    for programs outside of cctbx_project should place their environment
    files inside their repository. For example, the Phenix environment
    file should be in the phenix repository.

  Methods
  -------
  __init__(root_dir, conda_base, conda_env, verbose, log)
    Constructor that does the basic check for a conda installation
  get_conda_exe(prefix, check_file)
    Returns the platform-dependent conda executable
  get_conda_python(conda_env, check_file)
    Returns the platform-dependent conda python
  update_environments()
    Returns a list of paths that are conda environments based on the
    environments.txt file in ${HOME}/.conda
  install_miniconda(prefix)
    Downloads and installs the latest version of miniconda3
  update_conda()
    Updates the current version of conda
  create_environment(builder, filename, copy)
    Uses the known conda installtion to create an environment
  write_conda_setpaths(prefix, build_dir, conda_env, check_file)
    Writes an additional script that activates the conda environment before
    calling the normal setpaths script.
  """

  # Currently, there is one monolithic environment
  # The key names for this dictionary must match the builder names in
  # bootstrap.py
  phenix_env = os.path.join('phenix', 'conda_envs',
    default_format.format(builder='phenix', version=version,
                          platform=conda_platform[platform.system()]))
  env_locations = {
    'cctbxlite': default_file,
    'cctbx': default_file,
    'phenix': phenix_env,
    'phenix_discamb': phenix_env + '2',
    'phenix_molstar': phenix_env,
    'phenix_voyager': phenix_env,
    'phenix_release': phenix_env,
    'xfellegacy': default_file,
    'dials-old': os.path.join('dials', '.conda-envs',
      default_format.format(builder='dials', version=version,
                            platform=conda_platform[platform.system()])),
    'dials': os.path.join('dials', '.conda-envs',
             {
                 "Darwin": "macos.txt",
                 "Linux": "linux.txt",
                 "Windows": "windows.txt",
             }[platform.system()]),
    'external': default_file,
    'molprobity': default_file,
    'qrefine': default_file,
    'phaser': default_file,
    'voyager': os.path.join('phasertng', 'conda_envs',
      default_format.format(builder='phasertng', version=version,
                            platform=conda_platform[platform.system()]))
  }
  env_locations['xfel'] = env_locations['labelit'] = env_locations['dials']
  # A set of builders where the environment files do not specify the python
  # version
  env_without_python = [ "dials","xfel","labelit"]

  # ---------------------------------------------------------------------------
  def __init__(self, root_dir=root_dir, conda_base=None, conda_env=None,
               check_file=True, max_retries=5, verbose=False, log=sys.stdout):
    """
    Constructor that performs a basic check for the conda installation.
    If an installation is not found, the latest version can be downloaded
    and installed.

    Parameters
    ----------
    root_dir: str
      Required argument for specifying the root level directory for
      CCTBX builds. This is where the "modules" and "build" directories
      reside. If a new conda installation is required, it will be placed
      here under the "mc3" directory. The conda environment for building
      will also be placed in this directory
    conda_base: str
      Required argument for specifying location of a conda installation.
      If this is None, miniconda will be installed unless conda_env is
      set to a valid path.
    conda_env: str
      Optional argument for specifying location of a conda environment.
      Since this is assumed to be a working conda environment, a new
      installation of conda will not be created. This is for developers
      that want to manage their own environments.
    check_file: bool
      Flag for checking if a file exists. A RuntimeError is raised if a
      this flag is set and a file does not exist. Used in get_conda_exe
      and get_conda_python.
    max_retries: int
      When downloading conda packages, there may be network issues that
      prevent the environment from being constructed. This parameter
      controls the number of retry attempts for constructing the conda
      environment. The first retry is attempted 1 minute after the
      initial failure. The second retry is attempted 2 minutes, etc.
    verbose: bool
      Flag for showing conda output
    log: file
      For storing log output
    """
    self.system = platform.system()

    self.root_dir = root_dir

    self.conda_base = None
    if conda_base is not None:
      self.conda_base = os.path.normpath(conda_base)

    self.conda_env = None
    if conda_env is not None:
      self.conda_env = os.path.normpath(conda_env)

    self.check_file = check_file
    self.max_retries = max_retries
    self.verbose = verbose
    self.log = log

    self.conda_exe = None
    if self.conda_base is not None:
      self.conda_exe = self.get_conda_exe(self.conda_base, check_file=False)

    # default environment file for users
    self.environment_file = os.path.join(
      os.path.expanduser('~'), '.conda', 'environments.txt')
    self.environments = self.update_environments()

    # Clean environment for external Python processes
    self.env = os.environ.copy()
    self.env['PYTHONPATH'] = ''

    # error messages
    self.conda_exe_not_found = """
The conda executable cannot be found. Please make sure the correct
directory for the base conda installation was provided. The directory
can be found by running "conda info" and looking the "base environment"
value."""

    # try to determine base environment from $PATH
    if self.conda_base is None:
      paths = os.environ.get('PATH')
      if paths is not None:
        if self.system == 'Windows':
          paths = paths.split(';')
        else:
          paths = paths.split(':')
        for path in paths:
          conda_base = os.path.abspath(os.path.join(path, '..'))
          conda_exe = self.get_conda_exe(conda_base, check_file=False)
          if os.path.isfile(conda_exe):
            self.conda_base = conda_base
            self.conda_exe = conda_exe
            break

    # try to determine base environment from .conda/environments.txt
    if self.conda_base is None:
      for environment in self.environments:
        conda_exe = self.get_conda_exe(environment, check_file=False)
        if os.path.isfile(conda_exe):
          self.conda_base = environment
          self.conda_exe = conda_exe
          break

    # -------------------------------------------------------------------------
    # helper function for searching for conda_exe
    def walk_up_check(new_conda_base, new_conda_exe):
      if new_conda_base is None:
        new_conda_base = ''
      if new_conda_exe is None:
        new_conda_exe = ''
      while not os.path.isfile(new_conda_exe):
        # move up directory and recheck
        new_conda_base = os.path.abspath(os.path.join(new_conda_base, '..'))
        new_conda_exe = self.get_conda_exe(new_conda_base, check_file=False)
        if os.path.isfile(new_conda_exe):
          return new_conda_base, new_conda_exe

        # moved to root directory
        if new_conda_base == \
          os.path.abspath(os.path.join(new_conda_base, '..')):
          return '', ''
    # -------------------------------------------------------------------------

    # try to determine base evironment from conda_env
    if (self.conda_base is None) and (self.conda_env is not None):
      conda_base, conda_exe = walk_up_check(self.conda_env, self.conda_exe)
      if os.path.isfile(conda_exe):
        self.conda_base = conda_base
        self.conda_exe = conda_exe

    # install conda if necessary
    if (self.conda_base is None) and (self.conda_env is None):
      install_dir = os.path.join(self.root_dir, 'mc3')
      if os.path.isdir(install_dir):
        print('Using default conda installation', file=self.log)
        self.conda_base = install_dir
      else:
        print('Location of conda installation not provided', file=self.log)
        print('Proceeding with a fresh installation', file=self.log)
        self.conda_base = self.install_miniconda(prefix=self.root_dir)
      self.conda_exe = self.get_conda_exe(self.conda_base, check_file=False)

    self.environments = self.update_environments()

    # verify consistency and check conda version
    if self.conda_base is not None:

      # maybe a conda evironment was provided instead of the base environment
      if not os.path.isfile(self.conda_exe):
        self.conda_base, self.conda_exe = \
          walk_up_check(self.conda_base, self.conda_exe)
        self.environments = self.update_environments()

      if not os.path.isfile(self.conda_exe):
        raise RuntimeError(self.conda_exe_not_found)

      conda_info = json.loads(check_output([self.conda_exe, 'info', '--json'],
                                           env=self.env))
      consistency_check = [self.conda_base == conda_info['root_prefix']]
      for env in self.environments:
        consistency_check.append(env in conda_info['envs'])
      if False in consistency_check:
        message = """
There is a mismatch between the conda settings in your home directory
and what "conda info" is reporting. This is not a fatal error, but if
an error is encountered, please check that your conda installation and
environments exist and are working.
"""
        warnings.warn(message, RuntimeWarning)
      split_version = conda_info['conda_version'].split('.')
      major_version = int(split_version[0])
      minor_version = int(split_version[1])
      if major_version < 4 or (major_version == 4 and minor_version < 4):
        raise RuntimeError("""
CCTBX programs require conda version 4.4 and greater to make use of the
common compilers provided by conda. Please update your version with
"conda update conda".
""")

      print('Base conda installation:\n  {base}'.format(base=self.conda_base),
            file=self.log)
      if self.verbose:
        output = check_output([self.conda_exe, 'info'], env=self.env)
        print(output, file=self.log)

    if self.conda_env is not None:
      print('Build environment:\n  {conda_env}'.format(
        conda_env=self.conda_env), file=self.log)

  # ---------------------------------------------------------------------------
  def get_conda_exe(self, prefix=None, check_file=None):
    """
    Find the conda executable. This is platform-dependent

    Parameters
    ----------
    prefix: str
      The path to the base conda environment
    check_file: bool
      Used to override the check_file attribute

    Returns
    -------
    conda_exe: str
      The path to the conda executable
    """
    if prefix is None:
      prefix = self.conda_base

    if check_file is None:
      check_file = self.check_file

    if self.system == 'Windows':
      conda_exe = os.path.join(prefix, 'Scripts', 'conda.exe')
    else:
      conda_exe = os.path.join(prefix, 'bin', 'conda')

    if check_file:
      if not os.path.isfile(conda_exe):
        raise RuntimeError(self.conda_exe_not_found)

    return conda_exe

  # ---------------------------------------------------------------------------
  def get_conda_python(self, conda_env=None, check_file=None):
    """
    Find the conda python. This is platform-dependent

    Parameters
    ----------
    conda_env: str
      The path to the conda environment
    check_file: bool
      Used to override the check_file attribute

    Returns
    -------
    conda_python: str
      The path to the conda python
    """
    if conda_env is None:
      conda_env = self.conda_env
    if conda_env is None:
      conda_env = self.conda_base
    if check_file is None:
      check_file = self.check_file

    if self.system == 'Windows':
      conda_python = os.path.join(conda_env, 'python.exe')
    elif self.system == 'Darwin':
      # use python.app for GUI applications
      conda_python = os.path.join(conda_env, 'python.app', 'Contents', 'MacOS',
                                  'python')
    else:
      conda_python = os.path.join(conda_env, 'bin', 'python')

    if check_file:
      if not os.path.isfile(conda_python):
        raise RuntimeError("""
  Python could not be located in {conda_env}. Please make sure {conda_env}
  is a valid conda environment and that Python is installed.
  """.format(conda_env=conda_env))

    return conda_python

  # ---------------------------------------------------------------------------
  def update_environments(self):
    """
    Read and check for existence of environment directories

    Returns
    -------
    environments: list
      List of paths that exist on the filesystem
    """
    environments = set()
    try:
      with open(self.environment_file) as f:
        paths = f.readlines()
      for env in paths:
        env = env.strip()
        if os.path.isdir(env):
          environments.add(os.path.normpath(env))
    except IOError:
      pass

    if self.conda_base is not None:
      env_dirs = [os.path.join(self.conda_base, 'envs'),
                  os.path.join(os.path.expanduser('~'), '.conda', 'envs')]
      for env_dir in env_dirs:
        if os.path.isdir(env_dir):
          dirs = os.listdir(env_dir)
          for _dir in dirs:
            _dir = os.path.join(env_dir, _dir)
            if os.path.isdir(_dir):
              environments.add(_dir)

    return environments

  # ---------------------------------------------------------------------------
  def install_miniconda(self, prefix=None):
    """
    Download a miniconda installer and install. The default installation
    location is at the same directory level as the "modules" directory.

    Parameters
    ----------
    prefix: str
      The installation directory for miniconda

    Returns
    -------
    conda_base: str
      The location of the "base" conda environment
    """

    if prefix is None:
      prefix = self.root_dir

    # construct Miniconda3 filename
    os_names = {
      'Darwin': 'MacOSX',
      'Linux': 'Linux',
      'Windows': 'Windows',
    }
    filename = 'Miniconda3-latest-{platform}-x86_64'.format(
      platform=os_names[self.system])
    if conda_platform[self.system] == 'osx-arm64':
      filename = 'Miniconda3-latest-{platform}-arm64'.format(
        platform=os_names[self.system])
    if self.system == 'Windows':
      filename += '.exe'
    else:
      filename += '.sh'
    url_base = 'https://repo.anaconda.com/miniconda/'
    url = urljoin(url_base, filename)
    filename = os.path.join(prefix, filename)

    # Download from public repository
    if not os.path.isfile(filename):
      print('Downloading {url}'.format(url=url), file=self.log)
      download_file(url, filename)
      print('Downloaded file to {filename}'.format(filename=filename),
        file=self.log)
    else:
      print('Using local copy at {filename}'.format(filename=filename),
        file=self.log)

    # run the installer
    install_dir = os.path.join(prefix, 'mc3')
    if self.system == 'Windows':
      flags = '/InstallationType=JustMe /RegisterPython=0 /AddToPath=0 /S /D={install_dir}'.\
        format(install_dir=install_dir)
      command_list = ['"' + filename + '"', flags]
    else:
      flags = ['-b', '-p', '{install_dir}'.format(install_dir=install_dir)]
      command_list = ['/bin/sh', filename] + flags
    print('Installing miniconda to "{install_dir}"'.format(
      install_dir=install_dir), file=self.log)
    output = check_output(command_list, env=self.env)
    if self.verbose:
      print(output, file=self.log)

    return install_dir

  # ---------------------------------------------------------------------------
  def update_conda(self):
    """
    Update the version of conda, if possible. The defaults channel is
    used because that is the default for a normal miniconda installation.

    Parameters
    ----------
      None
    """
    command_list = [self.conda_exe, 'update', '-n', 'base', '-c', 'defaults',
                    '-y', 'conda']
    try:
      output = check_output(command_list, env=self.env)
    except Exception:
      print("""
*******************************************************************************
There was a failure in updating your base conda installaion. To update
manually, try running

  conda update -n base -c defaults conda

If you are using conda from a different channel, replace "defaults" with that
channel
*******************************************************************************
""")
    else:
      print(output)

  # ---------------------------------------------------------------------------
  def _retry_command(self, command_list, text, prefix, verbose=None):
    """
    Internal convenience function for retrying creation/update of a
    conda environment.

    Parameters
    ----------
      command_list: list
        Command list for check_output
      text: str
        Text to be printed. Usually "installion into" or "update of"
      prefix: str
        Directory of conda environment
      verbose: bool
        Used to override self.verbose

    Returns
    -------
      Nothing
    """

    run_command = check_output
    if self.verbose or verbose:
      run_command = call

    for retry in range(self.max_retries):
      retry += 1
      try:
        output = run_command(command_list, env=self.env)
      except Exception:
        print("""
*******************************************************************************
There was a failure in constructing the conda environment.
Attempt {retry} of {max_retries} will start {retry} minute(s) from {t}.
*******************************************************************************
""".format(retry=retry, max_retries=self.max_retries, t=time.asctime()))
        time.sleep(retry*60)
      else:
        break
    if retry == self.max_retries:
      raise RuntimeError("""
The conda environment could not be constructed. Please check that there is a
working network connection for downloading conda packages.
""")
    print('Completed {text}:\n  {prefix}'.format(text=text, prefix=prefix),
          file=self.log)

    # check that environment file is updated
    self.environments = self.update_environments()
    if prefix not in self.environments:
      raise RuntimeError("""
The newly installed environment cannot be found in
${HOME}/.conda/environments.txt.
""")

  # ---------------------------------------------------------------------------
  def create_environment(self, builder='cctbx', filename=None, python=None,
    copy=False, offline=False):
    """
    Create the environment based on the builder and file. The
    environment name is "conda_base".

    Parameters
    ----------
    builder: str
      The builder from bootstrap.py. The default environment is defined
      by the env_locations class variable
    filename: str
      If filename is not None, the argument overrides the file defined
      in the env_locations dictionary. The filename should be a
      relative path to the "modules" directory.
    python: str
      If set, the specific Python version of the environment for the
      builder is used instead of the default. Current options are
      '27' and '36' for Python 2.7 and 3.6, respectively.
    copy: bool
      If set to True, the --copy flag is passed to conda
    offline: bool
      If set to True, the --offline flag is passed to conda
    """

    # handles check for choices in case parser is not available
    if builder not in self.env_locations:
      raise RuntimeError("""
The builder, {builder}, is not recognized. The available builders are,
{builders}
""".\
format(builder=builder, builders=', '.join(sorted(self.env_locations.keys()))))

    if self.conda_base is None:
      raise RuntimeError("""A conda installation is not available.""")

    if builder == "dials" and python in ("27", "36"):
      builder = "dials-old"

    if filename is None:
      filename = os.path.join(
        self.root_dir, 'modules', self.env_locations[builder])
      if python is not None:
        if python not in ['27', '37', '38', '39', '310', '311', '312', '313']:
          raise RuntimeError(
            """Only Python 2.7, 3.7, 3.8, 3.9, and 3.10 are currently supported.""")
        filename = filename.replace('PYTHON_VERSION', python)
    else:
      filename = os.path.abspath(filename)

    if not os.path.isfile(filename):
      raise RuntimeError("""\
The file, {filename}, is not available. Please contact the developers to make \
sure that the requested version of Python is supported for the {builder} \
builder.""".format(filename=filename, builder=builder))

    yaml_format = False
    if filename.endswith('yml') or filename.endswith('yaml'):
      yaml_format = True

    # make a new environment directory
    if self.conda_env is None:
      name = 'conda_base'
      prefix = os.path.join(self.root_dir, name)
    # or use the existing one
    else:
      prefix = os.path.abspath(self.conda_env)

    # compare time stamps of the filename and environment directory
    # only install/update if the time stamp of the filename is more recent
    file_stats = None
    env_stats = None
    if os.path.exists(filename):
      file_stats = os.stat(filename)
    if os.path.exists(prefix):
      env_stats = os.stat(prefix)

    if env_stats is not None and file_stats is not None:
      if env_stats.st_mtime > file_stats.st_mtime:
        print('The environment is newer than the environment file. Skipping update.',
              file=self.log)
        return

    # install a new environment or update and existing one
    if prefix in self.environments:
      command = 'install'
      if yaml_format:
        command = 'update'
      text_messages = ['Updating', 'update of']
    else:
      command = 'create'
      text_messages = ['Installing', 'installation into']
    command_list = [self.conda_exe, command, '--prefix', prefix,
                    '--file', filename]
    if yaml_format:
      command_list.insert(1, 'env')
    if self.system == 'Windows':
      command_list = [os.path.join(self.conda_base, 'Scripts', 'activate'),
                      'base', '&&'] + command_list
    if copy and not yaml_format:
      command_list.append('--copy')
    if offline and not yaml_format:
      command_list.append('--offline')
    if builder in ("dials", "dials-old", "xfel", "labelit") and not yaml_format:
      command_list.append("-y")
    if builder in self.env_without_python:
      python_version = tuple(int(i) for i in (python or "36"))
      python_requirement = '"conda-forge::python>=%s.%s,<%s.%s"' % (
          python_version[0],
          python_version[1],
          python_version[0],
          python_version[1] + 1,
      )
      command_list.append(python_requirement)
    # RuntimeError is raised on failure
    print('{text} {builder} environment with:\n  {filename}'.format(
          text=text_messages[0], builder=builder, filename=filename),
          file=self.log)

    self._retry_command(command_list, text_messages[1], prefix, verbose=True)

    # on Windows, also download the Visual C++ 2008 Redistributable
    # use the same version as conda-forge
    # https://github.com/conda-forge/vs2008_runtime-feedstock
    if self.system == 'Windows' and prefix.endswith('conda_base'):
      download_file(
        url='https://download.microsoft.com/download/5/D/8/5D8C65CB-C849-4025-8E95-C3966CAFD8AE/vcredist_x64.exe',
        filename=os.path.join(prefix, 'vcredist_x64.exe'))

# ---------------------------------------------------------------------------
  def create_dev_environment(self, svn=False, git=True):
    """
    Create a separate environment for development tools. Packages from
    the conda-forge channel are used.

    Package list:
      svn
      git
      git-lfs

    Parameters
    ----------
      svn: bool
        If set to true, svn is installed. This is useful for Xcode 11.4
        and later where svn is no longer available.
      git: bool
        If set to true, git is installed with git-lfs. This is needed
        for repositories that use git-lfs.

    Returns
    -------
      dev_dir: str
        The directory with the environment
    """

    package_list = []
    if svn:
      package_list.append('svn')
    if git:
      package_list.append('git')
      package_list.append('git-lfs')

    prefix = os.path.join(self.root_dir, 'dev_env')
    command = 'create'
    text_messages = ['Installing', 'installation into']
    if prefix in self.environments:
      command = 'update'
      text_messages = ['Updating', 'update of']

    command_list = [self.conda_exe, command, '-y', '-c', 'conda-forge',
                    '--prefix', prefix] + package_list

    print('-'*79, file=self.log)
    print('{text} extra development environment containing:'.format(text=text_messages[0]),
          file=self.log)
    for package in package_list:
      print('  -', package, file=self.log)

    self._retry_command(command_list, text_messages[1], prefix, verbose=True)

    print('-'*79, file=self.log)
    return prefix

  # ---------------------------------------------------------------------------
  def write_conda_setpaths(self, prefix='conda', build_dir=None,
                           conda_env=None, check_file=True):
    """
    Write a script similar to setpaths.sh/csh/bat that activates the environment
    first. This is useful for developers that want to use other software
    installed in the conda environment without having to manually activate it.

    Parameters
    ----------
      prefix: str
        The prefix for the output file. The output file will be constructed
        as <prefix>_<script name>.<extension>. The <script name> is the
        standard setpaths or unsetpaths file, and the <extension> will be
        the existing extensions for the script (sh, csh, and bat)
      build_dir: str
        The build directory where the standard setpaths script resides.
      conda_env: str
        The conda environment directory
      check_file: bool
        Used to override the check_file attribute

    Returns
    -------
      Nothing
    """

    if check_file is None:
      check_file = self.check_file

    # check that build_dir is valid
    if build_dir is None:
      build_dir = os.getenv('LIBTBX_BUILD')
    if build_dir is None:
      raise RuntimeError("""\
Please run the dispatcher version of libtbx.install_conda or provide a valid
directory as an argument to the write_conda_setpaths function.""")

    build_dir_error = """\
Please provide the directory to the setpaths script.
"""
    if build_dir is None or not os.path.isdir(build_dir):
      raise RuntimeError(build_dir_error)
    if sys.platform == 'win32':
      if not os.path.isfile(os.path.join(build_dir, 'setpaths.bat')):
        raise RuntimeError(build_dir_error)
    else:
      if not os.path.isfile(os.path.join(build_dir, 'setpaths.sh')) \
         or not os.path.isfile(os.path.join(build_dir, 'setpaths.csh')):
        raise RuntimeError(build_dir_error)

    # check conda_env
    if conda_env is None:
      conda_env = self.conda_env
    if conda_env is None:
      from libtbx.env_config import get_conda_prefix
      conda_env = get_conda_prefix()
    conda_env = os.path.abspath(conda_env)

    # -------------------------------------------------------------------------
    def do_check_file(filename):
      """
      Convenience function for checking if the script was written.
      """
      if os.path.isfile(filename):
        print('{filename} has been written successfully.'.format(
          filename=os.path.basename(filename)))
      else:
        raise RuntimeError("""
{filename} has not been written successfully.""".format(filename=filename))
    # -------------------------------------------------------------------------

    # Windows
    if sys.platform == 'win32':
      script_template = """\
@ECHO OFF
CALL {mc3_dir} {conda_env}
CALL {setpaths}
"""
      # activate
      mc3_dir = os.path.abspath(
        os.path.join(self.conda_base, 'Scripts', 'activate.bat'))
      setpaths = os.path.abspath(os.path.join(build_dir, 'setpaths.bat'))
      filename = os.path.abspath(os.path.join(build_dir, prefix + '_setpaths.bat'))
      with open(filename, 'w') as f:
        f.write(script_template.format(
          mc3_dir=mc3_dir, conda_env=conda_env, setpaths=setpaths))
      if check_file:
        do_check_file(filename)
      # deactivate
      mc3_dir = 'conda'
      conda_env = 'deactivate'
      setpaths = os.path.abspath(os.path.join(build_dir, 'unsetpaths.bat'))
      filename = os.path.abspath(
        os.path.join(build_dir, prefix + '_unsetpaths.bat'))
      with open(filename, 'w') as f:
        f.write(script_template.format(
          mc3_dir=mc3_dir, conda_env=conda_env, setpaths=setpaths))
      if check_file:
        do_check_file(filename)
    # linux and macOS
    else:
      for ext in ('sh', 'csh'):
        # activate
        script_template = """\
source {mc3_dir}
{get_old_prompt}
conda activate {conda_env}
{set_old_prompt}
{unset_old_prompt}
source {setpaths}
"""
        mc3_dir = os.path.abspath(
          os.path.join(self.conda_base, 'etc', 'profile.d', 'conda.' + ext))
        if ext == 'sh':
          get_old_prompt = 'LIBTBX_OLD_PS1=$PS1'
          set_old_prompt = 'PS1=$LIBTBX_OLD_PS1'
          unset_old_prompt = 'unset LIBTBX_OLD_PS1'
        else:
          get_old_prompt = 'set libtbx_old_prompt="$prompt"'
          set_old_prompt = 'set prompt="$libtbx_old_prompt"'
          unset_old_prompt = 'unset libtbx_old_prompt'
        setpaths = os.path.abspath(os.path.join(build_dir, 'setpaths.' + ext))
        filename = os.path.abspath(
          os.path.join(build_dir, prefix + '_setpaths.' + ext))
        with open(filename, 'w') as f:
          f.write(script_template.format(
            mc3_dir=mc3_dir, get_old_prompt=get_old_prompt, conda_env=conda_env,
            set_old_prompt=set_old_prompt, unset_old_prompt=unset_old_prompt,
            setpaths=setpaths))
        if check_file:
          do_check_file(filename)
        # deactivate
        script_template = """\
conda deactivate
source {setpaths}
"""
        setpaths = os.path.abspath(os.path.join(build_dir, 'unsetpaths.' + ext))
        filename = os.path.abspath(
          os.path.join(build_dir, prefix + '_unsetpaths.' + ext))
        with open(filename, 'w') as f:
          f.write(script_template.format(setpaths=setpaths))
        if check_file:
          do_check_file(filename)

# =============================================================================
def run():
  prog = os.environ.get('LIBTBX_DISPATCHER_NAME')
  if prog is None or prog.startswith('python') or prog.endswith('python'):
    prog = os.path.basename(sys.argv[0])

  epilog = """
Example usage:

  {prog}
    Shows this help screen

  {prog} --verbose
    Shows if a base conda installation can be found. If no installation
    is found, the latest miniconda3 will be installed.

  {prog} --install_conda --builder=<builder>
    Install conda and default environment for <builder>

  {prog} --install_conda --builder=<builder> --python=37
    Install conda and default Python 3.7 environment for <builder>

  {prog} --conda_base=<path> --builder=<builder>
    Install default environment for <builder> with known conda installation

  {prog} --conda_env=<path> --builder=<builder>
    Update conda environment for builder

""".format(prog=prog)

  parser = argparse.ArgumentParser(
    prog=prog, description=__doc__, epilog=epilog,
    formatter_class=argparse.RawDescriptionHelpFormatter)

  # CLI options
  parser.add_argument(
    '--builder', default=None, type=str, nargs='?', const='cctbx',
    choices=sorted(conda_manager.env_locations.keys()),
    help="""Install the default environment for a builder. The choices are the
      same as the ones for bootstrap.py. The default builder is "cctbx." """)
  parser.add_argument(
    '--python', default='37', type=str, nargs='?', const='37',
    choices=['27', '37', '38', '39', '310', '311', '312', '313'],
    help="""When set, a specific Python version of the environment will be used.
    This only affects environments selected with the --builder flag.""")
  parser.add_argument(
    '--install_conda', action='store_true',
    help="""When set, conda will be automatically downloaded and installed
      regardless of an existing installation.""")
  parser.add_argument(
    '--update_conda', action='store_true',
    help="""When set, conda will try to update itself to the latest version.
      This should only be used if your conda installation was installed by
      this script or if your conda is writeable and uses the "defaults"
      channel""")
  parser.add_argument(
    '--install_env', default=None, type=str, nargs='?', const='',
    metavar='ENV_FILE',
    help="""When set, the environment for the builder will be installed. The
      default environment can be overridden by providing a path to the
      environment file.""")
  parser.add_argument(
    '--install_dev_env', action='store_true',
    help="""When set, an additional environment named dev_env will be
    created that contains extra development tools (svn, git, git-lfs).""")
  parser.add_argument(
    '--conda_base', default=None, type=str, metavar='BASE_DIRECTORY',
    help="""The location of the base conda environment. This is useful for
      systems where there is a multiuser installation of conda. Providing the
      path will ensure the the correct conda is used. To determine the base
      location, run "conda info" and look for the "base environment" setting.
      This is required, otherwise, a new conda installation will be created.""")
  parser.add_argument(
    '--conda_env', default=None, type=str, metavar='ENV_DIRECTORY',
    help="""The location of the conda environment for building. This is useful
      for when the exact conda environment is known. Providing the path will
      ensure that that environment is used. Using $CONDA_PREFIX as the
      argument will use the currently active environment for building.""")
  parser.add_argument(
    '--write_setpaths', default=None, type=str, nargs='?', metavar='PREFIX',
    const='conda',
    help="""When set, another script is added that activates the conda
      environment before sourcing the setpaths script. Optionally, the prefix
      of the script can be provided. The output files will be named
      <prefix>_setpaths.<extension> and <prefix>_unsetpaths.<extension>
      where the extension will be "sh"/"csh" for linux and macOS, and
      "bat" for Windows.""")
  parser.add_argument(
    '--copy', action='store_true', default=False,
    help="""When set, the new environment has copies, not links to files. This
      should only be used when building installers.""")
  parser.add_argument(
    '--offline', action='store_true', default=False,
    help="""When set, the network will not be accessed for installing packages.
      This should only be used if the packages are already cached.""")
  parser.add_argument(
    '--verbose', action='store_true', default=False,
    help="""When set, output from conda is displayed. """)

  # show help if no arguments are provided
  if len(sys.argv) == 1:
    parser.print_help()
    parser.exit()

  namespace = parser.parse_args()

  # logic for installing conda
  conda_base = namespace.conda_base
  if namespace.install_conda:
    conda_base = None

  # logic for installing environment
  filename = None
  builder = namespace.builder
  if namespace.install_env is not None:
    tmp_filename = os.path.abspath(namespace.install_env)
    if os.path.isfile(tmp_filename):
      filename = tmp_filename
    if builder is None:
      builder = 'cctbx'

  m = conda_manager(root_dir=root_dir, conda_base=conda_base,
                    conda_env=namespace.conda_env, check_file=True,
                    verbose=namespace.verbose)

  # if --update_conda is set, try to update now
  if namespace.update_conda:
    m.update_conda()

  # if --install_dev_env is set, construct development environment
  if namespace.install_dev_env:
    m.create_dev_environment()

  # if builder is available, construct environment
  if builder is not None:
    m.create_environment(builder=builder, filename=filename,
                         python=namespace.python,
                         copy=namespace.copy, offline=namespace.offline)

  # if --write_setpaths is set, write the extra script
  if namespace.write_setpaths is not None:
    m.write_conda_setpaths(prefix=namespace.write_setpaths, check_file=True)

  return 0

# =============================================================================
if __name__ == '__main__':
  sys.exit(run())

# =============================================================================
# end


 *******************************************************************************
