

 *******************************************************************************
mmtbx/programs/probescore_ligand.py
from __future__ import absolute_import, division, print_function

from libtbx.program_template import ProgramTemplate
from cctbx.array_family import flex
import mmtbx.model
import iotbx.pdb
from libtbx.utils import Sorry

from mmtbx.validation.molprobity import probescore_ligand
import os

class Program(ProgramTemplate):

  description = '''
molprobity.probescore_ligand: wrapper for probescore analysis of ligands
  Allows residue selections using Phenix atom selection syntax
    (see https://www.phenix-online.org/documentation/reference/atom_selections.html)
  Returns human-readable digest, raw probe results, or compact oneline

  For best results, use an input file that already contains correct hydrogens
    and the has_h=True flag.  Otherwise, probescore will attempt to add
    hydrogens for you, and this is not always reliable for ligands.

  Currently only whole-residue selections are supported. If you wish to select
    more or less, like a sidechain or a domain interface, use molprobity.probe
    directly.

  Multiple selections can be made in a single command and each will be reported
    separately.

  A single selection can contain multiple residues, suitable for polysaccharides
    See selection syntax for details.
    Selections of > about 30 residues may not work.

Usage examples:
  Select single ligand:
    molprobity.probescore_ligand model_H.pdb has_h=True "chain A resseq 350"
  Select multiple separate ligands:
    molprobity.probescore_ligand model.pdb "chain A resseq 350" "chain A resseq 352" output=oneline
  Select single multi-residue ligand, like carbohydrate:
    molprobity.probescore_ligand model.pdb "chain A resseq 350:355"
  '''

  datatypes = ['model', 'phil']

  master_phil_str = """
  probescore {
    output = *digest raw oneline
      .type = choice
      .help = '''choose output type'''
    has_h = False
      .type = bool
      .help = '''does input file have hydrogens?'''
    nuclear=False
      .type = bool
      .help = '''hydrogen distance for Reduce and Probe, ecloud by default'''
  }
  atom_selection_program {
    inselection = None
      .type = atom_selection
      .help = what to select
      .multiple = True
  }
"""

  # ---------------------------------------------------------------------------
  def validate(self):
    print('Validating inputs', file=self.logger)
    self.data_manager.has_models(raise_sorry=True)
    if (self.params.atom_selection_program.inselection is None or
        len(self.params.atom_selection_program.inselection) == 0):
      raise Sorry("Need selections")

  # ---------------------------------------------------------------------------
  def run(self):
    filename = os.path.basename(self.data_manager.get_model_names()[0])
    model = self.data_manager.get_model()
    atoms = model.get_atoms()
    all_bsel = flex.bool(atoms.size(), False)
    selection_string_list = []
    for selection_string in self.params.atom_selection_program.inselection:
      selection_string_list.append(selection_string)
    probescore = probescore_ligand.probescore(model, selection_string_list, self.params.probescore.has_h, nuclear=False, out=self.logger)
    if self.params.probescore.output == "digest":
      probescore.print_as_digest()
    elif self.params.probescore.output == "raw":
      probescore.print_as_raw()
    elif self.params.probescore.output == "oneline":
      probescore.print_as_oneline(filename=filename)

  # ---------------------------------------------------------------------------
  def get_results(self):
    return None


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/process_predicted_model.py
# -*- coding: utf-8 -*-

from __future__ import division, print_function
import os
from libtbx.utils import Sorry
from libtbx import group_args
try:
  from phenix.program_template import ProgramTemplate
except ImportError:
  from libtbx.program_template import ProgramTemplate

# =============================================================================
class Program(ProgramTemplate):
  description = '''
Replace values in B-factor field with estimated B values.
Optionally remove low-confidence residues and split into domains.

Inputs: Model file (PDB, mmCIF)
'''

  datatypes = ['phil', 'model', 'sequence']

  master_phil_str = """

  job_title = None
    .type = str
    .input_size = 400
    .help = Job title in PHENIX GUI, not used on command line
    .style = noauto bold

  input_files {
    chain_id = None
      .type = str
      .short_caption = chain_id
      .help = If specified, find domains in this chain only. NOTE: only one \
                chain can be used for finding domains at a time.
      .input_size = 400

    selection = None
      .type = str
      .short_caption = Selection
      .help = If specified, use only selected part of model
       .input_size = 400

    pae_file = None
      .type = path
      .help = Optional input json file with matrix of inter-residue estimated\
               errors (pae file)
      .short_caption = PAE file

    distance_model_file = None
      .type = path
      .help = Distance_model_file. A PDB or mmCIF file containing the model \
               corresponding to the PAE  \
               matrix. Only needed if weight_by_ca_ca_distances is True and \
               you want to specify a file other than your model file. (Default\
               is to use the model file)
      .short_caption = Distance model file

    model = None
      .type = path
      .help = Input predicted model (e.g., AlphaFold model).  Assumed to \
                have LDDT values in B-value field (or RMSD values).
      .style = file_type:pdb input_file
      .short_caption = Predicted model
      .expert_level = 3

  }
  output_files {
     target_output_format = *None pdb mmcif
       .type = choice
       .help = Desired output format (if possible). Choices are None (\
                try to use input format), pdb, mmcif.  If output model\
                 does not fit in pdb format, mmcif will be used. \
                 Default is pdb.
       .short_caption = Desired output format

    processed_model_prefix = None
      .type = str
      .help = Output file with processed models will begin with this prefix.\
               If not specified, the input model file name will be used with\
               the suffix _processed.
      .short_caption = Output file prefix (optional)

    remainder_seq_file_prefix = None
      .type = str
      .help = Output file with sequences of deleted parts of model \
          will begin with this prefix
      .short_caption = Output remainder seq file prefix

    mark_atoms_to_keep_with_occ_one = False
       .type = bool
       .help = Mark atoms to keep with occupancy of 1 and those to remove \
                  with zero (default is to remove those that are not desired)
       .short_caption = Mark atoms to keep with occupancy of 1


     maximum_output_b = 999.
       .type = float
       .help = Limit output B values (so that they fit in old-style PDB \
              format). Note that this limit is applied just before writing \
              output model files, it does not affect anything else. Also \
              if output model is trimmed normally, high-B value residues are\
              already removed, so in most cases this keyword has no effect.
       .short_caption = Maximum output B

     remove_hydrogen = True
       .type = bool
       .help = Remove hydrogen atoms from model on input
       .short_caption = Remove hydrogen

     single_letter_chain_ids = False
       .type = bool
       .help = Write output files with all chain IDS as single characters.\
                Default is to use original chain ID and to add digits (1-9)\
                for domains.
       .short_caption = Use only single-letter chain ID

  }

  include scope mmtbx.process_predicted_model.master_phil_str
  control {

    write_files = True
      .type = bool
      .help = Write output files
      .short_caption = Write output files
   }


  gui
    .help = "GUI-specific parameter required for output directory"
  {
    output_dir = None
    .type = path
    .style = output_dir
  }


  """

  def run(self):

    # print version and date
    # self.print_version_info()
    self.data_manager.set_overwrite(True)

    #
    self.get_data_inputs()  # get any file-based information
    from iotbx.pdb.utils import set_target_output_format_in_params
    set_target_output_format_in_params(self.params)

    # self.print_params()
    self.starting_model = self.model
    self.model_list = []
    self.processed_model = None
    self.processed_model_text = None
    self.processed_model_file_name = None
    self.processed_model_file_name_list = []

    # Split by chain ID. Normally only one chain ID but run separately if more
    working_model_list = self.model.as_model_manager_each_chain()
    from mmtbx.process_predicted_model import process_predicted_model

    processed_model_list = []
    remainder_sequence_str_list = []
    for model in working_model_list:
      # Run on each unique chain ID
      info = process_predicted_model(model = model,
       distance_model = self.distance_model,
       params = self.params,
       pae_matrix = self.pae_matrix,
       mark_atoms_to_keep_with_occ_one = \
          self.params.output_files.mark_atoms_to_keep_with_occ_one,
       log = self.logger,
       )

      if not info:
        print("Unable to process predicted model", file = self.logger)
        return

      self.model_list += info.model_list
      processed_model_list.append(info.model)
      remainder_sequence_str_list.append(info.remainder_sequence_str)


    if len(processed_model_list) > 1:
      # rename chains to match orig and merge. Limited functionality here
      for m, orig_m in zip(processed_model_list, working_model_list):
        chain_id = orig_m.first_chain_id()
        for model_m in m.get_hierarchy().models()[:1]:
          for chain in model_m.chains():
            chain.id = chain_id

      from iotbx.pdb.utils import add_model
      self.processed_model = processed_model_list[0]
      for m in processed_model_list[1:]:
        self.processed_model = add_model(self.processed_model, m)
    else: # usual
      self.processed_model = processed_model_list[0]

    self.dock_and_rebuild = group_args(
      group_args_type = 'dummy dock_and_rebuild for summary',
      processed_model = self.processed_model)

    if not self.params.control.write_files:
      return  # done


    starting_residues = self.model.get_hierarchy().overall_counts().n_residues
    print("\nStarting residues: %s" %(starting_residues), file = self.logger)

    if self.params.output_files.processed_model_prefix:
      prefix = self.params.output_files.processed_model_prefix
    else:
      prefix, ext  = os.path.splitext(self.params.input_files.model)
      prefix = "%s_processed" %(prefix)
      prefix = os.path.basename(prefix)
    self.processed_model_file_name = "%s.pdb" %(prefix) # PDB OK updated below
    if not self.processed_model or \
         self.processed_model.overall_counts().n_residues < 1:
      print("No residues obtained after processing...", file = self.logger)
      return None

    # Special case: write out split models marking residues as missing with
    #   occ = 0
    if self.params.output_files.mark_atoms_to_keep_with_occ_one:
      ii = 0
      for m in self.model_list:
        ii += 1
        fn = "%s_%s.pdb" %(prefix,ii)
        fn = self.data_manager.write_model_file(
           m, fn,
           format=self.params.output_files.target_output_format)
        print("Wrote model with all residues present to %s" %(fn)
          +"\n marking domain %s with" %(
           ii) + " occupancy=1 and rest with occupancy=0")
      return
    if (self.params.output_files.maximum_output_b is not None) and (
       self.processed_model.get_b_iso().min_max_mean().max >
       self.params.output_files.maximum_output_b):
      print("Limiting output B values to %.0f" %(
        self.params.output_files.maximum_output_b), file = self.logger)
    mm = limit_output_b(self.processed_model,
         maximum_output_b = self.params.output_files.maximum_output_b)

    if self.params.output_files.single_letter_chain_ids:
      # convert all chain_ids to single character (A)
      mm_to_split = convert_chain_ids_to_single_character(mm, chain_id = "A")
    else:
      mm_to_split = mm

    # original (multi-char chain IDs)

    self.processed_model_file_name = self.data_manager.write_model_file(
      mm, self.processed_model_file_name,
      format=self.params.output_files.target_output_format)

    final_residues = mm.get_hierarchy().overall_counts().n_residues
    print("Final residues: %s\n" %(final_residues), file = self.logger)

    # Split up processed model and write each chain as well
    if len(mm_to_split.chain_ids()) > 1 or \
         self.params.output_files.single_letter_chain_ids:
      model_list = mm_to_split.as_model_manager_each_chain()
    else:
      model_list = [mm_to_split]
    count = 0
    for m in model_list:
      count += 1
      chain_id = m.first_chain_id().strip()
      if not chain_id:
        if len(model_list) > 1:
          raise Sorry(
           "Input model cannot have a blank chain ID and non-blank chain IDS")
        chain_id = "A"
      fn = "%s_%s_%s.pdb" %(prefix,chain_id, count)      # PDB OK (updated below)
      if not m or not m.overall_counts().n_residues:
        print("Skipping #%s (no residues)" %(count), file = self.logger)
        continue
      mm = limit_output_b(m,
           maximum_output_b = self.params.output_files.maximum_output_b)
      fn = self.data_manager.write_model_file(mm,fn,
        format=self.params.output_files.target_output_format)
      print("Copying predicted model chain %s (#%s) to %s" %(
           chain_id,count,fn), file = self.logger)

      self.processed_model_file_name_list.append(fn)


    # Write out seq file for remainder (unused part) of model
    if remainder_sequence_str_list:
      remainder_sequence_str = "\n".join(remainder_sequence_str_list)
      if self.params.output_files.remainder_seq_file_prefix:
        prefix = self.params.output_files.remainder_seq_file_prefix
      else:
        prefix, ext  = os.path.splitext(self.params.input_files.model)
        prefix = "%s_remainder" %(prefix)
        prefix = os.path.basename(prefix)
      self.remainder_sequence_file_name = os.path.join(
        os.getcwd(), "%s.seq" %(prefix))
      sequence_str = remainder_sequence_str
      self.data_manager.write_sequence_file(sequence_str,
        filename = self.remainder_sequence_file_name)

    # Summarize each step

    self.summarize_predicted_model()

    print ('\nFinished with process_predicted_model', file=self.logger)
  # ---------------------------------------------------------------------------
  def get_results(self):

    return group_args(
      group_args_type = 'results of process_predicted_model',
      starting_model = self.starting_model,
      processed_model = self.processed_model,
      processed_model_file_name = self.processed_model_file_name,
      processed_model_file_name_list = self.processed_model_file_name_list,
      model_list = self.model_list,
      processed_model_text = self.processed_model_text,
      params = self.params)

# =============================================================================
#    Custom operations
# =============================================================================
#

  def summarize_predicted_model(self):
    #  Process predicted model
    dr = self.dock_and_rebuild
    processed_model = dr.processed_model
    if processed_model:
      chain_id_list = processed_model.chain_ids()
      text = ""
      text += "Processed model with %s domains and %s residues " %(
           len(chain_id_list),
           processed_model.get_hierarchy().overall_counts().n_residues,)
      text += "\n\nResidues by domain (as chains):"

      self.processed_model_text = ""
      for chain_id in chain_id_list:
        m = processed_model.apply_selection_string("chain '%s'" %(chain_id))
        n_found = m.get_hierarchy().overall_counts().n_residues
        text += "\nCHAIN: %s   Residues: %s " %(
           chain_id,n_found)
        print(text, file = self.logger)
        self.processed_model_text += text
    else:
        self.processed_model_text = "No processed model information available"


  def set_defaults(self):
    # set params for files identified automatically and vice versa
    params=self.params
    self.titles=[]

    # Read in default model as pdb_in
    file_name = getattr(params.input_files,'model',None)
    if file_name:
      if not os.path.isfile(file_name):
        raise Sorry("The file %s is missing?" %(file_name))
      else:
        pass # ok so far
    else: # guess it
      try:
        file_name=self.data_manager.get_default_model_name()
        self.params.input_files.model=file_name
      except Exception as e:
        pass # did not work

  def get_data_inputs(self):  # get any file-based information
    self.set_defaults()
    file_name=self.params.input_files.model
    if not file_name:
      raise Sorry("Unable to guess model file name...please specify")
    if not os.path.isfile(file_name):
      raise Sorry("Missing the model file '%s'" %(file_name))
    try:
      self.model=self.data_manager.get_model(filename=file_name)
    except Exception as e:
      raise Sorry("Failed to read model file '%s'" %(file_name))

    print("Read model from %s" %(file_name), file = self.logger)

    if not self.model:
      raise Sorry("Missing model")

    self.model.add_crystal_symmetry_if_necessary()

    # Remove waters and hetero atoms (ligands)
    self.model = self.model.apply_selection_string(
       "(not hetero) and (not water)")

    # Remove hydrogens and apply user selection
    selections = []
    if self.params.output_files.remove_hydrogen:
      selections.append("(not (element H))")
    if self.params.input_files.selection:
      selections.append("(%s)" %(self.params.input_files.selection))
    if selections:
      self.model = self.model.apply_selection_string(" and ".join(selections))

    if self.params.process_predicted_model.weight_by_ca_ca_distance:
      if not self.params.input_files.distance_model_file:
        self.params.input_files.distance_model_file = \
           self.params.input_files.model
      file_name=self.params.input_files.distance_model_file
      self.distance_model = self.data_manager.get_model(filename=file_name)
      print("Read distance model from %s" %(file_name), file = self.logger)
      self.distance_model.add_crystal_symmetry_if_necessary()
    else:
      self.distance_model = None

    if self.params.input_files.pae_file and \
       os.path.isfile(self.params.input_files.pae_file):
      from mmtbx.domains_from_pae import parse_pae_file
      self.pae_matrix = parse_pae_file(self.params.input_files.pae_file)
    else:
      self.pae_matrix = None

    if len(self.model.chain_ids()) > 1:
      if self.distance_model:
        raise Sorry(
          "The distance model cannot currently be used for multiple chains")
      if self.pae_matrix:
        raise Sorry(
          "The PAE matrix cannot currently be used for multiple chains")

  def validate(self):  # make sure we have files
    return True

  def print_params(self):
    import iotbx.phil
    master_phil = iotbx.phil.parse(master_phil_str)
    print ("\nInput parameters for process_predicted_model:\n", file = self.logger)
    master_phil.format(python_object = self.params).show(out = self.logger)

  def print_version_info(self):

    # Print version info
    import time
    print ("\n"+60*"*"+"\n"+10*" "+"PHENIX process_predicted_model" +\
      "  "+str(time.asctime())+"\n"+60*"*"+"\n",file=self.logger)
    print ("Working directory: ",os.getcwd(),"\n",file=self.logger)
    print ("PHENIX VERSION: ",os.environ.get('PHENIX_VERSION','svn'),"\n",
     file=self.logger)

def convert_chain_ids_to_single_character(m, chain_id = "A"):

  from mmtbx.secondary_structure.find_ss_from_ca import set_chain_id
  # rename all chains to "A" but keep separate chains for different segments
  mm = m.deep_copy()
  set_chain_id(mm.get_hierarchy(), chain_id)
  mm.reset_after_changing_hierarchy()
  return mm

def get_available_letter(c, all_letters, used_ids):

  if len(c) == 1 and not c in used_ids:
    return c
  if c and (not (c[0] in used_ids)):
    return c[0]

  for a in all_letters:
    if not (a in used_ids):
      return a
  return None



def limit_output_b(m, maximum_output_b = None):
  """ create deep copy of model m in which all isotropic
      values > maximum_output_b
      are set to maximum_output_b. If maximum_output_b is None or there are no
      b-values > maximum_output_b, return original model (not deep copy)"""

  if (maximum_output_b is not None) and (
       m.get_b_iso().min_max_mean().max > maximum_output_b):
    b_values = m.get_b_iso()
    b_values.set_selected((b_values > maximum_output_b), maximum_output_b)
    mm = m.deep_copy() # REQUIRED so we do not modify b-values in m itself
    mm.set_b_iso(b_values)
    return mm
  else:
    return m
# =============================================================================
# for reference documentation keywords
master_phil_str = Program.master_phil_str


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/quantum_interface.py
# LIBTBX_SET_DISPATCHER_NAME phenix.development.qi
from __future__ import absolute_import, division, print_function
import os
import sys
import time
import copy

from libtbx.program_template import ProgramTemplate

from mmtbx.monomer_library.linking_setup import ad_hoc_single_metal_residue_element_types

from mmtbx.geometry_restraints.quantum_restraints_manager import run_energies
from mmtbx.geometry_restraints.quantum_restraints_manager import update_restraints
from mmtbx.geometry_restraints.quantum_restraints_manager import min_dist2
from mmtbx.geometry_restraints.quantum_interface import get_qm_restraints_scope
from mmtbx.geometry_restraints.quantum_interface import get_working_directory
from mmtbx.geometry_restraints.qi_utils import classify_histidine
from mmtbx.geometry_restraints.qi_utils import run_serial_or_parallel
from mmtbx.geometry_restraints.qi_utils import get_hbonds_via_filenames
from mmtbx.geometry_restraints.qi_utils import get_rotamers_via_filenames

import iotbx.pdb
import iotbx.phil
from libtbx import Auto
from libtbx.utils import Sorry
from libtbx.utils import null_out
from libtbx.utils import multi_out

from mmtbx.monomer_library.linking_setup import ad_hoc_single_metal_residue_element_types

get_class = iotbx.pdb.common_residue_names_get_class

def stepper(b,e,s):
  b=float(b)
  e=float(e)
  s=float(s)
  for i in range(100):
    yield b
    b+=s
    if b>e: break

def merge_water(filenames, chain_id='A'):
  hierarchies = []
  for filename in filenames:
    ph = iotbx.pdb.input(filename).construct_hierarchy()
    hierarchies.append(ph)
  waters = {}
  for ph in hierarchies:
    for ag in ph.atom_groups():
      if ag.parent().parent().id!=chain_id: continue
      if get_class(ag.resname)=='common_water':
        waters.setdefault(ag.id_str(), [])
        waters[ag.id_str()].append(ag)
  outl = ''
  for id_str, ags in waters.items():
    if len(ags)>1 or 1:
      for i, ag in enumerate(ags):
        ag.altloc='ABCDEFGHIJKLMNOPQRSTUVWXYZ'[i]
        for atom in ag.atoms():
          outl += '%s\n' % atom.format_atom_record()
  print('-'*80)
  print(outl)
  f=open('water.pdb', 'w')
  f.write(outl)
  del f

def _add_HIS_H_atom_to_atom_group(ag, name):
  from mmtbx.ligands.ready_set_basics import construct_xyz
  from mmtbx.ligands.ready_set_basics import get_hierarchy_h_atom
 # move to basics
  bonded = {'HD1' : ['ND1', 'CE1', 'NE2'],
            'HE2' : ['NE2', 'CD2', 'CG'],
           }
  atoms = []
  for i in range(3):
    atoms.append(ag.get_atom(bonded[name.strip()][i]))
  ro2 = construct_xyz(atoms[0], 0.9,
                      atoms[1], 126.,
                      atoms[2], 180.,
                     )
  atom = get_hierarchy_h_atom(name, ro2[0], atoms[0])
  ag.append_atom(atom)
  return ag

def _add_NQ_H_atom_to_atom_group(ag, name):
  from mmtbx.ligands.ready_set_basics import construct_xyz
  from mmtbx.ligands.ready_set_basics import get_hierarchy_h_atom
  bonded = {'HD21' : ['ND2', 'CG', 'CB'], #ASN
            'HD22' : ['ND2', 'CG', 'OD1'],#ASN
            'HE21' : ['NE2', 'CD', 'CG'], #GLN
            'HE22' : ['NE2', 'CD', 'OE1'],#GLN
           }
  atoms = []
  for i in range(3):
    atoms.append(ag.get_atom(bonded[name.strip()][i]))
  ro2 = construct_xyz(atoms[0], 0.9,
                      atoms[1], 120.,
                      atoms[2], 180.,
                     )
  atom = get_hierarchy_h_atom(name, ro2[0], atoms[0])
  ag.append_atom(atom)
  return ag

def _merge_atom_groups(hierarchy):
  bag=None
  for i, ag in enumerate(hierarchy.atom_groups()):
    if i:
      rg=bag.parent()
      tag=ag.detached_copy()
      for atom in tag.atoms():
        bag.append_atom(atom.detached_copy())
      rg.remove_atom_group(ag)
    else:
      bag=ag
  return hierarchy

def get_first_ag(hierarchy):
  hierarchy=_merge_atom_groups(hierarchy)
  for i, ag in enumerate(hierarchy.atom_groups()): pass
  assert i==0
  return ag.detached_copy()

def add_histidine_H_atoms(hierarchy):
  '''
  HIS      ND1    HD1       coval       0.860    0.020    1.020
  HIS      NE2    HE2       coval       0.860    0.020    1.020
  '''
  ag = get_first_ag(hierarchy)
  for name in [' HD1', ' HE2']:
    atom = ag.get_atom(name.strip())
    if atom is None:
      ag = _add_HIS_H_atom_to_atom_group(ag, name)
  return ag

def assert_histidine_double_protonated(ag):
  count = 0
  for atom in ag.atoms():
    if atom.name.strip() in ['HD1', 'HE2', 'DD1', 'DE2']:
      count+=1
  if count not in [2]:
    raise Sorry('incorrect protonation of %s' % ag.id_str())

def construct_hierarchy(ag, chain_id=None, resseq=None):
  ph = iotbx.pdb.hierarchy.root()
  m = iotbx.pdb.hierarchy.model()
  c = iotbx.pdb.hierarchy.chain()
  if chain_id is None: c.id='A'
  else: c.id=chain_id
  r = iotbx.pdb.hierarchy.residue_group()
  if resseq is None: r.resseq='1'
  else: r.resseq=resseq
  r.append_atom_group(rc)
  c.append_residue_group(r)
  m.append_chain(c)
  ph.append_model(m)
  return ph

def generate_flipping_his(ag,
                          return_hierarchy=False,
                          include_unprotonated=False,
                          chain_id=None,
                          resseq=None):
  assert_histidine_double_protonated(ag)
  ag=ag.detached_copy()
  booleans = [[1,1], [1,0], [0,1]]
  if include_unprotonated: booleans = [[1,1], [1,0], [0,1], [0,0]]
  for flip in range(2):
    for i, (hd, he) in enumerate(booleans):
      if i==0 and flip:
        for n1, n2 in [[' ND1', ' CD2'],
                       [' CE1', ' NE2'],
                       [' HD1', ' HD2'],
                       [' HE1', ' HE2'],
                       [' DD1', ' DD2'],
                       [' DE1', ' DE2'],
                      ]:
          a1 = ag.get_atom(n1.strip())
          a2 = ag.get_atom(n2.strip())
          if a1 is None or a2 is None: continue
          tmp = a1.xyz
          a1.xyz = a2.xyz
          a2.xyz = tmp
      rc = iotbx.pdb.hierarchy.atom_group()
      rc.resname='HIS'
      for atom in ag.atoms():
        if hd==0 and atom.name in [' HD1', ' DD1']: continue
        if he==0 and atom.name in [' HE2', ' DE2']: continue
        atom = atom.detached_copy()
        rc.append_atom(atom)
      if return_hierarchy:
        yield construct_hierarchy(rc, chain_id=chain_id, resseq=resseq)
      else:
        yield rc

def generate_flipping_NQ(ag,
                         return_hierarchy=False,
                         chain_id=None,
                         resseq=None):
  ag=ag.detached_copy()
  if ag.resname=='ASN':
    hs = ['HD21', 'HD22']
    nos = [' ND2', ' OD1']
  elif ag.resname=='GLN':
    hs = ['HE21', 'HE22']
    nos = [' NE2', ' OE1']
  else:
    assert ag.resname in ['ASN', 'GLN'], 'resname %s' % ag.resname
  for atom in ag.atoms():
    if atom.name.strip() in hs:
      ag.remove_atom(atom)
  for flip in range(2):
    if flip:
      for n1, n2 in [nos]:
        a1 = ag.get_atom(n1.strip())
        a2 = ag.get_atom(n2.strip())
        if a1 is None or a2 is None: continue
        tmp = a1.xyz
        a1.xyz = a2.xyz
        a2.xyz = tmp
    rc = iotbx.pdb.hierarchy.atom_group()
    rc.resname=ag.resname
    for atom in ag.atoms():
      atom = atom.detached_copy()
      rc.append_atom(atom)
    for name in hs:
      _add_NQ_H_atom_to_atom_group(rc, name)
    if return_hierarchy:
      yield construct_hierarchy(rc, chain_id=chain_id, resseq=resseq)
    else:
      yield rc

def should_get_selection_from_user(params):
  def qm_restraints_has_selection(params):
    if len(params.qi.qm_restraints)==0:
      return True
    if not params.qi.qm_restraints[0].selection:
      return True
    return False
  bools = [
    qm_restraints_has_selection(params),
    not params.qi.each_amino_acid,
    not params.qi.each_water,
    not params.qi.merge_water,
    ]
  bc=0
  if not params.qi.selection:
    for i, boolean in enumerate(bools):
      if boolean: bc+=1
  else:
    return False
  return bc==len(bools)

def get_selection_from_user(hierarchy, include_amino_acids=None, return_list=False, log=None):
  j=0
  opts = []
  if include_amino_acids is not None:
    for a,b in enumerate(include_amino_acids):
      include_amino_acids[a]=b.upper()
  for residue_group in hierarchy.residue_groups():
    atom_group = residue_group.atom_groups()[0]
    rc = get_class(atom_group.resname)
    if include_amino_acids and atom_group.resname in include_amino_acids: pass
    elif (rc!='common_rna_dna' and
          atom_group.resname.strip() in ad_hoc_single_metal_residue_element_types):
      pass # ions
    elif rc in ['common_amino_acid', 'common_water', 'common_rna_dna']: continue
    for conformer in residue_group.conformers():
      for residue in conformer.residues():
        sel_str = 'chain %s and resid %s and resname %s' % (
            residue_group.parent().id,
            residue_group.resid(),
            residue.resname,
          )
        if residue.is_pure_main_conf:
          opts.append(sel_str)
        else:
          altlocs=[]
          for atom in residue.atoms():
            altloc = atom.parent().altloc
            if altloc not in altlocs: altlocs.append(altloc)
          ts = []
          for altloc in altlocs:
            if not altloc: altloc=' '
            ts.append("(%s and altloc '%s')" % (sel_str, altloc))
          opts.append(' or '.join(ts))
    j+=1
  print('\n\n', file=log)
  if return_list: return opts
  for i, sel in enumerate(opts):
    print('    %2d : "%s"' % (i+1,sel), file=log)
  if len(opts)==1:
    print('\n  Automatically selecting', file=log)
    rc=[opts[0]]
    return rc
  else:
    rc = input('\n  Enter selection by choosing number or typing a new one ~> ')
  try:
    rc = int(rc)
    rc = [opts[rc-1]]
  except ValueError:
    pass
  except IndexError:
    rc = ['resid 1']
  return rc

class Program(ProgramTemplate):

  description = '''
phenix.qi: tool for selecting some atoms for QI

Usage examples:
  phenix.quantum_interface model.pdb "chain A"
  '''

  datatypes = ['model', 'phil', 'restraint']

  master_phil_str = """
  qi {
    %s
    selection = None
      .type = atom_selection
      .help = what to select
      .multiple = True
    buffer_selection = None
      .type = atom_selection
      .help = what to select for buffer
      .style = hidden
    format = *phenix_refine qi
      .type = choice
    write_qmr_phil = Auto
      .type = bool
    run_qmr = False
      .type = bool
    run_directory = None
      .type = str
    iterate_NQH = HIS ASN GLN
      .type = choice
    proton_energy_difference = None
      .type = float
    only_i = None
      .type = int
    step_buffer_radius = None
      .type = str
    iterate_metals = None
      .type = str
    include_amino_acids = None
      .type = str
    each_amino_acid = False
      .type = bool
    each_water = False
      .type = bool
    merge_water = False
      .type = bool
    nproc = 1
      .type = int
    randomise_selection = None
      .type = float
    verbose = False
      .type = bool
    debug = False
      .type = bool
      .style = hidden
      .help = more output including PDB files from each step

  }
""" % (get_qm_restraints_scope())

  # ---------------------------------------------------------------------------
  def validate(self):
    print('Validating inputs', file=self.logger)
    model = self.data_manager.get_model()
    if not model.has_hd():
      raise Sorry('Model must have Hydrogen atoms')
    if self.params.output.prefix is None:
      prefix = os.path.splitext(self.data_manager.get_default_model_name())[0]
      print('  Setting output prefix to %s' % prefix, file=self.logger)
      self.params.output.prefix = prefix
    if self.params.qi.randomise_selection and self.params.qi.randomise_selection>0.5:
      raise Sorry('Random select value %s is too large' % self.params.qi.randomise_selection)
    if self.params.qi.write_qmr_phil is Auto:
      if self.params.qi.run_qmr:
        self.params.qi.write_qmr_phil=False

  # ---------------------------------------------------------------------------
  def run(self, log=None):
    self.logger = multi_out()
    self.logger.register("stdout", sys.stdout)
    log_filename = '%s.log' % self.data_manager.get_default_output_filename()
    if self.params.qi.run_qmr:
      if os.path.exists(log_filename):
        for i in range(1,1000):
          tf = log_filename.replace('000', '%03d'% i)
          if not os.path.exists(tf):
            log_filename=tf
            break
      log_file = open(log_filename, 'w')
      self.logger.register('logfile', log_file)
    print('''
    Running mmtbx.quantum
      excutable: %s
      arguments: %s
          ''' % (sys.executable, ' '.join(sys.argv[1:])))
    model = self.data_manager.get_model()
    self.restraint_filenames = []
    rc = self.data_manager.get_restraint_names()
    for f in rc:
      self.restraint_filenames.append(os.path.abspath(f))
    #
    # get selection
    #
    if self.params.qi.iterate_NQH and len(self.params.qi.qm_restraints)==0:
      resname = self.params.qi.iterate_NQH
      if not self.params.qi.selection:
        rc = get_selection_from_user(model.get_hierarchy(),
                                     include_amino_acids=[resname])
        if rc[0].find('resname %s' % resname)>-1:
          self.params.qi.format='qi'
        self.params.qi.selection = rc
    #
    include_amino_acids=self.params.qi.include_amino_acids
    if include_amino_acids:
      include_amino_acids=[include_amino_acids]

    rc = should_get_selection_from_user(self.params)
    if rc:
      rc = get_selection_from_user(model.get_hierarchy(),
                                   include_amino_acids=include_amino_acids)
      self.params.qi.selection = rc
      if len(self.params.qi.qm_restraints)!=0:
        for attr, item in self.params.qi.qm_restraints[0].__dict__.items():
          print(attr, item)
        #   print(self.params.qi.selection)
        #   print(getattr(self.params.qi.selection, attr))
    #
    # validate selection
    #
    include_nearest_neighbours=False
    selection=None
    if len(self.params.qi.qm_restraints)!=0:
      selection = self.params.qi.qm_restraints[0].selection
    elif self.params.qi.selection:
      selection=self.params.qi.selection[0]
    if selection:
      selection_array = model.selection(selection)
      selected_model = model.select(selection_array)
      print('Selected model:\n%s' % selected_model, file=self.logger)
      self.data_manager.add_model('ligand', selected_model)
      ags = selected_model.get_hierarchy().atom_groups()
      names = []
      for ag in ags: names.append(ag.resname.strip())
      if len(names)==1:
        if names[0] in ad_hoc_single_metal_residue_element_types:
          include_nearest_neighbours=True

    qm_work_dir = get_working_directory(model, self.params)

    if self.params.qi.step_buffer_radius:
      step_buffer_radius = self.params.qi.step_buffer_radius
      assert len(step_buffer_radius.split(','))==3
    #
    # options
    #
    if self.params.qi.each_amino_acid:
      hierarchy = model.get_hierarchy()
      outl = ''
      for rg in hierarchy.residue_groups():
        if len(rg.atom_groups())!=1: continue
        resname=rg.atom_groups()[0].resname
        include_amino_acids=self.params.qi.include_amino_acids
        if include_amino_acids and include_amino_acids!=resname: continue
        gc = get_class(resname)
        if gc not in ['common_amino_acid', 'modified_amino_acid']: continue
        selection = 'chain %s and resid %s' % (rg.parent().id, rg.resseq.strip())
        qi_phil_string = self.get_single_qm_restraints_scope(selection)
        # qi_phil_string = self.set_all_write_to_true(qi_phil_string)
        # qi_phil_string = qi_phil_string.replace('run_in_macro_cycles = *first_only first_and_last all test',
        #                                         'run_in_macro_cycles = first_only *first_and_last all test')
        # qi_phil_string = qi_phil_string.replace('include_nearest_neighbours_in_optimisation = False',
                                                # 'include_nearest_neighbours_in_optimisation = True')
        qi_phil_string = qi_phil_string.replace('ignore_x_h_distance_protein = False',
                                                'ignore_x_h_distance_protein = True')
        qi_phil_string = qi_phil_string.replace(' pdb_final_buffer', ' *pdb_final_buffer')
        print('  writing phil for %s %s' % (rg.id_str(), rg.atom_groups()[0].resname), file=self.logger)
        outl += '%s' % qi_phil_string
      pf = '%s_all.phil' % (
        self.data_manager.get_default_model_name().replace('.pdb',''))
      f=open(pf, 'w')
      f.write('refinement.qi {\n')
      for line in outl.splitlines():
        if line.strip().startswith('.'): continue
        f.write('%s\n' % line)
      f.write('}\n')
      del f
      print('  phenix.refine %s %s qi.nproc=6' % (self.data_manager.get_default_model_name(),
                                                  pf), file=self.logger)
      return

    if self.params.qi.merge_water:
      pf = self.data_manager.get_default_model_name().replace('.pdb', '')
      if os.path.exists(qm_work_dir):
        os.chdir(qm_work_dir)
        filenames=[]
        for filename in os.listdir('.'):
          if not filename.startswith(pf): continue
          if not filename.endswith('pdb'): continue
          if filename.find('HOH')==-1: continue
          if filename.find('_cluster_final_')==-1: continue
          filenames.append(filename)
        merge_water(filenames)
      else:
        print('no working directory', file=self.logger)

    if self.params.qi.each_water:
      if not self.params.qi.run_qmr:
        hierarchy = model.get_hierarchy()
        outl = ''
        for rg in hierarchy.residue_groups():
          if len(rg.atom_groups())!=1: continue
          resname=rg.atom_groups()[0].resname
          include_amino_acids=self.params.qi.include_amino_acids
          if include_amino_acids and include_amino_acids!=resname: continue
          gc = get_class(resname)
          if gc not in ['common_water']: continue
          selection = 'chain %s and resid %s and resname HOH' % (rg.parent().id, rg.resseq.strip())
          qi_phil_string = self.get_single_qm_restraints_scope(selection)
          qi_phil_string = self.set_one_write_to_true(qi_phil_string, 'pdb_final_buffer')
          qi_phil_string = qi_phil_string.replace('ignore_x_h_distance_protein = False',
                                                  'ignore_x_h_distance_protein = True')
          qi_phil_string = qi_phil_string.replace('do_not_update_restraints = False',
                                                  'do_not_update_restraints = True')
          print('  writing phil for %s %s' % (rg.id_str(), rg.atom_groups()[0].resname), file=self.logger)
          outl += '%s' % qi_phil_string
        pf = '%s_water.phil' % (
          self.data_manager.get_default_model_name().replace('.pdb',''))
        f=open(pf, 'w')
        f.write('qi {\n')
        for line in outl.splitlines():
          if line.strip().startswith('.'): continue
          f.write('%s\n' % line)
        f.write('}\n')
        del f

        ih = 'each_water=True'
        print('''

        mmtbx.quantum_interface %s run_qmr=True %s %s
        ''' % (self.data_manager.get_default_model_name(),
               ih,
               pf), file=self.logger)

      else:
        rc = self.run_qmr(self.params.qi.format)
        rc=rc[0]
        args = []
        cmd = '\n\tphenix.start_coot'
        for filenames in rc.final_pdbs:
          print(filenames)
          args.append(filenames[-1])
          cmd += ' %s' % args[-1]
        print(cmd)
        os.chdir(qm_work_dir)
        merge_water(args)
      return

    if self.params.qi.randomise_selection:
      import random
      sites_cart = model.get_sites_cart()
      for i, (b, xyz) in enumerate(zip(selection_array, sites_cart)):
        if b:
          xyz=list(xyz)
          for j in range(3):
            xyz[j] += random.gauss(0, self.params.qi.randomise_selection)
          sites_cart[i]=tuple(xyz)
      model.set_sites_cart(sites_cart)

    if self.params.qi.write_qmr_phil:
      # for attr, item in self.params.qi.qm_restraints[0].__dict__.items():
      #   print(attr, item)
      pf = self.write_qmr_phil(iterate_NQH=self.params.qi.iterate_NQH,
                               iterate_metals=self.params.qi.iterate_metals,
                               step_buffer_radius=self.params.qi.step_buffer_radius,
                               output_format=self.params.qi.format,
                               include_nearest_neighbours=include_nearest_neighbours,
                               )
      ih = ''
      if self.params.qi.iterate_NQH:
        ih = 'iterate_NQH=%s' % self.params.qi.iterate_NQH
        ih = ih.replace('  ',' ')
      if self.params.qi.iterate_metals:
        ih = 'iterate_metals="%s"' % self.params.qi.iterate_metals
      if self.params.qi.step_buffer_radius:
        ih = 'step_buffer_radius="%s"' % self.params.qi.step_buffer_radius

      program = 'mmtbx.quantum_interface'
      ih2 = ' run_qmr=True'
      if self.params.qi.format=='qi':
        ih2 += ' qi.nproc=%s' % self.params.qi.nproc
      else:
        program='phenix.refine'
        ih2 = self.data_manager.get_default_model_name()
        if ih2.endswith('.updated.pdb'):
          ih2 = ih2.replace('.updated.pdb', '.mtz')
        else:
          ih2 = ' %s' % 'test.mtz'

      print('''

      %s %s %s %s %s
      ''' % (program,
             self.data_manager.get_default_model_name(),
             ih,
             pf,
             ih2,
             ), file=self.logger)
      return

    if self.params.qi.run_directory:
      if not os.path.exists(self.params.qi.run_directory):
        os.mkdir(self.params.qi.run_directory)
      os.chdir(self.params.qi.run_directory)

    if self.params.qi.run_qmr and self.params.qi.step_buffer_radius:
      ph=selected_model.get_hierarchy()
      for i, atom_group in enumerate(ph.atom_groups()):
        id_str = atom_group.id_str()
      assert i==0
      rc = self.step_thru_buffer_radii(id_str=id_str, log=log)
      return

    if ( self.params.qi.run_qmr and
         not (self.params.qi.iterate_NQH or
              self.params.qi.iterate_metals)):
      self.params.qi.qm_restraints.selection=self.params.qi.selection
      rcs = self.run_qmr(self.params.qi.format)
      dmn = self.data_manager.get_default_model_name()
      cmd = '\n\n\tphenix.start_coot %s' % dmn
      for rc in rcs:
        filenames = getattr(rc, 'final_pdbs', [])
        if filenames:
          for f in filenames:
            for g in f:
              cmd += ' %s' % os.path.join('qm_work_dir', g)
      for r in ['.pdb', '.updated.pdb']:
        mf = dmn.replace(r, '_map_coeffs.mtz')
        if os.path.exists(mf):
          cmd += ' --auto=%s' % mf
          break
      print('%s\n\n' % cmd)

    if self.params.qi.iterate_NQH:
      print('"%s"' % self.params.qi.iterate_NQH, file=self.logger)
      assert self.params.qi.randomise_selection==None
      if self.params.qi.iterate_NQH=='HIS':
        rc = self.iterate_histidine()
      elif self.params.qi.iterate_NQH=='ASN':
        rc = self.iterate_ASN()
      elif self.params.qi.iterate_NQH=='GLN':
        rc = self.iterate_GLN()
      else:
        assert 0
      if rc:
        update, filename = rc
        self.update_residue(filename)
      model = self.data_manager.get_model()
      fn=self.data_manager.get_default_model_name()
      self.data_manager.write_model_file(model,
                                         fn.replace('.pdb', '_best.pdb'),
                                         overwrite=True)

    if self.params.qi.iterate_metals:
      self.iterate_metals()

  def update_residue(self, filename):
    def dist2(r1,r2): return (r1[0]-r2[0])**2+(r1[1]-r2[1])**2+(r1[2]-r2[2])**2
    selection = self.params.qi.qm_restraints[0].selection
    model = self.data_manager.get_model()
    from iotbx import pdb
    pdb_inp = pdb.input(filename)
    hierarchy = pdb_inp.construct_hierarchy()
    asc = hierarchy.atom_selection_cache()
    sel = asc.selection(selection)
    hierarchy = hierarchy.select(sel)
    for replace in hierarchy.residue_groups(): pass
    hierarchy = model.get_hierarchy()
    for h_model in hierarchy.models():
      for chain in h_model.chains():
        for rgi, residue_group in enumerate(chain.residue_groups()):
          for atom1 in replace.atoms(): break
          for atom2 in residue_group.atoms(): break
          d2 = dist2(atom1.xyz, atom2.xyz)
          if d2<1e-3:
            chain.remove_residue_group(residue_group)
            chain.insert_residue_group(rgi, replace)

  def get_selected_hierarchy(self):
    selection = self.params.qi.qm_restraints[0].selection
    model = self.data_manager.get_model()
    selection_array = model.selection(selection)
    selected_model = model.select(selection_array)
    hierarchy = selected_model.get_hierarchy()
    return hierarchy

  def iterate_metals(self, log=None):
    from mmtbx.geometry_restraints.quantum_interface import get_preamble
    if len(self.params.qi.qm_restraints)<1:
      self.write_qmr_phil(iterate_metals=True)
      print('Restart command with PHIL file', file=self.logger)
      return
    def generate_metals(s):
      if s.lower()=='all': s='LI,NA,MG,K,CA,CU,ZN'
      s=s.replace(' ',',')
      for t in s.split(','):
        yield t.upper()
    selection = self.params.qi.qm_restraints[0].selection
    nproc = self.params.qi.nproc
    preamble = get_preamble(None, 0, self.params.qi.qm_restraints[0])
    model = self.data_manager.get_model()
    selection_array = model.selection(selection)
    selected_model = model.select(selection_array)
    hierarchy = selected_model.get_hierarchy()
    for atom in hierarchy.atoms(): break
    rg_resseq = atom.parent().parent().resseq
    chain_id = atom.parent().parent().parent().id
    energies = []
    rmsds = []
    argstuples = []
    filenames = []
    t0=time.time()
    for element in generate_metals(self.params.qi.iterate_metals):
      print('Substituting element : %s' % element, file=self.logger)
      model = self.data_manager.get_model()
      if nproc>1: model=model.deep_copy()
      hierarchy = model.get_hierarchy()
      for chain in hierarchy.chains():
        if chain.id!=chain_id: continue
        for rg in chain.residue_groups():
          if rg.resseq!=rg_resseq: continue
          for j, ag in enumerate(rg.atom_groups()): pass
          assert j==0
          eag = ag.detached_copy()
          eag.resname = element
          eag.atoms()[0].element=element
          eag.atoms()[0].name=element
          tselection = selection.replace(' %s' % ag.resname.upper().strip(),
                                        ' %s' % element)
          self.params.qi.qm_restraints[0].selection = tselection
          rg.remove_atom_group(ag)
          rg.insert_atom_group(0, eag)
      self.params.output.prefix='iterate_metals'
      arg_log=null_out()
      if self.params.qi.verbose:
        arg_log=log
      filenames.append('%s_cluster_final_%s.pdb' % (self.params.output.prefix,
                                                   preamble))
      if nproc==-1:
        print('  Running metal swap %s' % (element), file=self.logger)
        res = update_restraints(model,
                                self.params,
                                never_write_restraints=True,
                                # never_run_strain=True,
                                log=arg_log)
        energies.append(energies)
        units=res.units
        rmsds.append(res.rmsds[0][1])
        print('    Energy : %s %s' % (energies[-1],units), file=self.logger)
        print('    Time   : %ds' % (time.time()-t0), file=self.logger)
        print('    RMSD   : %8.3f' % res.rmsds[0][1], file=self.logger)
      else:
        params = copy.deepcopy(self.params)
        argstuples.append(( model,
                            params,
                            None, # macro_cycle=None,
                            True, #never_write_restraints=False,
                            1, # nproc=1,
                            null_out(),
                            ))
    results = run_serial_or_parallel(update_restraints, argstuples, nproc)
    for i, filename in enumerate(filenames):
      assert os.path.exists(filename), ' Output %s missing' % filename
      results[i].filename = filename
    return results

  def iterate_NQH(self, nq_or_h, classify_nqh, add_nqh_H_atoms, generate_flipping, log=None):
    from mmtbx.geometry_restraints.quantum_interface import get_preamble
    if len(self.params.qi.qm_restraints)<1:
      pf = self.write_qmr_phil(iterate_NQH=True)
      print('Restart command with PHIL file : %s' % pf, file=self.logger)
      return
    qm_work_dir = get_working_directory(self.data_manager.get_model(), self.params)
    nproc = self.params.qi.nproc
    preamble = get_preamble(None, 0, self.params.qi.qm_restraints[0])
    hierarchy = self.get_selected_hierarchy()
    original_ch = classify_nqh(hierarchy)
    # add all H atoms
    his_ag = add_nqh_H_atoms(hierarchy)
    for atom in hierarchy.atoms(): break
    rg_resseq = atom.parent().parent().resseq
    chain_id = atom.parent().parent().parent().id
    buffer_selection = ''
    buffer = self.params.qi.qm_restraints[0].buffer
    buffer *= buffer
    t0=time.time()
    argstuples = []
    filenames = []
    for i, flipping_his in enumerate(generate_flipping(his_ag)):
      model = self.data_manager.get_model()
      model=model.deep_copy()
      hierarchy = model.get_hierarchy()
      for chain in hierarchy.chains():
        if chain.id!=chain_id: continue
        for rg in chain.residue_groups():
          if rg.resseq!=rg_resseq: continue
          for j, ag in enumerate(rg.atom_groups()): pass
          assert j==0, 'alt. loc. not supported'
          rg.remove_atom_group(ag)
          rg.insert_atom_group(0, flipping_his)
      self.params.output.prefix='iterate_%s_%02d' % (nq_or_h, i+1)
      # self.params.output.prefix='iterate_histidine_%02d' % (i+1)
      arg_log=null_out()
      if self.params.qi.verbose:
        arg_log=log
      #
      # need the same buffer for energy
      #
      if not buffer_selection:
        for rg in hierarchy.residue_groups():
          min_d2 = min_dist2(rg,ag)
          if min_d2[0]>=buffer: continue
          buffer_selection += ' (chain %s and resname %s and resid %s) or' % (
            rg.parent().id,
            rg.atom_groups()[0].resname,
            rg.resseq,
            )
        assert buffer_selection
        buffer_selection = buffer_selection[:-3]
      self.params.qi.qm_restraints[0].buffer_selection=buffer_selection
      #
      if self.params.qi.only_i is not None and self.params.qi.only_i!=i+1:
        continue
      filenames.append('%s_cluster_final_%s.pdb' % (self.params.output.prefix,
                                                   preamble))
      #
      if nproc==-1:
        print('  Running %s flip %d' % (nq_or_h, i+1), file=self.logger)
        res = update_restraints(model,
                                self.params,
                                never_write_restraints=True,
                                # never_run_strain=True,
                                log=arg_log)
        energies.append(energies)
        units=res.units
        rmsds.append(res.rmsds[0][1])
        print('    Energy : %s %s' % (energies[-1],units), file=self.logger)
        print('    Time   : %ds' % (time.time()-t0), file=self.logger)
        print('    RMSD   : %8.3f' % res.rmsds[0][1], file=self.logger)
      else:
        params = copy.deepcopy(self.params)
        argstuples.append(( model,
                            params,
                            None, # macro_cycle=None,
                            True, #never_write_restraints=False,
                            1, # nproc=1,
                            None, #null_out(),
                            ))
    results = run_serial_or_parallel(update_restraints, argstuples, nproc)
    for i, filename in enumerate(filenames):
      filename=os.path.join(qm_work_dir, filename)
      assert os.path.exists(filename), ' Output %s missing' % filename
      results[i].filename = filename
    return results

  def _process_energies(self, energies, units, resname='HIS', energy_adjustment=None, log=None):
    te=[]
    adjust = []
    if resname=='HIS': adjust=[0,3]
    for i, energy in enumerate(energies):
      energy=energy[1]
      if i in adjust:
        if units.lower() in ['kcal/mol']:
          if energy_adjustment is None:
            energy_adjustment=94.51
        elif units.lower() in ['hartree']:
          energy+=0.5
          assert 0
        elif units.lower() in ['ev']:
          if energy_adjustment is None:
            # energy_adjustment=13.61 # ???
            energy_adjustment=4.098 # 94.51 kcal/mol JM
        else:
          assert 0
        #
        # ADJUST!!!
        #
        energy-=energy_adjustment
      te.append(energy)
    outl=''
    if resname=='HIS':
      outl = '  Proton energy used : %0.4f %s' % (energy_adjustment, units)
    return te, outl

  def iterate_ASN(self, log=None):
    def classify_NQ(args): pass
    rc=self.iterate_NQH('ASN',
                        classify_NQ,
                        get_first_ag,
                        generate_flipping_NQ,
                        log=log)
    if rc is None: return None
    protonation = ['original', 'flipped']
    nproc = self.params.qi.nproc
    rc = self.process_flipped_jobs('ASN', rc, protonation=protonation, nproc=nproc, log=log)
    return rc

  def iterate_GLN(self, log=None):
    def classify_NQ(args): pass
    rc=self.iterate_NQH('GLN',
                        classify_NQ,
                        get_first_ag,
                        generate_flipping_NQ,
                        log=log)
    if rc is None: return None
    protonation = ['original', 'flipped']
    nproc = self.params.qi.nproc
    rc = self.process_flipped_jobs('GLN', rc, protonation=protonation, nproc=nproc, log=log)
    return rc

  def iterate_histidine(self, log=None):
    rc=self.iterate_NQH('HIS',
                        classify_histidine,
                        add_histidine_H_atoms,
                        generate_flipping_his,
                        log=log)
    if rc is None: return None
    protonation = [ 'HD1, HE2',
                    'HD1 only',
                    'HE2 only',
                    'HD1, HE2 flipped',
                    'HD1 only flipped',
                    'HE2 only flipped',
    ]
    nproc = self.params.qi.nproc
    energy_adjustment=self.params.qi.proton_energy_difference
    rc = self.process_flipped_jobs('HIS', rc, protonation=protonation, nproc=nproc, energy_adjustment=energy_adjustment, log=log)
    return rc

  def process_flipped_jobs(self, resname, rc, protonation=None, id_str=None, nproc=-1, energy_adjustment=None, log=None):
    energies = []
    units = None
    rmsds = []
    rotamers = []
    filenames = []
    for i, res in enumerate(rc):
      for selection, te in res.energies.items(): pass
      te=te[0]
      print('  Energy %d %s : %9.1f %s # ligand atoms : %d # cluster atoms : %d cluster charge :%3d' % (
        i+1,
        te[0],
        te[1],
        res.units,
        te[2],
        te[3],
        te[4],
        ), file=self.logger)
      energies.append(te)
      units=res.units
      rmsds.append(res.rmsds[0][1])
      filenames.append(res.filename)

    if protonation is None: protonation=filenames
    rc=get_hbonds_via_filenames(filenames,
                                resname,
                                nproc=nproc,
                                restraint_filenames=self.restraint_filenames)
    hbondss, pymols = rc
    selection = self.params.qi.qm_restraints[0].selection
    if resname not in ['radius']:
      rotamers=get_rotamers_via_filenames(filenames, selection, resname)
    else:
      rotamers=['None']*len(filenames)

    energies, outl = self._process_energies(energies, units, resname=resname, energy_adjustment=energy_adjustment, log=log)
    me=min(energies)
    cmd = '\n\n  phenix.start_coot'
    #
    if resname not in ['radius']:
      hierarchy = self.get_selected_hierarchy()
      original_ch = classify_histidine(hierarchy, resname=resname)
      print('\n\nEnergies in units of %s' % units, file=self.logger)
      print('%s\n' % outl, file=self.logger)
      print('  %i. %-20s : rotamer "%s"' % (
        0,
        original_ch[1],
        original_ch[0]),
      file=self.logger)
    #
    final_result=None
    close_result=[]
    outl = '  %i. %-20s : %12.3f %s ~> %10.2f kcal/mol. H-Bonds : %2d rmsd : %7.2f rotamer "%s"'
    # outl = '%i|%-20s|%7.5f|%s|%10.2f|%2d|%7.2f|%s'
    min_i=None
    for i, filename in enumerate(filenames):
      assert os.path.exists(filename), '"%s"' % filename
      if self.params.qi.run_directory:
        cmd += ' %s' % os.path.join(self.params.qi.run_directory, filename)
      else:
        cmd += ' %s' % filename
      #
      nci = hbondss[i].get_counts(filter_id_str=id_str, min_data_size=1)
      n=-1
      if nci:
        n=nci.n_filter
      energy = energies[i]
      #
      # convert to kcal/mol
      #
      if units.lower() in ['hartree']:
        de = (energy-me)*627.503
      elif units.lower() in ['kcal/mol', 'dirac']:
        de = (energy-me)
      elif units.lower() in ['ev']:
        de = (energy-me)*23.0605
      args = (
        i+1,
        protonation[i],
        energy,
        units,
        de,
        n,
        rmsds[i],
        rotamers[i],
        )
      print(outl % args, file=self.logger)
      update=False
      if de<1e-3:
        final_result = outl % args
        min_i=i
        tmp = protonation[i]
        tmp=tmp.replace('only','')
        # tmp=tmp.replace('flipped', '')
        if original_ch[1]:
          if tmp.strip()==original_ch[1].strip():
            final_result += ' SAME'
          elif tmp.replace('flipped', '').strip()==original_ch[1].strip():
            final_result += ' FLIPPED'
          else:
            final_result += ' DIFFERENT'
            update=True
        else:
          update=i
        j=i
      elif de<5.:
        close_result.append(outl % args)

    if units.lower()=='dirac':
      raise Sorry('MOPAC not installed! Please install or update to Python3.')

    import shutil
    nf = filenames[min_i].replace('%02d_cluster' % (min_i+1), 'best_cluster')
    shutil.copy(filenames[min_i], nf)

    cmd += '\n\n'
    print(cmd, file=self.logger)
    print(pymols, file=self.logger)
    print('!!! %s' % final_result, file=self.logger)
    if close_result:
      print('\nClose', file=self.logger)
      for cl in close_result:
        print('  >< %s' % cl, file=self.logger)
    return update, filenames[j]

  def step_thru_buffer_radii(self, id_str=None, log=None):
    from mmtbx.geometry_restraints.quantum_interface import get_preamble
    if len(self.params.qi.qm_restraints)<1:
      self.write_qmr_phil(step_buffer_radius=True)
      print('Restart command with PHIL file', file=self.logger)
      return
    nproc = self.params.qi.nproc
    #
    start, end, step = self.params.qi.step_buffer_radius.split(',')
    # qi_phil_string=qi_phil_string.replace('refinement.qi.qm_restraints',
    #                                       'qm_restraints')
    # qi_phil_string=qi_phil_string.replace('ignore_x_h_distance_protein = False',
    #                                       'ignore_x_h_distance_protein = True')
    # tmp = 'qi {\n'
    steps=[]
    for r in stepper(start, end, step): steps.append(r)
    steps.reverse()
    buffer = self.params.qi.qm_restraints[0].buffer
    t0=time.time()
    argstuples = []
    filenames = []
    for i, r in enumerate(steps):
      model = self.data_manager.get_model()
      model=model.deep_copy()
      self.params.output.prefix='iterate_radii'
      arg_log=null_out()
      if self.params.qi.verbose:
        arg_log=log
      #
      if self.params.qi.only_i is not None and self.params.qi.only_i!=i+1:
        continue
      params = copy.deepcopy(self.params)
      params.qi.qm_restraints[0].buffer=r
      preamble = get_preamble(None, 0, params.qi.qm_restraints[0])
      filenames.append('%s_cluster_final_%s.pdb' % (self.params.output.prefix,
                                                   preamble))
      #
      if nproc==-1:
        print('  Running radius %d' % (r), file=self.logger)
        res = update_restraints(model,
                                params,
                                never_write_restraints=True,
                                # never_run_strain=True,
                                log=arg_log)
        energies.append(res.energies)
        units=res.units
        rmsds.append(res.rmsds[0][1])
        print('    Energy : %s %s' % (energies[-1],units), file=self.logger)
        print('    Time   : %ds' % (time.time()-t0), file=self.logger)
        print('    RMSD   : %8.3f' % res.rmsds[0][1], file=self.logger)
      else:
        argstuples.append(( model,
                            params,
                            None, # macro_cycle=None,
                            False, #never_write_restraints=False,
                            1, # nproc=1,
                            None, #null_out(),
                            ))
    results = run_serial_or_parallel(update_restraints, argstuples, nproc)
    for i, filename in enumerate(filenames):
      assert os.path.exists(filename), ' Output %s missing' % filename
      results[i].filename = filename
    if results is None: return
    self.process_flipped_jobs('radius', results, id_str=id_str, nproc=nproc, log=log)
    return results

  def run_qmr(self, format, log=None):
    from mmtbx.refinement.energy_monitor import digest_return_energy_object
    model = self.data_manager.get_model()
    qmr = self.params.qi.qm_restraints[0]
    checks = 'starting_strain starting_energy starting_bound starting_binding'
    energies = None
    rcs=[]
    if any(item in checks for item in qmr.calculate):
      rc = run_energies(
        model,
        self.params,
        macro_cycle=1,
        pre_refinement=True,
        nproc=self.params.qi.nproc,
        log=log,
        )
      energies = digest_return_energy_object(rc, 1, energy_only=True)
      outl = energies.as_string()
      print(outl, file=self.logger)
      rcs.append(rc)
    #
    # minimise ligands geometry
    #
    rc = update_restraints( model,
                            self.params,
                            log=log,
                            )
    rcs.append(rc)
    if energies is None:
      energies = digest_return_energy_object(rc, 1, energy_only=False)
    else:
      digest_return_energy_object(rc, 1, False, energies)
    outl = energies.as_string()
    print(outl, file=self.logger)
    #
    cannot_run_final_energies=False
    if len(rc.final_pdbs)>1:
      cannot_run_final_energies=True
    checks = 'final_strain final_energy final_bound'
    if rc.final_pdbs[0]:
      fn = os.path.join('qm_work_dir', rc.final_pdbs[0][0])
      self.data_manager.process_model_file(fn)
      model = self.data_manager.get_model(fn)
    if any(item in checks for item in qmr.calculate):
      if cannot_run_final_energies:
        print('Cannot run final energies. Restart with only one ligand selection.',
              file=self.logger)
      else:
        rc = run_energies(
          model,
          self.params,
          macro_cycle=99,
          pre_refinement=False,
          nproc=self.params.qi.nproc,
          log=log,
          )
        energies = digest_return_energy_object(rc, 99, True, energies)
        outl = energies.as_string()
        print(outl, file=self.logger)
        rcs.append(rc)
    return rcs

  def get_single_qm_restraints_scope(self, selection):
    qi_phil_string = get_qm_restraints_scope()
    qi_phil_string = qi_phil_string.replace(' selection = None',
                                            ' selection = "%s"' % selection)
    qi_phil_string = qi_phil_string.replace('read_output_to_skip_opt_if_available = False',
                                            'read_output_to_skip_opt_if_available = True')
    qi_phil_string = qi_phil_string.replace('capping_groups = False',
                                            'capping_groups = True')
    return qi_phil_string

  def set_all_calculate_to_true(self, qi_phil_string):
    outl = ''
    for line in qi_phil_string.splitlines():
      if line.find(' calculate =')>-1:
        tmp=line.split()
        line=''
        for i, t in enumerate(tmp):
          if i>1 and t.find('*')==-1:
            line += ' *%s' % tmp[i]
          else:
            line += ' %s' % tmp[i]
      outl += '%s\n' % line
    return outl

  def set_all_write_to_true(self, qi_phil_string):
    outl = ''
    # write_files = *restraints pdb_core pdb_buffer pdb_final_core pdb_final_buffer
    for line in qi_phil_string.splitlines():
      if line.find(' write_')>-1:
        tmp=line.split()
        line = '  '
        for t in tmp:
          if t.startswith('pdb'): t='*%s'%t
          line+='%s ' % t
      outl += '%s\n' % line
    return outl

  def set_one_write_to_true(self, qi_phil_string, attr):
    return qi_phil_string.replace(' %s' % attr, ' *%s' % attr)

  def write_qmr_phil(self,
                     iterate_NQH=False,
                     iterate_metals=False,
                     step_buffer_radius=False,
                     output_format=None,
                     include_nearest_neighbours=False,
                     log=None):
    qi_phil_string = ''
    for i in range(len(self.params.qi.selection)):
      qi_phil_string += self.get_single_qm_restraints_scope(self.params.qi.selection[i])
    # qi_phil_string = self.get_single_qm_restraints_scope(self.params.qi.selection[0])
    # qi_phil_string = self.set_all_calculate_to_true(qi_phil_string)
    # qi_phil_string = self.set_all_write_to_true(qi_phil_string)
    qi_phil = iotbx.phil.parse(qi_phil_string,
                             # process_includes=True,
                             )
    qi_phil_string = qi_phil_string.replace(' pdb_final_buffer',
                                            ' *pdb_final_buffer')
    # qi_phil_string = qi_phil_string.replace(' pdb_buffer',
    #                                         ' *pdb_buffer')
    # qi_phil.show()

    qi_phil_string = qi_phil_string.replace('qm_restraints',
                                            'refinement.qi.qm_restraints',
                                            1)
    if step_buffer_radius:
      # start, end, step = step_buffer_radius.split(',')
      qi_phil_string=qi_phil_string.replace('refinement.qi.qm_restraints',
                                            'qm_restraints')
      qi_phil_string=qi_phil_string.replace('ignore_x_h_distance_protein = False',
                                            'ignore_x_h_distance_protein = True')
      start=3.5
      end=3.5
      step=1
      tmp = 'qi {\n'
      for r in stepper(start, end, step):
        tmp+=qi_phil_string.replace('buffer = 3.5', 'buffer = %s' % r)
      tmp += '\n}\n'
      qi_phil_string = tmp

    if iterate_NQH:
      qi_phil_string = qi_phil_string.replace('refinement.', '')
      qi_phil_string = qi_phil_string.replace('ignore_x_h_distance_protein = False',
                                              'ignore_x_h_distance_protein = True')
      qi_phil_string = qi_phil_string.replace(
        'protein_optimisation_freeze = *all None main_chain main_chain_to_beta main_chain_to_delta torsions',
        'protein_optimisation_freeze = all None main_chain main_chain_to_beta *main_chain_to_delta *torsions')
      qi_phil_string = qi_phil_string.replace(
        'solvent_model = None', 'solvent_model = EPS=78.4',
        )
      # qi_phil_string = qi_phil_string.replace('buffer = 3.5', 'buffer = 4.')

    if iterate_metals:
      qi_phil_string = qi_phil_string.replace('refinement.', '')
      qi_phil_string = qi_phil_string.replace('include_nearest_neighbours_in_optimisation = False',
                                              'include_nearest_neighbours_in_optimisation = True')

    if include_nearest_neighbours:
      qi_phil_string = qi_phil_string.replace('include_nearest_neighbours_in_optimisation = False',
                                              'include_nearest_neighbours_in_optimisation = True')
      qi_phil_string = qi_phil_string.replace('include_inter_residue_restraints = False',
                                              'include_inter_residue_restraints = True')

    if output_format=='qi':
      qi_phil_string = qi_phil_string.replace('refinement.qi', 'qi')

    # qi_phil_string = qi_phil_string.replace('nproc = 1', 'nproc = 6')

    def safe_filename(s):
      while s.find('  ')>-1:
        s=s.replace('  ',' ')
      s=s.replace('chain ','')
      s=s.replace('resname ','')
      s=s.replace('resid ','')
      s=s.replace('and ','')
      s=s.replace('altloc ','')
      s=s.replace(' ','_')
      s=s.replace('(','')
      s=s.replace(')','')
      s=s.replace(':','_')
      s=s.replace("'",'')
      return s

    print(self.params.qi.selection)
    pf = '%s_%s.phil' % (
      self.data_manager.get_default_model_name().replace('.pdb',''),
      safe_filename(self.params.qi.selection[0]),
      )
    print('  Writing QMR phil scope to %s' % pf, file=self.logger)
    f=open(pf, 'w')
    for line in qi_phil_string.splitlines():
      if line.strip().startswith('.'): continue
      print('%s' % line, file=self.logger)
      f.write('%s\n' % line)
    del f
    return pf

  # ---------------------------------------------------------------------------
  def get_results(self):
    return None


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/rama_z.py
# -*- coding: utf-8 -*-
from __future__ import absolute_import, division, print_function

from libtbx.program_template import ProgramTemplate

from mmtbx.validation import rama_z
from mmtbx.validation.ramalyze import ramalyze
from mmtbx.validation.ramalyze import res_type_labels
from cctbx.maptbx.box import shift_and_box_model

from libtbx.utils import Sorry, null_out
from libtbx import Auto
import os

# =============================================================================

class Program(ProgramTemplate):

  description = '''
mmtbx.rama_z: Tool to calculate Rama-Z score. Validation of Ramachandran plot.

Usage examples:
  mmtbx.rama_z model1.pdb
  '''

  datatypes = ['model', 'phil']
  data_manager_options = ['model_skip_expand_with_mtrix']

  master_phil_str = """\
  write_HSL_models = False
    .type = bool
  write_HSL_plot = False
    .type = bool
  write_HSL_general_only = True
    .type = bool
  write_whole_plot = False
    .type = bool
  write_whole_general_only = True
    .type = bool
"""
  # write everything:
  # write_HSL_models=True write_HSL_plot=True write_HSL_general_only=False write_whole_plot=True write_whole_general_only=False
  # write only general plots:
  # write_HSL_plot=True write_whole_plot=False
  #
  # ---------------------------------------------------------------------------
  def validate(self):
    print('Validating inputs', file=self.logger)
    self.data_manager.has_models()
    m = self.data_manager.get_model()
    print ('Inputs OK', file=self.logger)

  # ---------------------------------------------------------------------------

  def _write_plots_if_needed(self, model, label, type_of_plot='whole'):
    write_plot = getattr(self.params, "write_%s_plot" % type_of_plot)
    write_general_only = getattr(self.params, "write_%s_general_only" % type_of_plot)
    if write_plot:
      self.rama = ramalyze(model.get_hierarchy(), out=null_out())
      self.plots = self.rama.get_plots(
          show_labels=False,
          point_style='.',
          markersize=3,
          markeredgecolor="red",
          dpi=300,
          markerfacecolor="yellow")
      plots_to_write = range(6)
      if write_general_only:
        plots_to_write = [0]
      for i in plots_to_write:
        file_label = res_type_labels[i].replace("/", "_")
        fn = "%s.png" % self.get_default_output_filename(
            prefix='%s_%s_' % (self.inp_fn, label),
            suffix=file_label,
            serial=Auto)
        if os.path.isfile(fn) and not self.params.output.overwrite:
          raise Sorry("%s already exists and overwrite is set to False." % fn)
        print("Saving:", fn, file=self.logger)
        self.plots[i].save_image(fn, dpi=300)

  def run(self):
    self.result = None
    models = []
    for model_name in self.data_manager.get_model_names():
      models.append(self.data_manager.get_model(model_name))

    # model = self.data_manager.get_model()
    self.inp_fn = os.path.basename(self.data_manager.get_default_model_name())[:-4]
    self.rama_z = rama_z.rama_z(
        models = models,
        log = self.logger)
    if len(models) == 1:
      model = models[0]
      cs = model.crystal_symmetry()
      if (cs is None) or (cs.unit_cell() is None):
        model = shift_and_box_model(model)
      self._write_plots_if_needed(model, label='whole', type_of_plot='whole')
      helix_sel, sheet_sel, loop_sel = self.rama_z.get_ss_selections()
      if model.get_hierarchy().models_size() != 1:
        print ("Warning! Outputting partial models and plots are not supported \
  for multi-model files", file=self.logger)
      else:
        for sel, label in [(helix_sel, "helix"),
             (sheet_sel, "sheet"),
             (loop_sel, "loop")]:
          selected_model = model.select(sel)
          if self.params.write_HSL_models:
            fn = "%s" % self.get_default_output_filename(
                prefix='%s_' % self.inp_fn,
                suffix=label,
                serial=Auto)
            print("Writing out partial model: %s" % fn, file=self.logger)
            written_fn = self.data_manager.write_model_file(selected_model, filename=fn)
          self._write_plots_if_needed(selected_model, label, type_of_plot='HSL')
    self.result = self.get_results()
    # This brings 0 value to the user. Per-residue numbers
    # should not be analyzed, therefore no reason to print them.
    # res_info = self.rama_z.get_detailed_values()
    # print ("Individual residues info:", file=self.logger)
    # print ("Residue name, type, SS, (phi, psi), Z", file=self.logger)
    # for i in res_info:
    #   print ('%4s %10s %1s (%7.2f, %7.2f) %7.4f' % (
    #       i[2], res_type_labels[i[1]], i[3], i[4], i[5], i[6]), file=self.logger)

    print(self.result.as_string(prefix=""), file = self.logger)
    # print(self.result.as_json(), file=self.logger)

  # ---------------------------------------------------------------------------
  def get_results(self):
    if self.result is None:
      self.result = self.rama_z.get_result()
    return self.result

  def get_results_as_JSON(self):
    if self.result is None:
      self.result = self.rama_z.get_result()
    return self.result.as_json()


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/ramalyze.py
from __future__ import absolute_import, division, print_function

import os
import iotbx.phil
from mmtbx.validation.ramalyze import ramalyze
from libtbx.program_template import ProgramTemplate
from six.moves import range
try:
  from phenix.program_template import ProgramTemplate
except ImportError:
  pass
from libtbx.utils import Sorry
from datetime import datetime

master_phil_str = """
plot = False
  .type = bool
  .help = Create graphics of plots (if Matplotlib is installed)
show_labels = True
  .type = bool
  .help = Show labels on outlier residues
point_style = 'bo'
  .type = str
  .help = choose style of points, use matplotlib format from e.g. here: \
    https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.plot.html \
    very small is ',', little bigger is '.'
markersize=3
  .type=float
markerfacecolor = white
  .type = str
markeredgecolor="black"
  .type = str
show_filling = True
  .type = bool
show_contours = True
  .type = bool
dpi=100
  .type=int
wxplot = False
  .type = bool
  .help = Display interactive plots (requires wxPython and Matplotlib)
outliers_only = False
  .type = bool
  .help = "Only display outliers"
json = False
  .type = bool
  .help = "Prints results as JSON format dictionary"
verbose = True
  .type = bool
  .help = '''Verbose'''
output_prefix = None
  .type = str
  .help = prefix for outputted plots (if plot=True)
"""

def master_params():
  return iotbx.phil.parse(master_phil_str)

def compute(hierarchies, params, log, quiet=False, plot_file_base_default=None):
  results = []
  for hierarchy in hierarchies:
    result = ramalyze(
      pdb_hierarchy = hierarchy,
      show_errors   = None,
      outliers_only = params.outliers_only,
      out           = log,
      quiet         = quiet)
    results.append(result)
  # combine models
  result = results[0]
  for i in range(1,len(results)):
    result += results[i]
  if params.verbose and not params.json:
    result.show_old_output(out=log, verbose=True)
  if params.plot:
    plot_file_base = params.output_prefix
    if plot_file_base is None:
      plot_file_base = plot_file_base_default
    result.write_plots(
      plot_file_base  = plot_file_base,
      out             = log,
      show_labels     = params.show_labels,
      point_style     = params.point_style,
      markerfacecolor = params.markerfacecolor,
      show_filling    = params.show_filling,
      show_contours   = params.show_contours,
      dpi             = params.dpi,
      markeredgecolor = params.markeredgecolor,
      markersize      = params.markersize)
  if params.wxplot:
    try:
      import wxtbx.app
    except ImportError as e:
      raise Sorry("wxPython not available.")
    else:
      app = wxtbx.app.CCTBXApp(0)
      result.display_wx_plots()
      app.MainLoop()
  else:
    return result

class Program(ProgramTemplate):
  prog = os.getenv('LIBTBX_DISPATCHER_NAME')
  description="""
  %(prog)s file.pdb [params.eff] [options ...]

Options:

  model=input_file      input PDB file
  outliers_only=False   only print outliers
  json=False            Outputs results as JSON compatible dictionary
  verbose=False         verbose text output
  plot=False            Create graphics of plots (if Matplotlib is installed)

Example:

  %(prog)s model=1ubq.pdb outliers_only=True
""" % locals()

  # Pavel's style:
  # plot=True show_labels=False markerfacecolor=yellow markeredgecolor=red

  master_phil_str = master_phil_str

  datatypes = ['model','phil']
  data_manager_options = ['model_skip_expand_with_mtrix']
  known_article_ids = ['molprobity']

  def validate(self):
    self.data_manager.has_models(raise_sorry=True)

  def get_results_as_JSON(self):
    # this calculates the results separately from run() because historically
    # the ramalyze object couldn't handle multi-model files. Multi-model support was
    # added for the JSON code.  Ideally this would get fixed in the future.
    hierarchy = self.data_manager.get_model().get_hierarchy()
    self.info_json = {"model_name":self.data_manager.get_default_model_name(),
                      "time_analyzed": str(datetime.now())}
    result = ramalyze(
      pdb_hierarchy = hierarchy,
      outliers_only = self.params.outliers_only,
      out           = self.logger)
    return result.as_JSON(self.info_json)

  def run(self):
    if self.params.json:
      print(self.get_results_as_JSON())
    hierarchies = []
    for model_name in self.data_manager.get_model_names():
      hierarchy = self.data_manager.get_model(model_name).get_hierarchy()
      hierarchies.append(hierarchy)
    fb = os.path.splitext(os.path.basename(
      self.data_manager.get_model_names()[0]))[0]
    self.results = compute(
      hierarchies            = hierarchies,
      params                 = self.params,
      log                    = self.logger,
      quiet                  = False,
      plot_file_base_default = fb)

  def get_results(self):
    return self.results


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/reduce2.py
##################################################################################
# Copyright(c) 2021-2023, Richardson Lab at Duke
# Licensed under the Apache 2 license
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissionsand
# limitations under the License.

from __future__ import absolute_import, division, print_function
import sys
import os
import time
from datetime import datetime
from libtbx.program_template import ProgramTemplate
from libtbx import group_args, phil
from libtbx.str_utils import make_sub_header
from libtbx.utils import Sorry, null_out
import mmtbx
from mmtbx.probe import Helpers
from iotbx import pdb, cli_parser
from mmtbx.hydrogens import reduce_hydrogen
from mmtbx.reduce import Optimizers
from scitbx.array_family import flex
from iotbx.pdb import common_residue_names_get_class, amino_acid_codes, nucleic_acid_codes
from mmtbx.programs import probe2
import copy
from iotbx.data_manager import DataManager
import csv

version = "2.12.0"

master_phil_str = '''
approach = *add remove
  .type = choice
  .short_caption = Add or remove Hydrogens
  .help = Determines whether Reduce will add (and optimize) or remove Hydrogens from the model
keep_existing_H = False
  .type = bool
  .short_caption = Do not remove Hydrogens in the original model
  .help = Keep existing H atoms in the model
n_terminal_charge = *residue_one first_in_chain no_charge
  .type = choice(multi=False)
  .short_caption = N terminal charge approach
  .help = Mode for placing H3 at terminal nitrogen.
use_neutron_distances = False
  .type = bool
  .short_caption = Use neutron distances
  .help = Use neutron distances (-nuclear in reduce)
preference_magnitude = 1.0
  .type = float
  .short_caption = Rotational-preference magnitude
  .help = Multiplier on the rotational-preference energy for rotatable Movers (-penalty in reduce)
alt_id = None
  .type = str
  .short_caption = Alternate to optimize
  .help = Alternate to optimize.  The default is to optimize all of them.
model_id = None
  .type = int
  .short_caption = Model ID to optimize
  .help = Model ID to optimize.  The default is to optimize all of them.  If one is selected, the others are removed from the output file.
add_flip_movers = False
  .type = bool
  .short_caption = Add flip movers
  .help = Insert flip movers (-flip, -build, -noflip, -demandflipallnhqs in reduce)
non_flip_preference = 0.5
  .type = float
  .short_caption = Preference to not flip
  .help = For flip movers, only do the flip if the score in the flipped orientation is this much better.
skip_bond_fix_up = False
  .type = bool
  .short_caption = Skip fixup step for Movers that are flips
  .help = For debugging purposes, it can be useful to only do flips with no bond fix-up to compare scores. This fixup is done to make the bond angles within expected ranges for structures that are going to be deposited in the PDB. If further refinement is to be done, then it may also be useful to set this to True.
set_flip_states = None
  .type = str
  .short_caption = Comma-separated list of flip Mover states to set
  .help = String with comma-separated entries. Each entry has the form without the single quotes "'1 . A HIS 11H Flipped AnglesAdjusted'". These are space-separated values. The first word is the model number, starting with 1. The second is the lower-case alternate, or '.' for all alternates -- also use this when there are no alternates in the file. The third is the chain ID. The fourth is the residue name. The fifth is the residue id, which may include an insertion code as its last character. The sixth is either Flipped or Unflipped. If it is Flipped, then another word is added -- AnglesAdjusted or AnglesNotAdjusted, specifying whether to do the three-point dock to adjust the bond angles after the flip. An example with several entries is: again, no quotes are included: "'1 a A HIS 11H Unflipped,1 b A ASN 15 Flipped AnglesNotAdjusted,1 . B GLN 27 Flipped AnglesAdjusted'". Any Flip Movers that would be placed at the specified location are instead locked in the specified configuration.
profile = False
  .type = bool
  .short_caption = Profile the entire run
  .help = Profile the performance of the entire run
comparison_file = None
  .type = str
  .short_caption = Compare the Mover scores from this run with those in comparison_file
  .help = Points to a comparison_file that is the result of running Hydrogenate or Reduce or Reduce2 or some other hydrogen-placement program. The Probe2 scores for the Movers found in the current run are compared against the scores for comparison_file and stored in a file with the same name as output.file_name with _comparison.csv appended. If None, no comparison is done.
verbosity = 2
  .type = int
  .short_caption = Level of detail in description file
  .help = Level of detail in description file.
bonded_neighbor_depth = 4
  .type = int
  .short_caption = How many neighbors to consider bonded (>3 accepted only if hydrogen)
  .help = When looking for interactions between atoms, this specifies how many hops we should take when looking for atoms that are excluded because we share a common chain of bonds. Lengths more than 3 only happen when one end is a hydrogen. This value should not be changed from the default except for regression tests against earlier versions.
stop_on_any_missing_hydrogen = False
  .type = bool
  .short_caption = Emit a Sorry and stop when any hydrogen in the model has insufficient restraints.
  .help = Emit a Sorry and stop when any hydrogen in the model has insufficient restraints. It will always emit when there are one or more residues without restraints.

output
  .style = menu_item auto_align
{
  write_files = True
    .type = bool
    .short_caption = Write the output files
    .help = Write the output files(s) when this is True (default). Set to False when harnessing the program.
  description_file_name = None
    .type = str
    .short_caption = Description output file name
    .help = This file holds a description of the operations that Reduce2 performed when placing and optimize hydrogens. Its creation is required because it can contain important warnings that must be attended to by the person running the program. It also includes a REPORT section that lists the final orientation along with initial and final score for each Mover that can be parsed to determine the results. The REPORT information and some additional information used to be included in the resulting PDB file produced by Reduce.
  flipkin_directory = None
    .type = str
    .short_caption = Where to place the Flipkin Kinemages
    .help = Where to place the Flipkin Kinemages. If None, no Flipkin files are made.
  clique_outline_file_name = None
    .type = str
    .short_caption = Where to save a Kinemage showing all positions for atoms in each Mover in each clique
    .help = Where to save a Kinemage showing all positions for atoms in each Mover for each clique. This enable exploration of the reasons for the cliques. Each clique has the atoms expanded by the probe radius and as each is turned off, the Movers inside are revealed. Clicking on each Mover shows its description. If None, no such Kinemage is made.
  print_atom_info = False
    .type = bool
    .short_caption = Print extra atom info
    .help = Print extra atom info
}
''' + Helpers.probe_phil_parameters.replace("probe_radius = 0.25", "probe_radius = 0.0")
# @todo We replace the default probe radius of 0.25 with 0.0 to avoid the issue described in
# https://github.com/cctbx/cctbx_project/issues/1072 until we can figure out the appropriate
# fix.

program_citations = phil.parse('''
citation {
  authors = Word, et. al.
  journal = J. Mol. Biol.
  volume = 285
  pages = 1735-1747
  year = 1999
  external = True
}
''')

# ------------------------------------------------------------------------------

class _MoverLocation(object):
  # Holds information needed to identify a Mover within a model file.
  def __init__(self, moverType, modelId, altId, chain, resName, resIdWithICode):
    self.moverType = moverType  # String indicating Mover type: AmideFlip or HisFlip
    self.modelId = modelId      # Integer indicating the modelId that the entry corresponds to
    self.altId = altId          # String indicating the altId that the entry corresponds to
    self.chain = chain          # String Chain that the residue is in
    self.resName = resName      # String Name of the residue
    try:                        # String holding the integer ID of the residue and any insertion code
      self.resId = int(resIdWithICode)
      self.iCode = ''
    except Exception:
      self.resId = int(resIdWithICode[:-1])
      self.iCode = resIdWithICode[-1]

  def __str__(self):
    return "{} {} '{}' {} {} {}{}".format(self.moverType, self.modelId, self.altId,
      self.chain, self.resName, self.resId, self.iCode)
  def __repr__(self):
      return "_MoverLocation({})".format(str(self))


def _FindMoversInOutputString(s, moverTypes = ['SingleHydrogenRotator',
      'NH3Rotator', 'AromaticMethylRotator', 'AmideFlip', 'HisFlip']):
  '''Return a list of _MoverLocation items that include all of them found in the
  output string from an Optimizer.
  :param s: String returned from the getInfo() method on an optimizer.
  :param moverTypes: List of names for the movertypes to find.
  :return: List of _MoverLocation objects indicating all flip Movers listed inside
  any BEGIN...END REPORT block in the string, including whether they were marked as
  flipped.
  '''
  ret = []
  modelId = None
  altId = None
  inBlock = False
  for line in s.splitlines():
    words = line.split()
    if inBlock:
      if words[0:2] == ['END','REPORT']:
        inBlock = False
      elif words[0] in moverTypes:
        ret.append(_MoverLocation(words[0], modelId, altId, words[3], words[4], int(words[5])))
    else:
      if words[0:2] == ['BEGIN','REPORT:']:
        modelId = int(words[3])
        # Remove the single-quote and colon characters from the AltId, possibly leaving it empty
        trim = words[5].replace("'", "")
        trim = trim.replace(":", "")
        altId = trim
        inBlock = True
  return ret


def _FindFlipsInOutputString(s, moverType):
  '''Return a list of Optimizers.FlipMoverState items that include all of them found in the
  output string from an Optimizer.
  :param s: String returned from the getInfo() method on an optimizer.
  :param moverType: Either AmideFlip or HisFlip, selects the flip type to report.
  :return: List of Optimizers.FlipMoverState objects indicating all flip Movers listed inside
  any BEGIN...END REPORT block in the string, including whether they were marked as
  flipped.
  '''
  ret = []
  modelId = None
  altId = None
  inBlock = False
  for line in s.splitlines():
    words = line.split()
    if inBlock:
      if words[0:2] == ['END','REPORT']:
        inBlock = False
      elif words[0] == moverType:
        ret.append(Optimizers.FlipMoverState(moverType, modelId, altId, words[3], words[4],
                                   words[5], words[14] == 'Flipped', words[15] == 'AnglesAdjusted') )
    else:
      if words[0:2] == ['BEGIN','REPORT:']:
        modelId = int(words[3])
        # Remove the single-quote and colon characters from the AltId, possibly leaving it empty
        trim = words[5].replace("'", "")
        trim = trim.replace(":", "")
        altId = trim
        inBlock = True
  return ret

def _IsMover(rg, movers):
  '''Is a residue group in the list of residues that have Movers?
  :param rg: residue group
  :param movers: List of _MoverLocation or Optimizers.FlipMoverState objects
  :return: True if the residue is in the list, False if not
  '''
  for m in movers:
    chain = rg.parent()
    modelId = chain.parent().id
    # We must offset the index of the model by 1 to get to the 1-based model ID
    if ( (modelId == m.modelId + 1 or modelId == '') and
         (chain.id == m.chain) and
         (rg.resseq_as_int() == m.resId) and
         (rg.icode.strip() == m.iCode.strip())
       ):
      return True
  return False

def _AltFromFlipOutput(fo):
  '''Return a string that describes the alternate from a record in _FindFlipsInOutputString()
  output.  Reports ' ' for an empty alternate. Returns lower-case representation.
  '''
  if fo.altId in ["", ""]:
    return ' '
  return fo.altId.lower()


def _AddPosition(a, tag, group, partner=None):
  '''Return a string that describes the point at or line to the specified atom or just
  a sphere location.
  This is used when building Kinemages.  Reports the alternate only if it is not empty.
  :param a: Atom to describe.
  :param tag: 'P' for point, 'L' for line, '' for sphere location.
  :param group: The dominant group name the point or line is part of.
  :param partner: Lines connect two atoms, and the alternate of either of them
  causes the line to be in that alternate.  This provides a way to tell about
  a second atom whose alternate should be checked as well.
  '''
  if len(tag) > 0:
    tagString = ' {}'.format(tag)
  else:
    tagString = ''
  if a.parent().altloc in ['', ' ']:
    altLoc = ''
    altTag = ''
  else:
    altLoc = a.parent().altloc.lower()
    altTag = " '{}'".format(a.parent().altloc.lower())
  if (partner is not None) and not (partner.parent().altloc in ['', ' ']):
    altLoc = partner.parent().altloc.lower()
    altTag = " '{}'".format(partner.parent().altloc.lower())
  return '{{{:4s}{:1s}{} {} {:3d} B{:.2f} {}}}{}{} {:.3f}, {:.3f}, {:.3f}'.format(
    a.name.lower(),                       # Atom name
    altLoc,                               # Alternate, if any
    a.parent().resname.strip().lower(),   # Residue name
    a.parent().parent().parent().id,      # chain
    a.parent().parent().resseq_as_int(),  # Residue number
    a.b,                                  # B factor
    group,                                # Dominant group name
    tagString,                            # Tag (P or L)
    altTag,                               # Tag for alternate, if any
    a.xyz[0],                             # location
    a.xyz[1],
    a.xyz[2]
  )


def _DescribeMainchainLink(a0s, a1s, group):
  '''Return a string that describes the links between two atom sets, each of
  which may contain multiple alternates. Only link ones that have compatible
  alternates.
  :param a0s: Alternates of first atom.
  :param a1s: Alternates of second atom.
  :param group: The dominant group name the point or line is part of.
  @todo When we have alternates that end at a common atom, that atom's
  alternative is used for the line, making it appear in both alts.
  '''
  ret = ''
  if (a0s is None) or (a1s is None):
    return ret
  for a0 in a0s:
    for a1 in a1s:
      if Helpers.compatibleConformations(a0, a1):
        ret += _AddPosition(a0, 'P', group) + ' ' + _AddPosition(a1, 'L', group, a0) + '\n'
  return ret


_amino_acid_resnames = sorted(amino_acid_codes.one_letter_given_three_letter.keys())
def _IsStandardResidue(resname):
  return resname.strip().upper() in _amino_acid_resnames


_nucleic_acid_resnames = set(nucleic_acid_codes.rna_one_letter_code_dict.keys()).union(
  set(nucleic_acid_codes.dna_one_letter_code_dict.keys()))
def _IsNucleicAcidResidue(resname):
  return resname.strip().upper() in _nucleic_acid_resnames


def _MainChainAtomsWithHydrogen(resname):
  # Find the main chain atoms with hydrogen bonds
  if _IsStandardResidue(resname):
    return ['N', 'CA', 'C', 'O']
  elif _IsNucleicAcidResidue(resname):
    return ["OP2", "OP3", "C5'", "C4'", "C3'", "C2'", "C1'", "O3'", "O2'"]
  return []


def _DescribeMainchainResidue(r, group, prevCs):
  '''Return a string that describes the mainchain for a specified residue.
  Add the point for the first mainchain atom in the previous residue
  (none for the first) and lines to the N, Ca, C, and O.
  :param r: Residue to describe.
  :param group: The dominant group name the point or line is part of.
  :param prevCs: Atom(s) that is the mainchain last connection in all conformations
  of the previous residue. For protein, this is C and for nucleic acid, this is O3'.
  '''

  ret = ''

  ############################################################
  # Protein main chain
  if _IsStandardResidue(r.atom_groups()[0].resname):

    # Find the lists of atoms that we might need.
    Ns = [a for a in r.atoms() if a.name.strip().upper() == 'N']
    CAs = [a for a in r.atoms() if a.name.strip().upper() == 'CA']
    Cs = [a for a in r.atoms() if a.name.strip().upper() == 'C']
    Os = [a for a in r.atoms() if a.name.strip().upper() == 'O']
    OXTs = [a for a in r.atoms() if a.name.strip().upper() == 'OXT']

    # Make all of the connections.
    ret += _DescribeMainchainLink(prevCs, Ns, group)
    ret += _DescribeMainchainLink(Ns, CAs, group)
    ret += _DescribeMainchainLink(CAs, Cs, group)
    ret += _DescribeMainchainLink(Cs, Os, group)
    ret += _DescribeMainchainLink(Cs, OXTs, group)

  ############################################################
  # Nucleic acid main chain
  if _IsNucleicAcidResidue(r.atom_groups()[0].resname):

    # Find the lists of atoms that we might need.
    Ps = [a for a in r.atoms() if a.name.strip().upper() == "P"]
    OP3s = [a for a in r.atoms() if a.name.strip().upper() == "OP3"]
    OP2s = [a for a in r.atoms() if a.name.strip().upper() == "OP2"]
    OP1s = [a for a in r.atoms() if a.name.strip().upper() == "OP1"]
    O5Ps = [a for a in r.atoms() if a.name.strip().upper() == "O5'"]
    O4Ps = [a for a in r.atoms() if a.name.strip().upper() == "O4'"]
    O3Ps = [a for a in r.atoms() if a.name.strip().upper() == "O3'"]
    O2Ps = [a for a in r.atoms() if a.name.strip().upper() == "O2'"]
    C5Ps = [a for a in r.atoms() if a.name.strip().upper() == "C5'"]
    C4Ps = [a for a in r.atoms() if a.name.strip().upper() == "C4'"]
    C3Ps = [a for a in r.atoms() if a.name.strip().upper() == "C3'"]
    C2Ps = [a for a in r.atoms() if a.name.strip().upper() == "C2'"]
    C1Ps = [a for a in r.atoms() if a.name.strip().upper() == "C1'"]

    # Make all of the connections.
    ret += _DescribeMainchainLink(prevCs, Ps, group)
    ret += _DescribeMainchainLink(Ps, OP1s, group)
    ret += _DescribeMainchainLink(Ps, OP2s, group)
    ret += _DescribeMainchainLink(Ps, OP3s, group)
    ret += _DescribeMainchainLink(Ps, O5Ps, group)
    ret += _DescribeMainchainLink(O5Ps, C5Ps, group)
    ret += _DescribeMainchainLink(C5Ps, C4Ps, group)
    ret += _DescribeMainchainLink(C4Ps, C3Ps, group)
    ret += _DescribeMainchainLink(C3Ps, C2Ps, group)
    ret += _DescribeMainchainLink(C2Ps, O2Ps, group)

    ret += _DescribeMainchainLink(C4Ps, O4Ps, group)
    ret += _DescribeMainchainLink(O4Ps, C1Ps, group)
    ret += _DescribeMainchainLink(C1Ps, C2Ps, group)

    ret += _DescribeMainchainLink(C3Ps, O3Ps, group)

  return ret


def _DescribeMainchainResidueHydrogens(r, group, bondedNeighborLists):
  '''Return a string that describes the mainchain hydrogens for a specified residue.
  :param r: Residue to describe.
  :param group: The dominant group name the point or line is part of.
  :param bondedNeighborLists: A dictionary that contains an entry for each atom in the
  structure that the atom from the first parameter interacts with that lists all of the
  bonded atoms.  Can be obtained by calling mmtbx.probe.Helpers.getBondedNeighborLists().
  '''
  ret = ''

  # Find all of the Hydrogens in the residue
  Hs = [a for a in r.atoms() if a.element_is_hydrogen()]
  for h in Hs:
    try:
      n = bondedNeighborLists[h][0]
      # If the hydrogen is bonded to a mainchain atom, add it
      if n.name.strip().upper() in _MainChainAtomsWithHydrogen(r.atom_groups()[0].resname):
        ret += _AddPosition(n, 'P', group) + ' ' + _AddPosition(h, 'L', group, n) + '\n'
    except Exception:
      pass

  return ret


def _DescribeSidechainResidue(r, group, bondedNeighborLists):
  '''Return a string that describes the sidechain non-hydrogen portions for a specified residue.
  :param r: Residue to describe.
  :param group: The dominant group name the point or line is part of.
  :param bondedNeighborLists: A dictionary that contains an entry for each atom in the
  structure that the atom from the first parameter interacts with that lists all of the
  bonded atoms.  Can be obtained by calling mmtbx.probe.Helpers.getBondedNeighborLists().
  '''
  ret = ''

  described = []   # A list of sets of two atoms that we have already described bonds between
  queued = []

  ############################################################
  # Protein main chain
  if _IsStandardResidue(r.atom_groups()[0].resname):

    # Start with the CA atom and mark as handled all links that go back to the main chain
    # or to Hydrogens.  Add the CA to the list of atoms queued to be handled.
    try:
      # Get all of the neighbors of CA that are not N or C.  Queue them for testing.
      # Do this for all CAs found because there may be multiple atom groups (alts)
      for aCA in [a for a in r.atoms() if a.name.strip().upper() == 'CA']:
        queued.append(aCA)
        known = [a for a in bondedNeighborLists[aCA]
                 if a.element_is_hydrogen() or a.name.strip().upper() in ['N','C']]
        for a in known:
          described.append({aCA, a})
    except Exception:
      pass

  elif _IsNucleicAcidResidue(r.atom_groups()[0].resname):

    # Start with the C1' atom and mark as handled all links that go back to the main chain
    # or to Hydrogens.  Add the C1' to the list of atoms queued to be handled.
    try:
      # Get all of the neighbors of CA that are not C2' or O4'.  Queue them for testing.
      # Do this for all Cs found because there may be multiple atom groups (alts)
      for aC in [a for a in r.atoms() if a.name.strip().upper() == "C1'"]:
        queued.append(aC)
        known = [a for a in bondedNeighborLists[aC]
                 if a.element_is_hydrogen() or a.name.strip().upper() in ["C2'","O4'"]]
        for a in known:
          described.append({aC, a})
    except Exception:
      pass

  # Cycle through the list of queued atoms until we run out of them.
  # For each, look for a non-hydrogen neighbor that we've not yet described a bond
  # with.  If none are found, remove this entry from the list and cycle again.
  # If one is found, add a point and then a line for the first neighbor found, adding
  # that neighbor and all others to the queued list and continuing to chase to (line to
  # the first, adding it and all others to the queued list) until we find no more links
  # to atoms in the same residue.
  while len(queued) > 0:
    last = queued[0]
    links = [a for a in bondedNeighborLists[last]
              if (not {last, a} in described) and (not a.element_is_hydrogen())
                and (last.parent().parent() == a.parent().parent())
            ]
    if len(links) == 0:
      # First entry on the list yielded no useful neighbors; remove it and check the next
      queued = queued[1:]
      continue
    ret += _AddPosition(last, 'P', group) + ' '
    while len(links) != 0:
      # Put all but the first link into the list to be checked later.
      for a in links[1:]:
        queued.append(a)
      # Add the description for our first one and keep chasing this path
      curr = links[0]
      described.append({last,curr})
      ret += _AddPosition(curr, 'L', group, last) + '\n'
      links = [a for a in bondedNeighborLists[curr]
                if (not {curr, a} in described) and (not a.element_is_hydrogen())
                and (curr.parent().parent() == a.parent().parent())
              ]
      last = curr
  return ret


def _DescribeSidechainResidueHydrogens(r, group, bondedNeighborLists):
  '''Return a string that describes the sidechain hydrogens for a specified residue.
  :param r: Residue to describe.
  :param group: The dominant group name the point or line is part of.
  :param bondedNeighborLists: A dictionary that contains an entry for each atom in the
  structure that the atom from the first parameter interacts with that lists all of the
  bonded atoms.  Can be obtained by calling mmtbx.probe.Helpers.getBondedNeighborLists().
  '''
  ret = ''

  # Find all of the Hydrogens in the residue
  Hs = [a for a in r.atoms() if a.element_is_hydrogen()]
  for h in Hs:
    try:
      n = bondedNeighborLists[h][0]
      # If the hydrogen is bonded to a mainchain atom, add it
      if not n.name.strip().upper() in _MainChainAtomsWithHydrogen(r.atom_groups()[0].resname):
        ret += _AddPosition(n, 'P', group) + ' ' + _AddPosition(h, 'L', group, n) + '\n'
    except Exception:
      pass

  return ret


def _DescribeHet(r, group, bondedNeighborLists):
  '''Return a string that describes the bonds in a Hetatm structure.
  :param r: Residue to describe.
  :param group: The dominant group name the point or line is part of.
  :param bondedNeighborLists: A dictionary that contains an entry for each atom in the
  structure that the atom from the first parameter interacts with that lists all of the
  bonded atoms.  Can be obtained by calling mmtbx.probe.Helpers.getBondedNeighborLists().
  '''
  ret = ''

  # Start with the first atom and no described links.
  described = []   # A list of sets of two atoms that we have already described bonds between
  queued = [r.atoms()[0]]

  # Cycle through the list of queued atoms until we run out of them.
  # For each, look for a non-hydrogen neighbor that we've not yet described a bond
  # with.  If none are found, remove this entry from the list and cycle again.
  # If one is found, add a point and then a line for the first neighbor found, adding
  # that neighbor and all others to the queued list and continuing to chase to (line to
  # the first, adding it and all others to the queued list) until we find no more links
  # to atoms in the same residue.
  while len(queued) > 0:
    last = queued[0]
    links = [a for a in bondedNeighborLists[last]
              if (not {last, a} in described) and (not a.element_is_hydrogen())
                and (last.parent() == a.parent())
            ]
    if len(links) == 0:
      # First entry on the list yielded no useful neightbors; remove it and check the next
      queued = queued[1:]
      continue
    ret += _AddPosition(last, 'P', group) + ' '
    while len(links) != 0:
      # Put all but the first link into the list to be checked later.
      for a in links[1:]:
        queued.append(a)
      # Add the description for our first one and keep chasing this path
      curr = links[0]
      described.append({last,curr})
      ret += _AddPosition(curr, 'L', group, last) + '\n'
      links = [a for a in bondedNeighborLists[curr]
                if (not {curr, a} in described) and (not a.element_is_hydrogen())
                and (curr.parent() == a.parent())
              ]
      last = curr
  return ret


def _DescribeHetHydrogens(r, group, bondedNeighborLists):
  '''Return a string that describes the hydrogens for a specified residue.
  :param r: Residue to describe.
  :param group: The dominant group name the point or line is part of.
  :param bondedNeighborLists: A dictionary that contains an entry for each atom in the
  structure that the atom from the first parameter interacts with that lists all of the
  bonded atoms.  Can be obtained by calling mmtbx.probe.Helpers.getBondedNeighborLists().
  '''
  ret = ''

  # Find all of the Hydrogens in the residue
  Hs = [a for a in r.atoms() if a.element_is_hydrogen()]
  for h in Hs:
    try:
      n = bondedNeighborLists[h][0]
      ret += _AddPosition(n, 'P', group) + ' ' + _AddPosition(h, 'L', group, n) + '\n'
    except Exception:
      pass

  return ret


def _AddFlipkinBase(states, views, fileName, fileBaseName, model, alts, bondedNeighborLists,
    moverList, inSideChain, inWater, inHet):
  '''Return a string that forms the basis for a Flipkin file without the optional positions
  for the specified movers.  This includes the views that will be used to look at them.
  :param states: Return value from _FindFlipsInOutputString() indicating behavior of
  each Mover.
  :param views: List of viewpoints, one per entry in states.
  :param fileName: Name of the optimized output file associated with this Flipkin.
  :param fileBaseName: The base name of the file, without path or extension.
  :param model: The model we're optimizing.
  :param alts: A list of alternates, empty if there are none. Sorted in increasing order.
  :param bondedNeighborLists: List of neighboring atoms bonded to each atom.
  :param moverList: List of Movers, which will be used to exclude residues.
  :param inSideChain: Dictionary looked up by atom telling whether it is in a side chain.
  :param inWater: Dictionary looked up by atom telling whether it is in water.
  :param inHet: Dictionary looked up by atom telling whether it is a hetatm.
  '''
  ret = '@kinemage 1\n'
  ret += '@caption\nfrom file: {}\n'.format(fileName)

  # Compute the views for each Mover as the center of mass of all of the moving atoms and
  # record them, indicating which are flipped in Reduce.
  ret += ' views marked with * are for groups flipped by reduce\n'
  for i, s in enumerate(states):
    # We only have views for the states in the first alternate tried, so we end up with
    # more states than views.  They are repeats, so once we have done all views we are
    # done.
    if i >= len(views):
      break;

    # See whether the state is flipped in Reduce and add a star if so
    star = ' '
    if s.flipped:
      star = '*'

    # Find out the type of the residue, used to determine the type of flip.
    type = '?'
    if s.resName[-3:] == 'ASN':
      type = 'N'
    elif s.resName[-3:] == 'GLN':
      type = 'Q'
    elif s.resName[-3:] == 'HIS':
      type = 'H'

    if i > 0:
      indexString = str(i+1)
    else:
      indexString = ''
    # @todo The original Flipkin generation sometimes reported alternate conformations. We currently always
    # report the average view over all conformations.
    # ret += '@{}viewid {{{}{}{} {} {}}}\n'.format(indexString, star, type, s.resId, _AltFromFlipOutput(s), s.chain)
    ret += '@{}viewid {{{}{}{} {} {}}}\n'.format(indexString, star, type, s.resId, ' ', s.chain)
    ret += '@{}span 12\n'.format(indexString)
    ret += '@{}zslab 100\n'.format(indexString)
    ret += '@{}center{:9.3f}{:9.3f}{:9.3f}\n'.format(indexString, views[i][0], views[i][1], views[i][2])

  # Add the master descriptions
  ret += '@master {mainchain}\n'
  ret += '@master {sidechain}\n'
  ret += "@master {H's}\n"
  ret += '@master {hets}\n'
  ret += '@master {water}\n'

  # Add width and group description, which is the base name of the file without
  # its extension
  ret += '@onewidth\n'
  ret += '@group {{{}}} dominant\n'.format(fileBaseName)

  # Add the masters for the alternates if there are any. The sorted list always starts
  # with '' and then adds the others in increasing order.
  defaultAltSet = False
  for a in alts:
    # The first one is turned on and the others are turned off by default
    if defaultAltSet:
      state = 'off'
    else:
      defaultAltSet = True
      state = 'on'
    ret += "@pointmaster '{}' {{{}}} {}\n".format(a.lower(), 'alt'+a.lower(), state)

  # Add the mainchain (no hydrogens) for all residues (even Movers of the type
  # we're looking at right now). Record the location(s) for the last mainchain
  # atom in the previous residue (None for the first). Handle multiple alternates.
  ret += '@subgroup {{mc {}}} dominant\n'.format(fileBaseName)
  ret += '@vectorlist {mc} color= white  master= {mainchain}\n'
  for c in model.chains():
    prevCs = None
    for rg in c.residue_groups():
      ret += _DescribeMainchainResidue(rg, fileBaseName, prevCs)
      try:
        prevCs = [a for a in rg.atoms() if a.name.strip().upper() == 'C']
        # If not protein, check nucleic acid
        if len(prevCs) == 0:
          prevCs = [a for a in rg.atoms() if a.name.strip().upper() == "O3'"]
      except Exception:
        pass

  # Add the Hydrogens on the mainchain
  ret += "@vectorlist {mc H} color= gray  nobutton master= {mainchain} master= {H's}\n"
  for c in model.chains():
    for rg in c.residue_groups():
      if not inHet[rg.atoms()[0]] and not inWater[rg.atoms()[0]]:
        ret += _DescribeMainchainResidueHydrogens(rg, fileBaseName, bondedNeighborLists)

  # Add the sidechain non-hydrogen atoms for residues that do not have Movers
  ret += '@subgroup {{sc {}}} dominant\n'.format(fileBaseName)
  ret += '@vectorlist {sc} color= cyan  master= {sidechain}\n'
  for c in model.chains():
    for rg in c.residue_groups():
      if not inHet[rg.atoms()[0]] and not inWater[rg.atoms()[0]]:
        if not _IsMover(rg, moverList):
          ret += _DescribeSidechainResidue(rg, fileBaseName, bondedNeighborLists)

  # Add the Hydrogens on the sidechains for residues that do not have Movers
  ret += "@vectorlist {sc H} color= gray  nobutton master= {sidechain} master= {H's}\n"
  for c in model.chains():
    for rg in c.residue_groups():
      if not inHet[rg.atoms()[0]] and not inWater[rg.atoms()[0]]:
        if not _IsMover(rg, moverList):
          ret += _DescribeSidechainResidueHydrogens(rg, fileBaseName, bondedNeighborLists)

  # Describe links between atoms in a sidechain and another residue where neither of the
  # involved residues include Movers.  Don't repeat bonds that have already been
  # described.
  ret += '@vectorlist {SS} color= yellow  master= {sidechain}\n'
  described = []
  for a in model.get_atoms():
    for n in bondedNeighborLists[a]:
      if (a.parent().parent() != n.parent().parent() and inSideChain[a]
          and not _IsMover(a.parent().parent(), moverList)
          and not _IsMover(n.parent().parent(), moverList)
          ):
        if {a,n} not in described:
          ret += _AddPosition(a, 'P', fileBaseName) + ' ' + _AddPosition(n, 'L', fileBaseName, a) + '\n'
          described.append({a,n})

  # Add spheres for ions (was single-atom Het groups in original Flipkins?)
  ret += '@subgroup {het groups} dominant\n'
  ret += '@spherelist {het M} color= gray  radius= 0.5  nubutton master= {hets}\n'
  for a in model.get_atoms():
    if a.element_is_ion():
      ret += _AddPosition(a, '', fileBaseName) + '\n'

  # Add bonded structures for het groups that are not Movers
  ret += '@vectorlist {het} color= orange  master= {hets}\n'
  for c in model.chains():
    for rg in c.residue_groups():
      if inHet[rg.atoms()[0]] and not inWater[rg.atoms()[0]] and not _IsMover(rg, moverList):
         ret += _DescribeHet(rg, fileBaseName, bondedNeighborLists)
  ret += "@vectorlist {ht H} color= gray  master= {hets} master= {H's}\n"
  for c in model.chains():
    for rg in c.residue_groups():
      if inHet[rg.atoms()[0]] and not inWater[rg.atoms()[0]] and not _IsMover(rg, moverList):
         ret += _DescribeHetHydrogens(rg, fileBaseName, bondedNeighborLists)

  # Add waters
  ret += '@subgroup {waters} dominant\n'
  ret += '@balllist {water O} color= pink  radius= 0.15  master= {water}\n'
  for a in model.get_atoms():
    if inWater[a]:
      ret += _AddPosition(a, 'P', fileBaseName) + '\n'

  return ret

def _AddFlipkinMovers(states, fileBaseName, name, color, model, alts, bondedNeighborLists,
    moverList, inSideChain, inWater, inHet):
  '''Return a string that describes the Movers and atoms that are bonded to them.
  :param states: Return value from _FindFlipsInOutputString() indicating behavior of
  each Mover.
  :param fileBaseName: The base name of the file, without path or extension.
  :param name: Name for the master group.
  :param color: Color to use for the residues in states.
  :param model: The model we're optimizing.
  :param alts: A list of alternates, empty if there are none. Sorted in increasing order.
  :param bondedNeighborLists: List of neighboring atoms bonded to each atom.
  :param moverList: List of Movers, which will be used to exclude residues.
  :param inSideChain: Dictionary looked up by atom telling whether it is in a side chain.
  :param inWater: Dictionary looked up by atom telling whether it is in water.
  :param inHet: Dictionary looked up by atom telling whether it is a hetatm.
  '''
  ret = '@group {'+name+'} animate\n'
  ret += '@subgroup {sidechain} nobutton dominant\n'

  # Add balls on the nitrogens and oxygens in the Movers in the states so that
  # we can tell their orientations.  Nitrogens are sky colored and Oxygens are
  # red.
  ret += '@balllist {sc N} color= sky radius= 0.1000  nobutton master= {sidechain}\n'
  for c in model.chains():
    for rg in c.residue_groups():
      if _IsMover(rg, states):
        for a in rg.atoms():
          if a.element == 'N' and inSideChain[a]:
            ret += _AddPosition(a, 'P', fileBaseName) + '\n'
  ret += '@balllist {sc N} color= red radius= 0.1000  nobutton master= {sidechain}\n'
  for c in model.chains():
    for rg in c.residue_groups():
      if _IsMover(rg, states):
        for a in rg.atoms():
          if a.element == 'O' and inSideChain[a]:
            ret += _AddPosition(a, 'P', fileBaseName) + '\n'

  # Add the sidechain non-hydrogen atoms for the Movers that are in the states list.
  ret += '@vectorlist {sc} color= '+color+'  master= {sidechain}\n'
  for c in model.chains():
    for rg in c.residue_groups():
      if _IsMover(rg, states):
        ret += _DescribeSidechainResidue(rg, fileBaseName, bondedNeighborLists)

  # Add the Hydrogens on the sidechains for residues that are in the states list
  ret += "@vectorlist {sc H} color= gray  nobutton master= {sidechain} master= {H's}\n"
  for c in model.chains():
    for rg in c.residue_groups():
      if _IsMover(rg, states):
        ret += _DescribeSidechainResidueHydrogens(rg, fileBaseName, bondedNeighborLists)

  # Add the sidechain non-hydrogen atoms for the Movers that are not in the states list.
  ret += '@vectorlist {sc} color= cyan  master= {sidechain}\n'
  for c in model.chains():
    for rg in c.residue_groups():
      if _IsMover(rg, moverList) and not _IsMover(rg, states):
        ret += _DescribeSidechainResidue(rg, fileBaseName, bondedNeighborLists)

  # Add the Hydrogens on the sidechains for the Movers that are not in the states list
  ret += "@vectorlist {sc H} color= gray  nobutton master= {sidechain} master= {H's}\n"
  for c in model.chains():
    for rg in c.residue_groups():
      if _IsMover(rg, moverList) and not _IsMover(rg, states):
        ret += _DescribeSidechainResidueHydrogens(rg, fileBaseName, bondedNeighborLists)

  # Describe links between atoms in a sidechain and another residue where one of the
  # involved residues include Movers.  Don't repeat bonds that have already been
  # described.
  ret += '@vectorlist {SS} color= yellow  master= {sidechain}\n'
  described = []
  for a in model.get_atoms():
    for n in bondedNeighborLists[a]:
      if (a.parent().parent() != n.parent().parent() and inSideChain[a]
          and (_IsMover(a.parent().parent(), moverList)
          or _IsMover(n.parent().parent(), moverList))
          ):
        if {a,n} not in described:
          ret += _AddPosition(a, 'P', fileBaseName) + ' ' + _AddPosition(n, 'L', fileBaseName, a) + '\n'
          described.append({a,n})

  # Add bonded structures for het groups that are Movers
  ret += '@vectorlist {het} color= orange  master= {hets}\n'
  for c in model.chains():
    for rg in c.residue_groups():
      if inHet[rg.atoms()[0]] and not inWater[rg.atoms()[0]] and _IsMover(rg, moverList):
         ret += _DescribeHet(rg, fileBaseName, bondedNeighborLists)
  ret += "@vectorlist {ht H} color= gray  master= {hets} master= {H's}\n"
  for c in model.chains():
    for rg in c.residue_groups():
      if inHet[rg.atoms()[0]] and not inWater[rg.atoms()[0]] and _IsMover(rg, moverList):
         ret += _DescribeHetHydrogens(rg, fileBaseName, bondedNeighborLists)

  return ret

def _RemoveModelsExceptIndex(model_manager, model_index):
    hierarchy = model_manager.get_hierarchy()
    models = hierarchy.models()
    if model_index < len(models):
        selected_model = models[model_index]
        for model in models:
            if model != selected_model:
                hierarchy.remove_model(model=model)
    return model_manager

# ------------------------------------------------------------------------------

class Program(ProgramTemplate):
  description = '''
reduce2 version {}
Add Hydrogens to a model and optimize their placement by adjusting movable groups and
flippable groups of atoms.

Inputs:
  PDB or mmCIF file containing atomic model
  Ligand CIF file, if needed
Output:
  PDB or mmCIF file with added hydrogens.  If output.filename is specified, then the
  type of file to write will be determined by its suffix (.pdb or .cif).
  If output.filename is not specified, the output file will be
  written into the current working directory with the same base name and type as the
  original file and with FH or H added to the base name (FH when flips are requested);
  1xs0.pdb would be written to ./1xsoH.pdb and 1xso.cif to ./1xsoH.cif by default.

NOTES:
  If multiple alternates are present in the file and a specific one is not specified on the
  command line, they will all be processed in reverse order, such that the lowest-named
  one (perhaps A) will be processed last.  The hydrogen addition and arrangements for
  residues that are not part of any alternate will be left in the configuration that is best
  for the final alternate tested.  This may leave other alternates in sub-optimal configurations.
  When a single alternate is selected using alt_id= on the command line, everything is
  optimized a single time and for that configuration.

  Note that the program also takes probe Phil arguments; run with --show_defaults to see
  all Phil arguments.

  Equivalent PHIL arguments for original Reduce command-line options:
    -quiet: No equivalent; metadata is never written to the model file, it is always
            written to the description file, and progress information is always written
            to standard output.
    -trim: approach=remove
    -build: approach=add add_flip_movers=True
    -flip: approach=add add_flip_movers=True
    -allalt: This is the default.
    -penalty200: preference_magnitude=200
    -nobuild9999: approach=add preference_magnitude=9999
    -noflip: approach=add add_flip_movers=True preference_magnitude=9999
    -onlya: alt_id=A
    -nuclear: use_neutron_distances=True
    -demandflipallnhqs: add_flip_movers=True
'''.format(version)
  datatypes = ['model', 'restraint', 'phil']
  master_phil_str = master_phil_str
  data_manager_options = ['model_skip_expand_with_mtrix',
                          'model_skip_ss_annotations']
  citations = program_citations
  epilog = '''
  For additional information and help, see http://kinemage.biochem.duke.edu/software/reduce
  and http://molprobity.biochem.duke.edu
  '''

# ------------------------------------------------------------------------------

  def _GetViews(self, movers):
    '''Produce a list of views that will center the sidechains of the specified Movers.
    It ignores the alternate and averages over all of them.  It only makes one entry
    if the same Mover is in more than one alternate.
    :param movers: Movers returned by _FindFlipsInOutputString().
    :return: List of 3-tuples of centers of the sidechains.
    '''
    views = []
    selStrings = []
    for mover in movers:
      # Fill in information needed to construct the view.
      # As of 2/5/2023, the CCTBX selection returns no atoms on a file when the model
      # clause is used unless there is a MODEL statement in the file.  The get_number_of_models()
      # function returns 1 if there are 0 or 1 MODEL statements, so we check to see if there
      # are 2 or more (indicating the need to select) before adding the clause.
      # The model ID that the selection is looking for is 1-based, so we must add 1 to the
      # model index.
      if self.model.get_number_of_models() >= 2:
        modelClause = 'model {} and '.format(mover.modelId + 1)
      else:
        modelClause = ''
      x = 0.0
      y = 0.0
      z = 0.0
      selString = modelClause + "chain {} and resseq {} and sidechain".format(
            mover.chain, mover.resId)
      if selString in selStrings:
        break
      selStrings.append(selString)
      sel = self.model.selection(selString)
      count = 0;
      for a in self.model.get_hierarchy().atoms():
        if sel[a.i_seq]:
          x += a.xyz[0]
          y += a.xyz[1]
          z += a.xyz[2]
          count += 1
      if count > 0:
        x /= count
        y /= count
        z /= count
      views.append( (x, y, z) )
    return views
# ------------------------------------------------------------------------------

  # Create a parser for Probe2 PHIL parameters, overriding specific defaults.
  # Use it to parse the parameters we need to change and return the parser so we
  # can extract values from it.
  def _MakeProbePhilParser(self, movers_to_check, extraArgs = []):

    # Determine the source and target selections based on the Movers
    # that we are checking being tested against everything else.
    source_selection = 'sidechain and ('
    for i, m in enumerate(movers_to_check):
      if i > 0:
        term = 'or ('
      else:
        term = ' ('
      term += 'chain {} and resid {}) '.format(m.chain, m.resId)
      source_selection += term
    source_selection += ')'
    target_selection = 'all'

    parser = cli_parser.CCTBXParser(program_class=probe2.Program, logger=null_out())
    args = [
      "source_selection='{}'".format(source_selection),
      "target_selection='{}'".format(target_selection),
      "use_neutron_distances={}".format(self.params.use_neutron_distances),
      "approach=both",
      "excluded_bond_chain_length={}".format(self._bondedNeighborDepth),
      "minimum_water_hydrogen_occupancy=0.66",
      "maximum_water_hydrogen_b=40.0",
      "minimum_occupancy=0.01",
      "output.write_files=False",
      "ignore_lack_of_explicit_hydrogens=True",
      "output.add_group_line=False"
    ]
    args.extend(extraArgs)

    # Add the probe parameters from the command line to the parser
    for arg in sys.argv:
      if arg.startswith("probe."):
        # Remove the leading "probe." and add it to the parser
        arg = arg[6:]
        args.append(arg)

    parser.parse_args(args)
    return parser

# ------------------------------------------------------------------------------

  def _AddHydrogens(self):
    reduce_add_h_obj = reduce_hydrogen.place_hydrogens(
      model = self.model,
      use_neutron_distances=self.params.use_neutron_distances,
      n_terminal_charge=self.params.n_terminal_charge,
      exclude_water=True,
      stop_for_unknowns=False,
      keep_existing_H=self.params.keep_existing_H
    )
    reduce_add_h_obj.run()
    reduce_add_h_obj.show(self.logger)
    missed_residues = set(reduce_add_h_obj.no_H_placed_mlq)
    if len(missed_residues) > 0:
      bad = ""
      for res in missed_residues:
        bad += " " + res
      raise Sorry("Restraints were not found for the following residues:"+bad)
    insufficient_restraints = list(reduce_add_h_obj.site_labels_no_para)
    if self.params.stop_on_any_missing_hydrogen and len(insufficient_restraints) > 0:
      bad = insufficient_restraints[0]
      for res in insufficient_restraints[1:]:
        bad += "," + res
      raise Sorry("Insufficient restraints were found for the following atoms:"+bad)

    self.model = reduce_add_h_obj.get_model()

    if not self.model.has_hd():
      raise Sorry("It was not possible to place any H atoms. Is this a single atom model?")

# ------------------------------------------------------------------------------

  def _ReinterpretModel(self, make_restraints=True):
    # Reinterpret the model using the same approach that hydrogen-placement does.
    # :param make_restraints: Should we compute restraints during the interpretation?
    self.model.get_hierarchy().sort_atoms_in_place()
    self.model.get_hierarchy().atoms().reset_serial()

    p = reduce_hydrogen.get_reduce_pdb_interpretation_params(
      self.params.use_neutron_distances)
    p.pdb_interpretation.disable_uc_volume_vs_n_atoms_check=True
    # We need to turn this on because without it 1zz0.txt kept flipping the ring
    # in A TYR 214 every time we re-interpreted. The original interpretation done
    # by Hydrogen placement will have flipped them, so we don't need to do it again.
    p.pdb_interpretation.flip_symmetric_amino_acids=False
    #p.pdb_interpretation.sort_atoms=True
    self.model.process(make_restraints=make_restraints, pdb_interpretation_params=p)

# ------------------------------------------------------------------------------

  def _GetAtomCharacteristics(self, bondedNeighborLists):
    '''Determine additional characteristics needed to determine probe dots.
    :param bondedNeighborLists: A dictionary that contains an entry for each atom in the
    structure that the atom from the first parameter interacts with that lists all of the
    bonded atoms.  Can be obtained by calling mmtbx.probe.Helpers.getBondedNeighborLists().
    :return: Tuple of maps to Booleans for whether the atom is in water, in Hetatm
    group, in the main chain, and in a side chain.
    '''
    inWater = {}
    inHet = {}
    inMainChain = {}
    inSideChain = {}
    hetatm_sel = self.model.selection("hetatm")
    mainchain_sel = self.model.selection("backbone")  # Will NOT include Hydrogen atoms on the main chain
    sidechain_sel = self.model.selection("sidechain") # Will include Hydrogen atoms on the side chain
    for a in self.model.get_atoms():
      inWater[a] = common_residue_names_get_class(name=a.parent().resname) == "common_water"
      inHet[a] = hetatm_sel[a.i_seq]
      if not a.element_is_hydrogen():
        inMainChain[a] = mainchain_sel[a.i_seq]
      else:
        # Check our bonded neighbor to see if it is on the mainchain if we are a Hydrogen
        if len(bondedNeighborLists[a]) < 1:
          raise Sorry("Found Hydrogen with no neigbors.")
        else:
          inMainChain[a] = mainchain_sel[bondedNeighborLists[a][0].i_seq]
      inSideChain[a] = sidechain_sel[a.i_seq]
    return (inWater, inHet, inMainChain, inSideChain)

# ------------------------------------------------------------------------------

  def _DescribeLockdown(self, flipMover, invertFlip, fixedUp):
    '''Produce a flip-state string describing how to lock down the specified flip mover.
    :param flipMover: The Optimizers.FlipMoverState object being locked down.
    :param invertFlip: Do we want to invert the flip state relative to the one described
    in the mover state?
    :param fixedUp: Should the Fixup be applied after flipping?
    :return: String description suitable for use in the --flip_states command-line option.
    For example: 1 . A HIS 11H Flipped AnglesAdjusted
    '''
    if fixedUp:
      adjustedString = 'AnglesAdjusted'
    else:
      adjustedString = 'AnglesNotAdjusted'
    flipped = flipMover.flipped
    if invertFlip:
      flipped = not flipped
    if flipped:
      flipStateString = 'Flipped'
    else:
      flipStateString = 'Unflipped'
    # Look up the residue that is described and find Nitrogens in it whose names are
    # longer than one character. These will be part of the flipping part of the residue.
    # See if any of these atoms residue groups have the same altid as the flipMover; if
    # so, use that one.  If not, use ''.  If we use '', replace it with '.' so that we
    # can properly parse the string.
    # @todo Atom selection here is will not necessarily work for future flip Movers.
    # @todo How to handle cases where the different alternates resulted in different placement
    # for the flip Movers?  Presumably, we want to do them in backwards order and replace all of
    # the alternates with '.' so that they always get handled and the last one is the one that
    # is set.
    altId = ''
    flipAlt = flipMover.altId.strip()
    resAlt = ''
    for chain in self.model.chains():
      if flipMover.chain.strip() == chain.id.strip():
        for rg in chain.residue_groups():
          if int(flipMover.resId) == rg.resseq_as_int():
            for a in rg.atoms():
              if (a.element == 'N') and (len(a.name.strip()) > 1):
                if a.parent().altloc.lower() == flipAlt.lower():
                  resAlt = flipAlt
    if flipAlt == resAlt:
      altId = flipAlt
    if altId.strip() == '':
      altId = '.'
    return '{} {} {} {} {}{} {} {}'.format(flipMover.modelId+1, altId.lower(), flipMover.chain,
      flipMover.resName, flipMover.resId, flipMover.iCode, flipStateString, adjustedString)

  # ------------------------------------------------------------------------------

  def validate(self):
    # Set the default output file name if one has not been given.
    if self.params.output.filename is None:
      inName = self.data_manager.get_default_model_name()
      suffix = os.path.splitext(os.path.basename(inName))[1]
      if self.params.add_flip_movers:
        pad = 'FH'
      else:
        pad = 'H'
      base = os.path.splitext(os.path.basename(inName))[0] + pad
      self.params.output.filename = base + suffix
      print('Writing model output to', self.params.output.filename, file=self.logger)

    if os.environ.get('PHENIX_OVERWRITE_ALL', False):
      self.data_manager.set_overwrite(True)
    if not self.params.output.overwrite:
      if os.path.exists(self.params.output.filename):
        print('\n\tOutput filename exists. Use overwrite=True to continue.')

    self.data_manager.has_models(raise_sorry=True)
    if self.params.output.description_file_name is None:
      self.params.output.description_file_name=self.params.output.filename.replace('.pdb',
                                                                                   '.txt')
      self.params.output.description_file_name=self.params.output.description_file_name.replace('.cif',
                                                                                   '.txt')

    # Check the model ID to make sure they didn't set it to 0
    if self.params.model_id == 0:
      raise Sorry("Model ID must be >=1 if specified (None means all models)")

    # Turn on profiling if we've been asked to in the Phil parameters
    if self.params.profile:
      import cProfile
      self._pr = cProfile.Profile()
      self._pr.enable()

  # ------------------------------------------------------------------------------

  def run(self):

    # Set our bonded-neighbor depth
    self._bondedNeighborDepth = self.params.bonded_neighbor_depth

    # String describing the run that will be output to the specified file.
    outString = 'reduce2 v.{}, run {}\n'.format(version, datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    for a in sys.argv:
      outString += ' {}'.format(a)
    outString += '\n'

    make_sub_header('Loading Model', out=self.logger)

    # Get our model.
    self.model = self.data_manager.get_model()

    # Use model function to set crystal symmetry if necessary 2025-03-19 TT
    self.model.add_crystal_symmetry_if_necessary()

    # If we've been asked to only to a single model index from the file, strip the model down to
    # only that index.
    if self.params.model_id is not None:
      make_sub_header('Selecting Model ID ' + str(self.params.model_id), out=self.logger)

      # Select only the current submodel from the hierarchy
      submodel = self.model.deep_copy()
      _RemoveModelsExceptIndex(submodel, self.params.model_id)

      # Construct a hierarchy for the current submodel
      r = pdb.hierarchy.root()
      mdc = submodel.get_hierarchy().models()[0].detached_copy()
      r.append_model(mdc)

      # Make yet another model for the new hierarchy
      subset_model_manager = mmtbx.model.manager(
        model_input       = None,
        pdb_hierarchy     = r,
        stop_for_unknowns = False,
        crystal_symmetry  = submodel.crystal_symmetry(),
        restraint_objects = None,
        log               = None)

      self.model = subset_model_manager

    # Stores the initial coordinates for all of the atoms and the rest of the information
    # about the original model for use by Kinemages.
    initialModel = self.model.deep_copy()

    if self.params.approach == 'add':
      # Add Hydrogens to the model
      make_sub_header('Adding Hydrogens', out=self.logger)
      startAdd = time.time()
      self._AddHydrogens()
      doneAdd = time.time()

      # NOTE: We always optimize all models (leave modelIndex alone) because we've removed all
      # but the desired model ID structure from the model.
      make_sub_header('Optimizing', out=self.logger)
      startOpt = time.time()
      opt = Optimizers.Optimizer(self.params.probe, self.params.add_flip_movers,
        self.model, altID=self.params.alt_id,
        preferenceMagnitude=self.params.preference_magnitude,
        bondedNeighborDepth = self._bondedNeighborDepth,
        nonFlipPreference=self.params.non_flip_preference,
        skipBondFixup=self.params.skip_bond_fix_up,
        flipStates = self.params.set_flip_states,
        verbosity=self.params.verbosity,
        cliqueOutlineFileName=self.params.output.clique_outline_file_name,
        fillAtomDump = self.params.output.print_atom_info)
      doneOpt = time.time()
      outString += opt.getInfo()
      outString += 'Time to Add Hydrogen = {:.3f} sec'.format(doneAdd-startAdd)+'\n'
      outString += 'Time to Optimize = {:.3f} sec'.format(doneOpt-startOpt)+'\n'
      if self.params.output.print_atom_info:
        print('Atom information used during calculations:', file=self.logger)
        print(opt.getAtomDump(), file=self.logger)

    else: # Removing Hydrogens from the model rather than adding them.
      make_sub_header('Removing Hydrogens', out=self.logger)
      sel = self.model.selection("element H")
      for a in self.model.get_atoms():
        if sel[a.i_seq]:
          a.parent().remove_atom(a)

    # Re-process the model because we have removed some atoms that were previously
    # bonded.  Don't make restraints during the reprocessing.
    # We had to do this to keep from crashing on a call to pair_proxies when generating
    # mmCIF files, so we always do it for safety.
    self._ReinterpretModel(False)

    make_sub_header('Writing output', out=self.logger)

    # Skip writing the main output file and description output file if output.write_files is False.
    # This enables a program to harness Reduce2 and not have to deal with handling output files.
    if self.params.output.write_files:
      # Write the description output to the specified file.
      self.data_manager._write_text("description", outString,
        self.params.output.description_file_name)

      # Determine whether to write a PDB or CIF file and write the appropriate text output.
      suffix = os.path.splitext(self.params.output.filename)[1]
      if suffix.lower() == ".pdb":
        txt = self.model.model_as_pdb()
      else:
        txt = self.model.model_as_mmcif()
      self.data_manager._write_text("model", txt, self.params.output.filename)

      print('Wrote', self.params.output.filename,'and',
        self.params.output.description_file_name, file = self.logger)

    # If we've been asked to do a comparison with another program's output, do it.
    if self.params.comparison_file is not None:
      make_sub_header('Comparing with other model', out=self.logger)

      # Construct the file names we'll be using.
      compareOutName = self.params.output.filename + "_comparison.csv"

      # Find the list of all Movers in the model, which will be used to select
      # each in turn for evaluation.
      moverLocations = _FindMoversInOutputString(outString)

      # Make the first line in our table be the header line
      table = [ ["Mover",
                 "Score from Reduce2",
                 "Score from {}".format(self.params.comparison_file),
                 "Difference",
                 "Star if other is higher"] ]

      # Run Probe2 on each of the Movers for our current model and for
      # comparison_file and determine the summary score of the Mover against
      # the rest of the model in each case. Accumulate these into a table.
      for i, m in enumerate(moverLocations):
        print ('Computing scores for Mover',i,'of',len(moverLocations))

        #============================================================
        # Find the score for our output.

        # Make the Probe2 Phil parameters, then overwrite the ones that were
        # filled in with values that we want for our summaries.
        source = [ m ]
        extraArgs = [
          "approach=once",
          "output.format=raw",
          "output.contact_summary=True",
          "output.condensed=True",
          "output.count_dots=True"
          ]
        probeParser = self._MakeProbePhilParser(source, extraArgs)

        # Run Probe2
        p2 = probe2.Program(self.data_manager, probeParser.working_phil.extract(),
                            master_phil=probeParser.master_phil, logger=self.logger)
        p2.overrideModel(self.model)
        dots, output = p2.run()

        # Parse the output to find the scores for each of the two directions
        # and sum them up. There is one per line and the number ends with #.
        lines = output.strip().split('\n')
        values = []
        for line in lines:
          stripped_line = line.strip()
          if stripped_line:
            number = float(stripped_line.split('#')[0].strip())
            values.append(number)
        myScore = sum(values)

        print('My values for Mover', str(m), 'are', values, 'sum is', myScore, file=self.logger)

        #============================================================
        # Find the score for the comparison file.

        # Read the file using a new datamanager
        dm = DataManager()
        dm.process_model_file(self.params.comparison_file)
        #otherModel = dm.get_model(self.params.comparison_file)

        # Make the Probe2 Phil parameters, then overwrite the ones that were
        # filled in with values that we want for our summaries.
        extraArgs = [
          "approach=once",
          "output.format=raw",
          "output.contact_summary=True",
          "output.condensed=True",
          "output.count_dots=True"
          ]
        probeParser = self._MakeProbePhilParser(source, extraArgs)

        # Run Probe2
        p2 = probe2.Program(self.data_manager, probeParser.working_phil.extract(),
                            master_phil=probeParser.master_phil, logger=self.logger)
        p2.overrideModel(dm.get_model(self.params.comparison_file))
        dots, output = p2.run()

        # Parse the output to find the scores for each of the two directions
        # and sum them up. There is one per line and the number ends with #.
        lines = output.strip().split('\n')
        values = []
        for line in lines:
          stripped_line = line.strip()
          if stripped_line:
            number = float(stripped_line.split('#')[0].strip())
            values.append(number)
        otherScore = sum(values)

        print('Other values for Mover', str(m), 'are', values, 'sum is', otherScore, file=self.logger)

        #============================================================
        # Add the line to the table, indicating if the other is better.
        mark = ''
        if otherScore > myScore:
          mark = '*'
        table.append( [str(m), myScore, otherScore, myScore - otherScore, mark] )

      # Write the table to our output CSV file
      with open(compareOutName, 'w', newline='') as csvfile:
          writer = csv.writer(csvfile)
          writer.writerows(table)

    # If we've been asked to make Flipkins, then make each of them.
    if self.params.add_flip_movers and self.params.output.flipkin_directory is not None:
      make_sub_header('Producing flipkins', out=self.logger)

      # Find the base name of the two output files we will produce.
      inName = self.data_manager.get_default_model_name()
      suffix = os.path.splitext(os.path.basename(inName))[1]
      pad = 'FH'
      base = os.path.splitext(os.path.basename(inName))[0] + pad
      flipkinBase = self.params.output.flipkin_directory + "/" + base

      # Find the list of all Movers in the model, which will be used to segment
      # it into parts for the Flipkin.
      moverLocations = _FindMoversInOutputString(outString)

      # Find the list of all alternates in the model, ignoring empty ones.
      # Sort them in increasing alphabetical order.
      alts = Optimizers.AlternatesInModel(self.model)
      alts.discard('')
      alts.discard(' ')
      alts = sorted(list(alts))

      # ===========================================================================

      # Make list of Amides to lock in one flip orientation and then the other,
      # keeping track of which state they are in when Reduce was choosing.
      # We need a different list for the Amide Movers and the Histidine Movers
      # because we generate two different Flipkin files, one for each.
      amides = _FindFlipsInOutputString(outString, 'AmideFlip')

      if len(amides) > 0:
        make_sub_header('Generating Amide Flipkin', out=self.logger)

        # Find the viewpoint locations for each Mover we're going to
        # look at.
        views = self._GetViews(amides)

        # Interpret the model to fill in things we need for determining the neighbor list.
        self._ReinterpretModel()

        carts = flex.vec3_double()
        for a in self.model.get_atoms():
          carts.append(a.xyz)
        bondProxies = self.model.get_restraints_manager().geometry.get_all_bond_proxies(sites_cart = carts)[0]
        bondedNeighborLists = Helpers.getBondedNeighborLists(self.model.get_atoms(), bondProxies)

        # Get the other characteristics we need to know about each atom to do our work.
        inWater, inHet, inMainChain, inSideChain = self._GetAtomCharacteristics(bondedNeighborLists)

        # Write the base information in the Flipkin, not including the moving atoms in
        # the Movers that will be placed, or atoms bonded to the moving atoms.
        flipkinText = _AddFlipkinBase(amides, views, self.params.output.filename, base, self.model,
          alts, bondedNeighborLists, moverLocations, inSideChain, inWater, inHet)

        # Make two configurations, the one that Reduce picked and the one
        # that it did not.
        configurations = ['reduce', 'flipNQ']
        colors = ['sea', 'pink']

        # Run the optimization without fixup on the original orientation of all flippers and
        # again on the flipped orientation for each and combine the info from both of them
        # into the same Flipkin. Handle the re-initialization of atom coordinates before
        # each optimization, remembering the addition and deletion of atoms during placement
        # and optimization.
        for i, c in enumerate(configurations):
          # Restore the model to the state it had before we started adjusting it.
          self.model = initialModel.deep_copy()

          # Rerun hydrogen placement.
          self._AddHydrogens()

          # Run optimization, locking the specified Amides into each configuration.
          # Don't do fixup on the ones that are locked down.  Make sure that we can
          # avoid adding a comma on the first flip state that is added.
          flipStates = self.params.set_flip_states
          if flipStates is None:
            flipStates = ''
          if flipStates.strip() != '':
            flipStates += ','
          if i == 0:
            # For the first configuration, set all Amides to the orientation that Reduce decided
            # on, adding these to the list of locked-down flips.
            for ai, amide in enumerate(amides):
              flipStates += self._DescribeLockdown(amide, invertFlip=False, fixedUp=False)
              if ai < len(amides) - 1:
                flipStates += ','
          else:
            # For the second configuration, set all Amides to the orientation that Reduce did not
            # decide on, adding these to the list of locked-down flips.
            for ai, amide in enumerate(amides):
              flipStates += self._DescribeLockdown(amide, invertFlip=True, fixedUp=False)
              if ai < len(amides) - 1:
                flipStates += ','

          # Optimize the model and then reinterpret it so that we can get all of the information we
          # need for the resulting set of atoms (which may be fewer after Hydrogen removal).
          # NOTE: We always optimize all models (leave modelIndex alone) because we've removed all
          # but the desired model ID structure from the model.
          opt = Optimizers.Optimizer(self.params.probe, self.params.add_flip_movers,
            self.model, altID=self.params.alt_id,
            preferenceMagnitude=self.params.preference_magnitude,
            nonFlipPreference=self.params.non_flip_preference,
            skipBondFixup=self.params.skip_bond_fix_up,
            flipStates = flipStates,
            verbosity=3)
          print('Results of optimization:', file=self.logger)
          print(opt.getInfo(), file=self.logger)
          self._ReinterpretModel()

          # Get the other characteristics we need to know about each atom to do our work.
          # We must do this again here because the atoms change after Hydrogen addition.
          # We also need to re-generate the bonded-neighbor lists for the same reason.
          carts = flex.vec3_double()
          for a in self.model.get_atoms():
            carts.append(a.xyz)
          bondProxies = self.model.get_restraints_manager().geometry.get_all_bond_proxies(sites_cart = carts)[0]
          bondedNeighborLists = Helpers.getBondedNeighborLists(self.model.get_atoms(), bondProxies)
          inWater, inHet, inMainChain, inSideChain = self._GetAtomCharacteristics(bondedNeighborLists)

          # Write the updates to the Flipkin for this configuration, showing the
          # atoms for the amide in the Reduce configuration (i=0) or the other
          # configuration (i=1).
          flipkinText += _AddFlipkinMovers(amides, base, c, colors[i], self.model, alts,
            bondedNeighborLists, moverLocations, inSideChain, inWater, inHet)

          # Compute the dots in both 1->2 and 2->1 directions using probe2.
          # @todo Consider adding methods to probe2 that let us inject the various
          # computed quantities -- neighbor lists and extra atom info and such --
          # before calling the run() method so it does not have to recompute them.

          # Modify the parameters that are passed to include the ones for
          # the harnessed program, including the source and target atom selections.
          probeParser = self._MakeProbePhilParser(amides)

          # Run the program and append its Kinemage output to ours, deleting
          # the temporary file that it produced.
          p2 = probe2.Program(self.data_manager, probeParser.working_phil.extract(),
                              master_phil=probeParser.master_phil, logger=self.logger)

          p2.overrideModel(self.model)
          dots, kinString = p2.run()
          flipkinText += kinString

        # Write the accumulated Flipkin string to the output file.
        with open(flipkinBase+"-flipnq.kin", "w") as f:
          f.write(flipkinText)

      # ===========================================================================
      hists = _FindFlipsInOutputString(outString, 'HisFlip')

      if len(hists) > 0:
        make_sub_header('Generating Histidine Flipkin', out=self.logger)

        # Find the viewpoint locations for each Mover we're going to
        # look at.
        views = self._GetViews(hists)

        # Interpret the model to fill in things we need for determining the neighbor list.
        self._ReinterpretModel()

        carts = flex.vec3_double()
        for a in self.model.get_atoms():
          carts.append(a.xyz)
        bondProxies = self.model.get_restraints_manager().geometry.get_all_bond_proxies(sites_cart = carts)[0]
        bondedNeighborLists = Helpers.getBondedNeighborLists(self.model.get_atoms(), bondProxies)

        # Get the other characteristics we need to know about each atom to do our work.
        inWater, inHet, inMainChain, inSideChain = self._GetAtomCharacteristics(bondedNeighborLists)

        # Write the base information in the Flipkin, not including the moving atoms in
        # the Movers that will be placed, or atoms bonded to the moving atoms.
        flipkinText = _AddFlipkinBase(hists, views, self.params.output.filename, base, self.model,
          alts, bondedNeighborLists, moverLocations, inSideChain, inWater, inHet)

        # Make two configurations, the one that Reduce picked and the one
        # that it did not.
        configurations = ['reduce', 'flipH']
        colors = ['sea', 'pink']

        # Run the optimization without fixup on the original orientation of all flippers and
        # again on the flipped orientation for each and combine the info from both of them
        # into the same Flipkin. Handle the re-initialization of atom coordinates before
        # each optimization, remembering the addition and deletion of atoms during placement
        # and optimization.
        for i, c in enumerate(configurations):
          # Restore the model to the state it had before we started adjusting it.
          self.model = initialModel.deep_copy()

          # Rerun hydrogen placement.
          self._AddHydrogens()

          # Run optimization, locking the specified Histidines into each configuration.
          # Don't do fixup on the ones that are locked down.  Make sure that we can
          # avoid adding a comma on the first flip state that is added.
          flipStates = self.params.set_flip_states
          if flipStates is None:
            flipStates = ''
          if flipStates.strip() != '':
            flipStates += ','
          if i == 0:
            # For the first configuration, set all Histidines to the orientation that Reduce decided
            # on, adding these to the list of locked-down flips.
            for ai, hist in enumerate(hists):
              flipStates += self._DescribeLockdown(hist, invertFlip=False, fixedUp=False)
              if ai < len(hists) - 1:
                flipStates += ','
          else:
            # For the second configuration, set all HIstidines to the orientation that Reduce did not
            # decide on, adding these to the list of locked-down flips.
            for hi, hist in enumerate(hists):
              flipStates += self._DescribeLockdown(hist, invertFlip=True, fixedUp=False)
              if hi < len(hists) - 1:
                flipStates += ','

          # Optimize the model and then reinterpret it so that we can get all of the information we
          # need for the resulting set of atoms (which may be fewer after Hydrogen removal).
          # NOTE: We always optimize all models (leave modelIndex alone) because we've removed all
          # but the desired model ID structure from the model.
          opt = Optimizers.Optimizer(self.params.probe, self.params.add_flip_movers,
            self.model, altID=self.params.alt_id,
            preferenceMagnitude=self.params.preference_magnitude,
            nonFlipPreference=self.params.non_flip_preference,
            skipBondFixup=self.params.skip_bond_fix_up,
            flipStates = flipStates,
            verbosity=3)
          print('Results of optimization:', file=self.logger)
          print(opt.getInfo(), file=self.logger)
          self._ReinterpretModel()

          # Get the other characteristics we need to know about each atom to do our work.
          # We must do this again here because the atoms change after Hydrogen addition.
          # We also need to re-generate the bonded-neighbor lists for the same reason.
          carts = flex.vec3_double()
          for a in self.model.get_atoms():
            carts.append(a.xyz)
          bondProxies = self.model.get_restraints_manager().geometry.get_all_bond_proxies(sites_cart = carts)[0]
          bondedNeighborLists = Helpers.getBondedNeighborLists(self.model.get_atoms(), bondProxies)
          inWater, inHet, inMainChain, inSideChain = self._GetAtomCharacteristics(bondedNeighborLists)

          # Write the updates to the Flipkin for this configuration, showing the
          # atoms for the Histidines in the Reduce configuration (i=0) or the other
          # configuration (i=1).
          flipkinText += _AddFlipkinMovers(hists, base, c, colors[i], self.model, alts,
            bondedNeighborLists, moverLocations, inSideChain, inWater, inHet)

          # Compute the dots in both 1->2 and 2->1 directions using probe2.
          # @todo Consider adding methods to probe2 that let us inject the various
          # computed quantities -- neighbor lists and extra atom info and such --
          # before calling the run() method so it does not have to recompute them.

          # Modify the parameters that are passed to include the ones for
          # the harnessed program, including the source and target atom selections.
          probeParser = self._MakeProbePhilParser(hists)

          # Run the program and append its Kinemage output to ours, deleting
          # the temporary file that it produced.
          p2 = probe2.Program(self.data_manager, probeParser.working_phil.extract(),
                              master_phil=probeParser.master_phil, logger=self.logger)
          p2.overrideModel(self.model)
          dots, kinString = p2.run()
          flipkinText += kinString

        # Write the accumulated Flipkin string to the output file.
        with open(flipkinBase+"-fliphis.kin", "w") as f:
          f.write(flipkinText)

    # Report profiling info if we've been asked to in the Phil parameters
    if self.params.profile:
      print('Profile results:', file=self.logger)
      import pstats
      profile_params = {'sort_by': 'time', 'num_entries': 20}
      self._pr.disable()
      ps = pstats.Stats(self._pr).sort_stats(profile_params['sort_by'])
      ps.print_stats(profile_params['num_entries'])

# ------------------------------------------------------------------------------

  def get_results(self):
    return group_args(model = self.model)

# ------------------------------------------------------------------------------

  def Test(self):
    '''
      Run tests on the methods of the class.  Throw an assertion error if there is a problem with
      one of them and return normally if there is not a problem.
    '''

    #=====================================================================================
    # @todo Unit tests for other methods


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/ribbons.py
from __future__ import absolute_import, division, print_function
from libtbx.program_template import ProgramTemplate
import iotbx.pdb
import mmtbx.secondary_structure
from pathlib import Path
import numpy as np
from mmtbx.kinemage.validation import get_chain_color
from mmtbx.kinemage.ribbons import find_contiguous_protein_residues, find_contiguous_nucleic_acid_residues
from mmtbx.kinemage.ribbons import make_protein_guidepoints, make_nucleic_acid_guidepoints
from mmtbx.kinemage.ribbons import untwist_ribbon, swap_edge_and_face, _FindNamedAtomInResidue, _IsNucleicAcidResidue
from mmtbx.kinemage.ribbons import chain_has_DNA, chain_has_RNA
from mmtbx.kinemage.nrubs import Triple, NRUBS

version = "1.2.1"

master_phil_str = '''
do_protein = True
  .type = bool
  .short_caption = Construct protein ribbons
  .help = Construct ribbons for the protein sections of the model
do_nucleic_acid = True
  .type = bool
  .short_caption = Construct nucleic acid ribbons
  .help = Construct ribbons for the nucleic acid sections of the model
untwist_ribbons = True
  .type = bool
  .short_caption = Untwist ribbons
  .help = Remove excess twist from ribbons by making the neighboring dot products positive
DNA_style = False
  .type = bool
  .short_caption = DNA style ribbons
  .help = Use the DNA style ribbons instead of the default RNA style ribbons (rotates them by 90 degrees)
color_by = *rainbow secondary_structure solid
  .type = choice(multi=False)
  .short_caption = How to color the ribbons
  .help = How to color the ribbons. Rainbow adjusts the color smoothly along each chain. Solid make each chain a single color. Secondary structure colors every 7th chain by the secondary structure and makes the others solid colors.
do_plain_coils = False
  .type = bool
  .short_caption = Do plain coils
  .help = Do plain coils (no halo) even for the helix and sheet parts of the protein
coil_width = 1.0
  .type = float
  .short_caption = Coil width
  .help = Width of the coil part of the ribbon
selection = (altloc ' ' or altloc '' or altloc a)
  .type = atom_selection
  .short_caption = Atom selection
  .help = Atom selection description
nucleic_acid_as_helix = True
  .type = bool
  .short_caption = Draw nucleic acids as helix
  .help = If true, draw nucleic acids as helix rather than treating as coil because there are not secondary structure records for them
'''

# ------------------------------------------------------------------------------

class Program(ProgramTemplate):
  description = '''
mmtbx.ribbons version {}: Given PDB file produce Kinemage file with ribbons representation.

This program produces a kinemage file with ribbons representation of the input file using the
same algorithm as the Richardson lab's MolProbity server.  The code is based on the Java code
within the javadev repository.

How to run:
  mmtbx.ribbons model.pdb

Output:
  If output.filename is not specified, it will write
  to a file with the same name as the input model file name but with the
  extension replaced with with '.kin'.

'''.format(version)
  datatypes = ['model', 'phil']
  master_phil_str = master_phil_str

# ------------------------------------------------------------------------------

  def validate(self):
    self.data_manager.has_models(raise_sorry=True)

    if self.params.output.filename is None:
      # If the output file name is not specified, use the same root as the
      # input file and replace the suffix with .kin.
      suffix = '.kin'
      inName = self.data_manager.get_default_model_name()
      p = Path(inName)
      self.params.output.filename = str(p.with_suffix(suffix))
      print('Setting output.filename Phil parameter to',self.params.output.filename, file=self.logger)

# ------------------------------------------------------------------------------

  def splineInterplate(self, pts, nIntervals):
    # Returns a list of interpolated points between the points using a spline interpolation.
    # Based on https://docs.scipy.org/doc/scipy/tutorial/interpolate/1D.html#parametric-spline-curves
    # @param pts: The guidepoints to interpolate between (a list of 3D points with at least 6 points in it).
    # The first and last points are duplicates to form knots, so are not interpolated between.
    # @param nIntervals: The number of intervals to interpolate between each pair of guidepoints, skipping the first and last.
    # @return: The list of interpolated points

    nrubs = NRUBS()
    points = []
    for pt in pts:
      points.append( Triple(pt[0], pt[1], pt[2]) )
    res = nrubs.spline(points, nIntervals)
    ret = []
    for r in res:
      ret.append( np.array((r.x, r.y, r.z)) )
    return ret

    # Adjust the points to match what is expected by the Java code.
    # The Java code expects the first and last points to be duplicates of the second and second-to-last points.
    points = pts[1:-1]

# ------------------------------------------------------------------------------

  # The original code constructed a NONE crayon for the fancy print, which did not add color to
  # the output, re-using the colors specified by model or chain.  It sometimes also specified
  # the RAINBOW crayon, which overwrites the colors with a rainbow color scheme across each chain.
  # For the edges, it specified a constant crayon whose string value is deadblack
  # and it adds "U " to make it un-pickable.
  # We pull that logic into here by implementing the forRibbon() and shouldPrint() and
  # getKinString() methods in our own class.
  class Crayon:
    def __init__(self, doRainBow, color=None):
      self._doRainBow = doRainBow
      self._color = color
      self._rainbowColors = [ "blue", "sky", "cyan", "sea", "green", "lime", "yellow" ,"gold" ,"orange" ,"red" ]

    # Rainbow color map changes the color once across the rainbow for each chain (the chain goes from
    # blue to red).
    # The non-rainbow, constant-colored map does not change.
    def forRibbon(self, startGuide):
      if self._doRainBow:
        res = startGuide.prevRes
        chain = res.parent()
        firstChainResID = chain.residue_groups()[0].resseq
        lastChainResID = chain.residue_groups()[-1].resseq
        normRes = (int(res.resseq) - int(firstChainResID)) / (int(lastChainResID) - int(firstChainResID))
        scaledIndex = int(normRes * len(self._rainbowColors))
        if scaledIndex == len(self._rainbowColors):
          scaledIndex -= 1
        self._color = self._rainbowColors[scaledIndex]

    def getKinString(self):
      if self._color is None:
        return ""
      return self._color

    # All of our elements should be visible in the output.
    def shouldPrint(self):
      return True

  # Commented out the fields and did not include methods that we don't need for our implementation
  # Switched getType() to making type public.
  # Its fields should be based on the PDB secondary structure records.
  class Range:
    def __init__(self, pType = 'COIL', pChainId = '', pInit = 0, pEnd = 0, pSense = 0, pStrand = 1, pSheet = ' ', pFlipped = False):
      # self._rangeIndex = 0
      self.type = pType
      self._chainId = pChainId
      self.initSeqNum = pInit
      self.endSeqNum = pEnd
      #self._initICode = ' '
      #self._endICode = ' '
      self.sense = pSense    # 0 if first strand, 1 if parallel, -1 if anti-parallel
      self.strand = pStrand   # Starts at 1 for each strand within a sheet and increases by 1
      self.sheetID = pSheet
      self.flipped = pFlipped  # Used by printing code to make the tops within a set of ribbons all point the same way
      self.previous = None
      self.next = None
      self.duplicateOf = None

    def __str__(self):
      return 'Range: type={}, init={}, end={}, sense={}, strand={}, sheet={}, flipped={}'.format(
        self.type, self.initSeqNum, self.endSeqNum, self.sense, self.strand, self.sheetID, self.flipped)

  def ConsolidateSheets(self):
    uniqueStrands = {}

    # For each ribbon, record its predecessor in sheet, and check for duplicates
    for rng in self.secondaryStructure.values():
      if not rng.type == 'SHEET':
        continue

      key = str(int(rng.initSeqNum)) + rng._chainId
      if not key in uniqueStrands:
        uniqueStrands[key] = rng
      else:
        rng.duplicateOf = uniqueStrands[key]

      # Now find this strand's previous and next strand.
      for rng2 in self.secondaryStructure.values():
        if not rng2.type == 'SHEET':
          continue
        if rng2.sheetID == rng.sheetID and rng2.strand == rng.strand-1:
          rng.previous = rng2
          rng2.next = rng

      # Now go through and reassign previous/next fields in duplicates
      for rng in self.secondaryStructure.values():
        if not rng.type == 'SHEET':
          continue
        if rng.duplicateOf is None and rng.next is not None and rng.next.duplicateOf is not None:
          rng.next.duplicateOf.previous = rng
        if rng.duplicateOf is None and rng.previous is not None and rng.previous.duplicateOf is not None:
          rng.previous = rng.previous.duplicateOf

  class RibbonElement:
    def __init__(self, other=None, setRange=None):
      self.start = 0
      self.end = 0
      self.type = 'COIL'
      self.range = setRange
      if other is not None:
        self.like(other)
      if self.range is not None:
        if self.range.type is None or self.range.type == 'TURN':
          self.type = 'COIL'
        else:
          self.type = self.range.type

    def sameSSE(self, that):
      return self.type == that.type and self.range == that.range

    def like(self, that):
      self.start = that.start
      self.end = that.end
      self.type = that.type
      self.range = that.range

    def __lt__(self, that):
      a = 0
      b = 0
      if self.range is not None:
        a = self.range.strand
      if that.range is not None:
        b = that.range.strand
      return a < b

  # If the current point ID is the same as the previous point ID, we return the shorthand double-quote (") to
  # indicate this.  To force a new point ID, set self._lastPointID to "" before calling this function.
  def getPointID(self, point, start, end, interval, nIntervals):
    if self._lastPointID is None:
      self._lastPointID = ""

    res = start.nextRes
    if self.params.DNA_style and interval <= nIntervals // 2:
      res = start.prevRes   # == first res, for RNA/DNA only

    buf = res.atom_groups()[0].resname.strip() + " " + res.parent().id.strip() + " " + res.resseq.strip() + res.icode
    res = buf.lower().strip()

    if res == self._lastPointID:
      res = '"'
    else:
      self._lastPointID = res

    return res

  def printFancy(self, guides, splines, i, lineBreak = False):
    # Prints a fancy ribbon element with the given guidepoints and splines.
    # @param guides: The guidepoints for the ribbon
    # @param splines: The interpolated points for the ribbon
    # @param i: The index of the guidepoint to print

    ret = ""
    # Not self.nIntervals, we want a local variable here
    nIntervals = (len(splines) - 1) // (len(guides) - 3)
    interval = i % nIntervals
    startGuide = (i // nIntervals) + 1
    ret += "{"
    ret += self.getPointID(splines[i], guides[startGuide], guides[startGuide + 1], interval, nIntervals)
    ret += "}"
    if lineBreak:
      ret += "P "
    self.crayon.forRibbon(guides[startGuide])
    ret += self.crayon.getKinString()
    ret += " "
    ret += "{:.3f} {:.3f} {:.3f}\n".format(splines[i][0], splines[i][1], splines[i][2])

    return ret

  def printFancyRibbon(self, guides, widthAlpha, widthBeta, listAlpha, listBeta, listCoil, listCoilOutline, doRainbow):
    # Constructs a kinemage string for a ribbon representation of a protein or nucleic acid chain.
    # Makes a triangulated ribbon with arrowheads, etc.
    # @param guides: The guidepoints for the ribbon
    # @param widthAlpha: The width of the alpha helix part of the ribbon
    # @param widthBeta: The width of the beta sheet part of the ribbon
    # @param listAlpha: The kinemage string describing the alpha helix part of the ribbon
    # @param listBeta: The kinemage string describing the beta sheet part of the ribbon
    # @param listCoil: The kinemage string describing the coil part of the ribbon
    # @param listCoilOutline: The kinemage string describing the outline of the coil part of the ribbon
    # @param doRainbow: Whether or not to color the ribbon by rainbow
    # If false (the default), the protein style will be used instead.
    # @return: The kinemage string for the ribbon representation

    ret = ""

    # Initialize local references
    widthCoil = self.params.coil_width
    secStruct = self.secondaryStructure

    # Seven strands of guidpoints: coil, +/-alpha, +/-beta, +/-beta arrowheads.
    # Each strand is a list of 3D points and there is a strand for each offset from the center spline.
    halfWidths = [0.0, -widthAlpha/2, widthAlpha/2, -widthBeta/2, widthBeta/2, -widthBeta, widthBeta]
    # Make a different empty list for each strand
    strands = []
    for _ in range(len(halfWidths)):
      strands.append([])
    for g in guides:
      for i in range(len(halfWidths)):
        strands[i].append(g.pos + g.dvec * halfWidths[i])

    # Seven strands of interpolated points
    splinepts = []
    for i in range(len(strands)):
      splinepts.append(self.splineInterplate(strands[i], self.nIntervals))

    # Discovery of ribbon elements: ribbons, ropes, and arrows.
    # We skip the regions associated with the first and last points, which are present to cause the
    # curve to pass through those points (like knots) but are not interpolated between.
    # We do that by looping through fewer entries and by adding 1 to the index.
    ribbonElements = []
    ribElement = self.RibbonElement()
    prevRibElt = self.RibbonElement()
    ribbonElements.append(ribElement)
    # Element that is reused and copied when creating a new list entry
    ribElement.type = None
    for i in range(len(guides) - 1 - 2):
      g1 = guides[i + 1]
      g2 = guides[i + 2]

      # The Java code reports that we're not really using ribbon elements, just reusing the
      # class for convenience.  So not all of the member variables may be filled in.
      currSS = self.RibbonElement(setRange=secStruct[int(g1.nextRes.resseq)])
      nextSS = self.RibbonElement(setRange=secStruct[int(g2.nextRes.resseq)])

      # Otherwise, we get one unit of coil before alpha or beta at start
      if ribElement.type is None:
        ribElement.like(currSS)

      if i == 0 or not ribElement.sameSSE(currSS): # Helix / sheet starting
        if currSS.type == 'HELIX' or currSS.type == 'SHEET':
          ribElement.end = self.nIntervals*i + 1
          ribElement = self.RibbonElement(currSS)
          ribbonElements.append(ribElement)
          # Every helix or sheet starts with a coil; see below
          ribElement.start = self.nIntervals*i + 1
      if not ribElement.sameSSE(nextSS): # Helix / sheet ending
        if currSS.type == 'HELIX' or currSS.type == 'SHEET':
          end = self.nIntervals*i + 0
          if currSS.type == 'SHEET':
            end += self.nIntervals - 1
          ribElement.end = end
          ribElement = self.RibbonElement()
          ribbonElements.append(ribElement)
          # Every helix or sheet flows into coil
          ribElement.type = 'COIL'
          ribElement.start = end
    ribElement.end = len(splinepts[0]) - 1

    # "Crayons" to use for coloring the ribbon, juggling them around to keep the edges black.
    normalCrayon = self.Crayon(doRainbow)
    edgeCrayon = self.Crayon(False)  # Default no color; the deadblack will be set on the vectorlist

    # Sort the ribbon elements by strand number
    ribbonElements.sort()

    # Create a list of just sheets (Java STRANDs) for searching through
    strands = [r for r in ribbonElements if r.type == 'SHEET']

    for ribElement in ribbonElements:
      stGuide = (ribElement.start // self.nIntervals) + 2
      endGuide = (ribElement.end // self.nIntervals) - 1

      if ribElement.type == 'HELIX':

        k = (ribElement.start + ribElement.end) // 2
        pt = splinepts[2][k]
        v1 = splinepts[1][k] - pt
        v2 = splinepts[1][k+1] - pt
        cross = np.cross(v1, v2)
        dot = np.dot( np.linalg.norm(cross), np.linalg.norm(np.array(guides[k//self.nIntervals+1].cvec)))

        self.crayon = normalCrayon
        ret += "@ribbonlist {fancy helix} " + listAlpha + "\n"
        self._lastPointID = ""

        for i in range(ribElement.start, ribElement.end):
          if dot > 0:
            # Flip the normals (for sidedness) by switching the order of these two lines.
            ret += self.printFancy(guides, splinepts[2], i)
            ret += self.printFancy(guides, splinepts[1], i)
          else:
            ret += self.printFancy(guides, splinepts[1], i)
            ret += self.printFancy(guides, splinepts[2], i)
        ret += self.printFancy(guides, splinepts[0], ribElement.end)  # Angled tip at end of helix
        self.crayon = edgeCrayon
        ret += "@vectorlist {fancy helix edges} width=1 " + listAlpha + " color= deadblack\n"
        self._lastPointID = ""
        # Black edge, left side
        ret += self.printFancy(guides, splinepts[0], ribElement.start, True)
        for i in range(ribElement.start, ribElement.end):
          ret += self.printFancy(guides, splinepts[1], i)
        ret += self.printFancy(guides, splinepts[0], ribElement.end)
        # Black edge, right side
        ret += self.printFancy(guides, splinepts[0], ribElement.start, True)
        for i in range(ribElement.start, ribElement.end):
          ret += self.printFancy(guides, splinepts[2], i)
        ret += self.printFancy(guides, splinepts[0], ribElement.end)

      elif ribElement.type == 'SHEET':

        dot = 0.0     # Used to determine sidedness

        # Don't do for the first strand in the sheet
        if ribElement.range.strand != 1:
          # Look for previous strand
          for i in range(len(strands)):
            curElt = strands[i]
            if curElt.range == ribElement.range.previous:
              prevRibElt = curElt
              break

          prevRange = prevRibElt.range
          if prevRange is None:
            prevRibElt = ribElement

          # Detrmine sidedness using splinepts and normals
          prevStGuide = (prevRibElt.start // self.nIntervals) + 2
          prevEndGuide = (prevRibElt.end // self.nIntervals) + 1
          curClosest = stGuide      # Find the pair of guidepoints closest to each other
          prevClosest = prevStGuide # (one on each strand) to perform the test
          closeDist = 1e10
          for i in range(stGuide, endGuide+2 + 1):
            for j in range(prevStGuide, endGuide+2 + 1):
              # Look for closest pair of H-bonding partners
              try:
                O = _FindNamedAtomInResidue(guides[i].prevRes, "O")
                N = _FindNamedAtomInResidue(guides[i].prevRes, "N")
                dist = np.linalg.norm(O.pos - N.pos)
                if dist < closeDist:
                  closeDist = dist
                  curClosest = i
                  prevClosest = j
              except Exception:
                pass
          kCur = min(self.nIntervals*(curClosest-1), len(splinepts[4]))
          kPrev = min(self.nIntervals*(prevClosest-1), len(splinepts[4]))
          ptCur = splinepts[4][kCur]
          v1Cur = splinepts[3][kCur] - ptCur
          # VBC Hack to get 1jj2 at least generating ribbons kins.  Doesn't seem to
          # correctly generate beta sides though.  Error is kCur+1 generates an ArrayIndexOutOfBoundsException in splinepts[3]
          if kCur+1 < len(splinepts[3]):
            v2Cur = splinepts[3][kCur+1] - ptCur
            crossCur = np.cross(v1Cur, v2Cur)
            ptPrev = splinepts[4][kPrev]
            v1Prev = splinepts[3][kPrev] - ptPrev
            v2Prev = splinepts[3][kPrev+1] - ptPrev
            crossPrev = np.cross(v1Prev, v2Prev)
            dot = np.dot( crossCur, crossPrev)

        self.crayon = normalCrayon
        ret += "@ribbonlist {fancy sheet} " + listBeta + "\n"
        self._lastPointID = ""
        for i in range(ribElement.start, ribElement.end - 1):
          # If strands are not "facing" the same way,
          # flip the normals (for sidedness) by switching the order of these two lines, (ARK Spring2010)
          if (dot < 0 and not prevRibElt.range.flipped) or (dot > 0 and prevRibElt.range.flipped):
            ret += self.printFancy(guides, splinepts[4], i)
            ret += self.printFancy(guides, splinepts[3], i)
            ribElement.range.flipped = True
          else:
            ret += self.printFancy(guides, splinepts[3], i)
            ret += self.printFancy(guides, splinepts[4], i)

        # Ending *exactly* like this is critical to avoiding a break
        # between the arrow body and arrow head!
        if (dot < 0 and not prevRibElt.range.flipped) or (dot > 0 and prevRibElt.range.flipped):
          ret += self.printFancy(guides, splinepts[6], ribElement.end - 2)
          ret += self.printFancy(guides, splinepts[5], ribElement.end - 2)
          ret += self.printFancy(guides, splinepts[0], ribElement.end)
        else:
          ret += self.printFancy(guides, splinepts[5], ribElement.end - 2)
          ret += self.printFancy(guides, splinepts[6], ribElement.end - 2)
          ret += self.printFancy(guides, splinepts[0], ribElement.end)
        # Borders
        self.crayon = edgeCrayon
        ret += "@vectorlist {fancy sheet edges} width=1 " + listBeta + " color= deadblack\n"
        self._lastPointID = ""
        # Black edge, left side
        ret += self.printFancy(guides, splinepts[0], ribElement.start, True)
        for i in range(ribElement.start, ribElement.end - 1):
          ret += self.printFancy(guides, splinepts[3], i)
        ret += self.printFancy(guides, splinepts[5], ribElement.end - 2)
        ret += self.printFancy(guides, splinepts[0], ribElement.end)
        # Black edge, right side
        ret += self.printFancy(guides, splinepts[0], ribElement.start, True)
        for i in range(ribElement.start, ribElement.end - 1):
          ret += self.printFancy(guides, splinepts[4], i)
        ret += self.printFancy(guides, splinepts[6], ribElement.end - 2)
        ret += self.printFancy(guides, splinepts[0], ribElement.end)

      else: # Coil

        # for black outlines on coils
        if listCoilOutline is not None:
          self.crayon = normalCrayon
          ret += "@vectorlist {fancy coil edges} " + listCoilOutline + "\n"
          self._lastPointID = ""
          for i in range(ribElement.start, ribElement.end+1):
            ret += self.printFancy(guides, splinepts[0], i)

        self.crayon = normalCrayon
        ret += "@vectorlist {fancy coil} " + listCoil + "\n"
        self._lastPointID = ""
        for i in range(ribElement.start, ribElement.end+1):
          ret += self.printFancy(guides, splinepts[0], i)

      # Reset the crayon for the next pass
      self.crayon = normalCrayon

    return ret

# ------------------------------------------------------------------------------

  def run(self):
    self.model = self.data_manager.get_model()
    self.nIntervals = 4

    # Apply a selection to the model if one is provided.  The default is to select atoms in the
    # first alternate location.
    hierarchy = self.model.get_hierarchy()
    selection_string = self.params.selection
    if selection_string is None:
      selection_string = "(altloc ' ' or altloc '' or altloc a)"
    selection = hierarchy.atom_selection_cache().selection(selection_string)
    hierarchy = hierarchy.select(selection)

    # See if the model file has secondary structure records.
    # This should return None if there are no secondary structure records in the model.
    sec_str_from_pdb_file = self.model.get_ss_annotation()

    # Analyze the secondary structure and make a dictionary that maps from residue sequence number to secondary structure type
    # by filling in 'COIL' as a default value for each and then parsing all of the secondary structure records in the
    # model and filling in the relevant values for them.
    print('Finding secondary structure:', file=self.logger)
    params = mmtbx.secondary_structure.manager.get_default_ss_params()
    params.secondary_structure.protein.search_method="ksdssp"
    params = params.secondary_structure
    ss_manager = mmtbx.secondary_structure.manager(hierarchy,
                                                   params=params,
                                                   sec_str_from_pdb_file=sec_str_from_pdb_file,
                                                   log=self.logger)
    self.secondaryStructure = {}
    for model in hierarchy.models():
      for chain in model.chains():
        for residue_group in chain.residue_groups():
          self.secondaryStructure[residue_group.resseq_as_int()] = self.Range()
    for line in ss_manager.records_for_pdb_file().splitlines():
      r = self.Range(line[0:5].strip())
      if r.type == 'HELIX':
        r.sheetID = line[11:14].strip()
        r._chainId = line[19:21].strip()
        r.initSeqNum = int(line[22:26].strip())
        r.endSeqNum = int(line[33:38].strip())
      elif r.type == 'SHEET':  # Java code marks this internally as STRAND but we leave it as SHEET
        r.sheetID = line[11:14].strip()
        r._chainId = line[21:22].strip()
        r.initSeqNum = int(line[23:28].strip())
        r.endSeqNum = int(line[33:38].strip())
        r.sense = int(line[38:40].strip())
        r.strand = int(line[7:10].strip())
      elif r.type == 'TURN':
        # In fact, we turn turns int coils, so we really don't care.
        # r.sheetID = line[11:14].strip()
        r._chainId = line[20:21].strip()
        r.initSeqNum = int(line[22:26].strip())
        r.endSeqNum = int(line[33:37].strip())
      for i in range(r.initSeqNum,r.endSeqNum+1):
        self.secondaryStructure[i] = r

    self.ConsolidateSheets()

    # If we are treating nucleic acids as helices, change the record of each nucleic acid residue to be a helix.
    if self.params.nucleic_acid_as_helix:
      r = self.Range('HELIX')
      for res in hierarchy.residue_groups():
        if _IsNucleicAcidResidue(res.unique_resnames()[0]):
          self.secondaryStructure[int(res.resseq)] = r

    # The name of the structure, which is the root of the input file name (no path, no extension)
    self.idCode = self.data_manager.get_default_model_name().split('.')[0]
    if self.idCode is None or self.idCode == "":
      self.idCode = "macromol"

    # Create the output string that will be written to the output file.  It will be filled in during the run.
    outString = ""

    # Fill in the header information
    outString += "@kinemage 1\n"
    outString += "@onewidth\n"

    # Handle multiple models
    groupByModel = hierarchy.models_size() > 1
    for model in hierarchy.models():
      modelID = model.id
      if modelID == "":
        modelID = "_"
      print('Processing model', modelID, 'with', len(model.chains()), 'chains', file=self.logger)
      if groupByModel:
        outString += "@group {{{} {}}} animate dominant master= {{all models}}\n".format(self.idCode, str(modelID).strip())

      # Make a list of all the chain names in the model with only one entry per name.
      # Use this to make a dictionary to look up the color that is used for each chain name.
      # This ensures that the chains are colored the same no matter their order or repeat in the file.
      chainNames = set()
      for chain in model.chains():
        chainNames.add(chain.id)
      chainNames = sorted(list(chainNames))
      chainCount = 0
      chainColors = {}
      for name in chainNames:
        # Backbone color by model ID if we have multiple models, or by chain ID if we have multiple chains in a model.
        if groupByModel:
          c = get_chain_color(modelID)
        else:
          c = get_chain_color(chainCount)
        chainColors[name] = c
        chainCount += 1

      # Determine whether DNA, RNA, or both are present in the model
      hasDNA = False
      hasRNA = False
      for chain in model.chains():
        if chain_has_DNA(chain):
          hasDNA = True
        if chain_has_RNA(chain):
          hasRNA = True

      # Cycle over all chains in the model and make a group or subgroup for each chain
      # depending on whether we are grouping by model or not.
      for chain in model.chains():
        print('Processing chain',chain.id, file=self.logger)

        if self.params.do_protein:
          # Find the contiguous protein residues by CA distance
          contiguous_residue_lists = find_contiguous_protein_residues(chain)
          print('Found {} contiguous protein residue lists'.format(len(contiguous_residue_lists)), file=self.logger)

          if len(contiguous_residue_lists) > 0:
            if groupByModel:
              outString += "@subgroup {{chain{}}} dominant master= {{chain {}}}\n".format(chain.id, chain.id)
            else:
              outString += "@group {{{} {}}} dominant\n".format(self.idCode, chain.id)
            outString += "@subgroup {ribbon}\n"

            # Set the basic colors for the parts of the ribbon, which may be overridden by rainbow coloring on a
            # per-residue basis.
            bbColor = chainColors[chain.id]
            if bbColor == "white" and not (self.params.color_by == "solid"):
              # Distinguish between the different types of secondary structure for the first chain (out of every 7th)
              # if we're not coloring by solid colors
              outString += "@colorset {{alph{}}} red\n".format(chain.id)
              outString += "@colorset {{beta{}}} lime\n".format(chain.id)
              outString += "@colorset {{coil{}}} white\n".format(chain.id)
            else:
              # Do all secondary structure in the same color for all but the first chain (out of every 7th) to clean up the display
              outString += "@colorset {{alph{}}} {}\n".format(chain.id, bbColor)
              outString += "@colorset {{beta{}}} {}\n".format(chain.id, bbColor)
              outString += "@colorset {{coil{}}} {}\n".format(chain.id, bbColor)

            for contig in contiguous_residue_lists:
              guidepoints = make_protein_guidepoints(contig)
              print(' Made {} protein guidepoints for {} residues'.format(len(guidepoints),len(contig)), file=self.logger)
              if self.params.untwist_ribbons:
                print('  Untwisted ribbon', file=self.logger)
                untwist_ribbon(guidepoints)
              # There is always secondary structure looked up for protein residues, so we skip the case from the Java code
              # where it can be missing.
              if self.params.do_plain_coils:
                outString += self.printFancyRibbon(guidepoints, 2, 2.2,
                      "color= {alph"+chain.id+"} master= {protein} master= {ribbon} master= {alpha}",
                      "color= {beta"+chain.id+"} master= {protein} master= {ribbon} master= {beta}",
                      "width= 4 color= {coil"+chain.id+"} master= {protein} master= {ribbon} master= {coil}",
                      self.params.color_by == "rainbow");
              else:
                outString += self.printFancyRibbon(guidepoints, 2, 2.2,
                      "color= {alph"+chain.id+"} master= {protein} master= {ribbon} master= {alpha}",
                      "color= {beta"+chain.id+"} master= {protein} master= {ribbon} master= {beta}",
                      "width= 4 fore color= {coil"+chain.id+"} master= {protein} master= {ribbon} master= {coil}",
                      "width= 6 rear color= deadblack master= {protein} master= {ribbon} master= {coil}",
                      self.params.color_by == "rainbow")

        if self.params.do_nucleic_acid:
          # Find the contiguous nucleic acid residues by CA distance
          contiguous_residue_lists = find_contiguous_nucleic_acid_residues(chain)
          print('Found {} contiguous nucleic acid residue lists'.format(len(contiguous_residue_lists)), file=self.logger)

          if len(contiguous_residue_lists) > 0:
            if groupByModel:
              outString += "@subgroup {{chain{}}} dominant master= {chain {}}}\n".format(chain.id, chain.id)
            else:
              outString += "@group {{{} {}}} dominant\n".format(self.idCode, chain.id)
            outString += "@subgroup {ribbon}\n"

            bbColor = chainColors[chain.id]
            if bbColor == "white":
              outString += "@colorset {{nucl{}}} lime\n".format(chain.id)
              outString += "@colorset {{ncoi{}}} white\n".format(chain.id)
            else:
              outString += "@colorset {{nucl{}}} {}\n".format(chain.id, bbColor)
              outString += "@colorset {{ncoi{}}} {}\n".format(chain.id, bbColor)

            for contig in contiguous_residue_lists:
              guidepoints = make_nucleic_acid_guidepoints(contig)
              print(' Made {} NA guidepoints for {} residues'.format(len(guidepoints),len(contig)), file=self.logger)
              if self.params.untwist_ribbons:
                print('  Untwisted ribbon', file=self.logger)
                untwist_ribbon(guidepoints)
              # If the model has both DNA and RNA, and if this chain is DNA, swap the edge and face so that
              # we can distinguish between them in the same model.  Also, if the DNA_style parameter has been
              # set, then always make this style.
              if self.params.DNA_style or (hasDNA and hasRNA and chain_has_DNA(chain)):
                print('  Swapped edge and face (DNA style)', file=self.logger)
                swap_edge_and_face(guidepoints)
              else:
                print('  Using RNA style ribbons', file=self.logger)

              outString += self.printFancyRibbon(guidepoints, 3.0, 3.0,
                    "color= {nucl"+chain.id+"} master= {nucleic acid} master= {ribbon} master= {RNA helix?}",
                    "color= {nucl"+chain.id+"} master= {nucleic acid} master= {ribbon} master= {A-form}",
                    "width= 4 color= {ncoi"+chain.id+"} master= {nucleic acid} master= {ribbon} master= {coil}",
                    None,
                    self.params.color_by == "rainbow")

    # Write the output to the specified file.
    self.data_manager._write_text("Text", outString, self.params.output.filename)


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/rna_validate.py
from __future__ import absolute_import, division, print_function

import os
from mmtbx.model import manager
from mmtbx.validation.rna_validate import rna_validation
from libtbx.program_template import ProgramTemplate
from libtbx.utils import null_out
from datetime import datetime

class Program(ProgramTemplate):
  prog = os.getenv('LIBTBX_DISPATCHER_NAME')
  description="""\
%(prog)s file.pdb [params.eff] [options ...]

Options:

  model=input_file        input PDB file
  outliers_only=False   only print outliers
  json=False            Outputs results as JSON compatible dictionary
  verbose=False         verbose text output

Example:

  %(prog)s model=1ubq.pdb outliers_only=True
""" % locals()

  master_phil_str = """
  include scope mmtbx.validation.molprobity_cmdline_phil_str
  show_errors = False
    .type = bool
    .help = '''Print out errors'''
  json = False
    .type = bool
    .help = "Prints results as JSON format dictionary"
  use_parent = False
    .type = bool
  rna_sugar_pucker_analysis
    .short_caption = RNA sugar pucker analysis
    .style = box noauto auto_align menu_item parent_submenu:advanced
  {
    include scope mmtbx.monomer_library.rna_sugar_pucker_analysis.master_phil
  }
  """
  datatypes = ['model','phil']
  data_manager_options = ['model_skip_expand_with_mtrix']
  known_article_ids = ['molprobity']

  def validate(self):
    self.data_manager.has_models(raise_sorry=True)

  def run(self):
    model = self.data_manager.get_model()
    model.set_stop_for_unknowns(False)
    hierarchy = model.get_hierarchy()
    self.info_json = {"model_name":self.data_manager.get_default_model_name(),
                      "time_analyzed": str(datetime.now())}
    p = manager.get_default_pdb_interpretation_params()
    ##print(dir(p.pdb_interpretation))
    p.pdb_interpretation.allow_polymer_cross_special_position=True
    p.pdb_interpretation.flip_symmetric_amino_acids=False
    p.pdb_interpretation.clash_guard.nonbonded_distance_threshold = None
    model.set_log(log = null_out())
    model.process(make_restraints=True, pdb_interpretation_params=p)
    geometry = model.get_restraints_manager().geometry

    self.results = rna_validation(
      pdb_hierarchy=hierarchy,
      geometry_restraints_manager=geometry,
      params=self.params,
      outliers_only=self.params.outliers_only)
    if self.params.json:
      print(self.results.as_JSON(), file=self.logger)
    elif self.params.verbose:
      self.results.show(out=self.logger, verbose=True)

  def get_results(self):
    return self.results

  def get_results_as_JSON(self):
    return self.results.as_JSON(self.info_json)


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/rna_validate_bonds.py
from __future__ import absolute_import, division, print_function

import os
from mmtbx.model import manager
from mmtbx.validation.rna_validate import rna_bonds, rna_angles
from libtbx.program_template import ProgramTemplate
from libtbx.utils import null_out
import json
import pprint

class Program(ProgramTemplate):
  prog = os.getenv('LIBTBX_DISPATCHER_NAME')
  description="""\
%(prog)s file.pdb [params.eff] [options ...]

Options:

  model=input_file        input PDB file
  outliers_only=False   only print outliers
  json=False            Outputs results as JSON compatible dictionary
  verbose=False         verbose text output

Example:

  %(prog)s model=1ubq.pdb outliers_only=True
""" % locals()

  master_phil_str = """
  include scope mmtbx.validation.molprobity_cmdline_phil_str
  show_errors = False
    .type = bool
    .help = '''Print out errors'''
  json = False
    .type = bool
    .help = "Prints results as JSON format dictionary"
  use_parent = False
    .type = bool
  """
  datatypes = ['model','phil']
  data_manager_options = ['model_skip_expand_with_mtrix']
  known_article_ids = ['molprobity']

  def validate(self):
    self.data_manager.has_models(raise_sorry=True)

  def run(self):
    model = self.data_manager.get_model()
    model.set_stop_for_unknowns(False)
    hierarchy = model.get_hierarchy()
    p = manager.get_default_pdb_interpretation_params()
    ##print(dir(p.pdb_interpretation))
    p.pdb_interpretation.allow_polymer_cross_special_position=True
    p.pdb_interpretation.flip_symmetric_amino_acids=False
    p.pdb_interpretation.clash_guard.nonbonded_distance_threshold = None
    model.set_log(log = null_out())
    model.process(make_restraints=True, pdb_interpretation_params=p)
    geometry = model.get_restraints_manager().geometry
    atoms = hierarchy.atoms()
    bonds = rna_bonds(
      pdb_hierarchy=hierarchy,
      pdb_atoms=atoms,
      geometry_restraints_manager=geometry,
      outliers_only=self.params.outliers_only)
    angles = rna_angles(
      pdb_hierarchy=hierarchy,
      pdb_atoms=atoms,
      geometry_restraints_manager=geometry,
      outliers_only=self.params.outliers_only)
    if self.params.json:
      results = {"rna_bonds": json.loads(bonds.as_JSON()),
       "rna_angles": json.loads(angles.as_JSON())}
      pprint.pprint(results, compact=True)
    elif self.params.verbose:
      bonds.show(out=self.logger, verbose=True)
      angles.show(out=self.logger, verbose=True)


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/rna_validate_puckers.py
from __future__ import absolute_import, division, print_function

import os
from mmtbx.validation.rna_validate import rna_puckers
from libtbx.program_template import ProgramTemplate
from datetime import datetime

class Program(ProgramTemplate):
  prog = os.getenv('LIBTBX_DISPATCHER_NAME')
  description="""\
%(prog)s file.pdb [params.eff] [options ...]

Options:

  model=input_file        input PDB file
  outliers_only=False   only print outliers
  json=False            Outputs results as JSON compatible dictionary
  verbose=False         verbose text output

Example:

  %(prog)s model=1ubq.pdb outliers_only=True
""" % locals()

  master_phil_str = """
  include scope mmtbx.validation.molprobity_cmdline_phil_str
  show_errors = False
    .type = bool
    .help = '''Print out errors'''
  json = False
    .type = bool
    .help = "Prints results as JSON format dictionary"
  use_parent = False
    .type = bool
  rna_sugar_pucker_analysis
    .short_caption = RNA sugar pucker analysis
    .style = box noauto auto_align menu_item parent_submenu:advanced
  {
    include scope mmtbx.monomer_library.rna_sugar_pucker_analysis.master_phil
  }
  """
  datatypes = ['model','phil']
  data_manager_options = ['model_skip_expand_with_mtrix']
  known_article_ids = ['molprobity']

  def validate(self):
    self.data_manager.has_models(raise_sorry=True)

  def run(self):
    hierarchy = self.data_manager.get_model().get_hierarchy()
    self.info_json = {"model_name":self.data_manager.get_default_model_name(),
                      "time_analyzed": str(datetime.now())}
    self.results = rna_puckers(
      pdb_hierarchy=hierarchy,
      params=getattr(self.params, "rna_sugar_pucker_analysis", None),
      outliers_only=self.params.outliers_only)
    if self.params.json:
      print(self.results.as_JSON(), file=self.logger)
    elif self.params.verbose:
      self.results.show(out=self.logger, verbose=True)

  def get_results(self):
    return self.results

  def get_results_as_JSON(self):
    return self.results.as_JSON(self.info_json)


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/rna_validate_suites.py
from __future__ import absolute_import, division, print_function

import os
from mmtbx.model import manager
from mmtbx.suitename import suitealyze
from libtbx.program_template import ProgramTemplate
from libtbx.utils import null_out
from datetime import datetime

class Program(ProgramTemplate):
  prog = os.getenv('LIBTBX_DISPATCHER_NAME')
  description="""\
%(prog)s file.pdb [params.eff] [options ...]

Options:

  model=input_file        input PDB file
  outliers_only=False   only print outliers
  json=False            Outputs results as JSON compatible dictionary
  verbose=False         verbose text output

Example:

  %(prog)s model=1ubq.pdb outliers_only=True
""" % locals()

  master_phil_str = """
  include scope mmtbx.validation.molprobity_cmdline_phil_str
  show_errors = False
    .type = bool
    .help = '''Print out errors'''
  json = False
    .type = bool
    .help = "Prints results as JSON format dictionary"
  use_parent = False
    .type = bool
  """
  datatypes = ['model','phil']
  data_manager_options = ['model_skip_expand_with_mtrix']
  known_article_ids = ['molprobity']

  def validate(self):
    self.data_manager.has_models(raise_sorry=True)

  def run(self):
    model = self.data_manager.get_model()
    model.set_stop_for_unknowns(False)
    hierarchy = model.get_hierarchy()
    self.info_json = {"model_name":self.data_manager.get_default_model_name(),
                      "time_analyzed": str(datetime.now())}
    p = manager.get_default_pdb_interpretation_params()
    ##print(dir(p.pdb_interpretation))
    p.pdb_interpretation.allow_polymer_cross_special_position=True
    p.pdb_interpretation.flip_symmetric_amino_acids=False
    p.pdb_interpretation.clash_guard.nonbonded_distance_threshold = None
    model.set_log(log = null_out())
    model.process(make_restraints=True, pdb_interpretation_params=p)
    geometry = model.get_restraints_manager().geometry

    self.results = suitealyze.suitealyze(
      pdb_hierarchy=hierarchy,
      outliers_only=self.params.outliers_only)
    if self.params.json:
      print(self.results.as_JSON(), file=self.logger)
    elif self.params.verbose:
      self.results.show(out=self.logger, verbose=True)

  def get_results(self):
    return self.results

  def get_results_as_JSON(self):
    return self.results.as_JSON(self.info_json)


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/rotalyze.py
from __future__ import absolute_import, division, print_function

import os
from mmtbx.validation.rotalyze import rotalyze
from libtbx.program_template import ProgramTemplate
from libtbx.utils import Sorry
from datetime import datetime

class Program(ProgramTemplate):
  prog = os.getenv('LIBTBX_DISPATCHER_NAME')
  description="""\
%(prog)s file.pdb [params.eff] [options ...]

Options:

  model=input_file        input PDB file
  outliers_only=False   only print outliers
  json=False            Outputs results as JSON compatible dictionary
  verbose=False         verbose text output

Example:

  %(prog)s model=1ubq.pdb outliers_only=True
""" % locals()

  master_phil_str = """
  include scope mmtbx.validation.molprobity_cmdline_phil_str
  data_version = 8000
    .type = str
    .help = '''Use rotamer distributions from top8000'''
  show_errors = False
    .type = bool
    .help = '''Print out errors'''
  json = False
    .type = bool
    .help = "Prints results as JSON format dictionary"
  wxplot = False
    .type = bool
    .help = Display interactive plots (requires wxPython and Matplotlib)
  use_parent = False
    .type = bool
  """
  datatypes = ['model','phil']
  data_manager_options = ['model_skip_expand_with_mtrix']
  known_article_ids = ['molprobity']

  def validate(self):
    self.data_manager.has_models(raise_sorry=True)

  def run(self):
    hierarchy = self.data_manager.get_model().get_hierarchy()
    self.info_json = {"model_name":self.data_manager.get_default_model_name(),
                      "time_analyzed": str(datetime.now())}
    self.results = rotalyze(
      pdb_hierarchy=hierarchy,
      data_version="8000",#was 'params.data_version', no options currently
      show_errors=self.params.show_errors,
      outliers_only=self.params.outliers_only,
      use_parent=self.params.use_parent,
      out=self.logger,
      quiet=False)
    if self.params.json:
      print(self.results.as_JSON(), file=self.logger)
    elif self.params.verbose:
      self.results.show_old_output(out=self.logger, verbose=True)
    if self.params.wxplot :
      try :
        import wxtbx.app
      except ImportError as e :
        raise Sorry("wxPython not available.")
      else :
        app = wxtbx.app.CCTBXApp(0)
        self.results.display_wx_plots()
        app.MainLoop()

  def get_results(self):
    return self.results

  def get_results_as_JSON(self):
    return self.results.as_JSON(self.info_json)


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/ss_idealization.py
# -*- coding: utf-8 -*-
from __future__ import absolute_import, division, print_function

from libtbx.program_template import ProgramTemplate
from mmtbx.secondary_structure.build import ss_idealization
from libtbx import Auto
import os



# =============================================================================

class Program(ProgramTemplate):

  description = '''
phenix.ss_idealization: tool for idealization of secondary structure.
  Uses SS annotation in the input model file.

Usage examples:
  phenix.ss_idealization model.pdb
  phenix.ss_idealization model.cif
  phenix.ss_idealization model.pdb nproc=7
  '''

  datatypes = ['model', 'phil']

  master_phil_str = """
include scope mmtbx.secondary_structure.build.ss_idealization.ss_idealization_master_phil_str
  """

  # ---------------------------------------------------------------------------
  def validate(self):
    print('Validating inputs', file=self.logger)
    self.data_manager.has_models(raise_sorry=True)

  # ---------------------------------------------------------------------------
  def run(self):
    # I'm guessing self.data_manager, self.params and self.logger
    # are already defined here...
    print('Using model: %s' % self.data_manager.get_default_model_name(), file=self.logger)

    # this must be mmtbx.model.manager?
    self.model = self.data_manager.get_model()

    # Done in place!
    self.params.ss_idealization.enabled=True
    sss = ss_idealization.substitute_ss(
        model = self.model,
        params = self.params.ss_idealization,
        log=self.logger)
    sss.run()
    inp_fn = os.path.basename(self.data_manager.get_default_model_name())[:-4]
    fn = "%s" % self.get_default_output_filename(
                prefix='%s_' % inp_fn,
                suffix='ss_idealized',
                serial=Auto)
    actual_fn = self.data_manager.write_model_file(self.model, filename=fn)

  # ---------------------------------------------------------------------------
  def get_results(self):
    return self.model

# =============================================================================
# end


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/ss_validation.py
# -*- coding: utf-8 -*-
from __future__ import absolute_import, division, print_function

from libtbx.program_template import ProgramTemplate

from mmtbx.secondary_structure import ss_validation

# =============================================================================

class Program(ProgramTemplate):

  description = '''
phenix.secondary_structure_validation: tool for validation of secondary
  structure annotations.

Usage examples:
  phenix.secondary_structure_validation model.pdb
  phenix.secondary_structure_validation model.cif
  phenix.secondary_structure_validation model.pdb nproc=7
  '''

  datatypes = ['model', 'phil']

  master_phil_str = ss_validation.master_phil_str

  # ---------------------------------------------------------------------------
  def validate(self):
    print('Validating inputs', file=self.logger)
    self.data_manager.has_models(raise_sorry=True)

  # ---------------------------------------------------------------------------
  def run(self):
    # I'm guessing self.data_manager, self.params and self.logger
    # are already defined here...
    print('Using model: %s' % self.data_manager.get_default_model_name(), file=self.logger)

    # this must be mmtbx.model.manager?
    model = self.data_manager.get_model()

    self.val_obj = ss_validation.validate(
        model=model,
        params = self.params.ss_validation,
        log = self.logger)

  # ---------------------------------------------------------------------------
  def get_results(self):
    return self.val_obj.get_results()

# =============================================================================
# end


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/suitename.py
#        Copyright 2021  Richardson Lab at Duke University
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import absolute_import, division, print_function

import os
from mmtbx.suitename.suitealyze import suitealyze
from libtbx.program_template import ProgramTemplate
#from libtbx.utils import Sorry
from datetime import datetime

class Program(ProgramTemplate):
  prog = os.getenv('LIBTBX_DISPATCHER_NAME')
  description="""
  %(prog)s file.pdb [params.eff] [options ...]

Commandline interface for suitename validation
Supply a PDB or mmCIF file; get suitename validation

Options:

  model=input_file      input PDB file
  outliers_only=False   suppress non-outlier results
  report=True           standard text output
  json=False            JSON format output
  string=False          output in suitestring format, 3 characters per suite
  kinemage=False        kinemage-format visual markup

Example:

  %(prog)s model=1ubq.pdb
""" % locals()

  master_phil_str = """
  include scope mmtbx.validation.molprobity_cmdline_phil_str
    suitename {
    # input
      infile=""
        .type=str
        .help="the file to process"
      anglefields = 9
        .type=int
        .help="number of angle fields provided, for textual input only"
      pointidfields = 7
        .type=int
        .help="number of point id fields before the angle fields"
      ptid=0
        .type=int
        .help="number of point id fields before the angle fields"
      residuein=false
        .type=bool
        .help="expect dangle format giving residues"
      suitein=false
        .type=bool
        .help="expect kinemage format giving suites directly"
    # output
      string=False
        .type=bool
        .help="output in string format, 3 characters per suite"
      json=False
        .type=bool
        .help="output in JSON format, useful for machine parsing"
      kinemage=False
        .type=bool
        .help="output in kinemage format, useful for visualization"
      markup=False
        .type=bool
        .help="visual markup of suites and outliers for kinemage format"
      report=true
        .type=bool
        .help="output as a report, giving statistical details"
      chart=False
        .type=bool
        .help="modifier to standard report, output without statistical summary"
      nosequence = False
        .type=bool
        .help="modifier to string format, do not include base letters"
      causes=False
        .type=bool
        .help="output extra details concerning the causes of each assignment made"
      test=False
        .type=bool
        .help="display a lat of additional information about program internals"
    # compute
      satellites=False
        .type=bool
        .help="use the special satelliteWidths values for satellites"
      nowannabe=False
        .type=bool
        .help="do not consider 'wannabe' clusters"
      noinc=False
        .type=bool
        .help="do not display incomplete suites"
      etatheta=False
        .type=bool
      altid="A"
        .type=str
        .help="which alternate conformer to use (A, B, etc)"
      altidfield = 6
        .type=int
        .help="which field (1-based) gives the alternate conformer code"
      version=false
        .type=bool
        .help="give the version number of suite name"
    # deprecated and automatically true:
      oneline=false
        .type=bool
    }
"""
  datatypes = ['model','phil']
  data_manager_options = ['model_skip_expand_with_mtrix']
  known_article_ids = ['molprobity']

  def validate(self):
    self.data_manager.has_models(raise_sorry=True)

  def run(self):
    hierarchy = self.data_manager.get_model().get_hierarchy()
    self.info_json = {"model_name":self.data_manager.get_default_model_name(),
                      "time_analyzed": str(datetime.now())}
    self.suite_results = suitealyze(pdb_hierarchy=hierarchy, options=self.params)
    if self.params.suitename.string or self.params.suitename.oneline:# == "string":
      self.suite_results.display_suitestrings(blockform=True)
    elif self.params.suitename.markup:# == "markup":
      print(self.suite_results.as_kinemage_markup())
    elif self.params.suitename.json:
      print(self.suite_results.as_JSON())
    elif self.params.suitename.report:# == "report":
      self.suite_results.show_old_output(verbose=True)
    else:
      self.suite_results.show_old_output(verbose=True)
    #print(suite_results.as_kinemage())
    #suite_results.show_summary()

  def get_results(self):
    return self.suite_results

  def get_results_as_JSON(self):
    return self.suite_results.as_JSON(self.info_json)

    #hierarchy.atoms().reset_i_seq()
    #result = cbetadev(
    #  pdb_hierarchy=hierarchy,
    #  outliers_only=self.params.outliers_only,
    #  apply_phi_psi_correction=self.params.cbetadev.apply_phi_psi_correction,
    #  display_phi_psi_correction=self.params.cbetadev.display_phi_psi_correction,
    #  exclude_d_peptides=self.params.cbetadev.exclude_d_peptides,
    #  out=self.logger,
    #  quiet=False)
    #if self.params.cbetadev.output == "kin":
    #  self.logger.write(result.as_kinemage())
    #elif self.params.cbetadev.output == "bullseye":
    #  filebase = os.path.basename(self.data_manager.get_model_names()[0])
    #  self.logger.write(result.as_bullseye_kinemage(pdbid=filebase))
    #elif self.params.verbose:
    #  #pdb_file_str = os.path.basename(self.params.model)[:-4]
    #  #get input file name from data manager, strip file extension
    #  pdb_file_str = os.path.basename(self.data_manager.get_model_names()[0])[:-4]
    #  result.show_old_output(out=self.logger, prefix=pdb_file_str, verbose=True)


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/suitename_old.py
#        Copyright 2021  Richardson Lab at Duke University
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import division
from __future__ import nested_scopes, generators, absolute_import
from __future__ import with_statement, print_function
import sys, os

from mmtbx.suitename import dualparse, suites
from mmtbx.suitename.suitename import main, version

from iotbx.cli_parser import CCTBXParser
from libtbx.program_template import ProgramTemplate
from libtbx.utils import multi_out, show_total_time

#import libtbx.load_env
#from libtbx.utils import Usage

import os, sys

def run(args):
  "The main program, if run from CCTBX / PHENIX."
  logger = multi_out()
  logger.register('stderr', sys.stderr)
  logger2 = multi_out()
  logger2.register('stdout', sys.stdout)
  logger3 = multi_out()
  # TO DIAGNOSE OPTIONS TROUBLES:
  # logger3.register('verbiage', open("suitename.stderr.log", "w"))

  parser = dualparse.parseArgs(Program, logger3)
  working_phil = parser.working_phil
  options = working_phil.extract().suitename

  # now we call into the core of suitename itself
  if options.version:
      print(version, file=logger2)
      return
  if options.infile == "" or options.infile =="-" or options.residuein or options.suitein:
      # let the core figure out the input
      main(optionsIn=options, outFile=logger2, errorFile=logger)
  else:
      type, ext = analyzeFileType(options.infile)
      if type=="":
        logger.write("File extension "+str(ext)+" not recognized\n")
        return
      if type == "pdb":
          suites.main(options=options, outFile=logger2, errorFile=logger)
      else:
        # help the core figure out the input file type
        if type == "kinemage":
          options.suitein = True
        elif type == "dangle":
          options.residuein = True
        main(optionsIn=options, outFile=logger2, errorFile=logger)


extensionList={
    "pdb": "pdb",
    "cif": "pdb",
    "kin": "kinemage",
    "dangle": "dangle",
    "suitegeom": "dangle",
}

def analyzeFileType(filename):
    base, extension = os.path.splitext(filename)
    extension = extension[1:]
    type = extensionList.get(extension, "")
    return type, extension


class Program(ProgramTemplate):
  prog = os.getenv('LIBTBX_DISPATCHER_NAME')
  program_name = "suitename"
  description="""
   < insert help text here>
""" % locals()

  # The substructure below has been commented out because it would make it more
  # difficult to integrate with suitename's ability to run independently
  # of CCTBX
  master_phil_str = """
    suitename {
      # input
        infile=""
          .type=str
          .help="the file to process"
        anglefields = 9
          .type=int
          .help="number of angle fields provided, for textual input only"
        pointidfields = 7
          .type=int
          .help="number of point id fields before the angle fields"
        ptid=0
          .type=int
          .help="number of point id fields before the angle fields"
        residuein=false
          .type=bool
          .help="expect dangle format giving residues"
        suitein=false
          .type=bool
          .help="expect kinemage format giving suites directly"
      # output
        string=False
          .type=bool
          .help="output in string format, 3 characters per suite"
        kinemage=False
          .type=bool
          .help="output in kinemage format, useful for visualization"
        report=true
          .type=bool
          .help="output as a report, giving statistical details"
        chart=False
          .type=bool
          .help="modifier to standard report, output without statistical summary"
        nosequence = False
          .type=bool
          .help="modifier to string format, do not include base letters"
        causes=False
          .type=bool
          .help="output extra details concerning the causes of each assignment made"
        test=False
          .type=bool
          .help="display a lat of additional information about program internals"
      # compute
        satellites=False
          .type=bool
          .help="use the special satelliteWidths values for satellites"
        nowannabe=False
          .type=bool
          .help="do not consider 'wannabe' clusters"
        noinc=False
          .type=bool
          .help="do not display incomplete suites"
        etatheta=False
          .type=bool
        altid="A"
          .type=str
          .help="which alternate conformer to use (A, B, etc)"
        altidfield = 6
          .type=int
          .help="which field (1-based) gives the alternate conformer code"
        version=False
          .type=bool
          .help="give the version number of suite name"
      # deprecated
        oneline=False
          .type=bool
      }
"""

# might add:
        # altidval="A"
        #   .type=str
        #   .help="which alternate conformer to use (A, B, etc)"
#
  datatypes = ['model', 'phil']  # also
  data_manager_options = ['model_skip_expand_with_mtrix']
  known_article_ids = ['molprobity']

  def validate(self):
    pass

  def run(self, args):
    pass


  # end of class Program


# def rest_of_old_run(args):  -- an intermediate state, outdated technique
#   namespace, others = parser.parse_args(sys.argv[1:])
#   # whatever the old fashioned parser won't use becomes part of <others>
#   # and will be given to the phil parser
#
#   parser = CCTBXParser(
#     program_class=Program,
#     logger=logger)
#   namespace = parser.parse_args(others)
#
#   # start program
#   print('Starting job', file=logger)
#   print('='*79, file=logger)
#   phil1 = parser.working_phil.extract()
#   args2 = parseCommandLine()
#   task = Program(
#     parser.data_manager, phil1, logger=logger2)
#   main()

#=============================================================================
# def run(args):
#
#   # create parser
#   logger = multi_out()
#   logger.register('stderr', sys.stderr)
#   logger2 = multi_out()
#   logger2.register('stdout', sys.stdout)
#
#   parser = CCTBXParser(
#     program_class=cablam.Program,
#     logger=logger)
#   namespace = parser.parse_args(sys.argv[1:])
#
#   # start program
#   print('Starting job', file=logger)
#   print('='*79, file=logger)
#   task = cablam.Program(
#     parser.data_manager, parser.working_phil.extract(), logger=logger2)
#
#   # validate inputs
#   task.validate()
#
#   # run program
#   task.run()
#
#   # stop timer
#   print('', file=logger)
#   print('='*79, file=logger)
#   print('Job complete', file=logger)
#   show_total_time(out=logger)

# =============================================================================
if __name__ == '__main__':
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/undowser.py
from __future__ import absolute_import, division, print_function

import os
from mmtbx.validation.undowser import undowserlyze
from libtbx.program_template import ProgramTemplate
from datetime import datetime

class Program(ProgramTemplate):
  prog = os.getenv('LIBTBX_DISPATCHER_NAME')
  description="""\
%(prog)s file.pdb [params.eff] [options ...]

Options:

  model=input_file        input PDB file
  outliers_only=False   only print outliers
  keep_hydrogens=False      keep input hydrogen atoms if True, regenerate if False
  nuclear=False             use nuclear x-H distances and vdW radii
  json=False            Outputs results as JSON compatible dictionary
  verbose=False         verbose text output

Example:

  %(prog)s model=1ubq.pdb outliers_only=True
""" % locals()

  master_phil_str = """
  include scope mmtbx.validation.molprobity_cmdline_phil_str
  show_errors = False
    .type = bool
    .help = '''Print out errors'''
  keep_hydrogens = False
    .type = bool
    .help = '''Keep hydrogens in input file'''
  nuclear = False
    .type = bool
    .help = '''Use nuclear hydrogen positions'''
  time_limit = 120
    .type = int
    .help = '''Time limit (sec) for Reduce optimization'''
  json = False
    .type = bool
    .help = "Prints results as JSON format dictionary"
  use_parent = False
    .type = bool
  """
  datatypes = ['model','phil']
  data_manager_options = ['model_skip_expand_with_mtrix']
  known_article_ids = ['molprobity']

  def validate(self):
    self.data_manager.has_models(raise_sorry=True)

  def run(self):
    hierarchy = self.data_manager.get_model().get_hierarchy()
    self.info_json = {"model_name":self.data_manager.get_default_model_name(),
                      "time_analyzed": str(datetime.now())}
    self.results = undowserlyze(
      pdb_hierarchy=hierarchy,
      keep_hydrogens=self.params.keep_hydrogens,
      nuclear=self.params.nuclear,
      outliers_only=self.params.outliers_only,)
    if self.params.json:
      print(self.results.as_JSON(), file=self.logger)
    else:
      print(self.results.as_HTML())

  def get_results(self):
    return self.results

  def get_results_as_JSON(self):
    return self.results.as_JSON(self.info_json)


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/undowser2.py
"""
Water-atom clash analysis.
This is a rewrite of the original undowser.  This version uses mmtbx.reduce and
mmtbx.probe to generate the contact information rather than stand-alone programs.
It take the same parameters as the original clashscore (except for time_limit)
and it also takes mmtbx.probe parameters.
"""

from __future__ import absolute_import, division, print_function

import os
from mmtbx.validation.undowser2 import undowserlyze
from libtbx.program_template import ProgramTemplate
from datetime import datetime
from mmtbx.probe import Helpers

class Program(ProgramTemplate):
  prog = os.getenv('LIBTBX_DISPATCHER_NAME')
  description="""\
%(prog)s file.pdb [params.eff] [options ...]

Options:

  model=input_file        input PDB file
  outliers_only=False   only print outliers
  keep_hydrogens=False      keep input hydrogen atoms if True, regenerate if False
  nuclear=False             use nuclear x-H distances and vdW radii
  json=False            Outputs results as JSON compatible dictionary
  verbose=False         verbose text output

Example:

  %(prog)s model=1ubq.pdb outliers_only=True
""" % locals()

  master_phil_str = """
  include scope mmtbx.validation.molprobity_cmdline_phil_str
  show_errors = False
    .type = bool
    .help = '''Print out errors'''
  keep_hydrogens = False
    .type = bool
    .help = '''Keep hydrogens in input file'''
  nuclear = False
    .type = bool
    .help = '''Use nuclear hydrogen positions'''
  json = False
    .type = bool
    .help = "Prints results as JSON format dictionary"
  use_parent = False
    .type = bool
  """ + Helpers.probe_phil_parameters
  datatypes = ['model','phil']
  data_manager_options = ['model_skip_expand_with_mtrix']
  known_article_ids = ['molprobity']

  def validate(self):
    self.data_manager.has_models(raise_sorry=True)

  def run(self):
    self.info_json = {"model_name":self.data_manager.get_default_model_name(),
                      "time_analyzed": str(datetime.now())}
    self.results = undowserlyze(
      self.params.probe,
      data_manager=self.data_manager,
      keep_hydrogens=self.params.keep_hydrogens,
      nuclear=self.params.nuclear,
      outliers_only=self.params.outliers_only,)
    if self.params.json:
      print(self.results.as_JSON(), file=self.logger)
    else:
      print(self.results.as_HTML())

  def get_results(self):
    return self.results

  def get_results_as_JSON(self):
    return self.results.as_JSON(self.info_json)


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/validate_ligands.py
from __future__ import absolute_import, division, print_function
import os
try:
  from phenix.program_template import ProgramTemplate
except ImportError:
  from libtbx.program_template import ProgramTemplate
import mmtbx.validation.ligands
from mmtbx.validation import validate_ligands
from libtbx.utils import null_out, Sorry
from iotbx import crystal_symmetry_from_any
from libtbx.str_utils import make_sub_header
from libtbx import group_args


master_phil_str = """
include scope mmtbx.validation.validate_ligands.master_params
ligand_code = None
  .type = str
  .multiple = True
scattering_table = *n_gaussian wk1995 it1992 neutron electron
  .type = choice
  .short_caption = Scattering table
  .help = Scattering table for structure factors calculations
verbose = False
  .type = bool
"""

# old params from Nat
#reference_structure = None
#  .type = path
#only_segid = None
#  .type = str

# =============================================================================

class Program(ProgramTemplate):

  description = '''
mmtbx.validate_ligands model.pdb data.mtz LIGAND_CODE [...]

Print out basic statistics for residue(s) with the given code(s), including
electron density values/CC.
'''

  datatypes = ['model', 'phil', 'miller_array']

  master_phil_str = master_phil_str

  # ---------------------------------------------------------------------------

  def validate(self):
    print('Validating inputs...\n', file=self.logger)
    self.data_manager.has_models(
      raise_sorry = True,
      expected_n  = 1,
      exact_count = True)

  # ---------------------------------------------------------------------------

  def get_crystal_symmetry(self, model_fn, data_fn):
    crystal_symmetries = []
    for f in [model_fn, data_fn]:
      if f is None: continue
      cs = crystal_symmetry_from_any.extract_from(f)
      if (cs is not None):
        crystal_symmetries.append(cs)
    if (len(crystal_symmetries) == 0):
     raise Sorry("No crystal symmetry found.")
    elif (len(crystal_symmetries) > 1):
      if (not crystal_symmetries[0].is_similar_symmetry(crystal_symmetries[1])):
        raise Sorry("Crystal symmetry mismatch between different files.")
    crystal_symmetry = crystal_symmetries[0]
    return crystal_symmetry

  # ---------------------------------------------------------------------------

  def run(self):
    has_data = False
    fmodel = None
    model_fn = self.data_manager.get_default_model_name()
    data_fn = self.data_manager.get_default_miller_array_name()
    print('Using model file:', model_fn, file=self.logger)
    if data_fn is not None:
      print('Using reflection file:', data_fn, file=self.logger)
      has_data = True

    # Place H atoms with reduce2
    make_sub_header(' Placing H with reduce2 ', out=self.logger)
    basename = os.path.splitext(os.path.basename(model_fn))[0]
    model_fn_reduce2 = "%s_newH.cif" % basename
    from iotbx.cli_parser import run_program
    from mmtbx.programs import reduce2 as reduce2
    args=["overwrite=True",
          "%s" % model_fn,
          #"use_neutron_distances=True",
          "output.filename=%s" % model_fn_reduce2]
    print("mmtbx.reduce2 %s" %(" ".join(args)), file=self.logger)
    try:
      result = run_program(program_class=reduce2.Program,args=args,
       logger = null_out())
      model_reduce2 = result.model
    except Exception as e:
      msg = traceback.format_exc()
      self.success   = False
      self.write_log(step = 'Reduce2', msg  = msg)
      print('Reduce2 failed.\n' + msg, file=self.logger)
      return

    # get fmodel object
    if has_data:
      make_sub_header(' Creating fmodel object ', out=self.logger)
      self.data_manager.add_model(model_fn_reduce2, model_reduce2)
      fmodel = self.data_manager.get_fmodel(
        scattering_table = self.params.scattering_table,
        model_filename   = model_fn_reduce2)
      print('\n', file = self.logger)
      fmodel.update_all_scales()
      fmodel.show(log=self.logger, show_header=False)

#
#    cs = self.get_crystal_symmetry(model_fn, data_fn)
#    model = self.data_manager.get_model()
#    print('\nWorking crystal symmetry after inspecting all inputs:', file=self.logger)
#    cs.show_summary(f=self.logger)

    #t0 = time.time()
    ligand_manager = validate_ligands.manager(
      model = model_reduce2,
      fmodel = fmodel,
      params = self.params.validate_ligands,
      log   = self.logger)
    ligand_manager.run()
    ligand_manager.show_ligand_counts()
    ligand_manager.show_ligand_occupancies()
    ligand_manager.show_adps()
    ligand_manager.show_ccs()
    ligand_manager.show_nonbonded_overlaps()

    self.ligand_manager = ligand_manager
    #print('time running manager: ', time.time()-t0)

    # old class from Nat
    #if self.params.ligand_code and self.data_manager.get_default_miller_array_name() is not None:
    #  if (not(self.params.ligand_code is None or self.params.ligand_code[0] is None)):
    #    make_sub_header("Validating ligands", out=self.logger)
    #    for ligand_code in self.params.ligand_code :
    #      validations = mmtbx.validation.ligands.validate_ligands(
    #        pdb_hierarchy       = ph,
    #        fmodel              = fmodel,
    #        ligand_code         = ligand_code,
    #        reference_structure = self.params.reference_structure,
    #        only_segid          = self.params.only_segid)
    #      if (validations is None):
    #        raise Sorry("No ligands named '%s' found." % ligand_code)
    #      mmtbx.validation.ligands.show_validation_results(validations=validations,
    #        out     = self.logger,
    #        verbose = self.params.verbose)

  def get_results(self):
    return group_args(
      ligand_manager     = self.ligand_manager)


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/water_b_factors.py
from __future__ import absolute_import, division, print_function

from libtbx.program_template import ProgramTemplate
# from libtbx.utils import null_out

from iotbx.pdb import common_residue_names_get_class as get_class

class json_exchange(list):
  def set_style(self, style=None):
    assert style

  def add_title(self, title):
    self.append({'title': title})

  def add_paragraph(self, paragraph):
    self.append({'paragraph' : paragraph})

  def add_table(self, table):
    '''
    Do some checking
    Add features for caption and Coot interactions
    Styles?
    list of centres for coot/chimeraX
    '''
    self.append({'table':table})

class b_factor_data(dict):
  def mean(self):
    rc = {}
    for chain_id, wb in self.items():
      if not len(wb): continue
      assert chain_id not in rc
      rc[chain_id] = sum(wb.values())/len(wb)
    return rc

  def find_low(self, limit_fraction=0.25):
    mean = self.mean()
    rc = {}
    for chain_id, wb in self.items():
      tmean = mean.get(chain_id, None)
      if not tmean: continue
      limit = tmean*limit_fraction
      for i_seq, b in wb.items():
        if b<=limit:
          rc.setdefault(chain_id, [])
          rc[chain_id].append(i_seq)
    return rc

def is_interest_atom_group(ag, probe_ion=None):
  if probe_ion:
    if get_class(name=ag.resname)=='common_element':
      name=probe_ion.strip().upper()
      if ag.resname.strip().upper()==probe_ion.strip().upper():
        return name
  else:
    if (get_class(name=ag.resname)=="common_water"):
        return 'O'
  return False

def generate_selections(hierarchy, probe_ion=None):
  for sel_str in [#"all",
                  "protein",
                  #"nucleotide",
                  # "element H or element D",
                  "water",
                  # "not (water or nucleotide or protein)",
                  ]:
    yield None, sel_str
  for ag in hierarchy.atom_groups():
    name = is_interest_atom_group(ag, probe_ion=probe_ion)
    if name:
      yield ag.id_str(), 'within(5, chain %s and resseq %s and name %s)' % (
        ag.parent().parent().id,
        ag.parent().resseq,
        name,
        )

def get_bs(model, sel_str):
  sel = model.selection(sel_str)
  if(sel.count(True)==0): return None
  model = model.select(sel)
  atoms = model.get_atoms()
  bs = atoms.extract_b()
  return bs

def process_water_b_factors(model, probe_ion=None, log=None):
  model.process(make_restraints=True)
  hierarchy = model.get_hierarchy()
  atoms = model.get_atoms()
  bs = atoms.extract_b()
  mean = bs.min_max_mean().mean
  ssd = bs.sample_standard_deviation()
  bsZ = bs.deep_copy()
  bsZ.as_z_scores()

  rc = {}
  for id_str, sel_str in generate_selections(hierarchy, probe_ion=probe_ion):
    bs_selected = get_bs(model, sel_str)
    if bs_selected is None:
      print('\n\tNo %s molecules found' % sel_str, file=log)
      continue
    mean = bs_selected.min_max_mean().mean
    ssd = bs_selected.sample_standard_deviation()
    if ssd==0:
      print('\n\tNo atoms selected')
      continue
    for ag in hierarchy.atom_groups():
      if not is_interest_atom_group(ag, probe_ion=probe_ion): continue
      if id_str is not None:
        if ag.id_str()!=id_str: continue
      atom = ag.atoms()[0]
      bsZ_select = (atom.b-mean)/ssd
      key = '%s %5.2f' % (ag.id_str(), ag.atoms()[0].b)
      rc.setdefault(key, {})
      rc[key]['all']=bsZ[atom.i_seq]
      if sel_str.find('within')>-1:
        rc[key]['within']=bsZ_select
      else:
        rc[key][sel_str]=bsZ_select

  def _format_item(item, attr):
    outl = '%s:%5.1f' % (attr,item[attr])
    for key in item:
      if key==attr: continue
      outl += ' %s:%5.1f' % (key,item[key])
    return outl

  print(' Debugging ')
  print(rc)
  for attr in ['within', 'water']:
    d = dict(sorted(rc.items(), key=lambda item: item[1].get(attr,1e9)))
    for i, (key, item) in enumerate(d.items()):
      if item.get(attr, 1e9)>-1.: break
      print('  %s :: %s' % (key,_format_item(item, attr)))
      if i>30: break

  b = b_factor_data()
  for chain in hierarchy.chains():
    b.setdefault(chain.id, {})
    for residue_group in chain.residue_groups():
      atom_group = residue_group.atom_groups()[0]
      if not is_interest_atom_group(atom_group, probe_ion=probe_ion): continue
      # if get_class(atom_group.resname) not in ['common_water']: continue
      atom = atom_group.atoms()[0]
      b[chain.id][atom.i_seq]=atom.b
  return b

class Program(ProgramTemplate):

  description = '''
mmtbx.water_b_factors:

Usage examples:
  mmtbx.water_b_factors model.pdb
  '''

  datatypes = ['model', 'phil']

  master_phil_str = """
  water_b_factors {
    fraction_limit = .25
      .type = float
    probe_ion = None
      .type = str
  }
"""

  # ---------------------------------------------------------------------------
  def validate(self):
    print('Validating inputs', file=self.logger)
    if self.params.water_b_factors.fraction_limit>.4:
      print('\n  Fraction of mean limit seems too high : %5.2f' % (self.params.water_b_factors.fraction_limit))

  # ---------------------------------------------------------------------------
  def run(self, log=None):
    model = self.data_manager.get_model()
    hierarchy = model.get_hierarchy()
    hd_selection = model.get_hd_selection()
    model = model.select(~hd_selection)
    self.results = process_water_b_factors(model,
                                           probe_ion=self.params.water_b_factors.probe_ion,
                                           log=log,
                                           )
    #
    means = self.results.mean()
    i_seqs = self.results.find_low(self.params.water_b_factors.fraction_limit)
    #
    # transfer to results
    #
    summary=json_exchange()
    summary.add_title('Table of water centres with low B-factors')
    summary.add_paragraph('''
In <i>macromolecular</i> crystallographic structure refinement, water molecule
that refine to lower than average B-factors are often actually ion sites.
''')
    summary.add_paragraph('The waters listed below are candidates.')
    atoms = hierarchy.atoms()
    name = 'water'
    if self.params.water_b_factors.probe_ion:
      name = self.params.water_b_factors.probe_ion.upper()
    if i_seqs:
      print('-'*80)
      print('\n  Displaying %d results\n' % len(i_seqs), file=log)
    else:
      print('\n  No low %s found' % name, file=log)
    table = []
    for chain_id, t_i_seqs in i_seqs.items():
      print('  Low %s in chain %s : %s mean=%5.2f' % (name,
                                                      chain_id,
                                                      len(t_i_seqs),
                                                      means[chain_id]),
            file=log)
      for i_seq in t_i_seqs:
        atom = atoms[i_seq]
        b = atoms[i_seq].b
        fb = '%4.1f%%' % (atoms[i_seq].b/means[chain_id]*100)
        print('    %5.2f %s %s' % ( b,
                                    fb,
                                    atom.quote()),
             file=log)
        chain_id = atom.parent().parent().parent().id
        resseq = atom.parent().parent().resseq
        resname = atom.parent().resname
        mean = '%5.2f' % means[chain_id]
        table.append([i_seq, chain_id, resseq, resname, b, mean, fb])
    if table:
      table.insert(0,['i_seq', 'chain', 'resid', 'name', 'B-factor', 'mean', 'fraction of mean'])
    summary.add_table(table)

    self.results['summary']=summary
    self.get_json()

  # ---------------------------------------------------------------------------
  def get_results(self):
    return self.results

  def get_json(self):
    import json
    rc = self.get_results()
    rc = rc.get('summary', {})
    print(json.dumps(rc))
    f=open('myfile.json', 'w')
    json.dump(rc, f, indent=2)
    del f


 *******************************************************************************


 *******************************************************************************
mmtbx/programs/xtrapol8.py
from __future__ import absolute_import, division, print_function
import sys
from phenix.program_template import ProgramTemplate
from libtbx.utils import Sorry
import mmtbx.maps.xtrapol8 as xtrapol8

master_phil_str = '''
include scope libtbx.phil.interface.tracking_params
n_alpha = 10
  .type = int
  .help = number of alpha values to test
'''

#  =============================================================================

class Program(ProgramTemplate):

  description = """
Run xtrapol8.

  phenix.xtrapol8 reference_model.pdb reference.mtz triggered.mtz
"""

  datatypes = ['model', 'phil', 'miller_array', 'restraint']

  master_phil_str = master_phil_str

  # ---------------------------------------------------------------------------

  def validate(self):
    print('Validate inputs:', file = self.logger)
    self.data_manager.has_models(
      raise_sorry = True,
      expected_n  = 1,
      exact_count = True)
    fs  = self.data_manager.has_miller_arrays(
      raise_sorry = False,
      expected_n  = 2,
      exact_count = True)
    if (len(self.data_manager.get_miller_array_names()) != 2):
      raise Sorry('Exactly 2 reflection files are expected.')

    print('  ...all good.', file = self.logger)

  # ---------------------------------------------------------------------------

  def run(self):

    print('Using model file:', self.data_manager.get_default_model_name(),
      file=self.logger)
    print('Using reflection file(s):', self.data_manager.get_miller_array_names(),
      file=self.logger)

    model_reference = self.data_manager.get_model()
    hkls = self.data_manager.get_miller_array_names()
    # hack until data_manager.fmodel supports this
    fn_reference = hkls[0]
    fn_triggered = hkls[1]
    f_obs_reference = self.data_manager.get_miller_arrays(['FOBS'], fn_reference)[0]
    f_obs_triggered = self.data_manager.get_miller_arrays(['FOBS'], fn_triggered)[0]

    xtr = xtrapol8.manager(
      model_reference = model_reference,
      f_obs_reference = f_obs_reference,
      f_obs_triggered = f_obs_triggered,
      log             = sys.stdout)
    xtr.run()



 *******************************************************************************
