

 *******************************************************************************
spotfinder/__init__.py
from __future__ import absolute_import, division, print_function
inner_phil_str = """\
  scanbox_windows = 101 51 51
    #.type = ints(size_min=1, size_max=3, value_min=10)
    #  future: variable number of window passes
    .type = ints(size=3, value_min=10)
    .help = "Integer scanbox sizes for calculating background,"
            "for cycles 1,2, and 3, respectively."
            "Program defaults are 101, 51, and 51 pixels."
  peripheral_margin = 20
    .type = int(value_min=0)
    .help = "No spot detection inside margin; width in pixels."
"""

phil_str = """\
spotfinder {
%s
}
""" % inner_phil_str

labelit_related_commands = """\

#Preparation

wedgelimit = 2
  .type=int
  .help="maximum number of images to use for labelit indexing"
  .expert_level=2

goniometer_rotation = ''
  .type=str
  .help="Special types are Pringle-Shen, ..."
  .expert_level=3

#Coordinate systems

convention_override=None
  .type=int
  .help="if defined, override the image-format specific behavior (spot_convention number)"
  .expert_level=3

spot_convention=None
  .type=int
  .help="must be set by the calling program; no default"
  .expert_level=3

#Spotfinder

override_pickled_spotfinders = True
  .type=bool
  .help="automatically erase any existing DISTL_pickle file"
  .expert_level=3

spotfinder_header_tests = True
  .type=bool
  .expert_level=3

spotfinder_mode = 'distl'
  .type=str
  .expert_level=3

spotfinder_verbose = False
  .type=bool
  .expert_level=2

force_method2_resolution_limit = None
  .type=float
  .help="override resolution analysis based on spot count falloff; force spots at least this far out."
  .expert_level=2

distl_lowres_limit = 50.0
  .type=float
  .help="don't pick spots inside this resolution limit"
  .expert_level=3

distl_highres_limit = None
  .type=float
  .help="don't pick spots outside this resolution limit"
  .expert_level=3

distl_binned_image_spot_size = 4
  .type=int
  .expert_level=2

distl_maximum_number_spots_for_indexing = 300
  .type=int
  .expert_level=3

distl_minimum_number_spots_for_indexing = 40
  .type=int
  .expert_level=3

distl_profile_bumpiness = 2
  .type=int
  .help="maximum number of local maxima in good Bragg spots"
  .expert_level=2

distl_report_overloads = True
  .type=bool
  .expert_level=3

distl_keep_Zdata = True
  .type=bool
  .expert_level=3

percent_overlap_forcing_detail = 30.
  .type=float
  .help="detail examination of spots with nearest neighbor analysis and overlap likelihood"
  .expert_level=3

overlapping_spot_criterion = 1.2
  .type=float
  .help="in multiples of the semimajor axis"
  .expert_level=3

spots_pickle = './DISTL_pickle'
  .type=str
  .expert_level=3

distl_spotcenter_algorithm = 'center_of_mass'
  .type=str
  .help="either center_of_mass or maximum_pixel"
  .expert_level=3

distl_permit_binning=True
  .type=bool
  .multiple=False
  .help="Permit binning for large images; set False for Web-Ice since diffimage always renders unbinned."
  .expert_level=2

distl_force_binning=False
  .type=bool
  .multiple=False
  .help="Force binning for all images; only used for development and troubleshooting."
  .expert_level=2

#Data Parameters to Autoindex; Some Affect Spotfinder Also

autoindex_override_beam = None
  .type=floats(size=2)
  .help="x and y coordinates of the direct beam in mm"
  .expert_level=1

autoindex_override_distance = None
  .type=float
  .help="crystal-to-detector distance in mm"
  .expert_level=1

autoindex_override_wavelength = None
  .type=float
  .help="incident wavelength in Angstroms"
  .expert_level=1

autoindex_override_twotheta = None
  .type=float
  .help="detector swing angle in degrees"
  .expert_level=1

autoindex_override_deltaphi = None
  .type=float
  .help="single-shot rotation angle in degrees"
  .expert_level=1

image_specific_osc_start = None
  .type=str
  .help="A lambda x expression giving the rotation in degrees given the image number,
         such as lambda x: x-1.0"
  .expert_level=1

codecamp {
  maxcell = None
    .type=float
    .multiple=False
    .help="Directly specify max unit cell; potentially allow contiguous images"
    .expert_level=2
  minimum_spot_count = None
    .type=int
    .help="For determining spot masks on single images, minimum allowable spot count"
    .expert_level=2
}

pdf_output {

  file=""
    .type=str
    .multiple=False
    .help="If given, specify a file path to output a picture of the sublattice model."
    .expert_level=4
  box_selection="all"
    .type=str
    .multiple=False
    .help="index: show original superlattice | coset: show spots unique to the sublattice | all: default, show both"
    .expert_level=4
  enable_legend=False
    .type=bool
    .multiple=False
    .help="Print the Miller indices, in the triclinic sublattice basis system"
    .expert_level=4
  enable_legend_font_size=10
    .type=float
    .multiple=False
    .help="Print the Miller indices, font size in points"
    .expert_level=4
  enable_legend_ink_color=black
    .type=str
    .multiple=False
    .help="Print the Miller indices, ink color"
    .expert_level=4
  enable_legend_vertical_offset=10
    .type=float
    .multiple=False
    .help="Print the Miller indices, vertical legend offset"
    .expert_level=4
  box_linewidth=0.04
    .type=float
    .multiple=False
    .help="Line width for the rectangular box enclosing the spot profile"
    .expert_level=4
  window_fraction=0.666666
    .type=float
    .multiple=False
    .help="Fractional length of image x,y dimensions rendered to pdf; use fraction for x,y"
    .expert_level=4
  window_offset_x=0.16667
    .type=float
    .multiple=False
    .help="Fractional offset of image x dimension for the window rendered to pdf"
    .expert_level=4
  window_offset_y=0.16667
    .type=float
    .multiple=False
    .help="Fractional offset of image y dimension for the window rendered to pdf"
    .expert_level=4
  markup_inliers=True
    .type=bool
    .multiple=False
    .help="Markup the filtered Bragg candidates, peak and profile center"
    .expert_level=4
  render_all=False
    .type=bool
    .multiple=False
    .help="Show spot predictions for all possible sublattices on separate pages"
    .expert_level=4
  profile_shrink=0
    .type=int
    .multiple=False
    .help="For clarity of view, shrink the profile box by # of pixels"
    .expert_level=4

}

"""


 *******************************************************************************


 *******************************************************************************
spotfinder/applications/__init__.py


 *******************************************************************************


 *******************************************************************************
spotfinder/applications/heuristic_tbx/__init__.py


 *******************************************************************************


 *******************************************************************************
spotfinder/applications/heuristic_tbx/ice2.py
from __future__ import absolute_import, division, print_function
from six.moves import range
import math
from spotfinder.array_family import flex
from spotfinder.applications.heuristic_tbx.method2_resolution\
          import ResolutionShells
from libtbx.development.timers import Timer

# for identifying rings, the ratio of ring bin population to
#  adjacent non-ring bin population
ring_threshold = 2.0

class RingFinder:
  def __init__(self,spot_resolutions,firstBinCount,fractionCalculator):
    self.ref_spots = spot_resolutions
    self.firstBinCount = firstBinCount
    self.targetResolution = self.ref_spots[self.firstBinCount-1]
    self.fractionCalculator = fractionCalculator
    self.intervals = []
    self.force_finer_bins = False
    self.Shell = ResolutionShells(self.ref_spots,self.targetResolution,
                             self.fractionCalculator)
    while self.finer_bins_go():
      self.targetResolution *= math.pow(0.5,-1./3.) # double the reciprocal volume
      #T = Timer("instance of Resolution shells")
      #  this is an important performance bottleneck for virus work
      #  still needs to be optimized, probably with C++ code

      self.Shell = ResolutionShells(self.ref_spots,self.targetResolution,
                             self.fractionCalculator)
      #self.Shell.show()
      #del T
  def finer_bins_go(self):
    self.find_target_intervals()

    #signal must be high enough to detect
    if max(self.Shell.adjustPop) < ring_threshold:
      return False

    #the first bin should never have less than 1 spot
    elif self.ref_spots[0] <= self.targetResolution: return False

    #return True now if all spots are clustered at low-res end
    elif self.force_finer_bins:
      self.force_finer_bins = False
      return True

    #want at least an average of 4 spots per bin
    elif self.Shell.rows() >= 0.25 * len(self.ref_spots): return False

    else: return True

  def find_target_intervals(self):
    self.intervals = []
    if self.Shell.rows()<10: return # not enough bins
    self.Shell.addColumn('interval','---')
    self.Shell.interval.format = '%20s'

    # Get the signal from the central three bins:
    # ...___***___...
    # where .=ignored, _=background, *=signal, with x centered on middle *
    for x in range(2,self.Shell.rows()-1):
      first_bk = x - 4
      last_bk = x + 4
      if first_bk < 0:
        adjust = -first_bk
        first_bk += adjust
        last_bk += adjust
      if last_bk >= self.Shell.rows():
        adjust = last_bk - (self.Shell.rows() - 1)
        first_bk -= adjust
        last_bk -= adjust
      signal = self.Shell.adjustPop[x] + self.Shell.adjustPop[x-1] +\
               self.Shell.adjustPop[x+1]
      nsignal = 3.0

      background = 0.0
      for y in range(first_bk,last_bk+1):
        background += self.Shell.adjustPop[y]
      nbackground = 6
      background-=signal

      if (signal/nsignal) > ring_threshold * (background/nbackground):
        # bin population seems to be higher than surroundings, but
        # make sure this is significant based on counting statistics
        # use toy formula background + bkgd_error < signal - signal_error
        # signal minimum of 6 is still a little arbitrary
        if ( signal > 6.0 and
             ((signal-math.sqrt(signal))/nsignal) > ring_threshold *
             ((background + math.sqrt(background))/nbackground) ):
          if x < 4: self.force_finer_bins = True
          self.Shell.interval[x]='***'
          self.add_interval((self.Shell.Limit[x-2],self.Shell.Limit[x+1]))
    #self.Shell.show(['Limit','Population','Fract','interval'])

  def add_interval(self,interval):
    assert interval[0]>interval[1]
    eps = 0.0#0.05 # angstroms
    #consolidate so that end product is a set of disjoint resolution rings
    #self.intervals is a list of rings of form (low res end,high res end)
    for x in range(len(self.intervals)):
      existing = self.intervals[x]

      # check for disjointness
      if interval[1] > existing[0]+eps or interval[0] < existing[1]-eps:
        continue

      # check for containment of new interval
      if interval[0] < existing[0]+eps and interval[1] > existing[1]-eps:
        return

      # check for containment of old interval
      if interval[0] > existing[0]+eps and interval[1] < existing[1]-eps:
        self.intervals[x] = interval
        return

      # check for new interval overlap at low resolution end
      if (interval[1] <= existing[0]+eps) and (interval[0] >existing[0]+eps):
        #print existing,interval,"==>",(interval[0],existing[1])
        self.intervals.pop(x)
        self.add_interval( (interval[0],existing[1]) )
        return
      # check for new interval overlap at high resolution end
      if interval[0] >= existing[1]-eps:
        #print existing,interval,"-->",(existing[0],interval[1])
        self.intervals.pop(x)
        self.add_interval( (existing[0],interval[1]) )
        return

    self.intervals.append(interval)

  def filtered(self,sorted_order):
    # recoded in C++
    from spotfinder.core_toolbox import bin_exclusion_and_impact
    assert len(sorted_order)==len(self.ref_spots)

    self.impact = flex.int([0]*len(self.intervals))

    limits_low_hi_res = flex.double();
    for x in range(len(self.intervals)):
      limits_low_hi_res.append(self.intervals[x][0]);
      limits_low_hi_res.append(self.intervals[x][1]);

    N = bin_exclusion_and_impact(self.ref_spots,
                                    sorted_order,
                                    limits_low_hi_res,
                                    self.impact)
    return N

  def ice_ring_impact(self):
    #don't want to bother the user with information if the number
    # of filtered spots in the ring is less than 10.
    #
    return len( [x for x in self.impact if x>10] )

  def ice_ring_bounds(self):
    bounds = []
    for i,interval in enumerate(self.intervals):
      if self.impact[i] > 10:
        bounds.append( self.intervals[i] )
    return bounds


 *******************************************************************************


 *******************************************************************************
spotfinder/applications/heuristic_tbx/ice_nztt.py
from __future__ import absolute_import, division, print_function
from six.moves import range
from spotfinder.array_family import flex

from spotfinder.applications.heuristic_tbx.ice2 import RingFinder
from spotfinder.core_toolbox import hough
from spotfinder.diffraction.geometry import radius_to_resol
#not sure why he uses radius_to_resol if the equi-resolution curves are ellipses

class RingFinder_nztt(RingFinder):
  def __init__(self,spot_resolutions,firstBinCount,fractionCalculator,
               image):
    RingFinder.__init__(self,spot_resolutions,firstBinCount,fractionCalculator)
    # use Hough transform to locate ellipses
    frame = hough()
    frame.importData(image.linearintdata,image.pixel_size)
    frame.setGeometry( float(fractionCalculator.pd['xbeam']),
                       float(fractionCalculator.pd['ybeam']),
                       float(fractionCalculator.pd['distance']),
                       float(fractionCalculator.pd['twotheta']) )
    frame.cannyEdge(2,0.95,0.97)
    frame.findEllipse(2,750.0,3.5)
    self.rings = frame.getRings()
    self.col = 7
    self.nRings = len(self.rings)//self.col

    # add ellipses to existing list of rings
    for i in range(self.nRings):
      res = radius_to_resol(self.rings[i*self.col+6]*image.pixel_size,
                            fractionCalculator.pd)
      RingFinder.add_interval(self,(res+0.015,res-0.015))

    # ensure that rings from hough are definitely ice rings
    self.impact = flex.int([0]*len(self.intervals))
    for i in range(len(self.intervals)):
      for j in range(self.nRings):
        res = radius_to_resol(self.rings[j*self.col+6]*image.pixel_size,
                              fractionCalculator.pd)
        if (res <= self.intervals[i][0] and
            res >= self.intervals[i][1]):
          self.impact[i] = 15

  def filtered(self,sorted_order):
    # recoded in C++
    from spotfinder.core_toolbox import bin_exclusion_and_impact
    assert len(sorted_order)==len(self.ref_spots)

    limits_low_hi_res = flex.double();
    for x in range(len(self.intervals)):
      limits_low_hi_res.append(self.intervals[x][0]);
      limits_low_hi_res.append(self.intervals[x][1]);

    N = bin_exclusion_and_impact(self.ref_spots,
                                    sorted_order,
                                    limits_low_hi_res,
                                    self.impact)
    return N


 *******************************************************************************


 *******************************************************************************
spotfinder/applications/heuristic_tbx/method2_resolution.py
from __future__ import absolute_import, division, print_function
from six.moves import range
import math
from libtbx.table_utils import Spreadsheet,Formula
from spotfinder.core_toolbox import bin_populations

'''Support for determining the resolution limit from a group of
Bragg spots.  This module provides tools for organizing resolution
bin information into a spreadsheet; the caller is responsible for use
of the information'''

class ResolutionShells(Spreadsheet):
  def __init__(self,spots,targetResolution,fractionCalculator):
    #Total rows by formula
    Total_rows = int(math.pow(
       targetResolution/spots[len(spots)-1],3.))+1
    Spreadsheet.__init__(self,rows=Total_rows)
    self.addColumn('Limit')
    self.addColumn('Fract')
    self.addColumn('Population',0)
    self.addColumn('adjustPop',
                   Formula('self.Population[%row] / self.Fract[%row]'))

    # the outer resolution limit of the lowest-resolution shell
    self.Limit[0] = targetResolution
    self.Fract[0] = 1.0

    def BinRes(shellnumber):
      return self.Limit[0]/math.pow(shellnumber+1,1.0/3.0)

    #this little loop consumes 1.2 seconds of CPU time for a 1400-row spreadsheet
    for xrow in range(1,Total_rows):
      self.Limit[xrow] = BinRes(xrow)
      self.Fract[xrow] = fractionCalculator(self.Limit[xrow])

    bp = bin_populations(spots,self.Limit[0])
    for c in range(min(Total_rows,len(bp))): #reconcile inconsistent bin counts
        self.Population[c]=bp[c]

    self.Limit.format = "%.2f"
    self.Fract.format = "%.2f"
    self.Population.format = "%7d"
    self.adjustPop.format = "%7.1f"

  def show(self,default=['Limit','Population','Fract']):
    self.printTable(default)

  def vetter(self,cutoff,last):
    redcutoff = 10
    """The problem:  we are given a list of shell populations, pop.
       We are told we are only interested from index 0 thru last.
       We have to find a new slice from 0 to newlast such that there is
       no contiguous stretch of populations < cutoff, which is longer than 10.
    """
    pop = []
    for x in range(0,last+1):
      if self.Population[x]>cutoff: pop.append(1)
      else: pop.append(0)

    requalify=[0,]
    for x in range(1,last+1):
      if pop[x]==0: requalify.append(requalify[x-1]+1)
      else:
         requalify.append(0)
      if requalify[x] == redcutoff:
        break

    pop = pop[0:x+1]
    for x in range(len(pop)-1,-1,-1):
      if pop[x]==1:
        #print "In Vetter with input",last,"output",x
        return x


 *******************************************************************************


 *******************************************************************************
spotfinder/applications/heuristic_tbx/spotreporter.py
from __future__ import absolute_import, division, print_function
from six.moves import range
import math
from libtbx.table_utils import Spreadsheet
from spotfinder.core_toolbox import bin_populations
from spotfinder.array_family import flex

'''Detailed resolution-bin analysis for augmented spotfinder.'''

class spotreporter(Spreadsheet):
  def __init__(self,spots,phil_params,targetResolution=None,wavelength=None,
               max_total_rows=None,fractionCalculator=None,use_binning_of=None):

    if len(spots) == 0: return # No spots, no binwise analysis
    if use_binning_of is None or not hasattr(use_binning_of,"binning"):
      self.original_binning=True
      assert targetResolution is not None and wavelength is not None
      self.wavelength = wavelength

      #Total rows by formula
      Total_rows = int(math.pow(
         targetResolution/spots[len(spots)-1],3.))+1
      if max_total_rows is not None:
        Total_rows = min(Total_rows, max_total_rows)

      Spreadsheet.__init__(self,rows=Total_rows)
      self.addColumn('Limit')
      self.addColumn('Fract')
      self.addColumn('Missing') # fraction res shell remaining after missing cone is subtracted
      self.addColumn('Population',0)

      if fractionCalculator is not None and \
        phil_params.distl.bins.corner:
        last_d_star = 1./flex.min(fractionCalculator.corner_resolutions())
      else:
        last_d_star = 1./spots[-1]
      volume_fraction = (1./Total_rows)*math.pow(last_d_star,3)

      def BinRes(shellnumber):
        return 1./math.pow((shellnumber+1)*volume_fraction,1.0/3.0)

      #this little loop consumes 1.2 seconds of CPU time for a 1400-row spreadsheet
      for xrow in range(0,Total_rows):
        self.Limit[xrow] = BinRes(xrow)
        self.Fract[xrow] = fractionCalculator(self.Limit[xrow])

      self.populate_missing_cone(Total_rows)

    if use_binning_of is not None:
      if not hasattr(use_binning_of,"binning"):
        use_binning_of.binning = self #inject this spreadsheet into caller's space
      else:
        self.original_binning=False
        self.wavelength = wavelength

        Spreadsheet.__init__(self,rows=use_binning_of.binning.S_table_rows)
        self.addColumn('Limit')
        self.addColumn('Fract')
        self.addColumn('Missing')
        self.addColumn('Population',0)

        for xrow in range(0,self.S_table_rows):
          self.Limit[xrow] = use_binning_of.binning.Limit[xrow]
          self.Fract[xrow] = use_binning_of.binning.Fract[xrow]
          self.Missing[xrow] = use_binning_of.binning.Missing[xrow]
        Total_rows = self.S_table_rows

    bp = bin_populations(spots,self.Limit[0])
    for c in range(min(Total_rows,len(bp))): #reconcile inconsistent bin counts
        self.Population[c]=bp[c]

    self.Limit.format = "%.2f"
    self.Fract.format = "%.2f"
    self.Missing.format = "%.2f"
    self.Population.format = "%7d"


  def total_signal(self,fstats,indices):
    #for index in indices:
    #  print index,fstats.master[index].intensity(),flex.sum(fstats.master[index].wts)
    self.addColumn('Integrated',0) #total integrated signal within the shell
    self.Integrated.format = "%.0f"
    self.addColumn('MeanI',0) #mean integrated signal within the shell
    self.MeanI.format = "%.0f"
    self.addColumn('MeanBkg',0) #mean integrated background within the shell
    self.MeanBkg.format = "%.1f"
    self.addColumn('MeanSz',0) #mean pixel count for spots within the shell
    self.MeanSz.format = "%.0f"
    self.addColumn('MnEccen',0) #mean eccentricity spots within the shell
    self.MnEccen.format = "%.3f"
    self.addColumn('MnSkew',0) #mean eccentricity spots within the shell
    self.MnSkew.format = "%.3f"
    index=0
    for row in range(self.S_table_rows):
      row_values = flex.double()
      bkg_values = flex.double()
      sz_values = flex.double()
      eccen_values = flex.double()
      skew_values = flex.double()
      for idx in range(self.Population[row]):
        spot_signal = flex.sum(fstats.master[indices[index]].wts)
        bkg_signal = flex.sum(fstats.master[indices[index]].bkg)
        spot_sz = len(fstats.master[indices[index]].wts)
        spot_eccen = fstats.master[indices[index]].model_eccentricity()
        spot_skew = fstats.master[indices[index]].skewness()
        self.Integrated[row]+=spot_signal
        row_values.append(spot_signal)
        bkg_values.append(bkg_signal)
        sz_values.append(spot_sz)
        eccen_values.append(spot_eccen)
        skew_values.append(spot_skew)
        index+=1
      if len(row_values)>0:
        self.MeanI[row]=flex.mean(row_values)
        self.MeanBkg[row]=flex.mean(bkg_values)
        self.MeanSz[row]=flex.mean(sz_values)
        self.MnEccen[row]=flex.mean(eccen_values)
        self.MnSkew[row]=flex.mean(skew_values)
    self.persist_fstats = fstats
    self.persist_indices = indices

  def populate_missing_cone(self,total_rows):
    from spotfinder.math_support.sphere_formulae import sphere_volume
    from spotfinder.math_support.sphere_formulae import sphere_volume_minus_missing_cone
    last_cumulative_sphere_volume = 0.0
    last_cumulative_corrected_volume = 0.0
    for xrow in range(0,total_rows):
      this_sphere_volume = sphere_volume(1./self.Limit[xrow])
      this_corrected_volume = sphere_volume_minus_missing_cone(1./self.Limit[xrow],self.wavelength)
      shell_volume = this_sphere_volume - last_cumulative_sphere_volume
      shell_corrected_volume = this_corrected_volume - last_cumulative_corrected_volume
      self.Missing[xrow] = shell_corrected_volume/shell_volume
      last_cumulative_sphere_volume = this_sphere_volume
      last_cumulative_corrected_volume = this_corrected_volume

  def background(self,spotfinder):
    self.addColumn('PxlBkgrd') # mean pixel background at center of windows in the shell
    self.PxlBkgrd.format = "%.1f"
    self.addColumn('MnWndwSz') # mean size (in pixels) of the scanbox windows in the shell
    self.MnWndwSz.format = "%.0f"
    for irow in range(self.S_table_rows):
      self.PxlBkgrd[irow] = flex.double()
      self.MnWndwSz[irow] = flex.double()
    sortedidx = flex.sort_permutation(spotfinder.background_resolutions(),reverse=True)
    reverse_resolutions = spotfinder.background_resolutions().select(sortedidx)
    reverse_backgrounds = spotfinder.background_means().select(sortedidx)
    reverse_wndw_sz = spotfinder.background_wndw_sz().select(sortedidx)
    row = 0
    for x in range(len(reverse_resolutions)):
      while reverse_resolutions[x] < self.Limit[row]:
        row += 1
        if row >= self.S_table_rows: break
      if row >= self.S_table_rows: break
      self.PxlBkgrd[row].append(reverse_backgrounds[x])
      self.MnWndwSz[row].append(reverse_wndw_sz[x])
    for irow in range(self.S_table_rows):
      #print irow, len(self.PxlBkgrd[irow])
      #print list(self.PxlBkgrd[irow])
      #print list(self.PxlSigma[irow])
      if len(self.PxlBkgrd[irow])==0: self.PxlBkgrd[irow]=None; continue #No analysis without mean background
      self.PxlBkgrd[irow] = flex.mean(self.PxlBkgrd[irow])
      self.MnWndwSz[irow] = flex.mean(self.MnWndwSz[irow])

  def sigma_analysis(self):
    #assumes that self.total_signal() and self.background() have already been called.
    self.addColumn('MeanIsigI',0) #mean I over sig(I) for spots within the shell
    self.MeanIsigI.format = "%.3f"
    index=0
    for row in range(self.S_table_rows):
      if self.PxlBkgrd[row] == None: continue
      IsigI_values = flex.double()
      for idx in range(self.Population[row]):
        # Use International Tables Vol F (2001) equation 11.2.5.9 (p. 214)
        I_s = flex.sum(self.persist_fstats.master[self.persist_indices[index]].wts)
        I_bg = flex.sum(self.persist_fstats.master[self.persist_indices[index]].bkg)
        m_sz = len(self.persist_fstats.master[self.persist_indices[index]].wts)
        n_sz = self.MnWndwSz[row]
        gain = 1.00

        spot_variance = gain * (I_s + I_bg + (m_sz*m_sz) * (1./n_sz) * self.PxlBkgrd[row])

        IsigI_values.append( I_s / math.sqrt(spot_variance))

        index+=1
      if len(IsigI_values)>0: self.MeanIsigI[row]=flex.mean(IsigI_values)


  def show(self,message,default=['Limit','Population','Missing','Fract','PxlBkgrd','MnWndwSz','Integrated','MeanI',
           'MeanBkg','MeanSz','MeanIsigI','MnEccen','MnSkew']):
    self.summaries=['Population','Integrated']
    self.wtmean=['MeanI','MeanBkg','MeanSz','MeanIsigI','MnEccen','MnSkew']
    self.weights=self.Population
    legend = """Limit: outer edge of (equal-volume) resolution shell (Angstroms)
Population: number of spots in the resolution shell
Missing: fraction of reciprocal space shell recorded in complete rotation, accounting for missing cone
Fract: fraction of shell recorded, accounting for truncated detector corner
PxlBkgrd: mean pixel background at center of scanbox windows in the shell
MnWndwSz: mean scanbox window size in pixels after discarding spot pixels
Integrated: total integrated signal within the shell in analog-digital units above background
MeanI: mean integrated signal for spots within the shell
MeanBkg: mean integrated background for spots within the shell
MeanSz: mean pixel count for spots within the shell
MeanIsigI: mean I over sig(I) for spots within the shell
MnEccen: mean eccentricity for spots within the shell; 0=circle, 1=parabola
MnSkew: mean skewness for spots within the shell; skew:= (maximum-center_of_gravity)/semimajor_axis
"""; not_implemented="[PxlGain: estimate of the average gain for scanbox windows in the shell]"
    if self.original_binning: print(legend)
    print(message+":")
    to_print = [max([self.Population[i] for i in range(j,self.S_table_rows)])>0
                and self.PxlBkgrd[j] != None
           for j in range(self.S_table_rows)]
    self.printTable(default,printed_rows=to_print)

  def vetter(self,cutoff,last):
    redcutoff = 10
    """The problem:  we are given a list of shell populations, pop.
       We are told we are only interested from index 0 thru last.
       We have to find a new slice from 0 to newlast such that there is
       no contiguous stretch of populations < cutoff, which is longer than 10.
    """
    pop = []
    for x in range(0,last+1):
      if self.Population[x]>cutoff: pop.append(1)
      else: pop.append(0)

    requalify=[0,]
    for x in range(1,last+1):
      if pop[x]==0: requalify.append(requalify[x-1]+1)
      else:
         requalify.append(0)
      if requalify[x] == redcutoff:
        break

    pop = pop[0:x+1]
    for x in range(len(pop)-1,-1,-1):
      if pop[x]==1:
        #print "In Vetter with input",last,"output",x
        return x


 *******************************************************************************


 *******************************************************************************
spotfinder/applications/image_viewer.py
from __future__ import absolute_import, division, print_function
from spotfinder.applications.wrappers import DistlOrganizer

class Empty: pass

"Later go back and refactor this module and signal_strength to avoid code duplication."
class run_signal_strength_class(DistlOrganizer):

  def __init__(self,params):
    E = Empty()
    E.argv=['Empty']
    E.argv.append(params.distl.image)

    self.verbose = params.distl.verbose
    if params.distl.res.inner!=None:
      params.distl_lowres_limit = params.distl.res.inner
    if params.distl.res.outer!=None:
      params.force_method2_resolution_limit = params.distl.res.outer
      params.distl_highres_limit = params.distl.res.outer

    params.distl_force_binning = False
    params.distl_permit_binning = False
    params.wedgelimit = len(E.argv)
    params.spotfinder_header_tests = False
    DistlOrganizer.__init__(self,verbose = True, argument_module=E,
                         phil_params=params)
    self.S = None # need to initialize determined by class SpotFrame

  def view(self):
    from rstbx.viewer.spotfinder_wrap import spot_wrapper
    spot_wrapper(working_phil=self.phil_params).display(path = self.phil_params.distl.image,
                                     organizer = self)


 *******************************************************************************


 *******************************************************************************
spotfinder/applications/practical_heuristics.py
from __future__ import absolute_import, division, print_function
from six.moves import range
import six
from spotfinder.array_family import flex
import math
from spotfinder.exception import SpotfinderError
from spotfinder.core_toolbox import Distl,SpotFilterAgent,SingleMask
from spotfinder.math_support import stats_profile
from spotfinder.math_support import scitbx_stats
from spotfinder.applications.heuristic_tbx.spotreporter import spotreporter
from libtbx.development.timers import Timer, Profiler
from libtbx.utils import Sorry
from functools import reduce

TALLY2=0
OVERLAY = 1
DEBUG=0
VERBOSE_COUNT=0

def spot_filter(spotlist,function):
  return [x for x in spotlist if function(x)]

def resolution_comparisons(a,b):
  #gives -1,0,1 depending on a>b, a==b, a<b
  if a.resolution<b.resolution: return 1
  if a.resolution==b.resolution: return 0
  return -1

def resol_to_radius(resolution,pd):
  distance = float(pd['distance'])
  wavelength = float(pd['wavelength'])
  theta = math.asin(wavelength/2.0/resolution)
  return distance * math.tan(2.0*theta)

from spotfinder.diffraction.geometry import radius_to_resol

class pSpot:
  def __init__(self,x,y,intensity):
    self.mx = x
    self.my = y
    self.mi = intensity
  def x(self):
    return self.mx
  def y(self):
    return self.my
  def intensity(self):
    return self.mi

class SaturationMeasure(object):
  def forward_message(self):
    return "calculate saturation on %d of %d"%(self.n_resolution_spots,
            self.n_goodspots)
  def saturation(self):
    return self.p_saturation
  def message(self):
    return "%%Saturation, Top %d Peaks"%self.n_sample
  def format(self):
    return "%.2f"%(100*self.p_saturation)
  def message2(self):
    return "In-Resolution Ovrld Spots"
  def format2(self):
    return "%d"%(self.OverCount)

class ListNode:
  def __init__(self,nodelist,nodekey,parent=0):
    self.data = nodelist
    self.descriptor = nodekey
    self.parent = parent

class ListManager(dict):
  """From an initial spotlist, pick qualified subsets"""
  def __init__(self,masterlist,masterkey,spotfilter):
    self.master = masterlist
    self.nodes = {1:ListNode(masterlist,masterkey)}
    self.key = {masterkey:1}
    self.spotfilter = spotfilter

  def alias(self,oldkey,newkey):
    self.key[newkey]=self.key[oldkey]

  def add_child(self,oldkey,newkey,childselection):
    parent = self.key[oldkey];    nextkey = max(self.nodes.keys())+1
    self.nodes[nextkey]=ListNode(childselection,newkey,parent)
    self.key[newkey]=nextkey

  def spot_filter(self,oldkey,newkey,apfunction):
    #parent
    parent = self.key[oldkey]
    if parent == 1:
      parentselection = range(self.master.size())
    else:
      parentselection = self.nodes[parent].data
    nextkey = max(self.nodes.keys())+1
    childselection = flex.int()
    for x in parentselection:
      if apfunction(self.master[x]):
        childselection.append(x)
    self.nodes[nextkey]=ListNode(childselection,newkey,parent)
    self.key[newkey]=nextkey

  def c_spot_filter(self,oldkey,newkey,apfunction,arguments=[]):
    parent = self.key[oldkey]
    if parent == 1:
      parentselection = range(self.master.size())
    else:
      parentselection = self.nodes[parent].data
    nextkey = max(self.nodes.keys())+1
    self.spotfilter.set_arguments(flex.double(arguments))
    childselection = self.spotfilter.filter(
      self.master,parentselection,apfunction)
    self.nodes[nextkey]=ListNode(childselection,newkey,parent)
    self.key[newkey]=nextkey

  def precompute_resolution(self,twotheta,rotation_axis,camera_convention):
    self.spotfilter.precompute_resolution(self.master,twotheta,
      flex.double(rotation_axis),camera_convention)

  def single_mask(self,oldkey,phil_params):
    parent = self.key[oldkey]
    if parent == 1:
      parentselection = range(self.master.size())
    else:
      parentselection = self.nodes[parent].data
    Mask = SingleMask(master=self.master,selection=parentselection,
           minimum_spot_count =
           phil_params.codecamp.minimum_spot_count or 25)
    return Mask

  def resolution_sort(self,oldkey):
    parentselection = self.get_parentselection(oldkey)
    sort_order = self.spotfilter.resolution_sort(self.master,parentselection)
    sorted_resolutions=self.spotfilter.get_resolution(self.master,sort_order)
    return sort_order,sorted_resolutions

  def resolution_sort_nztt(self,oldkey):
    parentselection = self.get_parentselection(oldkey)
    sort_order = self.spotfilter.resolution_sort_nztt(self.master,parentselection)
    sorted_resolutions=self.spotfilter.get_resolution(self.master,sort_order)
    return sort_order,sorted_resolutions

  def order_by_criterion(self,oldkey,criterion):
    parentselection = self.get_parentselection(oldkey)
    sort_order = self.spotfilter.order_by(self.master,parentselection,criterion)
    spotlist = flex.distl_spot()
    for number in sort_order:
        spotlist.append(self.master[number])
    return spotlist

  def most_recent_child(self):
    return self.nodes[max(self.nodes.keys())].descriptor

  def get_indices(self,key):
    if self.key[key]==1: return range(len(self.master))
    return self.nodes[self.key[key]].data

  def get_indices_without(self,key,subtractive_key):
    initial_set = list(self.get_indices(key))
    subtractive_set = list(self.get_indices(subtractive_key))
    initial_set.sort()
    subtractive_set.sort()
    #use an algorithm to subtract list B from list A
    C = []
    ptrA = 0
    ptrB = 0
    lenA = len(initial_set)
    lenB = len(subtractive_set)
    while ptrA < lenA and ptrB <= lenB:
      if ptrB == lenB:
        C.append(initial_set[ptrA]); ptrA+=1; continue
      if initial_set[ptrA]==subtractive_set[ptrB]:
        ptrA+=1; ptrB+=1; continue
      if initial_set[ptrA]<subtractive_set[ptrB]:
        C.append(initial_set[ptrA]); ptrA+=1; continue
      ptrB+=1;
    return flex.int(C) # returned indices will no longer be sorted by resolution

  def get_property(self,key,property):
    parentselection = self.get_parentselection(key)
    return self.spotfilter.get_property(self.master,parentselection,property)

  def get_parentselection(self,key):
    parent = self.key[key]
    if parent == 1:
      parentselection = range(self.master.size())
    else:
      parentselection = self.nodes[parent].data
    return parentselection

  def __getitem__(self,key):
    if key.find("N_")==0:
      newkey=key[2:]
      return self.nodes[self.key[newkey]].data.size()
    if key=='spotoutput':
      return self
    if key=='resolution_spots':#for testing only
      spotlist = []
      for number in self.nodes[self.key[key]].data:
        spotlist.append(self.master[number])
      return spotlist
    if key in self.key.keys():
      if self.key[key]==1: return self.master
      spotlist = flex.distl_spot()
      for number in self.nodes[self.key[key]].data:
        spotlist.append(self.master[number])
      return spotlist
    return dict.__getitem__(self,key)

  def __delitem__(self,key):
    if key in self.key.keys(): pass
    else:
      dict.__delitem__(self,key)

  def keys(self):
    builtin = list(dict.keys(self)) # python 3 compatible
    for key in self.key.keys():
      builtin.append(key); builtin.append("N_"+key)
    return builtin

  def has_extended_key(self,key): # For Python 3 compatibility, make clear that ListManager has a specialized has_key behavior
    return key in self.keys()

def pickle_safe_spotcenter(spot,algorithm):
  #Image overlays and autoindexing maintain backward compatibility
  #  with spot information pickled under the old maximum_pixel method.
  if (algorithm == 'maximum_pixel' or not spot.com_valid()):
        return 'maximum_pixel'
  elif algorithm == 'center_of_mass':
        return 'center_of_mass'

class heuristics_base(object):

  def __init__(self,pd,phil_params):
    self.pd = pd
    self.phil_params = phil_params
    self.pd['resolution_inspection']='100.0'
    self.pd['ref_maxcel']='10.0' # default maximum cell dimension (always override this)
    self.NspotMin = self.phil_params.distl_minimum_number_spots_for_indexing
    self.NspotMax = self.phil_params.distl_maximum_number_spots_for_indexing
    self.BinMin = 25
    self.errormessage = None
    self.images = {}
    self.reporters = {}
    self.protocol = 'tnear2'
    self.overlapping = False #flag indicates whether the special procedure was used
    self.force_detail = False #flag indicates whether percent_overlap > force_detail cutoff

  def register_frames(self,frameinfo,imagefilesinstance):
    if type(frameinfo) in six.integer_types:
      frames = [int(frameinfo),]
    elif type(frameinfo) in [tuple,list]:
      frames = frameinfo
    for x in range(len(frames)):
      self.images[frames[x]] = self.oneImage(frames[x],self.pd,
                                       imagefilesinstance.imageindex(frames[x]))
      self.determine_maxcell(frames[x],self.pd)
      self.images[frames[x]]['spotoutput']['relpath']=imagefilesinstance.imagepath(frames[x])

  def oneImage(self,framenumber,pd,image):
    self.reporters[framenumber] = []
    # The only way to get pixel size & pixel dimensions (currently) is from header
    pimage = image
    pimage.read()
    #print "Detector type",type(pimage)
    if 'endstation' not in pd:
      from iotbx.detectors.context import endstation
      pd['endstation']=endstation.EndStation_from_ImageObject(pimage,self.phil_params)
      for key in pd['endstation'].mosflm():
        pd[key]=pd['endstation'].mosflm()[key]
    pd['vendortype'] = pimage.vendortype
    pd['binning']      = "%d"%pimage.bin
    pd['pixel_size'] = "%f"%pimage.pixel_size
    self.pixel_size = float(pd['pixel_size'])

    pd['size1']      = "%d"%pimage.size1
    self.size1       = float(pd['size1'])
    pd['size2']      = "%d"%pimage.size2
    self.size2       = float(pd['size2'])
    if 'osc_start' not in pd: pd['osc_start'] = {}
    pd['osc_start'][framenumber] = "%f"%pimage.osc_start
    if 'file' not in pd: pd['file'] = {}
    pd['file'][framenumber] = pimage.filename
    self.two_theta_degrees = float(pd['twotheta'])

    if 'xbeam' not in pd or 'ybeam' not in pd:
      raise SpotfinderError("Deprecation warning: inputs had no beam position",pd)
    self.complex_nominal_center = complex(float(pd["xbeam"]),float(pd["ybeam"]))

    arguments = "" # distl_aggressive no longer supported, eg "-s2 5 -s3 8"

    #allow for self.phil_params.distl_highres_limit
    if self.phil_params.distl_highres_limit != None:
      arguments = arguments + " -ro %.3f"%self.phil_params.distl_highres_limit

    #  test implementation of parallel processing for spotfinder
    #from labelit.webice_support import parallel_distl
    #pimage,pd = parallel_distl.split_image(pimage,pd)

    try: sf = Distl(arguments,pimage,pd,
            report_overloads=self.phil_params.distl_report_overloads,
            params=self.phil_params)
    except Sorry as e:
      raise e
    except Exception as e:
      raise SpotfinderError("Spotfinder cannot analyze image %s :"%pimage.filename + str(e))

    #To support sublattice detection, make pixel-wise Z-scores persistent
    if self.phil_params.distl_keep_Zdata:
      pimage.linear_Z_data = sf.Z_data() #potentially uses a lot of memory

    #************************************************************
    #
    #  Very important.  For the mar image plate (and allother circular detectors,
    #  must specify that these are embedded circular detectors and so adjust the
    #  percentage underloads.  Or else libdistl must be changed so as not to
    # search in these regions:  yes, this would be better because I propose to
    # change the search loop anyway.  However, the getUnderload function must
    # also be modified!!!
    #
    #  ice ring search must also be modified to take this into account, but this
    #  part must be more precise than the above.
    #
    #************************************************************

    if self.two_theta_degrees==0.0:
      mm_minimum_radius = resol_to_radius(
      self.phil_params.distl_lowres_limit,pd)

    sfa = SpotFilterAgent(pixel_size = pimage.pixel_size,
                          xbeam = float(pd["xbeam"]),
                          ybeam = float(pd["ybeam"]),
                          distance = float(pd['distance']),
                          wavelength = float(pd['wavelength']),
                          icerings = sf.icerings,)
    #from libtbx import easy_pickle
    #easy_pickle.dump("file.dmp",sfa)
    #easy_pickle.load("file.dmp")

    fstats = ListManager(
      masterlist=sf.spots,masterkey='spots_total',spotfilter=sfa)

    fstats['distl_resolution'] = sf.imgresol()

    # 1. Get all spots

    fstats.alias(oldkey = 'spots_total',newkey = 'goodspots')
    if VERBOSE_COUNT: print("total DISTL spots",fstats['N_spots_total'])

    fstats.c_spot_filter('goodspots','spots_non-ice','ice_ring_test')
    fstats['ice-ring_impact'] = sf.nicerings()
    fstats['ice-ring_bounds'] = [(sf.icerings[i].lowerresol,sf.icerings[i].upperresol)
      for i in range(fstats['ice-ring_impact']) ]

    #**********************************************************************
    #  Known parts of code that are inefficient: use 35000-spot HK97 example
    #  1. 3.8 seconds: sorting the resolution spots (item #4 in tnear2) (Corrected)
    #  2. 9.7 seconds: spreadsheet bookkeeping; method2_resolution.py, xrow loop (Partly corrected 5/09)
    #  3. 4.4 seconds: ice2::RingFinder::filtered()  (Corrected)

    # 3. omit spots too close to the beamstop
    if self.two_theta_degrees==0.0:
      fstats.c_spot_filter('spots_non-ice','hi_pass_resolution_spots',
                                         'resolution_test',
                                         arguments=[mm_minimum_radius,])
    else:
      fstats.precompute_resolution(
        self.two_theta_degrees * math.pi / 180., #two theta radians
        pd['endstation'].rotation_axis(),
        pd['endstation'].camera_convention())

      fstats.c_spot_filter('spots_non-ice','hi_pass_resolution_spots',
                                           'resolution_test_nztt',
                          arguments=[self.phil_params.distl_lowres_limit])


    if VERBOSE_COUNT:
      print("after lowres filter",fstats["N_hi_pass_resolution_spots"])
#start here.
#In the end, make sure these work:
#interface with mosflm: "TWOTHETA" keyword fails; "TILT" fix works with fudge factor
#James Holton's spots index (make unit test); anything with resolution_mm
#diffimage display!:  ring_markup() method of webice_support/__init__
#report the two theta value in stats index
    # 4. Calculate resolution cutoff
    if self.two_theta_degrees==0.0:
      sorted_order,sorted_resolutions = fstats.resolution_sort(
      "hi_pass_resolution_spots")
    else:
      sorted_order,sorted_resolutions = fstats.resolution_sort_nztt(
      "hi_pass_resolution_spots")
    # targetBinNumber: first try number of candidate Bragg spots per bin
    targetBinNumber = max(self.BinMin, len(sorted_order)//20)

    # cutoff threshhold: expected number spots in highest resolution bin
    cutoff_ratio = 100./self.phil_params.distl.method2_cutoff_percentage
    fstats['resolution_divisor']=cutoff_ratio
    lowerCutoffBinNumber = targetBinNumber / cutoff_ratio

    if len(sorted_order) < targetBinNumber:
      # So few spots that there is only one bin
      # no resolution determination possible
      fstats['resolution'] = None
      fstats['resolution_detail'] = len(sorted_order)

    elif False and sorted_resolutions[self.BinMin-1] < 4.0:
      '''This filter (that essentially says you must have low
      resolution spots) hindered the ability to index the case
      ana/procrun0000084148/sphN1_*.mar2300.  Further investigation
      showed that not a single one of the 94 reference cases in the
      regression database was affected by this test, so the test is
      being provisionally removed.  It is not known if the test has a
      beneficial effect on cases with no protein diffraction, i.e., just
      ice rings.'''
      # This test indicates that there are so few spots at low
      #  resolution that the first bin extends past 4.0 Angstroms,
      #  into the region where ice rings might be found
      #  since there are too few low resolution data
      #  conclude that these are false Bragg spots
      fstats['resolution'] = None
      sorted_resolutions=[]
      # deprecated; would need to be recoded:
      fstats['N_spots_resolution'] = 0

    else:
      from spotfinder.diffraction.geometry import Geom2d
      frac_calc = Geom2d(pd)
      #spot-based ice-ring filtering, added Aug 2004
      '''The case ana/procrun0000084148/sphN1_*.mar2300 (image 090) shows the
      limits of this filter as presently implemented.  In that particular
      case, this ice-ring filter eliminates spots from a large area in the
      2-3 Angstrom resolution range.  However, to be believed, the purported
      ice-spots should define a circle or ellipse centered at the beam position
      with a resolution spread that is very narrow.  Code could be
      written much more effectively to search and elimate these rings'''
      from spotfinder.applications.heuristic_tbx.ice2 import RingFinder
      from spotfinder.applications.heuristic_tbx.ice_nztt import RingFinder_nztt

      if (abs(float(pd['twotheta'])) > 0.0):
        # Very inefficient--8 seconds per call; will need to be optimized
        #PP = Profiler("nztt")
        Ring = RingFinder_nztt(sorted_resolutions,targetBinNumber,frac_calc,
                               image)
        #del PP
      else:
        Ring = RingFinder(sorted_resolutions,targetBinNumber,frac_calc)

      fstats.add_child("hi_pass_resolution_spots",
                       "ice_free_resolution_spots",
                       Ring.filtered(sorted_order))
      fstats['ice-ring_impact'] += Ring.ice_ring_impact()
      fstats['ice-ring_bounds'] += Ring.ice_ring_bounds()

      #*************************the filtering of existing spots

      if VERBOSE_COUNT:
       print("after spot_based ice-ring filter",fstats[
             'N_ice_free_resolution_spots'])

      if fstats['N_ice_free_resolution_spots'] < targetBinNumber:
        # So few spots that there is only one bin
        # no resolution determination possible
        fstats['resolution'] = None
        fstats['resolution_detail'] = fstats['N_ice_free_resolution_spots']
      else:
        from spotfinder.applications.heuristic_tbx.method2_resolution\
          import ResolutionShells
        sorted_resolutions = fstats.spotfilter.get_resolution(
                             fstats.master,fstats.get_indices('ice_free_resolution_spots'))

        Shell = ResolutionShells(sorted_resolutions,
          sorted_resolutions[targetBinNumber-1],frac_calc)
        #Shell.show()

        if self.phil_params.distl.bins.verbose:
          ShellR = spotreporter(sorted_resolutions,self.phil_params,
            sorted_resolutions[targetBinNumber-1],
            wavelength = float(pd['wavelength']),
            max_total_rows=self.phil_params.distl.bins.N,
            fractionCalculator=frac_calc,
            use_binning_of=self)
          ShellR.total_signal(fstats,fstats.get_indices('ice_free_resolution_spots'))
          ShellR.background(sf)
          ShellR.sigma_analysis()
          print()
          ShellR.show(message="Analysis of spots after ice removal, but prior to resolution cutoff, for image \n%s"%pimage.filename)
          self.reporters[framenumber].append(ShellR)

        # slight adjustment so that we don't focus on the lowest
        #  resolution data shell (spends too much time in Ewald sphere)
        #  But don't make this adjustment if we are limited by low spot count
        if Shell.rows() > 2 and \
            Shell.Population[1] > 2*lowerCutoffBinNumber and \
            Shell.Population[1] > self.BinMin:
          lowerCutoffBinNumber = Shell.Population[1] / cutoff_ratio

        # first determination of cutoff ignoring corner effect
        for x in range(Shell.rows()):
          idx = Shell.rows()-x-1
          if Shell.Population[idx] > lowerCutoffBinNumber:
            lastshell = idx
            break

        # eliminate pathological case where there are a lot of low resolution
        # spots and then some ice rings at high resolution.  If there are ten
        # empty shells in a row (empty defined as having fewer than
        # VetterCut spots), redetermine lastshell.
        #
        # Originally, VetterCut := lowerCutoffBinNumber
        # Modify the heuristic to cover two extremes:
        # Case 1.  Based on the HK97 virus work; there is a class of diffraction
        #    cases showing a distinct dip in diffraction intensity in the
        #    5-Angstrom regime.  If lowerCutoffBinNumber is used (usually
        #    20% of the spot count in the 2nd bin), the algorithm can
        #    misbehave and reject all the high-resolution Bragg spots.
        #    For one case in particular a tiny change in beam position
        #    flips the resolution cutoff from a 6.5- to 4.4-Angstrom.
        # Case 2.  There are many cases where the diffraction clearly
        #    drops off, and at higher resolutions there are random-signal
        #    spots plus ice rings.  The spot count in these high-res bins
        #    is typically small, <20.  Use "20" as a heuristic cutoff
        #    between Case 1 & Case 2.
        # In future, it may be productive to focus on smarter algorithms to
        # execute ellipse recognition in the "Ringfinder" section above

        if lowerCutoffBinNumber <= 20:
          VetterCut = lowerCutoffBinNumber
        else:
          VetterCut = 20 + lowerCutoffBinNumber // 5
        lastshell = Shell.vetter(VetterCut,lastshell)

        #option for overriding the resolution analysis based on falloff
        # of spot count.  Force spots at least this far out
        if self.phil_params.force_method2_resolution_limit is not None:
          for x in range(Shell.rows()):
            if Shell.Limit[x]<self.phil_params.force_method2_resolution_limit and lastshell<x:
              lastshell = x
              break

        # extend resolution cutoff taking into account corner cutoff
        while Shell.Fract[lastshell] < 1.0 and lastshell+1 < Shell.rows():
          nextshell = lastshell+1
          if Shell.adjustPop[nextshell] > lowerCutoffBinNumber:
            lastshell+=1
          else: break

        fstats['resolution'] = Shell.Limit[lastshell]
        if self.phil_params.distl_highres_limit!=None:
           fstats['resolution']=max(fstats['resolution'],
             self.phil_params.distl_highres_limit)

        for x in range(lastshell+1):
          if self.phil_params.spotfinder_verbose: print("(%.2f,%d)"%(Shell.Limit[x],Shell.Population[x]))

        if self.two_theta_degrees==0.0:
          fstats.c_spot_filter(          #hi-resolution radius
          'ice_free_resolution_spots',
          'lo_pass_resolution_spots',
          'lo_pass_resolution_test',
          arguments=[resol_to_radius(fstats['resolution'],self.pd),])
        else:
          fstats.c_spot_filter(          #hi-resolution radius
          'ice_free_resolution_spots',
          'lo_pass_resolution_spots',
          'lo_pass_resolution_test_nztt',
          arguments=[fstats['resolution'],])

        if VERBOSE_COUNT:
          print("ice_free_resolution_spots ",fstats['N_ice_free_resolution_spots'])

        fstats['shells']=Shell

        if VERBOSE_COUNT:
          print("after resolution-shell cutoff",fstats['N_lo_pass_resolution_spots'])
        fstats['resolution_mm']=resol_to_radius(fstats['resolution'],pd)

    fstats['saturation'] = self.calculate_saturation(fstats,image)

    if self.phil_params.distl.bins.verbose:
     try:
      subset = fstats.spotfilter.get_resolution(
               fstats.master,fstats.get_indices('lo_pass_resolution_spots'))
      ShellR = spotreporter(subset,self.phil_params,use_binning_of=self)
      ShellR.total_signal(fstats,fstats.get_indices('lo_pass_resolution_spots'))
      ShellR.background(sf)
      ShellR.sigma_analysis()
      print()
      ShellR.show(message="Analysis of spots after resolution filtering, but prior to spot quality heuristics, for image \n%s"%pimage.filename)
      self.reporters[framenumber].append(ShellR)

     except Exception: # in case the low-pass filter step was skipped; e.g., blank image.
      pass

    # 5. eliminate multi-modal spots & punctate spots
    fstats.c_spot_filter(
      fstats.most_recent_child(),
      'spots_unimodal',
      'modal_test',
      arguments=[self.phil_params.distl_profile_bumpiness,
                 self.phil_params.distl.minimum_spot_area or sf.spotbasesize()])
      # parameters are bumpiness(max number of local maxima in peak),minimum pixels

    if VERBOSE_COUNT: print("not bumpy & not punctate",fstats['N_spots_unimodal'])

    # 6. Compute distributions for outlier rejection
    #Y = Timer("Inliers")#try to get this down from 232 seconds to 8 seconds
                         #(For HK97 sz=4)

    inlier_idx_raw = flex.int()
    inlier_neigh=[]
    unimodal_spots = fstats['spots_unimodal']

    if fstats['N_spots_unimodal']>2: # avoids divide-by-zero error in stats calls, below
      intensities = flex.double([s.intensity() for s in unimodal_spots])
      areas       = flex.double([s.bodypixels.size() for s in unimodal_spots])
      # Deprecate shapes because code is unstable; in rare cases spots can have
      # body pixels but no border pixels ( RAW/APS_07_2005/pEI4/pEI4_8_1.0001 )
      #shapes      = flex.double([s.shape() for s in unimodal_spots])
      eccentricity= flex.double([s.model_eccentricity() for s in unimodal_spots])
      skewness    = fstats.get_property(fstats.most_recent_child(),'skewness')

      fstats['intensity'] = (i_ave,i_std) = scitbx_stats(intensities)
      fstats['area']      = (a_ave,a_std) = scitbx_stats(areas)
      #fstats['shape']     = (s_ave,s_std) = scitbx_stats(shapes)
      fstats['eccen']     = (e_ave,e_std) = scitbx_stats(eccentricity)
      fstats['skewness']  = (k_ave,k_std) = scitbx_stats(skewness)

      #Filtering on skewness is important when using center-of-mass positions
      # for autoindexing.  The goal is to eliminate pairs of unresolved Bragg
      # spots.  Condition is flagged when the max_pixel to center-of-mass
      # vector is more than 45% of the semi-major axis
      fstats.c_spot_filter(
          fstats.most_recent_child(),
          'spots_low_skew',
          'low_skew',
          arguments=[min(0.45, 2.0 * k_std + k_ave),])

      #Filter on the intensity distribution.
      fstats.c_spot_filter(
          fstats.most_recent_child(),
          'spots_good_intensity',
          'intensity_inlier',
          arguments=[i_ave - 5.0*i_std, i_ave + 5.0*i_std, image.saturation,])

      #special code for expecting a high MOSFLM RESID based on the
      # presence of very high signal/noise ratio (essentially lysozyme strength).
      # This is all just a supposition based on one dataset, offset_1 from Ana.
      # The assumption may be wrong; e.g. the high resid may be due to very low
      # background instead of high s/n; or due to some geometrical distortion.
      #This breaks encapsulation and will have to be re-organized in the future.
      if 'special_resid' not in pd: pd['special_resid']=''
      if fstats['intensity'][0]>160.: pd['special_resid']='RESID 10.0 #High s/n'
      #The most unusual thing about the procrun0000077831/TMC114_WT2_run77831_1_001
      #dataset is its large differential between spot areas of the largest spots
      # and the smallest spots.  Hypothesize that this also leads to high
      # weighted residuals.
      if stats_profile(areas)>10.: pd['special_resid']='RESID 10.0 #High s/n'

      from annlib_ext import AnnAdaptor
      data = fstats.get_property('goodspots',
             self.phil_params.distl_spotcenter_algorithm)
      query = fstats.get_property(fstats.most_recent_child(),
              self.phil_params.distl_spotcenter_algorithm)

      A = AnnAdaptor(data,2)       # construct k-d tree for reference set
      A.query(query)               # find nearest neighbors of query points

      neighbors = (self.pixel_size) * flex.sqrt(A.distances)

      """Explanation: Distance to the nearest neighbor is math.sqrt(A.distances[i]), in
         units of pixels.  The vector to the nearest neighbor, in units of pixels, is
         ( fstats.master[A.nn[i]].x()-query[2*i], fstats.master[A.nn[i]].y()-query[2*i+1])
      """

      fstats['neighbor']  = (n_ave,n_std) = scitbx_stats(neighbors)

      sep_input_spots = fstats[fstats.most_recent_child()]
      sep_input_indices = fstats.get_indices(fstats.most_recent_child())

      overlapping_count = 0
      for idx in range(len(sep_input_spots)):
        try:
          if float(pd['pixel_size'])*sep_input_spots[idx].majoraxis() * \
             self.phil_params.overlapping_spot_criterion > neighbors[idx]:
            overlapping_count+=1
        except Exception:
          pass
      if len(sep_input_spots)==0: percent_overlap = 0
      else: percent_overlap = 100*overlapping_count/len(sep_input_spots)
      #print "overlap %2.0f%% vs. cutoff %2.0f%%"%(percent_overlap,self.phil_params.percent_overlap_forcing_detail)

      from spotfinder.core_toolbox.close_spots_detail import NearNeighborVectors
      Afull = AnnAdaptor(data,2)
      Afull.query(data)
      NV = NearNeighborVectors(ave_area = a_ave, query_centers = data,
                               fstats = fstats, ann_adaptor = Afull)
      #NV.show_vector_map()
      #NV.show_maxima()

      DEVELOP_ASSERT = True
      self.force_detail = percent_overlap > self.phil_params.percent_overlap_forcing_detail
      if DEVELOP_ASSERT or self.force_detail:
        self.overlapping = True
        #extraordinary procedure, when many spots are close.  Include closely
        #  spaced spots in autoindexing, if it appears that they truly
        #  reflect lattice spacing.
        if self.phil_params.spotfinder_verbose:
          print(len(sep_input_spots),"spot count before close neighbor analysis;", end=' ')
          print(overlapping_count,"(%2.0f%%) rejected on neighbors;"%(percent_overlap))

        pmax = NV.vectors()
        #filter out spots that are potentially large enough to contain
        #two spots, now that we know a candidate projected unit-cell vector
        # expect big time savings if this section is pushed down to C++
        compact_idx = []

        if 0<len(pmax)<=3:
          sq_vectors = [v[0]*v[0] + v[1]*v[1] for v in pmax]
          for idx in range(len(sep_input_spots)):
            spot_compact = True
            for iv,vector in enumerate(pmax):
              thisspot = sep_input_spots[idx]
              #more efficient code--disallowed spots (based on nearest neighbor
              # vector) are now flagged based on the width of the ellipse model
              # rather than a more time-consuming body-pixel match:

              #calculate angle theta between major axis and neighbor vector
              dot = thisspot.eigenvector(1)[0]*vector[0] + thisspot.eigenvector(1)[1]*vector[1]
              costheta = dot / math.sqrt(sq_vectors[iv])
              costhetasq = min(costheta*costheta,1.0)
              sintheta = math.sqrt(1 - costhetasq)
              spota = thisspot.a()
              spotb = thisspot.b()
              a_sin_theta = spota * sintheta
              b_cos_theta = spotb * costheta
              #evaluate the ellipse full width along neighbor vector direction
              width_sq = 4.*(spota*spota*spotb*spotb/
                (a_sin_theta*a_sin_theta + b_cos_theta*b_cos_theta) )
              if width_sq >= sq_vectors[iv]:
                spot_compact = False
                break

            if spot_compact: compact_idx.append(idx)
            else: pass #print "eliminate the spot at",thisspot.x(),thisspot.y()
        else:
          compact_idx = range(len(sep_input_spots))
        if self.phil_params.spotfinder_verbose: print(len(sep_input_spots)-len(compact_idx),"large spots rejected")

        # finally, allow certain close spots (but not all of them) to be included
        for idx in compact_idx:
          try:
            S =  ( int( fstats.master[A.nn[idx]].max_pxl_x()-query[2*idx] ),
                   int( fstats.master[A.nn[idx]].max_pxl_y()-query[2*idx+1]) )
            #accept spot by default
            reject_spot = False
            #if close to nearest neighbor reject
            if sep_input_spots[idx].majoraxis() * \
               self.phil_params.overlapping_spot_criterion > math.sqrt(S[0]*S[0]+S[1]*S[1]):
               # with normal procedure, spot would be rejected at this point
               reject_spot = True
               if len(pmax)<=3:
                 for vector in pmax:
                   if abs(vector[0]-S[0])<=1 and abs(vector[1]-S[1])<=1:
                     #but allow if the proximity is to a candidate cell near neighbor
                     reject_spot=False
                     break
            if reject_spot: continue

            inlier_idx_raw.append(sep_input_indices[idx])
            inlier_neigh.append(neighbors[idx])
          except Exception:pass

        if self.phil_params.spotfinder_verbose:
          print(len(compact_idx)-len(inlier_idx_raw),"close spots rejected")
          print(len(sep_input_spots),"input for spot separation analysis;", end=' ')
          jj = len(sep_input_spots)-len(inlier_idx_raw)
          print(jj,"(%2.0f%%) rejected on special criteria;"%(100.*jj/len(sep_input_spots)))

      else: #normal procedure, assuming not too many close spots
        for idx in range(len(sep_input_spots)):
          try:
            if math.fabs(intensities[idx]-i_ave) <= 5.0*i_std and \
               intensities[idx]<image.saturation and \
               float(pd['pixel_size'])*sep_input_spots[idx].majoraxis() * \
               self.phil_params.overlapping_spot_criterion<=neighbors[idx]:
               inlier_idx_raw.append(sep_input_indices[idx])
               inlier_neigh.append(neighbors[idx])
          except Exception:
            #print "REJECT spot on exception"
            pass #sometimes throw an error when majoraxis is requested (edge spots)

        if len(inlier_idx_raw)<self.NspotMin:
          for idx in range(len(sep_input_spots)):
            try:
              proximal_radius = 2.0 * self.phil_params.overlapping_spot_criterion * float(pd['pixel_size'])*sep_input_spots[idx].majoraxis()
              if math.fabs(intensities[idx]-i_ave) <= 5.0*i_std and \
                 intensities[idx]<image.saturation and \
                 float(pd['pixel_size'])*sep_input_spots[idx].majoraxis() *self.phil_params.overlapping_spot_criterion > neighbors[idx] and \
                 sf.isIsolated(sep_input_spots[idx],proximal_radius):
                 #print "Very few Bragg spots; forced to accept spot with neighbor distance",neighbors[idx]/(float(pd['pixel_size'])*sep_input_spots[idx].majoraxis())
                 inlier_idx_raw.append(sep_input_indices[idx])
                 inlier_neigh.append(neighbors[idx])
            except Exception:
              print("REJECT spot on exception")
              pass #sometimes throw an error when majoraxis is requested (edge spots)

    if fstats.has_extended_key('lo_pass_resolution_spots'):
      fstats.alias('lo_pass_resolution_spots','spots_resolution')
    elif fstats.has_extended_key('ice_free_resolution_spots'):
      fstats.alias('ice_free_resolution_spots','spots_resolution')
    else:
      fstats.alias('hi_pass_resolution_spots','spots_resolution')

    fstats.add_child('spots_unimodal','spots_separated',
                     inlier_idx_raw)

    fstats.alias(fstats.most_recent_child(),'spots_inlier')
    fstats.alias('spots_inlier','inlier_spots')#for backward compatibility

    if self.phil_params.distl.bins.verbose:
     try:
      subset = fstats.spotfilter.get_resolution(
               fstats.master,fstats.get_indices('inlier_spots'))
      ShellR = spotreporter(subset,self.phil_params,use_binning_of=self)
      ShellR.total_signal(fstats,fstats.get_indices('inlier_spots'))
      ShellR.background(sf)
      ShellR.sigma_analysis()
      print()
      ShellR.show(message="Analysis of good Bragg spots after quality heuristics, for image \n%s"%pimage.filename)
      self.reporters[framenumber].append(ShellR)

     except Exception:
      pass #if there aren't enough spots, just skip the tabular printout

    if 'masks' not in pd:  pd['masks']={}
    pd['masks'][framenumber] = None
    if fstats['N_spots_inlier'] > ( #guard against C++ hard-coded minimum
      self.phil_params.codecamp.minimum_spot_count or 25):
      Msk = fstats.single_mask('inlier_spots',self.phil_params)
      pd['masks'][framenumber] = [Msk.x,Msk.y]

    if VERBOSE_COUNT: print("inlier spots",fstats["N_inlier_spots"])

    #need this for later calculation of maxcell
    fstats['neighbors'] = flex.double(inlier_neigh)

    return fstats

  def calculate_saturation(self,fstats,image):
    S = SaturationMeasure()
    resolution_spots = fstats[fstats.most_recent_child()]
    S.n_resolution_spots = len(resolution_spots)
    S.n_goodspots = fstats['N_goodspots']
    ispots = flex.int()
    for i in range(S.n_resolution_spots):
      spt = resolution_spots[i]
      ispots.append( image.linearintdata[(spt.max_pxl_x(),spt.max_pxl_y())] )
    S.OverCount = (ispots >= int(image.saturation)).count(True)
    perm = flex.sort_permutation(ispots,True)
    spot_peaks = flex.int([ispots[p] for p in perm[0:min(50,len(perm))]])
    S.n_sample = len(spot_peaks)
    if S.n_sample < 2: #no peaks on the image
      S.p_saturation = 0.0; return S
    S.average = float(reduce(lambda x,y:x+y, spot_peaks))/len(spot_peaks)
    S.p_saturation = S.average/image.saturation
    # for Raxis-II and Mar Image Plates, it has been noticed that image.linearintdata
    # can contain pixel values greater than image.saturation.  No doubt this is
    # a shortcoming in how the pixel values are decoded for overloaded values (not fixed)
    return S

  def show(self):
    for frame in self.images.keys():
      for key in ['N_spots_total','N_spots_non-ice','N_spots_resolution','N_spots_unimodal',
                  'N_spots_inlier','intensity','area',
                  'neighbor','maxcel','resolution',
                  'distl_resolution','ice-ring_impact']:
        if self.images[frame].has_extended_key(key):
          print("\t"+key,self.images[frame][key])
      for key in ['eccen']:
          if self.images[frame].has_extended_key(key):
            print("\t"+key,self.images[frame][key])

  def determine_maxcell(self,frame,pd):
    if self.phil_params.codecamp.maxcell != None:
      self.images[frame]['maxcel']=self.phil_params.codecamp.maxcell
      return
    if self.images[frame]['N_spots_inlier']>2:
      neighbors   = self.images[frame]['neighbors']
      n_ave,n_std = scitbx_stats(neighbors)

      average_nearest_neighbor = n_ave

      NNBIN = self.NspotMin//2 # recommended bin size for nearest neighbor histogram
      peak_of_interest = n_ave

      for pss in range(1):  #make two passes thru histo

        fineness = max( [self.pixel_size / 2.,
          peak_of_interest / (1.0+float(len(neighbors))/float(NNBIN))] )
        min_neighbors = min(neighbors)

        def histo_index_to_mm(index):
          return min_neighbors+index*fineness

        #neighbor_histogram
        histogram = [0]*int(peak_of_interest*4/fineness)
        for y in neighbors:
          ibin = int( (y-min_neighbors)/fineness )
          if ibin < len(histogram):
            histogram[ibin]+=1

        if TALLY2:
          for row in range(len(histogram)):
            low = histo_index_to_mm(row)
            hi  = histo_index_to_mm(row+1)
            print("%.2f to %.2f, %5.1f Ang"%(low,hi,radius_to_resol(histo_index_to_mm(row+.5),pd)), end=' ')
            print("*"*histogram[row], end=' ')
            print()

        most_probable_neighbor = histo_index_to_mm(0.5 + histogram.index(max(histogram)))

        #Compute yet another measure of unit cell--first peak in histogram
        peak1 = 0; peak1i = 0
        for peakpt in range(len(histogram)):
          if histogram[peakpt]>peak1i:
            peak1=peakpt; peak1i=histogram[peakpt]
          if histogram[peakpt]<0.5*peak1i and peak1i> 0.1*(max(histogram)):
            break

        first_peak_if_any = histo_index_to_mm(0.5 + peak1)
        peak_of_interest = min(first_peak_if_any,most_probable_neighbor)

        # Another trial measure: 5th percentile neighbor
        sort_perm = flex.sort_permutation(neighbors)
        cutoff_mm = neighbors[sort_perm[ int(0.05*len(sort_perm)) ]]

      #Caveat: this rough calculation becomes less accurate for non-zero two-theta
      self.images[frame]['neighboring_spot_separation']=min(most_probable_neighbor , cutoff_mm)
      MAXTOL = 1.5 # Margin of error for max unit cell estimate
                   # 11/19/02 old value 1.4; new value 2.0 to accomodate a
                   #   pathological case where zone is down the large unit cell.
                   #   Larger value is now tolerable because of post-mosflm
                   #   check for systematic absences.
                   # 9/28/03 change back to 1.5 with new autoindexer because
                   #   value of 2.0 can (infrequently) lead to misindexing;
                   #   based on experience preparing figure 4.
      maxcell = max(MAXTOL * radius_to_resol(most_probable_neighbor,pd),
                    0.0    * radius_to_resol(min(neighbors),pd),
                    0.0    * radius_to_resol(first_peak_if_any,pd),
                    MAXTOL * radius_to_resol(cutoff_mm,pd))
      self.images[frame]['maxcel']=maxcell

  def setError(self,newmessage):
    if self.errormessage == None: self.errormessage=newmessage

  def get_resolution_inspection(self):
    all_frames = self.images.keys()
    all_resolutions=flex.double([self.images[f]['resolution'] for f in all_frames])
    ave_resolution=flex.mean(all_resolutions)
    self.pd['resolution_inspection']='%f'%(ave_resolution)
    return self.pd['resolution_inspection']


 *******************************************************************************


 *******************************************************************************
spotfinder/applications/signal_strength.py
from __future__ import absolute_import, division, print_function
from spotfinder.array_family import flex
from spotfinder.applications.wrappers import DistlOrganizer

class Empty: pass

def run_signal_strength(params):
  E = Empty()
  E.argv=['Empty']
  E.argv.append(params.distl.image)
  return run_signal_strength_core(params,E)

def run_signal_strength_core(params,E):
  verbose = params.distl.verbose
  if params.distl.res.inner!=None:
    params.distl_lowres_limit = params.distl.res.inner
  if params.distl.res.outer!=None:
    params.force_method2_resolution_limit = params.distl.res.outer
    params.distl_highres_limit = params.distl.res.outer

  params.distl_force_binning = False
  params.distl_permit_binning = False
  params.wedgelimit = len(E.argv)
  params.spotfinder_header_tests = False
  Org = DistlOrganizer(verbose = True, argument_module=E,
                       phil_params=params)
  Org.printSpots()

  #Image analysis requested by NE-CAT (Point of contact: Craig Ogata)
  for key in Org.S.images.keys():
    # List of spots between specified high- and low-resolution limits
    if Org.S.images[key].has_extended_key('lo_pass_resolution_spots'):
      spots = Org.S.images[key]['lo_pass_resolution_spots']
    elif Org.S.images[key].has_extended_key('inlier_spots'):
      spots = Org.S.images[key]['inlier_spots']
    else:
      spots = []

    saturation = Org.Files.imageindex(key).saturation

    #Total number of spots in this range
    print()
    print("Number of focus spots on image #%d within the input resolution range: %d"%(
      key,len(spots)))

    signals=flex.double()
    saturations=flex.double()

    #Each spot
    for i,spot in enumerate(spots):
     signals.append(flex.sum(spot.wts))
     saturations.append(flex.max(spot.wts)/saturation)
     if verbose:
      #peak height given in ADC units above local background
      #integrated signal strength given in pixel-ADC units above local background
      print("%2d: Area in pixels=%d Peak=%.1f, Total integrated signal=%.1f (in pixel-ADC units above background)"%(
        i, spot.area(), flex.max(spot.wts), flex.sum(spot.wts)))

      #peak signal-to-noise expressed in standard deviations above local background
      print("    Peak signal-to-noise=%.1f"%(spot.intensity()))

      #peak height expressed in ADC units, without background subtraction
      image = Org.Files.imageindex(key)
      print("    Peak position x=%4d y=%4d (pixels); pixel value=%5d"%(
        spot.max_pxl_x(), spot.max_pxl_y(),
        image.linearintdata[(spot.max_pxl_x(),spot.max_pxl_y())]))

      #Gory detail, looping through each pixel on each spot
      for j,pixel in enumerate(spot.bodypixels):
        print("       body pixel x=%4d y=%4d; pixel value=%5d; ADC height above background=%.1f"%(
          pixel.x,pixel.y,image.linearintdata[(pixel.x,pixel.y)],spot.wts[j]))
    if signals.size()>0:
      print("Total integrated signal, pixel-ADC units above local background (just the good Bragg candidates) %d"%(
            flex.sum(flex.double([flex.sum(spot.wts) for spot in Org.S.images[key]['inlier_spots']]))
      ))
      print("Signals range from %.1f to %.1f with mean integrated signal %.1f"%(
      flex.min(signals), flex.max(signals), flex.mean(signals) ))
      print("Saturations range from %.1f%% to %.1f%% with mean saturation %.1f%%"%(
      100.*flex.min(saturations), 100.*flex.max(saturations), 100.*flex.mean(saturations) ))

  if params.distl.pdf_output != None:
    #later, put this in a separate module so reportlab is not imported unless requested
    from labelit.publications.sublattice.sublattice_pdf import SublatticePDF,graphic
    from labelit.publications.sublattice.sublattice_pdf import PointTransform
    class genPDF(SublatticePDF):
      def make_image_plots_detail(self):
         params.pdf_output.window_fraction=1.0
         params.pdf_output.window_offset_x=0.0
         params.pdf_output.window_offset_y=0.0
         params.pdf_output.markup_inliers=True
         couple=(params.pdf_output.window_offset_x,
                 params.pdf_output.window_offset_y)
         #instead of self.R.setTransform, which requires pickled spotfinder:
         self.R.T = PointTransform()
         self.R.S = self.R.spotfinder
         self.R.T.setImage(spotfinder=self.R.S,subwindow_origin=couple,commands=params)
         self.R.title(self.image_name)
         #try:
         pil_image = graphic(filein = self.image_name,
                             couple = couple,
                             commands = params)
         self.R.image(pil_image)
         #except:
         #  print "failure, file %s"%self.filename
         if params.pdf_output.markup_inliers:
           self.R.show_ellipse(
           image_number=list(self.R.spotfinder.images.keys())[0],
           tags = ['goodspots','spots_non-ice','hi_pass_resolution_spots',
                    'spots_unimodal'],
           detail=True)
         self.R.c.showPage()
         return self
    pdf = genPDF(params.distl.pdf_output)
    pdf.filename = params.distl.pdf_output
    pdf.image_name = params.distl.image
    pdf.set_spotfinder(Org.S)
    pdf.make_image_plots_detail()

  if params.distl.image_viewer == True:
    try:
      from rstbx.viewer.spotfinder_wrap import spot_wrapper
      spot_wrapper(params).display(path = params.distl.image,
                                   organizer = Org)
    except ImportError as e:
      from libtbx.utils import Sorry
      # must use phenix.wxpython for wx display
      raise Sorry(str(e)+" Try setting env variable PHENIX_GUI_ENVIRONMENT=1")

  return Org


 *******************************************************************************


 *******************************************************************************
spotfinder/applications/stats_distl.py
from __future__ import absolute_import, division, print_function

def pretty_filename(spotfinder,key):
  nwildcard = spotfinder.pd['template'].count('#')
  template_f='#'*nwildcard
  extensn_f='%%0%dd'%nwildcard
  if nwildcard > 0:
    return spotfinder.pd['template'].replace(template_f,extensn_f%key)
  else:
    return spotfinder.pd['template']

def optionally_add_saturation(canonical_info,image):
  if image.has_extended_key('saturation'):
    sat_info = ("%6s",image['saturation'].message(),
                      image['saturation'].format())
    canonical_info.append(sat_info)

    sat_info = ("%6s",image['saturation'].message2(),
                      image['saturation'].format2())
    canonical_info.append(sat_info)

def optionally_add_saturation_webice(canonical_info,image):
  if image.has_extended_key('saturation'):
    sat_info = ("%5s %%",image['saturation'].message().split("%")[1],
                      "%.1f"%(100*image['saturation'].p_saturation))
    canonical_info.append(sat_info)

    sat_info = ("%7s","In-resolution overloaded spots",
                      image['saturation'].format2())
    canonical_info.append(sat_info)

def key_adaptor(mapping,key,idx=None):
  if mapping.has_extended_key(key):
    if idx == None:
      return mapping[key]
    else: return mapping[key][idx]
  else:
    return None

def key_safe_items(image):
  return [
      ("%6d","Spot Total",key_adaptor(image,'N_spots_total')),
      ("%6d","Remove Ice",key_adaptor(image,'N_ice_free_resolution_spots')),
      ("%6d","In-Resolution Total",key_adaptor(image,'N_spots_resolution')),
      ("%6d","Good Bragg Candidates",key_adaptor(image,'N_spots_inlier')),
      ("%6d","Ice Rings",key_adaptor(image,'ice-ring_impact')),
      ("%6.2f","Method 1 Resolution",key_adaptor(image,'distl_resolution')),
      ("%6.2f","Method 2 Resolution",key_adaptor(image,'resolution')),
      ("%6.1f","Maximum unit cell",key_adaptor(image,'maxcel')),
      ("%7.3f ","<Spot model eccentricity>",key_adaptor(image,'eccen',0)),
  ]

def key_safe_items_webice(image):
  return [
      ("%7d","Initial spot picks (yellow/green)",key_adaptor(image,'N_spots_total')),
      ("%7d","Good Bragg candidates (green)",key_adaptor(image,'N_spots_inlier')),
      ("%7.3f ","Average spot model eccentricity",key_adaptor(image,'eccen',0)),
      ("%7d","Ice rings (orange)",key_adaptor(image,'ice-ring_impact')),
      ("%5.1f &#197","Resolution estimate before indexing",key_adaptor(image,'resolution')),
      ("%5.0f &#197","Maximum unit cell edge",key_adaptor(image,'maxcel')),
  ]

def pretty_image_stats(Spotfinder,key):
    print()
    image = Spotfinder.images[key]

    canonical_info = [
      ("%s","File",pretty_filename(Spotfinder,key)),
    ]

    canonical_info.extend(key_safe_items(image))

    optionally_add_saturation(canonical_info,image)

    for item in canonical_info:
      if item[2]==None:
        print("%25s : None"%item[1])
      else:
        print("%25s : %s"%(item[1],item[0]%item[2]))

def webice_image_stats(Spotfinder,key):
    from six.moves import StringIO
    image = Spotfinder.images[key]
    canonical_info = []
    canonical_info.extend(key_safe_items_webice(image))
    optionally_add_saturation_webice(canonical_info,image)
    g = StringIO()
    for item in canonical_info:
      if item[2]==None:
        print("%35s: None"%item[1], file=g)
      else:
        print("%35s: %s"%(item[1],item[0]%item[2]), file=g)
    ibinfac = int(Spotfinder.pd['binning'])
    if ibinfac > 1:
      print("\nImage was processed with %1dx%1d pixel binning\n to increase Viewer speed."%(ibinfac,ibinfac), file=g)
    return g.getvalue()

def notes(Spotfinder,key):
    print()
    image = Spotfinder.images[key]
    if image.has_extended_key('resolution_divisor'):
      print("Bin population cutoff for method 2 resolution: %.0f%%"%(
        100./image['resolution_divisor']))

if __name__=='__main__':
  Spotfinder = unpickle_spotfinder()

  for key in Spotfinder.pd['osc_start'].keys():
    pretty_image_stats(Spotfinder,key)
  notes(Spotfinder,list(Spotfinder.pd['osc_start'].keys())[0])


 *******************************************************************************


 *******************************************************************************
spotfinder/applications/wrappers.py
from __future__ import absolute_import, division, print_function
import os
from spotfinder.applications.stats_distl import pretty_image_stats,notes

def spotfinder_factory(absrundir,frames,phil_params):

  local_frames=frames.frames()

  A = frames.images[0]
  #A.readHeader()--deprecate this because it squashes any overrides
  #                from dataset_preferences processed in imagefiles.py
  pd = {'directory':frames.filenames.FN[0].cwd,
        'template': frames.filenames.FN[0].template,
        'identifier':frames.filenames.FN[0].fileroot,
        'vendortype':A.vendortype,
        'binning':'%d'%A.bin,
        'distance':'%f'%A.distance,
        'wavelength':'%f'%A.wavelength,
        'deltaphi':'%f'%A.deltaphi,
        }

  #temp values for getting coordinate convention
  pd['pixel_size']='%f'%A.pixel_size
  pd['size1']='%f'%A.size1
  pd['size2']='%f'%A.size2
  pd['ybeam'] = '%f'%A.beamy
  pd['xbeam'] = '%f'%A.beamx
  try:
    pd['twotheta'] = '%f'%A.twotheta
  except Exception:
    pd['twotheta'] = '0.0'

  from spotfinder.applications.practical_heuristics import heuristics_base
  Spotfinder = heuristics_base(pd,phil_params)

  for framenumber in local_frames:
    try:
      assert framenumber in Spotfinder.images
    except Exception:
      Spotfinder.register_frames(framenumber,frames)
      if phil_params.spotfinder_verbose: Spotfinder.show()

  return Spotfinder

def dxtbx_spotfinder_factory(phil_params):

  import dxtbx.format.Registry
  reader = dxtbx.format.Registry.get_format_class_for_file(phil_params.distl.image[0])
  from spotfinder.dxtbx_toolbox.practical_heuristics import heuristics_base
  Spotfinder = heuristics_base(phil_params)
  return Spotfinder

class DistlOrganizer(object):

  def __init__(self,verbose = 0,**kwargs):
    self.rundir = os.getcwd()
    self.verbose = verbose
    self.phil_params = kwargs["phil_params"]
    if self.phil_params.distl.dxtbx:
      self.set_dxtbx_input()
      return
    if 'argument_module' in kwargs:
      # new interface
      self.setCommandInput(kwargs['argument_module'])

  def set_dxtbx_input(self):
    pass

  def setCommandInput(self,argument_module):
    from spotfinder.diffraction.imagefiles import spotfinder_image_files as ImageFiles
    self.Files = ImageFiles(argument_module,self.phil_params)
    self.frames = self.Files.frames()

  def update_spotfinder(self):
    # used by distl.image_viewer
    S = spotfinder_factory(self.rundir,self.Files,self.phil_params)
    self.S = S
    for frame in self.frames:
      if self.verbose:
        pretty_image_stats(S,frame)
        notes(S,self.frames[0])

  def printSpots(self):
    '''spotfinder and pickle implicitly assumes ADSC format'''
    if self.phil_params.distl.dxtbx:
      self.S = S = dxtbx_spotfinder_factory(self.phil_params)
    else:
      self.S = S = spotfinder_factory(self.rundir,self.Files,self.phil_params)
      for frame in self.frames:
        if self.verbose:
          pretty_image_stats(S,frame)
          notes(S,self.frames[0])


 *******************************************************************************


 *******************************************************************************
spotfinder/applications/xfel/__init__.py


 *******************************************************************************


 *******************************************************************************
spotfinder/applications/xfel/correction_vector_plot.py
from __future__ import absolute_import, division, print_function
from six.moves import range
from scitbx import matrix

def vectors(handle,all):
  from scitbx.array_family import flex
  x = flex.double()
  y = flex.double()
  xpred = flex.double()
  ypred = flex.double()
  for line in handle.readlines():
    if line.find("CV ")!=0: continue
    tokens = line.split()
    obscen = matrix.col((float(tokens[2]),float(tokens[3])))
    refcen = matrix.col((float(tokens[5]),float(tokens[6])))
    obsspo = matrix.col((float(tokens[8]),float(tokens[9])))
    predspo = matrix.col((float(tokens[11]),float(tokens[12])))
    xpred.append(predspo[0])
    ypred.append(predspo[1])
    prediction = predspo-refcen
    observation = obsspo-obscen
    cv = prediction-observation
    x.append(cv[0])
    y.append(cv[1])

  if all:
    print("Plotting all %d spots one graph."%len(x))
    from matplotlib import pyplot as plt
    plt.plot(x,y,"r.")
    plt.show()
    return

  print(len(x),len(y))
  #from spotfinder.applications.xfel.cxi_run3 import get_initial_cxi_scope
  #print "ONLY FOR RUN 3!!!"
  #params = get_initial_cxi_scope()
  #tiling = params.distl.detector_tiling

  print("ONLY FOR RUN 4!!!")
  tiling = [518, 439, 712, 624, 715, 439, 909, 624, 519, 652, 713, 837, 716, 652, 910, 837, 510, 19, 695, 213, 510, 216, 695, 410, 721, 19, 906, 213, 721, 216, 906, 410, 87, 233, 281, 418, 284, 233, 478, 418, 88, 20, 282, 205, 285, 20, 479, 205, 108, 447, 293, 641, 108, 644, 293, 838, 321, 445, 506, 639, 321, 642, 506, 836, 437, 853, 622, 1047, 437, 1050, 622, 1244, 649, 853, 834, 1047, 649, 1050, 834, 1244, 19, 1069, 213, 1254, 216, 1069, 410, 1254, 18, 856, 212, 1041, 215, 856, 409, 1041, 230, 1282, 415, 1476, 230, 1479, 415, 1673, 16, 1282, 201, 1476, 16, 1479, 201, 1673, 442, 1469, 636, 1654, 639, 1469, 833, 1654, 443, 1257, 637, 1442, 640, 1257, 834, 1442, 852, 1137, 1046, 1322, 1049, 1137, 1243, 1322, 852, 925, 1046, 1110, 1049, 925, 1243, 1110, 1067, 1350, 1252, 1544, 1067, 1547, 1252, 1741, 854, 1352, 1039, 1546, 854, 1549, 1039, 1743, 1280, 1342, 1474, 1527, 1477, 1342, 1671, 1527, 1282, 1554, 1476, 1739, 1479, 1554, 1673, 1739, 1467, 924, 1652, 1118, 1467, 1121, 1652, 1315, 1255, 925, 1440, 1119, 1255, 1122, 1440, 1316, 1142, 521, 1327, 715, 1142, 718, 1327, 912, 930, 521, 1115, 715, 930, 718, 1115, 912, 1359, 514, 1553, 699, 1556, 514, 1750, 699, 1358, 727, 1552, 912, 1555, 727, 1749, 912, 1353, 92, 1538, 286, 1353, 289, 1538, 483, 1565, 91, 1750, 285, 1565, 288, 1750, 482, 932, 111, 1126, 296, 1129, 111, 1323, 296, 931, 323, 1125, 508, 1128, 323, 1322, 508]

  for itile in range(len(tiling)//4):
    print("tile",itile, end=' ')
    print("(%4d %4d)-(%4d %4d)"%tuple(tiling[4*itile:4*itile+4]), end=' ')
    selection = flex.bool()
    for i in range(len(x)):
      selection.append(
         tiling[4*itile+0]<xpred[i]<tiling[4*itile+2] and
         tiling[4*itile+1]<ypred[i]<tiling[4*itile+3]
     )
    print("in selection of %d/%d"%(selection.count(True),len(selection)))
    if selection.count(True)<10:continue
    from matplotlib import pyplot as plt
    plt.plot(x.select(selection),y.select(selection),"r.")
    plt.plot([flex.mean(x.select(selection))],[flex.mean(y.select(selection))],"go")
    print("Delta x=%.1f"%flex.mean(x.select(selection)),"Delta y=%.1f"%flex.mean(y.select(selection)))
    plt.show()

if __name__=="__main__":
  import sys
  handle = open(sys.argv[1],"r")
  vectors(handle,all = "all" in sys.argv)


 *******************************************************************************


 *******************************************************************************
spotfinder/applications/xfel/cxi_phil.py
# -*- mode: python; coding: utf-8; indent-tabs-mode: nil; python-indent: 2 -*-

from __future__ import absolute_import, division, print_function
#Phil parameters required to process data from Stanford LCLS CXI instrument

def cxi_basic_start():
  try:
    from labelit import preferences
    from rstbx.command_line.index import special_defaults_for_new_horizons
  except Exception:
    # option to view images or open pickle files without any LABELIT dependency
    from rstbx.phil import preferences
    def special_defaults_for_new_horizons(phil_scope):
      # for integration, do not want 2x2 binning
      phil_scope.merge_command_line(["distl_permit_binning=False"])

  new_horizons_phil = preferences.RunTimePreferences()
  special_defaults_for_new_horizons( new_horizons_phil )

  common_arguments = [
          "distl.bins.verbose=True",
          "distl.minimum_spot_area=3",
          "distl.peripheral_margin=1",
          "distl.peak_intensity_maximum_factor=10000.", #avoids intensity filter
          "distl.compactness_filter=True",
  ]

  new_horizons_phil.merge_command_line(common_arguments)

  return new_horizons_phil

def cxi_versioned_extract(*args):
  import copy

  # args is one or more lists of phil parameters, as would be passed
  # in through the command line; to be processed sequentially.

  working_phil = cxi_basic_start()

  #for arg in args:
  for arg in copy.deepcopy(args):
    working_phil.merge_command_line(arg)
  working_extract = working_phil.command_extractor

  if working_extract.distl.tile_translations is not None and \
     working_extract.distl.quad_translations is not None:
    return working_extract

  # Get the working tile translations for the given detector format version
  # from previous experiments
  legacy_extract = cxi_versioned_extract_detail(args)

  if working_extract.distl.tile_translations is None:
    working_extract.distl.tile_translations = legacy_extract.distl.tile_translations

  if working_extract.distl.quad_translations is None:
    working_extract.distl.quad_translations = legacy_extract.distl.quad_translations

  return working_extract

def cxi_versioned_extract_detail(args):

  # args is one or more lists of phil parameters, as would be passed
  # in through the command line; to be processed sequentially.

  working_phil = cxi_basic_start()

  for arg in args:
    working_phil.merge_command_line(arg)

  #distl_args = [a.object.as_str().strip() for a in working_phil.phil_scope.all_definitions()]

  cxi_version = working_phil.phil_scope.get("distl.detector_format_version"
                ).extract().detector_format_version

  print("cxi_versioned_extract()::cxi_version:", cxi_version)

  if cxi_version in ["CXI 3.1","CXI 3.2"]:
    working_extract = working_phil.command_extractor

    # Three sensors were disabled at this time.  The 2D-translations
    # will have (32 - 3) * 2 * 2 = 116 components.
    corrected_auxiliary_translations = [
        1,   1,   1,   1,   1,   2,   1,   2,   0,   0,   0,   0,   1,  -1,   1,  -1,
        1,  -2,   1,  -2,   0,  -2,   0,  -2,  -1,   1,  -1,   1,   1,   0,   1,   0,
        2,  -1,   2,  -1,  -3,   1,  -3,   1,  -4,   0,  -4,   0,   4,   0,   4,   0,
       -7,   4,  -7,   4,   2,  -1,   2,  -1,   1,  -2,   1,  -2,  -1,   1,  -1,   1,
       -1,   1,  -1,   1,   0,  -1,   0,  -1,   2,  -2,   2,  -2,   0,   1,   0,   1,
        0,   2,   0,   2,  -1,  -2,  -1,  -2,  -1,  -3,  -1,  -3,   1,   1,   1,   1,
        0,   1,   0,   1,   0,  -1,   0,  -1,   1,  -2,   1,  -2,  -2,  -1,  -2,  -1,
        2,   2,   2,   2]

    from scitbx.array_family import flex
    total_tile_translations = flex.int(corrected_auxiliary_translations)

    TT = list(total_tile_translations)
    working_extract.distl.tile_translations = TT
    working_extract.distl.quad_translations = [-19, 15, 21, 14, -25, -20, 20, -15]

    return working_extract
  elif cxi_version in ["CXI 4.1"]:
    working_extract = working_phil.command_extractor

    corrected_auxiliary_translations = [
                               0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                               0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1,0,-1,
                               0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                               0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                               0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-2,
                               0,0,0,-1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                               0,0,0,0,0,0,0,0]

    from scitbx.array_family import flex
    total_tile_translations = flex.int(corrected_auxiliary_translations)

    TT = list(total_tile_translations)
    working_extract.distl.tile_translations = TT
    #working_extract.distl.quad_translations = [0,0,0,0,0,0,0,0]
    #working_extract.distl.quad_translations = [5,-5,6,-9,-5,-2,0,-8]
    working_extract.distl.quad_translations = [6,-2,7,-4,-4,1,1,-5]
    return working_extract

  elif cxi_version in ["CXI 5.1"]:
    working_extract = working_phil.command_extractor

    # The auxiliary translations are modified with respect to CXI 4.1.  If the
    # SLAC-provided metrology were to be trusted, this would be be all
    # zeros?
    corrected_auxiliary_translations = [
                               1,-1,1,0,0,-1,0,-1,2,0,0,0,3,1,2,0,2,-1,2,-1,
                               0,0,1,0,1,-2,1,-3,0,-1,0,-1,-2,1,0,1,-1,0,0,0,
                               0,2,-1,1,0,2,-1,2,0,0,0,0,0,0,1,1,1,0,0,0,
                               -1,0,-1,0,1,1,0,0,0,1,0,1,0,-1,0,0,1,-2,0,0,
                               -1,-2,-1,-1,0,0,-1,-1,0,0,0,1,-1,-1,0,0,1,-2,1,-1,
                               1,-1,0,0,0,-2,0,-3,1,-4,1,-4,-2,0,-1,-1,0,0,-1,-1,
                               -1,1,-1,0,0,1,0,1]

    from scitbx.array_family import flex
    total_tile_translations = flex.int(corrected_auxiliary_translations)

    TT = list(total_tile_translations)
    #added NKS 8/19/14
    #TT = [0]*128
    working_extract.distl.tile_translations = TT

    print("IN CXI %>! WITH ",working_extract.distl.tile_translations)

    # Order: UL x, UL y, UR x, UR y, LL x, LL y, LR x, LR y
    working_extract.distl.quad_translations = [-3,-1,-1,-5,-13,2,-7,-4]
    return working_extract

  elif cxi_version in ["CXI 6.1"]:
    working_extract = working_phil.command_extractor
    corrected_auxiliary_translations = [
       2,  1,  1,  1,  1,  3, -1,  2,  3,  1,
       1,  0,  5,  2,  4,  1,  2, -1,  2,  0,
       2,  1,  2,  0, -1, -2, -1, -2, -1,  0,
      -2,  1, -1,  0,  0,  1,  1,  0,  1,  1,
      -1,  0, -1,  0, -1,  0, -1,  0,  0,  0,
      -1,  0,  1,  0,  1,  0,  0,  1,  1,  2,
      -1,  1,  0,  2, -1,  1,  0,  1,  0,  0,
       1,  0, -2,  0, -1,  1, -2, -1, -2,  1,
      -2,  0, -1,  1, -3, -1, -3,  0,  0,  1,
       0,  1,  0,  0,  1,  0,  2,  0,  2, -1,
       1,  0,  0, -1,  0,  0,  1, -2,  1, -1,
       2, -2, -1,  0,  0, -1, -2,  1,  0,  0,
      -1,  0, -1, -1,  1,  1,  1, -1]

    from scitbx.array_family import flex
    total_tile_translations = flex.int(corrected_auxiliary_translations)

    TT = list(total_tile_translations)
    working_extract.distl.tile_translations = TT

    # Order: UL x, UL y, UR x, UR y, LL x, LL y, LR x, LR y
    working_extract.distl.quad_translations = [0,7,13,8,-8,0,11,-3]
    return working_extract

  elif cxi_version in ["CXI 7.1"]:
    working_extract = working_phil.command_extractor
    corrected_auxiliary_translations = [
       2,  1,  1,  1,  1,  2,  0,  2,  3,  0,
       0,  0,  4,  1,  3,  1,  1, -2,  2, -1,
      -1, -1,  1, -1, -1, -2, -1, -1, -1,  0,
      -1,  1, -2,  0,  0,  1,  0,  0,  1,  1,
      -1,  1, -2,  1, -1,  0, -1,  1, -1,  1,
      -1,  1, -2,  1, -1,  1,  1,  1,  0,  2,
      -1,  1,  0,  1,  0,  1,  0,  1,  0,  0,
       0,  1, -1,  0,  0,  1,  0, -1, -1,  1,
      -1,  0, -1,  1, -1,  0, -2,  0,  0,  1,
       0,  1, -1,  0,  1,  0,  2, -1,  2, -1,
       1,  0,  0,  0,  1, -1,  1, -2,  2, -2,
       2, -2,  0, -1,  1, -1,  2,  1,  0,  0,
       0,  0,  0, -2,  1,  1,  1,  0]

    from scitbx.array_family import flex
    total_tile_translations = flex.int(corrected_auxiliary_translations)

    TT = list(total_tile_translations)
    working_extract.distl.tile_translations = TT

    # Order: UL x, UL y, UR x, UR y, LL x, LL y, LR x, LR y
    working_extract.distl.quad_translations = [2,-6,3,-6,-7,0,-1,-4]
    return working_extract

  elif cxi_version in ["CXI 7.d"]:
    working_extract = working_phil.command_extractor

    corrected_auxiliary_translations = [
       1,  1,  1,  0,  0,  0,  0,  0, -2, -1,
      -1, -1, -1, -3,  0, -3,  2,  3,  2,  1,
      -1,  4, -1,  2,  0,  1,  1,  1,  0,  2,
      -1,  2,  0,  0,  0,  0,  0,  0,  0,  0,
      -3, -2, -3, -1, -2, -1, -2, -1,  3, -3,
       3, -3,  5, -2,  4, -2,  2, -1,  2, -1,
       2, -2,  2, -1,  1,  1,  1,  0,  0,  0,
       0, -1, -1,  2, -2,  2, -2,  0, -1,  0,
      -1, -2, -1, -1, -3, -1, -3, -1,  3,  0,
       2,  0,  2,  0,  2,  0,  1,  0,  0,  0,
       0,  0, -1,  0,  0, -1,  0, -1,  1, -2,
       1, -2, -6,  0, -6,  0, -5,  1, -5,  1,
      -5, -2, -5, -3, -4, -2, -4, -2]

    from scitbx.array_family import flex
    total_tile_translations = flex.int(corrected_auxiliary_translations)

    TT = list(total_tile_translations)
    working_extract.distl.tile_translations = TT

    # Order: UL x, UL y, UR x, UR y, LL x, LL y, LR x, LR y
    working_extract.distl.quad_translations = [-6,-2,9,2,-14,-8,7,-12]
    return working_extract

  elif cxi_version in ["XPP 7.1"]:
    working_extract = working_phil.command_extractor

    corrected_auxiliary_translations = [
       0,  0,  0,  0,  0,  0,  0,  0,
       0, -2,  0, -2, -1, -1, -1, -1,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0, -2, -2, -2, -2,
      -1, -1, -1, -1, -1, -1, -1, -1,
       0,  0,  0,  0, -2, -1, -2, -1,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0, -1,  0, -1,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0, -1, -1, -1, -1,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0]

    L748_corrections_post103 = [
       0,  0,  0,  0,  0,  0,  0,  0,
       0, -1,  0, -1, -1,  0, -1,  0,
       1, -1,  1, -1,  0,  0,  0,  0,
       0,  0,  0,  0,  2,  1,  2,  1,

       0,  0,  0,  0, -1,  0, -1,  0,
       3,  0,  3,  0,  0,  1,  0,  1,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  1, -1,  1, -1,

       0,  0,  0,  0,  0,  1,  0,  1,
       1,  3,  1,  3,  1,  3,  1,  3,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  1,  1,  1,  1,

       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  2,  0,  2,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0, -2,  0, -2,  0,  0,  0,  0,
    ] # for 110 mm

    from scitbx.array_family import flex
    total_tile_translations = flex.int(corrected_auxiliary_translations) - \
                              flex.int(L748_corrections_post103)
    TT = list(total_tile_translations)
    working_extract.distl.tile_translations = TT

    # Order: UL x, UL y, UR x, UR y, LL x, LL y, LR x, LR y.  For the
    # XPP CSPAD, this is effectively correcting for the beam center.
    working_extract.distl.quad_translations = [-3, -21,
                                               -3, -22,
                                               -3, -21,
                                                2, -21]
    return working_extract

  elif cxi_version in ["XPP 8.1"]:
    working_extract = working_phil.command_extractor

    corrected_auxiliary_translations = [
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0]

    from scitbx.array_family import flex
    total_tile_translations = flex.int(corrected_auxiliary_translations)

    TT = list(total_tile_translations)
    working_extract.distl.tile_translations = TT

    # Order: UL x, UL y, UR x, UR y, LL x, LL y, LR x, LR y.  For the
    # XPP CSPAD, this is effectively correcting for the beam center.
    working_extract.distl.quad_translations = [0, 1,
                                               0, 1,
                                               0, 1,
                                               0, 1]
    return working_extract


  elif cxi_version in ["XPP 9.1"]:
    working_extract = working_phil.command_extractor

    # metrology from trial 14, runs 40, 41, xppe0314
    corrected_auxiliary_translations = [
       1,  2,  1,  2,  1,  2,  1,  2,
       2,  1,  2,  1,  2,  2,  2,  2,
      -1, -1, -1, -1,  0,  0,  0,  0,
      -2,  1, -2,  1, -1,  2, -1,  2,

       0, -1,  0, -1,  0,  0,  0,  0,
      -2, -1, -2, -1, -2, -1, -2, -1,
      -2,  0, -2,  0, -3, -1, -3, -1,
       0, -2,  0, -2,  0, -1,  0, -1,

       1, -1,  1, -1,  1, -1,  1, -1,
       0, -3,  0, -3,  1, -2,  1, -2,
      -2, -3, -2, -3,  0,  0,  0,  0,
      -3,  0, -3,  0,  0, -1,  0, -1,

      -1,  0, -1,  0,  0,  0,  0,  0,
      -3,  1, -3,  1, -3,  1, -3,  1,
      -1,  2, -1,  2, -4,  2, -4,  2,
       0,  0,  0,  0,  0, -1,  0, -1
    ]

    from scitbx.array_family import flex
    total_tile_translations = flex.int(corrected_auxiliary_translations)

    TT = list(total_tile_translations)
    working_extract.distl.tile_translations = TT

    # Order: UL x, UL y, UR x, UR y, LL x, LL y, LR x, LR y.  For the
    # XPP CSPAD, this is effectively correcting for the beam center.
    # analysis by hand from run 40+41, xppe0314.
    #working_extract.distl.quad_translations = [3, -1,
    #                                           6, -1,
    #                                           4, -1,
    #                                           4, -5]
    # account for a change in beam center.  offset 7 pixels in the x direction.
    # valid for runs 124, 126
    working_extract.distl.quad_translations = [3,  6,
                                               6,  6,
                                               4,  6,
                                               4,  1]

    return working_extract

  elif cxi_version in ["XPP 11.1"]:
    working_extract = working_phil.command_extractor

    # metrology from trial 14, runs 40, 41, xppe0314
    corrected_auxiliary_translations = [
       1,  2,  1,  2,  1,  2,  1,  2,
       2,  1,  2,  1,  2,  2,  2,  2,
      -1, -1, -1, -1,  0,  0,  0,  0,
      -2,  1, -2,  1, -1,  2, -1,  2,

       0, -1,  0, -1,  0,  0,  0,  0,
      -2, -1, -2, -1, -2, -1, -2, -1,
      -2,  0, -2,  0, -3, -1, -3, -1,
       0, -2,  0, -2,  0, -1,  0, -1,

       1, -1,  1, -1,  1, -1,  1, -1,
       0, -3,  0, -3,  1, -2,  1, -2,
      -2, -3, -2, -3,  0,  0,  0,  0,
      -3,  0, -3,  0,  0, -1,  0, -1,

      -1,  0, -1,  0,  0,  0,  0,  0,
      -3,  1, -3,  1, -3,  1, -3,  1,
      -1,  2, -1,  2, -4,  2, -4,  2,
       0,  0,  0,  0,  0, -1,  0, -1
    ]

    from scitbx.array_family import flex
    total_tile_translations = flex.int(corrected_auxiliary_translations)

    TT = list(total_tile_translations)
    working_extract.distl.tile_translations = TT

    # Order: UL x, UL y, UR x, UR y, LL x, LL y, LR x, LR y.  For the
    # XPP CSPAD, this is effectively correcting for the beam center.
    # analysis by hand from runs 35-38, trial 1, xpph9015.
    working_extract.distl.quad_translations = [1, 10,
                                               2,  9,
                                              -1,  9,
                                              -1,  4]

    return working_extract



  elif cxi_version in ["XPP 7.marccd"]:
    working_extract = working_phil.command_extractor
    working_extract.distl.quad_translations = None
    working_extract.distl.tile_translations = [0, 0]
    return working_extract

  elif cxi_version in ["CXI 8.1inheritedfrom7.1"]:
    working_extract = working_phil.command_extractor
    corrected_auxiliary_translations = [
       2,  1,  1,  1,  1,  2,  0,  2,  3,  0,
       0,  0,  4,  1,  3,  1,  1, -2,  2, -1,
      -1, -1,  1, -1, -1, -2, -1, -1, -1,  0,
      -1,  1, -2,  0,  0,  1,  0,  0,  1,  1,
      -1,  1, -2,  1, -1,  0, -1,  1, -1,  1,
      -1,  1, -2,  1, -1,  1,  1,  1,  0,  2,
      -1,  1,  0,  1,  0,  1,  0,  1,  0,  0,
       0,  1, -1,  0,  0,  1,  0, -1, -1,  1,
      -1,  0, -1,  1, -1,  0, -2,  0,  0,  1,
       0,  1, -1,  0,  1,  0,  2, -1,  2, -1,
       1,  0,  0,  0,  1, -1,  1, -2,  2, -2,
       2, -2,  0, -1,  1, -1,  2,  1,  0,  0,
       0,  0,  0, -2,  1,  1,  1,  0]

    from scitbx.array_family import flex
    total_tile_translations = flex.int(corrected_auxiliary_translations)

    TT = list(total_tile_translations)
    working_extract.distl.tile_translations = TT

    # Order: UL x, UL y, UR x, UR y, LL x, LL y, LR x, LR y
    working_extract.distl.quad_translations = [-22,-4,-14,11,0,8,2,-5]
    return working_extract

  elif cxi_version in ["CXI 8.1"]: # developed against "run 4 optical metrology"
    working_extract = working_phil.command_extractor
    corrected_auxiliary_translations = [
      -2, -3, -2, -3, -3, -3, -3, -3,
      -4, -4, -4, -4, -2, -4, -2, -4,
      -2, -2, -2, -2,  0,  0, -1,  1,
      -4, -2, -4, -2, -3,  0, -3,  0,
      -4,  2, -4,  2, -4,  2, -4,  2,
      -5,  3, -5,  3, -5,  3, -5,  3,
      -2,  3, -2,  3,  3,  1,  3,  1,
      -1,  2, -1,  2, -2,  1, -2,  1,
       3,  3,  3,  3,  2,  3,  2,  3,
       2,  3,  2,  3,  2,  2,  2,  2,
       2,  4,  2,  4,  0, -1, -1,  0,
       3,  3,  3,  3,  2,  2,  2,  2,
       4, -3,  4, -3,  4, -3,  4, -3,
       3, -3,  4, -3,  3, -3,  4, -3,
      -2, -1, -2, -2, -3,  2, -3,  2,
       1, -3,  1, -3,  2, -2,  2, -2,
    ]

    from scitbx.array_family import flex
    total_tile_translations = flex.int(corrected_auxiliary_translations)

    TT = list(total_tile_translations)
    working_extract.distl.tile_translations = TT

    # Order: UL x, UL y, UR x, UR y, LL x, LL y, LR x, LR y
    # Note, these numbers are valid for the CSPAD detector at roughly 100 mm distance
    working_extract.distl.quad_translations = [-14,7,-4,7,-22,0,-12,-4]

    # Calibrated at 201
    #working_extract.distl.quad_translations = [-14,7,-4,6,-23,0,-13,-5]

    # Due to a slight angle in the rail, if the detector is at the back of its
    # stage, around 548 mm, use these numbers instead.  They represent a change
    # of beam center due to a small translation at that distance
    #working_extract.distl.quad_translations = [-10,5,0,5,-18,-2,-8,-6]

    # Recalibration of 548 mm vs run 111 of lysozyme calibration dataset
    #working_extract.distl.quad_translations = [-11,4,-2,6,-18,-3,-9,-4]


    return working_extract

  elif cxi_version in ["CXI 8.2"]:
    working_extract = working_phil.command_extractor

    corrected_auxiliary_translations = [
       1,  7,  1,  7, -1,  0, -1,  0,
       5,  4,  5,  4,  1,  4,  1,  4,
       6, -2,  6, -2,  5,  3,  5,  3,
       5,  0,  5,  0,  0,  3,  0,  3,
       4,  0,  4,  0,  1,  0,  1,  0,
       3, -7,  3, -7,  3, -1,  3, -1,
      -1, -5, -1, -5,  6, -4,  6, -4,
       2, -3,  2, -3,  2, -4,  2, -4,
      -1, -5, -1, -5,  0,  0,  0,  0,
     -10,  0,-10,  0, -1, -1, -1, -1,
      -5,  8, -5,  8, -8,  2, -8,  2,
      -1,  2, -1,  2, -2,  1, -2,  1,
      -7,  0, -7,  0, -1,  0, -1,  0,
      -6,  4, -6,  4, -4, -6, -4, -6,
      -3,  2, -3,  2, -8,  3, -8,  3,
      -4,  6, -4,  6, -4,  2, -4,  2]

    LC06_mark10_001_corrections = [
       0,  0,  0,  0,  0, -1,  0, -1,
      -1,  1, -1,  1, -1,  1, -1,  1,
       0,  0,  0,  0,  0,  0,  0,  0,
       1,  2,  1,  2,  1,  0,  1,  0,

      -1,  0, -1,  0, -1,  0, -1,  0,
       0,  0,  0,  0,  0,  1,  0,  1,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  1,  0,  1,

       1,  2,  1,  2,  0,  1,  0,  1,
       0,  1,  0,  1,  0,  2,  0,  2,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  1,  0,  1,

       1, -1,  1, -1,  1, -1,  1, -1,
       0, -2,  0, -2,  1, -2,  1, -2,
       0,  0,  0,  0,  0,  0,  0,  0,
      -1,  2, -1,  2, -1,  0, -1,  0] # for 79 mm

    LC06_mark10_101_corrections = [
       0,  0,  0,  0,  0, -1,  0, -1,
      -1,  0, -1,  0, -0,  0, -0,  0,
       0,  1,  0,  1,  2,  2,  2,  2,
       0,  1,  0,  1,  0,  0,  0,  0,

      -1,  0, -1,  0, -1,  0, -1,  0,
      -1,  0, -1,  0, -1,  1, -1,  1,
      -1,  0, -1,  0,  0,  1,  0,  1,
      -1,  0, -1,  0,  0,  0,  0,  0,

       0,  2,  0,  2,  0,  1,  0,  1,
       0,  1,  0,  1,  0,  3,  0,  3,
       1,  2,  1,  2,  1,  3,  1,  3,
       0,  1,  0,  1,  0,  1,  0,  1,

       1, -1,  1, -1,  1, -1,  1, -1,
       0, -2,  0, -2,  2, -2,  2, -2,
       0, -1,  0, -1,  0, -2,  0, -2,
      -0,  0, -0,  0, -0,  0, -0,  0] # for 159 mm

    LB67_corrections_post009 = [
       1,  0,  1,  0,  0,  0,  0,  0,
       1,  1,  1,  1,  1,  1,  1,  1,
       2,  3,  2,  3,  2,  4,  2,  4,
       2,  2,  2,  2,  1,  0,  1,  0,

      -1,  0, -1,  0,  0,  0,  0,  0,
       0, -1,  0, -1,  0,  0,  0,  0,
       0, -1,  0, -1,  1,  0,  1,  0,
       0,  0,  0,  0,  0,  0,  0,  0,

       0,  1,  0,  1, -1,  0, -1,  0,
      -1,  1, -1,  1, -1,  2, -1,  2,
       0,  1,  0,  1,  0,  2,  0,  2,
       0,  0,  0,  0,  0,  0,  0,  0,

       1, -1,  1, -1,  0, -1,  0, -1,
       0, -1,  0, -1,  1, -1,  1, -1,
      -2,  0, -2,  0, -2, -1, -2, -1,
      -1,  1, -1,  1, -1, -1, -1, -1,] # for 105 mm

    from scitbx.array_family import flex
    total_tile_translations = flex.int(corrected_auxiliary_translations)  - \
                              flex.int(LB67_corrections_post009)

#                              flex.int(LC06_mark10_001_corrections)
#                              flex.int(LC06_mark10_101_corrections)

    TT = list(total_tile_translations)
    working_extract.distl.tile_translations = TT

    # Order: UL x, UL y, UR x, UR y, LL x, LL y, LR x, LR y. Optimized for 267 mm.
    #working_extract.distl.quad_translations = [-3,  2,
    #                                           -8,  3,
    #                                           -7,  8,
    #                                           -10,  8]

    # determined for LC06_runs15-17. Optimized for 159 mm
    #working_extract.distl.quad_translations = [-2,  1,
    #                                           -9,  3,
    #                                           -5,  8,
    #                                           -9,  10]

    # determined for LC67_run26. Optimized for 101 mm; detz_offset must be changed to move 100 mm distance to 101
    working_extract.distl.quad_translations = [ 0,  3,
                                               -7,  3,
                                               -5,  9,
                                               -9,  9]

    # Order: UL x, UL y, UR x, UR y, LL x, LL y, LR x, LR y. Optimized for 79 mm.
    #working_extract.distl.quad_translations = [-2,  3,
    #                                           -9,  5,
     #                                          -5,  10,
     #                                          -9,  12]
    return working_extract

  elif cxi_version in ["CXI 9.1"]:
    working_extract = working_phil.command_extractor

    from scitbx.array_family import flex
    # Based on the LD91 experiment, runs 95-114, redetermined 3/17/15 NKS
    corrected_auxiliary_translations = flex.int([
       0,  8,  0,  8, -1, -1, -1, -1,
       8,  2,  8,  2,  3,  2,  3,  2,
       5, -6,  5, -6,  3, -1,  3, -1,
       2, -1,  2, -1, -2,  1, -2,  1,

       4,  1,  4,  1,  1,  1,  1,  1,
       0, -7,  0, -7,  2, -2,  2, -2,
      -1, -4, -1, -4,  8, -4,  8, -4,
       7, -7,  7, -7,  7, -1,  7, -1,

       1, -5,  1, -5,  2, -1,  2, -1,
      -8, -3, -8, -3, -1, -5, -1, -5,
      -4,  6, -4,  6, -7, -3, -7, -3,
      -7,  1, -7,  1,  1, -1,  1, -1,

      -8,  3, -8,  3,  0,  1,  0,  1,
      -3,  8, -3,  8, -4,  1, -4,  1,
       0,  6,  0,  6, -7,  7, -7,  7,
      -3,  2, -3,  2, -3,  3, -3,  3])

    working_extract.distl.tile_translations = list(corrected_auxiliary_translations)

    # Order: UL x, UL y, UR x, UR y, LL x, LL y, LR x, LR y.
    # Determined for LD91 run 33. Optimized for 125 mm
    working_extract.distl.quad_translations = [ 8, -3,
                                               -9,  5,
                                                9,  7,
                                               -5, 15]

    return working_extract

  elif cxi_version in ["CXI 8.d"]:
    working_extract = working_phil.command_extractor

    from scitbx.array_family import flex
    total_tile_translations = flex.int(128)

    TT = list(total_tile_translations)
    working_extract.distl.tile_translations = TT



    # Order: UL x, UL y, UR x, UR y, LL x, LL y, LR x, LR y.
    working_extract.distl.quad_translations = [11,  3,
                                               -3, -2,
                                                0,  8,
                                                0,  4]
    print(len(working_extract.distl.tile_translations))

    return working_extract

  elif cxi_version in ["CXI 10.1"]:
    working_extract = working_phil.command_extractor

    from scitbx.array_family import flex

    # Determined from LG36, trial 305
    corrected_auxiliary_translations =flex.int([
       1,  6,  1,  6,  0,  0,  0,  0,
       6,  1,  6,  1,  2,  2,  2,  2,
       5, -6,  5, -6,  3, -3,  3, -3,
       3, -3,  3, -3, -1,  2, -1,  2,

       4,  0,  4,  0,  0,  0,  0,  0,
       2, -7,  2, -7,  2, -1,  2, -1,
      -3, -7, -3, -7,  3, -6,  3, -6,
       1, -9,  1, -9,  0, -2,  0, -2,

       0, -6,  0, -6,  0,  0,  0,  0,
     -10, -1,-10, -1, -1, -3, -1, -3,
      -7,  5, -7,  5,  0,  0,  0,  0,
      -7, -2, -7, -2, -1, -2, -1, -2,

      -7,  0, -7,  0,  0,  0,  0,  0,
      -5,  6, -5,  6, -5, -4, -5, -4,
      -1,  3, -1,  3,  1, -1,  1, -1,
      -3,  5, -3,  5, -2,  1, -2,  1])

    working_extract.distl.tile_translations = list(corrected_auxiliary_translations)

    # Order: UL x, UL y, UR x, UR y, LL x, LL y, LR x, LR y.
    # Determined for LG36 run 82. Optimized for 118 mm
    working_extract.distl.quad_translations = [8,  3,
                                               5,  3,
                                               7, 11,
                                               3, 12]


    return working_extract

  elif cxi_version in ["CXI 10.2"]:
    working_extract = working_phil.command_extractor

    from scitbx.array_family import flex

    corrected_auxiliary_translations =flex.int([
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,

       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,

       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,

       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0])


    working_extract.distl.tile_translations = list(corrected_auxiliary_translations)

    # Order: UL x, UL y, UR x, UR y, LL x, LL y, LR x, LR y.
    # Determined for LG36 run 82. Optimized for 118 mm
    working_extract.distl.quad_translations = [ 0, 0,
                                                0, 0,
                                                0, 0,
                                                0, 0]

    return working_extract

  elif cxi_version in ["CXI 11.1"]:
    working_extract = working_phil.command_extractor

    from scitbx.array_family import flex

    corrected_auxiliary_translations =flex.int([
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,

       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,

       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,

       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0])


    working_extract.distl.tile_translations = list(corrected_auxiliary_translations)

    # Order: UL x, UL y, UR x, UR y, LL x, LL y, LR x, LR y.
    working_extract.distl.quad_translations = [ 0, 0,
                                                0, 0,
                                                0, 0,
                                                0, 0]


    return working_extract

  elif cxi_version in ["CXI 11.2"]:
    working_extract = working_phil.command_extractor

    from scitbx.array_family import flex

    # Determined from LH80, runs 18-23, trial 014_000
    """
    corrected_auxiliary_translations =flex.int([
       2,  1,  2,  1,  1,  2,  1,  2,
       3,  0,  3,  0,  2,  0,  2,  0,
       1,  0,  1,  0,  0,  0,  0,  0,
       1,  1,  1,  1,  0,  1,  0,  1,

      -1,  0, -1,  0,  0,  0,  0,  0,
       0,  0,  0,  0, -1, -1, -1, -1,
       2, -2,  2, -2,  0,  0,  0,  0,
       1, -3,  1, -3,  0,  0,  0,  0,

       0, -3,  0, -3,  0, -2,  0, -2,
      -2, -4, -2, -4, -1, -3, -1, -3,
      -2, -3, -2, -3,  0,  0,  0,  0,
      -3, -1, -3, -1, -1, -2, -1, -2,

      -1,  2, -1,  2, -2,  1, -2,  1,
      -2,  2, -2,  2, -3,  2, -3,  2,
      -2,  2, -2,  2,  0,  0,  0,  0,
      -1, -2, -1, -2, -1,  0, -1,  0])
    """
    # Determined from LH80, runs 46-51, trial 019_000
    corrected_auxiliary_translations =flex.int([
       2,  1,  2,  1,  2,  2,  2,  2,
       2, -2,  2, -2,  2, -1,  2, -1,
      -1, -2, -1, -2, -3, -6, -3, -6,
      -1,  1, -1,  1,  0,  1,  0,  1,

      -2,  1, -2,  1, -1,  0, -1,  0,
     # row from 014_001
     # 0,  0,  0,  0, -1, -1, -1, -1,
     # original row from 019_000
     #-2,  1, -2,  1, -3,  0, -3,  0,
     # the minus 2s and 3s above put this sensor off of the edge.
       0,  1,  0,  1, -1,  0, -1,  0,
       1, -2,  1, -2,  1, -1,  1, -1,
       1, -4,  1, -4,  0,  0,  0,  0,

       1, -3,  1, -3,  0, -2,  0, -2,
      -1, -5, -1, -5,  0, -4,  0, -4,
      -3, -4, -3, -4, -3, -6, -3, -6,
      -1, -1, -1, -1,  0, -2,  0, -2,

      -1,  1, -1,  1, -2,  1, -2,  1,
      -2,  1, -2,  1, -3,  1, -3,  1,
      -1,  0, -1,  0,  0,  0,  0,  0,
       0, -3,  0, -3, -1,  0, -1,  0])

    working_extract.distl.tile_translations = list(corrected_auxiliary_translations)

    # Order: UL x, UL y, UR x, UR y, LL x, LL y, LR x, LR y.
    # Manually determined from LH80 run 12. Optimized for 85 mm
    #working_extract.distl.quad_translations = [-11, 2,
    #                                            -8, 2,
    #                                            -9, 2,
    #                                           -11, 4]
    # Manually determined from LH80 runs 31-37. Optimized for 85 mm. Good for runs 31+
    working_extract.distl.quad_translations = [-16, 5,
                                               -11, 5,
                                               -14, 5,
                                               -16, 6]
    return working_extract


  elif cxi_version in ["Sacla.MPCCD"]:
    working_extract = working_phil.command_extractor
    working_extract.distl.quad_translations = None
    working_extract.distl.tile_translations = None
    return working_extract

  elif cxi_version in ["Sacla.MPCCD.8tile"]:
    working_extract = working_phil.command_extractor
    working_extract.distl.quad_translations = None

    from scitbx.array_family import flex
    corrected_auxiliary_translations =flex.int([
       0,  0,  0,  0,  0,  0,  0,  0,
       0,  0,  0,  0,  0,  0,  0,  0,
    ])

    working_extract.distl.tile_translations = list(corrected_auxiliary_translations)

    #working_extract.distl.tile_translations = None
    return working_extract

  else:
    return working_phil.command_extractor


 *******************************************************************************


 *******************************************************************************
spotfinder/applications/xfel/cxi_run3.py
from __future__ import absolute_import, division, print_function
from six.moves import range
from scitbx.array_family import flex
from scitbx import matrix
from six.moves import zip
"""Standalone program gives tile translations for the CXI pad detector;
     based on lysozyme test powder arcs.
   Fixed coordinates for the detector center (850,850) are simply based on CXI output
     file size.
   distl.detector_tiling limits are based on a separate run of the program
     spotfinder.find_active_area
   coordinates of pixels on the powder arcs of all four quadrants were obtained by
     manual inspection.  200 XFEL shots with the highest count of spotfinder spots
     were summed and inspected with the phenix.image_viewer.
"""

init_ctr_slow = 850
init_ctr_fast = 850
init_ctr = matrix.col([init_ctr_slow,init_ctr_fast])

class quadrant:
  def __init__(self,arcs):
    self.arcs = arcs

  def refine_center_from_arcs(self):
    #initial guess for center, based on given size of Numpy arra
    init_ctr_slow = 850
    init_ctr_fast = 850
    init_ctr = matrix.col([init_ctr_slow,init_ctr_fast])
    self.x = flex.double([init_ctr_slow,init_ctr_fast])
    #add a radius parameter for each arc
    for arc in self.arcs:
      sample_point = matrix.col(arc.points[0])
      guess_radius = (sample_point - init_ctr).length()
      self.x.append(guess_radius)

    self.initial_functional = None
    import scitbx.lbfgs
    scitbx.lbfgs.run(target_evaluator=self)
    self.final_functional = self.compute_functional_and_gradients(
      functional_only=True)

  def compute_functional_and_gradients(self, functional_only=False):
    def get_f():
      center = matrix.col([self.x[0],self.x[1]])
      residual = 0.0
      for arc,radius in zip(self.arcs,self.x[2:]):
        for point in arc.points:
          ppoint = matrix.col(point)
          rad_vector = ppoint - center
          length = rad_vector.length()
          residual += (length-radius)*(length-radius)
      return residual

    f = get_f()
    if (self.initial_functional is None):
      self.initial_functional = f
    if (functional_only):
      return f
    g = flex.double()
    g.reserve(len(self.x))
    eps = 1e-6
    for i in range(len(self.x)):
      xi = self.x[i]
      self.x[i] = xi+eps
      f_eps = get_f()
      self.x[i] = xi
      g.append((f_eps-f)/eps)
    return f, g

  def show_summary(self):
    print("The center is %7.2f %7.2f; "%(self.x[0],self.x[1]), end=' ')
    print("radii are",[round(xx,2) for xx in self.x[2:]])

  def get_tile_translation(self):
    slow_translation = int(float(init_ctr_slow) - self.x[0])
    fast_translation = int(float(init_ctr_fast) - self.x[1])
    return (slow_translation,fast_translation)

def parse(string):
  words = string.split()
  values = []
  for x in range(len(words)//2):
    values.append((int(words[2*x]),int(words[2*x+1])))
  return values

class powder_arc:
  def __init__(self,points):
    self.points = flex.vec2_double(parse(points))
    print(list(self.points))

def lysozyme_calibration():
  quad_1_UL= quadrant([
    powder_arc("""
    844 729
    815 731
    788 740
    759 764
    738 796
    """),
    powder_arc("""
    752 799
    761 784
    779 764
    802 751
    837 742
    """),
    powder_arc("""
    839 754
    816 758
    792 769
    775 783
    763 800
    """),
    powder_arc("""
    804 808
    813 801
    828 794
    841 793
    """),
    powder_arc("""
    816 809
    823 805
    833 801
    845 802
    """),
  ])
  quad_1_UL_first_attempt = quadrant([
    powder_arc("""
    846 728
    814 731
    790 740
    760 761"""),
    powder_arc("""
    836 755
    822 757
    802 763
    788 771"""),
    powder_arc("""
    787 794
    799 784
    810 776
    825 772"""),
    powder_arc("""
    846 793
    832 794
    822 797
    812 802"""),
  ])
  quad_2_UR = quadrant([
    powder_arc("""
    798 856
    800 875
    805 886
    815 898
    """),
    powder_arc("""
    775 864
    778 884
    787 902
    799 915
    """),
    powder_arc("""
    759 863
    763 889
    773 908
    783 922
    """),
    powder_arc("""
    734 873
    740 900
    748 918
    809 968
    """),
    powder_arc("""
    697 884
    718 943
    768 992
    802 1005
    """),
  ])
  quad_3_LR = quadrant([
    powder_arc("""
    854 925
    867 925
    886 919
    896 914"""),
    powder_arc("""
    867 937
    880 933
    896 927
    909 919
    """),
    powder_arc("""
    923 941
    904 954
    885 959
    860 963
    """),
    powder_arc("""
    973 943
    959 959
    939 977
    883 998
    """),
  ])
  quad_4_LL = quadrant([
    powder_arc("""
    914 700
    948 719
    998 790
    1007 831
    """),
    powder_arc("""
    929 753
    952 780
    964 807
    968 831
    """),
    powder_arc("""
    942 841
    941 815
    931 795
    897 762
    """),
    powder_arc("""
    897 776
    913 789
    928 815
    931 838
    """),
  ])
  quadrants = [quad_1_UL,quad_2_UR,quad_3_LR,quad_4_LL]
  for quad in quadrants:
    quad.refine_center_from_arcs()
    quad.show_summary()
  return derive_tile_translations(quadrants)

def derive_tile_translations(quads):
  params = get_initial_cxi_scope()
  tile_list=[]
  tile_translations=[]
  tile_flags=[]
  for itile in range(len(params.distl.detector_tiling)//4):
    corner_UL = matrix.col([params.distl.detector_tiling[itile*4],
                            params.distl.detector_tiling[itile*4+1]])
    corner_LR = matrix.col([params.distl.detector_tiling[itile*4+2],
                            params.distl.detector_tiling[itile*4+3]])
    middle = (corner_UL + corner_LR)/2.
    if middle[0]<init_ctr_slow and middle[1]<init_ctr_fast:
      tile_list.append(1)      #quadrant 1, UL

    elif middle[0]<init_ctr_slow and middle[1]>init_ctr_fast:
      tile_list.append(2)      #quadrant 2, UR

    elif middle[0]>init_ctr_slow and middle[1]>init_ctr_fast:
      tile_list.append(3)      #quadrant 3, LR

    else:
      tile_list.append(4)      #quadrant 4, LL
    translation = quads[tile_list[-1]-1].get_tile_translation()
    tile_translations.append(translation[0])
    tile_translations.append(translation[1])

    #finished with tile translations; now output flags for the actual tiles
    # where powder arcs have been observed (the inner four tiles)
    this_quad = quads[tile_list[-1]-1]
    first_point = this_quad.arcs[0].points[0]
    if corner_UL[0]<first_point[0] and first_point[0]<corner_LR[0] and\
       corner_UL[1]<first_point[1] and first_point[1]<corner_LR[1]:
         tile_flags.append(1)
    else: tile_flags.append(0)
  TT = "distl.tile_translations=%s"%(",".join([str(t) for t in tile_translations]))
  TF = "distl.tile_flags=%s"%(",".join([str(t) for t in tile_flags]))
  print(TT)
  print(TF)
  return [TT,TF]

class run3_cxi_limits:
  # Tile limits (ULx,ULy) (LRx,LRy) determined from a Feb 2011 Lysozyme test
  # set, using the program distl.find_active_area
  limits="""(1479, 1515) (1672, 1699)
(1281, 1515) (1474, 1699)
(1092, 1506) (1249, 1699)
(1065, 1506) (1090, 1699)
(853, 1505) (1037, 1698)
(1650, 1081) (1672, 1487)
(1479, 1303) (1604, 1487)
(1281, 1303) (1474, 1487)
(1466, 1082) (1650, 1274)
(1065, 1308) (1249, 1501)
(1253, 1080) (1437, 1273)
(853, 1307) (1037, 1500)
(622, 1465) (815, 1649)
(424, 1465) (617, 1649)
(213, 1473) (397, 1666)
(1048, 1098) (1241, 1282)
(850, 1098) (1043, 1282)
(623, 1252) (816, 1436)
(425, 1252) (618, 1436)
(213, 1275) (397, 1468)
(1466, 883) (1650, 1076)
(1506, 664) (1699, 848)
(1253, 882) (1437, 1075)
(1048, 885) (1241, 1069)
(1308, 664) (1501, 848)
(1099, 656) (1283, 849)
(850, 885) (1043, 1069)
(634, 1048) (818, 1241)
(421, 1048) (605, 1241)
(198, 1064) (391, 1248)
(1506, 451) (1699, 635)
(1308, 451) (1501, 635)
(1099, 458) (1283, 651)
(1514, 231) (1698, 424)
(1085, 262) (1278, 446)
(1514, 33) (1698, 226)
(885, 656) (1069, 849)
(885, 458) (1069, 651)
(887, 262) (1080, 446)
(634, 850) (818, 1043)
(421, 850) (605, 1043)
(656, 626) (849, 810)
(656, 414) (849, 598)
(664, 198) (848, 391)
(664, 0) (848, 193)
(458, 626) (651, 810)
(198, 851) (391, 1035)
(458, 414) (651, 598)
(451, 198) (635, 391)
(451, 0) (635, 193)
(1, 1473) (185, 1666)
(1, 1275) (185, 1468)
(0, 1064) (193, 1248)
(0, 851) (193, 1035)
(263, 617) (447, 810)
(50, 616) (234, 809)
(263, 419) (447, 612)
(50, 418) (234, 611)
(231, 213) (424, 397)
(33, 213) (226, 397)"""
  def __init__(self):
    self.ilimits = flex.int()
    for line in self.limits.split("\n"):
      for ituple in line.split(") ("):
        for dint in ituple.split(" "):
          self.ilimits.append(
            int(dint.replace(")","").replace("(","").replace(",","")))
  def as_string(self):
    return str(",".join( [str(a) for a in self.ilimits]))
  def as_ints(self):
    return self.ilimits

def get_initial_cxi_scope():
  from spotfinder.command_line.signal_strength import master_params

  argument_interpreter = master_params.command_line_argument_interpreter(
    home_scope="distl")
  object1 = argument_interpreter.process(arg=
    "distl.detector_tiling=%s"%run3_cxi_limits().as_string())
  working_params = master_params.fetch(sources=[object1])
  return working_params.extract()

if __name__=="__main__":
  lysozyme_calibration()
  print("OK")


 *******************************************************************************


 *******************************************************************************
spotfinder/array_family/__init__.py


 *******************************************************************************


 *******************************************************************************
spotfinder/array_family/flex.py
from __future__ import absolute_import, division, print_function
import scitbx.array_family.flex
import cctbx.array_family.flex

import boost_adaptbx.boost.python as bp
ext_ = bp.import_ext("cctbx_array_family_flex_ext")
from scitbx_array_family_flex_ext import *
from cctbx_array_family_flex_ext import *
from spotfinder_array_family_flex_ext import *
ext = ext_
del ext_

scitbx.array_family.flex.export_to("spotfinder.array_family.flex")


 *******************************************************************************


 *******************************************************************************
spotfinder/command_line/__init__.py


 *******************************************************************************


 *******************************************************************************
spotfinder/command_line/find_active_area.py
from __future__ import absolute_import, division, print_function
from six.moves import range
# LIBTBX_SET_DISPATCHER_NAME distl.find_active_area
import os, sys
from iotbx.detectors.npy import NpyImage
from spotfinder.core_toolbox import find_active_area

#special import of pickled NumPy array: CXI/CSPad data file
def ImageFactory(filename):
  if os.path.isfile(filename):
    I = NpyImage(filename)
    I.readHeader()
    return I

class graph_tracker:
  def has_one(self,graph):
    for key in graph.keys():
      if len(graph[key])==1:
        self.key = key
        self.item_sink = graph[key][0]
        return True
    return False
  def prune(self,graph):
    for key in graph.keys():
      try:
        graph[key].remove(self.item_sink)
      except ValueError: pass

def run_one(path, display):
  image = ImageFactory(path)
  image.read()
  data = image.linearintdata
  PC = find_active_area(data)

  sources = []; sinks = []
  for x in range(0,len(PC),2):
    if PC[x]>=0:
      sources.append((PC[x],PC[x+1]))
    else:
      sinks.append((-PC[x],-PC[x+1]))
  print(len(sources),len(sinks))
  assert len(sources)==len(sinks)
  graph = {}
  final_graph = {}
  for src in sources:
    item_sinks = [i for i in sinks if i[0]>src[0] and i[1]>src[1]]
    graph[src]=item_sinks

  G = graph_tracker()
  while G.has_one(graph):
    print(G.key, G.item_sink)
    final_graph[G.key]=G.item_sink
    del graph[G.key]
    G.prune(graph)

  assert len(graph)==0

if __name__ == "__main__":
  for arg in sys.argv[1:]:
    run_one(arg, display=True)


 *******************************************************************************


 *******************************************************************************
spotfinder/command_line/image_viewer.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME distl.image_viewer
# LIBTBX_PRE_DISPATCHER_INCLUDE_SH export PHENIX_GUI_ENVIRONMENT=1
# LIBTBX_PRE_DISPATCHER_INCLUDE_SH export BOOST_ADAPTBX_FPE_DEFAULT=1
import sys,os
from spotfinder.command_line.signal_strength import master_params
from libtbx.utils import Sorry

def run(args, command_name="distl.image_viewer"):
  help_str="""Same as distl.signal_strength (type that command for help) except that
  the image_viewer starts up an interactive GUI to visualize spotfinder spots.
"""

  if (len(args) == 0 or args[0] in ["H","h","-H","-h","help","--help","-help"]):
    print("usage:   %s image_filename [parameter=value ...]" % command_name)
    print("example: %s lysozyme_001.img distl.res.outer=2.0 distl.res.inner=6.0 distl.minimum_spot_area=8"%command_name)
    master_params.show(attributes_level=1,expert_level=1)
    print(help_str)
    return

  print("%s: characterization of candidate Bragg spots"%command_name)

  phil_objects = []
  argument_interpreter = master_params.command_line_argument_interpreter(
    home_scope="distl")
  image_file_name = None
  moving_pdb_file_name = None
  for arg in args:
    if (os.path.isfile(arg)):
      if (image_file_name is None): image_file_name = arg
      else: raise Sorry("Too many file names.")
    else:
      try: command_line_params = argument_interpreter.process(arg=arg)
      except KeyboardInterrupt: raise
      except Exception: raise Sorry("Unknown file or keyword: %s" % arg)
      else: phil_objects.append(command_line_params)

  working_params = master_params.fetch(sources=phil_objects)
  params = working_params.extract()

  def raise_missing(what):
      raise Sorry("""\
Missing file name for %(what)s structure:
  Please add
    %(what)s=file_name
  to the command line to specify the %(what)s structure.""" % vars())

  if (image_file_name is None):
    if (params.distl.image is None): raise_missing("file name")
  else:
    params.distl.image = image_file_name

  working_params = master_params.format(python_object=params)
  #working_params.show(expert_level=1)

  #Now actually run the program logic
  from spotfinder.applications import image_viewer as app_image_viewer
  modeler = app_image_viewer.run_signal_strength_class(params=working_params.extract())
  modeler.view()

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
spotfinder/command_line/mp_spotfinder_server_read_file.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME distl.mp_spotfinder_server_read_file
from libtbx.utils import Sorry
from spotfinder.command_line.signal_strength import master_params

def run(args, command_name="distl.mp_spotfinder_server_read_file"):
  help_str="""Multiprocessing server to find Bragg spots & quantify signal strength.
Full documentation: http://cci.lbl.gov/publications/download/ccn_jul2010_page18.pdf
Allowed parameters:
"""

  if (len(args)>=1 and args[0] in ["H","h","-H","-h","help","--help","-help"]):
    print("usage:   %s [parameter=value ...]" % command_name)
    print("example: %s distl.port=8125 distl.processors=8"%command_name)
    print(help_str)
    return
  else:  print(help_str)

  phil_objects = []
  argument_interpreter = master_params.command_line_argument_interpreter(
    home_scope="distl")
  for arg in args:
      try: command_line_params = argument_interpreter.process(arg=arg)
      except KeyboardInterrupt: raise
      except Exception: raise Sorry("Unknown file or keyword: %s" % arg)
      else: phil_objects.append(command_line_params)

  working_params = master_params.fetch(sources=phil_objects)
  params = working_params.extract()

  working_params = master_params.format(python_object=params)
  #working_params.show()

  screen = 100
  for D in working_params.all_definitions():
    fp = D.object.full_path()
    if fp in ["distl.image", "distl.verbose", "distl.pdf_output"]: continue
    name = "  %s=%s"%(D.object.full_path(),D.object.extract())
    help = D.object.help
    if D.object.expert_level > 1: continue
    if len(name) + len(help) < screen and len(name) < 36:
        print("%-36s"%name,"[%s]"%help)
    else:
      print("%-36s"%name, end=' ')
      tokens = ("[%s]"%help).split()
      reserve = min(screen-36,screen-len(name))
      while len(tokens)>0:
        reserve -= len(tokens[0])
        if len(tokens[0])>(screen-36):break
        while reserve<0:
          print()
          print(" "*36, end=' ')
          reserve = screen-36
        print(tokens.pop(0), end=' ')
      print()

  #Now actually run the program logic
  from spotfinder.servers import mp_spotfinder_server_read_file as srv

  NUMBER_OF_PROCESSES = params.distl.processors
  srv.generate_common_parameters(working_params)

  server_address = ('', params.distl.port)

  srv.image_request_handler.protocol_version = "HTTP/1.0"

  print("Serving %d-process HTTP on"%NUMBER_OF_PROCESSES, server_address[0], "port", server_address[1], "...")
  print("To exit press Ctrl-C")
  srv.runpool(server_address,NUMBER_OF_PROCESSES,srv.image_request_handler)

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
spotfinder/command_line/signal_strength.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME distl.signal_strength
import spotfinder
import libtbx.phil
from libtbx.utils import Sorry
import sys, os
additional_spotfinder_phil_defs ="""
distl {
  minimum_spot_area = None
    .type = int
    .help = "Override application default (PADs:5, others:10) set minimum spot area (in pixels) within spotfinder."
  minimum_signal_height = None
    .type = float
    .help = "Override application default (PADs:2.5, CCDs:1.5) set minimum signal height (in units of background noise sigma) within spotfinder."
  minimum_spot_height = None
    .type = float
    .help = "Expert use only; after pixels are classified as signals rather than noise, minimum height to be considered a spot maximum (in units of background noise sigma). Default=3.5"
  spot_area_maximum_factor = None
    .type = float
    .help = "Expert use only; max spot area expressed as a multiple of minimum_spot_area. Default=5.0"
  peak_intensity_maximum_factor = None
    .type = float
    .help = "Expert use only; max peak intensity filter for use by libdistl. Default=10.0"
  method2_cutoff_percentage = 20
    .type = float
    .help = As described in Zhang(2006) spotfinder paper, the resolution cutoff is made at a shell that has this percentage of
    .help = spots as compared to the two inner shells.  Needs to be set to a lower percentage for still (XFEL) data!
    .help = Low percentage (5%% as recommended for XFEL) is more permissive and accepts higher resolution Bragg spots.
  compactness_filter = False
    .type = bool
    .help = "For CXI data (and Pilatus data?), set this to True to eliminate small non-compact spots"
  detector_tiling = None
    .type = ints
    .help = "Prior analysis of active area tiling on the detector; groups of 4 integers: UL_slow,UL_fast,LR_slow,LR_fast"
    .help = "...where UL=upper left corner, LR=lower right corner; coordinates form a Python range"
    .expert_level = 2
  tile_translations = None
    .type = ints
    .help = "For each identified tile, a group of 2 integers for slow & fast translations to correct position,"
    .help = "given in pixels"
    .expert_level = 2
  tile_flags = None
    .type = ints (value_min=0,value_max=1)
    .help = "For each identified tile, an integer [0,1] acting as a bool to define whether to ignore its data."
    .expert_level = 2
  quad_translations = None
    .type = ints
    .help = "For quadrants UL,UR,LL,LR groups of 2 integers for slow & fast translations to correct position,"
    .help = "given in pixels"
    .expert_level = 2
  detector_format_version = None
    .type = str
    .help = "Whatever additional text information is necessary to get an accurate file read"
    .expert_level = 2
  %s
  pdf_output = None
    .type = str
    .help="File name for optional PDF graphical output for distl.signal_strength (*.pdf)"
  image_viewer = False
    .type = bool
    .expert_level=2
    .help="Open the image viewer to inspect the spotfinder spots."
  port = 8125
    .type = int
    .help="For the server version, port number to listen for requests"
  processors = 1
    .type = int
    .help="For the multithreaded server version, number of server processes to be used"
  nproc = 1
    .type = int
    .short_caption = Number of processes
    .help="Number of processes to be used when processing multiple images."
}
""" % spotfinder.inner_phil_str

master_params_defs = """\
distl {
  image = None
    .type = str
    .help="Image file name"
  res {
    outer=None
      .type=float
      .help="High resolution limit in angstroms"
    inner=None
      .type=float
      .help="Low resolution limit in angstroms"
  }
  verbose = False
    .type = bool
    .help="Lengthy spot printout"
  dxtbx = False
    .type = bool
    .help="Switch algorithms to dxtbx models"
  bins {
    verbose = False
      .type = bool
      .help="Additional printout binned by resolution range"
    N = 20
      .type = int
      .help="Maximum number of bins, but fewer can result if there are few spots"
    corner = True
      .type = bool
      .help="Extend the binning all the way to detector corner, otherwise to outermost spot on first image"
  }
  range = None
    .type = ints (value_min = 0, size_max = 2)
    .help = "For HDF5 data, specifies image index (0-based), or Python-style range (0,10 means first 10)"
}

%s
"""%(spotfinder.labelit_related_commands)+additional_spotfinder_phil_defs

master_params = libtbx.phil.parse(master_params_defs)

def run(args, command_name="distl.signal_strength"):
  help_str="""explanation:
Local background and background standard deviation are determined.
Pixels are classified as signal if > minimum_signal_height sigmas above background.
Signals are chosen as spot maxima if > minimum_spot_height sigmas above background.
Spots are grown around the maxima, and retained if they fit minimal area criteria.
Total number of candidates at this stage is reported as "Spot Total"
Ice rings are eliminated by at least two different algorithms (rings of high pixel
  values and rings of high spot count).
Resolution filters are applied if given on the command line.
Total number of candidates at this stage is reported as "In-Resolution Total"
Other spot-quality filters are applied to give the number of "Good Bragg Candidates".
Method 1 Resolution is a published legacy algorithm (Zhang et al, 2006) no longer used.
Method 2 Resolution reflects drop off of spot count as a function of resolution shell,
  but is overridden by command line input of distl.res.outer
Signal strength of the Good Bragg Candidates is then presented as integrated area of
  the spot above local background, expressed in pixel-analog/digital units.
Very verbose output is available by setting distl.verbose=True
Full documentation: http://cci.lbl.gov/publications/download/ccn_jul2010_page18.pdf
"""

  if (len(args) == 0 or args[0] in ["H","h","-H","-h","help","--help","-help"]):
    print("usage:   %s image_filename [parameter=value ...]" % command_name)
    print("example: %s lysozyme_001.img distl.res.outer=2.0 distl.res.inner=6.0 distl.minimum_spot_area=8"%command_name)
    master_params.show(attributes_level=1,expert_level=1)
    print(help_str)
    return

  print("%s: characterization of candidate Bragg spots"%command_name)

  phil_objects = []
  argument_interpreter = master_params.command_line_argument_interpreter(
    home_scope="distl")
  image_file_name = None
  moving_pdb_file_name = None
  for arg in args:
    if (os.path.isfile(arg)):
      if (image_file_name is None): image_file_name = arg
      else: raise Sorry("Too many file names.")
    else:
      try: command_line_params = argument_interpreter.process(arg=arg)
      except KeyboardInterrupt: raise
      except Exception: raise Sorry("Unknown file or keyword: %s" % arg)
      else: phil_objects.append(command_line_params)

  working_params = master_params.fetch(sources=phil_objects)
  params = working_params.extract()

  def raise_missing(what):
      raise Sorry("""\
Missing file name for %(what)s structure:
  Please add
    %(what)s=file_name
  to the command line to specify the %(what)s structure.""" % vars())

  if (image_file_name is None):
    if (params.distl.image is None): raise_missing("file name")
  else:
    params.distl.image = image_file_name

  print("#Parameters used:")
  print("#phil __ON__")
  print()
  working_params = master_params.format(python_object=params)
  working_params.show(expert_level=1)
  print()
  print("#phil __OFF__")
  print()

  #Now actually run the program logic
  from spotfinder.applications import signal_strength
  return signal_strength.run_signal_strength(working_params.extract())

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
spotfinder/command_line/sweep_strength.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME distl.sweep_strength
# LIBTBX_PRE_DISPATCHER_INCLUDE_SH export BOOST_ADAPTBX_FPE_DEFAULT=1
from six.moves import range
import spotfinder
import libtbx.phil
from libtbx.utils import Sorry
import sys, os
from spotfinder.command_line.signal_strength import additional_spotfinder_phil_defs


master_params = libtbx.phil.parse("""\
distl {
  res {
    outer=None
      .type=float
      .help="High resolution limit in angstroms"
    inner=None
      .type=float
      .help="Low resolution limit in angstroms"
  }
  plot {
    file_name = None
      .type = path
      .help = "File path to output a plot of the distl results vs image number."
              "Supported formats include png, jpeg, pdf, ps, eps, svg."
  }
  csv = None
    .type = path
    .help = "Optional file name for output of distl results in CSV format."
  verbosity = 1
    .type = int
    .help="Control the amount of output:"
          "  0: print just the table"
          "  1: also print the parameters used by the program"
          "  2: also print distl summary for each individual image"
  bins {
    verbose = False
      .type = bool
      .help="Additional printout binned by resolution range"
    N = 20
      .type = int
      .help="Maximum number of bins, but fewer can result if there are few spots"
    corner = True
      .type = bool
      .help="Extend the binning all the way to detector corner, otherwise to outermost spot on first image"
  }
  dxtbx = False
    .type = bool
    .help="Switch algorithms to dxtbx models"
}

%s
"""%(spotfinder.labelit_related_commands)+additional_spotfinder_phil_defs)


class Empty(object): pass

def run_sweep_strength(image_file_names, params):
  E = Empty()
  E.argv=['Empty']
  E.argv.extend(image_file_names)
  return run_signal_strength_core(params,E)

def run_signal_strength_core(params,E):
  from spotfinder.applications.wrappers import DistlOrganizer
  verbosity = params.distl.verbosity
  if params.distl.res.inner!=None:
    params.distl_lowres_limit = params.distl.res.inner
  if params.distl.res.outer!=None:
    params.force_method2_resolution_limit = params.distl.res.outer
    params.distl_highres_limit = params.distl.res.outer

  params.distl_force_binning = False
  params.distl_permit_binning = False
  params.wedgelimit = len(E.argv)
  params.spotfinder_header_tests = False
  Org = DistlOrganizer(verbose=(verbosity>1), argument_module=E,
                       phil_params=params)
  Org.printSpots()
  return Org

def table(spotfinder_results, keys):
  headers = ['Image#']
  headers.extend(keys)
  rows = [headers]
  for i in sorted(spotfinder_results.images.keys()):
    spotfinder_one_image = spotfinder_results.images[i]
    row = []
    row.append("%i" %i)
    for k in keys:
      value = spotfinder_one_image[k]
      try:
        as_float = float(value)
        as_int = int(value)
        if float(as_int) == as_float:
          row.append("%i" %as_int)
        else:
          row.append("%.2f" %as_float)
      except (ValueError, TypeError):
        row.append("%s" %value)
    rows.append(row)
  return rows

def print_table(spotfinder_result, keys, out=None):
  if out is None:
    import sys
    out = sys.stdout
  from libtbx import table_utils
  rows = table(spotfinder_result, keys)
  print(table_utils.format(rows, has_header=True), file=out)

def as_columns(spotfinder_results):
  d = {}
  keys = (
    'N_spots_total', 'N_spots_non-ice', 'N_spots_resolution',
    'N_spots_unimodal', 'N_spots_inlier',
    #'intensity', 'area', 'neighbor', #'maxcel',
    'resolution', 'distl_resolution', 'ice-ring_impact')

  for i in sorted(spotfinder_results.images.keys()):
    spotfinder_result = spotfinder_results.images[i]
    for k in keys:
      d.setdefault(k, [])
      d[k].append(spotfinder_result[k])
  return d

def plot(spotfinder_results, file_name):
  try:
    import matplotlib
    matplotlib.use('Agg') # use a non-interactive backend
    # http://matplotlib.org/faq/howto_faq.html#generate-images-without-having-a-window-appear
    from matplotlib import pyplot
  except ImportError:
    raise Sorry("matplotlib must be installed to generate a plot.")
  columns = as_columns(spotfinder_results)
  n_spots = columns.get('N_spots_inlier')
  resolution = columns.get('resolution')
  i_image = range(1, len(n_spots)+1)
  fig = pyplot.figure()
  ax1 = fig.add_subplot(111)
  sc1 = ax1.scatter(i_image, n_spots, s=20, color='blue', marker='o', alpha=0.5)
  ax1.set_xlabel('Image #')
  ax1.set_ylabel('# spots')
  ax1.set_xlim((0, len(n_spots)))
  ax1.set_ylim(bottom=0)
  ax2 = ax1.twinx()
  sc2 = ax2.scatter(i_image, resolution, s=20, color='red', marker='^', alpha=0.5)
  ax2.set_ylabel(u'resolution (\u00c5)')
  ax2.set_xlim((0, len(n_spots)))
  ax2.invert_yaxis()
  lgd = pyplot.legend(
    (sc1, sc2), ('# good spots', 'resolution (method 2)'), ncol=2,
    loc='upper center',
    mode="expand", borderaxespad=0.,
    bbox_to_anchor=(0.0,-0.22, 1., .102))
  pyplot.savefig(file_name, dpi=600, bbox_extra_artists=(lgd,),
                 bbox_inches='tight')

def as_csv(spotfinder_results, out=None):
  if out is None:
    import sys
    out = sys.stdout
  columns = as_columns(spotfinder_results)
  from iotbx import csv_utils
  csv_utils.writer(out, list(columns.values()), field_names=list(columns.keys()))


def run(args, command_name="distl.sweep_strength"):
  help_str="""\
Similar to distl.signal_strength, but acting on a sweep of images, with
tabulation of the results and optional output of results as CSV file and
plots of number of spots and resolution with image number.
"""

  if (len(args) == 0 or args[0] in ["H","h","-H","-h","help","--help","-help"]):
    print("usage:   %s image_prefix_*.img [parameter=value ...]" % command_name)
    print("example: %s lysozyme_*.img distl.minimum_spot_area=8 plot.file_name=lysozyme.pdf"%command_name)
    master_params.show(attributes_level=1,expert_level=1)
    print(help_str)
    return

  print("%s: characterization of candidate Bragg spots"%command_name)

  phil_objects = []
  argument_interpreter = master_params.command_line_argument_interpreter(
    home_scope="distl")
  image_file_names = []
  moving_pdb_file_name = None

  for arg in args:
    if (os.path.isfile(arg)):
      image_file_names.append(arg)
    else:
      try: command_line_params = argument_interpreter.process(arg=arg)
      except KeyboardInterrupt: raise
      except Exception: raise Sorry("Unknown file or keyword: %s" % arg)
      else: phil_objects.append(command_line_params)

  if len(image_file_names) < 2:
    raise RuntimeError(
      "Please provide more than one file. Alternatively use "
      "distl.signal_strength to process a single image file.")

  working_params = master_params.fetch(sources=phil_objects)
  params = working_params.extract()

  if params.distl.verbosity > 0:
    print("#Parameters used:")
    print("#phil __ON__")
    print()
    working_params = master_params.format(python_object=params)
    working_params.show(expert_level=1)
    print()
    print("#phil __OFF__")
    print()

  from spotfinder.applications import signal_strength

  spotfinder_results = run_sweep_strength(image_file_names, params)
  print_table(spotfinder_results.S, keys=["N_spots_inlier", "resolution"])

  csv_file_name = params.distl.csv
  if csv_file_name is not None:
    with open(csv_file_name, 'wb') as f:
      as_csv(spotfinder_results.S, out=f)
  plot_file_name = params.distl.plot.file_name
  if plot_file_name is not None:
    plot(spotfinder_results.S, file_name=plot_file_name)


if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
spotfinder/command_line/thin_client.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME distl.thin_client
from spotfinder.servers.thin_client import do_main

if __name__=="__main__":
  "Client is intended to be used with distl.mp_spotfinder_server_read_file"
  import sys
  try:
    filepath, host, port = sys.argv[1:4]
    port = int(port)
  except Exception:
    print("""
Usage:
distl.thin_client <filepath> <host> <port>
Three mandatory arguments:
  filepath: absolute or relative path name of the ADSC test image to be analyzed
  host: usually "localhost";
  port: port number of image analyzer http service
""")
  do_main(filepath, host, port)


 *******************************************************************************


 *******************************************************************************
spotfinder/core_toolbox/__init__.py
from __future__ import absolute_import, division, print_function
from six.moves import range
import spotfinder.array_family.flex # implicit import

import boost_adaptbx.boost.python as bp
ext = bp.import_ext("spotfinder_distltbx_ext")
from spotfinder_distltbx_ext import *
bp.import_ext("spotfinder_hough_ext")
from spotfinder_hough_ext import *
from libtbx import adopt_init_args
from libtbx.utils import Sorry

class Distl(w_Distl):

  def __init__(self,options,image,pd,report_overloads=False,params=None):
    w_Distl.__init__(self,options,report_overloads)
    adopt_init_args(self, locals())

    try:    saturation = image.saturation
    except Exception: saturation = 65535
    try:    peripheral_margin = params.distl.peripheral_margin
    except Exception: peripheral_margin = 20
    self.setspotimg(pixel_size = image.pixel_size, distance = image.distance,
                    wavelength = image.wavelength, xbeam = float(pd['xbeam']),
                    ybeam = float(pd['ybeam']), rawdata = image.rawdata,
                    peripheral_margin = peripheral_margin,
                    saturation = saturation)
    #Fixes a longstanding gremlin:  my corrected xy must be propagated
    # to zepu's code; or else ice rings are treated incorrectly.

    #Setup tiling, if any.
    self.set_tiling(image.vendortype)

    self.deprecation_warnings()
    if params!=None:
        if params.distl.minimum_spot_area != None:
          self.set_minimum_spot_area(params.distl.minimum_spot_area)
        if params.distl.minimum_signal_height != None:
          self.set_minimum_signal_height(params.distl.minimum_signal_height)
        if params.distl.minimum_spot_height != None:
          self.set_minimum_spot_height(params.distl.minimum_spot_height)
        if params.distl.spot_area_maximum_factor != None:
          self.set_spot_area_maximum_factor(params.distl.spot_area_maximum_factor)
        if params.distl.peak_intensity_maximum_factor != None:
          self.set_peak_intensity_maximum_factor(params.distl.peak_intensity_maximum_factor)
        self.set_scanbox_windows(params.distl.scanbox_windows)
        if params.distl.detector_tiling != None:
          IT = image.get_tile_manager(params
               ).effective_tiling_as_flex_int()

          self.set_tiling(detector_tiling = IT,
                          peripheral_margin = peripheral_margin)

    self.parameter_guarantees()

    self.get_underload()
    try:
      self.pxlclassify()
    except Exception as e:
      if str(e).find("cannot distinguish signal")>0: print(e)
      else: raise e
    self.search_icerings()
    self.search_maximas()
    self.search_spots()
    self.search_overloadpatches()
    self.finish_analysis()

    if params!=None and params.distl.compactness_filter == True:
      self.compactness_filter()

  def compactness_filter(self):
    from spotfinder.array_family import flex
    keepspot = flex.bool()
    for spot in self.spots:
      x = [s.x for s in spot.bodypixels]
      y = [s.y for s in spot.bodypixels]
      xmin = min(x); ymin = min(y)
      xmax = max(x); ymax = max(y)
      graph = flex.bool(flex.grid(max(x)-xmin+1,max(y)-ymin+1),False)
      for s in spot.bodypixels:
        graph[(s.x-xmin,s.y-ymin)]=True
      edge_count = 0
      nx,ny = graph.focus()
      # count the edges along x:
      for xc in range(nx):
        for yc in range(ny-1):
          if graph[(xc,yc)] and graph[(xc,yc+1)]:  edge_count+=1
      # count the edges along y:
      for yc in range(ny):
        for xc in range(nx-1):
          if graph[(xc,yc)] and graph[(xc+1,yc)]:  edge_count+=1
      # count forward diagonals:
      for xc in range(nx-1):
        for yc in range(ny-1):
          if graph[(xc,yc)] and graph[(xc+1,yc+1)]:  edge_count+=1
      # count backward diagonals:
      for xc in range(nx-1):
        for yc in range(1,ny):
          if graph[(xc,yc)] and graph[(xc+1,yc-1)]:  edge_count+=1

      vertex_count = spot.bodypixels.size()
      if vertex_count >=9:
        keepspot.append( edge_count/vertex_count > 2.0 )
      else:
        keepspot.append( edge_count > {8:12, 7:9, 6:7, 5:5, 4:4, 3:2, 2:0, 1:-1}[vertex_count] )
    self.spots = self.spots.select(keepspot)

  def deprecation_warnings(self):
    """Eventually migrate away from dataset_preferences.py mechanism, toward
    100% use of phil for specifying parameters.  For now, simply guard against
    specifying a given parameter by both mechanisms."""

    template = "%s on the command line and %s parameter (%s) of dataset_preferences.py file specify the same thing."

    if self.params==None: return

    # spotarealowcut <==> -s2 <==> minimum_spot_area
    if self.params.distl.minimum_spot_area != None:
      if self.options.find("-s2") >= 0:
        raise Sorry( (template%("minimum_spot_area (%d)","-s2",self.options)%(
        self.params.distl.minimum_spot_area,)) )

    if self.params.distl.minimum_signal_height != None:
      template1 = template%("minimum_signal_height (%.2f)","-bg%1d",self.options)

      # bgupperint <==> -bg0 <==> minimum_signal_height
      if self.options.find("-bg0") >= 0:
        raise Sorry( (template1%(self.params.distl.minimum_signal_height,0)) )

      # bgupperint <==> -bg1 <==> minimum_signal_height
      if self.options.find("-bg1") >= 0:
        raise Sorry( (template1%(self.params.distl.minimum_signal_height,1)) )

      # bgupperint <==> -bg2 <==> minimum_signal_height
      if self.options.find("-bg2") >= 0:
        raise Sorry( (template1%(self.params.distl.minimum_signal_height,2)) )

    # difflowerint <==> -d1 <==> minimum_spot_height
    if self.params.distl.minimum_spot_height != None:
      if self.options.find("-d1") >= 0:
        raise Sorry( (template%("minimum_spot_height (%.2f)","-d1",self.options)%(
        self.params.distl.minimum_spot_height,)) )

    # spotareamaxfactor <==> -s7 <==> spot_area_maximum_factor
    if self.params.distl.spot_area_maximum_factor != None:
      if self.options.find("-s7") >= 0:
        raise Sorry( (template%("spot_area_maximum_factor (%.2f)","-s7",self.options)%(
        self.params.distl.spot_area_maximum_factor,)) )

    # spotpeakintmaxfactor <==> -s8 <==> peak_intensity_maximum_factor
    if self.params.distl.peak_intensity_maximum_factor != None:
      if self.options.find("-s8") >= 0:
        raise Sorry( (template%("peak_intensity_maximum_factor (%.2f)","-s8",self.options)%(
        self.params.distl.peak_intensity_maximum_factor,)) )

    # scanbox_window <==> -bx0,1,2 <==> spot_area_maximum_factor
    if self.options.find("-bx0") >= 0 or self.options.find("-bx1") >= 0 or self.options.find("-bx2") >= 0:
        raise Sorry( """dataset_preferences.py parameters -bx0 -bx1 -bx2 are no longer allowed; found %s.
    Use command line option distl.scanbox_windows=bx0,bx1,bx2 instead with three integer arguments."""%self.options)

@bp.inject_into(SpotFilterAgent)
class _():
  def __getinitargs__(self):
    return (self.pixel_size, self.xbeam, self.ybeam, self.distance,
            self.wavelength, self.icerings)


 *******************************************************************************


 *******************************************************************************
spotfinder/core_toolbox/boost_python/tst_small_image.py
from __future__ import absolute_import, division, print_function
def compute_image(work_params):
  dpx,dpy = work_params.detector.pixels
  from scitbx.array_family import flex
  assert work_params.noise.max > 0
  mt = flex.mersenne_twister(seed=work_params.noise.random_seed)
  image = mt.random_size_t(
    size=dpx*dpy,
    modulus=work_params.noise.max).as_int()
  image.reshape(flex.grid(dpx,dpy))
  pixels_center = None
  if (work_params.fill_beam_center):
    assert (dpx % 2) == (dpy % 2)
    if (dpx % 2 == 0):
      pixels_center = """\
 OOOO
OOOOOO
OOOOOO
OOOOOO
OOOOOO
 OOOO
"""
    else:
      pixels_center = """\
   O
 OOOOO
 OOOOO
OOOOOOO
 OOOOO
 OOOOO
   O
"""
  if (pixels_center is not None):
    lines = pixels_center.splitlines()
    n = max([len(line) for line in lines])
    oi,oj = dpx//2-n//2, dpy//2-n//2
    for i,line in enumerate(lines):
      line = line + " "*(n-len(line))
      for j,c in enumerate(line):
        if (c == "O"):
          pixel = (oi+i, oj+j)
          #print "beam center pixel:", pixel
          image[pixel] = work_params.signal_max//1000
  return image

def process(work_params, image):
  from spotfinder import core_toolbox
  options = ""
  report_overloads = True
  dobj = core_toolbox.w_Distl(options, report_overloads)
  dsx,dsy = work_params.detector.size
  dpx,dpy = work_params.detector.pixels
  pixel_size = dsx / dpx
  assert pixel_size == dsy / dpy
  dobj.setspotimg(
    pixel_size = pixel_size,
    distance = work_params.detector.distance,
    wavelength = work_params.wavelength,
    xbeam = dsx/2,
    ybeam = dsy/2,
    rawdata = image,
    peripheral_margin = work_params.spotfinder.peripheral_margin,
    saturation = work_params.signal_max)
  dobj.set_tiling("")
  dobj.set_peak_intensity_maximum_factor(100.)
  dobj.set_minimum_spot_area(10)
  dobj.set_scanbox_windows(work_params.spotfinder.scanbox_windows)
  dobj.parameter_guarantees()
  dobj.get_underload()
  dobj.pxlclassify()
  dobj.search_icerings()
  dobj.search_maximas()
  dobj.search_spots()
  dobj.search_overloadpatches()
  dobj.finish_analysis()
  dists = dobj.spots.ctr_mass_distances_from_direct_beam(
    detector_size=(dsx,dsy),
    detector_pixels=(dpx,dpy),
    xy_beam=(dsx/2,dsy/2)) # just a minimal test
  assert dists.size() == dobj.spots.size()
  return dobj

def run(args):
  import spotfinder
  from libtbx import phil
  phil_str = """\
wavelength = 1
  .type = float
signal_max = 60000
  .type = int
noise {
  max = 10
    .type = int
  random_seed = 0
    .type = int
}
detector {
  distance = 250
    .type = float
  size = 200 200
    .type = floats(size=2)
    .help = "Detector edge length (x,y)"
  pixels = 1000 1000
    .type = ints(size=2)
    .help = "Number of pixels in each detector dimension (x,y)"
}
fill_beam_center = False
  .type = bool
""" + spotfinder.phil_str
  import libtbx.phil
  master_phil = libtbx.phil.parse(input_string=phil_str)
  argument_interpreter = master_phil.command_line_argument_interpreter()
  updated_params = master_phil.fetch(sources =
   [argument_interpreter.process(arg=arg) for arg in args])
  work_params = updated_params.extract()
  image = compute_image(work_params)
  #from matplotlib import pyplot as plt
  #plt.imshow(image.as_numpy_array(),cmap="hot", interpolation="nearest")
  #plt.show()
  return process(work_params, image)

def run_scanbox_tests():
  # Large image, normal conditions
  run([])

  # SQUARE vs. CIRCLE image shape detection relies on hard-coded minimum size;
  #  to avoid segmentation fault, return UNKNOWN shape for small images (eg, 45x45).
  run("""spotfinder.scanbox_windows=10,10,10 detector.pixels=45,45""".split(" "))

  # Fix error in iotbx/detectors/scanbox.h; a 90x90 pixel image with 20-pixel margin
  #  should yield exactly one 50x50-pixel scanbox (insert SCITBX_EXAMINE to check)
  run("""spotfinder.scanbox_windows=50,50,50 detector.pixels=90,90""".split(" "))

  # A 89x89 pixel image with 20-pixel margin should yield exactly zero scanboxes;
  #  avoid divide-by-zero error by returning from generate_normal_spacing().
  run("""spotfinder.scanbox_windows=50,50,50 detector.pixels=89,89""".split(" "))

  # Function libdistl.cpp get_underload() makes hard-coded assumptions about
  #  minimum image size; avoid the special heuristics if image is < 100x100 pixels
  #  Note the minimum scanbox_window size is implicity hardcoded in libdistl.cpp,
  #  most likely in the diffimage::search_maximas() procedure.
  run("""spotfinder.scanbox_windows=10,10,10 detector.pixels=25,25 peripheral_margin=0""".split(" "))

  for dp,pkpx in [(100,32),(101,29)]:
    #print "detector pixels:", (dp,dp)
    spots = run([
      "detector.pixels=%d,%d" % (dp,dp),
      "fill_beam_center=True"]).spots
    assert spots.size() == 1
    spot = spots[0]
    assert pkpx == len(spot.bodypixels)
    #for px in spot.bodypixels:
    #  print px.x, px.y
    #print (spot.ctr_mass_x(), spot.ctr_mass_y())
    #print

  print("OK")

if (__name__ == "__main__"):
  import sys
  if len(sys.argv) > 1:
    run(args=sys.argv[1:])
  else:
    run_scanbox_tests()


 *******************************************************************************


 *******************************************************************************
spotfinder/core_toolbox/close_spots_detail.py
from __future__ import absolute_import, division, print_function
from six.moves import range
import math
from spotfinder.array_family import flex

'''Separate module for special treatment of close spots.
'''

#extraordinary procedure, when many spots are close.  Include closely
#  spaced spots in autoindexing, if it appears that they truly
#  reflect lattice spacing.

# a poor man's Fourier transform of the image, to determine
#   if close spots form a regular pattern

class NearNeighborVectors:

  def __init__(self, ave_area, query_centers, fstats, ann_adaptor):
    self.plot = {}
    self.pmax = []

    plot_to_spot_ratio = 20.
    significant_vector_fraction_of_highest = 0.2
    significant_vector_fraction_of_recent_child = 0.05

    # make plot with area 20*average spot area (an arbitrary cutoff)
    self.deltaxylimit = int(math.sqrt(plot_to_spot_ratio*ave_area)/2.)+1
    for x in range(-self.deltaxylimit,self.deltaxylimit+1):
      self.plot[x]=flex.int(2*self.deltaxylimit+1)

    for d in range(len(query_centers)//2):
      vector = (int( fstats.master[ann_adaptor.nn[d]].max_pxl_x()-query_centers[2*d] ),
                int( fstats.master[ann_adaptor.nn[d]].max_pxl_y()-query_centers[2*d+1]))
      if abs(vector[0])<=self.deltaxylimit and \
         abs(vector[1])<=self.deltaxylimit:
        self.plot[vector[0]][self.deltaxylimit+vector[1]]+=1
        self.plot[-vector[0]][self.deltaxylimit-vector[1]]+=1

    # get the maximum value of this "Fourier" plot
    allx = ()
    for x in range(-self.deltaxylimit+1,self.deltaxylimit):
      allx=allx+tuple(self.plot[x])
    maxp = max(allx) #"the largest peak is",maxp

    # Search for all local maxima in the plot. Only look in positive hemisphere.
    for locx in range(-self.deltaxylimit+1,self.deltaxylimit):
      for locy in range(-self.deltaxylimit+1,self.deltaxylimit):
        if locy>0 or (locy==0 and locx>0):  #primary hemisphere
          tlocy = self.deltaxylimit+locy
          refval = self.plot[locx][tlocy]
          #(Two important parameters subject to adjustment)
          if refval > significant_vector_fraction_of_highest*maxp and \
             refval > significant_vector_fraction_of_recent_child*\
                      fstats['N_%s'%fstats.most_recent_child()] and \
             refval >= self.plot[locx][tlocy+1] and \
             refval >= self.plot[locx+1][tlocy+1] and \
             refval >= self.plot[locx+1][tlocy] and \
             refval >= self.plot[locx+1][tlocy-1] and \
             refval > self.plot[locx][tlocy-1] and \
             refval > self.plot[locx-1][tlocy-1] and \
             refval > self.plot[locx-1][tlocy] and \
             refval > self.plot[locx-1][tlocy+1]:
             self.pmax.append((locx,locy,refval))

  def show_maxima(self):
    print("all maxima:",self.pmax)

  def show_vector_map(self):
     for x in range(-self.deltaxylimit,self.deltaxylimit+1):
      for i,y in enumerate(self.plot[x]):
        if x==0 and i==len(self.plot[x])//2:
          print("   X", end=' ')
        else:
          print("%4d"%y, end=' ')
      print()

  def vectors(self):
    return self.pmax


 *******************************************************************************


 *******************************************************************************
spotfinder/diffraction/__init__.py


 *******************************************************************************


 *******************************************************************************
spotfinder/diffraction/geometry.py
from __future__ import absolute_import, division, print_function
import math
"""assume data collection at two-theta angle of zero.
   assume a flat square detector normal to beam.
   calculate the fraction of a resolution shell covered by the detector.
"""
from scitbx import matrix
from spotfinder.core_toolbox import geometry_2d_base

def point(a,b):
  return matrix.col((a,b,0))

def magnitude(a):
  return math.sqrt( a.dot(a) )

def unit_vector(a):
  return a.normalize()

def dot(a,b):
  return a.dot(b)

def polar(a):
  return magnitude(a), math.atan2(a[1],a[0]) # r,theta.  z direction ignored

def cross_product(a,b):
  return a.cross(b)

def radius_to_resol(radius,parameter_dictionary):
  # assumes radius & distance in same units (e.g., mm)
  # wavelength and resolution in same units (e.g., Angstroms)
  distance = float(parameter_dictionary['distance'])
  wavelength = float(parameter_dictionary['wavelength'])
  theta = math.atan2(radius,distance)/2.0
  return wavelength/(2.0*math.sin(theta))

class Geom2d(geometry_2d_base):
  def __init__(self,pd):
    self.pd = pd
    geometry_2d_base.__init__(self,pixel_size=float(pd["pixel_size"]),
    size1=float(pd["size1"]),
    size2=float(pd["size2"]),
    xbeam=float(pd["xbeam"]),
    ybeam=float(pd["ybeam"]),
    distance=float(pd["distance"]),
    wavelength=float(pd["wavelength"]),
  )

if __name__=='__main__':
  from libtbx.test_utils import approx_equal
  pd = {'pixel_size':'1.0','xbeam':'3','ybeam':'6','size1':'10','size2':'10',
        'distance':'200','wavelength':'1'}
  f = Geom2d(pd)
  test_values = [(200,1.0), (100,1.0), (50,0.7643789), (30,0.2827813), (20,0.0)]
  for item in test_values:
    assert approx_equal(f(item[0]),item[1])
  print("OK")


 *******************************************************************************


 *******************************************************************************
spotfinder/diffraction/imagefiles.py
from __future__ import absolute_import, division, print_function
from six.moves import range
import os, re
from iotbx.detectors import ImageFactory, url_support
from iotbx.detectors.beam_center_convention import convert_beam_instrument_to_imageblock

# Contain information about a single file name
  # Pattern1:  valid image file names conform to the regular expression
  # fileroot_[0-9][0-9][0-9].ext
  # valid for adsc images *.img and renamed MarCCD images *.tif
pattern1a = re.compile(r'\A(?P<fileroot>.*)_(?P<number>[0-9]{3,6})\.(?P<ext>.*)\Z')
pattern1b = re.compile(r'\A(?P<fileroot>.*)\.(?P<number>[0-9]{3,6})\.(?P<ext>.*)\Z')
pattern1c = re.compile(r'\A(?P<fileroot>.*)(?P<number>[0-9]{3,6})\.(?P<ext>.*)\Z')
  # Pattern2:  valid image file names conform to the regular expression
  # fileroot.[0-9][0-9][0-9][0-9]  (between 3 & 5 numerals in the extension)
  # valid for MarCCD images from Blum's ftp site
pattern2 = re.compile(r'\A(?P<fileroot>.*)\.(?P<number>[0-9]{3,5})\Z')
pattern_small2grid = re.compile(r'\A(?P<fileroot>.*)_(?P<number1>[0-9]{1,3})_(?P<number2>[0-9]{1,3})\.(?P<ext>.*)\Z')
pattern_general = re.compile(r'\A(?P<fileroot>.*)_(?P<otherstuff>.*)\.(?P<ext>.*)\Z') # no file number

class FileName:
  exts = ["img","tif","tiff","image","mccd",
          "mar1200","mar1800","mar1600","mar2400","mar2000","mar3000","mar2300","mar3450",
          "cbf","osc","ipf","sfrm","edf","pickle","pkl","h5"
         ] #Permissible filename extensions for pattern 1
  """attributes of this class are:
     base = the file name without directory path
     cwd = just the directory path
     fileroot = the dataset root, like lyso_1 in lyso_1_002.img
     number = the image number, like 2 in lyso_1_002.img
     ext = the image extension, like img in lyso_1_002.img
     template = the dataset naming pattern, like lyso_1_###.img in lyso_1_002.img
     pattern = 1: name has an alphabetic file extension.  2: the number is in the file extension
     full_url = URL, if input as such
  """
  def __init__(self,dirname,fn):
    self.base = fn
    self.cwd = dirname
  def fullpath(self):
    if "full_url" in self.__dict__:
      return self.full_url
    return os.path.join(os.path.abspath(self.cwd),self.base)
  def isImageFileName(self):
    match1a = pattern1a.match(self.base)
    match1b = pattern1b.match(self.base)
    match1c = pattern1c.match(self.base)
    match_small2grid = pattern_small2grid.match(self.base)
    match_general = pattern_general.match(self.base)
    match2 = pattern2.match(self.base)
    if match1a!=None:
      d = match1a.groupdict()
      self.fileroot = d['fileroot']
      self.number = int(d['number'])
      self.ext = d['ext']
      self.template = "%s_%s.%s"%(self.fileroot,'#'*len(d['number']),self.ext)
      self.pattern = 1
      if self.ext.lower() in FileName.exts: return 1
    elif match1b!=None:
      d = match1b.groupdict()
      self.fileroot = d['fileroot']
      self.number = int(d['number'])
      self.ext = d['ext']
      self.template = "%s.%s.%s"%(self.fileroot,'#'*len(d['number']),self.ext)
      self.pattern = 1
      if self.ext in FileName.exts: return 1
    elif match1c!=None:
      d = match1c.groupdict()
      self.fileroot = d['fileroot']
      self.number = int(d['number'])
      self.ext = d['ext']
      self.template = "%s%s.%s"%(self.fileroot,'#'*len(d['number']),self.ext)
      self.pattern = 1
      if self.ext in FileName.exts: return 1
    elif match_small2grid!=None:
      d = match_small2grid.groupdict()
      self.fileroot = d['fileroot']
      self.number = 1000*int(d['number1'])+int(d['number2'])
      self.ext = d['ext']
      self.template = "%s_%s_%s.%s"%(self.fileroot,'#'*len(d['number1']),'#'*len(d['number2']),self.ext)
      self.pattern = 1
      if self.ext.lower() in FileName.exts: return 1
    elif match_general!=None:
      d = match_general.groupdict()
      self.fileroot = d['fileroot']
      self.otherstuff = d['otherstuff']
      self.number = 3
      self.ext = d['ext']
      self.template = "%s_%s.%s"%(self.fileroot,self.otherstuff,self.ext)
      self.pattern = 0
      if self.ext.lower() in FileName.exts: print(self.template);return 1
    if match2!=None:
      d = match2.groupdict()
      self.fileroot = d['fileroot']
      self.number = int(d['number'])
      self.numberlength = len(d['number'])
      self.ext = None
      self.template = "%s."%self.fileroot + "#"*self.numberlength
      self.pattern = 2
      return 1
    return 0
  def __repr__(self):
    return "FileName object(%s)"%self.fullpath()

class file_names:
  #Note: the arg_module used to be simply "sys"; this use was Deprecated so
  #      that the indexing functionality would be identical when used from
  #      the api.
  def __init__(self,arg_module):
    self.arg_module = arg_module
    self.FN = []
    if arg_module==None: return #added for directory analysis
    #file names come from either command line or current directory
    if len(self.arg_module.argv)==1:
      # Interface 1. Current directory
      self.interface1_directory(os.getcwd())
    elif os.path.isdir(self.arg_module.argv[1]):
      if len(self.arg_module.argv)==2:
      # Interface 1. Look for all files in the given directory
        self.interface1_directory(self.arg_module.argv[1])
      else:
      # Interface 2. argv gives directory plus image numbers
        self.interface2_directory_and_frames()
    else:
     if '#' in self.arg_module.argv[1]:
       self.interface4_template()
     else:
      # Interface 3. File pathnames given on command line
      # if images are taken from command line, must recalculate
      #  DISTL_pickle because images might be different each time
      self.interface3_parse_command()

  def interface3_FN_factory(self,absfile,error_message):
    cwd = os.path.dirname(absfile)
    item = os.path.basename(absfile)
    VF = FileName(cwd,item)
    if VF.isImageFileName():
      self.FN.append(VF)
    else:
      raise Exception("Input error: "+error_message)
    return VF

  def interface3_parse_command(self):
    #The assumption is that there will be one or two regular files specified
    # on command line that are valid image file names
    # If there are two, root and ext must be the same in each case.
    # In Unix, wildcards are permitted because they are expanded by the shell.

    for file in self.arg_module.argv[1:]:
      expanded_path = os.path.expandvars(file)
      if os.path.isfile(expanded_path):
        self.interface3_FN_factory(os.path.abspath(expanded_path),error_message="File name not accepted")
      else:
        A = url_support.potential_url_request(expanded_path)
        if expanded_path=="data_in_object":
          VF = FileName("cxi_data","present_image_0000001")
          VF.number = 1
          VF.template = "present_image_#######"
          VF.fileroot = "present_image"
          self.FN.append(VF)
        elif A.is_url_request():
          VF = self.interface3_FN_factory(A.file,error_message="URL %s not accepted"%expanded_path)
          VF.full_url = A.text
        else:
          raise Exception("File not found: %s"%expanded_path)

  def __call__(self):
    return [item.fullpath() for item in self.FN]

  def frames(self):
    return [item.number for item in self.FN]

class image_files:
  def __init__(self,arg_module,verbose=True):
    self.verbose = verbose
    self.filenames = file_names(arg_module)
    self.images = []
    for indx,name in enumerate(self.filenames()):
        A = ImageFactory(name)
        self.images.append(A)

  def frames(self,wedgelimit=None): # gives the frame numbers
    if wedgelimit == None:return [item.number for item in self.filenames.FN]
    import inspect
    print("image_files.frames deprecated usage called by %s line %d; contact nksauter@lbl.gov"%(
      inspect.currentframe().f_back.f_code.co_name,
      inspect.currentframe().f_back.f_lineno))
    return [item.number for item in self.filenames.FN[0:wedgelimit]]

  def imageindex(self,indexnumber): # gives the actual image
    for s in range(len(self.filenames.frames())):
      if self.filenames.frames()[s]==indexnumber:
        return self.images[s]

  def imagepath(self,indexnumber): #convenience function for finding filename
    for s in range(len(self.filenames.frames())):
      if self.filenames.frames()[s]==indexnumber:
        return self.filenames()[s]

class H5_aware_image_files(image_files):
  def __init__(self,arg_module,phil_params,verbose=True):
    # support the many-image-in-one-H5-container paradigm
    if phil_params.distl.range is not None:  # range parameter only intended for H5 files
      assert len(self.filenames())==1 # can be only one H5 master file if there is a range of image indices
      if len(phil_params.distl.range)==1:  self.unrolled_range = phil_params.distl.range
      else:
        self.unrolled_range = range(phil_params.distl.range[0],phil_params.distl.range[1])
        self.filenames.FN = [self.filenames.FN[0]]*len(self.unrolled_range)
      self.frames = self.h5_frames
      self.imageindex = self.h5_imageindex
      self.imagepath = self.h5_imagepath
      import copy
      for indx,name in enumerate(self.filenames()):
        if indx==0:
          A = ImageFactory(name,optional_index=self.unrolled_range[indx])
          self.site_modifications(A,self.filenames.FN[indx])
          self.images.append(A)
        else:
          Acopy = copy.deepcopy(A)
          Acopy.img_number = self.unrolled_range[indx]
          self.images.append(Acopy)
    else:  # range is not present; normal behavior for non-H5 images
      for indx,name in enumerate(self.filenames()):
        A = ImageFactory(name)
        self.site_modifications(A,self.filenames.FN[indx])
        self.images.append(A)

  def h5_frames(self,wedgelimit=None): return list(self.unrolled_range)

  def h5_imageindex(self,indexnumber): # gives the actual image
    return self.images[self.unrolled_range.index(indexnumber)]

  def h5_imagepath(self,indexnumber): #convenience function for finding filename
    return self.filenames()[self.unrolled_range.index(indexnumber)]

class spotfinder_image_files(H5_aware_image_files):
  def __init__(self,arg_module,phil_params,verbose=True):
    self.verbose = verbose
    self.filenames = file_names(arg_module)
    self.phil_params = phil_params
    self.images = []
    H5_aware_image_files.__init__(self,arg_module,phil_params,verbose=True)
    self.acceptable_use_tests_basic()

  def acceptable_use_tests_basic(self):
    if 'TWOTHETA' in self.images[0].parameters:
      if abs(self.images[0].twotheta) < 0.02:  #round off to zero and
                                               #retain legacy behavior
        for ik in range(len(self.images)):
          self.images[ik].parameters['TWOTHETA']=0.0

  def site_modifications(self,imageobject,filenameobject):

    from iotbx.detectors.context.config_detector\
      import beam_center_convention_from_image_object

    beam_center_convention = beam_center_convention_from_image_object(imageobject,self.phil_params)

    #we may elect to override the beam position globally for LABELIT.
    #Case I.  The user has provided a tuple of floats, superceding all else
    if self.phil_params.autoindex_override_beam != None:
      imageobject.parameters['BEAM_CENTER_X'],\
      imageobject.parameters['BEAM_CENTER_Y']=\
      self.phil_params.autoindex_override_beam
      imageobject.beam_center_reference_frame = "imageblock"

    #Case II.  An XY convention has been defined.
    elif beam_center_convention != 0:
      convert_beam_instrument_to_imageblock(imageobject,beam_center_convention)

    if self.phil_params.autoindex_override_distance != None:
      imageobject.parameters['DISTANCE']=self.phil_params.autoindex_override_distance

    if self.phil_params.autoindex_override_wavelength != None:
      imageobject.parameters['WAVELENGTH']=self.phil_params.autoindex_override_wavelength

    if self.phil_params.autoindex_override_deltaphi != None:
        if self.verbose:
          print("Overriding deltaphi not fully supported: contact authors")
        print("Altering deltaphi",(filenameobject.number-1)*self.phil_params.autoindex_override_deltaphi)
        imageobject.parameters['OSC_RANGE']=self.phil_params.autoindex_override_deltaphi
        imageobject.parameters['OSC_START']=(filenameobject.number-1)*self.phil_params.autoindex_override_deltaphi

    # override twotheta angle
    if self.phil_params.autoindex_override_twotheta != None:
      imageobject.parameters['TWOTHETA']=\
        self.phil_params.autoindex_override_twotheta

    if self.phil_params.image_specific_osc_start != None:
        imageobject.parameters['OSC_START']= \
          eval("(%s)(%d)"%(
          self.phil_params.image_specific_osc_start,filenameobject.number))

    #take care of unbinned Quantum 315
    if (self.phil_params.distl_permit_binning and \
      imageobject.size1 > 4000 and imageobject.vendortype=="ADSC") or \
      self.phil_params.distl_force_binning:
      imageobject.setBin(2)
      self.phil_params.distl.minimum_spot_area = min(
        self.phil_params.distl.minimum_spot_area,
        self.phil_params.distl_binned_image_spot_size)

    if imageobject.vendortype=="MARCCD":
      #This section corrects for the fact that ESRF writes the mar ccd header
      #  with beam center in mm instead of pixels.
      detector_center_in_mm = 0.5*imageobject.size1*imageobject.pixel_size
      one_tenth_error = 0.1*detector_center_in_mm

      #offset between given beam and detector center
      import math
      def distance(a,b):
        return math.sqrt((a[0]-b[0])*(a[0]-b[0])+(a[1]-b[1])*(a[1]-b[1]))
      offset1=distance( (detector_center_in_mm,detector_center_in_mm),
                        (imageobject.beamx,imageobject.beamy) )
      if offset1>one_tenth_error:
        newx = imageobject.beamx/imageobject.pixel_size
        newy = imageobject.beamy/imageobject.pixel_size
        #offset between corrected beam and detector center
        offset2=distance( (detector_center_in_mm,detector_center_in_mm),
                        (newx,newy) )
        if offset2<one_tenth_error:
          imageobject.parameters['BEAM_CENTER_X'] = newx
          imageobject.parameters['BEAM_CENTER_Y'] = newy
          #Furthermore the x and y are transposed in the one example we've been given
          convert_beam_instrument_to_imageblock(imageobject,
            beam_center_convention,force=True)
          if self.verbose:
            print("Mar CCD image appears to have beam center %.2f %.2f in mm instead of pixels"%(
            imageobject.beamx,imageobject.beamy))

class Spotspickle_argument_module:  #almost verbatim copy from procedure.py
  def __init__(self,directory,framelist=[]):
    self.argv = ['SP_argument']
    self.argv.append(directory)
    for item in framelist:
      self.argv.append('%d'%item)

def quick_image(filepath):
  '''A convenience factory function to return a single image object
     given a single file path, with implicit execution of all the file
     checking machinery of the ImageFiles class.  As used here it is
     an almost-thin wrapper around iotbx ImageFactory.'''
  argument_module = Spotspickle_argument_module(filepath)
  frames = image_files(argument_module)
  return frames.images[0]


 *******************************************************************************


 *******************************************************************************
spotfinder/dxtbx_toolbox/__init__.py
from __future__ import absolute_import, division, print_function
from six.moves import range
import spotfinder.array_family.flex # implicit import

import boost_adaptbx.boost.python as bp
ext = bp.import_ext("spotfinder_dxtbx_ext")
from spotfinder_dxtbx_ext import *

from libtbx import adopt_init_args

class Distl:

  def __init__(self, params, detector, beam, data):
    adopt_init_args(self, locals())

    npanels = len(detector)
    self.finderlist = []
    for n in range(npanels):
      SF = w_Distl(optionstring="",report_overloads=False)

      panel = detector[n]

      saturation = panel.get_trusted_range()[1]

      SF.setspotimg(panel = panel, beam = beam,
                      rawdata = data,
                      peripheral_margin = params.distl.peripheral_margin,
                      saturation = saturation)

      special_vendortype = {
          (2463,2527):"Pilatus-6M",
          (1475,1679):"Pilatus-2M",
          (487,195):"Pilatus-300K",
        }.get(panel.get_image_size(),"")
      print(special_vendortype)
      SF.set_tiling(special_vendortype)

      if params.distl.minimum_spot_area != None:
        SF.set_minimum_spot_area(params.distl.minimum_spot_area)
      if params.distl.minimum_signal_height != None:
        SF.set_minimum_signal_height(params.distl.minimum_signal_height)
      if params.distl.minimum_spot_height != None:
        SF.set_minimum_spot_height(params.distl.minimum_spot_height)
      if params.distl.spot_area_maximum_factor != None:
        SF.set_spot_area_maximum_factor(params.distl.spot_area_maximum_factor)
      if params.distl.peak_intensity_maximum_factor != None:
        SF.set_peak_intensity_maximum_factor(params.distl.peak_intensity_maximum_factor)

      SF.set_scanbox_windows(params.distl.scanbox_windows)

      #SF.parameter_guarantees() # XXX return to this.  As implemented the guarantees ruin the results
      SF.get_underload()

      SF.pxlclassify()
# Functions having resolution and thus need overrides:
# r2_to_resol and resol_to_r2 (search_icerings)
# xy2resol (pixelclassify_scanbox, search_spots, pixelisonice) DONE
      #SF.search_icerings()
      SF.search_maximas()
      SF.search_spots()
      SF.search_overloadpatches()
      SF.finish_analysis()
      from matplotlib import pyplot as plt
      plt.plot( [f.ctr_mass_x() for f in SF.spots],
                [f.ctr_mass_y() for f in SF.spots],"b.")
      plt.show()

      self.finderlist.append(SF)


 *******************************************************************************


 *******************************************************************************
spotfinder/dxtbx_toolbox/practical_heuristics.py
from __future__ import absolute_import, division, print_function
from spotfinder.array_family import flex
from spotfinder.core_toolbox import Distl


class heuristics_base(object):

  def __init__(self,phil_params):
    self.phil_params = phil_params
    self.pd = dict(resolution_inspection='100.0')
    self.NspotMin = self.phil_params.distl_minimum_number_spots_for_indexing
    self.NspotMax = self.phil_params.distl_maximum_number_spots_for_indexing
    self.BinMin = 25
    self.errormessage = None
    self.images = {}
    self.reporters = {}
    self.protocol = 'tnear2'
    self.overlapping = False #flag indicates whether the special procedure was used
    self.force_detail = False #flag indicates whether percent_overlap > force_detail cutoff

  def register_frames(self):
    nimages = len(self.phil_params.distl.image)

    return self.oneImage(0)

  def oneImage(self,framenumber):
    self.reporters[framenumber] = []

    import dxtbx.format.Registry
    filename = self.phil_params.distl.image[framenumber]
    reader = dxtbx.format.Registry.get_format_class_for_file(filename)
    img = reader(filename)

    detector = img.get_detector()
    beam = img.get_beam()
    S0 = beam.get_s0()
    data = img.get_raw_data()
    scan = img.get_scan()
    print(scan)
    if scan is None:
      print("No scan")
      RR = (0,1)
    else:
      print(scan.get_oscillation())
      RR = scan.get_oscillation_range()

    from spotfinder.dxtbx_toolbox import Distl

    sfall = Distl(params = self.phil_params, detector = detector, beam = beam, data = data)

    resolutions = flex.double()
    spotlist = []
    from dials.model.data import ReflectionList,Reflection
    reflections = ReflectionList()


    for ip,panel in enumerate(detector):
      for spot in sfall.finderlist[ip].spots:
        resolutions.append( panel.get_resolution_at_pixel(S0, (spot.ctr_mass_x(), spot.ctr_mass_y())) )
        spotlist.append(spot)
        refl = Reflection()
        refl.panel_number = ip
        refl.centroid_position = (spot.ctr_mass_x(), spot.ctr_mass_y(),0.0)
        refl.centroid_variance = (0.5,0.5,0.0)
        reflections.append(refl)


    selection = (resolutions>0.0)
    if self.phil_params.distl.res.outer is not None:
      selection = (selection and (resolutions>self.phil_params.distl.res.outer))
    if self.phil_params.distl.res.inner is not None:
      selection = (selection and (resolutions<self.phil_params.distl.res.inner))

    reflections = reflections.select(selection)

    return dict(detector=detector, beam=beam, reflections=reflections, scan = scan,
                gonio = img.get_goniometer())


 *******************************************************************************


 *******************************************************************************
spotfinder/exception.py
from __future__ import absolute_import, division, print_function

class SpotfinderError(Exception):
  def __init__(self,message,processdict=None):
    Exception.__init__(self,message)
    self.classname="Spotfinder Problem"
    self.parameters = processdict


 *******************************************************************************


 *******************************************************************************
spotfinder/math_support/__init__.py
from __future__ import absolute_import, division, print_function
def pixels_to_mmPos(x,y,pixel_size):
  return [pixel_size*x,pixel_size*y]

def scitbx_stats(data):
  from scitbx.math import basic_statistics
  bs = basic_statistics(values = data)
  return bs.mean, bs.bias_corrected_standard_deviation

def stats_profile(data):
  from scitbx.array_family import flex
  fdata = flex.double()
  for item in data:
    fdata.append(item)
  perm = flex.sort_permutation(fdata)
  percentile05 = int(0.05*len(fdata))
  percentile95 = int(0.95*len(fdata))

  '''The return value is the ratio of the 95%ile value to the 5%ile value.
  This gives some measure of how braod the spread is between big and small
  spots.'''
  return fdata[perm[percentile95]]/fdata[perm[percentile05]]


 *******************************************************************************


 *******************************************************************************
spotfinder/math_support/sphere_formulae.py
from __future__ import absolute_import, division, print_function
from six.moves import range
import math

"""radius is taken to be d_star, or 1/resolution limit in units of distance"""

def sphere_volume(radius):
  return (4./3.)*math.pi*math.pow(radius,3)

def vol_of_Ewald_sphere_solid_of_revolution(wavelength):
  """Use Pappus's centroid theorem.  Direct quote from Wikipedia:  The volume of a solid
     of revolution generated by rotating a plane Figure F about an external axis is equal to
     the product of the area of F and the distance traveled by its geometric centroid.

     Thus for the Ewald sphere the Figure F has [area = pi * K^2], and the centroid travels
     [distance = 2 * pi * K] therefore [volume = 2 * pi^2 * K^3]"""
  return 2. * math.pi * math.pi / math.pow(wavelength,3)

def sphere_volume_minus_missing_cone(radius,wavelength):
  """Use Pappus's centroid theorem.  Approach 1 (not used here):  Use integral calculus
     to get analytical formula for the solid of revolution.  Approach 2 (used here).
     Use analytical approach to get the area of the plane Figure F followed by
     computational approach to get the centroid and thus the volume of the solid of
     revolution.

     Consider a plane Figure F in the yz plane.  +z is the beam direction.  Ewald sphere
     of radius K is centered at [z = -K].  Resolution sphere of radius R is centered at
     the origin.  The plane figure F is divided vertically into a left side circular
     segment S bounded by the Resolution sphere, and a right side circular segment D bounded
     by the Ewald sphere.

     The vertical dividing line is at Z-coordinate [z = -V], where V is given by a
     separate calculation.

  """
  K = 1./wavelength
  assert radius <= 2.*K # Can never observe diffraction at less than half-wavelength
  D = areaD(radius,K)
  S = areaS(radius,K)
  areaF = D + S
  V = v_coordinate(radius,K)
  """Now find the centroid by a simplex integration.  The centroid must be
     somewhere on the line segment y=0 between [z = -R] and z=0.
  """
  centroid = simplex_integration(D,S,radius,K,V).centroid
  return areaF * 2. * math.pi * centroid

class simplex_integration:
  """Determine the centroid by simplex integration.  It is integral(z dA)/ total area A,
     where the two-d integral is over all area elements dA.
     Integral(z dA) can be re-expressed as Integral(z h(z) dz) where h(z) is the
     vertical chord length through Figure F at position z."""
  def __init__(self,D,S,R,K,V):
    self.V = V; self.D = D; self.S = S; self.R = R; self.K = K
    total_areaF = D + S
    Nsteps = 100
    dz = R/Nsteps
    weighted_sum = 0.0
    for iz in range(Nsteps):
      z = (2*iz+1)*R/(2.*Nsteps)
      if z > V:  # area element is part of segment S
        chord_length = 2. * math.sqrt(R*R - z*z)
      else: # area element is part of segment D
        chord_length = 2. * math.sqrt(2.*K*z-z*z)
      weighted_sum += z * chord_length * dz
    self.centroid = weighted_sum / total_areaF

def areaD(R,K): # Area of D
  beta = math.asin(R/(2.*K)) # quarter angle
  theta = 4.* beta
  return 0.5 * K * K *(theta - math.sin(theta))

def areaS(R,K): # Area of S
  alpha = math.acos(R/(2.*K)) # half angle
  #print "S half angle",alpha*180./math.pi
  theta = 2.* alpha
  return 0.5 * R * R *(theta - math.sin(theta))

def v_coordinate(R,K):
  # By similar triangles:
  return R * R / (2.0 * K)

def print_table():
  wavelength = 1.0 # Angstrom
  K = 1./wavelength
  print("R     K      Vsph  Vewld     D      S      V    Xroid  Vobs   o/s    S/V  Xroid/R")
  for x in range(1,21):
    radius = 0.1 * x # inverse Angstroms
    Vsph = sphere_volume(radius) # reciprocal space volume out to inverse resolution == radius
    Vewld= vol_of_Ewald_sphere_solid_of_revolution(wavelength) # reciprocal space volume
           # impacted by a complete revolution of the Ewald sphere.
    D = areaD(radius,K)
    S = areaS(radius,K)
    V = v_coordinate(radius,K)
    centroid = simplex_integration(D,S,radius,K,V).centroid
    Vobs2 = sphere_volume_minus_missing_cone(radius,wavelength)# actual reciprocal space volume
           # observed (inside Ewald sphere torus of rotation & inside resolution-limit)
    print("%5.3f %5.3f %6.3f %6.3f %6.3f %6.3f %6.3f %6.3f %6.3f %6.3f %6.3f %6.3f"%(
      radius,1./wavelength,Vsph,Vewld,D,S,V,centroid,Vobs2,Vobs2/Vsph,S/V,centroid/radius))
  print("At the R=2K limit, expected Vewld/Vsph ratio is [3*pi/16]=%6.3f, found %6.3f"%(
    (3.*math.pi/16.),Vewld/Vsph))
  print("At the R=2K limit, expected area D is [pi*K^2]=%6.3f, found %6.3f"%(
    (K*K*math.pi),D))
  print("At the R=0 limit, expected S/V==pi and centroid/R = 4/(3*pi) = 0.4244 [from mathworld.wolfram.com]")

def test_formulae():
  import sys
  from six.moves import cStringIO as StringIO
  F = StringIO()
  sys.stdout = F
  print_table()
  result = F.getvalue()
  sys.stdout = sys.__stdout__
  #print result
  assert result == \
"""R     K      Vsph  Vewld     D      S      V    Xroid  Vobs   o/s    S/V  Xroid/R
0.100 1.000  0.004 19.739  0.001  0.015  0.005  0.043  0.004  1.000  2.942  0.433
0.200 1.000  0.034 19.739  0.005  0.055  0.020  0.088  0.033  0.997  2.742  0.442
0.300 1.000  0.113 19.739  0.018  0.114  0.045  0.135  0.112  0.993  2.544  0.450
0.400 1.000  0.268 19.739  0.042  0.188  0.080  0.183  0.265  0.988  2.347  0.458
0.500 1.000  0.524 19.739  0.082  0.269  0.125  0.233  0.514  0.981  2.152  0.466
0.600 1.000  0.905 19.739  0.140  0.353  0.180  0.284  0.880  0.973  1.960  0.474
0.700 1.000  1.437 19.739  0.220  0.434  0.245  0.337  1.383  0.963  1.771  0.481
0.800 1.000  2.145 19.739  0.324  0.507  0.320  0.390  2.039  0.951  1.585  0.488
0.900 1.000  3.054 19.739  0.455  0.569  0.405  0.445  2.862  0.937  1.404  0.494
1.000 1.000  4.189 19.739  0.614  0.614  0.500  0.500  3.860  0.922  1.228  0.500
1.100 1.000  5.575 19.739  0.802  0.640  0.605  0.556  5.040  0.904  1.058  0.506
1.200 1.000  7.238 19.739  1.018  0.644  0.720  0.613  6.399  0.884  0.895  0.511
1.300 1.000  9.203 19.739  1.262  0.624  0.845  0.669  7.932  0.862  0.739  0.515
1.400 1.000 11.494 19.739  1.531  0.579  0.980  0.726  9.621  0.837  0.591  0.518
1.500 1.000 14.137 19.739  1.820  0.510  1.125  0.781 11.440  0.809  0.453  0.521
1.600 1.000 17.157 19.739  2.123  0.419  1.280  0.836 13.346  0.778  0.327  0.522
1.700 1.000 20.580 19.739  2.430  0.309  1.445  0.887 15.276  0.742  0.214  0.522
1.800 1.000 24.429 19.739  2.726  0.190  1.620  0.935 17.134  0.701  0.117  0.519
1.900 1.000 28.731 19.739  2.984  0.076  1.805  0.976 18.756  0.653  0.042  0.514
2.000 1.000 33.510 19.739  3.142  0.000  2.000  1.000 19.745  0.589  0.000  0.500
At the R=2K limit, expected Vewld/Vsph ratio is [3*pi/16]= 0.589, found  0.589
At the R=2K limit, expected area D is [pi*K^2]= 3.142, found  3.142
At the R=0 limit, expected S/V==pi and centroid/R = 4/(3*pi) = 0.4244 [from mathworld.wolfram.com]
"""

if __name__=="__main__":
  test_formulae()
  print("OK")


 *******************************************************************************


 *******************************************************************************
spotfinder/run_tests.py
from __future__ import absolute_import, division, print_function
from libtbx import test_utils
import libtbx.load_env

tst_list = (
  "$D/core_toolbox/boost_python/tst_small_image.py",
  "$D/diffraction/geometry.py",
  "$D/math_support/sphere_formulae.py"
  )

def run_standalones():
  build_dir = libtbx.env.under_build("spotfinder")
  dist_dir = libtbx.env.dist_path("spotfinder")

  test_utils.run_tests(build_dir, dist_dir, tst_list)

if (__name__ == "__main__"):
  run_standalones()


 *******************************************************************************


 *******************************************************************************
spotfinder/servers/__init__.py
from __future__ import absolute_import, division, print_function
from six.moves import cStringIO as StringIO
import sys

class LoggingFramework:
  def __init__(self):
    self.k = StringIO()
    self.current_out = sys.stdout
    self.current_err = sys.stderr
    sys.stdout = self.k
    sys.stderr = self.k

  def __del__(self):
    sys.stdout = self.current_out
    sys.stderr = self.current_err
    self.k.flush()
    self.k.close()

  def getvalue(self): return self.k.getvalue()



 *******************************************************************************


 *******************************************************************************
spotfinder/servers/adsc_client.py
from __future__ import absolute_import, division, print_function
from six.moves import range
import os
from spotfinder.diffraction.imagefiles import quick_image
from spotfinder.servers.multipart_encoder import post_multipart

def get_spotfinder_url(file_object,host,port):
  testurl = "%s:%d"%(host,port)
  selector = "/spotfinder"
  start_index=0
  stop_index = file_object.linearintdata.size()
  raw_string=file_object.linearintdata.slice_to_byte_str(start_index,stop_index)
  query_object = [
    ("moduleindex",file_object.__dict__.get("moduleindex",-1)),
    ("filename",file_object.filename),
    ("bin",1),
    ("vendortype",file_object.vendortype),
    ("beam_center_reference_frame",file_object.beam_center_reference_frame),
    ("beam_center_convention",file_object.beam_center_convention),
    ("header",file_object.header),
    ("headerlines",""),
  ]
  for item in ['DISTANCE', 'PHI', 'WAVELENGTH',
    'TWOTHETA', 'OSC_RANGE',
    'CCD_IMAGE_SATURATION', 'OSC_START', 'DETECTOR_SN', 'PIXEL_SIZE',
    'SIZE1','SIZE2','BEAM_CENTER_X','BEAM_CENTER_Y'
    ]:
    if type(file_object.parameters[item])==type(1.0):
      query_object.append((item,"%.6f"%file_object.parameters[item]))
    else:
      query_object.append((item,file_object.parameters[item]))

  files = [
    ("adsc_data",file_object.filename,raw_string)
  ]

  print("length of data in ints",stop_index)
  print("length of data in bytes",len(raw_string))
  assert len(raw_string)/4==stop_index

  Response = post_multipart(host=testurl, selector=selector,
    fields = query_object, files = files)

  print(Response.getresponse().read())

def get_labelit_image_object(file,convention):
  Q = quick_image(file)
  Q.set_beam_center_convention(convention)
  Q.read()

  return Q

def do_main(filepath, force_binning, convention, host, port):
  absfile = os.path.abspath(filepath)
  Q = get_labelit_image_object(absfile, convention)
  if force_binning:
    Q.setBin(2)
    Q.show_header()
  get_spotfinder_url(Q,host,port)

  from iotbx.detectors import image_divider
  number_of_modules = image_divider(
                        Q.linearintdata,
                        Q.vendor_specific_null_value
                      ).module_count()

  for x in range(number_of_modules):
    file = "file://%s?slice=%d"%(absfile,x)
    Q = get_labelit_image_object(file, convention)
    if force_binning:
      Q.setBin(2)
      Q.show_header()
    get_spotfinder_url(Q,host,port)

if __name__=="__main__":
  import sys
  try:
    filepath, force_binning, convention, host, port = sys.argv[1:6]
    force_binning = bool(force_binning)
    port = int(port)
    convention = int(convention)
  except Exception:
    print("""
Usage:
libtbx.python adsc_client.py <filepath> <force_binning> <convention> <host> <port>
Four mandatory arguments:
  filepath: absolute or relative path name of the ADSC test image to be analyzed
  force_binning: True (client-side 2x2-pixel software binning; sometimes the best
                       choice if raw data is not hardware-binned) or False
  convention: beam_center_convention as defined on the spotfinder servers wiki
  host: usually "localhost"; in any case, must be machine with same endianness
  port: port number of image analyzer http service
""")
  do_main(filepath, force_binning, convention, host, port)


 *******************************************************************************


 *******************************************************************************
spotfinder/servers/apache.py
from __future__ import absolute_import, division, print_function
from mod_python import apache
from six.moves import StringIO

def handler(req):
  req.content_type = "text/plain"
  from mod_python.util import FieldStorage
  FS = FieldStorage(req)
  logfile = StringIO()

  if req.filename.find("distl.signal_strength_bcsb")>=0:
    from spotfinder.servers.apache_bcsb import run as run_command
  elif req.filename.find("distl.signal_strength")>0:
    run_command = run
  elif req.filename.find("dials.find_spots")>0:
    from spotfinder.servers.apache_dials import run as run_command

  logfile.write(run_command(args=FS))
  log = logfile.getvalue()
  req.set_content_length(len(log))
  req.write(log)
  return apache.OK

def run(args, verbose=False):
  from libtbx.utils import Sorry
  import os
  from spotfinder.command_line.signal_strength import master_params
  from spotfinder.servers import LoggingFramework

  #For the Apache server version, do not allow site, user, or dataset preferences
  #all parameters are to be passed in through the http: query line

  logfile = LoggingFramework()

  phil_objects = []
  argument_interpreter = master_params.command_line_argument_interpreter(
    home_scope="distl")

  for key in args.keys():
      arg = "%s=%s"%(key,args.get(key,""))
      try: command_line_params = argument_interpreter.process(arg=arg)
      except Exception: return str(Sorry("Unknown file or keyword: %s" % arg))
      else: phil_objects.append(command_line_params)

  working_params = master_params.fetch(sources=phil_objects)
  params = working_params.extract()
  #working_params.show()

  if not os.path.isfile(params.distl.image):
    return str(Sorry("%s is not a readable file" % params.distl.image))

  print("Image: %s"%params.distl.image)

  from spotfinder.applications import signal_strength
  try:
    signal_strength.run_signal_strength(params)
  except Exception:
    import traceback
    logger = StringIO()
    logger.write(
    "Sorry, can't process %s.  Please contact authors.\n"% params.distl.image)
    traceback.print_exc(file=logger)
    return str(Sorry( logger.getvalue() ))

  return logfile.getvalue()


 *******************************************************************************


 *******************************************************************************
spotfinder/servers/apache_bcsb.py
from __future__ import absolute_import, division, print_function
from six.moves import range
from six.moves import StringIO

def run(args, verbose=False):
  from libtbx.utils import Sorry
  import os
  from spotfinder.command_line.signal_strength import master_params

  #For the Apache server version, do not allow site, user, or dataset preferences
  #all parameters are to be passed in through the http: query line

  phil_objects = []
  argument_interpreter = master_params.command_line_argument_interpreter(
    home_scope="distl")

  from spotfinder.servers.apache_utils import LongLineSimpleNode as SimpleNode
  from spotfinder.applications import signal_strength

  logger = StringIO()
  top = SimpleNode("spotfinder")

  try:
    for key in args.keys():
        arg = "%s=%s"%(key,args.get(key,""))
        command_line_params = argument_interpreter.process(arg=arg)
        phil_objects.append(command_line_params)

    working_params = master_params.fetch(sources=phil_objects)
    params = working_params.extract()

    top.child(SimpleNode(tag="file_name",contents=params.distl.image))

    if not os.path.isfile(params.distl.image):
      raise Sorry("%s not a readable file"%params.distl.image)

    Org = signal_strength.run_signal_strength(params)
    assert len(list(Org.S.images.keys()))==1 # there is only one image
    key = list(Org.S.images.keys())[0]

    # List of spots between specified high- and low-resolution limits
    if Org.S.images[key].has_extended_key('lo_pass_resolution_spots'):
      spots = Org.S.images[key]['lo_pass_resolution_spots']
    elif Org.S.images[key].has_extended_key('inlier_spots'):
      spots = Org.S.images[key]['inlier_spots']
    else:
      spots = []

    if Org.S.images[key].has_extended_key('N_spots_total'):
      total = "%d"%Org.S.images[key]["N_spots_total"]
    else:
      total = "0"

    if Org.S.images[key].has_extended_key('resolution'):
      resolution = Org.S.images[key]['resolution']
    elif Org.S.images[key].has_extended_key('distl_resolution'):
      resolution = Org.S.images[key]['distl_resolution']
    else:
      resolution = 0.0

    top.child(SimpleNode(tag="total_spots",contents=total))
    top.child(SimpleNode(tag="good_spots",contents="%d"%len(spots)))
    top.child(SimpleNode(tag="resolution",contents="%.3f"%resolution))

    if len(Org.S.reporters[key])==0:
      top.child(SimpleNode(tag="total_integrated",contents="0"))
      top.child(SimpleNode(tag="mean_isigi",contents="0"))
    else:
      reporter = Org.S.reporters[key][-1]
      normalizer = reporter.weights.sum()
      summation = 0;
      for x in range(reporter.S_table_rows):
        summation += reporter.weights[x] * reporter.MeanIsigI[x]
      top.child(SimpleNode(tag="mean_isigi",contents="%.3f"%(summation/normalizer)))
      integrated = reporter.Integrated.sum()
      top.child(SimpleNode(tag="integrated",contents="%.3f"%integrated))

  except Exception as e:
    top.child(SimpleNode(tag="status",contents=repr(e)))
    top.emit(logger)
    return logger.getvalue()

  top.child(SimpleNode(tag="status",contents="OK"))
  top.emit(logger)

  return logger.getvalue()


 *******************************************************************************


 *******************************************************************************
spotfinder/servers/apache_dials.py
from __future__ import absolute_import, division, print_function
from six.moves import StringIO

def run(args, verbose=False):
  from libtbx.utils import Sorry
  try:
    from dials.array_family import flex
  except ImportError:
    return str(Sorry("DIALS is not configured"))

  from iotbx.phil import parse
  import os
  from spotfinder.servers import LoggingFramework
  from dials.array_family import flex
  from dxtbx.model.experiment_list import ExperimentListFactory
  phil_scope = parse("""
  file_name = None
    .type = str
  frame_number = None
    .type = int
  stats = True
    .type = bool
  include scope dials.algorithms.spot_finding.factory.phil_scope
  """, process_includes=True)

  #For the Apache server version, do not allow site, user, or dataset preferences
  #all parameters are to be passed in through the http: query line

  logfile = LoggingFramework()

  phil_objects = []

  for key in args.keys():
    arg = "%s=%s"%(key,args.get(key,""))
    try: phil_objects.append(parse(arg))
    except Exception: return str(Sorry("Unknown file or keyword: %s" % arg))

  working_params = phil_scope.fetch(sources=phil_objects)
  params = working_params.extract()
  #working_params.show()

  if not os.path.isfile(params.file_name):
    return str(Sorry("%s is not a readable file" % params.file_name))

  print("Image: %s\n"%params.file_name)

  try:
    experiments = ExperimentListFactory.from_filenames([params.file_name])
    assert len(experiments) == 1
    if len(experiments[0].imageset) > 0 and params.frame_number is not None:
      print("Frame number", params.frame_number)
      experiments[0].imageset = experiments[0].imageset[params.frame_number:params.frame_number+1]
      experiments[0].scan = experiments[0].imageset.get_scan()
    reflections = flex.reflection_table.from_observations(experiments, params)

    if params.stats:
      from dials.algorithms.spot_finding.per_image_analysis import  stats_single_image
      print(stats_single_image(experiments[0].imageset, reflections, i=None, resolution_analysis=True, plot=False))

  except Exception:
    import traceback
    logger = StringIO()
    logger.write(
    "Sorry, can't process %s.  Please contact authors.\n"% params.file_name)
    traceback.print_exc(file=logger)
    return str(Sorry( logger.getvalue() )) + logfile.getvalue()

  print("Found %d strong reflections"%len(reflections))

  return logfile.getvalue()


 *******************************************************************************


 *******************************************************************************
spotfinder/servers/apache_utils.py
from __future__ import absolute_import, division, print_function
from libtbx.simplexml import SimpleNode

class LongLineSimpleNode(SimpleNode):

  def __init__(self,*args,**kwargs):
    SimpleNode.__init__(self,*args,**kwargs)

  def emit(self,channel,indent=0):
    if self.indent_f==False: indent=0
    attrs = [' %s="%s"'%(item[0],item[1]) for item in self.m_attributes]
    all_attrs = "".join(attrs)

    if self.content!='':
      print("%s<%s%s>%s</%s>"%(' '*indent,self.tag,all_attrs,self.content,self.tag), file=channel)
      return
    print("%s<%s%s>"%(' '*indent,self.tag,all_attrs), end=' ', file=channel)
    print(file=channel)
    for item in self.children:
      item.emit(channel,indent=indent+2)
    if len(self.children)>0:
      print("%s</%s>"%(' '*indent,self.tag), file=channel)
    else:
      channel.seek(channel.tell()-2)
      print("/>", file=channel)


 *******************************************************************************


 *******************************************************************************
spotfinder/servers/bcsb_client_example.py
from __future__ import absolute_import, division, print_function
from six.moves import range
import os,time
import threading
output_lock = threading.RLock()

def do_main_apache(filepath, host, port):
  absfile = os.path.abspath(filepath)
  base_url = "http://%s:%d/spotfinder/distl.signal_strength_bcsb?distl.image=%s"%(host,port,absfile)
  if len(DISTL_OPTIONS) > 0:
    base_url = base_url + "&" + "&".join(DISTL_OPTIONS)
  from six.moves import urllib
  try:
    Response = urllib.request.urlopen(base_url)
    log = Response.read()
    Response.close()
    return log
  except Exception as e:
    return str(e)

def single_thread(idx):
  for x in range(1):
    filepath, host, port = [ABS_DATA_TEMPLATE%idx,HOST,PORT]
    port = int(port)
    if OUTPUT_FILE is not None:
      output_lock.acquire(blocking=True)
      outfile = open(OUTPUT_FILE,"ab")
      print(do_main_apache(filepath, host, port), file=outfile)
      outfile.close()
      output_lock.release()
    else:
      print(do_main_apache(filepath, host, port))

def multi_thread():
  from multiprocessing import Pool
  pool = Pool(processes=N_CLIENT_THREADS)
  results = []
  for x in IMAGE_RANGE:
    if SERVER_TYPE=="Python": time.sleep(TIME_DELAY)
    result = pool.apply_async(single_thread, [x,])
    results.append(result)
  for j,item in enumerate(results):
    item.wait()

if __name__=="__main__":
  ABS_DATA_TEMPLATE = "/net/cci/dials/from_sunbird/sauter/rawdata/pilatus/ssrl_P6/all/I3_1_%04d.cbf"
  HOST = "viper"
  PORT = "8125"
  N_CLIENT_THREADS = 48
  IMAGE_RANGE = range(1,721)
  DISTL_OPTIONS = ["distl.res.outer=3.3","distl.bins.verbose=True"]
  SERVER_TYPE = ["Python","Apache"][1] # choose 0=Python, 1=Apache mod-python
  TIME_DELAY = 0.10 # seconds per-image throughput, depends on server
  OUTPUT_FILE = "/net/viper/raid1/sauter/apache/bcsb_results.txt"
  multi_thread()


 *******************************************************************************


 *******************************************************************************
spotfinder/servers/general_client_example.py
from __future__ import absolute_import, division, print_function
from six.moves import range
import os,time

def do_main_apache(filepath, host, port):
  absfile = os.path.abspath(filepath)
  base_url = "http://%s:%d/spotfinder/distl.signal_strength?distl.image=%s"%(host,port,absfile)
  if len(DISTL_OPTIONS) > 0:
    base_url = base_url + "&" + "&".join(DISTL_OPTIONS)
  from six.moves import urllib
  try:
    Response = urllib.request.urlopen(base_url)
    log = Response.read()
    Response.close()
    return log
  except Exception as e:
    return str(e)

def single_thread(idx):
  for x in range(1):
    filepath, host, port = [ABS_DATA_TEMPLATE%idx,HOST,PORT]
    port = int(port)
    print(do_main_apache(filepath, host, port))

def multi_thread():
  from multiprocessing import Pool
  pool = Pool(processes=N_CLIENT_THREADS)
  results = []
  for x in IMAGE_RANGE:
    if SERVER_TYPE=="Python": time.sleep(TIME_DELAY)
    result = pool.apply_async(single_thread, [x,])
    results.append(result)
  for j,item in enumerate(results):
    item.wait()

if __name__=="__main__":
  ABS_DATA_TEMPLATE = "/net/cci/dials/from_sunbird/sauter/rawdata/pilatus/ssrl_P6/all/I3_1_%04d.cbf"
  HOST = "viper"
  PORT = "8125"
  N_CLIENT_THREADS = 48
  IMAGE_RANGE = range(1,721)
  DISTL_OPTIONS = ["distl.res.outer=3.3","distl.bins.verbose=True"]
  SERVER_TYPE = ["Python","Apache"][0] # choose 0=Python, 1=Apache mod-python
  TIME_DELAY = 0.10 # seconds per-image throughput, depends on server
  multi_thread()


 *******************************************************************************


 *******************************************************************************
spotfinder/servers/mp_spotfinder_server_is_alive.py
from __future__ import absolute_import, division, print_function
import httplib

def get_spotfinder_url(host,port):
  testurl = "%s:%d"%(host,port)
  Connection = httplib.HTTPConnection(testurl,strict=True)
  Connection.putrequest('POST',"/spotfinder")
  Connection.putheader('Expect',"200")
  Connection.endheaders()
  Connection.send("")
  Response = Connection.getresponse()
  print(Response.status,Response.reason)
  Connection.close()

get_spotfinder_url("localhost",8125)


 *******************************************************************************


 *******************************************************************************
spotfinder/servers/mp_spotfinder_server_read_file.py
from __future__ import absolute_import, division, print_function
from BaseHTTPServer import HTTPServer
import cgi, sys
from multiprocessing import Process, current_process

from urlparse import urlparse
from six.moves import range
#backward compatibility with Python 2.5
try: from urlparse import parse_qs
except Exception: from cgi import parse_qs

def note(format, *args):
    sys.stderr.write('[%s]\t%s\n' % (current_process().name, format%args))

from spotfinder.servers.spotfinder_server_read_file import image_request_handler as irhbase
from spotfinder.servers.spotfinder_server_read_file import generate_common_parameters # import dependency

class image_request_handler(irhbase):

  def log_message(self, format, *args):
    note(format, *args)

def serve_forever(server):
    note('starting server')
    try:
        server.serve_forever()
    except KeyboardInterrupt:
        pass

def runpool(address, number_of_processes,handler):
    # create a single server object -- children will each inherit a copy
    server = HTTPServer(address, handler)

    # create child processes to act as workers
    for i in range(number_of_processes-1):
        Process(target=serve_forever, args=(server,)).start()

    # main process also acts as a worker
    serve_forever(server)


 *******************************************************************************


 *******************************************************************************
spotfinder/servers/multipart_encoder.py
# Code is derived from ActiveState Code Recipe 146306
# (http://code.activestate.com/recipes/146306/)
# This material is available under the MIT License, appended here:
"""
The MIT License

Copyright (c) 2002 Wade Leftwich

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
"""
from __future__ import absolute_import, division, print_function

import httplib, mimetypes

def post_multipart(host, selector, fields, files):
    """
    Post fields and files to an http host as multipart/form-data.
    fields is a sequence of (name, value) elements for regular form fields.
    files is a sequence of (name, filename, value) elements for data to be uploaded as files
    Return the server's response page.
    """
    content_type, body = encode_multipart_formdata(fields, files)
    h = httplib.HTTPConnection(host)
    h.putrequest('POST', selector)
    h.putheader('content-type', content_type)
    h.putheader('content-length', str(len(body)))
    h.endheaders()
    h.send(body)
    return h
    # it is the responsibility of the caller to call
    # h.getresponse()
    # h.close()

def encode_multipart_formdata(fields, files):
    """
    fields is a sequence of (name, value) elements for regular form fields.
    files is a sequence of (name, filename, value) elements for data to be uploaded as files
    Return (content_type, body) ready for httplib.HTTP instance
    """
    BOUNDARY = '----------ThIs_Is_tHe_bouNdaRY_$'
    CRLF = '\r\n'
    L = []
    for (key, value) in fields:
        L.append('--' + BOUNDARY)
        L.append('Content-Disposition: form-data; name="%s"' % key)
        L.append('')
        L.append(str(value))
    for (key, filename, value) in files:
        L.append('--' + BOUNDARY)
        L.append('Content-Disposition: form-data; name="%s"; filename="%s"' % (key, filename))
        L.append('Content-Type: %s' % get_content_type(filename))
        L.append('')
        L.append(value)
    L.append('--' + BOUNDARY + '--')
    L.append('')
    body = CRLF.join(L)
    content_type = 'multipart/form-data; boundary=%s' % BOUNDARY
    return content_type, body

def get_content_type(filename):
    return mimetypes.guess_type(filename)[0] or 'application/octet-stream'


 *******************************************************************************


 *******************************************************************************
spotfinder/servers/pilatus_client.py
from __future__ import absolute_import, division, print_function
from six.moves import range
import os
from spotfinder.diffraction.imagefiles import quick_image
from spotfinder.servers.multipart_encoder import post_multipart
from libtbx.development.timers import Timer

def get_spotfinder_url(file_object,host,port):
  testurl = "%s:%d"%(host,port)
  selector = "/spotfinder"
  start_index=0
  stop_index = file_object.linearintdata.size()
  raw_string=file_object.linearintdata.slice_to_byte_str(start_index,stop_index)
  query_object = [
    ("moduleindex",file_object.__dict__.get("sliceindex",-1)),
    ("filename",file_object.filename),
    ("bin",1),
    ("vendortype",file_object.vendortype),
    ("beam_center_reference_frame",file_object.beam_center_reference_frame),
    ("beam_center_convention",file_object.beam_center_convention),
    ("header",file_object.header),
    ("headerlines",""),
  ]
  for item in ['DISTANCE', 'PHI', 'WAVELENGTH',
    'TWOTHETA', 'OSC_RANGE',
    'CCD_IMAGE_SATURATION', 'OSC_START', 'DETECTOR_SN', 'PIXEL_SIZE',
    'SIZE1','SIZE2','BEAM_CENTER_X','BEAM_CENTER_Y'
    ]:
    query_object.append((item,file_object.parameters[item]))

  files = [
    ("adsc_data",file_object.filename,raw_string)
  ]

  print("length of data in ints",stop_index)
  print("length of data in bytes",len(raw_string))
  assert len(raw_string)/4==stop_index

  T = Timer("do_POST")
  Response = post_multipart(host=testurl, selector=selector,
    fields = query_object, files = files)
  del T

  print(Response.getresponse().read())

def get_labelit_image_object(file,convention):
  Q = quick_image(file)
  Q.set_beam_center_convention(convention)
  Q.read()

  return Q

def do_main(filepath, force_binning, convention, host, port):
  absfile = os.path.abspath(filepath)
  Q = get_labelit_image_object(absfile, convention)
  if force_binning:
    Q.setBin(2)
    Q.show_header()
  get_spotfinder_url(Q,host,port)

  for x in range(12):
    file = "file://%s?slice=%d"%(absfile,x)
    Q = get_labelit_image_object(file, convention)
    if force_binning:
      Q.setBin(2)
      Q.show_header()
    get_spotfinder_url(Q,host,port)

if __name__=="__main__":
  import sys
  try:
    filepath, force_binning, convention, host, port = sys.argv[1:6]
    force_binning = bool(force_binning)
    port = int(port)
    convention = int(convention)
  except Exception:
    print("""
Usage:
libtbx.python pilatus_client.py <filepath> <force_binning> <convention> <host> <port>
Four mandatory arguments:
  filepath: absolute or relative path name of the Pilatus test image to be analyzed
  force_binning: True (client-side 2x2-pixel software binning; normally
                        not a good choice for Pilatus) or False
  convention: beam_center_convention as defined on the spotfinder servers wiki ==0
  host: usually "localhost"; in any case, must be machine with same endianness
  port: port number of image analyzer http service
""")
  do_main(filepath, force_binning, convention, host, port)


 *******************************************************************************


 *******************************************************************************
spotfinder/servers/specific_client_example.py
from __future__ import absolute_import, division, print_function
from six.moves import range
import os,time
import threading
output_lock = threading.RLock()

def do_main_apache(filepath, host, port):
  absfile = os.path.abspath(filepath)
  base_url = "http://%s:%d/spotfinder/distl.signal_strength?distl.image=%s"%(host,port,absfile)
  if len(DISTL_OPTIONS) > 0:
    base_url = base_url + "&" + "&".join(DISTL_OPTIONS)
  from six.moves import urllib
  try:
    Response = urllib.request.urlopen(base_url)
    log = Response.read()
    Response.close()
    return log
  except Exception as e:
    return str(e)

def single_thread(idx):
  for x in range(1):
    filepath, host, port = [ABS_DATA_TEMPLATE%idx,HOST,PORT]
    port = int(port)
    if OUTPUT_FILE is not None:
      output_lock.acquire(blocking=True)
      outfile = open(OUTPUT_FILE,"ab")
      print(do_main_apache(filepath, host, port), file=outfile)
      outfile.close()
      output_lock.release()
    else:
      print(do_main_apache(filepath, host, port))

def multi_thread():
  from multiprocessing import Pool
  pool = Pool(processes=N_CLIENT_THREADS)
  results = []
  for x in IMAGE_RANGE:
    if SERVER_TYPE=="Python": time.sleep(TIME_DELAY)
    result = pool.apply_async(single_thread, [x,])
    results.append(result)
  for j,item in enumerate(results):
    item.wait()

if __name__=="__main__":
  ABS_DATA_TEMPLATE = "/net/cci/dials/from_sunbird/sauter/rawdata/pilatus/ssrl_P6/all/I3_1_%04d.cbf"
  HOST = "viper"
  PORT = "8125"
  N_CLIENT_THREADS = 48
  IMAGE_RANGE = range(1,721)
  DISTL_OPTIONS = ["distl.res.outer=3.3","distl.bins.verbose=True"]
  SERVER_TYPE = ["Python","Apache"][1] # choose 0=Python, 1=Apache mod-python
  TIME_DELAY = 0.10 # seconds per-image throughput, depends on server
  OUTPUT_FILE = "/net/viper/raid1/sauter/apache/spotfinder_results.txt"
  multi_thread()


 *******************************************************************************


 *******************************************************************************
spotfinder/servers/spotfinder_server_client_push.py
from __future__ import absolute_import, division, print_function
from BaseHTTPServer import BaseHTTPRequestHandler,HTTPServer
from scitbx.array_family import flex
from libtbx.development.timers import Timer
import cgi, sys
from six.moves import StringIO
from spotfinder.applications.stats_distl import optionally_add_saturation_webice,key_adaptor

from urlparse import urlparse
#backward compatibility with Python 2.5
try: from urlparse import parse_qs
except Exception: from cgi import parse_qs

def module_safe_items(image):
  return [
      ("%7d","Good Bragg Candidates",key_adaptor(image,'N_spots_inlier')),
      ("%7.0f","Total integrated signal, pixel-ADC units above local background",
                 key_adaptor(image,'ad_hoc_signal1')),
      ("%7d","Ice Rings",key_adaptor(image,'ice-ring_impact')),
      ("%7.1f","Resolution estimate",key_adaptor(image,'resolution')),
      ("%7.1f","Maximum unit cell",key_adaptor(image,'maxcel')),
  ]

def module_image_stats(S,key):
    # List of spots between specified high- and low-resolution limits
    image = S.images[key]
    spots = image.__getitem__('spots_inlier')

    integrated = 0.0

    for i,spot in enumerate(spots):
     integrated += flex.sum(spot.wts)
    image["ad_hoc_signal1"]=integrated

    canonical_info = []
    canonical_info.extend(module_safe_items(image))
    optionally_add_saturation_webice(canonical_info,image)

    for item in canonical_info:
      if item[2]==None:
        print("%63s : None"%item[1])
      else:
        print("%63s : %s"%(item[1],item[0]%item[2]))

class image_request_handler(BaseHTTPRequestHandler):

  def do_POST(self):
    T = Timer("do_POST")
    parsed = urlparse(self.path)
    qs = parse_qs(parsed.query)

    expect = self.headers.getheaders("Expect")
    if len(expect)>=1:
      if True in [item.find("100")>=0 for item in expect]:
        self.send_response(100) # untested; has no apparent affect on libcurl

    # Get arguments by reading body of request.
    # We read this in chunks to avoid straining
    # socket.read(); around the 10 or 15Mb mark, some platforms
    # begin to have problems (bug #792570).
    max_chunk_size = 10*1024*1024
    size_remaining = int(self.headers["content-length"])
    L = []
    while size_remaining:
        chunk_size = min(size_remaining, max_chunk_size)
        L.append(self.rfile.read(chunk_size))
        size_remaining -= len(L[-1])
    data = ''.join(L)
    post_data = StringIO(data)

    # Parse the multipart/form-data
    contentTypeHeader = self.headers.getheaders('content-type').pop()

    # Extract the boundary parameter in the content-type header
    headerParameters = contentTypeHeader.split(";")
    boundary = headerParameters[1].split("=")
    boundary = boundary[1].strip()

    parts = cgi.parse_multipart(post_data,
      {"boundary":boundary,
       "content-disposition":self.headers.getheaders('content-disposition')
      })
    print("*****************************")
    for item in parts.keys():
      if len(parts[item][0])< 1000:
        print(item, parts[item])
    print("*****************************")

    from iotbx.detectors.image_from_http_request import module_or_slice_from_http_request
    imgobj = module_or_slice_from_http_request(parts)
    imgobj.read()
    print("Final image object:")
    imgobj.show_header()

    from spotfinder.diffraction.imagefiles import image_files, file_names
    from spotfinder.diffraction.imagefiles import Spotspickle_argument_module

    from spotfinder.applications.overall_procedure import spotfinder_no_pickle

    class server_imagefiles(image_files):
      def __init__(self): pass

    Files = server_imagefiles()
    Files.filenames = file_names(Spotspickle_argument_module(imgobj.filename))
    Files.images = [imgobj]

    S = spotfinder_no_pickle(Files, s3_passthru = "-s3 4",
                             spot_convention = 0)

    frames = Files.frames()

    logfile = StringIO()
    sys.stdout = logfile

    from spotfinder.applications.stats_distl import pretty_image_stats,notes
    for frame in frames:
      #pretty_image_stats(S,frame)
      #notes(S,frames[0])
      module_image_stats(S,frame)

    sys.stdout = sys.__stdout__
    log = logfile.getvalue()
    print(log)

    ctype = 'text/plain'
    self.send_response(200)
    self.send_header("Content-type", ctype)
    self.send_header("Content-length",len(log))
    self.end_headers()
    self.wfile.write(log)
    self.opt_logging()

  def opt_logging(self):
    pass

if __name__=="__main__":
  import sys
  try:
    port = int(sys.argv[1])
  except Exception:
    print("""
Usage:  libtbx.python adsc_server.py <port number>
""")
  server_address = ('', port)

  image_request_handler.protocol_version = "HTTP/1.0"
  httpd = HTTPServer(server_address, image_request_handler)

  sa = httpd.socket.getsockname()
  print("Serving HTTP on", sa[0], "port", sa[1], "...")
  httpd.serve_forever()


 *******************************************************************************


 *******************************************************************************
spotfinder/servers/spotfinder_server_read_file.py
from __future__ import absolute_import, division, print_function
from BaseHTTPServer import BaseHTTPRequestHandler
from scitbx.array_family import flex
from libtbx.development.timers import Timer
from six.moves import StringIO
import cgi, sys, copy
from spotfinder.applications.stats_distl import optionally_add_saturation_webice,key_adaptor

from urlparse import urlparse
#backward compatibility with Python 2.5
try: from urlparse import parse_qs
except Exception: from cgi import parse_qs

def module_safe_items(image):
  return [
      ("%7d","Spot Total",key_adaptor(image,'N_spots_total')),
      ("%7d","Method-2 Resolution Total",key_adaptor(image,'N_spots_resolution')),
      ("%7d","Good Bragg Candidates",key_adaptor(image,'N_spots_inlier')),
      ("%7.0f","Total integrated signal, pixel-ADC units above local background",
                 key_adaptor(image,'ad_hoc_signal1')),
      ("%7d","Ice Rings",key_adaptor(image,'ice-ring_impact')),

      ("%7.2f","Method 1 Resolution",key_adaptor(image,'distl_resolution')),
      ("%7.2f","Method 2 Resolution",key_adaptor(image,'resolution')),

      ("%7.1f","Maximum unit cell",key_adaptor(image,'maxcel')),
  ]

def module_image_stats(S,key):
    # List of spots between specified high- and low-resolution limits
    image = S.images[key]
    spots = image.__getitem__('spots_inlier')

    integrated = 0.0

    for i,spot in enumerate(spots):
     integrated += flex.sum(spot.wts)
    image["ad_hoc_signal1"]=integrated

    canonical_info = []
    canonical_info.extend(module_safe_items(image))
    optionally_add_saturation_webice(canonical_info,image)

    for item in canonical_info:
      if item[2]==None:
        print("%63s : None"%item[1])
      else:
        print("%63s : %s"%(item[1],item[0]%item[2]))

class image_request_handler(BaseHTTPRequestHandler):

  def shutdown(self):
      def my_shutdown(arg1):
        print("IN SHUTDOWN THREAD")
        arg1.server.shutdown()
      import thread
      thread.start_new_thread(my_shutdown,(self,))
      #must be called in a different thread or deadlock.
      log = ""
      self.send_response(200)
      self.send_header("Content-type", 'text/plain')
      self.send_header("Content-length",len(log))
      self.end_headers()
      self.wfile.write(log)

  def do_POST(self):
    T = Timer("do_POST")
    parsed = urlparse(self.path)
    qs = parse_qs(parsed.query)

    expect = self.headers.getheaders("Expect")
    if len(expect)>=1:
      if True in [item.find("200")>=0 for item in expect]:
        self.send_response(200) # untested; has no apparent affect on libcurl
        return

    # Get arguments by reading body of request.
    # We read this in chunks to avoid straining
    # socket.read(); around the 10 or 15Mb mark, some platforms
    # begin to have problems (bug #792570).
    max_chunk_size = 10*1024*1024
    size_remaining = int(self.headers["content-length"])
    L = []
    while size_remaining:
        chunk_size = min(size_remaining, max_chunk_size)
        L.append(self.rfile.read(chunk_size))
        size_remaining -= len(L[-1])
    data = ''.join(L)
    post_data = StringIO(data)

    # Parse the multipart/form-data
    contentTypeHeader = self.headers.getheaders('content-type').pop()

    # Extract the boundary parameter in the content-type header
    headerParameters = contentTypeHeader.split(";")
    boundary = headerParameters[1].split("=")
    boundary = boundary[1].strip()

    parts = cgi.parse_multipart(post_data,
      {"boundary":boundary,
       "content-disposition":self.headers.getheaders('content-disposition')
      })
    print("*****************************")
    for item in parts.keys():
      if len(parts[item][0])< 1000:
        print(item, parts[item])
    print("*****************************")

    if parts["filename"][0].find("EXIT")>=0:
      self.shutdown()
      return

    from spotfinder.diffraction.imagefiles import spotfinder_image_files as ImageFiles
    from spotfinder.diffraction.imagefiles import Spotspickle_argument_module
    response_params = copy.deepcopy(common_parameters_singleton).extract()

    Files = ImageFiles(Spotspickle_argument_module(parts["filename"][0]),response_params)

    print("Final image object:")
    Files.images[0].show_header()
    print("beam_center_convention",Files.images[0].beam_center_convention)
    print("beam_center_reference_frame",Files.images[0].beam_center_reference_frame)

    logfile = StringIO()
    if response_params.distl.bins.verbose: sys.stdout = logfile

    from spotfinder.applications.wrappers import spotfinder_factory
    S = spotfinder_factory(None, Files, response_params)
    print()
    sys.stdout = sys.__stdout__

    frames = Files.frames()

    sys.stdout = logfile

    print("Image: %s"%parts["filename"][0])
    from spotfinder.applications.stats_distl import pretty_image_stats,notes
    for frame in frames:
      #pretty_image_stats(S,frame)
      #notes(S,frames[0])
      module_image_stats(S,frame)

    sys.stdout = sys.__stdout__
    log = logfile.getvalue()
    print(log)

    ctype = 'text/plain'
    self.send_response(200)
    self.send_header("Content-type", ctype)
    self.send_header("Content-length",len(log))
    self.end_headers()
    self.wfile.write(log)
    self.opt_logging()

  def opt_logging(self):
    pass

  def do_GET(self):
    T = Timer("do_GET")
    parsed = urlparse(self.path)
    qs = parse_qs(parsed.query)

    expect = self.headers.getheaders("Expect")
    if len(expect)>=1:
      if True in [item.find("200")>=0 for item in expect]:
        self.send_response(200) # untested; has no apparent affect on libcurl
        return

    log = self.do_GET_run(qs)

    ctype = 'text/plain'
    self.send_response(200)
    self.send_header("Content-type", ctype)
    self.send_header("Content-length",len(log))
    self.end_headers()
    self.wfile.write(log)
    self.opt_logging()

  def do_GET_run(self,qs): #similar to the run() function in apache.py module
    from libtbx.utils import Sorry
    import os
    from spotfinder.servers import LoggingFramework

    base_params = copy.deepcopy(common_parameters_singleton)
    argument_interpreter = base_params.command_line_argument_interpreter()
    phil_objects = []

    for key in qs.keys():
      arg = "%s=%s"%(key,qs.get(key,"")[0])
      try: command_line_params = argument_interpreter.process(arg=arg)
      except Exception: return str(Sorry("Unknown file or keyword: %s" % arg))
      else: phil_objects.append(command_line_params)

    working_params = base_params.fetch(sources=phil_objects)
    params = working_params.extract()
    #working_params.show()
    if not os.path.isfile(params.distl.image):
      return  str(Sorry("%s is not a readable file" % params.distl.image))

    print("Image: %s"%params.distl.image)

    logfile = LoggingFramework()
    from spotfinder.applications import signal_strength
    try:
      signal_strength.run_signal_strength(params)
    except Exception:
      import traceback
      logger = StringIO()
      logger.write(
      "Sorry, can't process %s.  Please contact authors.\n"% params.distl.image)
      traceback.print_exc(file=logger)
      return str(Sorry( logger.getvalue() ))

    return logfile.getvalue()

common_parameters_singleton = None

def generate_common_parameters(input_parameters):
  global common_parameters_singleton
  common_parameters_singleton = input_parameters


 *******************************************************************************


 *******************************************************************************
spotfinder/servers/thin_client.py
from __future__ import absolute_import, division, print_function
import os
from spotfinder.servers.multipart_encoder import post_multipart

def get_spotfinder_url(filename,host,port):
  if filename.find("EXIT")>=0:
    kill_server(host,port)
    return
  testurl = "%s:%d"%(host,port)
  selector = "/spotfinder"
  query_object = [
    ("filename",filename),
    ("bin",1),
  ]

  Response = post_multipart(host=testurl, selector=selector,
    fields = query_object, files = [])

  print(Response.getresponse().read())
  Response.close()

def kill_server(host,port):
  from socket import error as socketerror
  try:
    while 1:
      testurl = "%s:%d"%(host,port)
      selector = "/spotfinder"
      query_object = [
      ("filename","EXIT"),
      ("bin",1),
      ]

      Response = post_multipart(host=testurl, selector=selector,
      fields = query_object, files = [])
      Response.getresponse()
      Response.close()
  except socketerror as e:
    pass

def do_main(filepath, host, port):
  absfile = os.path.abspath(filepath)
  get_spotfinder_url(absfile,host,port)

def do_main_apache(filepath, host, port):
  absfile = os.path.abspath(filepath)
  from six.moves import urllib
  Response = urllib.request.urlopen(
   "http://%s:%d/spotfinder/distl.signal_strength?filename=%s"%(
   host,port,absfile))
  print(Response.read())
  Response.close()


if __name__=="__main__":
  "Client is intended to be used with [mp_]spotfinder_server_read_file.py"
  import sys
  try:
    filepath, host, port = sys.argv[1:4]
    port = int(port)
  except Exception:
    print("""
Usage:
libtbx.python thin_client.py <filepath> <host> <port>
Three mandatory arguments:
  filepath: absolute or relative path name of the ADSC test image to be analyzed
  host: usually "localhost";
  port: port number of image analyzer http service
""")
  do_main(filepath, host, port)


 *******************************************************************************
