

 *******************************************************************************
mmtbx/command_line/__init__.py

# XXX this module is tested implicitly in many other regression tests, but
# needs more thorough testing on its own

"""
Generic wrapper for bootstrapping high-level applications which rely on some
combination of model and data, with special attention to geometry restraints
interpretation and f_model setup.  All of the bookkeeping required to
disambiguate crystal symmetry and Miller array conventions is performed
automatically.  This is superficially similar to the setup for phenix.refine
(and re-uses many of the methods in mmtbx.utils), but is somewhat simpler
(single-dataset only) and more general-purpose.
"""

from __future__ import absolute_import, division, print_function
from cctbx import uctbx
from iotbx import file_reader
import iotbx.pdb
from libtbx.str_utils import make_header, make_sub_header
from libtbx.utils import Sorry, Usage, multi_out, null_out
from libtbx import Auto
from scitbx.array_family import flex
from six import string_types
from six.moves import cStringIO as StringIO
import sys
from iotbx import extract_xtal_data

cmdline_input_phil_base_str = """
input {
  include scope iotbx.extract_xtal_data.xray_data_str
  %(phases)s
  %(unmerged)s
  pdb {
    include scope mmtbx.utils.pdb_params
  }
  monomers {
    include scope mmtbx.utils.cif_params
  }
  maps {
    include scope mmtbx.real_space_correlation.map_files_params_str
  }
  sequence = None
    .type = path
  scattering_table = wk1995  it1992  *n_gaussian  neutron electron
    .type = choice
  wavelength = None
    .type = float
  energy = None
    .type = float
  %(phases_flag)s
  %(automatic_twin_detection)s
  %(twin_law)s
}
%(pdb_interpretation)s
"""

def generate_master_phil_with_inputs(
    phil_string,
    enable_twin_law=True,
    enable_automatic_twin_detection=False,
    enable_experimental_phases=False,
    enable_pdb_interpretation_params=False,
    enable_stop_for_unknowns=None,
    enable_full_geometry_params=False,
    enable_unmerged_data=False,
    enable_cdl=None,
    as_phil_string=False):
  """
  Generate a complete PHIL parameter block with generic input parameters plus
  user-specified options.  The result is suitable for input for the class
  load_model_and_data.  Depending on the target application, the exact input
  options can be adjusted.

  :param phil_string: application-specific parameters
  :param enable_twin_law: allow twinned f_model calculation
  :param enable_automatic_twin_detection: allow automatic detection of twinning
      and setup of the f_model object
  :param enable_experimental_phases: use Hendrickson-Lattman coefficients
  :param enable_pdb_interpretation_params: show options for modifying the
      behavior of mmtbx.monomer_library.pdb_interpretation
  :param enable_stop_for_unknowns: modify behavior of restraint interpretation
      when unknown atoms are encountered.  Default is None; if True, the
      program will not raise an error; if False, the program will raise an
      error which may be suppressed by the user
  :param enable_full_geometry_params: include parameters for specifying custom
      geometry resraints
  :param enable_unmerged_data: accept separate unmerged intensities
  :param enable_cdl: change default setting for conformation-dependent library
  :param as_phil_string: return parameter string instead of PHIL object
  :returns: PHIL object (unless as_phil_string=True)
  """
  import iotbx.phil
  phil_extra_dict = {
    "phases" : "",
    "unmerged" : "",
    "phases_flag" : "",
    "automatic_twin_detection" : "",
    "twin_law" : "",
    "pdb_interpretation" : "",
  }
  # for legacy, keep the 2 paramters for twin laws
  # one for enabling automatic detection
  # another for specifying a twin law
  if (enable_automatic_twin_detection):
    phil_extra_dict["automatic_twin_detection"] = """
      skip_twin_detection = False
        .type = bool"""
  if (enable_twin_law):
    phil_extra_dict["twin_law"] = """
      twin_law = Auto
        .type = str
        .help = Enter twin law if known.
        .input_size = 100"""
  if (enable_experimental_phases):
    phil_extra_dict["phases"] = """
      experimental_phases {
        include scope iotbx.extract_xtal_data.experimental_phases_params_str
      }"""
    phil_extra_dict["phases_flag"] = """
      use_experimental_phases = Auto
        .type = bool
        .short_caption = Use experimental phases (Hendrickson-Lattman coefficients)
      """
  else:
    phil_extra_dict["phases_flag"] = """
      use_experimental_phases = False
        .type = bool
        .short_caption = Use experimental phases (Hendrickson-Lattman coefficients)
      """
  if (enable_unmerged_data):
    phil_extra_dict["unmerged"] = """
      unmerged_data {
        file_name = None
          .type = path
        labels = None
          .type = str
        use_internal_variance = True
          .type = bool
      }"""
  if (enable_pdb_interpretation_params) or (enable_full_geometry_params):
    stop_for_unknowns_params = ""
    if (enable_stop_for_unknowns is not None):
      stop_for_unknowns_params = """
        stop_for_unknowns = %s
          .type = bool""" % enable_stop_for_unknowns
    phil_extra_dict["pdb_interpretation"] = """
      pdb_interpretation {
        include scope mmtbx.monomer_library.pdb_interpretation.master_params
        %s
      }""" % (stop_for_unknowns_params)
    if (enable_full_geometry_params):
      phil_extra_dict["pdb_interpretation"] += """
        geometry_restraints
          .alias = refinement.geometry_restraints
        {
          edits
            .short_caption = Custom geometry restraints
          {
            include scope mmtbx.monomer_library.pdb_interpretation.geometry_restraints_edits_str
          }
          remove {
            include scope mmtbx.monomer_library.pdb_interpretation.geometry_restraints_remove_str
          }
        }"""
  cmdline_input_phil_str = cmdline_input_phil_base_str % phil_extra_dict
  master_phil_str = """
    %s
    %s
  """ % (cmdline_input_phil_str, phil_string)
  if (as_phil_string):
    assert (enable_cdl is None)
    return master_phil_str
  master_phil = iotbx.phil.parse(master_phil_str, process_includes=True)
  if (enable_cdl is not None):
    wp = iotbx.phil.parse("pdb_interpretation.restraints_library.cdl=%s" % enable_cdl)
    master_phil = master_phil.fetch(source=wp)
  return master_phil

def generic_simple_input_phil():
  """
  Generate minimal PHIL input string with no additional parameters.
  """
  return generate_master_phil_with_inputs(
    phil_string="",
    enable_automatic_twin_detection=True)

class load_model_and_data(object):
  """
  Class for processing command-line input and creating necessary objects.
  The master_phil object should include cmdline_input_phil_str above, plus
  any application-specific parameters.  Programs which use this can be invoked
  using simple file arguments or explicit parameters, e.g.

    mmtbx.some_program model.pdb data.mtz

  This class performs the following functions (mostly using other wrappers
  elsewhere in mmtbx.utils):
    1. Process all arguments and extract as Python parameters
    2. Read in data and R-free flags
    3. Filter data and flags to be consistent if necessary
    4. Read in PDB file, either using the iotbx.pdb API, or if process_pdb_file
       is True, mmtbx.monomer_library.pdb_interpretation (using any CIF files
       included in the inputs)
    5. Extract the pdb_hierarchy and xray_structure objects.
    6. Create an mmtbx.f_model.manager object using the data, flags, and
       xray_structure.
  If at any point the inputs are ambiguous, hopefully the program will stop
  and raise an interpretable error.

  Parameters
  ----------
  args: list of command-line arguments
  master_phil: PHIL master (can optionally be an unparsed string)
  out: filehandle-like object
  process_pdb_file: run full restraints generation
  require_data: raise error if no experimental data supplied
  create_fmodel: setup mmtbx.f_model.manager object
  prefer_anomalous: preferentially use anomalous data if present
  force_non_anomalous: merge anomalous data if present
  set_wavelength_from_model_header: interpret PDB or mmCIF header to set \
    experimental wavelength
  set_inelastic_form_factors: table to use (if any) for setting anomalous \
    scattering form factors
  usage_string: console output for no arguments or --help
  create_log_buffer: store log output for later output to file
  remove_unknown_scatterers: delete atoms with scattering type 'X' (only \
    used when process_pdb_file=False)
  generate_input_phil: specifies that the master_phil object is a string \
    containing onky the app-specific options, and automatically add the \
    standard input parameters

  Attributes
  ----------
  args : list of str
  cif_file_names : libtbx.phil.scope_extract_list
  cif_objects : list of ...
  crystal_symmetry : cctbx.crystal.symmetry
  f_obs : cctbx.miller.array
  fmodel : mmtbx.f_model.manager
  geometry : cctbx.geometry_restraints.manager.manager
  hl_coeffs : ...
  intensity_flag : bool
  log : file
  master_phil : libtbx.phil.scope
  miller_arrays : list of cctbx.miller.array
  params : libtbx.phil.scope_extract
  pdb_file_names : libtbx.phil.scope_extract_list
  pdb_hierarchy : iotbx.pdb.hierarchy.root
  pdb_inp : iotbx.pdb.input
  processed_pdb_file : mmtbx.monomer_library.pdb_interpretation.process
  r_free_flags : cctbx.miller.array
  raw_data : cctbx.miller.array
  raw_flags : cctbx.miller.array
  sequence : ...
  test_flag_value : int
  unknown_residues_flag : bool
  unknown_residues_error_message : str
  unmerged_i_obs : ...
  working_phil : libtbx.phil.scope
  xray_structure : cctbx.xray.structure.structure

  Examples
  --------
  >>> from mmtbx.command_line import load_model_and_data
  >>> cmdline = load_model_and_data(
  ...  args=["model.pdb", "data.mtz"],
  ...  master_phil=master_phil,
  ...  prefer_anomalous=True,
  ...  set_wavelength_from_model_header=True,
  ...  set_inelastic_form_factors="sasaki",
  ...  )
  >>> assert cmdline.pdb_hierarchy is not None
  >>> assert cmdline.fmodel is not None
  >>> assert cmdline.params.input.wavelength is not None
  """
  def __init__(self,
      args,
      master_phil,
      out=sys.stdout,
      process_pdb_file=True,
      require_data=True,
      create_fmodel=True,
      prefer_anomalous=None,
      force_non_anomalous=False,
      set_wavelength_from_model_header=False,
      set_inelastic_form_factors=None,
      usage_string=None,
      create_log_buffer=False,
      remove_unknown_scatterers=False,
      generate_input_phil=False):
    import mmtbx.monomer_library.pdb_interpretation
    import mmtbx.monomer_library.server
    import mmtbx.utils
    import mmtbx.model
    from iotbx import crystal_symmetry_from_any
    import iotbx.phil
    if generate_input_phil :
      from six import string_types
      assert isinstance(master_phil, string_types)
      master_phil = generate_master_phil_with_inputs(phil_string=master_phil)
    if isinstance(master_phil, str):
      master_phil = iotbx.phil.parse(master_phil)
    if (usage_string is not None):
      if (len(args) == 0) or ("--help" in args):
        raise Usage("""%s\n\nFull parameters:\n%s""" % (usage_string,
          master_phil.as_str(prefix="  ")))
    if (force_non_anomalous):
      assert (not prefer_anomalous)
    assert (set_inelastic_form_factors in [None, "sasaki", "henke"])
    self.args = args
    self.master_phil = master_phil
    self.processed_pdb_file = self.pdb_inp = None
    self.pdb_hierarchy = self.xray_structure = None
    self.geometry = None
    self.sequence = None
    self.fmodel = None
    self.f_obs = None
    self.r_free_flags = None
    self.intensity_flag = None
    self.raw_data = None
    self.raw_flags = None
    self.test_flag_value = None
    self.miller_arrays = None
    self.hl_coeffs = None
    self.cif_objects = []
    self.log = out
    if ("--quiet" in args) or ("quiet=True" in args):
      self.log = null_out()
    elif create_log_buffer :
      self.log = multi_out()
      self.log.register(label="stdout", file_object=out)
      self.log.register(label="log_buffer", file_object=StringIO())
    make_header("Collecting inputs", out=self.log)
    cmdline = iotbx.phil.process_command_line_with_files(
      args=args,
      master_phil=master_phil,
      pdb_file_def="input.pdb.file_name",
      reflection_file_def="input.xray_data.file_name",
      cif_file_def="input.monomers.file_name",
      seq_file_def="input.sequence")
    self.working_phil = cmdline.work
    params = self.working_phil.extract()
    if len(params.input.pdb.file_name) == 0 :
      raise Sorry("At least one PDB file is required as input.")
    self.cif_file_names = params.input.monomers.file_name
    self.pdb_file_names = params.input.pdb.file_name
    # SYMMETRY HANDLING - PDB FILES
    self.crystal_symmetry = pdb_symm = None
    for pdb_file_name in params.input.pdb.file_name :
      pdb_symm = crystal_symmetry_from_any.extract_from(pdb_file_name)
      if (pdb_symm is not None):
        break
    # DATA INPUT
    data_and_flags = hkl_symm = hkl_in = None
    if (params.input.xray_data.file_name is None):
      if (require_data):
        raise Sorry("At least one reflections file is required as input.")
    else :
      # FIXME this may still require that the data file has full crystal
      # symmetry defined (although for MTZ input this will not be a problem)
      make_sub_header("Processing X-ray data", out=self.log)
      hkl_in = file_reader.any_file(params.input.xray_data.file_name)
      hkl_in.check_file_type("hkl")
      hkl_server = hkl_in.file_server
      symm = hkl_server.miller_arrays[0].crystal_symmetry()
      if ((symm is None) or
          (symm.space_group() is None) or
          (symm.unit_cell() is None)):
        if (pdb_symm is not None):
          from iotbx.reflection_file_utils import reflection_file_server
          print("No symmetry in X-ray data file - using PDB symmetry:", file=self.log)
          pdb_symm.show_summary(f=out, prefix="  ")
          hkl_server = reflection_file_server(
            crystal_symmetry=pdb_symm,
            reflection_files=[hkl_in.file_object])
        else :
          raise Sorry("No crystal symmetry information found in input files.")
      if (hkl_server is None):
        hkl_server = hkl_in.file_server
      try:
        pp = params.input.experimental_phases
      except AttributeError: pp=None
      data_and_flags = extract_xtal_data.run(
        reflection_file_server=hkl_server,
        parameters=params.input.xray_data,
        experimental_phases_params = pp,
        prefer_anomalous=prefer_anomalous,
        force_non_anomalous=force_non_anomalous)
      self.intensity_flag = data_and_flags.f_obs.is_xray_intensity_array()
      self.raw_data = data_and_flags.raw_data
      self.raw_flags = data_and_flags.raw_flags
      self.test_flag_value = data_and_flags.test_flag_value
      self.f_obs = data_and_flags.f_obs
      self.r_free_flags = data_and_flags.r_free_flags
      self.miller_arrays = hkl_in.file_server.miller_arrays
      self.hl_coeffs = None
      target_name = "ml"
      if(data_and_flags.experimental_phases is not None) and (
          params.input.use_experimental_phases):
        target_name = "mlhl"
        self.hl_coeffs = data_and_flags.experimental_phases
      hkl_symm = self.raw_data.crystal_symmetry()
    if len(self.cif_file_names) > 0 :
      for file_name in self.cif_file_names :
        cif_obj = mmtbx.monomer_library.server.read_cif(file_name=file_name)
        self.cif_objects.append((file_name, cif_obj))
    # SYMMETRY HANDLING - COMBINED
    if (hkl_symm is not None):
      use_symmetry = hkl_symm

    # check for weird crystal symmetry
    # modified from mmtbx.command_line.secondary_structure_restraints
    # plan to centralize functionality in another location
    # -------------------------------------------------------------------------
    cs = pdb_symm

    corrupted_cs = False
    if cs is not None:
      if [cs.unit_cell(), cs.space_group()].count(None) > 0:
        corrupted_cs = True
        cs = None
      elif cs.unit_cell().volume() < 10:
        corrupted_cs = True
        cs = None

    if cs is None:
      if corrupted_cs:
        print("Symmetry information is corrupted,", end=' ', file=out)
      else:
        print("Symmetry information was not found,", end=' ', file=out)

      if (hkl_symm is not None):
        print("using symmetry from data.", file=out)
        cs = hkl_symm
      else:
        print("putting molecule in P1 box.", file=out)
        pdb_combined = iotbx.pdb.combine_unique_pdb_files(
          file_names=self.pdb_file_names)
        pdb_structure = iotbx.pdb.input(
          source_info=None, lines=flex.std_string(pdb_combined.raw_records))
        atoms = pdb_structure.atoms()
        box = uctbx.non_crystallographic_unit_cell_with_the_sites_in_its_center(
          sites_cart=atoms.extract_xyz(),
          buffer_layer=3)
        atoms.set_xyz(new_xyz=box.sites_cart)
        cs = box.crystal_symmetry()

    pdb_symm = cs
    # -------------------------------------------------------------------------

    from iotbx.symmetry import combine_model_and_data_symmetry
    self.crystal_symmetry = combine_model_and_data_symmetry(
      model_symmetry=pdb_symm,
      data_symmetry=hkl_symm)
    if (self.crystal_symmetry is not None) and (self.f_obs is not None):
      self.f_obs = self.f_obs.customized_copy(
        crystal_symmetry=self.crystal_symmetry).eliminate_sys_absent().set_info(
          self.f_obs.info())
      if self.r_free_flags:
        self.r_free_flags = self.r_free_flags.customized_copy(
        crystal_symmetry=self.crystal_symmetry).eliminate_sys_absent().set_info(
          self.r_free_flags.info())
      else:
        self.r_free_flags = None
    # PDB INPUT
    self.unknown_residues_flag = False
    self.unknown_residues_error_message = False

    pdb_combined = mmtbx.utils.combine_unique_pdb_files(
      file_names=params.input.pdb.file_name,)
    pdb_combined.report_non_unique(out=self.log)
    pdb_raw_records = pdb_combined.raw_records
    try:
      self.pdb_inp = iotbx.pdb.input(source_info = None,
                                lines       = flex.std_string(pdb_raw_records))
    except ValueError as e :
      raise Sorry("Model format (PDB or mmCIF) error:\n%s" % str(e))

    if (remove_unknown_scatterers):
      h = self.pdb_inp.construct_hierarchy()
      known_sel = h.atom_selection_cache().selection(
        "not element X")
      if known_sel.count(False) > 0:
        self.pdb_inp = iotbx.pdb.input(
            source_info = None,
            lines=h.select(known_sel).as_pdb_or_mmcif_string())

    model_params = mmtbx.model.manager.get_default_pdb_interpretation_params()
    pdb_interp_params = getattr(params, "pdb_interpretation", None)
    if pdb_interp_params is None:
      pdb_interp_params = iotbx.phil.parse(
          input_string=mmtbx.monomer_library.pdb_interpretation.grand_master_phil_str,
          process_includes=True).extract()
      pdb_interp_params = pdb_interp_params.pdb_interpretation
    model_params.pdb_interpretation = pdb_interp_params
    stop_for_unknowns = getattr(pdb_interp_params, "stop_for_unknowns",False) or remove_unknown_scatterers
    if not process_pdb_file:
      stop_for_unknowns = True and not remove_unknown_scatterers
    self.model = mmtbx.model.manager(
        model_input = self.pdb_inp,
        crystal_symmetry= self.crystal_symmetry,
        restraint_objects = self.cif_objects,
        stop_for_unknowns=stop_for_unknowns,
        log=self.log)
    if process_pdb_file:
      make_sub_header("Processing PDB file(s)", out=self.log)
      self.model.process(pdb_interpretation_params = model_params,
        make_restraints=True)
      full_grm = self.model.get_restraints_manager()
      self.geometry = full_grm.geometry
      self.processed_pdb_file = self.model._processed_pdb_file # to remove later XXX
    self.xray_structure = self.model.get_xray_structure()
    self.pdb_hierarchy = self.model.get_hierarchy()
    self.pdb_hierarchy.atoms().reset_i_seq()
    # wavelength
    if (params.input.energy is not None):
      if (params.input.wavelength is not None):
        raise Sorry("Both wavelength and energy have been specified!")
      params.input.wavelength = 12398.424468024265 / params.input.energy
    if (set_wavelength_from_model_header and params.input.wavelength is None):
      wavelength = self.pdb_inp.extract_wavelength()
      if (wavelength is not None):
        print("", file=self.log)
        print("Using wavelength = %g from PDB header" % wavelength, file=self.log)
        params.input.wavelength = wavelength
    # set scattering table
    if (data_and_flags is not None):
      self.model.setup_scattering_dictionaries(
          scattering_table=params.input.scattering_table,
          d_min=self.f_obs.d_min(),
          log = self.log,
          set_inelastic_form_factors=set_inelastic_form_factors,
          iff_wavelength=params.input.wavelength)
      self.xray_structure.show_summary(f=self.log)

    # FMODEL SETUP
    if (create_fmodel) and (data_and_flags is not None):
      make_sub_header("F(model) initialization", out=self.log)
      skip_twin_detection = getattr(params.input, "skip_twin_detection", True)
      twin_law = getattr(params.input, "twin_law", None)
      if (twin_law is Auto):
        if (self.hl_coeffs is not None):
          raise Sorry("Automatic twin law determination not supported when "+
            "experimental phases are used.")
      elif (not skip_twin_detection):
        twin_law = Auto
      if (twin_law is Auto):
        print("Twinning will be detected automatically.", file=self.log)
        self.fmodel = mmtbx.utils.fmodel_simple(
          xray_structures=[self.xray_structure],
          scattering_table=params.input.scattering_table,
          f_obs=self.f_obs,
          r_free_flags=self.r_free_flags,
          skip_twin_detection=skip_twin_detection,
          target_name=target_name,
          log=self.log)
      else :
        if ((twin_law is not None) and (self.hl_coeffs is not None)):
          raise Sorry("Automatic twin law determination not supported when "+
            "experimental phases are used.")
        self.fmodel = mmtbx.utils.fmodel_manager(
          f_obs=self.f_obs,
          xray_structure=self.xray_structure,
          r_free_flags=self.r_free_flags,
          twin_law=params.input.twin_law,
          hl_coeff=self.hl_coeffs,
          target_name=target_name)
        self.fmodel.update_all_scales(
          params=None,
          log=self.log,
          optimize_mask=True,
          show=True)
      self.fmodel.info().show_rfactors_targets_scales_overall(out=self.log)
    # SEQUENCE
    if (params.input.sequence is not None):
      seq_file = file_reader.any_file(params.input.sequence,
        force_type="seq",
        raise_sorry_if_errors=True)
      self.sequence = seq_file.file_object
    # UNMERGED DATA
    self.unmerged_i_obs = None
    if hasattr(params.input, "unmerged_data"):
      if (params.input.unmerged_data.file_name is not None):
        self.unmerged_i_obs = load_and_validate_unmerged_data(
          f_obs=self.f_obs,
          file_name=params.input.unmerged_data.file_name,
          data_labels=params.input.unmerged_data.labels,
          log=self.log)
    self.params = params
    print("", file=self.log)
    print("End of input processing", file=self.log)

  def start_log_file(self, file_name):
    """
    Open a log file and write out the existing output buffer, returning the
    multi_out pseudo-filehandle.

    :param file_name: log file to create
    :returns: libtbx.utils.multi_out object
    """
    assert type(self.log).__name__ == 'multi_out'
    log_file = open(file_name, "w")
    self.log.replace_stringio(
      old_label="log_buffer",
      new_label="log",
      new_file_object=log_file)
    return self.log

  def save_data_mtz(self, file_name):
    """
    Write the processed amplitudes, optional Hendrickson-Lattman coefficients,
    and R-free flags to the designated MTZ file.
    """
    assert (self.f_obs is not None)
    mtz_data = self.f_obs.as_mtz_dataset(column_root_label="F")
    if (self.hl_coeffs is not None):
      mtz_data.add_miller_array(self.hl_coeffs,
        column_root_label="HL")
    if (self.r_free_flags is not None):
      mtz_data.add_miller_array(self.r_free_flags,
        column_root_label="FreeR_flag")
    mtz_data.mtz_object().write(file_name)

  def create_model_manager(self, log=None):
    """
    Instantiate an mmtbx.model.manager object with the current pdb hierarchy,
    xray structure, and geometry restraints.
    deprecated
    """
    return self.model

    if (log is None) : log = self.log
    import mmtbx.restraints
    import mmtbx.model
    restraints_manager = mmtbx.restraints.manager(
      geometry=self.geometry,
      normalization=True)
    return mmtbx.model.manager(
      xray_structure=self.xray_structure,
      pdb_hierarchy=self.pdb_hierarchy,
      restraints_manager=restraints_manager,
      log=log)

def load_and_validate_unmerged_data(f_obs, file_name, data_labels,
    log=sys.stdout):
  """
  Read in (and verify) unmerged intensities, e.g. from scalepack or XDS.
  """
  from iotbx import merging_statistics
  unmerged_i_obs = merging_statistics.select_data(
    file_name=file_name,
    data_labels=data_labels,
    log=log)
  if ((unmerged_i_obs.space_group() is not None) and
      (unmerged_i_obs.unit_cell() is not None)):
    if (not unmerged_i_obs.is_similar_symmetry(f_obs)):
      pg_f_obs = f_obs.space_group().build_derived_point_group()
      pg_i_obs = unmerged_i_obs.space_group().build_derived_point_group()
      if (pg_i_obs == pg_f_obs):
        # special case: same unit cell, same point group, different space group
        if unmerged_i_obs.unit_cell().is_similar_to(f_obs.unit_cell()):
          return unmerged_i_obs
      show_symmetry_error("Data file", "Unmerged data", unmerged_i_obs, f_obs)
  elif (unmerged_i_obs.space_group() is not None):
    pg_f_obs = f_obs.space_group().build_derived_point_group()
    pg_i_obs = unmerged_i_obs.space_group().build_derived_point_group()
    if (pg_i_obs != pg_f_obs):
      raise Sorry("Incompatible space groups in merged and unmerged data:"+
        "%s versus %s" % (f_obs.space_group_info(),
        unmerged_i_obs.space_group_info()))
  return unmerged_i_obs

def show_symmetry_error(file1, file2, symm1, symm2):
  symm_out1 = StringIO()
  symm_out2 = StringIO()
  symm1.show_summary(f=symm_out1, prefix="  ")
  symm2.show_summary(f=symm_out2, prefix="  ")
  raise Sorry("Incompatible symmetry definitions:\n%s:\n%s\n%s\n%s" %
    (file1, symm_out1.getvalue(), file2, symm_out2.getvalue()))

def check_files(phil_scope, file_type, error_message):
  if (phil_scope is not None):
    if (isinstance(phil_scope, list)):
      for file_name in phil_scope:
        f = file_reader.any_file(file_name)
        if (f.file_type != file_type):
          raise Sorry(error_message)
    else:
      f = file_reader.any_file(phil_scope)
      if (f.file_type != file_type):
        raise Sorry(error_message)

def validate_input_params(params):
  """
  Check for completeness of mandatory input parameters
  """
  if params.input.pdb.file_name is None :
    raise Sorry("No PDB file defined.")
  elif isinstance(params.input.pdb.file_name,list):
    if (len(params.input.pdb.file_name) == 0):
      raise Sorry("No PDB file defined.")
  elif params.input.xray_data.file_name is None :
    raise Sorry("No reflection file defined.")
  elif params.input.xray_data.labels is None :
    raise Sorry("No labels chosen for reflection data.")
  elif (params.input.xray_data.r_free_flags.label is None):
    raise Sorry("R-free flags not defined.  If you are trying to run this "+
      "program with a reflections file that is missing R-free flags, use "+
      "the reflection file editor to generate a new tests set.")
  return True


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/altloc_remediate.py
from __future__ import absolute_import, division, print_function
import os, sys
from libtbx import phil
import libtbx.phil.command_line
import iotbx.pdb
from libtbx.utils import Sorry
from six.moves import range

master_phil_string = """

altloc_remediate
  .caption = None
{
  input
  {
    pdb_file_name = None
      .type = path
      .short_caption = model
      .help = PDB filename
      .style = bold file_type:pdb
    residue_selection = None
      .type = str
      .multiple = True
      .short_caption = Use this selection to
      .help = The
  }
  control
  {
    correct_alt_loc = True
      .type = bool
      .help = General improvement
    spread_alt_loc = False
      .type = bool
      .help = expand the alt. loc.
    use_geometry_as_spread_criteria = True
      .type = bool
    block_alt_loc = False
      .type = bool
  }
  output
  {
    file_name = None
      .type = path
      .short_caption = Output file
      .help = Defaults to current directory
      .style = bold new_file file_type:pdb
    display = False
      .type = bool
      .short_caption = Display the residues only, no remediation
  }
}
"""

master_params = master_phil_string # need for auto documentation
if False:
  print('-'*80)
  print(master_phil_string)
  print('-'*80)
master_phil = phil.parse(master_phil_string)

mainchain = set(["CA", "C", "N", "O"])
partial1 = set(["C", "O"])
partial2 = set(["N", "H", "HA"])

def check_for_exchange_hd(residue_group, remove):
  if len(remove)!=2: return remove
  ag1 = residue_group.atom_groups()[remove[0]]
  ag2 = residue_group.atom_groups()[remove[1]]
  if len(ag1.atoms())!=len(ag2.atoms()): return remove
  isotopes1 = []
  for atom in ag1.atoms():
    if atom.element.strip() not in isotopes1:
      isotopes1.append(atom.element.strip())
  if len(isotopes1)!=1: return remove
  isotopes2 = []
  for atom in ag2.atoms():
    if atom.element.strip() not in isotopes2:
      isotopes2.append(atom.element.strip())
  if len(isotopes2)!=1: return remove
  if isotopes1[0]=="H" and isotopes2[0]=="D": return []
  if isotopes1[0]=="D" and isotopes2[0]=="H": return []

def adjust_hydrogen_alt_locs(hierarchy):
  for residue_group in hierarchy.residue_groups():
    remove = []
    for atom_group_i, atom_group in enumerate(residue_group.atom_groups()):
      if not atom_group.altloc.strip(): continue
      hydrogens = []
      for atom in atom_group.atoms():
        if atom.element.strip() not in ["H", "D"]: continue
        hydrogens.append(atom)
      if len(hydrogens)==len(atom_group.atoms()):
        remove.append(atom_group_i)
    if remove:
      # check for H/D exchangeable
      remove = check_for_exchange_hd(residue_group, remove)
    if remove:
      for atom_group_i, atom_group in enumerate(residue_group.atom_groups()):
        if not atom_group.altloc.strip(): blank = atom_group
        if atom_group_i in remove:
          blank_atom_names = []
          for atom in blank.atoms(): blank_atom_names.append(atom.name.strip())
          for atom in atom_group.atoms():
            if not atom.name.strip() in blank_atom_names:
              blank.append_atom(atom.detached_copy())
            atom_group.remove_atom(atom)
          residue_group.remove_atom_group(atom_group)
  return hierarchy

def all_mainchain_alt_loc(hierarchy):
  for residue_group in hierarchy.residue_groups():
    blank = None
    atoms = set()
    move_blank_to_alt_locs = False
    move_CO_to_alt_locs = False
    move_NH_to_alt_locs = False
    for atom_group_i, atom_group in enumerate(residue_group.atom_groups()):
      if not atom_group.altloc.strip():
        blank = atom_group
        continue
      if blank is None: break
      for atom in atom_group.atoms():
        atoms.add(atom.name.strip())
      if atoms.intersection(mainchain):
        if atoms.intersection(partial1) and not atoms.intersection(partial2):
          move_CO_to_alt_locs = True
        elif atoms.intersection(partial2) and not atoms.intersection(partial1):
          move_NH_to_alt_locs = True
        else:
          move_blank_to_alt_locs = True
        break
    if 0:
      print('move_blank_to_alt_locs',move_blank_to_alt_locs)
      print('move_CO_to_alt_locs   ',move_CO_to_alt_locs)
      print('move_NH_to_alt_locs   ',move_NH_to_alt_locs)
    moving_atoms = []
    moving_group = None
    if move_blank_to_alt_locs:
      for atom_group_i, atom_group in enumerate(residue_group.atom_groups()):
        if not atom_group.altloc.strip():
          moving_group = atom_group
          moving_atoms = atom_group.atoms()
          continue
        if moving_group is None: break # blank group must be first?
    else:
      if move_CO_to_alt_locs:
        for atom_group_i, atom_group in enumerate(residue_group.atom_groups()):
          if atom_group.altloc.strip(): continue
          for atom in atom_group.atoms():
            if atom.name.strip() in partial1:
              moving_atoms.append(atom)
              moving_group = atom_group
      if move_NH_to_alt_locs:
        for atom_group_i, atom_group in enumerate(residue_group.atom_groups()):
          if atom_group.altloc.strip(): continue
          for atom in atom_group.atoms():
            if atom.name.strip() in partial2:
              moving_atoms.append(atom)
              moving_group = atom_group

    if moving_atoms:
      for atom in moving_atoms:
        for atom_group_i, atom_group in enumerate(residue_group.atom_groups()):
          if not atom_group.altloc.strip(): continue
          atom_group.append_atom(atom.detached_copy())
        moving_group.remove_atom(atom)
      if len(moving_group.atoms())==0:
        residue_group.remove_atom_group(moving_group)
  return hierarchy

def general_corrections(hierarchy):
  hierarchy = all_mainchain_alt_loc(hierarchy)
  hierarchy = adjust_hydrogen_alt_locs(hierarchy)
  return hierarchy

def get_alt_loc_type(residue_group, verbose=False):
  altloc_list = set()
  altloc_list_h = set()
  atom_names = []
  atom_names_h = []
  for atom in residue_group.atoms():
    if atom.name.strip() not in atom_names_h:
        atom_names_h.append(atom.name.strip())
    if atom.parent().altloc.strip():
      altloc_list_h.add(atom.name.strip())
    if atom.element.strip() in ["H", "D"]: continue
    if atom.name.strip() not in atom_names: atom_names.append(atom.name.strip())
    if atom.parent().altloc.strip():
      altloc_list.add(atom.name.strip())
  for atom_group in residue_group.atom_groups(): break
  if not altloc_list:
    return None
  if len(altloc_list)==len(atom_names): # this should be all atoms
    return "all"
  if altloc_list.intersection(mainchain)==mainchain:
    if altloc_list.difference(mainchain):
      print("mainchain only",mainchain)
      print('intersection',altloc_list.intersection(mainchain))
      print('difference',altloc_list.difference(mainchain))
    else:
      assert 0
  elif altloc_list.intersection(partial1)==partial1:
    return 'partial'
  elif altloc_list.intersection(partial2)==partial2:
    return 'partial'
  else:
    return "sidechain only"
  assert 0

def get_alt_locs(hierarchy, verbose=False):
  altlocs = {}
  for model in hierarchy.models():
    if verbose: print('model: "%s"' % model.id)
    for chain in model.chains():
      if verbose: print('chain: "%s"' % chain.id)
      altlocs.setdefault(chain.id, {})
      three = []
      for residue_group in chain.residue_groups():
        if verbose: print('  residue_group: resseq="%s" icode="%s"' % (
          residue_group.resseq, residue_group.icode))
        if len(residue_group.atom_groups())>1:
          altlocs[chain.id].setdefault((residue_group.resseq, residue_group.icode),
                                       len(residue_group.atom_groups()),
                                       )
  return altlocs

def generate_threes(hierarchy, verbose=False):
  altlocs = get_alt_locs(hierarchy)
  for model in hierarchy.models():
    if verbose: print('model: "%s"' % model.id)
    for chain in model.chains():
      if verbose: print('chain: "%s"' % chain.id)
      three = []
      for residue_group in hierarchy.residue_groups():
        if verbose: print('  residue_group: resseq="%s" icode="%s"' % (
          residue_group.resseq, residue_group.icode))
        if chain.id != residue_group.parent().id: break
        three.append(residue_group)
        if len(three)>3: del three[0]
        if len(three)<3: continue
        chain_dict = altlocs.get(chain.id, {})
        key = (three[1].resseq,
               three[1].icode,
               )
        is_altloc = chain_dict.get(key, None)
        if is_altloc not in [2, 3]: continue
        yield three

def get_distance(x, y):
  from math import sqrt
  d = 0
  for i in range(3):
    d += (x[i]-y[i])**2
  return sqrt(d)

def get_geometry_flags(three):
  rc = {}
  cbs = []
  for atom in three[1].atoms():
    if atom.name.strip()=="CB": cbs.append(atom)
  if len(cbs)==2:
    d = get_distance(cbs[0].xyz, cbs[1].xyz)
    rc["c_beta_dist"] = d
  else:
    rc["c_beta_dist"] = None
  return rc

def expand_altloc(hierarchy, verbose=False):
  for three in generate_threes(hierarchy):
    types = []
    for residue_group in three:
      types.append(get_alt_loc_type(residue_group))
    if types[1] in ["sidechain only"]: continue
    spread_altlocs = []
    for atom_group in three[1].atom_groups():
      spread_altlocs.append(atom_group.altloc)
    for j in range(0,3,2):
      if len(three[j].atom_groups())==1:
        clone = three[j].atom_groups()[0].detached_copy()
        three[j].append_atom_group(clone)
        for i, atom_group in enumerate(three[j].atom_groups()):
          atom_group.altloc = spread_altlocs[i]
  hierarchy.atoms().reset_serial()
  if verbose: hierarchy.show()
  return hierarchy

def get_altloc_data(hierarchy):
  rc = []
  for residue_group in hierarchy.residue_groups():
    rc.append([])
    for atom_group in residue_group.atom_groups():
      rc[-1].append(atom_group.altloc)
  return rc

def print_residue_group(residue_group):
  print('residue_group', residue_group.resseq)
  atom_names = []
  for atom_group in residue_group.atom_groups():
    print('  altloc "%s"' % atom_group.altloc)
    for i, atom in enumerate(atom_group.atoms()):
      print("    %2d %s" % (i, atom.format_atom_record()))
      if atom.name.strip() not in atom_names: atom_names.append(atom.name.strip())
  #print 'atoms',len(atom_names)
  #print 'end'

def display_model(hierarchy):
  for residue_group in hierarchy.residue_groups():
    print_residue_group(residue_group)

def atom_name_in_atom_group(atom_group, atom):
  for tmp in atom_group.atoms():
    if tmp.name.strip()==atom.name.strip(): return True
  return False

def merge_altloc_into_space(residue_group):
  space_atom_group = None
  for atom_group in residue_group.atom_groups():
    if not atom_group.altloc.strip():
      space_atom_group = atom_group
      continue
    assert space_atom_group
    assert space_atom_group.resname == atom_group.resname
    for atom in atom_group.atoms():
      if not atom_name_in_atom_group(space_atom_group, atom):
        tmp = atom.detached_copy()
        space_atom_group.append_atom(tmp)
      atom_group.remove_atom(atom)
    residue_group.remove_atom_group(atom_group)

def spread_to_c_alpha(residue_group,
                      spread_altlocs,
                      pre_peptide=True,
                      verbose=1,
  ):
  def _check_atom_groups_ok(residue_group, atoms):
    for atom_group in residue_group.atom_groups():
      if not atom_group.altloc.strip(): continue
      for atom in atom_group.atoms():
        if atom.name.strip() not in atoms: return False
    return True
  atoms = partial2
  if pre_peptide:
    atoms = partial1
  if not _check_atom_groups_ok(residue_group, atoms):
    print('not spreading to')
    assert 0
    return
  if len(residue_group.atom_groups())!=1:
    # merge
    merge_altloc_into_space(residue_group)
  assert len(residue_group.atom_groups())==1
  resname = residue_group.atom_groups()[0].resname
  spread_atoms = {}
  for sa in spread_altlocs:
    spread_atoms[sa] = []
    ag = iotbx.pdb.hierarchy.atom_group()
    ag.altloc = sa
    ag.resname = resname
    residue_group.append_atom_group(ag)
  if verbose:
    print('duplicating',atoms)
  for atom_group in residue_group.atom_groups():
    for atom in atom_group.atoms():
      if atom.name.strip() in atoms:
        for sa in spread_atoms:
          spread_atoms[sa].append(atom.detached_copy())
        atom_group.remove_atom(atom)
  for sa in sorted(spread_atoms):
    if not sa.strip(): continue
    for atom_group in residue_group.atom_groups():
      if atom_group.altloc==sa: break
    else: assert 0
    for new_atom in spread_atoms[sa]:
      if verbose: print('adding to "%s" <- %s' % (sa, atom.quote()))
      atom_group.append_atom(new_atom)

def spread_to_residue(residue_group):
  blank_atom_group = residue_group.atom_groups()[0]
  altlocs = []
  for atom_group in residue_group.atom_groups():
    if atom_group == blank_atom_group: continue
    altlocs.append(atom_group.altloc)
  for atom in blank_atom_group.atoms():
    for atom_group in residue_group.atom_groups():
      if atom_group == blank_atom_group: continue
      d_atom = atom.detached_copy()
      atom_group.append_atom(d_atom)
    blank_atom_group.remove_atom(atom)
  residue_group.remove_atom_group(blank_atom_group)

def correct_altloc(hierarchy, max_c_beta_deviation=0.2, verbose=False):
  for three in generate_threes(hierarchy):
    types = []
    for residue_group in three:
      types.append(get_alt_loc_type(residue_group))
    spread_altlocs = []
    for atom_group in three[1].atom_groups():
      spread_altlocs.append(atom_group.altloc)
    geometry_flags = get_geometry_flags(three)
    if types[:2] == [None, "all"]:
      spread_to_c_alpha(three[0], spread_altlocs)
    elif types[:2] == [None, "sidechain only"]:
      if geometry_flags["c_beta_dist"]>max_c_beta_deviation:
        spread_to_residue(three[1])
        spread_to_c_alpha(three[0], spread_altlocs)

    if types[1:] == ["all", None]:
      spread_to_c_alpha(three[2], spread_altlocs, pre_peptide=False)
    elif types[1:] == ["sidechain only", None]:
      if (geometry_flags["c_beta_dist"] and
          geometry_flags["c_beta_dist"] > max_c_beta_deviation):
        spread_to_c_alpha(three[2], spread_altlocs, pre_peptide=False)

  hierarchy.atoms().reset_serial()
  if verbose: hierarchy.show()
  return hierarchy

def block_alt_loc(hierarchy):
  for residue_group in hierarchy.residue_groups():
    moving_group = None
    if len(residue_group.atom_groups())==1: continue
    for atom_group in residue_group.atom_groups():
      if not atom_group.altloc.strip():
        moving_group = atom_group
        break
    if moving_group:
      for atom in moving_group.atoms():
        for atom_group_i, atom_group in enumerate(residue_group.atom_groups()):
          if not atom_group.altloc.strip(): continue
          atom_group.append_atom(atom.detached_copy())
        moving_group.remove_atom(atom)
      if len(moving_group.atoms())==0:
        residue_group.remove_atom_group(moving_group)

  hierarchy.atoms().reset_serial()
  return hierarchy

def correct_occupancies(hierarchy):
  for atom_group in hierarchy.atom_groups():
    if not atom_group.altloc.strip(): continue
    occ=None
    for atom in atom_group.atoms():
      if atom.occ!=1:
        occ = atom.occ
    for atom in atom_group.atoms():
      if atom.occ==1:
        if occ:
          atom.occ=occ
        else:
          atom.occ=.5

def run(rargs):
  argument_interpreter = libtbx.phil.command_line.argument_interpreter(
    master_phil=master_phil,
    home_scope="altloc_remediate")
  #
  phils = []
  phil_args = []
  pdbs = []
  for arg in args:
    if os.path.isfile(arg):
      if iotbx.pdb.is_pdb_file(arg):
        pdbs.append(arg)
        continue
      try :
        file_phil = phil.parse(file_name=arg)
      except RuntimeError :
        pass
      else :
        phils.append(file_phil)
    else :
      phil_args.append(arg)
      phils.append(argument_interpreter.process(arg))
  working_phil = master_phil.fetch(sources=phils)
  #working_phil.show()
  working_params = working_phil.extract()

  if not getattr(working_params, "altloc_remediate", False):
    raise Sorry('Must have a "altloc_remediate" scope in phil file')
  in_scope = working_params.altloc_remediate.input
  control = working_params.altloc_remediate.control
  output = working_params.altloc_remediate.output
  if control.block_alt_loc and control.correct_alt_loc:
    raise Sorry('''Block residue altlocs are not consider "correct".
  To block residues set control.correct_alt_loc=False''')
  #
  for i, pdb in enumerate(pdbs):
    if i==0 and not in_scope.pdb_file_name:
      in_scope.pdb_file_name = pdbs[i]
  #
  if in_scope.pdb_file_name is None:
    raise Sorry("Must supply a protein PDB file")
  #
  if not output.file_name:
    output.file_name = in_scope.pdb_file_name
    d = os.path.dirname(output.file_name)
    output.file_name = os.path.basename(output.file_name)
    output.file_name = output.file_name.split(".")[0]
    if control.spread_alt_loc:
      output.file_name += "_spread"
    if control.correct_alt_loc:
      output.file_name += "_correct"
    if control.block_alt_loc:
      output.file_name += "_block"
    output.file_name += ".pdb"
    output.file_name = os.path.join(d, output.file_name)
  #
  preamble = output.file_name.split(".")[0]
  print("\n  Writing effective parameters to %s.eff\n" % preamble)
  print("#phil __ON__")
  working_phil.format(python_object=working_params).show()
  print("#phil __OFF__\n")
  f=open("%s.eff" % preamble, "w")
  f.write(working_phil.format(python_object=working_params).as_str())
  f.close()

  pdb_inp = iotbx.pdb.input(in_scope.pdb_file_name)
  hierarchy = pdb_inp.construct_hierarchy()
  #hierarchy.show()
  if output.display:
    display_model(hierarchy)
    return
  hierarchy = general_corrections(hierarchy)

  if control.spread_alt_loc:
    hierarchy = expand_altloc(hierarchy)

  if control.correct_alt_loc:
    hierarchy = correct_altloc(hierarchy)

  if control.block_alt_loc:
    hierarchy = block_alt_loc(hierarchy)

  correct_occupancies(hierarchy)

  print("  Writing output to %s" % output.file_name)
  f=open(output.file_name, "w")
  f.write(hierarchy.as_pdb_string(
    crystal_symmetry=pdb_inp.crystal_symmetry()),
          )
  f.close()

if __name__=="__main__":
  args = sys.argv[1:]
  del sys.argv[1:]
  run(args)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/angle.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.angle

import sys, os
import iotbx.pdb
from libtbx.utils import Sorry
from scitbx.linalg import eigensystem
import math
import scitbx.math
from scitbx import matrix
from six.moves import zip

legend = """phenix.angle:
  Given PDB file and two atom selections that allow to define two lines compute
  the angle between these two lines. If atom selection defines two points then
  the line is defined uniquely and passes through these points. If atom
  selection defines more than two points then line coincides with the longest
  axis of the cloud of points.

How to run:
  phenix.angle model.pdb "chain A and (resseq 1 and name CA or resseq 2 and name CA)" \
    "chain B and (resseq 1 and name CA or resseq 2 and name CA)"
  phenix.angle model.pdb "chain A" "chain B"

Feedback:
  PAfonine@lbl.gov
  phenixbb@phenix-online.org"""

def process_args(args):
  pdb_file_name, line_selections = None,[]
  if(len(args) != 3):
    raise Sorry(
      "Three arguments expected: PDB file, two atom selections to define axes.")
  for arg in args:
    if(os.path.isfile(arg) and iotbx.pdb.is_pdb_file(file_name=arg)):
      pdb_file_name = arg
    else:
      line_selections.append(arg)
  if(pdb_file_name is None):
    raise Sorry("PDB file must be provided.")
  ph = iotbx.pdb.input(file_name = pdb_file_name).construct_hierarchy()
  asc = ph.atom_selection_cache()
  # If it is protein: leave only backbone
  if(len(list(ph.chains()))==1):
    chain = list(ph.chains())[0]
    if(chain.is_protein()):
      sel = asc.selection(
        string = "pepnames and (name ca or name n or name c or name o)")
      ph = ph.select(sel)
      asc = ph.atom_selection_cache()
  #
  if(len(line_selections) != 2):
    raise Sorry("Two atom selections to define two axes must be provided.")
  try:
    sel1 = asc.selection(string=line_selections[0])
  except Exception:
    raise Sorry("Invalid atom selection: %s"%line_selections[0])
  try:
    sel2 = asc.selection(string=line_selections[1])
  except Exception:
    raise Sorry("Invalid atom selection: %s"%line_selections[1])
  for sel, ls in zip([sel1, sel2], line_selections):
    if(sel.count(True)<2):
      raise Sorry(
        "Atom selection '%s' selects less than two points."%ls)
  return ph, asc, sel1, sel2

def vector_from_two_points(s1, s2):
  a = [s2[0]-s1[0], s2[1]-s1[1], s2[2]-s1[2]]
  norm = math.sqrt(a[0]**2 + a[1]**2 + a[2]**2)
  if(abs(norm)<1.e-9):
    raise Sorry("Two points defining axis coincide.")
  return matrix.col((a[0]/norm, a[1]/norm, a[2]/norm))

def get_axis_from_xrs(xrs):
  if xrs.scatterers().size() > 2:
    sites_cart_moving = xrs.sites_cart()-xrs.center_of_mass()
    es = scitbx.math.principal_axes_of_inertia(points=sites_cart_moving).eigensystem()
    vecs = es.vectors()
    axis = vecs[6], vecs[7], vecs[8]
    return matrix.col((axis[0], axis[1], axis[2]))
  elif xrs.scatterers().size() == 2:
    sites_cart = xrs.sites_cart()
    assert sites_cart.size() == 2
    s1,s2 = sites_cart[0], sites_cart[1]
    return vector_from_two_points(s1, s2)
  return None

def calculate_axes_and_angle(xrs1, xrs2):
  a1 = get_axis_from_xrs(xrs1)
  a2 = get_axis_from_xrs(xrs2)
  angle = a1.angle(a2)*180./math.pi
  return a1, a2, angle

def calculate_axes_and_angle_directional(xrs1, xrs2):
  """ The same as above, but check the direction of vectors assuming that
  atoms in xrs1 and xrs2 are ordered from N to C terminus. This will enable
  the function to produce angles > 90 degrees.
  Uses rough estimate of direction of xrs using the first and the last atom
  and inverting vectors a1 and a2 when necessary.
  Used in iotbx.pdb.secondary_structure:concatenate_consecutive_helices()"""
  a1 = get_axis_from_xrs(xrs1)
  a2 = get_axis_from_xrs(xrs2)
  v1 = vector_from_two_points(xrs1.sites_cart()[0], xrs1.sites_cart()[-1])
  v2 = vector_from_two_points(xrs2.sites_cart()[0], xrs2.sites_cart()[-1])
  if a1.angle(v1)*180./math.pi > 90:
    a1 = -a1
  if a2.angle(v2)*180./math.pi > 90:
    a2 = -a2
  angle = a1.angle(a2)*180./math.pi
  return a1, a2, angle

def run(args, log=sys.stdout):
  if(len(args)==0 or (len(args)==1 and
     ("-h" in args or "--h" in args or "-help" in args or "--help" in args))):
    print("-"*79, file=log)
    print(legend, file=log)
    print("-"*79, file=log)
    sys.exit(0)
  ph, asc, sel1, sel2 = process_args(args=args)
  sel12 = sel1 | sel2
  xrs = ph.extract_xray_structure()
  #
  xrs  = xrs.select(sel12)
  sel1 = sel1.select(sel12)
  sel2 = sel2.select(sel12)
  xrs  = xrs.orthorhombic_unit_cell_around_centered_scatterers(buffer_size = 3)
  #
  a1, a2, angle = calculate_axes_and_angle(xrs.select(sel1), xrs.select(sel2))
  print("Axis 1: %6.4f %6.4f %6.4f"%(a1[0], a1[1], a1[2]), file=log)
  print("Axis 2: %6.4f %6.4f %6.4f"%(a2[0], a2[1], a2[2]), file=log)
  print("Angle : %6.4f" % angle, file=log)

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/apply_ncs_to_ligand.py

from __future__ import absolute_import, division, print_function
from libtbx.str_utils import make_header
import sys

master_phil_str = """
ligand_code = LIG
  .type = str
atom_selection = None
  .type = atom_selection
add_to_model = True
  .type = bool
output_file = None
  .type = path
output_map = None
  .type = path
%s
"""

def run(args, out=sys.stdout):
  from mmtbx.command_line import load_model_and_data
  import mmtbx.ncs.ligands
  cmdline = load_model_and_data(
    args=args,
    master_phil=master_phil_str % mmtbx.ncs.ligands.ncs_ligand_phil,
    out=out,
    process_pdb_file=True,
    generate_input_phil=True,
    usage_string="""\
mmtbx.apply_ncs_to_ligand model.pdb data.mtz ligand_code=LIG ...

Given a multi-chain PDB file and a ligand residue name, find copies of the
ligand in the input file, identify NCS operators relating macromolecule chains,
and search for additional ligand sites by applying these operators.  Used to
complete ligand placement in cases where LigandFit (etc.) is only partially
successful.
""")
  pdb_hierarchy = cmdline.pdb_hierarchy
  fmodel = cmdline.fmodel
  params = cmdline.params
  if (params.output_file is None):
    params.output_file = "ncs_ligands.pdb"
  if (params.output_map is None):
    params.output_map = "ncs_ligands.mtz"
  make_header("Finding ligands by NCS operators", out=out)
  result = mmtbx.ncs.ligands.apply_ligand_ncs(
    pdb_hierarchy=pdb_hierarchy,
    fmodel=fmodel,
    params=params,
    ligand_code=params.ligand_code,
    atom_selection=None,
    add_new_ligands_to_pdb=params.add_to_model,
    log=out)
  result.write_pdb(params.output_file)
  result.write_maps(params.output_map)
  return result

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/arginine_geometry.py
from __future__ import absolute_import, division, print_function

from iotbx.cli_parser import run_program
from mmtbx.programs.arginine_geometry import Program

if (__name__ == '__main__'):
  results = run_program(program_class=Program)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/barbed_wire_analysis.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.barbed_wire_analysis
# LIBTBX_SET_DISPATCHER_NAME molprobity.barbed_wire_analysis

from iotbx.cli_parser import run_program
from mmtbx.programs import barbed_wire_analysis

if __name__ == "__main__":
  run_program(barbed_wire_analysis.Program)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/cablam.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.cablam
# LIBTBX_SET_DISPATCHER_NAME molprobity.cablam
# LIBTBX_PRE_DISPATCHER_INCLUDE_SH export PHENIX_GUI_ENVIRONMENT=1

import sys

from iotbx.cli_parser import CCTBXParser
from libtbx.utils import multi_out, show_total_time
from mmtbx.programs import cablam
from iotbx.cli_parser import run_program

#=============================================================================
def old_run(args):

  # create parser
  logger = multi_out()
  logger.register('stderr', sys.stderr)
  logger2 = multi_out()
  logger2.register('stdout', sys.stdout)

  parser = CCTBXParser(
    program_class=cablam.Program,
    logger=logger)
  namespace = parser.parse_args(sys.argv[1:])

  # start program
  print('Starting job', file=logger)
  print('='*79, file=logger)
  task = cablam.Program(
    parser.data_manager, parser.working_phil.extract(), logger=logger2)

  # validate inputs
  task.validate()

  # run program
  task.run()

  # stop timer
  print('', file=logger)
  print('='*79, file=logger)
  print('Job complete', file=logger)
  show_total_time(out=logger)

# =============================================================================
if __name__ == '__main__':
  #run(sys.argv[1:])
  run_program(program_class=cablam.Program, hide_parsing_output=True)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/cablam_idealization.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.cablam_idealization

from iotbx.cli_parser import run_program
from mmtbx.programs import cablam_idealization

if __name__ == "__main__":
  run_program(cablam_idealization.Program)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/cbetadev.py
from __future__ import division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.cbetadev
# LIBTBX_SET_DISPATCHER_NAME molprobity.cbetadev
# LIBTBX_PRE_DISPATCHER_INCLUDE_SH export PHENIX_GUI_ENVIRONMENT=1

import sys

from iotbx.cli_parser import CCTBXParser
from libtbx.utils import multi_out, show_total_time
from mmtbx.programs import cbetadev
from iotbx.cli_parser import run_program

#=============================================================================
def old_run(args):

  # create parser
  logger = multi_out()
  logger.register('stderr', sys.stderr)
  logger2 = multi_out()
  logger2.register('stdout', sys.stdout)

  parser = CCTBXParser(
    program_class=cbetadev.Program,
    logger=logger)
  namespace = parser.parse_args(sys.argv[1:])

  # start program
  print('Starting job', file=logger)
  print('='*79, file=logger)
  task = cbetadev.Program(
    parser.data_manager, parser.working_phil.extract(), logger=logger2)

  # validate inputs
  task.validate()

  # run program
  task.run()

  # stop timer
  print('', file=logger)
  print('='*79, file=logger)
  print('Job complete', file=logger)
  show_total_time(out=logger)

# =============================================================================
if __name__ == '__main__':
  #run(sys.argv[1:])
  run_program(program_class=cbetadev.Program, hide_parsing_output=True)



 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/cc_star.py
# LIBTBX_SET_DISPATCHER_NAME phenix.cc_star

from __future__ import absolute_import, division, print_function
from libtbx.str_utils import make_sub_header, format_value
from libtbx.utils import Sorry, Usage
from libtbx import runtime_utils
import libtbx.phil
import sys

master_phil = libtbx.phil.parse("""
data = None
  .type = path
  .help = Data file (usually MTZ) containing R-free flags and either the \
    pre-calculated F(model) array or experimental amplitudes or intensities.
  .style = file_type:hkl input_file bold process_hkl child:ampl:f_obs_labels \
           child:rfree:r_free_flags.label child:fmodel:f_model_labels \
           force_data
f_obs_labels = None
  .type = str
  .help = Column labels for experimental data array
  .short_caption = F(obs) labels
  .input_size = 150
  .style = bold renderer:draw_fobs_label_widget
f_model_labels = None
  .type = str
  .short_caption = F(model) labels
  .style = renderer:draw_fmodel_label_widget
  .input_size = 150
r_free_flags.label = None
  .type = str
  .help = Column label for R-free flags
  .short_caption = Free R label
  .style = bold renderer:draw_rfree_label_widget
  .input_size = 150
r_free_flags.test_flag_value = None
  .type = int
  .help = Test flag value.  Not normally required.
model = None
  .type = path
  .help = Model file, required if F(model) is not pre-calculated.
  .style = file_type:pdb input_file
unmerged_data = None
  .type = path
  .help = File containing scaled, unmerged intensities
  .style = bold file_type:hkl OnChange:extract_unmerged_intensities input_file
unmerged_labels = None
  .type = str
  .help = Labels for unmerged intensity array
  .style = bold renderer:draw_unmerged_intensities_widget
  .input_size = 150
n_bins = 20
  .type = int(value_min=5, value_max=50)
  .help = Number of resolution bins
  .input_size = 64
  .style = spinner
include scope iotbx.merging_statistics.sigma_filtering_phil_str
include scope libtbx.phil.interface.tracking_params
loggraph = False
  .type = bool
""", process_includes=True)
master_params = master_phil # for phenix GUI

def run(args=None, params=None, out=sys.stdout):
  assert [args, params].count(None) == 1
  if args is not None:
    if (len(args) == 0) or ("--help" in args):
      raise Usage("""
  phenix.cc_star model.pdb data.mtz unmerged_data=data.hkl [n_bins=X] [options]
  phenix.cc_star model_refine_001.mtz unmerged_data=data.hkl [...]

Implementation of the method for assessing data and model quality described in:
  Karplus PA & Diederichs K (2012) Science 336:1030-3.

Full parameters:
  %s
  """ % master_phil.as_str(prefix=" ", attributes_level=1))
    import iotbx.phil
    cmdline = iotbx.phil.process_command_line_with_files(
      args=args,
      master_phil=master_phil,
      pdb_file_def="model",
      reflection_file_def="data")
    params = cmdline.work.extract()
  import mmtbx.command_line
  import mmtbx.validation.experimental
  from iotbx import merging_statistics
  from iotbx import file_reader
  import iotbx.pdb
  if (params.data is None):
    raise Sorry("Please specify a data file (usually MTZ format).")
  if (params.unmerged_data is None):
    raise Sorry("Please specify unmerged_data file")
  hkl_in = file_reader.any_file(params.data, force_type="hkl")
  hkl_in.check_file_type("hkl")
  f_model = f_obs = r_free_flags = None
  f_models = []
  data_arrays = []
  f_model_labels = []
  if (params.f_model_labels is None):
    for array in hkl_in.file_server.miller_arrays :
      labels = array.info().label_string()
      if (array.is_complex_array()):
        if (labels.startswith("F-model") or labels.startswith("FMODEL")):
          f_models.append(array)
          f_model_labels.append(labels)
    if (len(f_models) > 1):
      raise Sorry(("Multiple F(model) arrays found:\n%s\nPlease specify the "+
        "'labels' parameter.") % "\n".join(f_model_labels))
    elif (len(f_models) == 1):
      f_model = f_models[0]
      if (f_model.anomalous_flag()):
        info = f_model.info()
        f_model = f_model.average_bijvoet_mates().set_info(info)
      print("F(model):", file=out)
      f_model.show_summary(f=out, prefix="  ")
    else :
      data_array = hkl_in.file_server.get_xray_data(
        file_name=params.data,
        labels=params.f_obs_labels,
        ignore_all_zeros=True,
        parameter_scope="")
      if (data_array.is_xray_intensity_array()):
        from cctbx import french_wilson
        f_obs = french_wilson.french_wilson_scale(
          miller_array=data_array,
          out=out)
      else :
        f_obs = data_array
  else :
    for array in hkl_in.file_server.miller_arrays :
      array_labels = array.info().label_string()
      if (array_labels == params.f_model_labels):
        if (array.is_complex_array()):
          f_model = array
          break
        else :
          raise Sorry("The data in %s are not of the required type." %
            array_labels)
  if (f_model is not None):
    assert (f_obs is None)
    for array in hkl_in.file_server.miller_arrays :
      labels = array.info().label_string()
      if (labels == params.f_obs_labels):
        f_obs = array
        break
    else :
      try :
        f_obs = hkl_in.file_server.get_amplitudes(
          file_name=params.f_obs_labels,
          labels=None,
          convert_to_amplitudes_if_necessary=False,
          parameter_name="f_obs_labels",
          parameter_scope="",
          strict=True)
      except Sorry :
        raise Sorry("You must supply a file containing both F-obs and F-model "+
          "if you want to use a pre-calculated F-model array.")
  assert (f_obs.is_xray_amplitude_array())
  if (f_obs.anomalous_flag()):
    info = f_obs.info()
    f_obs = f_obs.average_bijvoet_mates().set_info(info)
  print("F(obs):", file=out)
  f_obs.show_summary(f=out, prefix="  ")
  print("", file=out)
  r_free_flags, test_flag_value = hkl_in.file_server.get_r_free_flags(
    file_name=params.data,
    label=params.r_free_flags.label,
    test_flag_value=params.r_free_flags.test_flag_value,
    disable_suitability_test=False,
    parameter_scope="")
  info = r_free_flags.info()
  r_free_flags = r_free_flags.customized_copy(
    data=r_free_flags.data()==test_flag_value).set_info(info)
  if (r_free_flags.anomalous_flag()):
    r_free_flags = r_free_flags.average_bijvoet_mates().set_info(info)
  print("R-free flags:", file=out)
  r_free_flags.show_summary(f=out, prefix="  ")
  print("", file=out)
  unmerged_i_obs = mmtbx.command_line.load_and_validate_unmerged_data(
    f_obs=f_obs,
    file_name=params.unmerged_data,
    data_labels=params.unmerged_labels,
    log=out)
  print("Unmerged intensities:", file=out)
  unmerged_i_obs.show_summary(f=out, prefix="  ")
  print("", file=out)
  if (f_model is None):
    assert (f_obs is not None)
    if (params.model is None):
      raise Sorry("A PDB file is required if F(model) is not pre-calculated.")
    make_sub_header("Calculating F(model)", out=out)
    pdb_in = iotbx.pdb.input(params.model)
    pdb_symm = pdb_in.crystal_symmetry()
    if (pdb_symm is None):
      pdb_symm = f_obs
    else :
      if (f_obs.crystal_symmetry() is None):
        f_obs = f_obs.customized_copy(crystal_symmetry=pdb_symm)
      elif (not pdb_symm.is_similar_symmetry(f_obs)):
        mmtbx.command_line.show_symmetry_error(
          file1="PDB file",
          file2="data file",
          symm1=pdb_symm,
          symm2=f_obs)
    xray_structure = pdb_in.xray_structure_simple(
      crystal_symmetry=pdb_symm)
    from mmtbx.utils import fmodel_simple
    # XXX this gets done anyway later, but they need to be consistent before
    # creating the fmodel manager
    if (f_obs.anomalous_flag()):
      f_obs = f_obs.average_bijvoet_mates()
    f_obs = f_obs.eliminate_sys_absent()
    f_obs, r_free_flags = f_obs.map_to_asu().common_sets(
      other=r_free_flags.map_to_asu())
    fmodel = fmodel_simple(
      f_obs=f_obs,
      r_free_flags=r_free_flags,
      xray_structures=[xray_structure],
      skip_twin_detection=True,
      scattering_table="n_gaussian")
    fmodel.show(log=out)
    f_model = fmodel.f_model()
    f_obs        = fmodel.f_obs()
    r_free_flags = fmodel.r_free_flags()
  else :
    if (f_model.anomalous_flag()):
      f_model = f_model.average_bijvoet_mates()

  stats = mmtbx.validation.experimental.merging_and_model_statistics(
    f_model         = f_model,
    f_obs           = f_obs,
    r_free_flags    = r_free_flags,
    unmerged_i_obs  = unmerged_i_obs,
    n_bins          = params.n_bins,
    sigma_filtering = params.sigma_filtering)
  stats.show_cc_star(out=out)
  if (params.loggraph):
    stats.show_loggraph(out=out)
  print("", file=out)
  print("Reference:", file=out)
  print("  Karplus PA & Diederichs K (2012) Science 336:1030-3.", file=out)
  print("", file=out)
  return stats

def validate_params(params):
  if (params.data is None) or (params.f_obs_labels is None):
    raise Sorry("No experimental data supplied!")
  if (params.f_model_labels is None) and (params.model is None):
    raise Sorry("You must supply either a pre-calculated F(model) array, "+
      "or the current refined model.")
  return True

class launcher(runtime_utils.target_with_save_result):
  def run(self):
    return run(args=list(self.args), out=sys.stdout)

def finish_job(result):
  stats = []
  if (result is not None):
    stats = [
      ("High resolution", format_value("%.3g", result.overall.d_min)),
      ("Redundancy", format_value("%.1f", result.overall.mean_redundancy)),
      ("<I/sigma>", format_value("%.2g", result.overall.i_over_sigma_mean)),
      ("<I/sigma> (high-res)", format_value("%.2g",
        result.bins[-1].i_over_sigma_mean)),
      ("Completeness", format_value("%.1f%%", result.overall.completeness*100)),
      ("Completeness (high-res)", format_value("%.1f%%",
        result.bins[-1].completeness*100)),
      ("CC*", format_value("%.3f", result.overall.cc_star)),
      ("CC* (high-res)", format_value("%.3f", result.bins[-1].cc_star)),
      ("CC(work)", format_value("%.3f", result.overall.cc_work)),
      ("CC(work) (high-res)", format_value("%.3f", result.bins[-1].cc_work)),
      ("CC(free)", format_value("%.3f", result.overall.cc_free)),
      ("CC(free) (high-res)", format_value("%.3f", result.bins[-1].cc_free)),
    ]
  return ([], stats)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/chiral_validation.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.chiral_validation
# LIBTBX_SET_DISPATCHER_NAME molprobity.chiral_validation
# LIBTBX_PRE_DISPATCHER_INCLUDE_SH export PHENIX_GUI_ENVIRONMENT=1

import sys

from iotbx.cli_parser import CCTBXParser
from libtbx.utils import multi_out, show_total_time
from mmtbx.programs import chiral_validation
from iotbx.cli_parser import run_program

# =============================================================================
def old_run(args):

  # create parser
  logger = multi_out()
  logger.register('stderr', sys.stderr)
  logger2 = multi_out()
  logger2.register('stdout', sys.stdout)

  parser = CCTBXParser(
    program_class=chiral_validation.Program,
    logger=logger)
  namespace = parser.parse_args(sys.argv[1:])

  # start program
  print('Starting job', file=logger)
  print('='*79, file=logger)
  task = chiral_validation.Program(
    parser.data_manager, parser.working_phil.extract(), logger=logger2)

  # validate inputs
  task.validate()

  # run program
  task.run()

  # stop timer
  print('', file=logger)
  print('='*79, file=logger)
  print('Job complete', file=logger)
  show_total_time(out=logger)

# =============================================================================
if __name__ == '__main__':
  #run(sys.argv[1:])
  run_program(program_class=chiral_validation.Program, hide_parsing_output=True)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/cif_as_mtz.py
# LIBTBX_SET_DISPATCHER_NAME phenix.cif_as_mtz
# LIBTBX_SET_DISPATCHER_NAME iotbx.cif_as_mtz

from __future__ import absolute_import, division, print_function
from iotbx.option_parser import iotbx_option_parser
from iotbx import crystal_symmetry_from_any
import iotbx.phil
import iotbx.mtz
import iotbx.pdb
from iotbx import cif_mtz_data_labels
from cctbx.array_family import flex
from cctbx import crystal
from libtbx import runtime_utils
from libtbx.utils import Sorry
import libtbx.callbacks # import dependency
import string
import re
import os
import sys
import six

"""
Notes on CIF (source: http://www.ccp4.ac.uk/html/mtz2various.html)
All reflections in the MTZ input file will be output to the CIF file. However,
there are ways to flag certain reflections with the data type _refln.status.
Observed reflections will be flagged with 'o'. Unobserved reflections, i.e.
those flagged as missing in the relevant amplitude or intensity column, will be
flagged as 'x'; these reflections will not be added to _reflns.number_obs. The
'free' reflections will be flagged as 'f'. The keyword FREEVAL can be used to
indicate this set. Systematically absent reflections are flagged with '-'.

If the RESO keyword is specified then reflections at higher or lower resolution
than the limits given, will be written with _refln.status 'h' or 'l'
respectively. The limits will be written to the CIF as the values of
_refine.ls_d_res_high and _refine.ls_d_res_low.

If EXCLUDE SIG is given then reflections for which F < <value>*sigma(F), and
which satisfy the resolution limits (if given), will be written with
_refln.status '<'. The value of _reflns.number_obs excludes all reflections
which do not satisfy the condition on sigma(F). All other sub-keywords of
EXCLUDE are ignored for CIF output.
NB: The translation of the RESOLUTION and EXCLUDE SIGP conditions to
_refln.status values does not imply that the the use of these conditions is
good crystallographic practice. Be prepared to justify why you have excluded
any data from your final refinement!
"""

def run(args, command_name = "phenix.cif_as_mtz", out=sys.stdout,
       return_as_miller_arrays=False):
  if (len(args) == 0): args = ["--help"]
  try:
    command_line = (iotbx_option_parser(
      usage="%s [reflection_cif_file] [options]" % command_name,
      description='Example: %s r1o9ksf.ent --symmetry=pdb1o9k.ent'%command_name)
      .enable_symmetry_comprehensive()
      .option(None, "--output_file_name",
        action="store",
        default=False,
        type="string",
        help="Output mtz file name.")
      .option(None, "--wavelength_id",
        action="store",
        default=None,
        type="int",
        help="Extract data set with given wavelength_id.")
      .option(None, "--crystal_id",
        action="store",
        default=None,
        type="int",
        help="Extract data set with given crystal_id.")
      .option(None, "--output_r_free_label",
        action="store",
        default="R-free-flags",
        type="string",
        help="MTZ column label to use for R-free flags (default: R-free-flags)")
      .option(None, "--merge",
        action="store_true",
        help="Merge non-unique data where present.")
      .option(None, "--incompatible_flags_to_work_set",
        action="store_true",
        help="When merging place reflections with incompatible flags into the "
             "working set.")
      .option(None, "--remove_systematic_absences",
        action="store_true",
        help="Remove systematic absent reflections.")
      .option(None, "--map_to_asu",
        action="store_true",
        help="Map to asymmetric unit.")
      .option("--show_details_if_error",
          action="store_true",
          help="Show data details for some errors.")
      .option("--show_log",
          action="store_true",
          help="Show some output.")
      .option("--ignore_bad_sigmas",
          action="store_true",
          help="Set sigmas to None instead of raising an error when bad sigmas "
               "are present.")
      .option("--extend_flags",
          action="store_true",
          help="Extend R-free flags to cover all reflections if necessary.")

    ).process(args=args)
  except Exception as e:
    if(str(e) != "0"): print(str(e))
    sys.exit(0)
  crystal_symmetry = command_line.symmetry
  if(len(command_line.args) > 1):
    print("%d arguments are given from the command line:"% \
      len(command_line.args), command_line.args, file=out)
    raise Sorry("Please specify one reflection cif file.")
  file_name = command_line.args[0]
  if(not os.path.isfile(file_name)):
    raise Sorry("File is not found: %s"%file_name)
  output_r_free_label = command_line.options.output_r_free_label
  if ((not output_r_free_label[0] in string.ascii_uppercase) or
      (re.search(r"[^a-zA-Z0-9_\-]", output_r_free_label))):
    raise Sorry(("%s is not a suitable column label.  MTZ format requires "+
      "an uppercase letter as the first character, and only alphanumeric "+
      "characters or hyphens in the rest of the string.")% output_r_free_label)
  result=process_files(
    file_name=file_name,
    crystal_symmetry=crystal_symmetry,
    output_file_name=command_line.options.output_file_name,
    wavelength_id=command_line.options.wavelength_id,
    crystal_id=command_line.options.crystal_id,
    show_details_if_error=command_line.options.show_details_if_error,
    output_r_free_label=command_line.options.output_r_free_label,
    merge_non_unique_under_symmetry=command_line.options.merge,
    map_to_asu=command_line.options.map_to_asu,
    remove_systematic_absences=command_line.options.remove_systematic_absences,
    incompatible_flags_to_work_set=command_line.options.incompatible_flags_to_work_set,
    return_as_miller_arrays=return_as_miller_arrays,
    ignore_bad_sigmas=command_line.options.ignore_bad_sigmas,
    extend_flags=command_line.options.extend_flags,
    log=out)
  if return_as_miller_arrays:
    return result

def process_files(file_name,
                   crystal_symmetry,
                   output_file_name,
                   wavelength_id,
                   crystal_id,
                   show_details_if_error,
                   output_r_free_label,
                   merge_non_unique_under_symmetry=False,
                   map_to_asu=False,
                   remove_systematic_absences=False,
                   incompatible_flags_to_work_set=False,
                   ignore_bad_sigmas=False,
                   return_as_miller_arrays=False,
                   extend_flags=False,
                   log=sys.stdout):
  mtz_object = extract(
    file_name                       = file_name,
    crystal_symmetry                = crystal_symmetry,
    wavelength_id                   = wavelength_id,
    crystal_id                      = crystal_id,
    show_details_if_error           = show_details_if_error,
    output_r_free_label             = output_r_free_label,
    merge_non_unique_under_symmetry = merge_non_unique_under_symmetry,
    map_to_asu                      = map_to_asu,
    remove_systematic_absences      = remove_systematic_absences,
    incompatible_flags_to_work_set  = incompatible_flags_to_work_set,
    ignore_bad_sigmas               = ignore_bad_sigmas,
    return_as_miller_arrays         = return_as_miller_arrays,
    extend_flags                    = extend_flags,
    log                             = log)

  if return_as_miller_arrays:
    return mtz_object

  if(mtz_object is not None):
    if not output_file_name :
      basename = os.path.basename(file_name)
      if(basename[-4:-3] == "."): output_file_name = basename[:-4]+".mtz"
      elif(basename[-5:-4] == "."): output_file_name = basename[:-5]+".mtz"
      elif(basename.endswith(".ent.gz")): output_file_name=basename[:-7]+".mtz"
      else: output_file_name = basename+".mtz"
    mtz_object.write(file_name = output_file_name)
    return mtz_object.n_reflections()

def get_label(miller_array, output_r_free_label):
  label = None
  for l in miller_array.info().labels:
    if miller_array.anomalous_flag():
      if miller_array.is_xray_amplitude_array():
        label = "F"
      elif miller_array.is_xray_intensity_array():
        label = "I"
      break
    elif ('_meas' in l):
      if miller_array.is_xray_amplitude_array():
        label = "FOBS"
      elif miller_array.is_xray_intensity_array():
        label = "IOBS"
      elif l.endswith(".phase_meas"):
        label = "PHIM"
      break
    elif ("_calc" in l):
      if miller_array.is_xray_amplitude_array():
        label = "FC"
      elif miller_array.is_xray_intensity_array():
        label = "ICALC"
      elif ".F_calc" in l: # cope with _refln.F_calc_au  and _refln.F_calc labels
        label = "FC"
      elif l.endswith(".phase_calc"):
        label = "PHIC"
      break
    elif 'status' in l or '_free' in l:
      label = output_r_free_label
      break
    elif miller_array.is_hendrickson_lattman_array():
      label = "HL"
      break
    elif (miller_array.is_complex_array()):
      if "DELFWT" in l:
        label = "DELFWT"
        break
      elif "FWT" in l:
        label = "FWT"
        break
    elif (miller_array.is_real_array()):
      if (l.endswith( "pdbx_anom_difference")):
        label = "DANO"
        break
      elif (l.endswith(".fom")):
        label = "FOM"
        break
    # as a last resort try find a match in cif_mtz_data_labels dictionary
    label = cif_mtz_data_labels.ccp4_label_from_cif(l)
    if label:
      return label
  return label

def extract(file_name,
            crystal_symmetry,
            wavelength_id,
            crystal_id,
            show_details_if_error,
            output_r_free_label,
            merge_non_unique_under_symmetry,
            map_to_asu,
            remove_systematic_absences,
            all_miller_arrays=None,
            incompatible_flags_to_work_set=False,
            ignore_bad_sigmas=False,
            extend_flags=False,
            return_as_miller_arrays=False,
            log=sys.stdout):
  import iotbx.cif
  from cctbx import miller
  if all_miller_arrays is None:
    base_array_info = miller.array_info(
      crystal_symmetry_from_file=crystal_symmetry)
    all_miller_arrays = iotbx.cif.reader(file_path=file_name).build_miller_arrays(
      base_array_info=base_array_info)
  if (len(all_miller_arrays) == 0):
    raise Sorry("No data arrays were found in this CIF file.  Please make "+
      "sure that the file contains reflection data, rather than the refined "+
      "model.")
  column_labels = set()
  if (extend_flags):
    map_to_asu = True
  # TODO: is all_mille_arrays a dict ? If not change back
  for (data_name, miller_arrays) in six.iteritems(all_miller_arrays):
    for ma in miller_arrays.values():
      other_symmetry = crystal_symmetry
      try:
        crystal_symmetry = other_symmetry.join_symmetry(
          other_symmetry=ma.crystal_symmetry(),
          force=True)
      except AssertionError as e:
        str_e = str(e)
        from six.moves import cStringIO as StringIO
        s = StringIO()
        if "Space group is incompatible with unit cell parameters." in str_e:
          other_symmetry.show_summary(f=s)
          ma.crystal_symmetry().show_summary(f=s)
          str_e += "\n%s" %(s.getvalue())
          raise Sorry(str_e)
        else:
          raise
  if(crystal_symmetry.unit_cell() is None or
     crystal_symmetry.space_group_info() is None):
    raise Sorry(
      "Crystal symmetry is not defined. Please use the --symmetry option.")
  mtz_object = iotbx.mtz.object() \
    .set_title(title="phenix.cif_as_mtz") \
    .set_space_group_info(space_group_info=crystal_symmetry.space_group_info())
  unit_cell=crystal_symmetry.unit_cell()
  mtz_crystals = {}
  mtz_object.set_hkl_base(unit_cell=unit_cell)
  from iotbx.reflection_file_utils import cif_status_flags_as_int_r_free_flags
  # generate list of all reflections (for checking R-free flags)
  from iotbx.reflection_file_utils import make_joined_set
  all_arrays = []
  for (data_name, miller_arrays) in six.iteritems(all_miller_arrays):
    for ma in miller_arrays.values():
      all_arrays.append(ma)
  complete_set = make_joined_set(all_arrays)
  if return_as_miller_arrays:
    miller_array_list=[]
  current_i = -1
  uc = None
  for i, (data_name, miller_arrays) in enumerate(six.iteritems(all_miller_arrays)):
    for ma in miller_arrays.values():
      #ma = ma.customized_copy(
      #  crystal_symmetry=crystal_symmetry).set_info(ma.info())
      if ma._space_group_info is None:
        ma._space_group_info = crystal_symmetry.space_group_info()
      labels = ma.info().labels
      label = get_label(miller_array=ma, output_r_free_label=output_r_free_label)
      if label is None:
        print("Can't determine output label for %s - skipping." % \
          ma.info().label_string(), file=log)
        continue
      elif label.startswith(output_r_free_label):
        ma, _ = cif_status_flags_as_int_r_free_flags(
          ma, test_flag_value="f")
        if isinstance(ma.data(), flex.double):
          data_int = ma.data().iround()
          assert data_int.as_double().all_eq(ma.data())
          ma = ma.customized_copy(data=data_int).set_info(ma.info())
      elif ((ma.is_xray_amplitude_array() or ma.is_xray_intensity_array())
            and isinstance(ma.data(), flex.int)):
        ma = ma.customized_copy(data=ma.data().as_double()).set_info(ma.info())
      crys_id = 0
      for l in labels:
        if 'crystal_id' in l:
          crys_id = int(l.split('=')[-1])
          break
      if crys_id > 0 and crystal_id is None:
        label += "%i" %crys_id
      if crystal_id is not None and crys_id > 0 and crys_id != crystal_id:
        continue

      if ma.unit_cell() is not None: # use symmetry file on the command line if it's None
        unit_cell = ma.unit_cell()

      if crys_id not in mtz_crystals or \
        (i > current_i and unit_cell is not None and uc is not None and unit_cell.parameters() != uc.parameters()):
        # Ensure new mtz crystals are created if miller_array objects have different unit cells
        # Can happen if there are more datasets in the same cif file, like MAD datasets
        uc = unit_cell
        current_i = i
        # Use unique project and crystal names so that MtzGet() in cmtzlib.c picks up individual unit cells
        mtz_crystals[crys_id] = (
          mtz_object.add_crystal(
            name="crystal_%i" %i,
            project_name="project_%i" %i,
            unit_cell =uc), {})
      crystal, datasets = mtz_crystals[crys_id]
      w_id = 0
      for l in labels:
        if 'wavelength_id' in l:
          w_id = int(l.split('=')[-1])
          break
      if wavelength_id is not None and w_id > 0 and w_id != wavelength_id:
        continue
      if w_id > 1 and wavelength_id is None:
        if (label in column_labels):
          label += "%i" %w_id
        #print "label is", label
      if w_id not in datasets:
        wavelength = ma.info().wavelength
        if (wavelength is None):
          wavelength = 0
        datasets[w_id] = crystal.add_dataset(
          name="dataset",
          wavelength=wavelength)
      dataset = datasets[w_id]
      # if all sigmas for an array are set to zero either raise an error, or set sigmas to None
      if ma.sigmas() is not None and (ma.sigmas() == 0).count(False) == 0:
        if ignore_bad_sigmas:
          print("Warning: bad sigmas, setting sigmas to None.", file=log)
          ma.set_sigmas(None)
        else:
          raise Sorry(
  """Bad sigmas: all sigmas are equal to zero.
  Add --ignore_bad_sigmas to command arguments to leave out sigmas from mtz file.""")
      if not ma.is_unique_set_under_symmetry():
        if merge_non_unique_under_symmetry:
          print("Warning: merging non-unique data", file=log)
          if (label.startswith(output_r_free_label)
              and incompatible_flags_to_work_set):
            merging = ma.merge_equivalents(
              incompatible_flags_replacement=0)
            if merging.n_incompatible_flags > 0:
              print("Warning: %i reflections were placed in the working set " \
                    "because of incompatible flags between equivalents." %(
                      merging.n_incompatible_flags), file=log)
          else:
            try:
              merging = ma.merge_equivalents()
            except Sorry as e:
              if ("merge_equivalents_exact: incompatible" in str(e)):
                raise Sorry(str(e) + " for %s" %ma.info().labels[-1] + "\n" +
                  "Add --incompatible_flags_to_work_set to command line "
                  "arguments to place incompatible flags to working set.")
                raise
          ma = merging.array().customized_copy(
            crystal_symmetry=ma).set_info(ma.info())
        elif return_as_miller_arrays: # allow non-unique set
          pass
        else:
          n_all = ma.indices().size()
          sel_unique = ma.unique_under_symmetry_selection()
          sel_dup = ~flex.bool(n_all, sel_unique)
          n_duplicate = sel_dup.count(True)
          n_uus = sel_unique.size()
          msg = (
            "Miller indices not unique under symmetry: " + file_name + \
            "(%d redundant indices out of %d)" % (n_all-n_uus, n_all) +
            "Add --merge to command arguments to force merging data.")
          if (show_details_if_error):
            print(msg, file=log)
            ma.show_comprehensive_summary(prefix="  ")
            ma.map_to_asu().sort().show_array(prefix="  ")
          raise Sorry(msg)
      if(map_to_asu):
        ma = ma.map_to_asu().set_info(ma.info())
      if(remove_systematic_absences):
        ma = ma.remove_systematic_absences()
      if (label.startswith(output_r_free_label) and complete_set is not None):
        n_missing = len(complete_set.lone_set(other=ma).indices())
        if (n_missing > 0):
          if (extend_flags):
            from cctbx import r_free_utils
            # determine flag values
            fvals = list(set(ma.data()))
            print("fvals", fvals, file=log)
            fval = None
            if(len(fvals)==1):
              fval = fvals[0]
            elif(len(fvals)==2):
              f1 = (ma.data()==fvals[0]).count(True)/ma.data().size()
              f2 = (ma.data()==fvals[1]).count(True)/ma.data().size()
              if(f1<f2): fval = fvals[0]
              else:      fval = fvals[1]
            elif(len(fvals)==0):
              fval = None
            else:
              fval = 0
              if(not fval in fvals):
                raise Sorry("Cannot determine free-R flag value.")
            #
            if(fval is not None):
              ma = r_free_utils.extend_flags(
                r_free_flags=ma,
                test_flag_value=fval,
                array_label=label,
                complete_set=complete_set,
                preserve_input_values=True,
                allow_uniform_flags=True,
                log=sys.stdout)
            else:
              ma = None
          else :
            strings = ["%d reflections do not have R-free flags in the "%n_missing,
              "array '%s' - this may "%label,
              "cause problems if you try to use the MTZ file for refinement ",
              "or map calculation.  We recommend that you extend the flags ",
              "to cover all reflections (--extend_flags on the command line)."]
            print("WARNING: ", "\n".join(strings), file=log)
      # Get rid of fake (0,0,0) reflection in some CIFs
      if(ma is not None):
        ma = ma.select_indices(indices=flex.miller_index(((0,0,0),)),
          negate=True).set_info(ma.info())

      if return_as_miller_arrays:
        miller_array_list.append(ma)
        continue  # don't make a dataset

      dec = None
      if ("FWT" in label):
        dec = iotbx.mtz.ccp4_label_decorator()
      column_types = None
      if ("PHI" in label or "PHWT" in label) and (ma.is_real_array()):
        column_types = "P"
      elif (label.startswith("DANO") and ma.is_real_array()):
        if (ma.sigmas() is not None):
          column_types = "DQ"
        else :
          column_types = "D"
      label_base = label
      i = 1
      while label in column_labels:
        label = label_base + "-%i" %(i)
        i += 1
      if(ma is not None):
        column_labels.add(label)
        if("FWT-1" in label): dec=None
        dataset.add_miller_array(ma,
          column_root_label=label,
          label_decorator=dec,
          column_types=column_types)
  if return_as_miller_arrays:
    return miller_array_list
  else:
    return mtz_object

########################################################################
# PHENIX GUI ROUTINES
#
master_phil = iotbx.phil.parse("""
input
  .caption = This program will convert CIF-formatted structure factors (used \
    by the PDB) to an MTZ file.  Other CIF types (restraints, etc.) will be \
    ignored.  Because the data in the PDB often contains mistakes or lacks \
    symmetry, an optional model file is strongly recommended.  If you want the \
    program to generate an MTZ file for a specific PDB ID, you may specify \
    that instead of input files, and the CIF and PDB will be fetched from \
    www.rcsb.org.
  .style = caption_img:icons/custom/phenix.reflection_file_editor.png
{
  pdb_id = None
    .type = str
    .short_caption = PDB ID to retrieve
    .input_size = 80
    .style = bold noauto
  cif_file = None
    .type = path
    .short_caption = CIF data file
    .style = bold noauto OnChange:extract_symm_for_cif
  pdb_file = None
    .type = path
    .short_caption = Model file
    .style = bold noauto file_type:pdb OnChange:extract_symm_for_cif
  wavelength_id = None
    .type = str
    .short_caption = Wavelength ID
    .help = Not required when only one wavelength is present
    .input_size = 120
    .style = noauto
  crystal_id = None
    .type = str
    .short_caption = Crystal ID
    .help = Not required when only one crystal is present
    .input_size = 120
    .style = noauto
}
crystal_symmetry {
  space_group = None
    .type = space_group
    .style = bold
  unit_cell = None
    .type = unit_cell
    .style = bold
}
output_file_name = None
  .type = path
  .style = new_file bold
include scope libtbx.phil.interface.tracking_params
options {
  merge = False
    .type = bool
    .short_caption = Merge non-unique data
  map_to_asu = True
    .type = bool
    .short_caption = Map HKL indices to ASU
  eliminate_sys_absent = False
    .type = bool
    .short_caption = Remove systematic absences
  show_details_if_error = True
    .type = bool
    .short_caption = Show data details for some errors
  incompatible_flags_to_work_set = False
    .type = bool
    .short_caption = Move incompatible flags to work set
  ignore_bad_sigmas = False
    .type = bool
  extend_flags = False
    .type = bool
    .short_caption = Extend incomplete R-free flags
  show_log = True
    .type = bool
}
""", process_includes=True)

# TODO replace the old 'run' method
#
# XXX this is still a little unsophisticated with respect to extracting
# crystal symmetry, but it's meant to be run from the Phenix GUI right now.
def run2(args,
          log=sys.stdout,
          check_params=True,
          params=None):
  import mmtbx.command_line.fetch_pdb
  libtbx.call_back.set_warning_log(sys.stderr)
  parameter_interpreter = master_phil.command_line_argument_interpreter(
    home_scope="")
  pdb_file = None
  cif_file = None
  sources = []
  for arg in args :
    if os.path.isfile(arg):
      if iotbx.pdb.is_pdb_file(arg):
        pdb_files = os.path.abspath(arg)
      elif arg.endswith(".cif") or arg.endswith(".cif.txt"):
        cif_file = os.path.abspath(arg)
      else :
        try :
          user_phil = iotbx.phil.parse(file_name=arg)
        except RuntimeError :
          print("Unrecognizable file format for %s" % arg)
        else :
          sources.append(user_phil)
    else :
      if arg.startswith("--"):
        arg = arg[2:] + "=True"
      try :
        user_phil = parameter_interpreter.process(arg=arg)
        sources.append(user_phil)
      except RuntimeError :
        print("Unrecognizable parameter %s" % arg)
  if (params is None):
    params = master_phil.fetch(sources=sources).extract()
  symm = None
  if (params.input.pdb_id is not None):
    params.input.pdb_file = mmtbx.command_line.fetch_pdb.run2(
      args=[params.input.pdb_id],
      log=log)
    params.input.cif_file = mmtbx.command_line.fetch_pdb.run2(
      args=["-x", params.input.pdb_id],
      log=log)
    symm = crystal_symmetry_from_any.extract_from(params.input.pdb_file)
    params.crystal_symmetry.space_group = symm.space_group_info()
    params.crystal_symmetry.unit_cell = symm.unit_cell()
    params.input.pdb_id = None
  if check_params :
    validate_params(params)
  if params.output_file_name is None :
    base, ext = os.path.splitext(params.input.cif_file)
    params.output_file_name = os.path.join(os.getcwd(), base + ".mtz")
  if symm is None :
    assert (type(params.crystal_symmetry.space_group).__name__ ==
            "space_group_info")
    symm = crystal.symmetry(
      space_group_info=params.crystal_symmetry.space_group,
      unit_cell=params.crystal_symmetry.unit_cell)
  n_refl = process_files(
    file_name=params.input.cif_file,
    crystal_symmetry=symm,
    output_file_name=params.output_file_name,
    wavelength_id=params.input.wavelength_id,
    crystal_id=params.input.crystal_id,
    show_details_if_error=params.options.show_details_if_error,
    output_r_free_label="FreeR_flag",
    merge_non_unique_under_symmetry=params.options.merge,
    map_to_asu=params.options.map_to_asu,
    remove_systematic_absences=params.options.eliminate_sys_absent,
    incompatible_flags_to_work_set=\
      params.options.incompatible_flags_to_work_set,
    ignore_bad_sigmas=params.options.ignore_bad_sigmas,
    extend_flags=params.options.extend_flags)
  return (params.output_file_name, n_refl)

def validate_params(params):
  if params.input.cif_file is None and params.input.pdb_id is None:
    raise Sorry("No CIF file provided!")
  if params.input.cif_file == [] and params.input.pdb_id is None:
    raise Sorry("No structure factors found!")
  if (params.input.pdb_id is not None):
    if (params.input.cif_file is not None):
      raise Sorry("Please specify either a PDB ID or a CIF file, not both.")
    import iotbx.pdb.fetch
    try :
      iotbx.pdb.fetch.validate_pdb_id(params.input.pdb_id)
    except RuntimeError as e :
      raise Sorry(str(e))
  else :
    if ((params.crystal_symmetry.space_group is None) or
        (params.crystal_symmetry.unit_cell is None)):
      raise Sorry("Crystal symmetry missing or incomplete.")
  if (params.output_file_name is not None):
    output_dir = os.path.dirname(params.output_file_name)
    if (not os.path.isdir(output_dir)):
      raise Sorry(("The output directory %s does not exist or is not a "+
        "directory.") % output_dir)
  return True

class launcher(runtime_utils.target_with_save_result):
  def run(self):
    os.chdir(self.output_dir)
    return run2(args=list(self.args), log=sys.stdout)

def finish_job(results):
  (mtz_file, n_refl) = results
  if n_refl is None :
    n_refl = 0
  if (mtz_file is not None) and os.path.isfile(mtz_file):
    return ([("MTZ file", mtz_file)], [("Number of reflections", n_refl)])
  return ([], [])

if(__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/clashscore.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.clashscore
# LIBTBX_SET_DISPATCHER_NAME molprobity.clashscore
# LIBTBX_PRE_DISPATCHER_INCLUDE_SH export PHENIX_GUI_ENVIRONMENT=1

import sys

from iotbx.cli_parser import CCTBXParser
from libtbx.utils import multi_out, show_total_time
from mmtbx.programs import clashscore
from iotbx.cli_parser import run_program

#=============================================================================
def old_run(args):

  # create parser
  logger = multi_out()
  logger.register('stderr', sys.stderr)
  logger2 = multi_out()
  logger2.register('stdout', sys.stdout)

  parser = CCTBXParser(
    program_class=clashscore.Program,
    logger=logger)
  namespace = parser.parse_args(sys.argv[1:])

  # start program
  print('Starting job', file=logger)
  print('='*79, file=logger)
  task = clashscore.Program(
    parser.data_manager, parser.working_phil.extract(), logger=logger2)

  # validate inputs
  task.validate()

  # run program
  task.run()

  # stop timer
  print('', file=logger)
  print('='*79, file=logger)
  print('Job complete', file=logger)
  show_total_time(out=logger)

# =============================================================================
if __name__ == '__main__':
  #run(sys.argv[1:])
  run_program(program_class=clashscore.Program, hide_parsing_output=True)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/clashscore2.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.clashscore2
# LIBTBX_SET_DISPATCHER_NAME molprobity.clashscore2
# LIBTBX_SET_DISPATCHER_NAME mmtbx.clashscore2
# LIBTBX_PRE_DISPATCHER_INCLUDE_SH export PHENIX_GUI_ENVIRONMENT=1

import sys

from iotbx.cli_parser import CCTBXParser
from libtbx.utils import multi_out, show_total_time
from mmtbx.programs import clashscore2
from iotbx.cli_parser import run_program

#=============================================================================
def old_run(args):

  # create parser
  logger = multi_out()
  logger.register('stderr', sys.stderr)
  logger2 = multi_out()
  logger2.register('stdout', sys.stdout)

  parser = CCTBXParser(
    program_class=clashscore2.Program,
    logger=logger)
  namespace = parser.parse_args(sys.argv[1:])

  # start program
  print('Starting job', file=logger)
  print('='*79, file=logger)
  task = clashscore2.Program(
    parser.data_manager, parser.working_phil.extract(), logger=logger2)

  # validate inputs
  task.validate()

  # run program
  task.run()

  # stop timer
  print('', file=logger)
  print('='*79, file=logger)
  print('Job complete', file=logger)
  show_total_time(out=logger)

# =============================================================================
if __name__ == '__main__':
  #run(sys.argv[1:])
  run_program(program_class=clashscore2.Program, hide_parsing_output=True)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/comparama.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.comparama

from mmtbx.programs import comparama
from iotbx.cli_parser import run_program

if __name__ == "__main__":
  run_program(comparama.Program)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/density_modification.py
from __future__ import absolute_import, division, print_function
from mmtbx import density_modification
import mmtbx.utils
from cctbx.array_family import flex
from cctbx import crystal
from iotbx.option_parser import option_parser
import iotbx.phil
from iotbx.reflection_file_reader import any_reflection_file
from libtbx.utils import show_times_at_exit, Sorry
from libtbx import runtime_utils
from libtbx import adopt_init_args
import mmtbx.maps
from mmtbx.ncs import ncs
from scitbx.math import nearest_phase, phase_error
import os, sys
from six.moves import range
from iotbx import extract_xtal_data

master_params_including_IO_str = """\
density_modification {
  input
    .style = noauto
  {
    reflection_data {
      %s
    }
    experimental_phases {
      %s
    }
    map_coefficients
      .optional=True
      .help = Optional starting map coefficients
    {
      %s
    }
    ncs_file_name = None
      .type = path
      .optional = True
      .short_caption = NCS file
      .help = .ncs_spec file produced by phenix.find_ncs or phenix.find_ncs_from_density
    unit_cell = None
      .type = unit_cell
      .optional = False
      .style = bold noauto
    space_group = None
      .type = space_group
      .optional = False
      .style = bold noauto
  }
  output
    .style = noauto
  {
    map {
      file_name = None
        .type = path
        .help = The file name for the final density-modified map
        .short_caption = Output map file
        .style = bold noauto new_file file_type:mtz
      format = xplor *ccp4
        .type = choice
        .short_caption = Map format
      scale = *sigma volume
        .type = choice(multi=False)
        .short_caption = Map scaling
        .expert_level=2
    }
    mtz {
      file_name = None
        .type = path
        .help = The file name for the coefficients of the final density-modified map
        .short_caption = Output map coefficients
        .style = bold noauto new_file
      output_hendrickson_lattman_coefficients = False
        .type = bool
        .help = Output density modified phase probability distributions
      skip_output_if_worse = False
        .type = bool
        .help = Skip output if FOM gets worse
        .style = hidden
    }
  }
include scope libtbx.phil.interface.tracking_params
%s
}
""" %(iotbx.extract_xtal_data.data_and_flags_str,
      iotbx.extract_xtal_data.experimental_phases_params_str,
      mmtbx.utils.map_coefficients_params_str,
      density_modification.master_params_str)

def defaults(log):
  parsed = iotbx.phil.parse(
    master_params_including_IO_str, process_includes=True)
  print(file=log)
  return parsed

def run(args, log = sys.stdout, as_gui_program=False):
  if(len(args)==0):
    parsed = defaults(log=log)
    parsed.show(prefix="  ", out=log)
    return
  command_line = (option_parser()
                  .enable_symmetry_comprehensive()
                  .option("-q", "--quiet",
                          action="store_true",
                          default=False,
                          help="suppress output")
                  .option("--output_plots",
                          action="store_true",
                          default=False)
                  ).process(args=args)
  parsed = defaults(log=log)
  processed_args = mmtbx.utils.process_command_line_args(
    args=command_line.args,
    cmd_cs=command_line.symmetry,
    master_params=parsed,
    log=log,
    suppress_symmetry_related_errors=True)
  processed_args.params.show(out=log)
  params = processed_args.params.extract().density_modification
  output_plots = command_line.options.output_plots

  crystal_symmetry = crystal.symmetry(
    unit_cell=params.input.unit_cell,
    space_group_info=params.input.space_group)
  reflection_files = {}
  for rfn in (params.input.reflection_data.file_name,
              params.input.experimental_phases.file_name,
              params.input.map_coefficients.file_name):
    if os.path.isfile(str(rfn)) and rfn not in reflection_files:
      reflection_files.setdefault(
        rfn, iotbx.reflection_file_reader.any_reflection_file(
          file_name=rfn, ensure_read_access=False))
  # TODO is reflection_files a dict ?
  server = iotbx.reflection_file_utils.reflection_file_server(
    crystal_symmetry=crystal_symmetry,
    reflection_files=list(reflection_files.values()))
  o = extract_xtal_data.run(
    server,
    parameters=params.input.reflection_data,
    experimental_phases_params=params.input.experimental_phases,
    extract_r_free_flags=False)
  fo = o.f_obs
  hl_coeffs = o.experimental_phases
  if params.input.map_coefficients.file_name is not None:
    map_coeffs = server.get_phases_deg(
      file_name=params.input.map_coefficients.file_name,
      labels=params.input.map_coefficients.labels,
      convert_to_phases_if_necessary=False,
      original_phase_units=None,
      parameter_scope="",
      parameter_name="labels").map_to_asu()
  else:
    map_coeffs = None
  ncs_object = None
  if params.input.ncs_file_name is not None:
    ncs_object = ncs.ncs()
    ncs_object.read_ncs(params.input.ncs_file_name)
    ncs_object.display_all(log=log)

  fo = fo.map_to_asu()
  hl_coeffs = hl_coeffs.map_to_asu()

  fo = fo.eliminate_sys_absent().average_bijvoet_mates()
  hl_coeffs = hl_coeffs.eliminate_sys_absent().average_bijvoet_mates()

  model_map = None
  model_map_coeffs = None
  if len(processed_args.pdb_file_names):
    pdb_inp = mmtbx.utils.pdb_inp_from_multiple_files(
      pdb_files=processed_args.pdb_file_names,
      log=log)
    xs = pdb_inp.xray_structure_simple()
    fo_, hl_ = fo, hl_coeffs
    if params.change_basis_to_niggli_cell:
      change_of_basis_op = xs.change_of_basis_op_to_niggli_cell()
      xs = xs.change_basis(change_of_basis_op)
      fo_ = fo_.change_basis(change_of_basis_op).map_to_asu()
      hl_ = hl_.change_basis(change_of_basis_op).map_to_asu()
    #fo_, hl_ = fo_.common_sets(hl_)
    fmodel_refined = mmtbx.utils.fmodel_simple(
      f_obs=fo_,
      scattering_table="wk1995",#XXX pva: 1) neutrons? 2) move up as a parameter.
      xray_structures=[xs],
      bulk_solvent_correction=True,
      anisotropic_scaling=True,
      r_free_flags=fo_.array(data=flex.bool(fo_.size(), False)))
    fmodel_refined.update(abcd=hl_)

    master_phil = mmtbx.maps.map_and_map_coeff_master_params()
    map_params = master_phil.fetch(iotbx.phil.parse("""\
map_coefficients {
  map_type = 2mFo-DFc
  isotropize = True
}
""")).extract().map_coefficients[0]
    model_map_coeffs = mmtbx.maps.map_coefficients_from_fmodel(
      fmodel=fmodel_refined, params=map_params)
    model_map = model_map_coeffs.fft_map(
      resolution_factor=params.grid_resolution_factor).real_map_unpadded()

  import time

  t0 = time.time()
  dm = density_modify(
    params,
    fo,
    hl_coeffs,
    ncs_object=ncs_object,
    map_coeffs=map_coeffs,
    model_map_coeffs=model_map_coeffs,
    log=log,
    as_gui_program=as_gui_program)
  time_dm = time.time()-t0
  print("Time taken for density modification: %.2fs" %time_dm, file=log)
  # run cns
  if 0:
    from cctbx.development import cns_density_modification
    cns_result = cns_density_modification.run(params, fo, hl_coeffs)
    print(cns_result.modified_map.all())
    print(dm.map.all())
    dm_map_coeffs = dm.map_coeffs_in_original_setting
    from cctbx import maptbx, miller
    crystal_gridding = maptbx.crystal_gridding(
      dm_map_coeffs.unit_cell(),
      space_group_info=dm_map_coeffs.space_group().info(),
      pre_determined_n_real=cns_result.modified_map.all())
    dm_map = miller.fft_map(crystal_gridding, dm_map_coeffs).apply_sigma_scaling()
    corr = flex.linear_correlation(cns_result.modified_map.as_1d(), dm_map.real_map_unpadded().as_1d())
    print("CNS dm/mmtbx dm correlation:")
    corr.show_summary()
    if dm.model_map_coeffs is not None:
      model_map = miller.fft_map(
        crystal_gridding,
        dm.miller_array_in_original_setting(dm.model_map_coeffs)).apply_sigma_scaling()
      corr = flex.linear_correlation(cns_result.modified_map.as_1d(), model_map.real_map_unpadded().as_1d())
      print("CNS dm/model correlation:")
      corr.show_summary()

  if output_plots:
    plots_to_make = (
      "fom", "skewness",
      "r1_factor", "r1_factor_fom", "mean_solvent_density", "mean_protein_density",
      "f000_over_v", "k_flip", "rms_solvent_density", "rms_protein_density",
      "standard_deviation_local_rms", "mean_delta_phi", "mean_delta_phi_initial",
      )
    from matplotlib.backends.backend_pdf import PdfPages
    from libtbx import pyplot

    stats = dm.get_stats()
    pdf = PdfPages("density_modification.pdf")

    if len(dm.correlation_coeffs) > 1:
      if 0:
        start_coeffs, model_coeffs = dm.map_coeffs_start.common_sets(model_map_coeffs)
        model_phases = model_coeffs.phases(deg=True).data()
        exptl_phases = nearest_phase(
          model_phases, start_coeffs.phases(deg=True).data(), deg=True)
        corr = flex.linear_correlation(exptl_phases, model_phases)
        corr.show_summary()
        fig = pyplot.figure()
        ax = fig.add_subplot(1,1,1)
        ax.set_title("phases start")
        ax.set_xlabel("Experimental phases")
        ax.set_ylabel("Phases from refined model")
        ax.scatter(exptl_phases,
                   model_phases,
                   marker="x", s=10)
        pdf.savefig(fig)
        #
        dm_coeffs, model_coeffs = dm.map_coeffs.common_sets(model_map_coeffs)
        model_phases = model_coeffs.phases(deg=True).data()
        dm_phases = nearest_phase(
          model_phases, dm_coeffs.phases(deg=True).data(), deg=True)
        corr = flex.linear_correlation(dm_phases, model_phases)
        corr.show_summary()
        fig = pyplot.figure()
        ax = fig.add_subplot(1,1,1)
        ax.set_title("phases dm")
        ax.set_xlabel("Phases from density modification")
        ax.set_ylabel("Phases from refined model")
        ax.scatter(dm_phases,
                   model_phases,
                   marker="x", s=10)
        pdf.savefig(fig)
      #
      data = dm.correlation_coeffs
      fig = pyplot.figure()
      ax = fig.add_subplot(1,1,1)
      ax.set_title("correlation coefficient")
      ax.plot(list(range(1, dm.i_cycle+2)), data)
      pdf.savefig(fig)
      #
      data = dm.mean_phase_errors
      fig = pyplot.figure()
      ax = fig.add_subplot(1,1,1)
      ax.set_title("Mean effective phase errors")
      ax.plot(list(range(1, dm.i_cycle+2)), data)
      pdf.savefig(fig)

    for plot in plots_to_make:
      data = [getattr(stats.get_cycle_stats(i), plot) for i in range(1, dm.i_cycle+2)]
      fig = pyplot.figure()
      ax = fig.add_subplot(1,1,1)
      ax.set_title(plot.replace("_", " "))
      ax.plot(list(range(1, dm.i_cycle+2)), data)
      pdf.savefig(fig)

    data = [stats.get_cycle_stats(i).rms_solvent_density/
            stats.get_cycle_stats(i).rms_protein_density
            for i in range(1, dm.i_cycle+2)]
    fig = pyplot.figure()
    ax = fig.add_subplot(1,1,1)
    ax.set_title("RMS solvent/protein density ratio")
    ax.plot(list(range(1, dm.i_cycle+2)), data)
    pdf.savefig(fig)

    pdf.close()

  dm_map_coeffs = dm.map_coeffs_in_original_setting
  dm_hl_coeffs = dm.hl_coeffs_in_original_setting

  # output map if requested
  map_params = params.output.map
  if map_params.file_name is not None:
    fft_map = dm_map_coeffs.fft_map(resolution_factor=params.grid_resolution_factor)
    if map_params.scale == "sigma":
      fft_map.apply_sigma_scaling()
    else:
      fft_map.apply_volume_scaling()
    gridding_first = gridding_last = None
    title_lines = []
    if map_params.format == "xplor":
      fft_map.as_xplor_map(
        file_name      = map_params.file_name,
        title_lines    = title_lines,
        gridding_first = gridding_first,
        gridding_last  = gridding_last)
    else :
      fft_map.as_ccp4_map(
        file_name      = map_params.file_name,
        gridding_first = gridding_first,
        gridding_last  = gridding_last,
        labels=title_lines)

  # output map coefficients if requested
  mtz_params = params.output.mtz

  # Decide if we are going to actually write the mtz
  if mtz_params.file_name is not None:
    orig_fom,final_fom=dm.start_and_end_fom()
    if mtz_params.skip_output_if_worse and final_fom < orig_fom:
      ok_to_write_mtz=False
      print("Not writing out mtz. Final FOM (%7.3f) worse than start (%7.3f)" %(
        final_fom,orig_fom))
    else:  # usual
      ok_to_write_mtz=True
  else:
      ok_to_write_mtz=True

  if mtz_params.file_name is not None and ok_to_write_mtz:
    label_decorator=iotbx.mtz.ccp4_label_decorator()
    fo = dm.miller_array_in_original_setting(dm.f_obs_complete).common_set(dm_map_coeffs)
    mtz_dataset = fo.as_mtz_dataset(
      column_root_label="F",
      label_decorator=label_decorator)
    mtz_dataset.add_miller_array(
      dm_map_coeffs,
      column_root_label="FWT",
      label_decorator=label_decorator)
    phase_source = dm.miller_array_in_original_setting(dm.phase_source).common_set(dm_map_coeffs)
    mtz_dataset.add_miller_array(
      phase_source.array(data=flex.abs(phase_source.data())),
      column_root_label="FOM",
      column_types='W',
      label_decorator=label_decorator)
    mtz_dataset.add_miller_array(
      phase_source.array(data=phase_source.phases(deg=True).data()),
      column_root_label="PHIB",
      column_types='P',
      label_decorator=None)
    if mtz_params.output_hendrickson_lattman_coefficients:
      mtz_dataset.add_miller_array(
        dm_hl_coeffs,
        column_root_label="HL",
        label_decorator=label_decorator)
    mtz_dataset.mtz_object().write(mtz_params.file_name)

  return result(
    map_file=map_params.file_name,
    mtz_file=mtz_params.file_name,
    stats=dm.get_stats())

# just for development purposes, compare the correlation of the
# density-modified map with map calculated from the model at each cycle
class density_modify(density_modification.density_modification):

  def __init__(self, params,
                     fo,
                     hl_coeffs,
                     ncs_object=None,
                     map_coeffs=None,
                     model_map_coeffs=None,
                     log=None,
                     as_gui_program=False):
    self.model_map_coeffs = model_map_coeffs
    self.correlation_coeffs = flex.double()
    self.mean_phase_errors = flex.double()
    density_modification.density_modification.__init__(
      self, params, fo, hl_coeffs,
      ncs_object=ncs_object,
      map_coeffs=map_coeffs,
      log=log,
      as_gui_program=as_gui_program)
    if len(self.correlation_coeffs) > 1:
      model_coeffs, start_coeffs = self.model_map_coeffs.common_sets(self.map_coeffs_start)
      model_fft_map = model_coeffs.fft_map(
        resolution_factor=self.params.grid_resolution_factor).apply_sigma_scaling()
      fft_map = start_coeffs.fft_map(
        resolution_factor=self.params.grid_resolution_factor
      ).apply_sigma_scaling()
      corr = flex.linear_correlation(
        model_fft_map.real_map_unpadded().as_1d(), fft_map.real_map_unpadded().as_1d())
      print("Starting dm/model correlation: %.6f" %corr.coefficient())
      print("Final dm/model correlation:    %.6f" %self.correlation_coeffs[-1])
      fft_map.as_ccp4_map(file_name="starting.map", labels=[])

  def compute_map(self):
    density_modification.density_modification.compute_map(self)
    if self.model_map_coeffs is not None:
      model_coeffs, dm_coeffs = self.model_map_coeffs.common_sets(self.map_coeffs)
      fft_map = model_coeffs.fft_map(
        resolution_factor=self.params.grid_resolution_factor).apply_sigma_scaling()
      dm_map = dm_coeffs.fft_map(
        resolution_factor=self.params.grid_resolution_factor).apply_sigma_scaling()
      print()
      corr = flex.linear_correlation(
        fft_map.real_map_unpadded().as_1d(), dm_map.real_map_unpadded().as_1d())
      print("dm/model correlation:")
      corr.show_summary()
      self.correlation_coeffs.append(corr.coefficient())
      self.mean_phase_errors.append(flex.mean(phase_error(
        flex.arg(model_coeffs.data()),
        flex.arg(dm_coeffs.data())))/density_modification.pi_180)

def validate_params(params):
  params_ = params.density_modification
  if (params_.input.reflection_data.file_name is None):
    raise Sorry("No reflection data provided.")
  if (params_.input.reflection_data.labels is None):
    raise Sorry("Data labels not specified.")
  if (params_.input.experimental_phases.file_name is None):
    raise Sorry("Experimental phases (Hendrickson-Lattman coefficients " +
                "not specified.")
  if (params_.input.experimental_phases.labels is None):
    raise Sorry("Experimental phase labels not specified.")
  if ((params_.output.map.file_name is None) and
      (params_.output.mtz.file_name is None)):
    raise Sorry("No output requested!")
  if (params_.solvent_fraction is None):
    raise Sorry("Please specify the solvent fraction!")

class launcher(runtime_utils.target_with_save_result):
  def run(self):
    return run(args=list(self.args),
      log=sys.stdout, # 2012-03-09 should be called with log defined?
      as_gui_program=True)

class result(object):
  def __init__(self, map_file, mtz_file, stats):
    adopt_init_args(self, locals())

  def extract_loggraph(self):
    return self.stats.extract_loggraph()

  def get_final_job_statistics(self):
    stats = [
      ("FOM", self.stats.get_cycle_stats(-1).fom),
      ("Skewness", self.stats.get_cycle_stats(-1).skewness)
    ]
    return stats

  def finish_job(self):
    output_files = []
    if (self.mtz_file is not None):
      output_files.append((self.mtz_file, "Map coefficients"))
    if (self.map_file is not None):
      output_files.append((self.map_file, "Real-space map"))
    stats = self.get_final_job_statistics()
    return (output_files, stats)

if __name__ == '__main__':
  show_times_at_exit()
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/development_aev.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME mmtbx.development.aev
import sys
import time
import mmtbx
import iotbx.pdb
import mmtbx.model
from libtbx.utils import null_out
import __init__ as aev

def main(filename):
  t0 = time.time()
  pdb_inp = iotbx.pdb.input(file_name = filename)
  model = mmtbx.model.manager(
    model_input   = pdb_inp,
    log           = null_out())
  sel = model.selection(string="protein")
  model = model.select(selection=sel)
  model.crystal_symmetry()
  a = aev.AEV(model = model)
  CC_value = aev.compare(a)
  print(CC_value)
  recs = aev.format_HELIX_records_from_AEV(CC_value)
  print("\n".join(recs))
  print('time', time.time()-t0)

if __name__ == '__main__':
  main(*tuple(sys.argv[1:]))


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/development_fem.py
# LIBTBX_SET_DISPATCHER_NAME phenix.fem
# LIBTBX_SET_DISPATCHER_NAME phenix.feature_enhanced_map

from __future__ import absolute_import, division, print_function
import mmtbx.command_line
import mmtbx.maps
import iotbx.phil
import iotbx.pdb
from scitbx.array_family import flex
from libtbx import runtime_utils
import os.path
import time
import sys
import random
import mmtbx.maps.fem
import mmtbx.masks

def get_master_phil():
  return mmtbx.command_line.generate_master_phil_with_inputs(
    phil_string="""
random_seed=2679941
  .type = int
use_omit = True
  .type = bool
  .help = Use composite OMIT protocol
sharp=True
  .type=bool
use_unsharp_masking = True
  .type = bool
resolution_factor = 1./4
  .type = float
signal_threshold = 0.5
  .type = float
use_resolve = Auto
  .type = bool
use_max_map = True
  .type = bool
ignore_zero_occupancy_atoms = True
  .type=bool
output {
  file_name_prefix = fem
    .type = str
    .input_size = 400
  column_root_label = FEM
    .type = str
    .input_size = 120
    .short_caption = Base MTZ column label
  gui_output_dir = None
    .type = path
    .short_caption = Output directory
    .style = bold output_dir
}
include scope libtbx.phil.interface.tracking_params
""",
    enable_twin_law=False)

master_phil = get_master_phil()
master_params = master_phil # for phenix GUI

def manage_random_seed(random_seed):
  if(random_seed is None):
    random_seed = flex.get_random_seed()
  random.seed(random_seed)
  flex.set_random_seed(random_seed)

def run(args, command_name = "phenix.development.fem", log = sys.stdout):
  cmdline = mmtbx.command_line.load_model_and_data(
    args=args,
    master_phil=master_phil,
    out=log,
    process_pdb_file=False,
    force_non_anomalous=True,
    create_fmodel=False,
    usage_string="""
  phenix.development.fem model.pdb data.mtz
  phenix.development.fem data.mtz model.pdb f_obs_label=F

Calculate a "feature-enhanced" 2mFo-DFc map.
""")
  params = cmdline.params
  xray_structure = cmdline.xray_structure
  f_obs = cmdline.f_obs
  r_free_flags = cmdline.r_free_flags
  if not r_free_flags:
    from libtbx.utils import Sorry
    raise Sorry("Please supply a file with r_free flags for FEM")
  manage_random_seed(random_seed=params.random_seed)
  cs=f_obs.crystal_symmetry()
  mask_params = mmtbx.masks.mask_master_params.extract()
  mask_params.ignore_zero_occupancy_atoms = params.ignore_zero_occupancy_atoms
  #
  fem = mmtbx.maps.fem.run(
    f_obs               = f_obs,
    r_free_flags        = r_free_flags,
    xray_structure      = xray_structure,
    use_resolve         = params.use_resolve,
    use_omit            = params.use_omit,
    use_max_map         = params.use_max_map,
    sharp               = params.sharp,
    use_unsharp_masking = params.use_unsharp_masking,
    resolution_factor   = params.resolution_factor,
    log                 = log)
  mtz_file_name = "%s.mtz"%params.output.file_name_prefix
  ccp4_map_file_name = "%s.ccp4"%params.output.file_name_prefix
  fem.write_output_files(
    mtz_file_name      = mtz_file_name,
    ccp4_map_file_name = ccp4_map_file_name,
    fem_label          = params.output.column_root_label,
    orig_label         = "2mFo-DFc")
  return os.path.abspath(mtz_file_name)

class launcher(runtime_utils.target_with_save_result):
  def run(self):
    os.mkdir(self.output_dir)
    os.chdir(self.output_dir)
    return run(args=self.args, log=sys.stdout)

def validate_params(params):
  return mmtbx.command_line.validate_input_params(params)

if(__name__ == "__main__"):
  t0 = time.time()
  run(sys.argv[1:])
  print("Time: %6.4f"%(time.time()-t0))


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/distance_difference.py
from __future__ import absolute_import, division, print_function
# LIBTBX_PRE_DISPATCHER_INCLUDE_SH export PHENIX_GUI_ENVIRONMENT=1
# LIBTBX_PRE_DISPATCHER_INCLUDE_SH export BOOST_ADAPTBX_FPE_DEFAULT=1

# TODO need a good test for this

import libtbx.phil.command_line
from libtbx.utils import Sorry, Usage, null_out
import os
import sys

calculate_matrix_phil = """
model_1 = None
  .type = path
  .optional = False
chain_1 = None
  .type = str
model_2 = None
  .type = path
  .optional = False
chain_2 = None
  .type = str
"""

master_phil = libtbx.phil.parse("""
calculate_matrix
  .caption = This tool calculates a distance-difference matrix for two \
    protein chains.  The resulting plot shows the change in interatomic \
    distances (between C-alpha atoms), illustrating correlated motions and \
    rigid bodies in the structures.  The input structures are assumed to be \
    identical in sequence numbering, but point mutations and missing regions \
    are allowed.
  .short_caption = Calculate distance-difference matrix
  .style = auto_align box caption_img:icons/custom/distance_difference.png
{
%s
display_plot = False
  .type = bool
  .style = hidden
}""" % calculate_matrix_phil)

def usage():
  raise Usage("""
mmtbx.distance_difference model1.pdb CHAIN_1 model2.pdb CHAIN_2
mmtbx.distance_difference model_1=... model_2=... chain_1=... chain_2=...

other options:
  --display_plot or display_plot=True : display plot interactively

Calculate and plot a distance difference matrix for two (near-identical)
protein chains.  Chain IDs are optional for models that have only one protein
chain.
""")

def run(args=(), params=None, out=None, display_plot=False):
  if (out is None):
    out = sys.stdout
  user_phil = []
  pdb_files = []
  chain_ids = []
  interp = libtbx.phil.command_line.argument_interpreter(
    master_phil=master_phil,
    home_scope="calculate_matrix")
  if (params is None):
    if (len(args) == 0):
      usage()
    import iotbx.pdb
    for arg in args :
      if os.path.isfile(arg):
        if (iotbx.pdb.is_pdb_file(arg)):
          pdb_files.append(arg)
        else :
          user_phil.append(libtbx.phil.parse(file_name=arg))
      elif (len(arg) <= 2):
        chain_ids.append(arg)
      else :
        if (arg.startswith("--")):
          arg = arg[2:] + "=True"
        try :
          arg_phil = interp.process_arg(arg)
        except RuntimeError :
          pass
        else :
          user_phil.append(arg_phil)
          continue
    for i, file_name in enumerate(pdb_files):
      i += 1
      user_phil.append(interp.process_arg("model_%d=\"%s\"" % (i, file_name)))
    for i, chain_id in enumerate(chain_ids):
      i += 1
      user_phil.append(interp.process_arg("chain_%d=\"%s\"" % (i, chain_id)))
    working_phil = master_phil.fetch(sources=user_phil)
    params = working_phil.extract()
    validate_params(params)
  params = params.calculate_matrix
  ddm = calculate_matrix(params, log=out)
  title = "Distance-difference matrix: %s:%s vs. %s:%s" % (
    os.path.basename(params.model_1), params.chain_1,
    os.path.basename(params.model_2), params.chain_2)
  ddm.set_title(title)
  if (display_plot) and (params.display_plot):
    try :
      display_plot_pylab(ddm)
    except ImportError :
      raise Sorry("matplotlib is not installed - can't generate plot image.")
    except Exception as e :
      print("Oops!  Can't display an interactive plot:", file=out)
      print("  %s" % str(e), file=out)
  elif (display_plot) : # only if not run from GUI!
    try :
      import matplotlib
    except ImportError :
      raise Sorry("matplotlib is not installed - can't generate plot image.")
    matplotlib.use('Agg')
    display_plot_pylab(ddm, savefig=True)
    print("Saved plot as distance_difference.png")
  return ddm

def calculate_matrix(params, log=None):
  if (log is None) : log = null_out()
  import iotbx.pdb
  pdb_1 = iotbx.pdb.input(params.model_1)
  hierarchy_1 = pdb_1.construct_hierarchy()
  hierarchy_1.atoms().reset_i_seq()
  pdb_2 = iotbx.pdb.input(params.model_2)
  hierarchy_2 = pdb_2.construct_hierarchy()
  hierarchy_2.atoms().reset_i_seq()
  for k, hierarchy in enumerate([hierarchy_1,hierarchy_2]):
    k += 1
    if (getattr(params, "chain_%d" % k) is None):
      try :
        chain_id = find_single_protein_chain(hierarchy)
        if (chain_id is None):
          raise Sorry(("The file %s does not appear to have any protein "+
            "chains!  If you think this is an error, you should explicitly "+
            "specify the parameter chain_%d.  (Nucleic acids are not yet "+
            "supported, sorry.)") % (getattr(params, "model_%d" % k), k))
        setattr(params, "chain_%d" % k, chain_id)
      except RuntimeError :
        raise Sorry(("The file %s has more than one protein chain, and no "+
          "explicit chain ID to use was specified.") %
            getattr(params, "model_%d" % k))
      except AssertionError :
        raise Sorry(("The file %s contains multiple models.  You can use "+
          "iotbx.pdb.split_models to extract the individual models from the "+
          "file (also available in the PHENIX GUI).") %
            getattr(params, "model_%d" % k))
  return distance_difference_matrix(
    hierarchy_1=hierarchy_1,
    chain_id_1=params.chain_1,
    hierarchy_2=hierarchy_2,
    chain_id_2=params.chain_2,
    log=log)

# TODO any polymer, not just protein
def find_single_protein_chain(hierarchy):
  assert (len(hierarchy.models()) == 1)
  chain_id = None
  for chain in hierarchy.models()[0].chains():
    if chain.is_protein():
      if (chain_id is not None):
        raise RuntimeError("More than one protein chain in hierarchy.")
      chain_id = chain.id
  return chain_id

class distance_difference_matrix(object):
  def __init__(self,
                hierarchy_1,
                chain_id_1,
                hierarchy_2,
                chain_id_2,
                log=None):
    assert (not None in [hierarchy_1, chain_id_1, hierarchy_2, chain_id_2])
    assert (len(hierarchy_1.models())==1) and (len(hierarchy_2.models())==1)
    assert (not hierarchy_1.atoms().extract_i_seq().all_eq(0))
    assert (not hierarchy_2.atoms().extract_i_seq().all_eq(0))
    from scitbx.array_family import flex
    if (log is None):
      log = null_out()
    self.matching_resids = []
    chain_1 = chain_2 = None
    for chain in hierarchy_1.models()[0].chains():
      if (chain.id == chain_id_1):
        if chain.is_protein():
          if (chain_1 is not None):
            raise Sorry("Multiple protein chains with ID '%s' in hierarchy_1")
          else :
            chain_1 = chain
    for chain in hierarchy_2.models()[0].chains():
      if (chain.id == chain_id_2):
        if chain.is_protein():
          if (chain_2 is not None):
            raise Sorry("Multiple protein chains with ID '%s' in hierarchy_1")
          else :
            chain_2 = chain
    if (chain_1 is None):
      raise Sorry("Can't find protein chain '%s' in 1st model." % chain_id_1)
    if (chain_2 is None):
      raise Sorry("Can't find protein chain '%s' in 2nd model." % chain_id_2)
    resids = [ [], [] ]
    selections = [ flex.size_t(), flex.size_t() ]
    for i, chain in enumerate([chain_1, chain_2]):
      for residue_group in chain.residue_groups():
        atom_groups = residue_group.atom_groups()
        resid = residue_group.resid()
        if (len(atom_groups) > 1):
          print("Warning: multiple conformers in model %d at %s" % (i+1,
            resid), file=log)
        for atom in atom_groups[0].atoms():
          if (atom.name == " CA "):
            resids[i].append(resid)
            selections[i].append(atom.i_seq)
            break
    for i,j in [ (0,1), (1,0) ] :
      k = 0
      assert (len(resids[i]) == len(selections[i]))
      while (k < len(resids[i])):
        if (not resids[i][k] in resids[j]):
          del resids[i][k]
          del selections[i][k]
        else :
          k += 1
    assert (len(resids[0]) == len(resids[1]))
    assert (len(selections[0]) == len(selections[1]))
    if (len(resids[0]) == 0):
      raise Sorry("No matching residues in model 1!  Make sure it is "+
        "really a protein chain with CA atoms for each residue.")
    if (len(resids[1]) == 0):
      raise Sorry("No matching residues in model 2!  Make sure it is "+
        "really a protein chain with CA atoms for each residue.")
    sites_1 = hierarchy_1.atoms().extract_xyz()
    sites_1 = sites_1.select(selections[0])
    sites_2 = hierarchy_2.atoms().extract_xyz()
    sites_2 = sites_2.select(selections[1])
    import scitbx.math
    self.m = scitbx.math.distance_difference_matrix(sites_1, sites_2)
    self.resids_1 = resids[0]
    self.resids_2 = resids[1]
    self.title = "Distance-difference matrix"

  def set_title(self, title):
    self.title = title

def draw_plot(ddm,
               figure):
  plot = figure.add_axes([0.1,0.1,0.8,0.8])
  im = plot.imshow(ddm.m.as_numpy_array(), origin="lower")
  plot.set_xlabel("Residue ID")
  plot.set_ylabel("Residue ID")
  xticklabels = []
  for x in plot.get_xticks():
    if (x >= 0) and (x < len(ddm.resids_1)):
      xticklabels.append(ddm.resids_1[int(x)])
    else :
      xticklabels.append("")
  plot.set_xticklabels(xticklabels)
  yticklabels = []
  for y in plot.get_yticks():
    if (y >= 0) and (y < len(ddm.resids_2)):
      yticklabels.append(ddm.resids_1[int(y)])
    else :
      yticklabels.append("")
  plot.set_yticklabels(yticklabels)
  cb = figure.colorbar(im, ax=plot, fraction=0.05, aspect=40)
  cb.set_label("Change in C-alpha:C-alpha distance")
  plot.set_title(ddm.title)

def display_plot_pylab(ddm, savefig=False):
  from matplotlib import pyplot as plt
  figure = plt.figure(figsize=(12,10))
  draw_plot(ddm, figure)
  if (savefig):
    figure.savefig("distance_difference.png", format="png")
  else :
    plt.show()

def validate_params(params):
  params = params.calculate_matrix
  for i in [1,2] :
    file_param = getattr(params, "model_%d" % i)
    chain_param = getattr(params, "chain_%d" % i)
    if (file_param is None):
      raise Sorry("Missing file for model_%d!" % i)
    elif (not os.path.isfile(file_param)):
      raise Sorry("%s is not a file or does not exist." % file_param)
    if (chain_param is not None) and ((len(chain_param) > 2) or
        (len(chain_param) == 0)):
      raise Sorry(("Invalid chain ID '%s' - must be 1 or 2 characters in "+
        "length if explicitly set.") % chain_param)
  return True

if (__name__ == "__main__"):
  run(sys.argv[1:], display_plot=True)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/dynamics.py
# LIBTBX_SET_DISPATCHER_NAME phenix.dynamics

from __future__ import absolute_import, division, print_function
from mmtbx.command_line import geometry_minimization
import iotbx.phil
from scitbx.array_family import flex
from libtbx.utils import user_plus_sys_time, Usage
from libtbx import runtime_utils
from libtbx.str_utils import make_header
import os
import sys

master_params_str = """
%s
dynamics_type = *cartesian
  .type = choice
stop_at_diff = None
  .type = float
  .help = stop after reaching specified cutoff value
cartesian_dynamics
  .short_caption = Cartesian dynamics
{
  include scope mmtbx.dynamics.cartesian_dynamics.master_params
}""" % geometry_minimization.base_params_str

def master_params():
  return iotbx.phil.parse(master_params_str, process_includes=True)

def run_cartesian_dynamics(
    xray_structure,
    states_collector,
    restraints_manager,
    params,
    stop_at_diff,
    log):
  from mmtbx.dynamics import cartesian_dynamics
  make_header("Simple cartesian dynamics", out=log)
  sites_cart_start = xray_structure.sites_cart().deep_copy()
  gradients_calculator = \
    cartesian_dynamics.gradients_calculator_reciprocal_space(
      restraints_manager = restraints_manager,
      sites_cart         = xray_structure.sites_cart(),
      wc                 = 1)
  cartesian_dynamics.run(
    xray_structure=xray_structure,
    gradients_calculator=gradients_calculator,
    temperature=params.temperature,
    states_collector=states_collector,
    n_steps=params.number_of_steps,
    time_step=params.time_step,
    initial_velocities_zero_fraction=params.initial_velocities_zero_fraction,
    n_print=params.n_print,
    stop_cm_motion=params.stop_cm_motion,
    stop_at_diff=stop_at_diff,
    log=log,
    verbose=1)
  sites_cart_end = xray_structure.sites_cart()
  rmsd = sites_cart_end.rms_difference(sites_cart_start)
  print("", file=log)
  print("RMSD from starting structure: %.3f" % rmsd, file=log)
  return sites_cart_end

class run(geometry_minimization.run):
  _pdb_suffix = "shaken"
  def master_params(self):
    return master_params()

  def format_usage_message(self):
    raise Usage("""\
phenix.dynamics: perform simple dynamics to perturb a model
Usage examples:
  phenix.dynamics model.pdb
  phenix.dynamics model.pdb ligands.cif
""")

  def __execute(self):
    #
    self.caller(self.initialize,           "Initialization, inputs")
    self.caller(self.process_inputs,       "Processing inputs")
    self.caller(self.atom_selection,       "Atom selection")
    self.caller(self.get_restraints,       "Geometry Restraints")
    self.caller(self.dynamics,             "Dynamics")
    self.caller(self.write_pdb_file,       "Write PDB file")
    self.caller(self.write_geo_file,       "Write GEO file")
    #
    self.show_times()

  def atom_selection(self, prefix):
    self.selection = flex.bool(self.model.get_xray_structure().sites_cart().size(), True)
    geometry_minimization.broadcast(m=prefix, log = self.log)

  def dynamics(self, prefix):
    geometry_minimization.broadcast(m=prefix, log = self.log)
    self.sites_cart = self.model.get_sites_cart()
    if (self.params.dynamics_type == "cartesian"):
      sites_cart_result = run_cartesian_dynamics(
        xray_structure=self.model.get_xray_structure(),
        restraints_manager=self.model.get_restraints_manager(),
        states_collector=self.states_collector,
        params=self.params.cartesian_dynamics,
        stop_at_diff=self.params.stop_at_diff,
        log=self.log)
    else : # TODO
      raise NotImplementedError()
    self.model.set_sites_cart(sites_cart=sites_cart_result)

class launcher(runtime_utils.target_with_save_result):
  def run(self):
    os.mkdir(self.output_dir)
    os.chdir(self.output_dir)
    filename = run(args=self.args, log=sys.stdout,
                   use_directory_prefix=False).result_model_fname
    return os.path.join(self.output_dir, filename)

def validate_params(params):
  return geometry_minimization.validate_params(params)

def finish_job(result):
  return geometry_minimization.finish_job(result)

if(__name__ == "__main__"):
  timer = user_plus_sys_time()
  log = sys.stdout
  o = run(sys.argv[1:], log=log)
  tt = timer.elapsed()
  print("Overall runtime: %-8.3f" % tt, file=o.log)
  assert abs(tt-o.total_time) < 0.1 # guard against unaccounted times


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/electrons.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME mmtbx.development.electrons

from iotbx.cli_parser import run_program
from mmtbx.ligands import electrons

if __name__ == "__main__":
  run_program(electrons.Program)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/emringer.py
from __future__ import absolute_import, division, print_function

from iotbx.cli_parser import run_program
from mmtbx.programs import emringer
from six.moves import range

if __name__  ==  '__main__':
  run_program(program_class = emringer.Program)

#  =============================================================================
# old code - maybe necessary until GUI is updated

# LIBTBX_SET_DISPATCHER_NAME phenix.emringer
# LIBTBX_PRE_DISPATCHER_INCLUDE_SH PHENIX_GUI_ENVIRONMENT = 1
# LIBTBX_PRE_DISPATCHER_INCLUDE_SH export PHENIX_GUI_ENVIRONMENT

"""
Implementation of the EMRinger method, with plots, for use with the
EMRinger workflow.

References:
  Barad BA, Echols N, Wang RYR, Cheng YC, DiMaio F, Adams PD, Fraser JS. (2015)
  Side-chain-directed model and map validation for 3D Electron Cryomicroscopy.
  Nature Methods, in press.

  Lang PT, Ng HL, Fraser JS, Corn JE, Echols N, Sales M, Holton JM, Alber T.
  Automated electron-density sampling reveals widespread conformational
  polymorphism in proteins. Protein Sci. 2010 Jul;19(7):1420-31. PubMed PMID:
  20499387
"""

# Any software that wants to use the pkl output of this tool
# should import ringer_residue and ringer_chi from it.
#from __future__ import absolute_import, division, print_function
import libtbx.phil
from libtbx import easy_pickle
from libtbx.str_utils import make_header
from libtbx import runtime_utils
from libtbx.utils import Sorry
from iotbx.map_model_manager import map_model_manager
import time
import os
import sys

master_phil = libtbx.phil.parse("""
model = None
  .type = path
  .style = file_type:pdb bold input_file
  .short_caption = Model file
map_file = None
  .type = path
  .short_caption = CCP4 or MRC map
  .style = file_type:ccp4_map bold
map_coeffs = None
  .type = path
  .short_caption = Map coefficients
  .style = file_type:hkl input_file OnChange:extract_ringer_map_labels
map_label = 2FOFCWT, PH2FOFCWT
  .type = str
  .input_size = 200
  .short_caption = 2Fo-FC map labels
  .style = renderer:draw_map_arrays_widget noauto
sampling_angle = 5
  .type = int
  .input_size = 64
sampling_method = linear *spline direct
  .type = choice(multi = False)
grid_spacing = 1./5
  .type = float
scaling = *sigma volume
  .type = choice(multi = False)
rolling_window_threshold = 0
  .type = float(value_min = 0)
  .help = Threshold for calculating statistics across rolling windows of residues
skip_alt_confs = True
  .type = bool
nproc = 1
  .type = int
  .short_caption = Number of processors
  .input_size = 64
  .style = renderer:draw_nproc_widget
show_gui = False
  .type = bool
wrapping = None
  .type = bool
  .help = You can specify that the map wraps around the unit cell
ignore_symmetry_conflicts = False
  .type = bool
  .help = You can specify that the model and map symmetryies to not have to \
      match
output_base = None
  .type = str
output_dir = None
  .type = path
  .short_caption = Output directory
  .style = output_dir
include scope libtbx.phil.interface.tracking_params
""", process_includes = True)
master_params = master_phil # XXX Gui hack

def run(args, out = None, verbose = True, plots_dir = None):
  t0 = time.time()
  if (out is None) : out = sys.stdout
  import iotbx.phil
  cmdline = iotbx.phil.process_command_line_with_files(
    args = args,
    master_phil = master_phil,
    pdb_file_def = "model",
    reflection_file_def = "map_coeffs",
    map_file_def = "map_file",
    usage_string = """\
phenix.emringer model.pdb map.mrc [cif_file ...] [options]

%s
""" % __doc__)
  params = cmdline.work.extract()
  validate_params(params)
  from iotbx.data_manager import DataManager
  dm = DataManager()
  model = dm.get_model(params.model)
  crystal_symmetry_model = model.crystal_symmetry()
  hierarchy = model.get_hierarchy()
  map_coeffs = map_inp = None
  map_data, unit_cell = None, None
  if (params.map_coeffs is not None):
    mtz_in = cmdline.get_file(params.map_coeffs)
    mtz_in.check_file_type("hkl")
    best_guess = None
    best_labels = []
    all_labels = []
    for array in mtz_in.file_server.miller_arrays :
      if (array.info().label_string()  ==  params.map_label):
        map_coeffs = array
        break
      elif (params.map_label is None):
        if (array.is_complex_array()):
          labels = array.info().label_string()
          all_labels.append(labels)
          if (labels.startswith("2FOFCWT") or labels.startswith("2mFoDFc") or
              labels.startswith("FWT")):
            best_guess = array
            best_labels.append(labels)
    if (map_coeffs is None):
      if (len(all_labels)  ==  0):
        raise Sorry("No valid (pre-weighted) map coefficients found in file.")
      elif (best_guess is None):
        raise Sorry("Couldn't automatically determine appropriate map labels. "+
          "Choices:\n  %s" % "  \n".join(all_labels))
      elif (len(best_labels) > 1):
        raise Sorry("Multiple appropriate map coefficients found in file. "+
          "Choices:\n  %s" % "\n  ".join(best_labels))
      map_coeffs = best_guess
      print("  Guessing %s for input map coefficients"% best_labels[0], file = out)
  else :
    ccp4_map_in = cmdline.get_file(params.map_file)
    ccp4_map_in.check_file_type("ccp4_map")
    map_inp = ccp4_map_in.file_object
    base = map_model_manager(
      map_manager               = map_inp,
      model            = model,
      wrapping = params.wrapping,
      ignore_symmetry_conflicts = params.ignore_symmetry_conflicts)
    hierarchy = base.model().get_hierarchy()
    map_data = base.map_data()
    unit_cell = map_inp.grid_unit_cell()

  hierarchy.atoms().reset_i_seq()
  make_header("Iterating over residues", out = out)
  t1 = time.time()
  from mmtbx.ringer import iterate_over_residues
  results = iterate_over_residues(
    pdb_hierarchy = hierarchy,
    map_coeffs = map_coeffs,
    map_data  = map_data,
    unit_cell = unit_cell,
    params = params,
    log = out).results
  t2 = time.time()
  if (verbose):
    print("Time excluding I/O: %8.1fs" % (t2 - t1), file = out)
    print("Overall runtime:    %8.1fs" % (t2 - t0), file = out)
  if (params.output_base is None):
    pdb_base = os.path.basename(params.model)
    params.output_base = os.path.splitext(pdb_base)[0] + "_emringer"
  easy_pickle.dump("%s.pkl" % params.output_base, results)
  print("Wrote %s.pkl" % params.output_base, file = out)
  csv = "\n".join([ r.format_csv() for r in results ])
  open("%s.csv" % params.output_base, "w").write(csv)
  print("Wrote %s.csv" % params.output_base, file = out)
  if (plots_dir is None):
    plots_dir = params.output_base + "_plots"
  if (not os.path.isdir(plots_dir)):
    os.makedirs(plots_dir)
  from mmtbx.ringer import em_rolling
  from mmtbx.ringer import em_scoring
  import matplotlib
  matplotlib.use("Agg")
  make_header("Scoring results", out = out)
  scoring = em_scoring.main(
    file_name = params.output_base,
    ringer_result = results,
    out_dir = plots_dir,
    sampling_angle = params.sampling_angle,
    quiet = False,
    out = out)
  make_header("Inspecting chains", out = out)
  rolling_window_threshold = params.rolling_window_threshold
  rolling = em_rolling.main(
    ringer_results = results,
    dir_name = plots_dir,
    threshold = rolling_window_threshold, #scoring.optimal_threshold,
    graph = False,
    save = True,
    out = out)
  scoring.show_summary(out = out)
  print("\nReferences:", file = out)

  references = """\
  Barad BA, Echols N, Wang RYR, Cheng YC, DiMaio F, Adams PD, Fraser JS. (2015)
  Side-chain-directed model and map validation for 3D Electron Cryomicroscopy.
  Nature Methods, in press.

  Lang PT, Ng HL, Fraser JS, Corn JE, Echols N, Sales M, Holton JM, Alber T.
  Automated electron-density sampling reveals widespread conformational
  polymorphism in proteins. Protein Sci. 2010 Jul;19(7):1420-31. PubMed PMID:
  20499387"""
  print(references, file = out)
  if (params.show_gui):
    run_app(results)
  else :
    return (results, scoring, rolling)

def validate_params(params):
  if (params.model is None):
    raise Sorry("No PDB file supplied (parameter: model)")
  if (params.map_coeffs is None) and (params.map_file is None):
    raise Sorry("No map coefficients supplied (parameter: map_coeffs)")
  return True

class launcher(runtime_utils.target_with_save_result):
  def run(self):
    os.makedirs(self.output_dir)
    os.chdir(self.output_dir)
    return run(args = list(self.args), out = sys.stdout, plots_dir = "plots")

########################################################################
# GUI
try :
  import wx
except ImportError :
  def run_app(results):
    raise Sorry("wxPython not available.")
else :
  from wxtbx import plots

  def run_app(results):
    app = wx.App(0)
    frame = RingerFrame(None, -1, "Ringer results")
    frame.show_results(results)
    frame.Show()
    app.MainLoop()

  class RingerFrame(plots.plot_frame):
    def create_plot_panel(self):
      plot = RingerPlot(self, figure_size = (6, 8))
      plot.canvas.Bind(wx.EVT_CHAR, self.OnChar)
      return plot

    def draw_top_panel(self):
      self.top_panel = wx.Panel(self, style = wx.SUNKEN_BORDER)
      panel_szr = wx.BoxSizer(wx.VERTICAL)
      self.top_panel.SetSizer(panel_szr)
      szr2 = wx.BoxSizer(wx.HORIZONTAL)
      panel_szr.Add(szr2)
      txt1 = wx.StaticText(self.top_panel, -1, "Residue to display:")
      szr2.Add(txt1, 0, wx.ALL|wx.ALIGN_CENTER_VERTICAL, 5)
      self.chooser = wx.Choice(self.top_panel, -1, size = (200, -1))
      szr2.Add(self.chooser, 0, wx.ALL|wx.ALIGN_CENTER_VERTICAL, 5)
      self.Bind(wx.EVT_CHOICE, self.OnSelect, self.chooser)
      self.Bind(wx.EVT_CHAR, self.OnChar)
      self.chooser.Bind(wx.EVT_CHAR, self.OnChar)
      return self.top_panel

    def OnSelect(self, event):
      selection = event.GetEventObject().GetSelection()
      self.plot_panel.show_residue(self.results[selection])

    def show_results(self, results):
      self.results = results
      choices = [ result.format() for result in results ]
      self.chooser.SetItems(choices)
      self.chooser.SetSelection(0)
      self.plot_panel.show_residue(self.results[0])

    def OnChar(self, event):
      key = event.GetKeyCode()
      if (len(self.results)  ==  0) : return
      selection = self.chooser.GetSelection()
      if (key in [wx.WXK_TAB, wx.WXK_RETURN, wx.WXK_SPACE]):
        if (selection < (len(self.results) - 1)):
          selection +=  1
        elif (len(self.results) > 0):
          selection = 0
      elif (key in [wx.WXK_DELETE, wx.WXK_BACK]):
        if (selection > 0):
          selection -=  1
        else :
          selection = len(results) - 1
      self.chooser.SetSelection(selection)
      self.plot_panel.show_residue(self.results[selection])

  class RingerPlot(plots.plot_container):
    def show_residue(self, residue, show_background_boxes = False):
      if (self.disabled) : return
      self.figure.clear()
      subplots = []
      for i in range(1, residue.n_chi + 1):
        chi = residue.get_angle(i)
        if (chi is None) : continue
        if (len(subplots) > 0):
          p = self.figure.add_subplot(4, 1, i, sharex = subplots[0])
        else :
          p = self.figure.add_subplot(4, 1, i)
          p.set_title(residue.format())
        p.set_position([0.15, 0.725 - 0.225*(i-1), 0.8, 0.225])
        x = [ k*chi.sampling for k in range(len(chi.densities)) ]
        p.plot(x, chi.densities, 'r-', linewidth = 1)
        p.axvline(chi.angle_current, color = 'b', linewidth = 2, linestyle = '--')
        p.axvline(chi.peak_chi, color = 'g', linewidth = 2, linestyle = '--')
        p.axhline(0, color = (0.4, 0.4, 0.4), linestyle = '--', linewidth = 1)
        if show_background_boxes:
          p.axhspan(0.3, 1, facecolor = "green", alpha = 0.5)
          p.axhspan(-1, 0.3, facecolor = "grey", alpha = 0.5)
        p.set_xlim(0, 360)
        p.set_ylabel("Rho")
        p.set_xlabel("Chi%d" % i)
        subplots.append(p)
      for p in subplots[:-1] :
        for label in p.get_xticklabels():
          label.set_visible(False)
      p.text(0, -0.5, 'Green = Peak, Blue = Modelled',
          transform = ax.transAxes)
      self.canvas.draw()
      self.canvas.Fit()
      self.Layout()
      self.parent.Refresh()

#if (__name__  ==  "__main__"):
#  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/emringer_score.py

"""
Standalone tool for analyzing output of phenix.emringer and rendering plots,
as described in:

  Barad BA, Echols N, Wang RYR, Cheng YC, DiMaio F, Adams PD, Fraser JS. (2015)
  Side-chain-directed model and map validation for 3D Electron Cryomicroscopy.
  Nature Methods, in press.
"""

from __future__ import absolute_import, division, print_function
import mmtbx.ringer.em_scoring
import argparse
import os.path
import sys

def run(args, out=sys.stdout):
    parser = argparse.ArgumentParser()
    parser.add_argument("files",nargs="*")
    parser.add_argument("-s", "--Sampling_Angle", dest="sampling_angle", help="Don't mess with this unless you've also made the corresponding change in ringer. By default it is 5, which is identical to the default in ringer.", nargs='?', default=5)
    parser.add_argument("-r", "--Residues", dest="residues")
    parser.add_argument("--gui", dest="show_gui", action="store_true",
      default=False)
    args = parser.parse_args(args)
    #if (not args.show_gui):
    try :
      import matplotlib
    except ImportError as e :
      print("WARNING: matplotlib not present, plotting disabled", file=out)
      matplotlib = None
      args.show_gui = False
    else :
      matplotlib.use("Agg")
    app = None
    for file_name in args.files :
      result = mmtbx.ringer.em_scoring.main(
        file_name=file_name,
        sampling_angle=args.sampling_angle,
        out=out,
        quiet=(matplotlib is None)).show_summary(out=out)
      file_name = os.path.basename(file_name)
      if (args.show_gui):
        import wxtbx.plots.emringer
        import wxtbx.app
        if (app is None):
          app = wxtbx.app.CCTBXApp(0)
        f1 = wxtbx.plots.emringer.peaks_plot_frame(
          parent=None,
          title="Histogramss for %s" % file_name)
        f1.SetResult(result)
        f1.Show()
        f2 = wxtbx.plots.emringer.threshold_plot_frame(
          parent=None,
          title="Statistics across all thresholds for %s" % file_name)
        f2.SetResult(result)
        f2.Show()
    if (args.show_gui):
      app.MainLoop()

if __name__ == "__main__":
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/estimate_bijvoet_ratio.py

from __future__ import absolute_import, division, print_function
from libtbx.utils import Sorry
from math import sqrt
import sys

master_phil_str = """
element = None
  .type = str
  .help = Anomalously scattering atom type
n_sites = None
  .type = int
fdp = None
  .type = float
wavelength = None
  .type = float
  .help = Data collection wavelength (in Angstroms)
energy = None
  .type = float
  .help = Data collection energy (in eV)
n_res = None
  .type = int
  .help = Number of residues in ASU
mw = None
  .type = float
  .help = Molecular weight of ASU
"""


def run(args, out=sys.stdout, params=None):
  import iotbx.phil
  from cctbx.eltbx import chemical_elements, sasaki
  class interpreter(iotbx.phil.process_command_line_with_files):
    def process_other(self, arg):
      if (len(arg) <= 2):
        if (arg.upper() in chemical_elements.proper_upper_list()):
          return iotbx.phil.parse("element=%s" % arg)
  if (params is None):
    cmdline = interpreter(
      args=args,
      master_phil_string=master_phil_str,
      integer_def="n_sites",
      float_def="fdp",
      usage_string="""\
mmtbx.estimate_bijvoet_ratios Se 20 n_res=1000 wavelength=0.9792

Estimate the Bijvoet ratio for a macromolecular X-ray diffraction experiment
given an anomalous scatterer type and expected asymmetric unit contents.""")
    params = cmdline.work.extract()
  validate_params(params)
  fdp = params.fdp
  if (fdp is None):
    if (params.wavelength is not None):
      fdp = sasaki.table(params.element).at_angstrom(params.wavelength).fdp()
      caption = "%s A" % params.wavelength
    else :
      fdp = sasaki.table(params.element).at_ev(params.energy).fdp()
      caption = "%s eV" % params.energy
  if (params.n_res is not None):
    n_atoms = params.n_res * 110 / 15
  else :
    n_atoms = params.mw / 15
  bijvoet_ratio_acentric = sqrt(2 * params.n_sites / n_atoms) * (fdp / 6.7)
  print("Heavy atom type: %s" % params.element, file=out)
  print("Number of sites: %d" % params.n_sites, file=out)
  print("Approx. # of non-H/D atoms: %d" % n_atoms, file=out)
  if (params.fdp is None):
    print("f'' of %s at %s : %6.3f" % (params.element, caption, fdp), file=out)
  else :
    print("f'' (experimental) : %6.3f" % fdp, file=out)
  print("Expected Bijvoet ratio : %4.1f%%" % \
    (bijvoet_ratio_acentric * 100), file=out)
  return bijvoet_ratio_acentric

def validate_params(params):
  from cctbx.eltbx import chemical_elements
  all_elems = chemical_elements.proper_upper_list()
  if (params.element is None):
    raise Sorry("Element symbol not specified.")
  elif (not params.element.upper() in all_elems):
    raise Sorry("Element symbol '%s' not recognized." % params.element)
  if (params.n_sites is None):
    raise Sorry("Number of sites not specified.")
  if ([params.fdp, params.energy, params.wavelength].count(None) != 2):
    print([params.fdp, params.energy, params.wavelength])
    raise Sorry("Please specify either an X-ray wavelength or energy "+
      "(but not both), or the expected f''.")
  if ([params.n_res, params.mw].count(None) != 1):
    raise Sorry("Please specify either the number of residues or the "+
      "approximate molecular weight (but not both).")
  return True

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/f000.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.f000

import sys
import iotbx.pdb
from libtbx.utils import Sorry
import mmtbx.utils

legend = """phenix.f000: Given PDB file estimate F(0,0,0)

How to run:
  phenix.f000 model.pdb
  phenix.f000 model.pdb mean_solvent_density=0.44
"""

master_params_str = """
mean_solvent_density=0.35
  .type=float
"""

def master_params():
  return iotbx.phil.parse(master_params_str)

def run(args, log=sys.stdout):
  print("-"*79, file=log)
  print(legend, file=log)
  print("-"*79, file=log)
  inputs = mmtbx.utils.process_command_line_args(args = args,
    master_params = master_params())
  file_names = inputs.pdb_file_names
  if(len(file_names) != 1): raise Sorry("One PDB file is expected.")
  xrs = iotbx.pdb.input(file_name = file_names[0]).xray_structure_simple()
  msd = inputs.params.extract().mean_solvent_density
  f_000 = mmtbx.utils.f_000(xray_structure=xrs,
    mean_solvent_density=msd)
  f_000_str = str("%-13.3f"%f_000.f_000).strip()
  msd_str = str("%-6.3f"%msd).strip()
  sf_str = str("%-6.3f"%f_000.solvent_fraction).strip()
  msg = """
Estimate of F(0,0,0)=%s given mean bulk-solvent density %s and fraction %s
"""
  print(msg%(f_000_str, msd, sf_str), file=log)

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/fab_elbow_angle.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.fab_elbow_angle
from mmtbx.utils.fab_elbow_angle import fab_elbow_angle
import iotbx.pdb
import sys
import iotbx.phil

def get_master_phil():
  import libtbx.phil
  return libtbx.phil.parse(
    input_string="""
      model_file_name = None
        .type = path
        .multiple = True
        .help = '''Enter a PDB file name'''
      light = 'L'
        .type = str
        .help = '''chain ID of light domain'''
      heavy = 'H'
        .type = str
        .help = '''chain ID of heavy domain'''
      limit_l = 107
        .type = int
        .help = the number of the residue separating between variable \
            and constant domains in the light chain
      limit_h = 113
        .type = int
        .help = the number of the residue separating between variable \
            and constant domains in the heavy chain, by default 113
""")

def usage():
  return """
  Calculating Fragment Antigen-Binding (Fab) elbow angle

  Each FAB is made of two chains, Heavy (H) and Light (L), and two domains,
  Variable (V) and Constant (C or C1, The heavy domain has three parts).
  The angle between the variable and constant domains is the elbow angle.
  It is the angle between rotation axes, the pseudo-dyad axes,
  defined by aligning the light portion of each domain, on-to the heavy one.

  command line options:
  light        chain ID of light domain, by default set to L
  heavy        chain ID of heavy domain, by default set to H
  limit_l      the number of the residue separating between variable
               and constant domains in the light chain, by default 107
  limit_H      the number of the residue separating between variable
               and constant domains in the heavy chain, by default 113
  h            help

  usage:
  phenix.fab_elbow_angle fab_name.pdb [light=L] [heavy=H] [limit_l=107] [limit_h=113]

  examples:
  >>>phenix.fab_elbow_angle 7fab.pdb light=L heavy=H limit_l=104 limit_h=117
  >>>123.00
  >>>phenix.fab_elbow_angle 1bbd.pdb
  >>>126.34
  """

def run(args, log=sys.stdout):
  master_phil = get_master_phil()
  input_objects = iotbx.phil.process_command_line_with_files(
    args=args,
    master_phil=master_phil,
    pdb_file_def="model_file_name")
  work_params = input_objects.work.extract()
  if len(work_params.model_file_name) != 1:
    print(usage(), file=log)
    return

  ph = iotbx.pdb.input(file_name=work_params.model_file_name[0]).construct_hierarchy()
  elbow_angle = fab_elbow_angle(
      pdb_hierarchy=ph,
      chain_id_light=work_params.light,
      chain_id_heavy=work_params.heavy,
      limit_light=work_params.limit_l,
      limit_heavy=work_params.limit_h).fab_elbow_angle
  print('fab elbow angle (deg): {0:.2f}'.format(elbow_angle), file=log)

if __name__ == "__main__":
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/fake_f_obs.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.fake_f_obs

from cctbx import adptbx
from cctbx.array_family import flex
import random, math, sys, os
import iotbx.pdb
import mmtbx.utils
from libtbx import easy_run
import mmtbx.dynamics.cartesian_dynamics as cartesian_dynamics
from mmtbx import monomer_library
import mmtbx.monomer_library.pdb_interpretation
import mmtbx.monomer_library.server
from mmtbx.tls import ladp
from mmtbx.utils import run_reduce_with_timeout
import mmtbx.tls.tools
import mmtbx.f_model
import iotbx.phil
import mmtbx.masks
from libtbx.utils import Sorry
from six.moves import range
import mmtbx.model

if(1):
  random.seed(0)
  flex.set_random_seed(0)

master_params_str="""\
f_obs {
  high_resolution = 2.0
    .type = float
  low_resolution = 15.0
    .type = float
  scattering_table = wk1995 it1992 *n_gaussian neutron
  f_calc {
    atomic_model {
      ensemble_size = 20
        .type = int
      add_hydrogens = False
        .type = bool
      tls {
        max_tl = 2
          .type = float
        min_tl = 0
          .type = float
      }
      apply_cartesian_dynamics = True
        .type = bool
      regularize_geometry {
        rmsd_bonds_target = 0.025
          .type = float
        rmsd_angles_target = 2.5
          .type = float
      }
      ladp_angle = 3.0
        .type = float
      switch_rotamers = True
        .type = bool
      shake_sites_rmsd = 0.01
        .type = float
      rigid_body_shift {
        rotation_angle = 1.0
          .type = float
        translation_length = 0.1
          .type = float
      }
      stop_cartesian_dynamics_at_diff = 0.5
        .type = float
      use_ramachandran_plot_restraints = True
        .type = bool
      output_file_name = fake_model.pdb
        .type = str
    }
    accuracy {
      include scope mmtbx.f_model.sf_and_grads_accuracy_master_params
    }
  }
  f_bulk {
    k_sol = 0.35
      .type = float
    b_sol = 50.0
      .type = float
    mask {
      include scope mmtbx.masks.mask_master_params
    }
  }
  overall_scale = 1.0
  overall_anisotropic_scale_matrix_b_cart {
    max = 10
      .type = float
    min = 0
      .type = float
  }
  experimental_noise {
    add_random_error_to_amplitudes_percent = 5
      .type = float
  }
  output_file_name = fake_f_obs.mtz
    .type = str
}

"""

class show(object):
  def __init__(self,
               xrs,
               xrs_start,
               grm,
               prefix=""):
    esg = grm.energies_sites(
      sites_cart = xrs.sites_cart(), compute_gradients = False).geometry
    self.bond_rmsd = esg.bond_deviations()[2]
    self.angle_rmsd = esg.angle_deviations()[2]
    self.error = flex.mean(xrs.distances(other = xrs_start))
    print("  %s err=%8.3f rmsd: bonds=%6.3f angles=%6.3f"%(prefix, self.error,
      self.bond_rmsd, self.angle_rmsd))

def switch_rotamers(xray_structure, pdb_hierarchy):
  x = xray_structure.deep_copy_scatterers()
  p = pdb_hierarchy.deep_copy()
  p.atoms().reset_i_seq()
  p = mmtbx.utils.switch_rotamers(
    pdb_hierarchy = p,
    mode = "min_distant")
  x.set_sites_cart(sites_cart = p.atoms().extract_xyz())
  return x, p

def set_ladp(xray_structure, pdb_hierarchy, angle):
  axes_and_atoms_i_seqs = ladp.get_axes_and_atoms_i_seqs(
    pdb_hierarchy = pdb_hierarchy,
    mon_lib_srv   = monomer_library.server.server())
  xray_structure = xray_structure.set_b_iso(value=random.randrange(5,10))
  xray_structure.convert_to_isotropic()
  xray_structure = ladp.set_ladp(
    xray_structure        = xray_structure,
    axes_and_atoms_i_seqs = axes_and_atoms_i_seqs,
    value                 = angle,
    enable_recursion      = True,
    depth                 = 0)
  return xray_structure

def random_aniso_adp(space_group, unit_cell, u_scale=2, u_min=0):
  return adptbx.u_star_as_u_cart(unit_cell, space_group.average_u_star(
    u_star = adptbx.u_cart_as_u_star(unit_cell, adptbx.random_u_cart(
      u_scale=u_scale, u_min=u_min))))

def apply_tls(xray_structure, params):
  uc = xray_structure.unit_cell()
  sg = xray_structure.space_group()
  selections_1d = flex.bool(xray_structure.scatterers().size(),True)
  selections = [selections_1d.iselection()]
  T=random_aniso_adp(space_group=sg, unit_cell=uc, u_scale=params.max_tl,
    u_min=params.min_tl)
  L=random_aniso_adp(space_group=sg, unit_cell=uc, u_scale=params.max_tl,
    u_min=params.min_tl)
  print("  T: %s"%",".join([("%7.3f"%i).strip() for i in T]))
  print("  L: %s"%",".join([("%7.3f"%i).strip() for i in L]))
  tlsos = mmtbx.tls.tools.generate_tlsos(
    selections     = selections,
    xray_structure = xray_structure,
    T=[T],
    L=[L],
    S=[[0,0,0,0,0,0,0,0,0]])
  u_cart_from_tls = mmtbx.tls.tools.u_cart_from_tls(
    sites_cart = xray_structure.sites_cart(),
    selections = selections,
    tlsos      = tlsos)
  xray_structure.convert_to_anisotropic()
  u_cart = xray_structure.scatterers().extract_u_cart(uc)
  utot = u_cart_from_tls+u_cart
  xray_structure.set_u_cart(u_cart=utot, selection = selections_1d.iselection())
  xray_structure.tidy_us()
  return xray_structure

def apply_rigid_body_shift(xray_structure, params):
  import scitbx.matrix
  mt = flex#.mersenne_twister(seed=0)
  rot_axis = scitbx.matrix.col(mt.random_double_point_on_sphere())
  rot_matrix = scitbx.math.r3_rotation_axis_and_angle_as_matrix(
    axis=rot_axis, angle=params.rotation_angle, deg=True)
  run_away_counter = 0
  while True:
    transl = mt.random_double_point_on_sphere()
    transl_no_cont_sh = scitbx.matrix.col(xray_structure.crystal_symmetry()
      .subtract_continuous_allowed_origin_shifts(translation_cart=transl))
    l = abs(transl_no_cont_sh)
    if(l > 0.1):
      break
    run_away_counter += 1
    print("run_away_counter", run_away_counter, l)

  assert run_away_counter < 100
  transl = transl_no_cont_sh * (params.translation_length/l)
  sites_cart = xray_structure.sites_cart()
  cm = xray_structure.center_of_mass()
  ns = rot_matrix * (sites_cart-cm) + transl + cm
  xray_structure.set_sites_cart(sites_cart =
    rot_matrix * (sites_cart-cm) + transl + cm)
  return xray_structure

def simulate_f_obs(root, crystal_symmetry, params):
  f_calc_data = None
  f_masks_data = []
  for i_m, m in enumerate(root.models()):
    raw_records = flex.std_string()
    raw_records.append(
      iotbx.pdb.format_cryst1_record(crystal_symmetry = crystal_symmetry))
    for atom in m.atoms():
      ra = atom.format_atom_record()
      ru = atom.format_anisou_record()
      raw_records.append(ra[:])
      raw_records.append(ru[:])
    xrs = iotbx.pdb.input(lines = raw_records,
      source_info=None).xray_structure_simple()
    if(i_m==0):
      dummy = abs(xrs.structure_factors(
        d_min=params.f_obs.high_resolution).f_calc())
      dummy = dummy.resolution_filter(d_max = params.f_obs.low_resolution)
    fmodel = mmtbx.f_model.manager(
      f_obs          = dummy,
      xray_structure = xrs,
      mask_params    = params.f_obs.f_bulk.mask,
      sf_and_grads_accuracy_params = params.f_obs.f_calc.accuracy)
    fcd = fmodel.f_calc().data()
    fms = fmodel.f_masks()
    if(i_m==0):
      f_calc_data = fcd
      f_masks_data = []
      for f in fms:
        f_masks_data.append(f.data())
    else:
      f_calc_data += fcd
      fmsks = fms
      assert len(f_masks_data) == len(fmsks)
      for ifmd in range(len(f_masks_data)):
        f_masks_data[ifmd] += fmsks[ifmd].data()
  fcalc_average = fmodel.f_obs().array(data = f_calc_data)
  f_masks_data_average = []
  for f in f_masks_data:
    f_masks_data_average.append(fmodel.f_obs().array(data = f/len(root.models())))
  b_cart = None
  if([params.f_obs.overall_anisotropic_scale_matrix_b_cart.max,
      params.f_obs.overall_anisotropic_scale_matrix_b_cart.min].count(None)==0):
    b_cart = random_aniso_adp(
      space_group=crystal_symmetry.space_group(),
      unit_cell=crystal_symmetry.unit_cell(),
      u_scale=params.f_obs.overall_anisotropic_scale_matrix_b_cart.max,
      u_min=params.f_obs.overall_anisotropic_scale_matrix_b_cart.min)
    print("\noverall_anisotropic_scale_matrix_b_cart: %s"%",".join(
      [("%7.3f"%i).strip() for i in b_cart]))
  fmodel = mmtbx.f_model.manager(
    f_obs  = dummy,
    f_calc = fcalc_average,
    f_mask = f_masks_data_average,
    k_sol  = params.f_obs.f_bulk.k_sol,
    b_sol  = params.f_obs.f_bulk.b_sol,
    b_cart = b_cart)
  #
  f_obs = abs(fmodel.f_model())
  f_obs.set_observation_type_xray_amplitude()
  mtz_dataset = f_obs.as_mtz_dataset(column_root_label="F(ake)obs")
  r_free_flags = f_obs.generate_r_free_flags()
  mtz_dataset.add_miller_array(
    miller_array=r_free_flags, column_root_label="R-free-flags")
  mtz_object = mtz_dataset.mtz_object()
  mtz_object.write(file_name=params.f_obs.output_file_name)

def regularize_geometry(xray_structure, restraints_manager, params):
  from mmtbx.refinement import geometry_minimization as gm
  import scitbx.lbfgs
  sites_cart = xray_structure.sites_cart()
  minimized = gm.lbfgs(
    sites_cart = sites_cart,
    correct_special_position_tolerance = 1.0,
    geometry_restraints_manager = restraints_manager.geometry,
    geometry_restraints_flags = gm.geometry_restraints.flags.flags(default=True),
    rmsd_bonds_termination_cutoff=params.rmsd_bonds_target,
    rmsd_angles_termination_cutoff=params.rmsd_angles_target,
    lbfgs_termination_params=scitbx.lbfgs.termination_parameters(
      max_iterations=500))
  xray_structure = xray_structure.replace_sites_cart(new_sites = sites_cart)
  return xray_structure

def cd(xray_structure, restraints_manager, params):
  gradients_calculator=cartesian_dynamics.gradients_calculator_reciprocal_space(
    restraints_manager = restraints_manager,
    sites_cart         = xray_structure.sites_cart(),
    wc                 = 1)
  cartesian_dynamics.run(
    gradients_calculator             = gradients_calculator,
    xray_structure                   = xray_structure,
    temperature                      = 3000,
    n_steps                          = 500000,
    time_step                        = 0.0005,
    initial_velocities_zero_fraction = 0,
    n_print                          = 100,
    stop_cm_motion                   = True,
    log                              = None,
    stop_at_diff                     = params.stop_cartesian_dynamics_at_diff,
    verbose                          = -1)

def loop_2(params, xray_structure, pdb_hierarchy, restraints_manager, root):
  print("model:")
  amp = params.f_obs.f_calc.atomic_model
  grm = restraints_manager
  xrs = xray_structure.deep_copy_scatterers()
  show(xrs = xrs, xrs_start = xrs, grm = grm, prefix = "start:")
  xrs_sh = xrs.deep_copy_scatterers()
  if(amp.shake_sites_rmsd is not None):
    xrs_sh.shake_sites_in_place(rms_difference = amp.shake_sites_rmsd)
  if(amp.apply_cartesian_dynamics):
    cd(xray_structure = xrs_sh, restraints_manager = grm, params = amp)
    show(xrs = xrs_sh, xrs_start = xrs, grm = grm, prefix = "cd:   ")
  if([amp.regularize_geometry.rmsd_bonds_target,
      amp.regularize_geometry.rmsd_angles_target].count(None)==0):
    xrs_sh = regularize_geometry(xray_structure = xrs_sh,
      restraints_manager = grm, params = amp.regularize_geometry)
    show(xrs = xrs_sh, xrs_start = xrs, grm = grm, prefix = "min:  ")
  if(amp.ladp_angle is not None):
    xrs_sh = set_ladp(xray_structure = xrs_sh, pdb_hierarchy = pdb_hierarchy,
      angle = amp.ladp_angle)
  if([amp.tls.max_tl, amp.tls.min_tl].count(None)==0):
    xrs_sh = apply_tls(xray_structure = xrs_sh, params = amp.tls)
  if([amp.rigid_body_shift.rotation_angle,
      amp.rigid_body_shift.translation_length].count(None)==0):
    if xrs.crystal_symmetry().space_group().type().number()!=1:
      xrs_sh = apply_rigid_body_shift(xray_structure = xrs_sh,
        params = amp.rigid_body_shift)
      show(xrs = xrs_sh, xrs_start = xrs, grm = grm, prefix = "rb:   ")
  #
  h = pdb_hierarchy.deep_copy()
  h.atoms().reset_i_seq() # XXX
  h.atoms().set_xyz(xrs_sh.sites_cart().deep_copy())
  h.atoms().set_uij(xrs_sh.scatterers().extract_u_cart(xrs_sh.unit_cell()))
  h.atoms().set_b(xrs_sh.extract_u_iso_or_u_equiv()*adptbx.u_as_b(1.))
  m = h.models()[0].detached_copy()
  m.id = str(None)
  root.append_model(m)

def loop_1(params, root, xray_structure, pdb_hierarchy, restraints_manager):
  xh = [(xray_structure,pdb_hierarchy)]
  if(params.f_obs.f_calc.atomic_model.switch_rotamers):
    xh.append(switch_rotamers(
      xray_structure = xray_structure.deep_copy_scatterers(),
      pdb_hierarchy = pdb_hierarchy.deep_copy()))
  counter = 0
  size = int(math.ceil(params.f_obs.f_calc.atomic_model.ensemble_size/len(xh)))
  for xh_ in xh:
    x_, h_ = xh_
    for mc in range(size):
      loop_2(
        params         = params,
        xray_structure = x_,
        pdb_hierarchy  = h_,
        restraints_manager = restraints_manager,
        root               = root)
  for i_model, model in enumerate(root.models()):
    model.id = str(i_model)
  root.atoms().set_occ(root.atoms().extract_occ()/len(root.models()))

def defaults(log):
  print("Default params::\n", file=log)
  parsed = iotbx.phil.parse(master_params_str, process_includes=True)
  print(file=log)
  return parsed

def run(args, log = sys.stdout):
  if(len(args)==0):
    parsed = defaults(log=log)
    parsed.show(prefix="  ", out=log)
    return
  parsed = defaults(log=log)
  processed_args = mmtbx.utils.process_command_line_args(args = args,
    log = sys.stdout, master_params = parsed)
  processed_args.params.show()
  params = processed_args.params.extract()
  if(len(processed_args.pdb_file_names)==0):
    raise Sorry("No PDB file found.")
  if(len(processed_args.pdb_file_names)>1):
    raise Sorry("More than one PDB file found.")
  pdb_file_name = processed_args.pdb_file_names[0]
  if(params.f_obs.f_calc.atomic_model.add_hydrogens):
    pdb_file_name_r = os.path.basename(pdb_file_name)+"_reduce"
    # easy_run.go("phenix.reduce %s > %s"% (pdb_file_name, pdb_file_name_r))
    run_reduce_with_timeout(file_name=pdb_file_name, parameters=" > %s" % pdb_file_name_r)
    pdb_file_name = pdb_file_name_r
  pdbi_params = mmtbx.model.manager.get_default_pdb_interpretation_params()
  if(params.f_obs.f_calc.atomic_model.use_ramachandran_plot_restraints):
    pdbi_params.pdb_interpretation.ramachandran_plot_restraints.enabled=True
  model = mmtbx.model.manager(
    model_input = iotbx.pdb.input(file_name = pdb_file_name))
  model.process(make_restraints=True,
    pdb_interpretation_params = pdbi_params)
  root = iotbx.pdb.hierarchy.root()
  loop_1(
    params             = params,
    root               = root,
    xray_structure     = model.get_xray_structure(),
    pdb_hierarchy      = model.get_hierarchy(),
    restraints_manager = model.get_restraints_manager())
  root.write_pdb_file(
    file_name = params.f_obs.f_calc.atomic_model.output_file_name,
    crystal_symmetry = model.crystal_symmetry())
  simulate_f_obs(root=root, crystal_symmetry=model.crystal_symmetry(),
    params = params)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/fetch_pdb.py
from __future__ import absolute_import, division, print_function

# LIBTBX_SET_DISPATCHER_NAME phenix.fetch_pdb
# LIBTBX_SET_DISPATCHER_NAME iotbx.fetch_pdb

from iotbx.cli_parser import run_program
from mmtbx.programs import fetch

def custom_args_proc(cli_parser):
  wf = cli_parser.working_phil.extract()
  if len(cli_parser.namespace.unknown) > 0:
    # print("What is unknown: %s" % cli_parser.namespace.unknown)
    # print("Curr selection: '%s'" % wf.fetch.pdb_ids)
    res = []
    for unk in cli_parser.namespace.unknown:
      res += unk.replace(',',' ').split()
    wf.fetch.pdb_ids = res
    cli_parser.namespace.unknown = []
  cli_parser.working_phil = cli_parser.master_phil.format(python_object=wf)

if (__name__ == "__main__"):
  run_program(program_class=fetch.Program, custom_process_arguments=custom_args_proc)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/find_peaks_holes.py
# LIBTBX_SET_DISPATCHER_NAME phenix.find_peaks_holes
# LIBTBX_SET_DISPATCHER_NAME mmtbx.find_peaks_holes

# simple frontend to mmtbx.find_peaks, primarily intended for use in quickly
# analyzing structures in the PDB (and storing results)

from __future__ import absolute_import, division, print_function
from mmtbx import utils
from scitbx.array_family import flex
from libtbx.str_utils import make_header, format_value
from libtbx import runtime_utils
from libtbx.utils import Sorry
import libtbx.phil
from libtbx import adopt_init_args, group_args
from iotbx.pdb.hybrid_36 import hy36encode
import operator
import os
import sys
from six.moves import zip

def get_master_phil():
  from mmtbx.command_line import generate_master_phil_with_inputs
  return generate_master_phil_with_inputs(
    enable_automatic_twin_detection=True,
    phil_string="""
find_peaks
  .style = auto_align
{
  include scope mmtbx.find_peaks.master_params
}
map_cutoff = 3.0
  .type = float
  .short_caption = mFo-DFc map cutoff (sigma)
anom_map_cutoff = 3.0
  .type = float
  .short_caption = Anomalous map cutoff (sigma)
include_peaks_near_model = False
  .type = bool
  .short_caption = Don't filter peaks by distance to model
  .help = By default, the program will only display peaks that map to points \
    outside of the current model, ignoring those that overlap with atoms.  \
    Setting this option to True is equivalent to specifying a distance \
    cutoff of zero for the filtering step.
  .style = OnChange:toggle_min_model_peak_dist
wavelength = None
  .type = float
  .help = Optional parameter, if defined this will cause all atoms to be \
    treated as anomalous scatterers using the standard Sasaki table to \
    obtain theoretical fp and fpp values.  Only really useful if the Phaser \
    LLG map is being used for the anomalous map.
filter_peaks_by_2fofc = None
  .type = float
  .short_caption = Filter peaks by 2mFo-DFc
  .help = If this is set, peaks outside 2mFo-DFc density at the \
    cutoff will be discarded.  (This does not apply to the analysis of \
    solvent atoms.)  Holes will not be changed.
use_phaser_if_available = True
  .type = bool
  .short_caption = Use Phaser LLG map
  .help = If True, and Phaser is installed and configured, an anomalous LLG \
    map will be used in place of the simple anomalous difference map.  The \
    wavelength should be specified for this to be maximally useful.
write_pdb = True
  .type = bool
  .short_caption = Write peaks to PDB file
write_maps = True
  .type = bool
  .short_caption = Save map coefficients
output_file_prefix = peaks_holes
  .type = str
include scope libtbx.phil.interface.tracking_params
""")

master_phil = get_master_phil()
master_params = master_phil # for phenix GUI

class peaks_holes_container(object):
  def __init__(self, peaks, holes, map_cutoff=3.0, anom_peaks=None,
      anom_map_cutoff=3.0, water_peaks=None, water_anom_peaks=None,
      non_water_anom_peaks=None):
    adopt_init_args(self, locals())
    # XXX pre-sort all lists
    self.peaks.sort(reverse=True)
    self.holes.sort()
    if (self.anom_peaks is not None):
      self.anom_peaks.sort(reverse=True)
    if (self.water_peaks is not None):
      self.water_peaks = sorted(self.water_peaks, key=operator.attrgetter("peak_height"), reverse=True)
    if (self.water_anom_peaks is not None):
      self.water_anom_peaks = sorted(self.water_anom_peaks,
                                     key=operator.attrgetter("peak_height"),
                                     reverse=True)
    self.pdb_file = None
    self.map_file = None

  def show_summary(self, out=sys.stdout):
    self.get_summary().show(out=out)

  def get_summary(self):
    """
    Returns a simple object for harvesting statistics elsewhere.
    """
    n_anom_peaks = None
    if (self.anom_peaks is not None):
      n_anom_peaks = len(self.anom_peaks.heights)
    n_water_peaks = n_water_anom_peaks = None
    if (self.water_peaks is not None):
      n_water_peaks = len(self.water_peaks)
    if (self.water_anom_peaks is not None):
      n_water_anom_peaks = len(self.water_anom_peaks)
    hole_max = peak_max = None
    if (len(self.peaks.heights) > 0):
      peak_max = flex.max(self.peaks.heights)
    if (len(self.holes.heights) > 0):
      hole_max = flex.min(self.holes.heights)
    n_non_water_anom_peaks = None
    if (getattr(self, "non_water_anom_peaks", None) is not None):
      n_non_water_anom_peaks = len(self.non_water_anom_peaks)
    return summary(
      n_peaks_1=(self.peaks.heights > self.map_cutoff).count(True),
      n_peaks_2=(self.peaks.heights > self.map_cutoff + 3).count(True),
      n_peaks_3=(self.peaks.heights > self.map_cutoff + 6).count(True),
      n_holes_1=(self.holes.heights < -self.map_cutoff).count(True),
      n_holes_2=(self.holes.heights < -self.map_cutoff - 3).count(True),
      n_holes_3=(self.holes.heights < -self.map_cutoff - 6).count(True),
      peak_max=peak_max,
      hole_max=hole_max,
      n_anom_peaks=n_anom_peaks,
      n_water_peaks=n_water_peaks,
      n_water_anom_peaks=n_water_anom_peaks,
      map_cutoff=self.map_cutoff,
      anom_map_cutoff=self.anom_map_cutoff,
      n_non_water_anom_peaks=n_non_water_anom_peaks)

  def n_peaks_above_cutoff(self, cutoff):
    assert (cutoff > 0)
    return (self.peaks.heights > cutoff).count(True)

  def n_holes_below_cutoff(self, cutoff):
    assert (cutoff < 0)
    return (self.holes.heights < cutoff).count(True)

  def save_pdb_file(self,
      file_name="peaks.pdb",
      include_holes=True,
      include_anom=True,
      include_water=True,
      log=None):
    """
    Write out a PDB file with up to three chains: A for peaks, B for holes,
    C for anomalous peaks.  Atoms are UNK, with the B-factor set to the height
    or depth of the peak or hole.
    """
    if (log is None) : log = sys.stdout
    import iotbx.pdb.hierarchy
    self.peaks.sort(reverse=True)
    root = iotbx.pdb.hierarchy.root()
    model = iotbx.pdb.hierarchy.model()
    root.append_model(model)
    peaks_chain = iotbx.pdb.hierarchy.chain(id="A")
    model.append_chain(peaks_chain)
    def create_atom(xyz, peak, serial):
      rg = iotbx.pdb.hierarchy.residue_group(resseq=hy36encode(4, serial))
      ag = iotbx.pdb.hierarchy.atom_group(resname="UNK")
      rg.append_atom_group(ag)
      a = iotbx.pdb.hierarchy.atom()
      ag.append_atom(a)
      a.name = " UNK"
      a.element = "X"
      a.xyz = xyz
      a.b = peak
      a.occ = 1.
      a.serial = serial
      return rg
    k = 1
    for peak, xyz in zip(self.peaks.heights, self.peaks.sites):
      rg = create_atom(xyz, peak, k)
      peaks_chain.append_residue_group(rg)
      k += 1
    f = open(file_name, "w")
    f.write("REMARK  Interesting sites from mmtbx.find_peaks_holes\n")
    f.write("REMARK  Chain A is difference map peaks (> %g sigma)\n" %
      self.map_cutoff)
    if (include_holes):
      f.write("REMARK  Chain B is difference map holes (< %g sigma)\n" %
        (- self.map_cutoff))
      holes_chain = iotbx.pdb.hierarchy.chain(id="B")
      model.append_chain(holes_chain)
      k = 1
      for hole, xyz in zip(self.holes.heights, self.holes.sites):
        rg = create_atom(xyz, hole, k)
        holes_chain.append_residue_group(rg)
        k += 1
    if (include_anom) and (self.anom_peaks is not None):
      f.write("REMARK  Chain C is anomalous peaks (> %g sigma)\n" %
        self.anom_map_cutoff)
      anom_chain = iotbx.pdb.hierarchy.chain(id="C")
      model.append_chain(anom_chain)
      k = 1
      for peak, xyz in zip(self.anom_peaks.heights, self.anom_peaks.sites):
        rg = create_atom(xyz, peak, k)
        anom_chain.append_residue_group(rg)
        k += 1
    if (include_water) and (self.water_peaks is not None):
      f.write("REMARK  Chain D is waters with mFo-DFc peaks (> %g sigma)\n" %
        self.map_cutoff)
      waters_chain = iotbx.pdb.hierarchy.chain(id="D")
      model.append_chain(waters_chain)
      for k, peak in enumerate(self.water_peaks):
        rg = create_atom(peak.xyz, peak.peak_height, k+1)
        waters_chain.append_residue_group(rg)
      if (include_anom) and (self.water_anom_peaks is not None):
        f.write("REMARK  Chain E is waters with anom. peaks (> %g sigma)\n" %
          self.anom_map_cutoff)
        waters_chain_2 = iotbx.pdb.hierarchy.chain(id="E")
        model.append_chain(waters_chain_2)
        for k, peak in enumerate(self.water_anom_peaks):
          rg = create_atom(peak.xyz, peak.peak_height, k+1)
          waters_chain_2.append_residue_group(rg)
    if ((include_anom) and
        (getattr(self, "non_water_anom_peaks", None) is not None)):
      f.write("REMARK  Chain F is non-water, non-HD atoms with anom. peaks\n")
      anom_chain_2 = iotbx.pdb.hierarchy.chain(id="F")
      model.append_chain(anom_chain_2)
      for k, peak in enumerate(self.non_water_anom_peaks):
        rg = create_atom(peak.xyz, peak.peak_height, k+1)
        anom_chain_2.append_residue_group(rg)
    f.write(root.as_pdb_string())
    f.close()
    print("Wrote %s" % file_name, file=log)
    self.pdb_file = file_name

  def get_output_file_info(self):
    output_files = []
    if (self.pdb_file is not None):
      output_files.append((self.pdb_file, "Peaks as PDB atoms"))
    if (self.map_file is not None):
      output_files.append((self.map_file, "Map coefficients"))
    return output_files

class summary(group_args):
  def show(self, out=sys.stdout):
    print("", file=out)
    print("SUMMARY OF MAP PEAKS:", file=out)
    cutoffs = [self.map_cutoff, self.map_cutoff + 3.0, self.map_cutoff + 6.0]
    peaks = [ self.n_peaks_1, self.n_peaks_2, self.n_peaks_3 ]
    labels = []
    values = []
    for cutoff, n_peaks in zip(cutoffs, peaks):
      labels.append("mFo-DFc >  %-4g" % cutoff)
      values.append("%6d" % n_peaks)
    labels.append("mFo-DFc max")
    values.append(format_value("%6.2f", self.peak_max))
    holes = [ self.n_holes_1, self.n_holes_2, self.n_holes_3 ]
    for cutoff, n_holes in zip(cutoffs, holes):
      labels.append("mFo-DFc < -%-4g" % cutoff)
      values.append("%6d" % n_holes)
    labels.append("mFo-DFc min")
    values.append(format_value("%6.2f", self.hole_max))
    if (self.n_anom_peaks is not None):
      labels.append("anomalous > %-4g" % self.anom_map_cutoff)
      values.append("%6d" % self.n_anom_peaks)
    if (self.n_water_peaks is not None):
      labels.append("suspicious H2O (mFo-DFC > %g)" % self.map_cutoff)
      values.append("%6d" % self.n_water_peaks)
    if (self.n_water_anom_peaks is not None):
      labels.append("anomalous H2O (anomalous > %g)" % self.map_cutoff)
      values.append("%6d" % self.n_water_anom_peaks)
    if (self.n_non_water_anom_peaks is not None):
      labels.append("anomalous non-water atoms")
      values.append("%6d" % self.n_non_water_anom_peaks)
    labels = [ l.strip() + ":" for l in labels ]
    label_len = max([ len(l) for l in labels ])
    format = "%%-%ds" % label_len
    for label, value in zip(labels, values):
      formatted = format % label
      print("  %s %s" % (formatted, value), file=out)
    print("", file=out)

class water_peak(object):
  def __init__(self, id_str, xyz, peak_height, map_type="mFo-DFc"):
    adopt_init_args(self, locals())

  def show(self, out=sys.stdout):
    print("  %s  map_type=%s  peak=%g" % (self.id_str,
      self.map_type, self.peak_height), file=out)

def find_peaks_holes(
    fmodel,
    pdb_hierarchy,
    params=None,
    map_cutoff=3.0,
    anom_map_cutoff=3.0,
    filter_peaks_by_2fofc=None,
    use_phaser_if_available=True,
    return_llg_map=False,
    include_peaks_near_model=False,
    out=None):
  """
  Find peaks and holes in mFo-DFc map, plus flag solvent atoms with
  suspiciously high mFo-DFc values, plus anomalous peaks if anomalous data are
  present.  Returns a pickle-able object storing all this information (with
  the ability to write out a PDB file with the sites of interest).
  """
  if (out is None) : out = sys.stdout
  if (params is None):
    params = master_phil.fetch().extract().find_peaks
  if (include_peaks_near_model):
    params.map_next_to_model.min_model_peak_dist = 0
  pdb_atoms = pdb_hierarchy.atoms()
  unit_cell = fmodel.xray_structure.unit_cell()
  from mmtbx import find_peaks
  from cctbx import maptbx
  f_map = None
  if (filter_peaks_by_2fofc is not None):
    f_map_ = fmodel.electron_density_map().fft_map(
      resolution_factor=min(0.5, params.grid_step/fmodel.f_obs().d_min()),
      symmetry_flags=maptbx.use_space_group_symmetry,
      map_type="2mFo-DFc",
      use_all_data=True)
    f_map_.apply_sigma_scaling()
    f_map = f_map_.real_map()
  make_header("Positive difference map peaks", out=out)
  coeffs = fmodel.electron_density_map().map_coefficients(
    map_type     = "mFo-DFc",
    fill_missing = False,
    isotropize   = False)
  peaks_result = find_peaks.manager(
    map_coeffs = coeffs,
    xray_structure = fmodel.xray_structure,
    map_cutoff=map_cutoff,
    params=params,
    log=out)
  peaks_result.peaks_mapped()
  peaks_result.show_mapped(pdb_atoms)
  peaks = peaks_result.peaks()
  if (filter_peaks_by_2fofc is not None):
    n_removed = peaks.filter_by_secondary_map(
      map=f_map,
      min_value=filter_peaks_by_2fofc)
    print("", file=out)
    print("%d peaks remaining after 2mFo-DFc filtering" % \
      len(peaks.sites), file=out)
  # very important - sites are initially fractional coordinates!
  peaks.sites = unit_cell.orthogonalize(peaks.sites)
  print("", file=out)
  out.flush()
  make_header("Negative difference map holes", out=out)
  coeffs = fmodel.electron_density_map().map_coefficients(
    map_type     = "mFo-DFc",
    fill_missing = False,
    isotropize   = False)
  holes_result = find_peaks.manager(
    map_coeffs = coeffs,
    xray_structure = fmodel.xray_structure,
    map_cutoff=-map_cutoff,
    params=params,
    log=out)
  holes_result.peaks_mapped()
  holes_result.show_mapped(pdb_atoms)
  holes = holes_result.peaks()
  # XXX is this useful?
  #if (filter_peaks_by_2fofc is not None):
  #  holes.filter_by_secondary_map(
  #    map=f_map,
  #    min_value=filter_peaks_by_2fofc)
  holes.sites = unit_cell.orthogonalize(holes.sites)
  print("", file=out)
  out.flush()
  anom = None
  anom_map_coeffs = None
  if (fmodel.f_obs().anomalous_flag()):
    make_header("Anomalous difference map peaks", out=out)
    anom_map_type = "anom_residual"
    if ((use_phaser_if_available) and (libtbx.env.has_module("phaser")) and
        (not fmodel.twin)):
      import mmtbx.map_tools
      print("Will use Phaser LLG map", file=out)
      anom_map_type = None
      anom_map_coeffs = mmtbx.map_tools.get_phaser_sad_llg_map_coefficients(
        fmodel=fmodel,
        pdb_hierarchy=pdb_hierarchy,
        log=out)
    anom_result = find_peaks.manager(
      fmodel=fmodel,
      map_type=anom_map_type,
      map_coeffs=anom_map_coeffs,
      map_cutoff=anom_map_cutoff,
      params=params,
      log=out)
    anom_result.peaks_mapped()
    anom_result.show_mapped(pdb_atoms)
    anom = anom_result.peaks()
    if (filter_peaks_by_2fofc is not None):
      anom.filter_by_secondary_map(
        map=f_map,
        min_value=filter_peaks_by_2fofc)
      print("", file=out)
      print("%d peaks remaining after 2mFo-DFc filtering" % \
        len(anom.sites), file=out)
    anom.sites = unit_cell.orthogonalize(anom.sites)
    print("", file=out)
    out.flush()
  anom_map = None
  cache = pdb_hierarchy.atom_selection_cache()
  sites_frac = fmodel.xray_structure.sites_frac()
  water_isel = cache.selection(
    "resname HOH and not (element H or element D)").iselection()
  waters_out = [None, None]
  if (len(water_isel) > 0):
    map_types = ["mFo-DFc"]
    map_cutoffs = [ map_cutoff ]
    if (fmodel.f_obs().anomalous_flag()):
      map_types.append("anomalous")
      map_cutoffs.append(anom_map_cutoff)
    for k, map_type in enumerate(map_types):
      fft_map = None
      # re-use Phaser LLG map if it was previously calculated
      if (map_type == "anomalous") and (anom_map_coeffs is not None):
        fft_map = anom_map_coeffs.fft_map(
          resolution_factor=min(0.5, params.grid_step/fmodel.f_obs().d_min()),
          symmetry_flags=maptbx.use_space_group_symmetry)
      else :
        fft_map = fmodel.electron_density_map().fft_map(
          resolution_factor= min(0.5, params.grid_step/fmodel.f_obs().d_min()),
          symmetry_flags=maptbx.use_space_group_symmetry,
          map_type=map_type,
          use_all_data=True)
      real_map = fft_map.apply_sigma_scaling().real_map_unpadded()
      if (map_type == "anomalous") : anom_map = real_map
      suspicious_waters = []
      for i_seq in water_isel :
        atom = pdb_atoms[i_seq]
        rho = real_map.tricubic_interpolation(sites_frac[i_seq])
        if (rho >= map_cutoffs[k]):
          peak = water_peak(
            id_str=atom.id_str(),
            xyz=atom.xyz,
            peak_height=rho,
            map_type=map_type)
          suspicious_waters.append(peak)
      if (len(suspicious_waters) > 0):
        make_header("Water molecules with %s peaks" % map_type, out=out)
        for peak in suspicious_waters :
          peak.show(out=out)
        print("", file=out)
        waters_out[k] = suspicious_waters
  non_water_anom_peaks = None
  if (fmodel.f_obs().anomalous_flag()):
    non_water_anom_peaks = []
    if (anom_map is None):
      fft_map = fmodel.electron_density_map().fft_map(
        resolution_factor=min(0.5, params.grid_step/fmodel.f_obs().d_min()),
        symmetry_flags=maptbx.use_space_group_symmetry,
        map_type="anom",
        use_all_data=True)
      anom_map = fft_map.apply_sigma_scaling().real_map_unpadded()
    non_water_non_H_i_sel = cache.selection(
      "not (resname HOH or element H or element D)").iselection()
    for i_seq in non_water_non_H_i_sel :
      rho = anom_map.tricubic_interpolation(sites_frac[i_seq])
      if (rho >= anom_map_cutoff):
        atom = pdb_atoms[i_seq]
        peak = water_peak(
          id_str=atom.id_str(),
          xyz=atom.xyz,
          peak_height=rho,
          map_type="anomalous")
        non_water_anom_peaks.append(peak)
  all_results = peaks_holes_container(
    peaks=peaks,
    holes=holes,
    anom_peaks=anom,
    map_cutoff=map_cutoff,
    anom_map_cutoff=anom_map_cutoff,
    water_peaks=waters_out[0],
    water_anom_peaks=waters_out[1],
    non_water_anom_peaks=non_water_anom_peaks)
  all_results.show_summary(out=out)
  if (return_llg_map):
    return all_results, anom_map_coeffs
  return all_results

def run(args, out=None):
  if (out is None) : out = sys.stdout
  import mmtbx.command_line
  usage_string = """\
mmtbx.find_peaks_holes - difference map analysis
  Prints a summary of all peaks and holes above the specified cutoff in the
  mFo-DFc map, and flag any water molecules with suspiciously high peaks
  (possible ions).  Will also check the anomalous map if available.
"""
  cmdline = mmtbx.command_line.load_model_and_data(
    args=args,
    master_phil=master_phil,
    out=out,
    process_pdb_file=False,
    create_fmodel=True,
    prefer_anomalous=True,
    usage_string=usage_string)
  fmodel = cmdline.fmodel
  params = cmdline.params
  if (params.wavelength is not None):
    xrs = fmodel.xray_structure
    xrs.set_inelastic_form_factors(
      photon=params.wavelength,
      table="sasaki")
    fmodel.update_xray_structure(xrs, update_f_calc=True)
  out.flush()
  result, llg_map = find_peaks_holes(
    fmodel=fmodel,
    pdb_hierarchy=cmdline.pdb_hierarchy,
    params=params.find_peaks,
    map_cutoff=params.map_cutoff,
    anom_map_cutoff=params.anom_map_cutoff,
    filter_peaks_by_2fofc=params.filter_peaks_by_2fofc,
    use_phaser_if_available=True,
    return_llg_map=True,
    include_peaks_near_model=params.include_peaks_near_model,
    out=out)
  prefix = cmdline.params.output_file_prefix
  if (cmdline.params.write_pdb):
    result.save_pdb_file(file_name="%s.pdb" % prefix, log=out)
  if (cmdline.params.write_maps):
    import mmtbx.maps.utils
    import iotbx.map_tools
    f_map, diff_map = mmtbx.maps.utils.get_maps_from_fmodel(fmodel)
    anom_map = llg_map # use LLG map for anomalous map if available
    if (fmodel.f_obs().anomalous_flag()) and (anom_map is None):
      anom_map = mmtbx.maps.utils.get_anomalous_map(fmodel)
    iotbx.map_tools.write_map_coeffs(
      fwt_coeffs=f_map,
      delfwt_coeffs=diff_map,
      file_name="%s_maps.mtz" % prefix,
      anom_coeffs=anom_map)
    result.map_file = "%s_maps.mtz" % prefix
  return result

def validate_params(params, callback=None):
  from mmtbx.command_line import validate_input_params
  validate_input_params(params)
  if (params.find_peaks.map_next_to_model.min_model_peak_dist < 0):
    raise Sorry("The parameter 'Minimum distance from model' must be at least"+
      " zero.")
  if (params.find_peaks.peak_search.min_cross_distance <= 0):
    raise Sorry("The parameter 'Minimum cross distance' must be greater than "+
      "zero.")

class launcher(runtime_utils.target_with_save_result):
  def run(self):
    os.chdir(self.output_dir)
    return run(args=list(self.args), out=sys.stdout)

def finish_job(result):
  output_files = []
  stats = []
  if (result is not None):
    output_files = result.get_output_file_info()
  return (output_files, stats)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/find_residue_in_pdb.py
from __future__ import absolute_import, division, print_function
from libtbx.utils import Sorry, Usage
import libtbx.phil.command_line
import sys

master_phil = libtbx.phil.parse("""
resname = None
  .type = str
d_max = None
  .type = float
protein_only = False
  .type = bool
xray_only = True
  .type = bool
data_only = False
  .type = bool
quiet = False
  .type = bool
""")

def run(args, out=sys.stdout):
  if (len(args) == 0) or ("--help" in args):
    raise Usage("""mmtbx.find_residue_in_pdb RESNAME [options]

Use the RCSB web services to retrieve a list of PDB structures containing the
specified chemical ID.

Full parameters:
%s
""" % master_phil.as_str(prefix="  "))
  sources = []
  def process_unknown(arg):
    if (1 <= len(arg) <= 3) and (arg.isalnum()):
      return libtbx.phil.parse("resname=%s" % arg)
  cai = libtbx.phil.command_line.argument_interpreter(master_phil=master_phil)
  working_phil = cai.process_and_fetch(args=args,
    custom_processor=process_unknown)
  params = working_phil.extract()
  if (params.resname is None):
    raise Sorry("No residue ID specified.")
  from mmtbx.wwpdb import rcsb_web_services
  pdb_ids = rcsb_web_services.chemical_id_search(
    resname=params.resname,
    d_max=params.d_max,
    protein_only=params.protein_only,
    xray_only=params.xray_only,
    data_only=params.data_only,
    )
  pdb_ids = [ id.lower() for id in pdb_ids ]
  if (len(pdb_ids) == 0):
    raise Sorry("No structures found matching the specified criteria.")
  else :
    if (not params.quiet):
      print("%d PDB IDs retrieved:" % len(pdb_ids), file=out)
      i = 0
      while (i < len(pdb_ids)):
        print("  %s" % " ".join(pdb_ids[i:i+16]), file=out)
        i += 16
    else :
      print("%d PDB IDs matching" % len(pdb_ids), file=out)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/find_tls_groups.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.find_tls_groups

from mmtbx.tls import tools
from mmtbx.refinement import print_statistics
import mmtbx.secondary_structure
import iotbx.pdb
from scitbx.array_family import flex
import scitbx.linalg
import libtbx.phil
from libtbx.utils import Sorry
from libtbx import Auto
from copy import deepcopy
from six.moves import cStringIO as StringIO
import random
import os
import time
import sys
import six
from six.moves import zip

from six.moves import range


master_phil = libtbx.phil.parse("""
  pdb_file = None
    .type = path
  nproc = 1
    .type = int
  random_seed = 4865136
    .type = int
""")

##### PERMTOOLS
def consequtive_permutations(iterable, r=None):
  pool = tuple(iterable)
  n = len(pool)
  r = n if r is None else r
  if r > n: return
  indices = list(range(n))
  cycles = list(range(n, n-r, -1))
  yield tuple(pool[i] for i in indices[:r])
  while n:
    for i in reversed(range(r)):
      cycles[i] -= 1
      if cycles[i] == 0:
        indices[i:] = indices[i+1:] + indices[i:i+1]
        cycles[i] = n - i
      else:
        j = cycles[i]
        indices[i], indices[-j] = indices[-j], indices[i]
        tmp = []
        good=True
        for k in indices[:r]:
          x = pool[k]
          ltmp = len(tmp)
          if(ltmp>0 and tmp[ltmp-1]-x!=-1):
            good=False
            break
          tmp.append(x)
        if(good): yield tuple(pool[i] for i in indices[:r])
        break
    else:
      return

def all_permutations(N):
  unique_set = list(range(N))
  array = [[i] for i in unique_set]
  gss = reversed(range(2,N))
  def is_all(x, us):
    tmp = []
    for i in x:
      for j in i:
        if(not j in tmp): tmp.append(j)
    tmp.sort()
    return tmp == us
  def not_in(v, t):
    for i in v:
      if i in t:
        return False
    return True
  result = [array[:]]
  for gs in gss:
    #print "group by:",gs
    for start_index in range(N):
      tmp = []
      tmp_ = []
      for i,a in enumerate(array):
        if(i>=start_index and i<=start_index+gs-1):
          tmp_.append(a[0])
        else: tmp.append(a)
        if(len(tmp_)==gs):
          tmp.append(tmp_)
          tmp_ = []
      tmp__=[]
      if(is_all(tmp, unique_set)):
        #print "  tmp=",tmp
        result.append(tmp)
        tmp__.append(tmp)
        for i,ti in enumerate(tmp):
          ztmp = []
          for j,tj in enumerate(tmp):
            if(j>i and abs(j-i)==1): ztmp.append([ti[0],tj[0]])
            elif(i!=j): ztmp.append(tj)
          if(not ztmp in result and is_all(ztmp, unique_set)):
            result.append(ztmp)
            #print "     ",ztmp
            tmp__.append(ztmp)
  def h1(x):
    tmp = []
    for i in x:
      for j in i:
        if not j in tmp: tmp.append(j)
    return tmp
  for i, xtmp_ in enumerate(result):
    for j, ytmp_ in enumerate(result):
      if(j>i):
        for xtmp__ in xtmp_:
          tmp = []
          tmp.append(xtmp__)
          tmpl = h1(tmp)
          for ytmp__ in ytmp_:
            if(ytmp__ != xtmp__ and not_in(ytmp__, tmpl)):
              tmp.append(ytmp__)
              if(is_all(tmp, unique_set)):
                tmp.sort()
                if(not tmp in result):
                  result.append(tmp)
                  tmp=[]
                  break
  n = []
  for r_ in result:
    n_=[]
    for r__ in r_:
      r__.sort()
      n_.append(r__)
    n_.sort()
    n.append(n_)
  result = n
  result.sort()
  #print "  Number of all permutations:",len(result)
  ### DEBUG
  for i,ri in enumerate(result):
    for j,rj in enumerate(result):
      if(i!=j): assert ri != rj
  return result

###############

def group_residues(residues):
  sels, sel = [], []
  cntr = 0
  chs1=0
  cntr3 = 0
  for i, r in enumerate(residues):
    chs1 += r[0].size()
    next = i+1
    if(next<len(residues)):
      if(r[1] == residues[next][1]):
        sel.append(r)
        #print i, r[1], cntr
      else:
        sel.append(r)
        sels.append(sel)
        for ss in sel: cntr3 += ss[0].size()
        sel = []
        #print i, r[1], cntr
        cntr += 1
    else:
      sel.append(r)
      sels.append(sel)
      for ss in sel: cntr3 += ss[0].size()
      sel = []
      #print i, r[1], cntr
      cntr += 1
  chs2=0
  for i, s in enumerate(sels):
    for s_ in s: chs2 += s_[0].size()
  assert min([chs1,chs2,cntr3]) == max([chs1,chs2,cntr3])
  return sels

def regroup_groups(sels, residues, fragment_size, max_sels):
  sel = []
  min_size = 1.e+6
  i_min = None
  chsum1 = 0
  for i_seq, s in enumerate(sels):
    chsum1 += len(s)
    if(len(s)<min_size):
      i_min = i_seq
      min_size = len(s)
  while (len(sels)>max_sels or min_size < fragment_size):
    new_sels = []
    min_size = 1.e+6
    i_min = None
    for i_seq, s in enumerate(sels):
      if(len(s)<min_size):
        i_min = i_seq
        min_size = len(s)
    if(min_size < fragment_size or len(sels)>max_sels):
      l,r = None,None
      if(i_min-1>=0): l=sels[i_min-1]
      if(i_min+1<len(sels)): r=sels[i_min+1]
      if([l,r].count(None)==0):
        if(len(l)<len(r)):
          x = deepcopy(sels[i_min-1])
          y = deepcopy(sels[i_min])
          x.extend(y)
          sels[i_min-1]=x
          sels = sels[:i_min]+sels[i_min+1:]
        else:
          x = deepcopy(sels[i_min])
          y = deepcopy(sels[i_min+1])
          x.extend(y)
          sels[i_min]=x
          sels = sels[:i_min+1]+sels[i_min+2:]
      elif(l is not None):
          x = deepcopy(sels[i_min-1])
          y = deepcopy(sels[i_min])
          x.extend(y)
          sels[i_min-1]=x
          sels = sels[:i_min]+sels[i_min+1:]
      elif(r is not None):
          x = deepcopy(sels[i_min])
          y = deepcopy(sels[i_min+1])
          x.extend(y)
          sels[i_min]=x
          sels = sels[:i_min+1]+sels[i_min+2:]
      else:
        break # XXX Find why it may get here! Example 3zvn XXX
  chsum2 = 0
  for i_seq, s in enumerate(sels):
    chsum2 += len(s)
  assert chsum1 == chsum2, [chsum1, chsum2]
  return sels

def split_groups(sels, fragment_size):
  new_sels = []
  for sel in sels:
    if(len(sel)>fragment_size*3):
      #print "len(sel):", len(sel)
      is_ss_cntr=0
      for s_ in sel:
        #print s_
        if(s_[1]): is_ss_cntr += 1
      if(is_ss_cntr*100./len(sel)<50.):
        nc = 0
        new_sel = []
        while nc < len(sel):
          new_sels.append(sel[nc:nc+fragment_size])
          nc += fragment_size
      else:
        new_sels.append(sel)
    else:
      new_sels.append(sel)
  return new_sels

def show_groups(sels, out=None):
  if (out is None):
    out = sys.stdout
  min_group_size = 1.e+6
  if 0: print("          Residues  Resseq  Sec.Structure", file=out)
  for i, s in enumerate(sels):
    is_ss_cntr=0
    for s_ in s:
      if(s_[1]): is_ss_cntr += 1
    if 0: print("      #%d: %8d  %s-%s %9d"%(i, len(s), s[0][2].strip(),
      s[len(s)-1][2].strip(), is_ss_cntr), file=out)
    if(len(s)<min_group_size): min_group_size = len(s)
  return min_group_size

def sels_as_selection_arrays(sels):
  result = []
  for s in sels:
    r_ = flex.size_t()
    for s_ in s:
      r_.extend(s_[0])
    if(r_.size()>0): result.append(r_)
  return result

def get_model_partitioning(residues,
                           secondary_structure_selection,
                           max_sels=13,
                           out=None):
  if (out is None):
    out = sys.stdout
  fragment_size = 5
  print("  Grouping residues by secondary structure...", file=out)
  sels = group_residues(residues)
  print("  Fragment size:", fragment_size, file=out)
  print("    Initial groups...", file=out)
  min_group_size = show_groups(sels=sels)
  print("      n_groups=", len(sels), file=out)
  ###
  print("    Splitting groups is necesary...", file=out)
  print("      n_groups=", len(sels), file=out)
  sels = split_groups(sels = sels, fragment_size = fragment_size)
  show_groups(sels=sels)
  ###
  if(len(sels) > max_sels or min_group_size < fragment_size and len(sels)>1):
    print("  Re-grouping to achieve maximum possible nuber of groups...", file=out)
    sels = regroup_groups(sels, residues, fragment_size, max_sels)
    print("    n_groups=", len(sels), file=out)
    show_groups(sels=sels)
  len_new_sels = len(sels)
  if(len_new_sels==10):
    from mmtbx.tls import perm10
    perms = perm10.res
  elif(len_new_sels==11):
    from mmtbx.tls import perm11
    perms = perm11.res
  elif(len_new_sels==12):
    from mmtbx.tls import perm12
    perms = perm12.res
  elif(len_new_sels==13):
    from mmtbx.tls import perm13
    perms = perm13.res
  elif(len_new_sels==14):
    from mmtbx.tls import perm14
    perms = perm14.res
  elif(len_new_sels==15):
    from mmtbx.tls import perm15
    perms = perm15.res
  elif(len_new_sels==1):
    perms = [[[0]]]
  elif(len_new_sels<10):
    perms = all_permutations(len(range(len_new_sels)))
  else: raise RuntimeError("Too many permutations.")
  return sels, perms

def chains_and_atoms(pdb_hierarchy, secondary_structure_selection,
    out=None):
  if (out is None):
    out = sys.stdout
  new_secondary_structure_selection = flex.bool()
  get_class = iotbx.pdb.common_residue_names_get_class
  chains_and_residue_selections = []
  for model in pdb_hierarchy.models():
    for chain in model.chains():
      result = []
      for rg in chain.residue_groups():
        result_ = flex.size_t()
        is_secondary_structure = False
        for ag in rg.atom_groups():
          #print >> out, ag.resname, get_class(name=ag.resname)
          if(get_class(name=ag.resname) == "common_amino_acid" or
             get_class(name=ag.resname) == "common_rna_dna"):
            for atom in ag.atoms():
              result_.append(atom.i_seq)
              if(not is_secondary_structure):
                is_secondary_structure = \
                  secondary_structure_selection[atom.i_seq]
              new_secondary_structure_selection.append(
                secondary_structure_selection[atom.i_seq])
        if(result_.size()>0):
          result.append(
            [result_, is_secondary_structure, rg.resid(), rg.unique_resnames()])
      if(len(result)>0):
        chains_and_residue_selections.append([chain.id, result])
  print("Considering these chains:", file=out)
  for ch in chains_and_residue_selections:
    print("  chain '%s' (number of residues selected: %d)" % (ch[0], len(ch[1])), file=out)
  return chains_and_residue_selections, new_secondary_structure_selection

def tls_group_selections(groups, perm):
  result = []
  for p in perm:
    one_group = flex.size_t()
    for p_ in p:
      for g in groups[p_]:
        one_group.extend(g[0])
    result.append(one_group)
  return result

def tls_refinery(sites_cart, selection, u_cart=None, u_iso=None,
                 use_minimizer=False, max_iterations=100):
  sites_cart_ = sites_cart.select(selection)
  cm = sites_cart_.mean_weighted(weights=flex.double(sites_cart_.size(),1))
  assert [u_cart, u_iso].count(None)==1
  if(not use_minimizer):
    obj = tools.tls_ls_derivative_coefficients(
      origin     = cm,
      sites_cart = sites_cart_,
      u_iso      = u_iso.select(selection))
    def s1(use_generalized_inverse=True):
      if(not use_generalized_inverse):
        obj.a.matrix_inversion_in_place()
        res = obj.a.matrix_multiply(obj.b)
      else:
        es = scitbx.linalg.eigensystem.real_symmetric(
          m=obj.a,
          relative_epsilon=1.e-12,
          absolute_epsilon=0)
        a = es.generalized_inverse_as_packed_u().matrix_packed_u_as_symmetric()
        res = a.matrix_multiply(obj.b)
      return res
    result = s1()
    target = tools.ls_target_from_iso_tls(
      t = result[0],
      l = tuple(result[1:7]),
      s = tuple(result[7:]),
      origin = cm,
      sites_cart = sites_cart_,
      u_isos = u_iso.select(selection))
    #print "target:",target
    class foo: pass
    foo.f = target
    return foo
  else:
    if(u_cart is not None):
      return tools.tls_from_uaniso_minimizer(
        uaniso         = u_cart.select(selection),
        T_initial      = [0,0,0,0,0,0],
        L_initial      = [0,0,0,0,0,0],
        S_initial      = [0,0,0,0,0,0,0,0,0],
        refine_T       = True,
        refine_L       = True,
        refine_S       = True,
        origin         = cm,
        sites          = sites_cart_,
        max_iterations = max_iterations)
    else:
      minimized = tools.tls_from_uiso_minimizer(
        uiso           = u_iso.select(selection),
        T_initial      = [0],
        L_initial      = [0,0,0,0,0,0],
        S_initial      = [0,0,0],
        refine_T       = True,
        refine_L       = True,
        refine_S       = True,
        origin         = cm,
        sites          = sites_cart_,
        max_iterations = max_iterations)
      if(0): # DEBUG
        print("Minimization:", xxx.f)
        print("T_min:", minimized.T_min)
        print("L_min:", minimized.L_min)
        print("S_min:", minimized.S_min)
        print()
      return minimized

def chunks(size, n_groups):
  chunk_size = size//n_groups
  nc = chunk_size
  counter = 0
  sum_size = 0
  res = []
  check = 0
  while nc <= size:
    check += 1
    chunk_size_ = chunk_size + random.randrange(-1,2)*int(0.5*chunk_size)
    next = nc+chunk_size_
    if check >100 or nc>=next or next>=size:
      ###
      chunk_size = size//n_groups
      nc = chunk_size
      counter = 0
      sum_size = 0
      res = []
      check = 0
      ###
      check=0
    if(next>size or next+chunk_size_>size): next = size
    if(counter==n_groups and nc+chunk_size_>size): break
    if(len(res)>n_groups-1): break
    r = random.randrange(nc,next)
    try: ev = size-1-r>1 and r-max(res)>1
    except Exception: ev = size-1-r>1 and not r in res
    if(ev):
      res.append(r)
      nc+=chunk_size_
      if(len(res)>n_groups-2): break
  result = []
  for i, r in enumerate(res):
   if i==0: result.append([0,r])
   elif(i==len(res)): result.append([r,size])
   else: result.append([res[i-1]+1,res[i]])
  result.append([res[len(res)-1]+1,size-1])
  tmp = []
  for r in result:
    a = r[0]
    b = r[1]
    if(a!=0): a = a
    b = b+1
    r_ = flex.size_t(range(a,b))
    assert r_.size() > 0, [result, res]
    tmp.append(r_)
  # DEBUG
  cntr = 0
  for s in tmp:
    cntr += s.size()
  assert cntr == size
  #
  return tmp

def tls_refinery_random_groups(sites_cart, n_groups, u_cart=None, u_iso=None, n_runs=50):
  assert [u_cart, u_iso].count(None)==1
  t = 0
  for tr in range(n_runs):
    while True:
      selections = chunks(size=sites_cart.size(), n_groups=n_groups)
      #print [(min(s),max(s)) for s in selections]
      if(len(selections) == n_groups): break
    assert len(selections) == n_groups
    for selection in selections:
      mo = tls_refinery(u_cart=u_cart, u_iso=u_iso, sites_cart=sites_cart, selection=selection)
      t += mo.f
  return t/n_runs

def chain_selection_from_residues(residues):
  chain_selection = flex.size_t()
  for r in residues:
    chain_selection.extend(r[0])
  return chain_selection

def permutations_as_atom_selection_string(groups, perm):
  result = []
  for p in perm:
    one_group = []
    for p_ in p:
      for g in groups[p_]:
        one_group.append(g[2])
    resid = "resid %s through %s" % (one_group[0],
      one_group[len(one_group)-1])
    result.append(resid)
  return result

# XXX for multiprocessing
class analyze_permutations(object):
  def __init__(self, groups, sites_cart, u_cart, u_iso):
    self.groups = groups
    self.sites_cart = sites_cart
    self.u_cart = u_cart
    self.u_iso = u_iso

  def __call__(self, perm):
    selections = tls_group_selections(self.groups, perm)
    target = 0
    for selection in selections:
      mo = tls_refinery(
        u_cart     = self.u_cart,
        u_iso      = self.u_iso,
        sites_cart = self.sites_cart,
        selection  = selection)
      target += mo.f
    return target

def run(args=(), params=None, pdb_hierarchy=None, xray_structure=None,
    out=None):
  if (out is None):
    out = sys.stdout
  print_statistics.make_header("phenix.find_tls_groups", out=out)
  default_message="""\

phenix.find_tls_groups: Tool for automated partitioning a model into TLS groups.

Usage:
  phenix.find_tls_groups model.pdb [nproc=...]
"""
  if(len(args) == 0):
    print(default_message)
    return
  cmdline_phil = []
  for arg in args :
    if os.path.isfile(arg):
      if iotbx.pdb.is_pdb_file(arg) or iotbx.pdb.is_pdb_mmcif_file(arg):
        pdb_phil = libtbx.phil.parse("pdb_file=%s" % os.path.abspath(arg))
        cmdline_phil.append(pdb_phil)
      else:
        try: file_phil = libtbx.phil.parse(file_name=arg)
        except Exception: raise Sorry("Bad parameter file: %s"%arg)
        cmdline_phil.append(file_phil)
    else:
      try: arg_phil = libtbx.phil.parse(arg)
      except Exception: raise Sorry("Bad parameter: %s"%arg)
      cmdline_phil.append(arg_phil)
  working_phil = master_phil.fetch(sources=cmdline_phil)
  params = working_phil.extract()
  # XXX params.pdb_file is not used anymore. Maybe should be removed.
  pdb_file_name = params.pdb_file
  if ((pdb_file_name is None) or
      (not iotbx.pdb.is_pdb_file(pdb_file_name) and
          not iotbx.pdb.is_pdb_mmcif_file(pdb_file_name))):
    print("A model file is required.")
    return
  if (params.nproc is None):
    params.nproc = 1
  pdb_inp = iotbx.pdb.input(file_name=pdb_file_name)
  pdb_hierarchy = pdb_inp.construct_hierarchy()
  pdb_atoms = pdb_hierarchy.atoms()
  pdb_atoms.reset_i_seq()
  #
  xray_structure = pdb_inp.xray_structure_simple()
  return find_tls(
    params         = params,
    # pdb_inp        = pdb_inp,
    pdb_hierarchy  = pdb_hierarchy,
    xray_structure = xray_structure,
    out            = out)

def total_score(pdb_hierarchy, sites_cart, u_iso, selection_strings):
  assert sites_cart.size() == u_iso.size()
  target = 0
  all_selections = []
  for sel_str in selection_strings:
    sel_str_final = "(%s) and (not resname HOH)" % sel_str
    sel = pdb_hierarchy.atom_selection_cache().selection(
      string = sel_str_final.replace('"',""))
    for k, other in enumerate(all_selections):
      if ((sel & other).count(True) != 0):
        raise RuntimeError("Overlapping TLS selections:\n%s\n%s" % (sel_str,
          selection_strings[k]))
    all_selections.append(sel)
    assert sel.size() == u_iso.size()
    if (sel.count(True) == 0):
      continue
    target += tls_refinery(sites_cart=sites_cart, selection=sel, u_iso=u_iso).f
  return target

def external_tls(pdb_inp, pdb_hierarchy, sites_cart, u_iso, out=None):
  if (out is None):
    out = sys.stdout
  pdb_inp_tls = pdb_inp.extract_tls_params(pdb_hierarchy)
  print_statistics.make_header("TLS groups from PDB file header",
    out = out)
  selection_strings = []
  if(len(pdb_inp_tls.tls_params)>0):
    for tp in pdb_inp_tls.tls_params:
      print("  ", tp.selection_string, file=out)
      selection_strings.append(tp.selection_string)
  else:
    print("  ... none found.", file=out)
  if(len(selection_strings)>0):
    total_target = total_score(
      pdb_hierarchy     = pdb_hierarchy,
      sites_cart        = sites_cart,
      u_iso             = u_iso,
      selection_strings = selection_strings)
    print(file=out)
    print("Total target for groups from PDB file header: %10.1f"%total_target, file=out)

def check_adp(u_iso, step=10, out=None):
  if (out is None):
    out = sys.stdout
  min_adp = flex.min(u_iso)
  if(min_adp<=0):
    bad_i_seqs = []
    for i_seq in range(len(u_iso)):
      if (u_iso[i_seq] <= 0):
        bad_i_seqs.append(i_seq)
    return bad_i_seqs
  i = 0
  while i < u_iso.size():
    if(i+step < u_iso.size()):
      u_iso_i = u_iso[i:i+step]
    else:
      u_iso_i = u_iso[i:]
    if(u_iso_i.size() >= step//2):
      min_adp = flex.min(u_iso)
      max_adp = flex.max(u_iso)
      if(abs(min_adp-max_adp)<0.1):
        raise Sorry("At least 10 bonded atoms have identical ADPs.")
    i+=step
  return None

def merge_groups_by_connectivity(pdb_hierarchy, xray_structure,
                                 selection_strings=None, selection_arrays=None):
  assert [selection_strings, selection_arrays].count(None)==1
  if(selection_strings is None): selections = selection_arrays
  else:
    selections = []
    for ss in selection_strings:
      sa = pdb_hierarchy.atom_selection_cache().selection(string = ss.replace('"',""))
      selections.append(sa)
  for i_seq, si in enumerate(selections):
    for j_seq, sj in enumerate(selections):
      if(i_seq < j_seq):
        xi = xray_structure.select(si)
        xj = xray_structure.select(sj)
        if(xi.scatterers().size() > xj.scatterers().size()):
          distances = xi.closest_distances(xj.sites_frac(), distance_cutoff=6).smallest_distances
          cnt = ((distances > 0) & (distances < 3)).count(True)
          assert distances.size() == xj.scatterers().size()
          distances = distances.select(distances > 0)
          p = cnt*100./xj.scatterers().size()
          if(p>=1):
            print()
            if(selection_strings is not None):
              print(sj)
              print(si)
            print(i_seq,j_seq, p, flex.min_default(distances,0), flex.mean_default(distances,0))
        else:
          distances = xj.closest_distances(xi.sites_frac(), distance_cutoff=6).smallest_distances
          cnt = ((distances > 0) & (distances < 3)).count(True)
          assert distances.size() == xi.scatterers().size()
          distances = distances.select(distances > 0)
          p = cnt*100./xi.scatterers().size()
          if(p>=1):
            print()
            if(selection_strings is not None):
              print(sj)
              print(si)
            print(i_seq,j_seq, p, flex.min_default(distances,0), flex.mean_default(distances,0))

  #
  print()

def find_tls(params,
              pdb_hierarchy,
              xray_structure,
              return_as_list=False,
              ignore_pdb_header_groups=False,
              out=None):
  """
  !!! WARNING! incoming xray_structure here gets converted to
  isotropic B-factors IN PLACE.
  """
  if (out is None):
    out = sys.stdout
  print_statistics.make_header("Analyzing inputs", out=out)
  if (params.random_seed is None):
    params.random_seed = flex.get_random_seed()
  random.seed(params.random_seed)
  flex.set_random_seed(params.random_seed)
  xray_structure.convert_to_isotropic()
  sites_cart = xray_structure.sites_cart()
  u_cart = None
  u_iso  = xray_structure.extract_u_iso_or_u_equiv()#*adptbx.u_as_b(1.) # ?
  bad_i_seqs = check_adp(u_iso=u_iso, out=out)
  if (bad_i_seqs is not None):
    atoms = pdb_hierarchy.atoms()
    bad_atom_strings = []
    for i_seq in bad_i_seqs[:10] :
      atom_str = atoms[i_seq].format_atom_record()
      bad_atom_strings.append(atom_str)
    if (len(bad_i_seqs) > 10):
      bad_atom_strings.append("... (remaining %d not shown)" %
        (len(bad_i_seqs)-10))
    raise Sorry(("%d atoms in the model contain isotropic B-factors <= 0:\n"+
      "\n".join(bad_atom_strings)) % (len(bad_i_seqs)))
  #
  ssm = mmtbx.secondary_structure.manager(
    pdb_hierarchy                = pdb_hierarchy,
    sec_str_from_pdb_file        = None,
    params                       = None,
    log                          = out)
  alpha_h_selection = ssm.helix_selection()
  secondary_structure_selection = ssm.helix_selection() | \
      ssm.beta_selection() | ssm.base_pair_selection()
  if(u_cart is not None):
    assert secondary_structure_selection.size() == u_cart.size()
  else:
    assert secondary_structure_selection.size() == u_iso.size()
  ssm.show_summary(log=out)
  chains_and_residue_selections, secondary_structure_selection = chains_and_atoms(
    pdb_hierarchy                 = pdb_hierarchy,
    secondary_structure_selection = secondary_structure_selection,
    out                           = out)
  chains_and_permutations = []
  chains_and_atom_selection_strings = []
  print_statistics.make_header("Processing chains", out=out)
  if (params.nproc is None):
    params.nproc = 1
  for crs in chains_and_residue_selections:
    print_statistics.make_sub_header("Processing chain '%s'"%crs[0],
      out=out)
    chain_selection = chain_selection_from_residues(crs[1])
    groups, perms = get_model_partitioning(residues = crs[1],
      secondary_structure_selection = secondary_structure_selection,
      out = out)
    #
    if(len(perms)==1):
      print("  Whole chain is considered as one TLS group.", file=out)
      chains_and_atom_selection_strings.append([crs[0],
        permutations_as_atom_selection_string(groups, perms[0])])
    else:
      print("  Fitting TLS matrices...", file=out)
      dic = {}
      target_best = 1.e+9
      if (params.nproc is Auto) or (params.nproc > 1):
        process_perms = analyze_permutations(
          groups=groups,
          sites_cart=sites_cart,
          u_cart=u_cart,
          u_iso=u_iso)
        from libtbx import easy_mp
        stdout_and_targets = easy_mp.pool_map(
          processes=params.nproc,
          fixed_func=process_perms,
          args=perms,
          chunksize=100,
          func_wrapper="buffer_stdout_stderr")
        targets = [ t for so, t in stdout_and_targets ]
        for (perm, target) in zip(perms, targets):
          dic.setdefault(len(perm), []).append([target,perm])
      else :
        for i_perm, perm in enumerate(perms):
          if i_perm%500==0:
            print("    ...perm %d of %d"%(i_perm, len(perms)), file=out)
          selections = tls_group_selections(groups, perm)
          target = 0
          for selection in selections:
            mo = tls_refinery(
              u_cart     = u_cart,
              u_iso      = u_iso,
              sites_cart = sites_cart,
              selection  = selection)
            target += mo.f
          dic.setdefault(len(perm), []).append([target,perm])
        #print "    perm %d of %d: target=%8.3f (TLS groups: %s), permutation:"%(
        #  i_perm, len(perms),target,len(perm)),perm
      print("    Best fits:", file=out)
      print("      No. of         Targets", file=out)
      print("      groups   best   rand.pick  diff.  score permutation", file=out)
      score_best = -1.e+9
      perm_choice = None
      for k, v in six.iteritems(dic):
        t_best = v[0][0]
        perm_best = v[0][1]
        for v_ in v:
          if(v_[0]<t_best):
            t_best = v_[0]
            perm_best = v_[1]
        if(u_cart is not None):
          u_cart_ = u_cart.select(chain_selection)
        else: u_cart_ = None
        if(u_iso is not None):
          u_iso_ = u_iso.select(chain_selection)
        else: u_iso_ = None
        r = tls_refinery_random_groups(
          u_cart     = u_cart_,
          u_iso      = u_iso_,
          sites_cart = sites_cart.select(chain_selection),
          n_groups   = k)
        score = (r-t_best)/(r+t_best)*100.
        print("         %3d %6.3f      %6.3f %6.2f %6.3f"%(
          k,t_best, r, r-t_best, score), perm_best, file=out)
        if(score > score_best):
          score_best = score
          perm_choice = perm_best[:]
      #
      chains_and_permutations.append([crs[0],perm_choice])
      chains_and_atom_selection_strings.append([crs[0],
        permutations_as_atom_selection_string(groups, perm_choice)])
      #
  print_statistics.make_header("SUMMARY", out=out)
  #print "Optimal TLS groups:"
  #for chain_and_permutation in chains_and_permutations:
  #  print chain_and_permutation
  #print
  print("TLS atom selections for phenix.refine:", file=out)
  groups_out = StringIO()
  selection_strings = []
  print("refinement.refine.adp {", file=groups_out)
  for r in chains_and_atom_selection_strings:
    prefix = "chain '%s'"%r[0]
    if(len(r[1])>0 and len(r[1:])>0):
      prefix += " and "
      for r_ in r[1:]:
        for r__ in r_:
          if(len(r__)>0):
            group_selection = prefix+"(%s)"%r__
            print("  tls = \"%s\"" % group_selection, file=groups_out)
            selection_strings.append("%s" % group_selection)
    else:
      print("  tls = \"%s\"" % prefix, file=groups_out)
      selection_strings.append("%s" % prefix)
  print("}", file=groups_out)
  print(groups_out.getvalue(), file=out)
  print(file=out)
  #XXX
  if 0:
    merge_groups_by_connectivity(
      pdb_hierarchy     = pdb_hierarchy,
      xray_structure    = xray_structure,
      selection_strings = selection_strings)
  #XXX
  if(len(selection_strings)>0):
    total_target = total_score(
      pdb_hierarchy     = pdb_hierarchy,
      sites_cart        = sites_cart,
      u_iso             = u_iso,
      selection_strings = selection_strings)
    print("Overall best total target for automatically found groups: %10.1f"%total_target, file=out)
    print(file=out)
  if (return_as_list):
    return selection_strings
  else :
    return groups_out.getvalue()

# XXX wrapper for running in Phenix GUI
class _run_find_tls(object):
  def __init__(self, params, pdb_hierarchy, xray_structure):
    self.params = params
    self.pdb_hierarchy = pdb_hierarchy
    self.xray_structure = xray_structure

  def __call__(self, *args, **kwds):
    return find_tls(
      params=self.params,
      # pdb_inp=None,
      pdb_hierarchy=self.pdb_hierarchy,
      xray_structure=self.xray_structure)

if (__name__ == "__main__"):
  t0 = time.time()
  run(args=sys.argv[1:])
  print("Time: %10.3f"%(time.time()-t0))


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/fmodel.py
# LIBTBX_SET_DISPATCHER_NAME phenix.fmodel
from __future__ import absolute_import, division, print_function

from iotbx.cli_parser import run_program
from mmtbx.programs import fmodel

if __name__ == '__main__':
  run_program(program_class=fmodel.Program)

#from __future__ import absolute_import, division, print_function
## LIBTBX_SET_DISPATCHER_NAME phenix.fmodel
#
#import sys, os
#import mmtbx.utils
#import iotbx.phil
#import iotbx.pdb
#from scitbx.array_family import flex
#from libtbx import runtime_utils
#from libtbx.utils import Sorry
#import random
#
#legend = """
#phenix.fmodel: a tool to compute structure factors, Fmodel:
#
#  Fmodel = scale * exp(AnisoScale) * (Fcalc + k_sol * exp(-b_sol*s^2/4) * Fmask)
#
#  where:
#
#  - Fmodel - total model structure factor (complex value)
#  - AnisoScale = -ht*A(-1)*b_cart*A(-1)th/4
#  - h - column vector with Miller indices
#  - A - orthogonalization matrix
#  - b_cart - anisotropic scale matrix
#  - t and (-1) denotes transposition and inversion operations
#  - scale - overall scale factor
#  - Fcalc - structure factors calculated from atomic model
#  - k_sol and b_sol - Flat Bulk solvent model parameters
#  - Fmask - structure factors calculated from bulk solvent mask
#
#Usage examples:
#
#  1) phenix.fmodel model.pdb high_resolution=1.5
#
#     will result in a file containing complete set of Fmodel = Fcalc computed
#     from atomic model up to 1.5A resolution.
#
#  2) phenix.fmodel model.pdb scale=2 k_sol=0.35 b_sol=50 b_cart="1 2 3 0 4 7" high_res=1.5 low_res=10
#
#     will result in a file containing complete set of Fmodel computed using the
#     above formula in resolution range 1.5-20.0A.
#
#  3) phenix.fmodel model.pdb high_resolution=1.5 algorithm=direct
#
#     is similar to "1)" but the Fcalc are computed using direct summation algorithm.
#
#  4) phenix.fmodel model.pdb high_res=1.5 format=cns label=FOBS type=real r_free=0.1
#
#     will result in CNS formatted file containing complete set of amplitudes of
#     Fmodel = Fcalc computed up to 1.5A resolution, labelled as FOBS, and free-R
#     flags with 10% of test reflections. This is a typical command to simulate Fobs.
#
#  5) phenix.fmodel model.pdb high_res=1.5 scattering_table=neutron
#
#     will result in a file containing complete set of Fmodel = Fcalc computed
#     from atomic model up to 1.5A resolution using neutron scattering table.
#
#  6) phenix.fmodel model.pdb parameters.txt
#
#     will result in a structure factor file, where Fmodel were computed using
#     parameters defined in parameters.txt file. The parameters.txt file can
#     contain all or any subset of parameters listed below. Note, that each {
#     must have a matching one }.
#
#  7) phenix.fmodel model.pdb reflection_data.mtz
#
#     will result in a file containing a set of Fmodel = Fcalc that will match
#     the set of Miller indices of the data in reflection_data.mtz file.
#
#  8) phenix.fmodel model.pdb reflection_data.mtz data_column_label="FOBS,SIGMA"
#
#     similar to "7)", where the specific data array is selected.
#
#  9) phenix.fmodel model.pdb reflection_data.mtz twin_law="l,-k,h" twin_fraction=0.3
#
#     generates twin data set (real type) with given twin law and fraction.
#
#See below for complete list of available parameters.
#"""
#
#fmodel_from_xray_structure_params_str = """\
#fmodel
#  .short_caption = F(model) options
#  .expert_level = 1
#  .style = auto_align box
#{
#  k_sol = 0.0
#    .type = float
#    .help = Bulk solvent k_sol values
#    .short_caption=Bulk solvent K_sol value
#  b_sol = 0.0
#    .type = float
#    .help = Bulk solvent b_sol values
#    .short_caption=Bulk solvent B_sol value
#  b_cart = 0 0 0 0 0 0
#    .type = floats(6)
#    .help = Anisotropic scale matrix
#    .input_size = 200
#    .short_caption = Anisotropic scale matrix
#  scale = 1.0
#    .type = float
#    .help = Overall scale factor
#}
#structure_factors_accuracy
#  .short_caption = Structure factors accuracy
#  .style = auto_align box
#{
#  include scope mmtbx.f_model.sf_and_grads_accuracy_master_params
#}
#mask
#  .short_caption = Bulk solvent mask
#  .style = auto_align box
#{
#  include scope mmtbx.masks.mask_master_params
#}
#"""
#fmodel_from_xray_structure_params = iotbx.phil.parse(
#  fmodel_from_xray_structure_params_str, process_includes=True)
#
#fmodel_from_xray_structure_master_params_str = """\
#high_resolution = None
#  .type = float
#  .expert_level=1
#  .style = noauto bold
#low_resolution = None
#  .type = float
#  .expert_level=1
#  .style = noauto
#r_free_flags_fraction = None
#  .type = float
#  .expert_level=1
#  .style = noauto
#add_sigmas = False
#  .type = bool
#  .expert_level=1
#  .help = Adds calculated Sigma(F) column to output file.
#  .style = noauto
#add_random_error_to_amplitudes_percent = None
#  .type = float
#  .short_caption = Add random error (percent)
#  .style = noauto
#scattering_table = wk1995  it1992  *n_gaussian  neutron electron
#  .type = choice
#  .help = Choices of scattering table for structure factors calculations.  \
#    n_gaussian is the standard set of X-ray scattering factors.
#  .expert_level=1
#  .style = noauto
#custom_scattering_factors = None
#  .type = path
#  .help = Use custom scattering factors and replaces default values entirely
#pdb_file = None
#  .type = path
#  .multiple = True
#  .optional = True
#  .short_caption = Model file
#  .style = bold noauto file_type:pdb input_file OnChange:update_output_file_name
#reference_file = None
#  .type = path
#  .short_caption = Reference set
#  .help = Reflections file containing Miller indices (h,k,l) to use in output \
#    file.
#  .style = noauto input_file file_type:mtz OnChange:update_reference_column_labels
#data_column_label = None
#  .type = str
#  .short_caption = Reference file label
#  .style = noauto renderer:draw_any_label_widget
#%s
#random_seed=None
#  .type = int
#  .help = Random seed
#  .expert_level=2
#twin_law = None
#  .type = str
#  .help = Optional twin law if we want to generate a twinned dataset
#  .input_size = 120
#  .style = noauto
#twin_fraction = None
#  .type = float
#  .help = Twin fraction, ignored if twin_law is not specified
#  .style = noauto
#wavelength = None
#  .type = float
#  .input_size = 80
#  .help = Wavelength, sets all atoms to anomalous
#  .style = noauto
#generate_fake_p1_symmetry = False
#  .type = bool
#  .short_caption = Generate fake symmetry if necessary
#  .help = Allows use of PDB files without CRYST1 records as input.  The \
#    crystal symmetry will be assumed to be a P1 box.
#output
#  .short_caption = Reflection output
#  .expert_level=0
#  .style = noauto
#{
#  format = *mtz cns
#    .type = choice
#    .short_caption = File format
#  label = FMODEL
#    .type = str
#    .short_caption = Data label
#    .input_size = 100
#  type = real *complex
#    .type = choice
#    .short_caption = Output data type
#    .help = Numeric type of output data.  'real' is amplitudes only, \
#      'complex' is complete structure factors as complex numbers.
#    .expert_level=1
#    .style = bold
#  obs_type = *amplitudes intensities
#    .type = choice
#    .help = Experimental observation type to output.  Certain restrictions \
#      apply if intensities are selected.
#    .expert_level = 2
#  file_name = None
#    .type = path
#    .short_caption = Output file
#    .style = bold noauto new_file
#  include scope libtbx.phil.interface.tracking_params
#}
#anomalous_scatterers
#  .short_caption = Anomalous sites
#  .style = menu_item noauto
#{
#  group
#    .optional = True
#    .multiple = True
#    .short_caption = Anomalous scatterer group
#    .style = auto_align
#  {
#    selection = None
#      .type = atom_selection
#      .short_caption = Atom selection
#      .input_size = 400
#    f_prime = 0
#      .type = float
#      .short_caption = f'
#    f_double_prime = 0
#      .type = float
#      .short_caption = f''
#  }
#}
#"""%fmodel_from_xray_structure_params_str
#
#fmodel_from_xray_structure_master_params = iotbx.phil.parse(
#  fmodel_from_xray_structure_master_params_str, process_includes=True)
#master_phil = fmodel_from_xray_structure_master_params # XXX for phenix docs
#
#def set_fp_fdp_for_anomalous_scatterers(pdb_hierarchy, xray_structure,
#  anomalous_scatterer_groups):
#  scatterers = xray_structure.scatterers()
#  for group in anomalous_scatterer_groups:
#    iselection = pdb_hierarchy.atom_selection_cache().selection(
#      string = group.selection).iselection()
#    if(iselection.size() == 0):
#      raise Sorry(
#        "Empty selection: selection string '%s' does not select any atom."%
#        group.selection)
#    for i_seq in iselection:
#      scatterers[i_seq].fp = group.f_prime
#      scatterers[i_seq].fdp = group.f_double_prime
#
#def run(args, log = sys.stdout):
#  print(legend, file=log)
#  # XXX: pre-processing for GUI; duplicates some of mmtbx.utils
#  sources = []
#  for arg in args :
#    if os.path.isfile(arg):
#      try :
#        file_phil = iotbx.phil.parse(file_name=arg)
#      except KeyboardInterrupt :
#        raise
#      except RuntimeError :
#        pass
#      else :
#        if len(file_phil.objects) != 0 :
#          sources.append(file_phil)
#  if len(sources) > 0 :
#    cmdline_phil = fmodel_from_xray_structure_master_params.fetch(
#      sources=sources)
#    params = cmdline_phil.extract()
#    if len(params.pdb_file) > 0 :
#      args.extend(params.pdb_file)
#    if params.reference_file is not None :
#      args.append(params.reference_file)
#  # end of preprocessing
#  processed_args = mmtbx.utils.process_command_line_args(args = args, log = log,
#    master_params = fmodel_from_xray_structure_master_params)
#  pdb_combined = iotbx.pdb.combine_unique_pdb_files(
#    file_names = processed_args.pdb_file_names)
#  pdb_combined.report_non_unique(out = log)
#  print("-"*79, file=log)
#  print("\nParameters to compute Fmodel::\n", file=log)
#  processed_args.params.show(out = log, prefix=" ")
#  params = processed_args.params.extract()
#  if(params.random_seed is not None):
#    random.seed(params.random_seed)
#    flex.set_random_seed(params.random_seed)
#  pdb_file_names = processed_args.pdb_file_names
#  if len(pdb_file_names) == 0 :
#    pdb_file_names = params.pdb_file # for GUI
#  pdb_combined = iotbx.pdb.combine_unique_pdb_files(file_names=pdb_file_names)
#  pdb_combined.report_non_unique(out = log)
#  if(len(pdb_combined.unique_file_names) == 0):
#    raise Sorry("Model file is not provided.")
#  print("-"*79, file=log)
#  print("\nInput model file(s):", " ".join(processed_args.pdb_file_names), file=log)
#  pdb_inp = iotbx.pdb.input(source_info = None,
#    lines = flex.std_string(pdb_combined.raw_records))
#  # select miller array to use as a set of miller indices for f_model
#  miller_array = None
#  if(len(processed_args.reflection_files) > 1):
#    raise Sorry("Multiple reflection files found at input.")
#  # FIXME this does not pick up the reference_file parameter!  in fact, it
#  # appears to be ignored completely when run on the command line.
#  if(len(processed_args.reflection_files) == 1):
#    print("-"*79, file=log)
#    print("Input reflection data:", \
#      " ".join(processed_args.reflection_file_names), file=log)
#    if([params.high_resolution, params.low_resolution].count(None) != 2):
#      raise Sorry("high_resolution and low_resolution must be undefined "+
#                  "if reflection data file is given.")
#    miller_arrays = processed_args.reflection_files[0].as_miller_arrays()
#    data_sizes = flex.int([ma.data().size() for ma in miller_arrays])
#    if(data_sizes.all_eq(data_sizes[0])): miller_array = miller_arrays[0]
#    else:
#      all_labels = []
#      for ma in miller_arrays:
#        if(params.data_column_label is not None and
#           ma.info().label_string() == params.data_column_label):
#          miller_array = ma
#          break
#        all_labels.append(",".join(ma.info().labels))
#    if(miller_array is None):
#      raise Sorry("Multiple data available in input reflection file:\n%s\n%s"%(
#        "\n".join(all_labels),"Please select one using 'data_column_label=' keyword."))
#    else:
#      miller_array.show_comprehensive_summary(f = log, prefix="  ")
#  if(miller_array is not None):
#    miller_array = miller_array.map_to_asu().customized_copy(
#      data = flex.double(miller_array.data().size(), 1))
#  #
#  cryst1 = pdb_inp.crystal_symmetry_from_cryst1()
#  if(cryst1 is None and miller_array is not None):
#    cryst1 = miller_array.crystal_symmetry()
#    if (cryst1 is not None) and (params.generate_fake_p1_symmetry):
#      raise Sorry("The input reference data already define crystal symmetry; "+
#        "you may not use this in combination with the option "+
#        "generate_fake_p1_symmetry=True.")
#  if (not params.generate_fake_p1_symmetry):
#    if(cryst1 is None):
#      raise Sorry(
#        "CRYST1 record in input PDB file is incomplete or missing.  "+
#        "If you want the program to generate P1 symmetry automatically, set "+
#        "generate_fake_p1_symmetry=True.")
#    else:
#      if([cryst1.unit_cell(), cryst1.space_group_info()].count(None) != 0):
#        raise Sorry(
#          "CRYST1 record in input PDB file is incomplete or missing. "+
#          "If you want the program to generate P1 symmetry automatically, "+
#          "set generate_fake_p1_symmetry=True.")
#  pdb_hierarchy = pdb_inp.construct_hierarchy()
#  # need to preserve the order in the hierarchy in case we have to perform an
#  # atom selection later
#  xray_structure = pdb_hierarchy.extract_xray_structure(
#    crystal_symmetry = cryst1)
#  if (cryst1 is None):
#    cryst1 = xray_structure.crystal_symmetry()
#  if (miller_array is not None):
#    if (miller_array.crystal_symmetry() is None):
#      miller_array = miller_array.customized_copy(crystal_symmetry=cryst1)
#  xray_structure.show_summary(f = log, prefix="  ")
#  if(len(params.anomalous_scatterers.group) != 0):
#    pdb_atoms = pdb_hierarchy.atoms()
#    pdb_atoms.reset_i_seq()
#    set_fp_fdp_for_anomalous_scatterers(
#      pdb_hierarchy              = pdb_hierarchy,
#      xray_structure             = xray_structure,
#      anomalous_scatterer_groups = params.anomalous_scatterers.group)
#  elif (params.wavelength is not None):
#    if (params.scattering_table == "neutron"):
#      raise Sorry("Wavelength parameter not supported when the neutron "+
#        "scattering table is used.")
#    print("Setting inelastic form factors for wavelength = %g" % \
#      params.wavelength, file=log)
#    xray_structure.set_inelastic_form_factors(
#      photon=params.wavelength,
#      table="sasaki")
#  #
#  validate_params_command_line(params)
#  #
#  print("-"*79, file=log)
#  print("Computing model structure factors, Fmodel:", file=log)
#  if(params.output.format == "cns"): extension = ".hkl"
#  elif(params.output.format == "mtz"): extension = ".mtz"
#  ofn = params.output.file_name
#  if(ofn is None):
#    ofn = os.path.basename(processed_args.pdb_file_names[0])
#    if(len(processed_args.pdb_file_names)==1): ofn = ofn + extension
#    else: ofn = ofn + "_et_al" + extension
#  if([miller_array, params.high_resolution].count(None)==2):
#    raise Sorry("Input data file or high_resolution has to be provided.")
#  use_custom_scattering_dictionary = False
#  if params.custom_scattering_factors:
#    use_custom_scattering_dictionary = True
#  mmtbx.utils.fmodel_from_xray_structure(
#    xray_structure = xray_structure,
#    f_obs          = miller_array,
#    add_sigmas     = params.add_sigmas,
#    params         = params,
#    twin_law       = params.twin_law,
#    twin_fraction  = params.twin_fraction,
#    use_custom_scattering_dictionary = use_custom_scattering_dictionary,
#    out            = log).write_to_file(file_name = ofn,
#      obs_type=params.output.obs_type)
#  print("Output file name:", ofn, file=log)
#  print("All done.", file=log)
#  print("-"*79, file=log)
#  return ofn
#
#class launcher(runtime_utils.target_with_save_result):
#  def run(self):
#    return run(args=list(self.args), log=sys.stdout)
#
#def validate_params(params, callback=None):
#  if len(params.pdb_file) == 0 :
#    raise Sorry("You must provide at least one model file to use for "+
#      "F(model) calculations.")
#  if (params.high_resolution is None):
#    if (params.reference_file is None):
#      raise Sorry("Please specify a high-resolution cutoff.")
#  elif (params.reference_file is not None):
#    if (params.data_column_label is None):
#      raise Sorry("Please select a column label to use in the reference "+
#        "data file.")
#    elif ([params.high_resolution, params.low_resolution].count(None) != 2):
#      raise Sorry("High resolution and low resolution must be undefined "+
#                  "if reflection data file is given.")
#  if (params.output.file_name is None):
#    raise Sorry("Please specify an output file.")
#  validate_params_command_line(params)
#
#def validate_params_command_line(params):
#  if (params.output.type == "complex") and (params.add_sigmas):
#    raise Sorry("Sigma values only supported when the output type is 'real'.")
#  if (    params.low_resolution is not None
#      and params.high_resolution is not None):
#    if params.low_resolution < params.high_resolution :
#      raise Sorry("Low-resolution cutoff must be larger than the high-"+
#        "resolution cutoff.")
#  if (params.output.obs_type == "intensities"):
#    if (params.output.type == "complex"):
#      raise Sorry("Output type must be 'real' when intensities specified "+
#        "for obs_type.")
#    if (not params.output.label.upper().startswith("I")):
#      raise Sorry("Output label must start with 'I' (any case) when "+
#        "intensities specified for obs_type (was: %s)." % params.output.label)
#    if (params.output.format != "mtz"):
#      raise Sorry("Output format must be 'mtz' when intensities specified.")
#  return True
#
#def finish_job(result):
#  output_files = []
#  if (result is not None) and (os.path.isfile(result)):
#    output_files.append((os.path.abspath(result), "MTZ file"))
#  return (output_files, [])
#
#if (__name__ == "__main__"):
#  run(args=sys.argv[1:])
#


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/fobs_minus_fobs_map.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.fobs_minus_fobs_map

import mmtbx.maps.fobs_minus_fobs_map
import sys

if(__name__ == "__main__"):
  mmtbx.maps.fobs_minus_fobs_map.run(args = sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/geometry_minimization.py
# LIBTBX_SET_DISPATCHER_NAME phenix.geometry_minimization

from __future__ import absolute_import, division, print_function
import mmtbx.refinement.geometry_minimization
import mmtbx.utils
from iotbx.pdb import combine_unique_pdb_files
import iotbx.phil
from cctbx.array_family import flex
from libtbx.utils import user_plus_sys_time, Sorry
from libtbx import runtime_utils
import os
import sys
from six.moves import cStringIO as StringIO
from mmtbx.monomer_library import pdb_interpretation
from mmtbx.hydrogens import riding
import mmtbx.model
from cctbx import uctbx

base_params_str = """\
silent = False
  .type = bool
write_geo_file = True
  .type = bool
file_name = None
  .type = path
  .short_caption = Model file
  .style = file_type:pdb bold input_file
show_states = False
  .type = bool
restraints = None
  .type = path
  .multiple = True
  .short_caption = Restraints
  .style = file_type:cif bold input_file
restraints_directory = None
  .type = path
  .style = directory
output_file_name_prefix = None
  .type = str
  .input_size = 400
  .style = bold
directory = None
  .type = path
  .short_caption = Output directory
  .style = output_dir
include scope libtbx.phil.interface.tracking_params
fix_rotamer_outliers = True
  .type = bool
  .help = Remove outliers
allow_allowed_rotamers = True
  .type = bool
  .help = More strict fixing outliers
stop_for_unknowns = True
  .type = bool
  .short_caption = Stop for unknown residues
  .style = noauto
include scope mmtbx.monomer_library.pdb_interpretation.grand_master_phil_str
include scope \
    mmtbx.geometry_restraints.torsion_restraints.reference_model.reference_model_params
"""

master_params_str = """
%s
selection = all
  .type = str
  .help = Atom selection string: selected atoms are subject to move
  .short_caption = Atom selection
  .input_size = 400
minimization
  .help = Geometry minimization parameters
  .short_caption = Minimization parameters
  .expert_level=1
{
  max_iterations = 500
    .type = int
    .help = Maximun number of minimization iterations
    .short_caption = Max. iterations
    .style = noauto
  macro_cycles = 5
    .type = int
    .help = Number of minimization macro-cycles
  alternate_nonbonded_off_on = False
    .type = bool
    .short_caption = Macro cycles
    .style = noauto
  rmsd_bonds_termination_cutoff = 0
    .type = float
    .help = stop after reaching specified cutoff value
  rmsd_angles_termination_cutoff = 0
    .type = float
    .help = stop after reaching specified cutoff value
  grms_termination_cutoff = 0
    .type = float
    .help = stop after reaching specified cutoff value
  correct_special_position_tolerance = 1.0
    .type = float
  riding_h = True
    .type = bool
    .help = Use riding model for H
  move
    .help = Define what to include into refinement target
    .short_caption = Geometry terms
    .style = box auto_align columns:4 noauto
  {
  bond = True
    .type = bool
    .short_caption = Bond lengths
  nonbonded = True
    .type = bool
    .short_caption = Nonbonded distances
  angle = True
    .type = bool
    .short_caption = Bond angle
  dihedral = True
    .type = bool
    .short_caption = Dihedral angle
  chirality = True
    .type = bool
    .short_caption = Chirality
  planarity = True
    .type = bool
    .short_caption = Planarity
  parallelity = True
    .type = bool
    .short_caption = Parallelity
  }
}
  include scope mmtbx.geometry_restraints.external.external_energy_params_str
""" % base_params_str

def master_params():
  return iotbx.phil.parse(master_params_str, process_includes=True)

def broadcast(m, log):
  print("-"*79, file=log)
  print(m, file=log)
  print("*"*len(m), file=log)

def format_usage_message(log):
  print("-"*79, file=log)
  msg = """\
phenix.geometry_minimization: regularize model geometry

Usage examples:
  phenix.geometry_minimization model.pdb
  phenix.geometry_minimization model.pdb ligands.cif
"""
  print(msg, file=log)
  print("-"*79, file=log)

def run_minimization(
      selection,
      restraints_manager,
      riding_h_manager,
      pdb_hierarchy,
      params,
      cdl,
      rdl,
      correct_hydrogens,
      states_collector,
      fix_rotamer_outliers,
      allow_allowed_rotamers,
      log,
      ncs_restraints_group_list = [],
      mon_lib_srv = None):
  o = mmtbx.refinement.geometry_minimization.run2(
    restraints_manager             = restraints_manager,
    riding_h_manager               = riding_h_manager,
    pdb_hierarchy                  = pdb_hierarchy,
    ncs_restraints_group_list      = ncs_restraints_group_list,
    max_number_of_iterations       = params.max_iterations,
    number_of_macro_cycles         = params.macro_cycles,
    selection                      = selection,
    correct_special_position_tolerance = params.correct_special_position_tolerance,
    bond                           = params.move.bond,
    nonbonded                      = params.move.nonbonded,
    angle                          = params.move.angle,
    dihedral                       = params.move.dihedral,
    chirality                      = params.move.chirality,
    planarity                      = params.move.planarity,
    parallelity                    = params.move.parallelity,
    rmsd_bonds_termination_cutoff  = params.rmsd_bonds_termination_cutoff,
    rmsd_angles_termination_cutoff = params.rmsd_angles_termination_cutoff,
    alternate_nonbonded_off_on     = params.alternate_nonbonded_off_on,
    cdl                            = cdl,
    rdl                            = rdl,
    states_collector               = states_collector,
    correct_hydrogens              = correct_hydrogens,
    fix_rotamer_outliers           = fix_rotamer_outliers,
    allow_allowed_rotamers         = allow_allowed_rotamers,
    log                            = log,
    mon_lib_srv                    = mon_lib_srv)

def run_minimization_amber(
      selection,
      restraints_manager,
      pdb_hierarchy,
      params,
      log,
      prmtop,
      ambcrd,
      ):
  import amber_adaptbx.amber_geometry_minimization
  o = amber_adaptbx.amber_geometry_minimization.run(
    restraints_manager             = restraints_manager,
    pdb_hierarchy = pdb_hierarchy,
    max_number_of_iterations       = params.max_iterations,
    number_of_macro_cycles         = params.macro_cycles,
    selection                      = selection,
    bond                           = params.move.bond,
    nonbonded                      = params.move.nonbonded,
    angle                          = params.move.angle,
    dihedral                       = params.move.dihedral,
    chirality                      = params.move.chirality,
    planarity                      = params.move.planarity,
    parallelity                    = params.move.parallelity,
    grms_termination_cutoff       = params.grms_termination_cutoff,
    alternate_nonbonded_off_on     = params.alternate_nonbonded_off_on,
    log                            = log,
    prmtop                         = prmtop,
    ambcrd                         = ambcrd,
    )

class run(object):
  _pdb_suffix = "minimized"
  def __init__(self, args, log, use_directory_prefix=True):
    # You are not supposed to put here (in __init__) any time-consuming stuff,
    # otherwise self.total_time would be unaccurate. It's not clear
    # why it is important.
    self.model                = None
    self.log                  = log
    self.params               = None
    self.inputs               = None
    self.args                 = args
    self.selection            = None
    self.restrain_selection   = None
    self.time_strings         = []
    self.total_time           = 0
    self.pdb_file_names       = []
    self.use_directory_prefix = use_directory_prefix
    self.sites_cart_start     = None
    self.states_collector     = None
    self.__execute()

  def __execute(self):
    #
    self.caller(self.initialize,            "Initialization, inputs")
    self.caller(self.process_inputs,        "Processing inputs")
    self.caller(self.atom_selection,        "Atom selection")
    self.caller(self.get_restraints,        "Geometry Restraints")
    self.caller(self.setup_riding_h,        "Setup riding H")
    self.caller(self.minimization,          "Minimization")
    self.caller(self.write_pdb_file,        "Write PDB file")
    self.caller(self.write_geo_file,        "Write GEO file")
    self.caller(self.show_model_statistics, "Model statistics")
    #
    self.show_times()

  def master_params(self):
    return master_params()

  def caller(self, func, prefix):
    timer = user_plus_sys_time()
    func(prefix = prefix)
    t = timer.elapsed()
    self.total_time += t
    self.time_strings.append("  %s: %s"%(prefix, str("%8.3f"%t).strip()))

  def show_times(self):
    broadcast(m="Detailed timing", log = self.log)
    max_len = 0
    for ts in self.time_strings:
      lts = len(ts)
      if(lts > max_len): max_len = lts
    fmt = "  %-"+str(lts)+"s"
    for ts in self.time_strings:
      sts = ts.split()
      l = " ".join(sts[:len(sts)-1])
      print(fmt%l, sts[len(sts)-1], file=self.log)
    print("  Sum of individual times: %s"%\
      str("%8.3f"%self.total_time).strip(), file=self.log)

  def format_usage_message(self):
    format_usage_message(log=self.log)

  def setup_output_file_names(self):
    # for pdb
    ofn = self.params.output_file_name_prefix
    directory = self.params.directory
    base_name = ""
    if self.use_directory_prefix and directory is not None:
      base_name = directory
    suffix = "_" + self._pdb_suffix  + ".pdb"
    if self.params.output_file_name_prefix is None:
      in_fn = os.path.basename(self.pdb_file_names[0])
      ind = max(0, in_fn.rfind("."))
      ofn = in_fn + suffix
      if ind > 0:
        ofn = in_fn[:ind]+suffix
    else:
      ofn = self.params.output_file_name_prefix+".pdb"
    self.result_model_fname = os.path.join(base_name, ofn)
    self.result_states_fname = self.result_model_fname[:].replace(".pdb","_all_states.pdb")
    self.final_geo_fname = self.result_model_fname[:].replace(".pdb",".geo")

  def initialize(self, prefix):
    if (self.log is None) : self.log = sys.stdout
    if(len(self.args)==0):
      self.format_usage_message()
    parsed = self.master_params()
    self.inputs = mmtbx.utils.process_command_line_args(args = self.args,
      master_params = parsed)
    self.params = self.inputs.params.extract()
    if(self.params.silent): self.log = StringIO()
    broadcast(m=prefix, log = self.log)
    self.inputs.params.show(prefix="  ", out=self.log)
    if(len(self.args)==0): sys.exit(0)

  def process_inputs(self, prefix):
    broadcast(m=prefix, log = self.log)
    self.pdb_file_names = list(self.inputs.pdb_file_names)
    if(self.params.file_name is not None):
      self.pdb_file_names.append(self.params.file_name)

    #=================================================
    cs = self.inputs.crystal_symmetry
    is_non_crystallographic_unit_cell = False
    import iotbx.pdb
    pdb_combined = combine_unique_pdb_files(file_names = self.pdb_file_names)
    pdb_inp = iotbx.pdb.input(lines=pdb_combined.raw_records, source_info=None)
    if(cs is None):
      cs=pdb_inp.crystal_symmetry()
    if(cs is None):
      is_non_crystallographic_unit_cell = True
      box = uctbx.non_crystallographic_unit_cell_with_the_sites_in_its_center(
        sites_cart   = pdb_inp.atoms().extract_xyz(),
        buffer_layer = 10)
      cs = box.crystal_symmetry()
    cif_objects = list(self.inputs.cif_objects)
    if (len(self.params.restraints) > 0):
      import iotbx.cif
      for file_name in self.params.restraints :
        cif_object = iotbx.cif.reader(file_path=file_name, strict=False).model()
        cif_objects.append((file_name, cif_object))
    if (self.params.restraints_directory is not None):
      restraint_files = os.listdir(self.params.restraints_directory)
      for file_name in restraint_files :
        if (file_name.endswith(".cif")):
          full_path = os.path.join(self.params.restraints_directory, file_name)
          cif_object = iotbx.cif.reader(file_path=full_path,
            strict=False).model()
          cif_objects.append((full_path, cif_object))
    self.model = mmtbx.model.manager(
        model_input = pdb_inp,
        crystal_symmetry = cs,
        restraint_objects = cif_objects,
        stop_for_unknowns = self.params.stop_for_unknowns,
        log = self.log)
    self.model.process(
      pdb_interpretation_params = self.params,
      make_restraints           = True)
    self.ncs_obj = self.model.get_ncs_obj()
    self.output_crystal_symmetry = not is_non_crystallographic_unit_cell
    self.sites_cart_start = self.model.get_xray_structure().sites_cart().deep_copy()
    if(self.params.show_states):
      self.states_collector = mmtbx.utils.states(
        xray_structure = self.model.get_xray_structure(),
        pdb_hierarchy  = self.model.get_hierarchy())
    self.setup_output_file_names()

  def atom_selection(self, prefix):
    broadcast(m=prefix, log = self.log)
    self.selection = self.model.selection(string = self.params.selection)
    print("  selected %s atoms out of total %s"%(
      str(self.selection.count(True)),str(self.selection.size())), file=self.log)

  def get_restraints(self, prefix):
    broadcast(m=prefix, log = self.log)
    self.model.get_restraints_manager()

  def setup_riding_h(self, prefix):
    if not self.params.minimization.riding_h: return
    broadcast(m=prefix, log = self.log)
    self.model.setup_riding_h_manager(idealize=True)

  def minimization(self, prefix): # XXX USE alternate_nonbonded_off_on etc
    broadcast(m=prefix, log = self.log)
    use_amber = False
    if self.ncs_obj is not None:
      print("Using NCS constraints:", file=self.log)
      self.ncs_obj.show(format='phil', log=self.log)
    ncs_restraints_group_list = []
    if self.ncs_obj is not None:
      ncs_restraints_group_list = self.ncs_obj.get_ncs_restraints_group_list()
    run_minimization(
      selection              = self.selection,
      restraints_manager     = self.model.get_restraints_manager(),
      riding_h_manager       = self.model.get_riding_h_manager(),
      params                 = self.params.minimization,
      pdb_hierarchy          = self.model.get_hierarchy(),
      cdl                    = self.params.pdb_interpretation.restraints_library.cdl,
      rdl                    = self.params.pdb_interpretation.restraints_library.rdl,
      correct_hydrogens      = self.params.pdb_interpretation.correct_hydrogens,
      fix_rotamer_outliers   = self.params.fix_rotamer_outliers,
      allow_allowed_rotamers = self.params.allow_allowed_rotamers,
      states_collector       = self.states_collector,
      log                    = self.log,
      ncs_restraints_group_list = ncs_restraints_group_list,
      mon_lib_srv            = self.model.get_mon_lib_srv())
    self.model.set_sites_cart_from_hierarchy()

  def write_pdb_file(self, prefix):
    broadcast(m=prefix, log = self.log)
    # self.pdb_hierarchy.adopt_xray_structure(self.xray_structure)
    print(self.min_max_mean_shift(), file=self.log)

    if self.model.can_be_output_as_pdb():
      print("  output file name:", self.result_model_fname, file=self.log)
      r = self.model.model_as_pdb(output_cs=self.output_crystal_symmetry)
      f = open(self.result_model_fname, 'w')
      f.write(r)
      f.close()

    cif_fname = self.result_model_fname.replace('.pdb', '.cif')
    if not os.path.isfile(cif_fname):
      print("  output file name:", cif_fname, file=self.log)
      r = self.model.model_as_mmcif(output_cs=self.output_crystal_symmetry)
      with open(cif_fname, 'w') as f:
        f.write(r)

    if(self.states_collector):
      self.states_collector.write(
        file_name=self.result_states_fname)

  def min_max_mean_shift(self):
    return "min,max,mean shift from start: %6.3f %6.3f %6.3f"%flex.sqrt((
      self.sites_cart_start - self.model.get_xray_structure().sites_cart()).dot()
      ).min_max_mean().as_tuple()

  def write_geo_file(self, prefix):
    if self.params.write_geo_file:
      broadcast(m=prefix, log = self.log)
      # no output of NCS stuff here
      restr_txt = self.model.restraints_as_geo()
      f = open(self.final_geo_fname, "w")
      f.write("# Geometry restraints after refinement\n")
      f.write(restr_txt)
      f.close()

  def show_model_statistics(self, prefix):
    if self.params.write_geo_file:
      broadcast(m=prefix, log = self.log)
      s = self.model.geometry_statistics()
      s.show(log = self.log, uppercase=False)

class launcher(runtime_utils.target_with_save_result):
  def run(self):
    os.mkdir(self.output_dir)
    os.chdir(self.output_dir)
    filename = run(args=self.args, log=sys.stdout,
                   use_directory_prefix=False).result_model_fname
    return os.path.join(self.output_dir, filename)

def validate_params(params):
  if (params.file_name is None):
    raise Sorry("Please specify a model file to minimize.")
  if (params.restraints_directory is not None):
    if (not os.path.isdir(params.restraints_directory)):
      raise Sorry("The path '%s' does not exist or is not a directory." %
        params.restraints_directory)
  return True

def finish_job(result):
  output_files = []
  if (result is not None):
    output_files.append((result, "Minimized model"))
  return output_files, []

if(__name__ == "__main__"):
  timer = user_plus_sys_time()
  log = sys.stdout
  o = run(sys.argv[1:], log=log)
  tt = timer.elapsed()
  print("Overall runtime: %-8.3f" % tt, file=o.log)
  assert abs(tt-o.total_time) < 0.1 # guard against unaccounted times


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/grow_density.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.grow_density

from mmtbx import grow_density
import sys

if(__name__ == "__main__"):
  grow_density.cmd_run(
    args         = sys.argv[1:],
    command_name = "phenix.grow_density")


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/hbond.py
from __future__ import division
# LIBTBX_SET_DISPATCHER_NAME phenix.hbond

from mmtbx.programs import hbond
from iotbx.cli_parser import run_program

if __name__ == "__main__":
  run_program(hbond.Program)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/helix_sheet_recs_as_pdb_files.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.helix_sheet_recs_as_pdb_files

import sys
import iotbx.pdb
from libtbx.utils import Sorry

legend = """phenix.helix_sheet_recs_as_pdb_files:
  Given PDB file with HELIX/SHEET records output PDB files corresponding to
  each individual HELIX/SHEET record.

How to run:
  phenix.helix_sheet_recs_as_pdb_files model.pdb

Feedback:
  PAfonine@lbl.gov
  phenixbb@phenix-online.org"""

def run(args):
  if(len(args)!=1): raise Sorry("PDB file must be provided.")
  pdb_inp = iotbx.pdb.input(file_name = args[0])
  h = pdb_inp.construct_hierarchy()
  asc = h.atom_selection_cache()
  sso = pdb_inp.extract_secondary_structure()
  for rec in sso.sheets+sso.helices:
    file_name = "_".join(rec.as_pdb_str().split())
    file_name = file_name[:min(36, len(file_name))]
    file_name += ".pdb"
    sel_list = rec.as_atom_selections()
    assert type(sel_list) == list
    if(len(sel_list) == 1):
      sel_str=sel_list[0]
    else:
      sel_str=" or ".join( ["(%s)"%s for s in rec.as_atom_selections()] )
    sel = asc.selection(string=sel_str)
    h_selected = h.select(sel)
    h_selected.write_pdb_file(file_name=file_name)

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/holton_geometry_validation.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.holton_geometry_validation
# LIBTBX_SET_DISPATCHER_NAME mmtbx.holton_geometry_validation
# LIBTBX_PRE_DISPATCHER_INCLUDE_SH export PHENIX_GUI_ENVIRONMENT=1

from mmtbx.programs import holton_geometry_validation
from iotbx.cli_parser import run_program

if __name__ == '__main__':
  run_program(program_class=holton_geometry_validation.Program)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/hydrogenate.py
# LIBTBX_SET_DISPATCHER_NAME mmtbx.debugging.hydrogenate
from __future__ import absolute_import, division, print_function

from iotbx.cli_parser import run_program
from mmtbx.programs import hydrogenate

if __name__ == "__main__":
  run_program(hydrogenate.Program)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/kinemage.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.kinemage
# LIBTBX_SET_DISPATCHER_NAME molprobity.kinemage

import sys
from mmtbx.kinemage import validation

if __name__ == "__main__":
  validation.run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/ligand_restraints_validation.py
# LIBTBX_SET_DISPATCHER_NAME mmtbx.development.ligand_restraints_validation
from __future__ import absolute_import, division, print_function

from iotbx.cli_parser import run_program
from mmtbx.programs.ligand_restraints_validation import Program

if (__name__ == '__main__'):
  results = run_program(program_class=Program)


 *******************************************************************************


 *******************************************************************************
mmtbx/command_line/map_box.py
from __future__ import absolute_import, division, print_function
# LIBTBX_SET_DISPATCHER_NAME phenix.map_box

import mmtbx.utils
import mmtbx.model
from libtbx import adopt_init_args
from mmtbx.refinement import print_statistics
import libtbx.phil
from libtbx.utils import Sorry
import os, sys
from iotbx import reflection_file_utils
from cctbx import maptbx
from scitbx.matrix import col
from six.moves import zip
from iotbx.map_manager import map_manager

master_phil = libtbx.phil.parse("""
  include scope libtbx.phil.interface.tracking_params
  pdb_file = None
    .type = path
    .help = Optional model file used to define region to be cut out
    .short_caption = Model file (optional)
    .style = file_type:pdb bold input_file
  map_coefficients_file = None
    .type = path
    .help = Input map coefficients file (alternative to ccp4 map file)
    .short_caption = Map coefficients
    .style = file_type:hkl bold input_file process_hkl child:map_labels:label
  label = None
    .type = str
    .short_caption = Map labels
    .help = Labels for map coefficients file
    .style = renderer:draw_map_arrays_widget parent:file_name:map_coefficients_file
  ccp4_map_file = None
    .help = Input map file (CCP4/mrc format).
    .short_caption = Input map file
    .type = path
    .style = file_type:ccp4_map bold input_file
  mask_file_name = None
    .help = Input mask file (CCP4/mrc format).
    .short_caption = Input mask file
    .type = str
  target_ncs_au_file = None
    .help = File with model indicating which au to choose in extract_unique
    .short_caption = Input target ncs au file
    .type = str
  selection = all
    .type = str
    .help = Atom selection to be applied to input PDB file
    .short_caption = Atom selection (optional)
    .input_size = 400
  selection_radius = 3.0
    .type = float
    .help = Atoms within selection_radius of a selected atom model will be\
             kept as part of the selection.
    .short_caption = Selection radius
  box_cushion = 3.0
    .type = float
    .help = If model is supplied, a box of density will be cut out around\
            the input model (after selections are applied to the model). \
            The size of the box of density will be box_cushion bigger than \
            the model.  Box cushion also applied if density_select is set.\
            Box cushion is also used in extract_unique.
    .short_caption = Box cushion

  mask_atoms = False
    .type = bool
    .help = Set map values to 0 outside molecular mask
    .short_caption = Mask atoms

  mask_atoms_atom_radius = 3.
    .type = float
     .help = Radius for masking around atoms
     .short_caption = Mask atoms atom radius

  write_mask_file = False
     .type = bool
     .help = Write mask file. Requires setting mask_atoms
     .short_caption = Write mask file

  set_outside_to_mean_inside = False
    .type = bool
    .help = Set value outside mask equal to mean inside
    .short_caption = Set outside to mean inside

  resolution_factor = 1./4
    .type = float
    .help = Resolution factor for calculation of map coefficients
    .short_caption = Resolution factor
  map_scale_factor = None
    .type = float
    .help = Scale factor to apply to map
    .short_caption = Map scale factor
  scale_max = 99999
    .type = float
    .help = Maximum value of amplitudes for output mtz file. If None, apply\
             volume scaling
    .short_caption = Scale max
  resolution = None
    .type = float
    .help = Resolution for calculation of output map coefficients. Default is \
            based on the gridding of the map (and may be higher-resolution than\
            you want).
    .short_caption = Resolution
  output_format = xplor *mtz *ccp4
    .type = choice(multi = True)
    .help = Output format(s) for boxed map. Note that mtz format is only\
            available if keep_origin = False or keep_map_size = True. (These \
            are the cases where the map is cut down to size and placed \
            at the origin or there is a full unit cell of data.)
    .short_caption = Output format

  output_file_name_prefix = None
    .type = str
    .help = Prefix for output file names. Default is name of the pdb file \
            without the ".pdb" suffix.
    .short_caption = Output file name prefix

  mask_select = False
    .type = bool
    .help = Select boundaries (min, max in x, y, z) based on auto-mask
    .short_caption = Mask select

  density_select = False
    .type = bool
    .help = Select boundaries based on where density is located.
    .short_caption = Density select

  density_select_threshold = 0.05
    .type = float
    .help = Choose region where density is this fraction of maximum or greater
    .short_caption = density_select threshold

  get_half_height_width = True
    .type = bool
    .help = Use 4 times half-width at half-height as estimate of max size \
              in density_select
    .short_caption = Use half-height width

  symmetry = None
    .type = str
    .help = Optional symmetry (e.g., D7, I, C2) to be used if extract_unique\
            is set.  Alternative to symmetry_file.  To find symmetry \
            automatically specify symmetry = ALL.
    .short_caption = Symmetry
  symmetry_file = None
    .type = path
    .help = Symmetry file.\
            Symmetry or symmetry_file required if extract_unique = True.  \
            May be a \
            Phenix .ncs_spec file or BIOMTR records or a resolve ncs file.
    .short_caption = Symmetry file

  sequence_file = None
    .type = path
    .help = Sequence file (any standard format). Can be unique part or \
            all copies.  Used in identification of unique part of map \
            and in masking with mask_select
    .short_caption = Sequence file (optional)

  molecular_mass = None
    .type = float
    .help = Molecular mass of object in map in Da (i.e., 33000 for 33 Kd).\
              Used in identification \
            of unique part of map and in masking by mask_select.
    .short_caption = Molecular mass (optional)

  solvent_content = None
    .type = float
    .help = Optional fraction of volume of map that is empty.  \
            Used in identification \
            of unique part of map and in masking by mask_select
    .short_caption = Solvent content

  extract_unique = False
    .type = bool
    .help = Extract unique part of map. Requires either symmetry_file or \
            symmetry and\
            either sequence file or molecular mass to be supplied. If chain \
            type is not protein it should be set as well.
    .short_caption = Extract unique

  increase_box_cushion_and_atom_radius_for_soft_mask = True
    .type = bool
    .help = Expand cushion and atom radii by soft_mask_radius
    .short_caption = Increase box cushion and atom radius for soft mask

  soft_mask_extract_unique = True
    .type = bool
    .help = Create soft mask at edges of extract_unique box (feather map into \
               edge of box). Uses resolution as mask_radius
      .short_caption = Soft mask in extract unique

  mask_expand_ratio = 1
      .type = float
      .help = Mask expansion relative to resolution for extract_unique
      .short_caption = Mask expand ratio

  regions_to_keep = None
    .type = int
    .short_caption = Regions to keep
    .help = You can specify a limit to the number of regions to keep\
             when generating the asymmetric unit of density.

  keep_low_density = True
    .type = bool
    .help = Get remainder (weak density) with extract_unique.
    .short_caption = Get remainder


  chain_type = None *PROTEIN DNA RNA
    .type = choice
    .help = Chain type. Only used if extract_unique is set. Has minor effect \
            in setting thresholds for identification of molecular region.\
            Use None if there is a mixture.
    .short_caption = Chain type

  soft_mask = False
    .type = bool
    .help = Use Gaussian mask in mask_atoms and on outside surface of box
    .short_caption = Soft mask

  invert_mask = False
    .type = bool
    .help = Make mask with 1 outside model (only applies to mask_around_atoms)
    .short_caption = Invert mask to outside atoms

  soft_mask_radius = 3
    .type = float
    .help = Gaussian mask smoothing radius
    .short_caption = Soft mask radius

  lower_bounds = None
    .type = ints
    .help = Lower bounds for cut out box. You can specify them directly.\
            NOTE: lower and upper bounds refer to grid points after shifting \
            the map to place the origin at (0, 0, 0). To refer to absolute \
            values specify bounds_are_absolute = True.
    .short_caption = Lower bounds

  upper_bounds = None
    .type = ints
    .help = Upper bounds for cut out box.  You can specify them directly.\
            NOTE: lower and upper bounds refer to grid points after shifting \
            the map to place the origin at (0, 0, 0). To refer to absolute \
            values specify bounds_are_absolute = True.
    .short_caption = Upper bounds

  bounds_are_absolute = False
    .type = bool
    .help = Define lower and upper bounds as absolute. \
            NOTE: lower and upper bounds refer to grid points after shifting \
            the map to place the origin at (0, 0, 0). To refer to absolute \
            values specify bounds_are_absolute = True.
    .short_caption = Bounds are absolute

  zero_outside_original_map = False
    .type = bool
    .help = If bounds for new map are outside original map, zero all points\
             outside of original map
    .short_caption = Zero outside original map
  keep_map_size = False
    .type = bool
    .help = Keep original map gridding (do not cut anything out). \
            Use to apply soft_mask and/or mask_atoms keeping same map size.
    .short_caption = Keep map size

  keep_origin = True
    .type = bool
    .help = Write out map, map_coefficients, and model \
            with origin in original location.  \
            If False, shift the origin to (0, 0, 0).  \
            NOTE: to cut out a part of a map, shift the origin to (0, 0, 0), \
               and make a new small map use keep_origin = False\
               keep_input_unit_cell_and_grid = False
    .short_caption = Keep origin

  keep_input_unit_cell_and_grid = True
     .type = bool
     .help = Keep the input unit_cell dimensions and unit_cell_grid. \
             If False, use the dimensions and grid of the cut out box as the \
              unit cell map_box dimensions and grid.\
            NOTE: to cut out a part of a map, shift the origin to (0, 0, 0), \
               and make a new small map set keep_origin = False and \
               keep_input_unit_cell_and_grid = False
     .short_caption = Keep input unit cell and grid

  output_unit_cell = None
     .type = floats
     .help = You can specify the unit cell for your map with 3 numbers. \
              This should normally\
             not be necessary. It can be used to fix a map that has the \
             wrong unit cell.
     .short_caption = Output unit cell
     .expert_level = 3

  output_unit_cell_grid = None
    .type = ints
    .help = You can specify the grid (3 integers) corresponding to the \
              output unit cell. \
              This can be used to specify the full grid for the unit cell. \
              if output_unit_cell is not specified, new unit cell parameters\
              will be generated to maintain the grid spacing.
    .short_caption = Output unit cell grid
    .expert_level = 3

  output_origin_grid_units = None
    .type = ints
    .help = You can specify the origin of your output map.  Normally you \
           should use keep_origin = True or False to specify your origin \
           but if you want to move it to a specific grid point you can do that.\
    .short_caption = Output origin
    .expert_level = 3

  output_origin_match_this_file = None
    .type = path
    .help = As output_origin_grid_units, but use origin from this file
    .short_caption = File with origin info

  bounds_match_this_file = None
    .type = path
    .help = Take the lower and upper bounds from this map file and apply them \
             to the input map file.
    .short_caption = File with bounds to match

  output_external_origin = None
    .type = floats
    .help = Write ORIGIN record to map file (this is an external origin \
            used to specify relationship to external files such as model files.\
            Three floating point numbers (A).
    .short_caption = output external origin

  restrict_map_size = False
    .type = bool
    .help = Do not go outside original map boundaries
    .short_caption = Restrict map size

  ignore_symmetry_conflicts = False
    .type = bool
    .help = Ignore unit cell from model if it conflicts with the map.
    .short_caption = Ignore symmetry conflicts

  wrapping = False
    .type = bool
    .help = If wrapping, map wraps around at map boundaries.
    .short_caption = Wrapping

  check_wrapping = False
    .type = bool
    .help = Check that wrapping is consistent with map if it is set to True
    .short_caption = Check wrapping

  output_ccp4_map_mean = None
    .type = float
    .help = Choose mean and SD of output CCP4 map
    .short_caption = Mean of output CCP4 map

  output_ccp4_map_sd = None
    .type = float
    .help = Choose mean and SD of output CCP4 map
    .short_caption = SD of output CCP4 map

  output_map_label = None
    .type = str
    .multiple = True
    .help = Add this label to output map
    .short_caption = Add label

  remove_output_map_labels = None
    .type = bool
    .help = Remove all output map labels
    .short_caption = Remove labels

  invert_hand = False
    .type = bool
    .help = Just before writing out the map, swap the order of all sections \
             in Z.  This will change the hand of the map. Note that this\
             removes any correspondence to models (these are not inverted). \
             If you use this, be sure to apply it to all your starting maps.\
    .short_caption = Invert hand of map

  gui
    .help = "GUI-specific parameter required for output directory"
  {
    output_dir = None
    .type = path
    .style = output_dir
  }
""", process_includes = True)

master_params = master_phil

def remove_element(text_list, element = None):
    new_text_list = []
    for x in text_list:
      if x !=  element:
        new_text_list.append(x)
    return new_text_list

def get_model_from_inputs(
    model = None,
    pdb_hierarchy = None,
    file_names = None,
    crystal_symmetry = None,
    log = sys.stdout):
  print_statistics.make_sub_header("pdb model", out = log)

  if pdb_hierarchy:  # convert to model object . XXX should come in this way
    model =  pdb_hierarchy.as_model_manager(crystal_symmetry = crystal_symmetry)

  if len(file_names)>0:
    file_name = file_names[0]
    if not file_name or not os.path.isfile(file_name):
      raise Sorry("The file %s is missing" %(file_name))
    print("Reading model from %s" %(file_name), file = log)
    from iotbx.data_manager import DataManager
    dm = DataManager()
    dm.set_overwrite(True)
    dm.process_model_file(file_name)
    model = dm.get_model(file_name)
    if crystal_symmetry and not model.crystal_symmetry():
      model.set_crystal_symmetry(crystal_symmetry)

  return model

def get_map_manager_objects(
    params = None,
    inputs = None,
    crystal_symmetry = None,
    ccp4_map = None,
    mask_as_map_manager = None,
     map_data = None,  # XXX
     mask_data = None, # XXX
     log = sys.stdout):

  # Map or map coefficients
  map_coeff = None
  resolution_from_map_coeffs = None
  input_unit_cell_grid = None
  input_unit_cell = None
  input_map_labels = None
  map_or_map_coeffs_prefix = None

  if map_data and not ccp4_map:  # convert to map_manager
    # Called with map_data.  We do not know for sure if map_data is
    #  wrapped or not. Require wrapping to be set to define it.

    assert isinstance(params.wrapping, bool)
    ccp4_map = map_manager(map_data = map_data,
      unit_cell_grid = map_data.all(),
      unit_cell_crystal_symmetry = crystal_symmetry,
      wrapping = params.wrapping)
  elif (not ccp4_map):

    # read first mtz file
    if ( (len(inputs.reflection_file_names) > 0) or
         (params.map_coefficients_file is not None) ):
      # Here with MTZ input, wrapping default is True (crystallographic map)
      if not isinstance(params.wrapping, bool):
        params.wrapping = True
      # file in phil takes precedent
      if (params.map_coefficients_file is not None):
        if (len(inputs.reflection_file_names)  ==  0):
          inputs.reflection_file_names.append(params.map_coefficients_file)
        else:
          inputs.reflection_file_names[0] = params.map_coefficients_file
      map_coeff = reflection_file_utils.extract_miller_array_from_file(
        file_name = inputs.reflection_file_names[0],
        label     = params.label,
        type      = "complex",
        log       = log)
      resolution_from_map_coeffs = map_coeff.d_min()
      if not crystal_symmetry: crystal_symmetry = map_coeff.crystal_symmetry()
      fft_map = map_coeff.fft_map(resolution_factor = params.resolution_factor)
      fft_map.apply_sigma_scaling()
      map_data = fft_map.real_map_unpadded()
      map_or_map_coeffs_prefix = os.path.basename(
         inputs.reflection_file_names[0][:-4])
      # Convert map_data to map_manager object
      ccp4_map = map_manager(map_data = map_data,
        unit_cell_grid = map_data.all(),
        unit_cell_crystal_symmetry = crystal_symmetry,
        wrapping = params.wrapping)

    # or read CCP4 map
    elif ( (inputs.ccp4_map is not None) or
           (params.ccp4_map_file is not None) ):
      # Here wrapping comes from map file; no need to set default. If not
      #  specified in map labels, wrapping will be False for map file.

      if (params.ccp4_map_file is not None):
        inputs.ccp4_map = read_map_file_with_data_manager(params.ccp4_map_file)
        inputs.ccp4_map_file_name = params.ccp4_map_file
      print_statistics.make_sub_header("CCP4 map", out = log)
      ccp4_map = inputs.ccp4_map
      ccp4_map.show_summary(prefix = "  ", out = log)
      if not crystal_symmetry: crystal_symmetry = ccp4_map.crystal_symmetry()
      map_data = ccp4_map.map_data()
      input_unit_cell_grid = ccp4_map.unit_cell_grid
      input_unit_cell = ccp4_map.unit_cell().parameters()
      input_map_labels = ccp4_map.get_labels()

      if inputs.ccp4_map_file_name.endswith(".ccp4"):
        map_or_map_coeffs_prefix = os.path.basename(
          inputs.ccp4_map_file_name[:-5])
      else:
        map_or_map_coeffs_prefix = os.path.basename(
          inputs.ccp4_map_file_name[:-4])

  if mask_data and (not mask_as_map_manager):
    mask_as_map_manager = map_manager(map_data = mask_data.as_double(),
        unit_cell_grid = mask_data.all(),
        unit_cell_crystal_symmetry = crystal_symmetry,
        wrapping = params.wrapping)
  if (not mask_as_map_manager) and params.mask_file_name:
    mask_as_map_manager = read_map_file_with_data_manager(
        params.mask_file_name)

  if len(inputs.pdb_file_names)>0:
    output_prefix = os.path.basename(inputs.pdb_file_names[0])[:-4]
  else:
    output_prefix = map_or_map_coeffs_prefix

  return ccp4_map, mask_as_map_manager, \
    output_prefix, resolution_from_map_coeffs

def read_map_file_with_data_manager(file_name):
    from iotbx.data_manager import DataManager
    dm = DataManager()
    dm.set_overwrite(True)
    dm.process_real_map_file(file_name)
    return dm.get_real_map(file_name)

def check_parameters(inputs = None, params = None,
   model = None,
   ncs_object = None,
   pdb_hierarchy = None,
   log = sys.stdout):

  if(len(inputs.pdb_file_names)!= 1 and not params.density_select and not
    params.mask_select and not pdb_hierarchy and
     not model and not params.keep_map_size and not params.upper_bounds
     and not params.extract_unique and not params.bounds_match_this_file):
    raise Sorry("PDB file is needed unless extract_unique, "+
      "density_select, mask_select, keep_map_size \nor bounds are set .")
  if (len(inputs.pdb_file_names)!= 1 and not pdb_hierarchy and not model and\
       (params.mask_atoms )):
    raise Sorry("PDB file is needed for mask_atoms")
  if params.soft_mask and (not params.resolution) and \
        (len(inputs.pdb_file_names)!= 1 and not pdb_hierarchy and not model):
    raise Sorry("Need resolution for soft_mask without PDB file")
  if (params.density_select and params.extract_unique):
    raise Sorry("Cannot set both density_select and extract_unique")
  if ((params.density_select or params.mask_select) and params.keep_map_size):
    raise Sorry("Cannot set both density_select/mask_select and keep_map_size")
  if ((params.density_select or params.mask_select) and params.upper_bounds):
    raise Sorry("Cannot set both density_select/mask_select and bounds")
  if (params.keep_map_size and params.upper_bounds):
    raise Sorry("Cannot set both keep_map_size and bounds")
  if (params.upper_bounds and not params.lower_bounds):
    raise Sorry("Please set lower_bounds if you set upper_bounds")
  if (params.extract_unique):
    if (not params.resolution):
      raise Sorry("Please set resolution for extract_unique")
    if (not params.symmetry) and (not params.symmetry_file) and \
        (not ncs_object):
      params.symmetry="ALL"
      print("Setting symmetry=ALL as no symmetry information supplied",
        file = log)
    if params.mask_atoms:
      raise Sorry("You cannot set mask_atoms with extract_unique")

  if params.keep_input_unit_cell_and_grid and (
      (params.output_unit_cell_grid is not None ) or
      (params.output_unit_cell is not None ) ):
    raise Sorry("If you set keep_input_unit_cell_and_grid then you cannot "+\
       "set \noutput_unit_cell_grid or output_unit_cell")

def print_default_message(log = sys.stdout):
  h = "phenix.map_box: extract box with model and map around selected atoms"
  print_statistics.make_header(h, out = log)
  default_message = """\

%s.

Usage:
  phenix.map_box model.pdb map_coefficients.mtz selection = "chain A and resseq 1:10"

or

  phenix.map_box map.ccp4 density_select = True

Parameters:"""%h

def process_inputs(args = None,
  crystal_symmetry = None,
  log = sys.stdout):

  # Process inputs ignoring symmetry conflicts

  inputs = mmtbx.utils.process_command_line_args(args = args,
      cmd_cs = crystal_symmetry,
      master_params = master_phil,
      suppress_symmetry_related_errors = True)
  params = inputs.params.extract()

  master_phil.format(python_object = params).show(out = log)

  return inputs, params

def get_origin_or_bounds_from_ccp4_file(params = None, log = sys.stdout):
  if params.output_origin_match_this_file:
    fn = params.output_origin_match_this_file
    if params.bounds_match_this_file:
      raise Sorry("Cannot match origin and bounds at same time")
  else:
    fn = params.bounds_match_this_file
  if not params.ccp4_map_file:
    raise Sorry(
     "Need to specify your input file with ccp4_map_file = xxx if you use "+
      "output_origin_match_this_file = xxxx or bounds_match_this_file = xxxx")

  ccp4_map = read_map_file_with_data_manager(fn)

  if (ccp4_map):
    origin = ccp4_map.map_data().origin()
    if params.output_origin_match_this_file:
      params.output_origin_grid_units = origin
      print("Origin of (%s, %s, %s) taken from %s" %(
         origin[0], origin[1], origin[2], fn))
    else:
      all = ccp4_map.map_data().all()
      params.lower_bounds = origin
      print("Lower bounds of (%s, %s, %s) taken from %s" %(
         params.lower_bounds[0], params.lower_bounds[1],
           params.lower_bounds[2], fn))
      params.upper_bounds = list(col(origin)+col(all)-col((1, 1, 1)))
      print("upper bounds of (%s, %s, %s) taken from %s" %(
         params.upper_bounds[0], params.upper_bounds[1],
          params.upper_bounds[2], fn))
      params.bounds_are_absolute = True
  else:
    raise Sorry("Unable to interpret %s as map file" %(fn))

  return params

def modify_params(params = None,
    inputs = None,
    model = None,
    pdb_hierarchy = None,
    write_output_files = None,
    upper_bounds = None,
    lower_bounds = None,
    wrapping = None,
    log = sys.stdout):

  #  Update wrapping if specified
  if isinstance(wrapping, bool):
    params.wrapping = wrapping

  # PDB file
  if params.pdb_file and not inputs.pdb_file_names and not pdb_hierarchy \
      and not model:
    inputs.pdb_file_names = [params.pdb_file]

  # Overwrite params with parameters in call if available
  if lower_bounds:
     params.lower_bounds = lower_bounds
  if upper_bounds:
     params.upper_bounds = upper_bounds

  if (write_output_files) and ("mtz" in params.output_format) and (
       (params.keep_origin) and (not params.keep_map_size)):
    print("\nNOTE: Skipping write of mtz file as keep_origin = True and \n"+\
       "keep_map_size is False\n", file = log)
    params.output_format = remove_element(params.output_format, element = 'mtz')

  if params.output_external_origin and (not params.keep_origin):
    raise Sorry(
      "If you specify an external origin you must set keep_origin=True")

  if (write_output_files) and ("mtz" in params.output_format) and (
       (params.extract_unique)):
    print("\nNOTE: Skipping write of mtz file as extract_unique = True\n",
      file = log)
    params.output_format = remove_element(params.output_format, element = 'mtz')


  # XXX Get origin or bounds from a ccp4 file Instead use data_manager to read

  if params.output_origin_match_this_file or params.bounds_match_this_file:
    params = get_origin_or_bounds_from_ccp4_file(params = params, log = log)


  # Check that bounds are None or tuples of three

  if params.lower_bounds and len(params.lower_bounds) != 3:
    raise Sorry("Need 3 values for lower_bounds")
  if params.upper_bounds and len(params.upper_bounds) != 3:
    raise Sorry("Need 3 values for upper_bounds")

  if params.output_origin_grid_units is not None and params.keep_origin:
    params.keep_origin = False
    print("Setting keep_origin = False as output_origin_grid_units is set",
       file = log)

  if params.soft_mask_radius is None:
    params.soft_mask_radius = params.resolution

  if (params.soft_mask and params.mask_atoms and
      params.increase_box_cushion_and_atom_radius_for_soft_mask):
    params.box_cushion+= params.mask_atoms_atom_radius
    print ("Increasing box_cushion by mask_atoms_atom_radius for soft mask",
       file = log)

  return params

def get_origin_to_match(
   params = None,
   n_real = None,
   crystal_symmetry = None):

  if params.output_origin_grid_units is not None:
    origin_to_match = tuple(params.output_origin_grid_units)
  else:
    origin_to_match = None

  if origin_to_match:
    sc = []
    for x, o, a in zip(crystal_symmetry.unit_cell().parameters()[:3],
        origin_to_match, n_real):
      sc.append(-x*o/a)
    shift_cart_for_origin_to_match = tuple(sc)
  else:
    origin_to_match = None
    shift_cart_for_origin_to_match = None

  return origin_to_match, shift_cart_for_origin_to_match

def apply_selection_to_model(params = None, model = None, log = sys.stdout):
  if not model:
     return

  if not params.selection or params.selection == "all":
    return model

  selection = model.selection(params.selection)
  model = model.select(selection)
  return model

def get_ncs_object(params = None,
    ncs_object = None,
    log = sys.stdout):
  if not ncs_object:
    from mmtbx.ncs.ncs import ncs
    ncs_object = ncs()
    if params.symmetry_file:
      ncs_object.read_ncs(params.symmetry_file, log = log)
      print("Total of %s operators read" %(ncs_object.max_operators()), file = log)
  if ncs_object.max_operators()<1:
      print("No symmetry available", file = log)

  return ncs_object

def get_sequence_and_molecular_mass(params = None, ncs_object = None,
   log = sys.stdout):

  if (not params.extract_unique) and (not params.mask_select):
    return  params, None  # no sequence

  if params.sequence_file:
    if ncs_object.max_operators()> 1: # get unique part of sequence
      remove_duplicates = True
    else:
      remove_duplicates = False
    from iotbx.bioinformatics import get_sequences
    sequence = (" ".join(get_sequences(file_name = params.sequence_file,
      remove_duplicates = remove_duplicates)))
  else:
    sequence = None

  if params.chain_type in ['None', None]: params.chain_type = None
  if sequence and not params.molecular_mass:
    # get molecular mass from sequence
    from iotbx.bioinformatics import text_from_chains_matching_chain_type
    if params.chain_type in [None, 'PROTEIN']:
      n_protein = len(text_from_chains_matching_chain_type(
        text = sequence, chain_type = 'PROTEIN'))
    else:
      n_protein = 0
    if params.chain_type in [None, 'RNA']:
      n_rna = len(text_from_chains_matching_chain_type(
        text = sequence, chain_type = 'RNA'))
    else:
      n_rna = 0
    if params.chain_type in [None, 'DNA']:
      n_dna = len(text_from_chains_matching_chain_type(
       text = sequence, chain_type = 'DNA'))
    else:
      n_dna = 0
    params.molecular_mass = ncs_object.max_operators()*(
         n_protein*110+(n_rna+n_dna)*330)
    print("\nEstimate of molecular mass is %.0f " %(
        params.molecular_mass), file = log)
  return params, sequence

def print_what_will_happen(
   params = None,
   model = None,
   log = sys.stdout):


  if params.density_select or params.mask_select:
    print_statistics.make_sub_header(
    "Extracting box around selected density and writing output files", out = log)
  else:
   print_statistics.make_sub_header(
    "Extracting box around selected atoms and writing output files", out = log)
  #
  if params.set_outside_to_mean_inside:
    print("\nValue outside atoms mask will be set to mean inside mask", file = log)
  if params.get_half_height_width and params.density_select:
    print("\nHalf width at half height will be used to id boundaries", file = log)

  if params.soft_mask and model and \
      model.get_xray_structure().sites_cart().size()>0:
    print("\nSoft mask will be applied to model-based mask", file = log)
  elif params.soft_mask:
    print ("\nSoft mask will be applied to outside of map box", file = log)
  if params.keep_map_size:
    print("\nEntire map will be kept (not cutting out region)", file = log)
  if params.restrict_map_size:
    print("\nOutput map will be within input map", file = log)
  if params.lower_bounds and params.upper_bounds:
    print("Bounds for cut out map are (%s, %s, %s) to (%s, %s, %s)" %(
     tuple(list(params.lower_bounds)+list(params.upper_bounds))), file = log)

def print_notes(params = None,
    mam = None,
    crystal_symmetry = None,
    ccp4_map = None,
    log = sys.stdout):

  if params.mask_select and hasattr(mam, 'get_solvent_content') and \
        mam.get_solvent_content():
    print("\nSolvent content used in mask_select: %.3f " %(
      mam.get_solvent_content()), file = log)

  if (ccp4_map and
    crystal_symmetry and
    crystal_symmetry.unit_cell().parameters() and
     ccp4_map.unit_cell().parameters()  ) and (
       crystal_symmetry.unit_cell().parameters() !=
       ccp4_map.unit_cell().parameters()):
    print("\nNOTE: Input CCP4 map is only part of unit cell:", file = log)
    print("Full unit cell ('unit cell parameters'): "+\
      "(%.1f, %.1f, %.1f, %.1f, %.1f, %.1f) A" %tuple(
        ccp4_map.unit_cell().parameters()), file = log)
    print("Size of CCP4 map 'map unit cell':        "+\
      "(%.1f, %.1f, %.1f, %.1f, %.1f, %.1f) A" %tuple(
       crystal_symmetry.unit_cell().parameters()), file = log)
    print("Full unit cell as grid units: (%s, %s, %s)" %(
      tuple(ccp4_map.unit_cell_grid)), file = log)
    print("Map unit cell as grid units:  (%s, %s, %s)" %(
      tuple(ccp4_map.map_data().all())), file = log)

    if params.invert_hand:
      print("\nOutput map will be inverted hand "+
         "(swapping order of sections in Z)", file = log)

def run(args,
     ncs_object = None,  # ncs object
     model = None,  # model.manager object
     ccp4_map = None,  # map_manager object
     mask_as_map_manager = None, # map_manager object
     crystal_symmetry = None,  # XXX remove
     pdb_hierarchy = None, #XXX remove
     map_data = None,  # XXX remove
     mask_data = None, # XXX remove
     lower_bounds = None,
     upper_bounds = None,
     wrapping = None,  # Alternative way to specify wrapping
     write_output_files = True,
     log = None):

  if (log is None): log = sys.stdout


  if(len(args)  ==  0 and not pdb_hierarchy):
    print_default_message(log = log)
    master_phil.show(prefix = "  ")
    return

  # Read files with file reader and get parameters
  inputs, params = process_inputs(args = args,
    crystal_symmetry = crystal_symmetry,
    log = log)


  # Custom changes in parameters based on input files and supplied bounds
  params = modify_params(params = params,
    inputs = inputs,
    model = model,
    pdb_hierarchy = pdb_hierarchy, # XXX remove later
    write_output_files = write_output_files,
    upper_bounds = upper_bounds,
    lower_bounds = lower_bounds,
    wrapping = wrapping,
    log = log)

  # Check parameters and issue error messages if necessary
  check_parameters(inputs = inputs, params = params,
    model = model,
    ncs_object = ncs_object,
    pdb_hierarchy = pdb_hierarchy, # remove later XXX
    log = log)

  # Use inputs.crystal_symmetry (precedence there is for map)
  crystal_symmetry = inputs.crystal_symmetry

  # Get map_manager objects

  # XXX get rid of most of these as they are part of mm objects
  ccp4_map, mask_as_map_manager, \
    output_prefix, resolution_from_map_coeffs = get_map_manager_objects(
      params = params,
      inputs = inputs,
      ccp4_map = ccp4_map,
      mask_as_map_manager = mask_as_map_manager,
      crystal_symmetry = crystal_symmetry,
      map_data = map_data,  # XXX delete
      mask_data = mask_data, # XXX  delete
      log = log)

  if not ccp4_map:
    raise Sorry("Need a map for map_box")

  # Apply a scale factor to map data on read-in if requested
  if params.map_scale_factor:
    print("Applying scale factor of %s to map data on read-in" %(
       params.map_scale_factor))
    ccp4_map = ccp4_map.customized_copy(
      map_data = ccp4_map.map_data()*params.map_scale_factor)

  # Use ccp4_map crystal_symmetry if not set
  if ccp4_map and not crystal_symmetry:
    crystal_symmetry = ccp4_map.unit_cell_crystal_symmetry()


  # Get model object (replaces pdb_hierarchy)
  model = get_model_from_inputs(
    model = model,
    pdb_hierarchy = pdb_hierarchy,
    file_names = inputs.pdb_file_names,
    crystal_symmetry = crystal_symmetry,
    log = log)

  # Apply selection to model if desired
  if model:
    model = apply_selection_to_model(params = params, model = model, log = log)

  # Get target model object for extract_unique if present
  if params.target_ncs_au_file:
    target_ncs_au_model = get_model_from_inputs(
      file_names = [params.target_ncs_au_file],
      crystal_symmetry = crystal_symmetry,
      log = log)
  else:
    target_ncs_au_model = None

  # final check that map_data exists
  if(ccp4_map.map_data is None):
    raise Sorry("Map or map coefficients file is needed.")

  # Set wrapping if specified:
  if params.wrapping in [True, False]:
    ccp4_map.set_wrapping(params.wrapping)

  ncs_object = get_ncs_object(params = params,
      ncs_object = ncs_object, log = log)

  # Get sequence if extract_unique or mask_select is set
  params, sequence = get_sequence_and_molecular_mass(params = params,
    ncs_object = ncs_object,
    log = log)

  # Summarize what will happen
  print_what_will_happen(params = params,
    model = None,
    log = log)

  # Run now

  # Change map/model unit_cell_crystal_symmetry if requested
  if params.output_unit_cell and \
     tuple(params.output_unit_cell)!= tuple(ccp4_map.unit_cell().parameters()):
    ccp4_map, model = change_output_unit_cell(params = params,
       ccp4_map = ccp4_map,
       model = model)


  # Decide if we are going to box at the beginning:
  box = (model and (not params.keep_map_size))
  if (params.lower_bounds and params.upper_bounds):
    box = False
  if (params.extract_unique):
    box = False
  if (params.density_select):
    box = False
  if (params.mask_select):
    box = False

  from iotbx.map_model_manager import map_model_manager
  mam = map_model_manager(
    model = model,
    map_manager = ccp4_map,
    ncs_object = ncs_object,
    ignore_symmetry_conflicts = params.ignore_symmetry_conflicts)
  if box:
    mam.box_all_maps_around_model_and_shift_origin(
      box_cushion = params.box_cushion)
    if mam.warning_message():
      print (mam.warning_message(), file = log)

  # Map and model and ncs are boxed if requested and
  #   shifted to place origin at (0, 0, 0)
  # Now box the map if desired and shift origin if requested
  # Shift bounds if bounds_are_absolute and original origin is not zero:
  if params.bounds_are_absolute:
    params.lower_bounds = tuple([lb-o for lb, o in zip(params.lower_bounds,
      mam.map_manager().origin_shift_grid_units)])
    params.upper_bounds = tuple([lb-o for lb, o in zip(params.upper_bounds,
      mam.map_manager().origin_shift_grid_units)])
    params.bounds_are_absolute = False

  if params.lower_bounds and params.upper_bounds:  # Box it
    assert not box # should not have used boxing
    from cctbx.maptbx.box import with_bounds
    mam = with_bounds(mam.map_manager(), # actually a box
         params.lower_bounds,
         params.upper_bounds,
         model = mam.model(),
         log = log)
    if mam.warning_message():
      print (mam.warning_message(), file = log)

  elif params.density_select:  # Box it with density_select
    assert not box # should not have used boxing
    from cctbx.maptbx.box import around_density
    mam = around_density(mam.map_manager(), # actually a box
         box_cushion = params.box_cushion,
         threshold = params.density_select_threshold,
         get_half_height_width = params.get_half_height_width,
         model = mam.model(),
         log = log)
    if mam.warning_message():
      print (mam.warning_message(), file = log)

  elif params.mask_select:  # Box it with mask_select
    assert not box # should not have used boxing
    from cctbx.maptbx.box import around_mask
    if not mask_as_map_manager: # Generate it
      mm = mam.map_manager().deep_copy()
      mm.create_mask_around_density(
        resolution = params.resolution,
        molecular_mass = params.molecular_mass,
        sequence = sequence,
        solvent_content = params.solvent_content,
        )
      cm=mm._created_mask
      mask_as_map_manager = mm.get_mask_as_map_manager()
      if not mask_as_map_manager:
        raise Sorry("Unable to auto-generate mask")

    mam = around_mask(mam.map_manager(), # actually a box, shifted
         mask_as_map_manager = mask_as_map_manager,
         box_cushion = params.box_cushion,
         model = mam.model(),
         log = log)
    if mam.warning_message():
      print (mam.warning_message(), file = log)

  # Now mask map if requested

  if (params.extract_unique):  # mask around unique part of map and rebox
    # NOTE: actually returns box not mam XXX
    mam = apply_around_unique(mam, params = params,
       sequence = sequence,
       target_ncs_au_model = target_ncs_au_model,
       log = log)

  elif (params.mask_atoms):  # mask around atoms, optionally soft
    mam = apply_mask_around_atoms(mam, params = params, log = log)

  elif (params.soft_mask):  # apply soft mask to outside of box
    mam = apply_mask_around_edge_of_box(mam, params = params, log = log)

  if params.write_mask_file:
    if not hasattr(mam.map_manager(),'_created_mask') or not \
       mam.map_manager()._created_mask:
      raise Sorry("Cannot create mask file if no mask has been created")
    mask_map_manager = mam.map_manager()._created_mask.map_manager().deep_copy()
  else:
    mask_map_manager = None

  # Shift origin of output file if requested
  if params.output_origin_grid_units or params.output_unit_cell_grid or\
       (not params.keep_origin) or (not params.keep_input_unit_cell_and_grid):

    if params.output_origin_grid_units:
      print ("Setting origin of final map to be at %s" %(
       str(params.output_origin_grid_units)), file = log)
    elif not params.keep_origin:
      print ("Setting origin of final map to be at (0, 0, 0)", file = log)
      params.output_origin_grid_units = (0, 0, 0)

    if (not params.keep_input_unit_cell_and_grid) and (
         not params.output_unit_cell_grid):
      params.output_unit_cell_grid = mam.map_manager().map_data().all()
    if params.output_unit_cell_grid:
      print ("Setting gridding of unit cell of final map to be at %s" %(
       str(params.output_unit_cell_grid)), file = log)
    mam.map_manager().set_original_origin_and_gridding(
       original_origin = params.output_origin_grid_units,
       gridding = params.output_unit_cell_grid)
    if mam.map_manager().ncs_object():
      # mam.map_manager().ncs_object().display_all()

      mam.map_manager().ncs_object().set_shift_cart(
        mam.map_manager().shift_cart())

    if mam.model():
      mam.model().shift_model_and_set_crystal_symmetry(
       shift_cart = (0,0,0),
       crystal_symmetry = mam.map_manager().crystal_symmetry())
      mam.model().set_shift_cart((0,0,0)) # next line requires shift-cart=0,0,0
      mam.model().set_unit_cell_crystal_symmetry(
        mam.map_manager().crystal_symmetry())
      mam.model().set_shift_cart(mam.map_manager().shift_cart())

  if params.wrapping in [True, False] and mam.map_manager().is_full_size():
    mam.map_manager().set_wrapping(params.wrapping)
    if params.wrapping and params.check_wrapping and (
       not mam.map_manager().is_consistent_with_wrapping()):
      print("\nWARNING: This map is not consistent with wrapping but wrapping"+
        " is set to True",file = log)

  # Adjust labels
  if params.output_map_label:  # add it
    for label in params.output_map_label:
      mam.map_manager().add_label(label)

  if params.remove_output_map_labels:
    mam.map_manager().remove_labels()

  if params.invert_hand:
    mam.map_manager().invert_hand()

  # Print out any notes about the output files
  print_notes(params = params, mam = mam,
    crystal_symmetry = crystal_symmetry,
    ccp4_map = ccp4_map,
    log = log)

  # For output files ONLY:
  #  keep_origin == False leave origin at (0, 0, 0)
  #  keep_origin == True: we shift everything back to where it was,
  #  output_origin_grid_units = 10, 10, 10: output origin is at (10, 10, 10)
  #  output_external_origin = 10,10,10; set output_external_origin value

  print("\nBox cell dimensions: (%.2f, %.2f, %.2f) A" %(
      mam.map_manager().crystal_symmetry().unit_cell().parameters()[:3]),
       file = log)

  if mam.map_manager().origin_shift_grid_units:
     print("Working origin moved from grid position of"+\
        ": (%d, %d, %d) to (0, 0, 0) " %(
        tuple( mam.map_manager().origin_shift_grid_units)),
        file = log)
     print("Working origin moved from  coordinates of:"+\
        " (%.2f, %.2f, %.2f) A to (0, 0, 0)\n" %(
        tuple([-x for x in mam.map_manager().shift_cart()])),
           file = log)

  #  For now, need to return a box object
  if mam.model():
    xrs = mam.model().get_xray_structure()
    hierarchy = mam.model().get_hierarchy()
  else:
    xrs = None
    hierarchy = None
  output_box = box_object(
      shift_cart = mam.map_manager().shift_cart(),
      xray_structure_box = xrs,
      hierarchy = hierarchy,
      ncs_object = mam.map_manager().ncs_object(),
      map_box = mam.map_manager().map_data(),
      map_data = ccp4_map.map_data(),
      map_box_half_map_list = None,
      box_crystal_symmetry = mam.map_manager().crystal_symmetry(),
      pdb_outside_box_msg = "",
      gridding_first = getattr(mam, 'gridding_first', (0, 0, 0)),
      gridding_last = getattr(mam,
          'gridding_last', mam.map_manager().map_data().all()),
      solvent_content = params.solvent_content,
      origin_shift_grid_units = [
         -x for x in mam.map_manager().origin_shift_grid_units],
      )
  if write_output_files:
    model = mam.model()
    map_manager = mam.map_manager()
    ncs_object = mam.map_manager().ncs_object()
    from iotbx.data_manager import DataManager
    dm = DataManager(datatypes = [
       'model', 'ncs_spec', 'real_map', 'miller_array'])
    dm.set_overwrite(True)

    if params.output_external_origin:
      assert (isinstance(params.output_external_origin,tuple) or \
             isinstance(params.output_external_origin,list)) and \
             len(params.output_external_origin) == 3
      map_manager.set_output_external_origin(params.output_external_origin)
      print("Set output_external_origin to %s" %(
       str(params.output_external_origin)), file = log)

    # Write PDB file
    if model:
      if(params.output_file_name_prefix is None):
        filename = "%s_box"%output_prefix
      else: filename = "%s"%params.output_file_name_prefix
      full_filename = dm.write_model_file(
        model, filename = filename, format = "pdb")
      print("Writing boxed PDB with box unit cell to %s" %(
          "%s" %full_filename), file = log)

    # Write NCS file if NCS
    if ncs_object and ncs_object.max_operators()>0:
      if(params.output_file_name_prefix is None):
        filename =  "%s_box.ncs_spec"%output_prefix
      else:
        filename =  "%s.ncs_spec"%params.output_file_name_prefix
      dm.write_ncs_spec_file(ncs_object, filename = filename)
      print("\nWriting symmetry to %s" %( filename), file = log)
      # we are writing out new location

    # Write ccp4 map.
    if("ccp4" in params.output_format):
      if(params.output_file_name_prefix is None):
        filename = "%s_box.ccp4"%output_prefix
      else:
        filename = "%s.ccp4"%params.output_file_name_prefix
      dm.write_real_map_file(
         map_manager, filename = filename)
      print("\nWriting map to %s" %( filename), file = log)

    # Write ccp4 mask.
    if("ccp4" in params.output_format and mask_map_manager):
      if(params.output_file_name_prefix is None):
        filename = "%s_mask_box.ccp4"%output_prefix
      else:
        filename = "%s_mask.ccp4"%params.output_file_name_prefix
      dm.write_real_map_file(
         mask_map_manager, filename = filename)
      print("\nWriting mask to %s" %( filename), file = log)

    # Write xplor map.  Shift back if keep_origin = True
    if("xplor" in params.output_format):
     if(params.output_file_name_prefix is None):
       file_name = "%s_box.xplor"%output_prefix
     else: file_name = "%s.xplor"%params.output_file_name_prefix
     output_box.write_xplor_map(file_name = file_name,
         output_crystal_symmetry = mam.map_manager().crystal_symmetry(),
         output_unit_cell_grid = mam.map_manager().unit_cell_grid,
         shift_back = (output_box.shift_cart !=  (0, 0, 0)) )
     print("Writing boxed map "+\
         "to X-plor formatted file: %s"%file_name, file = log)

    # Write mtz map coeffs.  Shift back if keep_origin = True
    if("mtz" in params.output_format):
     if(params.output_file_name_prefix is None):
       file_name = "%s_box.mtz"%output_prefix
     else: file_name = "%s.mtz"%params.output_file_name_prefix

     print("Writing map coefficients "+\
         "to MTZ file: %s"%file_name, file = log)
     if(resolution_from_map_coeffs is not None):
       d_min = resolution_from_map_coeffs
     elif params.resolution is not None:
       d_min = params.resolution
     else:
       d_min = maptbx.d_min_from_map(map_data = mam.map_manager().map_data(),
         unit_cell = mam.map_manager().crystal_symmetry().unit_cell())
     map_coeffs = mam.map_manager().map_as_fourier_coefficients(
       d_min = d_min)
     mtz_dataset = map_coeffs.as_mtz_dataset(column_root_label = 'F')
     mtz_object = mtz_dataset.mtz_object()
     dm.write_miller_array_file(mtz_object, filename = file_name)

  print(file = log)
  return output_box

class box_object(object):
  '''
    Temporary holder that replaces box in map_box
  '''
  def __init__(self,
      shift_cart = None,
      origin_shift_grid_units = None,
      hierarchy = None,
      xray_structure_box = None,
      ncs_object = None,
      map_box = None,  # boxed map_data
      map_data = None,  # original map_data
      map_box_half_map_list = None,
      box_crystal_symmetry = None,
      pdb_outside_box_msg = "",
      solvent_content = None,
      gridding_first = None,
      gridding_last = None,
      ):
    adopt_init_args(self, locals())
    del self.origin_shift_grid_units
    self._origin_shift_grid_units = origin_shift_grid_units

  def show_summary(self, log = sys.stdout):
     print("Box object summary", file = log)
     print("Value of shift_cart: ", self.shift_cart, file = log)
     print("Value of origin_shift_grid_units: ", self.origin_shift_grid_units(),
       file = log)
     print("Value of map_box.origin(): ", self.map_box.origin(), file = log)
     print("Value of map_box.all(): ", self.map_box.all(), file = log)
     print("Value of map_data.origin(): ", self.map_data.origin(), file = log)
     print("Value of map_data.all(): ", self.map_data.all(), file = log)
     print("Value of solvent_content: ", self.solvent_content, file = log)
     print("Value of gridding_first: ", self.gridding_first, file = log)
     print("Value of gridding_last: ", self.gridding_last, file = log)

  def shift_sites_cart_back(self, sites_cart):
    from scitbx.matrix import col
    return sites_cart-col(self.shift_cart)

  def get_solvent_content(self): # XXX need to save it from
    return self.solvent_content

  def origin_shift_grid_units(self, reverse = True):
    if reverse:
      return tuple([-x for x in self._origin_shift_grid_units])
    else:
      return self._origin_shift_grid_units

  def shift_map_back(self, map_data):
    # Shift map from map_box cell to original coordinate system
    #  Note this map only applies in the region of the map_box cell (the
    #   map may be repeated in space but only one copy is valid).
    # The dimensions of this map are the same as the box map.
    from scitbx.matrix import col
    new_origin = self.origin_shift_grid_units(reverse = True)
    new_all = list(col(self.map_box.all())+col(new_origin))
    shifted_map_data = map_data.deep_copy()
    from scitbx.array_family import flex
    shifted_map_data.resize(flex.grid(new_origin, new_all))
    return shifted_map_data

  def write_xplor_map(self, file_name = "box.xplor", shift_back = None,
      output_unit_cell_grid = None,
      output_crystal_symmetry = None):

    # write out xplor map on same grid as ccp4 map (0 to focus-1)
    from scitbx.matrix import col
    if shift_back:
      map_data = self.shift_map_back(self.map_box)
    else:
      map_data = self.map_box

    if output_unit_cell_grid is None:
     output_unit_cell_grid = map_data.all()

    if output_crystal_symmetry is None:
      output_crystal_symmetry = self.xray_structure_box.crystal_symmetry()
    import iotbx.xplor
    gridding = iotbx.xplor.map.gridding(
        n     = output_unit_cell_grid,
        first = map_data.origin(),
        last  = tuple(col(map_data.focus())-col((1, 1, 1))))

    iotbx.xplor.map.writer(
      file_name          = file_name,
      is_p1_cell         = None, # XXX temporary flag allowing any cell
      title_lines        = ['Map in box', ],
      unit_cell          = output_crystal_symmetry.unit_cell(),
      gridding           = gridding,
      data               = map_data.as_double(),
      average            = -1,
      standard_deviation = -1)

def change_output_unit_cell(params = None,
   ccp4_map = None,
   model = None):

    '''
     Change the output unit cell as requested by user

     Check to see if user is also going to set the output_unit_cell_grid.
     If so, change that first.
    '''

    # Make sure there is no origin offset because that would change
    if ccp4_map.origin_shift_grid_units!= (0, 0, 0) or \
         ccp4_map.map_data().origin()!= (0, 0, 0):
       raise Sorry("Input map cannot have an origin "+
         "shift if output_unit_cell is to be changed")

    # Does user want to simultaneously change output_unit_cell_grid
    #  If so, then they want the output pixel size to be
    #      (output_unit_cell/output_unit_cell_grid)
    #    therefore change the unit_cell_grid first, then set crystal symmetry
    if params.output_unit_cell_grid and \
      tuple(params.output_unit_cell_grid)!= tuple(ccp4_map.unit_cell_grid):
      ccp4_map.set_original_origin_and_gridding(
        gridding = params.output_unit_cell_grid)

    from cctbx import crystal
    new_symmetry = crystal.symmetry(
      tuple(params.output_unit_cell),
      ccp4_map.crystal_symmetry().space_group_number())

    ccp4_map.set_unit_cell_crystal_symmetry(new_symmetry)

    # Now set model crystal_symmetry to match so we can combine them
    if model:
      model.set_unit_cell_crystal_symmetry(
        ccp4_map.unit_cell_crystal_symmetry())
      model.set_crystal_symmetry(ccp4_map.crystal_symmetry())
    return ccp4_map, model

def apply_around_unique(mam,
      params = None,
      sequence = None,
      target_ncs_au_model = None,
      log = None):

    from cctbx.maptbx.box import around_unique
    new_mam = around_unique(
      mam.map_manager(),
      model = mam.model(),
      target_ncs_au_model = target_ncs_au_model,
      sequence = sequence,
      regions_to_keep = params.regions_to_keep,
      solvent_content = params.solvent_content,
      resolution = params.resolution,
      molecular_mass = params.molecular_mass,
      symmetry = params.symmetry,
      chain_type = params.chain_type,
      keep_low_density = params.keep_low_density,
      box_cushion = params.box_cushion,
      soft_mask = params.soft_mask_extract_unique,
      mask_expand_ratio = params.mask_expand_ratio,
      )
    return new_mam  # XXX actually it is a box not an mam

def apply_mask_around_atoms(mam, params = None, log = None):
    assert mam.model() is not None
    if (params.soft_mask and
       params.increase_box_cushion_and_atom_radius_for_soft_mask):
      # add soft_mask_radius to atom radius
      print ("Mask radius around atoms increased by soft_mask_radius", file = log)
      mask_atoms_atom_radius = \
         params.mask_atoms_atom_radius+params.soft_mask_radius
    else: # use atom radius
      mask_atoms_atom_radius = params.mask_atoms_atom_radius
    print ("Applying mask around atoms with radius of %.1f A" %(
       mask_atoms_atom_radius), file = log)
    if params.set_outside_to_mean_inside:
      print("Value outside mask will be set to mean inside", file = log)
    if params.invert_mask:
      print("Mask will be inverted (zero inside region of atoms, one outside)",
        file=log)
    mam.map_manager().create_mask_around_atoms(model = mam.model(),
        mask_atoms_atom_radius = mask_atoms_atom_radius,
        invert_mask = params.invert_mask)
    if (params.soft_mask): # make it a soft mask
      mam.map_manager().soft_mask(soft_mask_radius = params.soft_mask_radius)
      print ("Mask will be soft with radius of %.1f A" %(
         params.soft_mask_radius), file = log)
    mam.map_manager().apply_mask(
      set_outside_to_mean_inside = params.set_outside_to_mean_inside)
    return mam


def apply_mask_around_edge_of_box(mam, params = None, log = None):
    print ("Applying soft mask around edge of box with radius of %.1f A" %(
       params.soft_mask_radius), file = log)
    if params.set_outside_to_mean_inside:
      print("Value outside mask will be set to mean inside", file = log)

    mam.map_manager().create_mask_around_edges(
          soft_mask_radius = params.soft_mask_radius)
    mam.map_manager().soft_mask(soft_mask_radius = params.soft_mask_radius)
    mam.map_manager().apply_mask(
      set_outside_to_mean_inside = params.set_outside_to_mean_inside)
    return mam

#  =============================================================================
# GUI-specific class for running command
from libtbx import runtime_utils
from wxGUI2 import utils

def validate_params(params):
  if params.write_mask_file and not params.mask_atoms:
    raise Sorry("You need to set mask_atoms for write_mask_file")
  return True

class launcher(runtime_utils.target_with_save_result):
  def run(self):
    utils.safe_makedirs(self.output_dir)
    os.chdir(self.output_dir)
    result = run(args = self.args, log = sys.stdout)
    return 0

#  =============================================================================

if (__name__  ==  "__main__"):
  run(args = sys.argv[1:])


 *******************************************************************************
