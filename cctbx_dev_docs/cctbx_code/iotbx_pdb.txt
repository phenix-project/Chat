

 *******************************************************************************
iotbx/pdb/__init__.py
"""
Tools for reading, writing, and manipulating PDB-formatted files and
for managing their data as a PDB hierarchy.
"""
from __future__ import absolute_import, division, print_function
from cctbx.array_family import flex

import boost_adaptbx.boost.python as bp
from six.moves import zip
ext = bp.import_ext("iotbx_pdb_ext")
from iotbx_pdb_ext import *

import iotbx.pdb.records
import iotbx.pdb.hierarchy
from iotbx.pdb.experiment_type import experiment_type
from scitbx import matrix

from iotbx.pdb.atom_name_interpretation import \
  interpreters as protein_atom_name_interpreters
import scitbx.array_family.shared # import dependency
import scitbx.stl.set
from libtbx import smart_open
from libtbx.str_utils import show_string
from libtbx.utils import plural_s, hashlib_md5, date_and_time, to_bytes, Sorry
from libtbx import Auto
from six.moves import cStringIO as StringIO
import sys
import calendar
import six
import os
op = os.path

def construct_special_position_settings(
      crystal_symmetry,
      special_position_settings=None,
      weak_symmetry=False,
      min_distance_sym_equiv=0.5,
      u_star_tolerance=0):
  """Construct the special-position settings for a crystal symmetry"""
  #crystal_symmetry = crystal_symmetry(
  #  crystal_symmetry=special_position_settings,
  #  weak_symmetry=weak_symmetry)
  if (crystal_symmetry is None): return None
  if (special_position_settings is not None):
    min_distance_sym_equiv=special_position_settings.min_distance_sym_equiv()
    u_star_tolerance = special_position_settings.u_star_tolerance()
  return crystal_symmetry.special_position_settings(
    min_distance_sym_equiv=min_distance_sym_equiv,
    u_star_tolerance=u_star_tolerance)

def is_pdb_file(file_name):
  """Return True if this is a PDB file"""
  for known_binary_extension in ['mtz', 'ccp4', 'mrc', 'pickle', 'pkl']:
    if file_name.endswith(known_binary_extension):
      return False
  with smart_open.for_reading(file_name=file_name) as f:
    pdb_raw_records = f.read().splitlines()
  for pdb_str in pdb_raw_records:
    if (pdb_str.startswith("CRYST1")):
      try: cryst1 = iotbx.pdb.records.cryst1(pdb_str=pdb_str)
      except iotbx.pdb.records.FormatError: continue
      if (cryst1.ucparams is not None and cryst1.sgroup is not None):
        return True
    elif (   pdb_str.startswith("ATOM  ")
          or pdb_str.startswith("HETATM")): # PDB OK
      try: pdb_inp = ext.input(
        source_info=None, lines=flex.std_string([pdb_str]))
      except KeyboardInterrupt: raise
      except Exception: continue
      if (pdb_inp.atoms().size() == 1):
        atom = pdb_inp.atoms()[0]
        if (atom.name != "    "):
          return True
  return False

def is_pdb_mmcif_file(file_name):
  """Return True if this is an mmCIF file"""
  try:
    cif_model = iotbx.cif.reader(file_path=file_name).model()
    cif_block = cif_model.values()[0]
    if "_atom_site" in cif_block:
      return True
  except Exception as e:
    return False

def systematic_chain_ids():
  """Return a list of possible 2-character chain IDS"""
  import string
  u, l, d = string.ascii_uppercase, string.ascii_lowercase, string.digits
  _ = result = list(u)
  _.extend(l)
  _.extend(d)
  def xy(first, second):
    for f in first:
      for s in second:
        _.append(f+s)
  a = u+l+d
  xy(u, a)
  xy(l, a)
  xy(d, a)
  return result

cns_dna_rna_residue_names = {
  "ADE": "A",
  "CYT": "C",
  "GUA": "G",
  "THY": "T",
  "URI": "U"
}

mon_lib_dna_rna_cif = set(["AD", "A", "CD", "C", "GD", "G", "TD", "U"])

rna_dna_reference_residue_names = {
  "A": "?A",
  "C": "?C",
  "G": "?G",
  "U": "U",
  "T": "DT",
  "+A": "?A",
  "+C": "?C",
  "+G": "?G",
  "+U": "U",
  "+T": "DT",
  "DA": "DA",
  "DC": "DC",
  "DG": "DG",
  "DT": "DT",
  "ADE": "?A",
  "CYT": "?C",
  "GUA": "?G",
  "URI": "U",
  "THY": "DT",
  # "AR": "A",
  # "CR": "C",
  # "GR": "G",
  # "UR": "U",
  "AD": "DA",
  "CD": "DC",
  "GD": "DG",
  "TD": "DT"
}

def get_one_letter_rna_dna_name(resname):
  """ Truncate the residue name to one letter. Return the letter or None."""
  if resname is None:
    return None
  assert isinstance(resname, str)
  result = resname.strip()
  result = result.strip("r").strip("R")
  result = result.strip("d").strip("D")
  result = result.strip("+")
  if len(result) == 1:
    return result.upper()
  else:
    result = cns_dna_rna_residue_names.get(result, None)
    return result

def rna_dna_reference_residue_name(common_name):
  """Return the standard RNA or DNA reference name for this common name"""
  return rna_dna_reference_residue_names.get(common_name.strip().upper())

rna_dna_atom_names_reference_to_mon_lib_translation_dict = {
  " C1'": "C1*",
  " C2 ": "C2",
  " C2'": "C2*",
  " C3'": "C3*",
  " C4 ": "C4",
  " C4'": "C4*",
  " C5 ": "C5",
  " C5'": "C5*",
  " C6 ": "C6",
  " C7 ": "C5M",
  " C8 ": "C8",
  " H1 ": "H1",
  " H1'": "H1*",
  " H2 ": "H2",
# " H2'": special case: rna: "H2*", dna: "H2*1"
  " H21": "H21",
  " H22": "H22",
  " H3 ": "H3",
  " H3'": "H3*",
  " H4'": "H4*",
  " H41": "H41",
  " H42": "H42",
  " H5 ": "H5",
  " H5'": "H5*1",
  " H6 ": "H6",
  " H61": "H61",
  " H62": "H62",
  " H71": "H5M1",
  " H72": "H5M2",
  " H73": "H5M3",
  " H8 ": "H8",
  " N1 ": "N1",
  " N2 ": "N2",
  " N3 ": "N3",
  " N4 ": "N4",
  " N6 ": "N6",
  " N7 ": "N7",
  " N9 ": "N9",
  " O2 ": "O2",
  " O2'": "O2*",
  " O3'": "O3*",
  " O4 ": "O4",
  " O4'": "O4*",
  " O5'": "O5*",
  " O6 ": "O6",
  " OP1": "O1P",
  " OP2": "O2P",
  " OP3": "O3T",
  " P  ": "P",
  "H2''": "H2*2",
  "H5''": "H5*2",
  "HO2'": "HO2*",
  "HO3'": "HO3*",
  "HO5'": "HO5*",
  "HOP3": "HOP3" # added to monomer library
}

protein_atom_names_backbone = [
  " N  ",
  " CA ",
  " C  ",
  " O  ",
  " OXT",
  " H  ",
  " D  ",
  " HXT",
  " DXT",
  " HA ",
  " HA2",
  " HA3",
  " DA ",
  " DA2",
  " DA3",
  " H1 ",
  " H2 ",
  " H3 ",
  " D1 ",
  " D2 ",
  " D3 ",
]

rna_dna_atom_names_backbone_reference_set = set([
  " C1'",
  " C2'",
  " C3'",
  " C4'",
  " C5'",
  " H1'",
  " H2'",
  " H3'",
  " H4'",
  " H5'",
  " O2'",
  " O3'",
  " O4'",
  " O5'",
  " OP1",
  " OP2",
  " OP3",
  " P  ",
  "H2''",
  "H5''",
  "HO2'",
  "HO3'",
  "HO5'",
  "HOP3"
])

rna_dna_atom_name_aliases = [
  ("1D2", " H21", "G DG"),
  ("1D2'", " H2'", "ANY"),
  ("1D2*", " H2'", "ANY"),
  ("1D4", " H41", "C DC"),
  ("1D5'", " H5'", "ANY"),
  ("1D5*", " H5'", "ANY"),
  ("1D5M", " H71", "DT"),
  ("1D6", " H61", "A DA"),
  ("1H2", " H21", "G DG"),
  ("1H2'", " H2'", "ANY"),
  ("1H2*", " H2'", "ANY"),
  ("1H4", " H41", "C DC"),
  ("1H5'", " H5'", "ANY"),
  ("1H5*", " H5'", "ANY"),
  ("1H5M", " H71", "DT"),
  ("1H6", " H61", "A DA"),
  ("2D2", " H22", "G DG"),
  ("2D2'", "H2''", "DA DC DG DT"),
  ("2D2*", "H2''", "DA DC DG DT"),
  ("2D4", " H42", "C DC"),
  ("2D5'", "H5''", "ANY"),
  ("2D5*", "H5''", "ANY"),
  ("2D5M", " H72", "DT"),
  ("2D6", " H62", "A DA"),
  ("2DO'", "HO2'", "A C G U"),
  ("2DO*", "HO2'", "A C G U"),
  ("2DOP", "HOP2", "ANY"),
  ("2H2", " H22", "G DG"),
  ("2H2'", "H2''", "DA DC DG DT"),
  ("2H2*", "H2''", "DA DC DG DT"),
  ("2H4", " H42", "C DC"),
  ("2H5'", "H5''", "ANY"),
  ("2H5*", "H5''", "ANY"),
  ("2H5M", " H72", "DT"),
  ("2H6", " H62", "A DA"),
  ("2HO'", "HO2'", "A C G U"),
  ("2HO*", "HO2'", "A C G U"),
  ("2HOP", "HOP2", "ANY"),
  ("3D5M", " H73", "DT"),
  ("3DOP", "HOP3", "ANY"),
  ("3H5M", " H73", "DT"),
  ("3HOP", "HOP3", "ANY"),
  ("C1'", " C1'", "ANY"),
  ("C1*", " C1'", "ANY"),
  ("C2", " C2 ", "ANY"),
  ("C2'", " C2'", "ANY"),
  ("C2*", " C2'", "ANY"),
  ("C3'", " C3'", "ANY"),
  ("C3*", " C3'", "ANY"),
  ("C4", " C4 ", "ANY"),
  ("C4'", " C4'", "ANY"),
  ("C4*", " C4'", "ANY"),
  ("C5", " C5 ", "ANY"),
  ("C5'", " C5'", "ANY"),
  ("C5*", " C5'", "ANY"),
  ("C5M", " C7 ", "DT"),
  ("C6", " C6 ", "ANY"),
  ("C7", " C7 ", "DT"),
  ("C8", " C8 ", "A G DA DG"),
  ("D1", " H1 ", "G DG"),
  ("D1'", " H1'", "ANY"),
  ("D1*", " H1'", "ANY"),
  ("D2", " H2 ", "A DA"),
  ("D2'", " H2'", "ANY"),
  ("D2*", " H2'", "ANY"),
  ("D2''", "H2''", "DA DC DG DT"),
  ("D2'1", " H2'", "ANY"),
  ("D2*1", " H2'", "ANY"),
  ("D2'2", "H2''", "DA DC DG DT"),
  ("D2*2", "H2''", "DA DC DG DT"),
  ("D21", " H21", "G DG"),
  ("D22", " H22", "G DG"),
  ("D3", " H3 ", "U DT"),
  ("D3'", " H3'", "ANY"),
  ("D3*", " H3'", "ANY"),
  ("D3T", "HO3'", "ANY"),
  ("D4'", " H4'", "ANY"),
  ("D4*", " H4'", "ANY"),
  ("D41", " H41", "C DC"),
  ("D42", " H42", "C DC"),
  ("D5", " H5 ", "C U DC"),
  ("D5'", " H5'", "ANY"),
  ("D5*", "HO5'", "ANY"),
  ("D5''", "H5''", "ANY"),
  ("D5'1", " H5'", "ANY"),
  ("D5*1", " H5'", "ANY"),
  ("D5'2", "H5''", "ANY"),
  ("D5*2", "H5''", "ANY"),
  ("D5M1", " H71", "DT"),
  ("D5M2", " H72", "DT"),
  ("D5M3", " H73", "DT"),
  ("D5T", "HO5'", "ANY"),
  ("D6", " H6 ", "C U DC DT"),
  ("D61", " H61", "A DA"),
  ("D62", " H62", "A DA"),
  ("D71", " H71", "DT"),
  ("D72", " H72", "DT"),
  ("D73", " H73", "DT"),
  ("D8", " H8 ", "A G DA DG"),
  ("DO2'", "HO2'", "A C G U"),
  ("DO2*", "HO2'", "A C G U"),
  ("H1", " H1 ", "G DG"),
  ("H1'", " H1'", "ANY"),
  ("H1*", " H1'", "ANY"),
  ("H2", " H2 ", "A DA"),
  ("H2'", " H2'", "ANY"),
  ("H2*", " H2'", "ANY"),
  ("H2''", "H2''", "DA DC DG DT"),
  ("H2'1", " H2'", "ANY"),
  ("H2*1", " H2'", "ANY"),
  ("H2'2", "H2''", "DA DC DG DT"),
  ("H2*2", "H2''", "DA DC DG DT"),
  ("H21", " H21", "G DG"),
  ("H22", " H22", "G DG"),
  ("H3", " H3 ", "U DT"),
  ("H3'", " H3'", "ANY"),
  ("H3*", " H3'", "ANY"),
  ("H3T", "HO3'", "ANY"),
  ("H4'", " H4'", "ANY"),
  ("H4*", " H4'", "ANY"),
  ("H41", " H41", "C DC"),
  ("H42", " H42", "C DC"),
  ("H5", " H5 ", "C U DC"),
  ("H5'", " H5'", "ANY"),
  ("H5*", "HO5'", "ANY"),
  ("H5''", "H5''", "ANY"),
  ("H5'1", " H5'", "ANY"),
  ("H5*1", " H5'", "ANY"),
  ("H5'2", "H5''", "ANY"),
  ("H5*2", "H5''", "ANY"),
  ("H5M1", " H71", "DT"),
  ("H5M2", " H72", "DT"),
  ("H5M3", " H73", "DT"),
  ("H5T", "HO5'", "ANY"),
  ("H6", " H6 ", "C U DC DT"),
  ("H61", " H61", "A DA"),
  ("H62", " H62", "A DA"),
  ("H71", " H71", "DT"),
  ("H72", " H72", "DT"),
  ("H73", " H73", "DT"),
  ("H8", " H8 ", "A G DA DG"),
  ("HO2'", "HO2'", "A C G U"),
  ("HO2*", "HO2'", "A C G U"),
  ("HO3'", "HO3'", "ANY"),
  ("HO3*", "HO3'", "ANY"),
  ("HO5'", "HO5'", "ANY"),
  ("HO5*", "HO5'", "ANY"),
  ("HOP2", "HOP2", "ANY"),
  ("HOP3", "HOP3", "ANY"),
  ("N1", " N1 ", "ANY"),
  ("N2", " N2 ", "G DG"),
  ("N3", " N3 ", "ANY"),
  ("N4", " N4 ", "C DC"),
  ("N6", " N6 ", "A DA"),
  ("N7", " N7 ", "A G DA DG"),
  ("N9", " N9 ", "A G DA DG"),
  ("O1P", " OP1", "ANY"),
  ("O2", " O2 ", "C U DC DT"),
  ("O2'", " O2'", "A C G U"),
  ("O2*", " O2'", "A C G U"),
  ("O2P", " OP2", "ANY"),
  ("O3'", " O3'", "ANY"),
  ("O3*", " O3'", "ANY"),
  ("O3P", " OP3", "ANY"),
  ("O3T", " OP3", "ANY"),
  ("O4", " O4 ", "U DT"),
  ("O4'", " O4'", "ANY"),
  ("O4*", " O4'", "ANY"),
  ("O5'", " O5'", "ANY"),
  ("O5*", " O5'", "ANY"),
  ("O5T", " OP3", "ANY"),
  ("O6", " O6 ", "G DG"),
  ("OP1", " OP1", "ANY"),
  ("OP2", " OP2", "ANY"),
  ("OP3", " OP3", "ANY"),
  ("P", " P  ", "ANY")]

def __rna_dna_atom_names_backbone_aliases():
  result = {}
  for a,r,f in rna_dna_atom_name_aliases:
    if (r in rna_dna_atom_names_backbone_reference_set):
      result[a] = r
  return result
rna_dna_atom_names_backbone_aliases = __rna_dna_atom_names_backbone_aliases()

class rna_dna_atom_names_interpretation(object):

  def __init__(self, residue_name, atom_names):
    if (residue_name == "T"):
      residue_name = "DT"
    else:
      assert residue_name in ["?A", "?C", "?G",
                              "A", "C", "G", "U",
                              "DA", "DC", "DG", "DT", "T"]
    self.residue_name = residue_name
    self.atom_names = atom_names
    rna_dna_atom_names_interpretation_core(self)

  def unexpected_atom_names(self):
    result = []
    for atom_name,info in zip(self.atom_names, self.infos):
      if (info.reference_name is None):
        result.append(atom_name)
    return result

  def mon_lib_names(self):
    result = []
    for info in self.infos:
      rn = info.reference_name
      if (rn is None):
        result.append(None)
      else:
        mn = rna_dna_atom_names_reference_to_mon_lib_translation_dict.get(rn)
        if (mn is not None):
          result.append(mn)
        elif (rn == " H2'"):
          if (self.residue_name.startswith("D")):
            result.append("H2*1")
          else:
            result.append("H2*")
        else:
          assert rn == "HOP3", '%s!="HOP3"' % rn # only atom not covered by monomer library
          result.append(None)
    return result

class residue_name_plus_atom_names_interpreter(object):
  """Create an object that has standard values of work_residue_name and
     atom_name_interpretation"""
  def __init__(self,
        residue_name,
        atom_names,
        translate_cns_dna_rna_residue_names=None,
        return_mon_lib_dna_name=False):
    work_residue_name = residue_name.strip().upper()
    if (len(work_residue_name) == 0):
      self.work_residue_name = None
      self.atom_name_interpretation = None
      return
    from iotbx.pdb.amino_acid_codes import three_letter_l_given_three_letter_d
    l_aa_rn = three_letter_l_given_three_letter_d.get(work_residue_name)
    if (l_aa_rn is None):
      d_aa_rn = None
    else:
      d_aa_rn = work_residue_name
      work_residue_name = l_aa_rn
    protein_interpreter = protein_atom_name_interpreters.get(
      work_residue_name)
    atom_name_interpretation = None
    if (protein_interpreter is not None):
      atom_name_interpretation = protein_interpreter.match_atom_names(
        atom_names=atom_names)
      if (atom_name_interpretation is not None):
        atom_name_interpretation.d_aa_residue_name = d_aa_rn
    else:
      assert d_aa_rn is None
      if (    translate_cns_dna_rna_residue_names is not None
          and not translate_cns_dna_rna_residue_names
          and work_residue_name in cns_dna_rna_residue_names):
        rna_dna_ref_residue_name = None
      else:
        rna_dna_ref_residue_name = rna_dna_reference_residue_name(
          common_name=work_residue_name)
      if (rna_dna_ref_residue_name is not None):
        atom_name_interpretation = rna_dna_atom_names_interpretation(
          residue_name=rna_dna_ref_residue_name,
          atom_names=atom_names)
        if (atom_name_interpretation.n_unexpected != 0):
          if (    len(atom_names) == 1
              and work_residue_name in mon_lib_dna_rna_cif):
            self.work_residue_name = None
            self.atom_name_interpretation = None
            return
          if (    translate_cns_dna_rna_residue_names is None
              and work_residue_name in cns_dna_rna_residue_names):
            atom_name_interpretation = None
        if (atom_name_interpretation is not None):
          work_residue_name = atom_name_interpretation.residue_name
          if (return_mon_lib_dna_name):
            work_residue_name = {
              "A": "A",
              "C": "C",
              "G": "G",
              "U": "U",
              "DA": "AD",
              "DC": "CD",
              "DG": "GD",
              "DT": "TD"}[work_residue_name]
    self.work_residue_name = work_residue_name
    self.atom_name_interpretation = atom_name_interpretation

#
# check out merge_files_and_check_for_overlap
class combine_unique_pdb_files(object):

  def __init__(self, file_names):
    self.file_name_registry = {}
    self.md5_registry = {}
    self.unique_file_names = []
    self.raw_records = []
    self.raw_text_block_list = []
    for file_name in file_names:
      if (file_name in self.file_name_registry):
        self.file_name_registry[file_name] += 1
      else:
        self.file_name_registry[file_name] = 1
        with smart_open.for_reading(file_name=file_name) as f:
          text = f.read()
          r = [s.expandtabs().rstrip() for s in text.splitlines()]
        m = hashlib_md5()
        m.update(to_bytes("\n".join(r), codec='utf8'))
        m = m.hexdigest()
        l = self.md5_registry.get(m)
        if (l is not None):
          l.append(file_name)
        else:
          self.md5_registry[m] = [file_name]
          self.unique_file_names.append(file_name)
          self.raw_records.extend(r)
          self.raw_text_block_list.append(text)

  def report_non_unique(self, out=None, prefix=""):
    if (out is None): out = sys.stdout
    n_ignored = 0
    for file_name in sorted(self.file_name_registry.keys()):
      n = self.file_name_registry[file_name]
      if (n != 1):
        print(prefix+"INFO: PDB file name appears %d times: %s" % (
          n, show_string(file_name)), file=out)
        n_ignored += (n-1)
    if (n_ignored != 0):
      print(prefix+"  %d repeated file name%s ignored." % \
        plural_s(n=n_ignored), file=out)
    n_identical = 0
    for file_names in sorted(self.md5_registry.values()):
      if (len(file_names) != 1):
        print(prefix+"INFO: PDB files with identical content:", file=out)
        for file_name in file_names:
          print(prefix+"  %s" % show_string(file_name), file=out)
        n_identical += len(file_names)-1
    if (n_identical != 0):
      print(prefix+"%d file%s with repeated content ignored." % \
        plural_s(n=n_identical), file=out)
    if (n_ignored != 0 or n_identical != 0):
      print(prefix.rstrip(), file=out)

class header_date(object):

  def __init__(self, field):
    "Expected format: DD-MMM-YY"
    self.dd = None
    self.mmm = None
    self.yy = None
    self.yyyy = None
    if (len(field) != 9): return
    if (field.count("-") != 2): return
    if (field[2] != "-" or field[6] != "-"): return
    dd, mmm, yy = field.split("-")
    try: self.dd = int(dd)
    except ValueError: pass
    else:
      if (self.dd < 1 or self.dd > 31): self.dd = None
    if (mmm.upper() in [
          "JAN", "FEB", "MAR", "APR", "MAY", "JUN",
          "JUL", "AUG", "SEP", "OCT", "NOV", "DEC"]):
      self.mmm = mmm.upper()
    try: self.yy = int(yy)
    except ValueError: pass
    else:
      if (self.yy < 0 or self.yy > 99): self.yy = None
    if self.yy is not None:
      if self.yy < 60: # I hope by 2060 no one uses the PDB format seriously!
        self.yyyy = 2000 + self.yy
      else:
        self.yyyy = 1900 + self.yy

  def is_fully_defined(self):
    return self.dd is not None \
       and self.mmm is not None \
       and self.yy is not None \
       and self.yyyy is not None

def header_year(record):
  """Return year from header record"""
  if (record.startswith("HEADER")):
    date = header_date(field=record[50:59])
    if (date.is_fully_defined()): return date.yyyy
    fields = record.split()
    fields.reverse()
    for field in fields:
      date = header_date(field=field)
      if (date.is_fully_defined()): return date.yyyy
  return None

class Please_pass_string_or_None(object): pass

class pdb_input_from_any(object):

  def __init__(self,
               file_name=None,
               source_info=Please_pass_string_or_None,
               lines=None,
               raise_sorry_if_format_error=False):
    self.file_format = None
    content = None
    from iotbx.pdb.mmcif import cif_input
    mmcif_exts = ('.cif', '.mmcif')
    if file_name is not None and file_name.strip(".gz").endswith(mmcif_exts):
      file_inputs = (cif_input, pdb_input)
    else:
      file_inputs = (pdb_input, cif_input)
    exc_info = None
    for file_input in file_inputs:
      try:
        content = file_input(
          file_name=file_name,
          source_info=source_info,
          lines=lines,
          raise_sorry_if_format_error=raise_sorry_if_format_error)
      except Exception as e:
        # store the first error encountered and re-raise later if can't
        # interpret as any file type
        if exc_info is None: exc_info = sys.exc_info()
        continue
      else: exc_info = None
      if file_input is pdb_input:
        # XXX nasty hack:
        #   pdb_input only raises an error if there are lines starting with
        #   "ATOM  " or "HETATM" and it subsequently fails to interpret these
        #   lines as ATOM/HETATM records
        #
        # XXX This hack fails to recognize /net/cci/pdb_mirror/mmcif/of/2of6.cif.gz
        # Reason: atom coordinates luckily can be parsed (no letters there)
        #
        n_unknown_records = content.unknown_section().size()
        n_records = sum(content.record_type_counts().values())
        n_blank_records = content.record_type_counts().get('      ', 0)
        # n_records > 0 for empty input, to get empty pdb_input object instead
        # of Sorry from cif_input
        if (((n_unknown_records == n_records) or
              (n_unknown_records == (n_records - n_blank_records)
                  and n_unknown_records > 0))
            and n_records>0):
          continue
        # Additional check that solves 2of6:
        # if the first non-comment non-empty line contains data_ this is mmCIF
        if lines is not None and len(lines)>0:
          len_lines = len(lines)
          i = 0
          while i < len_lines and (
            lines[i].strip().startswith('#') or len(lines[i].strip()) == 0):
            i += 1
          if i < len_lines and lines[i][:5].strip() == 'data_':
            continue
        self.file_format = "pdb"
      else :
        self.file_format = "cif"
      break
    if exc_info is not None:
      six.reraise(exc_info[0], exc_info[1], exc_info[2])
    if content is None:
      raise Sorry("Could not interpret input as any file type.")
    self._file_content = content

  def file_content(self):
    return self._file_content

def pdb_input(
    file_name=None,
    source_info=Please_pass_string_or_None,
    lines=None,
    raise_sorry_if_format_error=False):
  """Read in a model file and return a pdb_input object. Normally use input() instead"""
  if (file_name is not None):
    try :
      with smart_open.for_reading(file_name, gzip_mode='rt') as f:
        lines = f.read()
      return ext.input(
        source_info="file " + str(file_name), # XXX unicode hack - dangerous
        lines=flex.split_lines(lines))
    except ValueError as e :
      if (raise_sorry_if_format_error):
        raise Sorry("Format error in %s:\n%s" % (str(file_name), str(e)))
      else :
        raise
  assert source_info is not Please_pass_string_or_None
  if (isinstance(lines, str)):
    lines = flex.split_lines(lines)
  elif (isinstance(lines, (list, tuple))):
    lines = flex.std_string(lines)
  try :
    return ext.input(source_info=source_info, lines=lines)
  except ValueError as e :
    if (raise_sorry_if_format_error):
      raise Sorry("Format error:\n%s" % str(e))
    else :
      raise

def input(
    file_name=None,
    source_info=Please_pass_string_or_None,
    lines=None,
    raise_sorry_if_format_error=False):
  """
  Main input method for both PDB and mmCIF files; will automatically determine
  the actual format and return the appropriate data type.

  Parameters
  ----------
  file_name: path to PDB or mmCIF file
  source_info: string describing source of input (e.g. file name)
  lines: flex.std_string array of input lines
  raise_sorry_if_format_error: re-raise any low-level parser errors as a
    libtbx.utils.Sorry exception instance for clean user feedback

  Returns
  -------
  An object representing the result of parsing, including an array of atom
  objects; the actual class will differ depending on the input format.  Much of
  the API will be the same in either case.
  """
  return pdb_input_from_any(
    file_name=file_name,
    source_info=source_info,
    lines=lines,
    raise_sorry_if_format_error=raise_sorry_if_format_error).file_content()

default_atom_names_scattering_type_const = ["PEAK", "SITE"]

input_sections = (
  "unknown_section",
  "title_section",
  "remark_section",
  "primary_structure_section",
  "heterogen_section",
  "secondary_structure_section",
  "connectivity_annotation_section",
  "miscellaneous_features_section",
  "crystallographic_section",
  "connectivity_section",
  "bookkeeping_section")


class pdb_input_mixin(object):

  def label_to_auth_asym_id_dictionary(self):
    """ Only avaliable for cif_input
    """
    return None

  def deposition_date(self, us_style=True):
    """
    Placeholder to match mmCIF functionality. Probably could parse
    REVDAT.
    """
    result = None
    for line in self.title_section():
      if(line.startswith("HEADER ")):
        date = header_date(field=line[50:59])
        if(date.is_fully_defined()):
          dd = str(date.dd).strip()
          if(len(dd)==1): dd = "0"+dd
          result = "%s-%s-%s"%(dd, str(date.mmm), str(date.yyyy))
          if(us_style):
            months = dict((v.upper(),k) for k,v in enumerate(calendar.month_abbr))
            m=str(months[str(date.mmm).upper()])
            if(len(m)==1): m = "0"+m
            result = "%s-%s-%s"%(str(date.yyyy), m, dd)
    return result

  def special_position_settings(self,
        special_position_settings=None,
        weak_symmetry=False,
        min_distance_sym_equiv=0.5,
        u_star_tolerance=0):
    crystal_symmetry = self.crystal_symmetry(
      crystal_symmetry=special_position_settings,
      weak_symmetry=weak_symmetry)
    return construct_special_position_settings(
      crystal_symmetry = crystal_symmetry,
      special_position_settings=special_position_settings,
      weak_symmetry=weak_symmetry,
      min_distance_sym_equiv=min_distance_sym_equiv,
      u_star_tolerance=u_star_tolerance)

  def as_pdb_string(self,
        crystal_symmetry=Auto,
        cryst1_z=Auto,
        write_scale_records=True,
        append_end=False,
        atom_hetatm=True,
        sigatm=True,
        anisou=True,
        siguij=True,
        cstringio=None,
        link_records=Auto,
        return_cstringio=Auto):
    """
    Generate standard PDB format.  Will use built-in crystal symmetry if
    available.
    """
    if (cstringio is None):
      cstringio = StringIO()
      if (return_cstringio is Auto):
        return_cstringio = False
    elif (return_cstringio is Auto):
      return_cstringio = True
    if 0:
      if (link_records is Auto):
        print(format_link_records(self.get_link_records()), file=cstringio)
      elif (link_records is not None):
        print(format_link_records(link_records), file=cstringio)
    if (crystal_symmetry is Auto):
      crystal_symmetry = self.crystal_symmetry()
    if (cryst1_z is Auto):
      cryst1_z = self.extract_cryst1_z_columns()
    if (crystal_symmetry is not None or cryst1_z is not None):
      print(format_cryst1_and_scale_records(
        crystal_symmetry=crystal_symmetry,
        cryst1_z=cryst1_z,
        write_scale_records=write_scale_records), file=cstringio)

    py3out = self._as_pdb_string_cstringio(
      cstringio=cstringio,
      append_end=append_end,
      atom_hetatm=atom_hetatm,
      sigatm=sigatm,
      anisou=anisou,
      siguij=siguij)
    if six.PY3:
      cstringio.write( py3out)
    if (return_cstringio):
      return cstringio
    return cstringio.getvalue()

  def write_pdb_file(self,
        file_name,
        open_append=False,
        crystal_symmetry=Auto,
        cryst1_z=Auto,
        write_scale_records=True,
        append_end=False,
        atom_hetatm=True,
        sigatm=True,
        anisou=True,
        siguij=True):
    if (crystal_symmetry is Auto):
      crystal_symmetry = self.crystal_symmetry()
    if (cryst1_z is Auto):
      cryst1_z = self.extract_cryst1_z_columns()
    if (crystal_symmetry is not None or cryst1_z is not None):
      if (open_append): mode = "a"
      else:             mode = "w"
      with open(file_name, mode) as f:
        print(format_cryst1_and_scale_records(
          crystal_symmetry=crystal_symmetry,
          cryst1_z=cryst1_z,
          write_scale_records=write_scale_records), file=f)
      open_append = True
    self._write_pdb_file(
      file_name=file_name,
      open_append=open_append,
      append_end=append_end,
      atom_hetatm=atom_hetatm,
      sigatm=sigatm,
      anisou=anisou,
      siguij=siguij)

  def xray_structure_simple(self,
        crystal_symmetry=None,
        weak_symmetry=False,
        cryst1_substitution_buffer_layer=None,
        unit_cube_pseudo_crystal=False,
        fractional_coordinates=False,
        use_scale_matrix_if_available=True,
        min_distance_sym_equiv=0.5,
        non_unit_occupancy_implies_min_distance_sym_equiv_zero=True,
        scattering_type_exact=False,
        enable_scattering_type_unknown=False,
        atom_names_scattering_type_const
          =default_atom_names_scattering_type_const):
    """
    Create a single cctbx.xray.structure object from the atom records, using
    only the first model found.
    """
    if(crystal_symmetry is not None): self._scale_matrix = None
    return self.xray_structures_simple(
      one_structure_for_each_model=False,
      crystal_symmetry=crystal_symmetry,
      weak_symmetry=weak_symmetry,
      cryst1_substitution_buffer_layer=cryst1_substitution_buffer_layer,
      unit_cube_pseudo_crystal=unit_cube_pseudo_crystal,
      fractional_coordinates=fractional_coordinates,
      use_scale_matrix_if_available=use_scale_matrix_if_available,
      min_distance_sym_equiv=min_distance_sym_equiv,
      non_unit_occupancy_implies_min_distance_sym_equiv_zero=
        non_unit_occupancy_implies_min_distance_sym_equiv_zero,
      scattering_type_exact=scattering_type_exact,
      enable_scattering_type_unknown=enable_scattering_type_unknown,
      atom_names_scattering_type_const=atom_names_scattering_type_const)[0]

  def xray_structures_simple(self,
        one_structure_for_each_model=True,
        crystal_symmetry=None,
        weak_symmetry=False,
        cryst1_substitution_buffer_layer=None,
        unit_cube_pseudo_crystal=False,
        fractional_coordinates=False,
        min_distance_sym_equiv=0.5,
        non_unit_occupancy_implies_min_distance_sym_equiv_zero=True,
        use_scale_matrix_if_available=True,
        scattering_type_exact=False,
        enable_scattering_type_unknown=False,
        atom_names_scattering_type_const
          =default_atom_names_scattering_type_const):
    """
    Create a list of cctbx.xray.structure objects, one per model in the
    input file.  Note that for most single-model structures (i.e. nearly all
    crystal structures), this will be a single-item list.
    """
    from cctbx import xray
    from cctbx import crystal
    from cctbx import uctbx
    if (unit_cube_pseudo_crystal):
      assert crystal_symmetry is None and cryst1_substitution_buffer_layer is None
      crystal_symmetry = crystal.symmetry(
        unit_cell=(1,1,1,90,90,90),
        space_group_symbol="P1")
    else:
      crystal_symmetry = self.crystal_symmetry(
        crystal_symmetry=crystal_symmetry,
        weak_symmetry=weak_symmetry)
      if (crystal_symmetry is None):
        crystal_symmetry = crystal.symmetry()
      if (crystal_symmetry.unit_cell() is None):
        crystal_symmetry = crystal_symmetry.customized_copy(
          unit_cell=uctbx.non_crystallographic_unit_cell(
            sites_cart=self.atoms().extract_xyz(),
            buffer_layer=cryst1_substitution_buffer_layer))
      if (crystal_symmetry.space_group_info() is None):
        crystal_symmetry = crystal_symmetry.cell_equivalent_p1()
    unit_cell = crystal_symmetry.unit_cell()
    scale_r = (0,0,0,0,0,0,0,0,0)
    scale_t = (0,0,0)
    if (not unit_cube_pseudo_crystal):
      if (use_scale_matrix_if_available):
        scale_matrix = self.scale_matrix()
        if (scale_matrix is not None):
          # Avoid subtle inconsistencies due to rounding errors.
          # 1.e-6 is the precision of the values on the SCALE records.
          if (max([abs(s-f) for s,f in zip(
                     scale_matrix[0],
                     unit_cell.fractionalization_matrix())]) < 1.e-6):
            if (scale_matrix[1] != [0,0,0]):
              scale_matrix[0] = unit_cell.fractionalization_matrix()
            else:
              scale_matrix = None
      else:
        scale_matrix = None
      if (scale_matrix is not None):
        scale_r = scale_matrix[0]
        scale_t = scale_matrix[1]
    result = []
    if (atom_names_scattering_type_const is None):
      atom_names_scattering_type_const = []
    loop = xray_structures_simple_extension(
      one_structure_for_each_model,
      unit_cube_pseudo_crystal,
      fractional_coordinates,
      scattering_type_exact,
      enable_scattering_type_unknown,
      self.atoms_with_labels(),
      self.model_indices(),
      scitbx.stl.set.stl_string(atom_names_scattering_type_const),
      unit_cell,
      scale_r,
      scale_t)
    special_position_settings = crystal_symmetry.special_position_settings(
      min_distance_sym_equiv=min_distance_sym_equiv)
    try :
      while (next(loop)):
        result.append(xray.structure(
          special_position_settings=special_position_settings,
          scatterers=loop.scatterers,
          non_unit_occupancy_implies_min_distance_sym_equiv_zero=
            non_unit_occupancy_implies_min_distance_sym_equiv_zero))
    except ValueError as e :
      raise Sorry(str(e))
    return result

bp.inject(ext.input, pdb_input_mixin)
@bp.inject_into(ext.input)
class _():

  """
  This class parses PDB format, including non-ATOM records.  Atom objects will
  be created as part of the parsing, but the full PDB hierarchy object requires
  calling the construct_hierarchy() method.
  """

  def __getinitargs__(self):
    lines = flex.std_string()
    for section in input_sections[:-2]:
      lines.extend(getattr(self, section)())
    pdb_string = StringIO()

    py3out = self._as_pdb_string_cstringio(  # NOTE py3out is None in python 2
      cstringio=pdb_string,
      append_end=False,
      atom_hetatm=True,
      sigatm=True,
      anisou=True,
      siguij=True)
    if six.PY3:
      pdb_string.write(py3out)
    lines.extend(flex.split_lines(pdb_string.getvalue()))
    for section in input_sections[-2:]:
      lines.extend(getattr(self, section)())
    return ("pickle", lines)

  def file_type(self):
    return "pdb"

  def sequence_from_SEQRES(self):
    from iotbx.pdb import amino_acid_codes
    d = {}
    ps = self.primary_structure_section()
    for l in ps:
      l = l.strip()
      ls = l.split()
      if(l.startswith("SEQRES")):
        kw, i_seq, chid, rns = ls[0], ls[1], ls[2], ls[4:]
        d.setdefault(chid, []).extend(rns)
    result = []
    ott = amino_acid_codes.one_letter_given_three_letter
    for k, vs in zip(d.keys(), d.values()): # FIXME use iteritems?
      result.append(">chain %s"%k)
      result.append("".join([ott.get(v,"?") for v in vs]))
    return "\n".join(result)

  def extract_header_year(self):
    for line in self.title_section():
      if (line.startswith("HEADER ")):
        return header_year(line)
    return None

  def extract_authors(self):
    trigger = "AUTHOR"
    result = []
    def is_number(s):
      try:
        float(s)
        return True
      except ValueError: return False
    # extract and put into one string...
    lt = ""
    cntr=0
    for l in self.title_section():
      if(l.startswith(trigger)):
        l_=l.strip().replace(trigger,"").strip()
        if(is_number(l_[0])): l_ = l_.replace(l_[0],"").strip()
        #
        l1 = lt.split(",")
        l1 = l1[len(l1)-1]
        l2 = l_.split(",")[0]
        if((l1.count(".")>0 and l2.count(".")==0) or l1.endswith("-")): j=""
        else: j = ","
        #
        lt = lt + j + l_
        cntr+=1
    # ...then analyze
    l_=lt.strip().replace(trigger,"").strip()
    if(is_number(l_[0])): l_ = l_.replace(l_[0],"").strip()
    if(not (l_.startswith(trigger) or is_number(l_))):
      l_ = l_.split(",")
      for l__ in l_:
        l__ = "".join([x.strip() for x in l__])
        if(len(l__)>0):
          l__ = l__.split(".")
          l__.sort()
          l__ = [x.upper() for x in l__]
          l__ = ".".join(l__)
          if(l__[0].isalpha() and l__[len(l__)-1].isalpha()):
            result.append(l__)
    return result

  def extract_remark_iii_records(self, iii):
    result = []
    pattern = "REMARK %3d " % iii
    for line in self.remark_section():
      if (line.startswith(pattern)):
        result.append(line)
    return result

  def extract_secondary_structure(self, log=None):
    from iotbx.pdb import secondary_structure
    records = self.secondary_structure_section()
    return secondary_structure.annotation.from_records(records, log)

  def extract_LINK_records(self):
    '''
    Collect link records from PDB file
    '''
    result = []
    for line in self.connectivity_annotation_section():
      if (line.startswith('LINK') or line.startswith('link')):
        result.append(line)
    return result

  def crystal_symmetry_from_cryst1(self):
    from iotbx.pdb import cryst1_interpretation
    for line in self.crystallographic_section():
      if (line.startswith("CRYST1")):
        return cryst1_interpretation.crystal_symmetry(cryst1_record=line)
    return None

  def extract_cryst1_z_columns(self):
    for line in self.crystallographic_section():
      if (line.startswith("CRYST1")):
        result = line[66:]
        if (len(result) < 4): result += " " * (4-len(result))
        return result
    return None

  def _crystal_symmetry_from_cns_remark_sg(self):
    from iotbx.cns import pdb_remarks
    for line in self.remark_section():
      if (line.startswith("REMARK sg=")):
        crystal_symmetry = pdb_remarks.extract_symmetry(pdb_record=line)
        if (crystal_symmetry is not None):
          return crystal_symmetry
    return None

  def crystal_symmetry(self,
        crystal_symmetry=None,
        weak_symmetry=False):
    self_symmetry = self.crystal_symmetry_from_cryst1()
    if (self_symmetry is None):
      self_symmetry = self._crystal_symmetry_from_cns_remark_sg()
    if (crystal_symmetry is None):
      return self_symmetry
    if (self_symmetry is None):
      return crystal_symmetry
    return self_symmetry.join_symmetry(
      other_symmetry=crystal_symmetry,
      force=not weak_symmetry)

  def scale_matrix(self):
    if (not hasattr(self, "_scale_matrix")):
      source_info = self.source_info()
      if (len(source_info) > 0): source_info = " (%s)" % source_info
      self._scale_matrix = [[None]*9,[None]*3]
      done_set = set()
      done_list = []
      for line in self.crystallographic_section():
        if (line.startswith("SCALE") and line[5:6] in ["1", "2", "3"]):
          r = read_scale_record(line=line, source_info=source_info)
          if (r.n not in done_set):
            for i_col,v in enumerate(r.r):
              self._scale_matrix[0][(r.n-1)*3+i_col] = v
            self._scale_matrix[1][r.n-1] = r.t
            done_set.add(r.n)
          done_list.append(r.n)
      if (len(done_list) == 0):
        self._scale_matrix = None
      elif (sorted(done_list[:3]) != [1,2,3]):
        raise ValueError(
          "Improper set of PDB SCALE records%s" % source_info)
    return self._scale_matrix

  def process_BIOMT_records(self):
    import iotbx.mtrix_biomt
    return iotbx.mtrix_biomt.process_BIOMT_records_pdb(
      lines = self.extract_remark_iii_records(350))

  def process_MTRIX_records(self):
    import iotbx.mtrix_biomt
    return iotbx.mtrix_biomt.process_MTRIX_records_pdb(
      lines=self.crystallographic_section())

  def get_r_rfree_sigma(self, file_name=None):
    from iotbx.pdb import extract_rfactors_resolutions_sigma
    remark_2_and_3_records = self.extract_remark_iii_records(2)
    remark_2_and_3_records.extend(self.extract_remark_iii_records(3))
    return extract_rfactors_resolutions_sigma.get_r_rfree_sigma(
      remark_2_and_3_records, file_name)

  def resolution(self):
    return self.get_r_rfree_sigma().resolution

  def get_program_name(self):
    remark_3_lines = self.extract_remark_iii_records(3)
    result = None
    for line in remark_3_lines:
      line = line.strip()
      result = iotbx.pdb.remark_3_interpretation.get_program(st = line)
      if(result is not None): return result
    if(result is not None):
      result = "_".join(result.split())
    return result

  def get_solvent_content(self):
    remark_280_lines = self.extract_remark_iii_records(280)
    mc = []
    for remark in remark_280_lines:
      remark = remark.upper()
      if(remark.count("SOLVENT")==1 and
         remark.count("CONTENT")==1):
        try:
          mc.append(remark.split()[6])
        except Exception:
          try:
            mc.append(remark[remark.index(":")+1:])
          except Exception:
            mc.append(remark)
    result = None
    if(len(mc) == 1):
      try: result = float(mc[0])
      except IndexError: pass
      except ValueError: pass
    return result

  def get_matthews_coeff(self):
    remark_280_lines = self.extract_remark_iii_records(280)
    mc = []
    for remark in remark_280_lines:
      remark = remark.upper()
      if(remark.count("MATTHEWS")==1 and
         remark.count("COEFFICIENT")==1):
        try:
          mc.append(remark.split()[6])
        except Exception:
          try:
            mc.append(remark[remark.index(":")+1:])
          except Exception:
            mc.append(remark)
    result = None
    if(len(mc) == 1):
      try: result = float(mc[0])
      except IndexError: pass
      except ValueError: pass
    return result

  def extract_tls_params(self, hierarchy):
    import iotbx.pdb.remark_3_interpretation
    remark_3_records = self.extract_remark_iii_records(3)
    chain_ids = []
    for model in hierarchy.models():
      for chain in model.chains():
        chain_ids.append(chain.id)
    return iotbx.pdb.remark_3_interpretation.extract_tls_parameters(
      remark_3_records = remark_3_records,
      pdb_hierarchy    = hierarchy,
      chain_ids        = chain_ids)

  def extract_f_model_core_constants(self):

    remark_3_records = self.extract_remark_iii_records(3)
    return remark_3_interpretation.extract_f_model_core_constants(remark_3_records)

  def extract_wavelength(self, first_only=True):
    for line in self.remark_section():
      # XXX this will miss multi-line records!
      if (line.startswith("REMARK 200  WAVELENGTH OR RANGE")):
        fields = line.split(":")
        assert (len(fields) == 2)
        subfields = fields[1].replace(";", ",").strip().split(",")
        wavelengths = []
        for field in subfields :
          if (field.strip() == ""):
            continue
          elif (field.strip() == "NULL"):
            wavelengths.append(None)
          else :
            try :
              wavelengths.append(float(field.strip()))
            except ValueError :
              wavelengths.append(None)
        if (first_only):
          if (len(wavelengths) > 0):
            return wavelengths[0]
          return None
        return wavelengths
    return None

  def get_experiment_type(self):
    for line in self.title_section():
      if (line.startswith("EXPDTA")):
        return experiment_type(iotbx.pdb.records.expdta(line).keywords)
    return experiment_type([])

  def extract_connectivity(self):
    """
    Parse CONECT records and extract the indices of bonded atoms.  Returns
    a scitbx.array_family.shared.stl_set_unsigned object corresponding to the
    atoms array, with each element being the list of indices of bonded atoms
    (if any).  If no CONECT records are found, returns None.

    Note that the ordering of atoms may be altered by construct_hierarchy(), so
    this method should probably be called after the hierarchy is made.
    """
    lines = self.connectivity_section()
    if (len(lines) == 0):
      return None
    from scitbx.array_family import shared
    bonds = shared.stl_set_unsigned(len(self.atoms()), [])
    serial_ref_hash = {}
    for i_seq, atom in enumerate(self.atoms()):
      serial = atom.serial.strip()
      serial_ref_hash[serial] = i_seq
    for line in lines :
      assert (line.startswith("CONECT"))
      record = iotbx.pdb.records.conect(line)
      i_seq = serial_ref_hash[record.serial.strip()]
      assert (record.serial_numbers_bonded_atoms.count('') != 4)
      for j_seq_str in record.serial_numbers_bonded_atoms :
        if (j_seq_str != ''):
          bonds[i_seq].append(serial_ref_hash[j_seq_str.strip()])
    return bonds

  def get_link_records(self):
    for atom1 in self.atoms_with_labels():
      if not atom1.hetero: continue
      for atom2 in self.atoms_with_labels():
        if not atom2.hetero: continue
        if atom1.resname==atom2.resname: continue
        yield atom1, atom2, "1555", "1555"
        break
      break

  def get_restraints_used(self):
    return {'CDL' : self.used_cdl_restraints(),
            'omega' : self.used_omega_restraints(),
            'Amber' : self.used_amber_restraints(),
           }

  def _used_what_restraints(self, what):
    rc = False
    for line in self.remark_section():
      if line.startswith("REMARK   3") and (what in line):
        rc = True
        break
    return rc

  def used_cdl_restraints(self):
    return self._used_what_restraints('CDL')

  def used_omega_cdl_restraints(self):
    return self._used_what_restraints('omega-cdl')

  def used_amber_restraints(self):
    return self._used_what_restraints('Amber')

# Table of structures split into multiple PDB files.
# Assembled manually.
# Based on 46377 PDB files as of Tuesday Oct 02, 2007
#   noticed in passing: misleading REMARK 400 in 1VSA (1vs9 and 2i1c
#   don't exist)
# Updated 2009-04-07, based on 56751 PDB files, using SPLIT records.
pdb_codes_fragment_files = """\
1crp 1crr
1f49 1gho
1gix 1giy
1j4z 1kpo
1jgo 1jgp 1jgq
1jyy 1jyz
1jz0 1jz1
1otz 1p0t
1pns 1pnu
1pnx 1pny
1s1h 1s1i
1ti2 1vld
1ti4 1vle
1ti6 1vlf
1utf 1utv
1voq 1vor 1vos 1vou 1vov 1vow 1vox 1voy 1voz 1vp0
1vs5 1vs6 1vs7 1vs8
1vsa 2ow8
1vsp 2qnh
1we3 1wf4
1yl3 1yl4
2avy 2aw4 2aw7 2awb
2b64 2b66
2b9m 2b9n
2b9o 2b9p
2bld 2bvi
2gy9 2gya
2gyb 2gyc
2hgi 2hgj
2hgp 2hgq
2hgr 2hgu
2i2p 2i2t 2i2u 2i2v
2j00 2j01 2j02 2j03
2jl5 2jl6 2jl7 2jl8
2qal 2qam 2qan 2qao
2qb9 2qba 2qbb 2qbc
2qbd 2qbe 2qbf 2qbg
2qbh 2qbi 2qbj 2qbk
2qou 2qov 2qow 2qox
2qoy 2qoz 2qp0 2qp1
2uv9 2uva
2uvb 2uvc
2v46 2v47 2v48 2v49
2vhm 2vhn 2vho 2vhp
2z4k 2z4l 2z4m 2z4n
2zkq 2zkr
2zuo 2zv4 2zv5
3bz1 3bz2
3d5a 3d5b 3d5c 3d5d
3df1 3df2 3df3 3df4
3f1e 3f1f 3f1g 3f1h
"""

class join_fragment_files(object):
  def __init__(self, file_names):
    info = flex.std_string()
    info.append("REMARK JOINED FRAGMENT FILES (iotbx.pdb)")
    info.append("REMARK " + date_and_time())
    roots = []
    z = None
    from cctbx import crystal
    self.crystal_symmetry = crystal.symmetry()
    z_warning = 'REMARK ' \
      'Warning: CRYST1 Z field (columns 67-70) is not an integer: "%-4.4s"'
    for file_name in file_names:
      pdb_inp = iotbx.pdb.input(file_name=file_name)
      z_ = pdb_inp.extract_cryst1_z_columns()
      if (z_ is not None):
        z_ = z_.strip()
        if (z_ != "") : z_ = int(z_)
        else : z_ = None
      else: z_ = None
      if z is None:
        z = z_
      else:
        z = max(z, z_)
      cs = pdb_inp.crystal_symmetry()
      info.append("REMARK %s" % show_string(file_name))
      if cs is not None and cs.unit_cell() is not None:
        info.append("REMARK %s" % iotbx.pdb.format_cryst1_record(cs, z=z_))
        self.crystal_symmetry = self.crystal_symmetry.join_symmetry(
          cs, force=True)
      roots.append(pdb_inp.construct_hierarchy(sort_atoms=False))
    if self.crystal_symmetry.unit_cell() is not None:
      info.append(iotbx.pdb.format_cryst1_record(
        crystal_symmetry=self.crystal_symmetry, z=z))
    result = iotbx.pdb.hierarchy.join_roots(roots=roots)
    result.info.extend(info)
    result.reset_i_seq_if_necessary()
    self.joined = result

def merge_files_and_check_for_overlap(file_names, output_file,
    site_clash_cutoff=0.5, log=sys.stdout):
  """ Merge models and write composite model"""
  assert len(file_names) > 0
  merged_records = combine_unique_pdb_files(file_names)
  warnings = StringIO()
  merged_records.report_non_unique(out=warnings)
  merged_hierarchy = join_fragment_files(file_names).joined
  f = open(output_file, "w")
  f.write(merged_hierarchy.as_pdb_string())
  f.close()
  n_clashes = quick_clash_check(output_file,
    site_clash_cutoff=site_clash_cutoff,
    out=log)
  return n_clashes

def quick_clash_check(file_name, site_clash_cutoff=0.5, out=sys.stdout,
    show_outliers=5):
  """Carry out clash check on a model file"""
  pdb_inp = input(file_name=file_name)
  pdb_atoms = pdb_inp.atoms_with_labels()
  xray_structure = pdb_inp.xray_structure_simple(
    cryst1_substitution_buffer_layer=10,
    enable_scattering_type_unknown=True)
  sites_frac = xray_structure.sites_frac()
  unit_cell = xray_structure.unit_cell()
  pair_asu_table = xray_structure.pair_asu_table(
    distance_cutoff=site_clash_cutoff)
  pair_sym_table = pair_asu_table.extract_pair_sym_table()
  atom_pairs = pair_sym_table.simple_edge_list()
  return len(atom_pairs)

standard_rhombohedral_space_group_symbols = [
"R 3 :H",
"R 3 :R",
"R -3 :H",
"R -3 :R",
"R 3 2 :H",
"R 3 2 :R",
"R 3 m :H",
"R 3 m :R",
"R 3 c :H",
"R 3 c :R",
"R -3 m :H",
"R -3 m :R",
"R -3 c :H",
"R -3 c :R"]
if ("set" in __builtins__):
  standard_rhombohedral_space_group_symbols = set(
    standard_rhombohedral_space_group_symbols)

def format_cryst1_sgroup(space_group_info):
  """Format space_group for CRYST1 record"""
  result = space_group_info.type().lookup_symbol()
  if (result in standard_rhombohedral_space_group_symbols):
    result = result[-1] + result[1:-3]
  def compress(s):
    if (len(s) > 11): return s.replace(" ", "")
    return s
  result = compress(result)
  if (len(result) > 11 and not space_group_info.group().is_centric()):
    from iotbx.mtz.extract_from_symmetry_lib import ccp4_symbol
    alt = ccp4_symbol(
      space_group_info=space_group_info,
      lib_name="syminfo.lib",
      require_at_least_one_lib=False)
    if (alt is not None and alt != result.replace(" ", "")):
      result = compress(alt)
  return result

def format_cryst1_record(crystal_symmetry, z=None):
  """Format CRYST1 record from crystal_symmetry"""
  # CRYST1
  #  7 - 15       Real(9.3)      a             a (Angstroms).
  # 16 - 24       Real(9.3)      b             b (Angstroms).
  # 25 - 33       Real(9.3)      c             c (Angstroms).
  # 34 - 40       Real(7.2)      alpha         alpha (degrees).
  # 41 - 47       Real(7.2)      beta          beta (degrees).
  # 48 - 54       Real(7.2)      gamma         gamma (degrees).
  # 56 - 66       LString        sGroup        Space group.
  # 67 - 70       Integer        z             Z value.
  if (z is None): z = ""
  else: z = str(z)
  return ("CRYST1%9.3f%9.3f%9.3f%7.2f%7.2f%7.2f %-11.11s%4.4s" % (
    crystal_symmetry.unit_cell().parameters()
    + (format_cryst1_sgroup(
         space_group_info=crystal_symmetry.space_group_info()),
       z))).rstrip()

def format_scale_records(unit_cell=None,
                         fractionalization_matrix=None,
                         u=[0,0,0]):
  """Format SCALE records from unit_cell"""
  #  1 -  6       Record name    "SCALEn"       n=1, 2, or 3
  # 11 - 20       Real(10.6)     s[n][1]        Sn1
  # 21 - 30       Real(10.6)     s[n][2]        Sn2
  # 31 - 40       Real(10.6)     s[n][3]        Sn3
  # 46 - 55       Real(10.5)     u[n]           Un
  assert [unit_cell, fractionalization_matrix].count(None) == 1
  if (unit_cell is not None):
    f = unit_cell.fractionalization_matrix()
  else:
    assert len(fractionalization_matrix) == 9
    f = fractionalization_matrix
  assert len(u) == 3
  return (("SCALE1    %10.6f%10.6f%10.6f     %10.5f\n"
           "SCALE2    %10.6f%10.6f%10.6f     %10.5f\n"
           "SCALE3    %10.6f%10.6f%10.6f     %10.5f") % (
    f[0], f[1], f[2], u[0],
    f[3], f[4], f[5], u[1],
    f[6], f[7], f[8], u[2])).replace(" -0.000000", "  0.000000")

def format_cryst1_and_scale_records(
      crystal_symmetry=None,
      cryst1_z=None,
      write_scale_records=True,
      scale_fractionalization_matrix=None,
      scale_u=[0,0,0]):
  """Format CRYST1 and SCALE records from crystal_symmetry"""
  from cctbx import crystal
  from cctbx import sgtbx
  from cctbx import uctbx
  if (crystal_symmetry is None):
    unit_cell = None
    space_group_info = None
  elif (isinstance(crystal_symmetry, crystal.symmetry)):
    unit_cell = crystal_symmetry.unit_cell()
    space_group_info = crystal_symmetry.space_group_info()
  elif (isinstance(crystal_symmetry, uctbx.ext.unit_cell)):
    unit_cell = crystal_symmetry
    space_group_info = None
  elif (isinstance(crystal_symmetry, (list, tuple))):
    assert len(crystal_symmetry) == 6 # unit cell parameters
    unit_cell = uctbx.unit_cell(crystal_symmetry)
    space_group_info = None
  else:
    raise ValueError("invalid crystal_symmetry object")
  if (unit_cell is None):
    if (scale_fractionalization_matrix is None):
      unit_cell = uctbx.unit_cell((1,1,1,90,90,90))
    else:
      unit_cell = uctbx.unit_cell(
        orthogonalization_matrix=matrix.sqr(
          scale_fractionalization_matrix).inverse())
  if (space_group_info is None):
    space_group_info = sgtbx.space_group_info(symbol="P 1")
  result = format_cryst1_record(
    crystal_symmetry=crystal.symmetry(
      unit_cell=unit_cell, space_group_info=space_group_info),
    z=cryst1_z)
  if (write_scale_records):
    if (scale_fractionalization_matrix is None):
      scale_fractionalization_matrix = unit_cell.fractionalization_matrix()
    result += "\n" + format_scale_records(
      fractionalization_matrix=scale_fractionalization_matrix,
      u=scale_u)
  return result

def format_link_records(link_list):
  """Format LINK records"""

  """
COLUMNS         DATA TYPE      FIELD           DEFINITION
-----------------------------------------------------------------------------
 1 -  6         Record name    "LINK  "
13 - 16         Atom           name1           Atom name.
17              Character      altLoc1         Alternate location indicator.
18 - 20         Residue name   resName1        Residue  name.
22              Character      chainID1        Chain identifier.
23 - 26         Integer        resSeq1         Residue sequence number.
27              AChar          iCode1          Insertion code.
43 - 46         Atom           name2           Atom name.
47              Character      altLoc2         Alternate location indicator.
48 - 50         Residue name   resName2        Residue name.
52              Character      chainID2        Chain identifier.
53 - 56         Integer        resSeq2         Residue sequence number.
57              AChar          iCode2          Insertion code.
60 - 65         SymOP          sym1            Symmetry operator atom 1.
67 - 72         SymOP          sym2            Symmetry operator atom 2.
74 - 78         Real(5.2)      Length          Link distance
"""
  test = """
         1         2         3         4         5         6         7         8
12345678901234567890123456789012345678901234567890123456789012345678901234567890
LINK         O   GLY A  49                NA    NA A6001     1555   1555  2.98
"""
  def _format_link_atom(atom):
    result = "%4s%s%-3s %s%4s%s" % (atom.name,
                                   atom.altloc,
                                   atom.resname,
                                   atom.chain_id,
                                   atom.resseq,
                                   atom.icode,
                                   )
    return result
  result = ""
  for atom1, atom2, sym_op1, sym_op2 in link_list:
    result += "LINK        "
    result += _format_link_atom(atom1)
    result += " "*15
    result += _format_link_atom(atom2)
    result += " "
    result += "   1555"
    result += "   1555"
    result += " %5.2f" % 2.9
  return result

class read_scale_record(object):

  __slots__ = ["n", "r", "t"]

  def __init__(O, line, source_info=""):
    try: O.n = int(line[5:6])
    except ValueError: O.n = None
    if (O.n not in [1,2,3]):
      raise RuntimeError(
        "Unknown PDB record %s%s" % (show_string(line[:6]), source_info))
    values = []
    for i in [10,20,30,45]:
      fld = line[i:i+10]
      if (len(fld.strip()) == 0):
        value = 0
      else:
        try: value = float(fld)
        except ValueError:
          raise RuntimeError(
            "Not a floating-point value, PDB record %s%s:\n" % (
              show_string(line[:6]), source_info)
            + "  " + line + "\n"
            + "  %s%s" % (" "*i, "^"*10))
      values.append(value)
    O.r, O.t = values[:3], values[3]

def resseq_decode(s):
  """Convert from hybrid-36 to integer number """
  try: return hy36decode(width=4, s="%4s" % s)
  except ValueError:
    raise ValueError('invalid residue sequence number: "%4s"' % s)

def resseq_encode(value):
  """Convert from integer number to hybrid-36"""
  return hy36encode(width=4, value=value)

def encode_serial_number(width, value):
  """Convert from serial number to hybrid-36"""

  if (isinstance(value, str)):
    assert len(value) <= width
    return value
  if (isinstance(value, int)):
    return hy36encode(width=width, value=value)
  raise RuntimeError("serial number value must be str or int.")

def make_atom_with_labels(
      result=None,
      xyz=None,
      sigxyz=None,
      occ=None,
      sigocc=None,
      b=None,
      sigb=None,
      uij=None,
      siguij=None,
      hetero=None,
      serial=None,
      name=None,
      segid=None,
      element=None,
      charge=None,
      model_id=None,
      chain_id=None,
      resseq=None,
      icode=None,
      altloc=None,
      resname=None):
  """Make an atom_with_labels-like object """
  if (result is None):
    result = hierarchy.atom_with_labels()
  else :
    assert type(result).__name__ == 'atom_with_labels'
  if (xyz is not None): result.xyz = xyz
  if (sigxyz is not None): result.sigxyz = sigxyz
  if (occ is not None): result.occ = occ
  if (sigocc is not None): result.sigocc = sigocc
  if (b is not None): result.b = b
  if (sigb is not None): result.sigb = sigb
  if (uij is not None): result.uij = uij
  if (siguij is not None): result.siguij = siguij
  if (hetero is not None): result.hetero = hetero
  if (serial is not None): result.serial = serial
  if (name is not None): result.name = name
  if (segid is not None): result.segid = segid
  if (element is not None): result.element = element
  if (charge is not None): result.charge = charge
  if (model_id is not None): result.model_id = model_id
  if (chain_id is not None): result.chain_id = chain_id
  if (resseq is not None): result.resseq = resseq
  if (icode is not None): result.icode = icode
  if (altloc is not None): result.altloc = altloc
  if (resname is not None): result.resname = resname
  return result

def get_file_summary(pdb_in, hierarchy=None):
  """Summarize model file"""
  if (hierarchy is None):
    hierarchy = pdb_in.construct_hierarchy()
  counts = hierarchy.overall_counts()
  chain_ids = []
  for id in sorted(counts.chain_ids.keys()):
    if (id == " "):
      chain_ids.append("' '")
    else :
      chain_ids.append(id)
  info_list = [
    ("Number of atoms", counts.n_atoms),
    ("Number of chains", counts.n_chains),
    ("Chain IDs", ", ".join(chain_ids)),
    ("Alternate conformations", counts.n_alt_conf),
  ]
  if (counts.n_models > 1):
    info_list.insert(0, ("Number of models", counts.n_models))
  cl = counts.resname_classes
  if ("common_amino_acid" in cl):
    info_list.append(("Amino acid residues", cl['common_amino_acid']))
  if ("common_nucleic_acid" in cl) or ("ccp4_mon_lib_rna_dna" in cl):
    n_atoms = cl.get("common_nucleic_acid", 0) + \
              cl.get("ccp4_mon_lib_rna_dna", 0)
    info_list.append(("Nucleic acid residues", n_atoms))
  if ("common_water" in cl):
    info_list.append(("Water molecules", cl['common_water']))
  if ("common_element" in cl):
    names = []
    for name in counts.resnames :
      if (iotbx.pdb.common_residue_names_get_class(name)=="common_element"):
        names.append(name)
    value = "%d (%s)" % (cl['common_element'], ", ".join(names))
    info_list.append(("Elemental ions", value))
  if ("common_small_molecule" in cl) or ("other" in cl):
    names = []
    for name in counts.resnames :
      res_class = iotbx.pdb.common_residue_names_get_class(name)
      if (res_class in ["common_small_molecule", "other"]):
        names.append(name)
    n_atoms = cl.get("common_small_molecule", 0) + cl.get("other", 0)
    value = "%d (%s)" % (n_atoms, ", ".join(names))
    info_list.append(("Other molecules", value))
  atoms = hierarchy.atoms()
  b_factors = atoms.extract_b()
  mean_b = flex.mean(b_factors)
  min_b = flex.min(b_factors)
  max_b = flex.max(b_factors)
  info_list.append(("Mean isotropic B-factor", "%.2f (range: %.2f - %.2f)" %
    (mean_b, min_b, max_b)))
  if (min_b <= 0):
    n_bad_adp = (b_factors <= 0).count(True)
    info_list.append(("Atoms with iso. B <= 0", "%d ***" % n_bad_adp))
  occ = atoms.extract_occ()
  if (flex.min(occ) <= 0):
    n_zero_occ = (occ <= 0).count(True)
    info_list.append(("Atoms with zero ocupancy", "%d ***" % n_zero_occ))
  symm = pdb_in.crystal_symmetry()
  if (symm is not None):
    space_group = symm.space_group_info()
    info_list.append(("Space group", str(space_group)))
    unit_cell = symm.unit_cell()
    if (unit_cell is not None):
      uc_str = " ".join([ "%g" % x for x in unit_cell.parameters() ])
      info_list.append(("Unit cell", uc_str))
  return info_list

def show_file_summary(pdb_in, hierarchy=None, out=None):
  """Display summary of model file"""
  if (out is None):
    out = sys.stdout
  info = get_file_summary(pdb_in, hierarchy)
  label_width = max([ len(l) for l,v in info ]) + 2
  format = "%%-%ds %%s" % label_width
  for label, value in info :
    print(format % (label + ":", str(value)), file=out)
  return info


 *******************************************************************************


 *******************************************************************************
iotbx/pdb/aa_utils.py
"""Utilities for working with atom names"""
from __future__ import division, print_function
from iotbx.pdb import modified_aa_names
from iotbx.pdb.amino_acid_codes import three_letter_given_one_letter
from iotbx.pdb.amino_acid_codes import one_letter_given_three_letter

from mmtbx.chemical_components import get_atom_names, get_bond_pairs

def get_aa_parent(code):
  one = modified_aa_names.lookup.get(code.upper(), False)
  if not one: return None
  return three_letter_given_one_letter.get(one, None)

def get_aa_children(code):
  one = one_letter_given_three_letter.get(code, None)
  if one is None: return None
  if one not in modified_aa_names.lookup.values(): return None
  rc=[]
  for key, item in modified_aa_names.lookup.items():
    if item==one: rc.append(key)
  rc.sort()
  return rc

def standard_polymerise(code):
  names = get_atom_names(code, heavy_atom_only=True)
  names = set(names)
  return set(['N','CA','C','O']).issubset(names)

def compare_atom_names(child, parent):
  c_names = set(get_atom_names(child))
  p_names = get_atom_names(parent, heavy_atom_only=True)
  p_names.remove('OXT')
  return set(p_names).issubset(c_names)

def _is_specific_number_heavy_bonds(bonds, name, number, verbose=False):
  n_bonds = 0
  for bond in bonds:
    if verbose: print(bond)
    if 'OXT' in bond: continue
    if name in bond:
      n_bonds+=1
    if verbose: print(n_bonds)
  return n_bonds!=number

def is_n_terminal(bonds):
  return _is_specific_number_heavy_bonds(bonds, 'N', 1)

def is_c_terminal(bonds):
  return _is_specific_number_heavy_bonds(bonds, 'C', 2)

def is_ca_mod(bonds, n_bonds=3):
  return _is_specific_number_heavy_bonds(bonds, 'CA', n_bonds)

def is_standard_bonding(bonds, include_cb=True):
  standard = [('CA', 'N'), ('C', 'CA'), ('C', 'O')]
  if include_cb:
    standard.append(('CA', 'CB'))
  return set(standard).issubset(set(bonds))

def is_not_standard_main_chain(code):
  assert standard_polymerise(code)
  bonds = get_bond_pairs(code, heavy_atom_only=True, use_tuple=True)
  if is_n_terminal(bonds):
    return 'N terminal'
  elif is_c_terminal(bonds):
    return 'C terminal'
  elif is_ca_mod(bonds):
    return 'CA mod'
  elif not is_standard_bonding(bonds):
    return 'bonding mod'
  return False

def get_aa_type(code):
  parent = get_aa_parent(code)
  if not standard_polymerise(code):
    return 'non-polymer'
  exact_subset = True
  if not compare_atom_names(code, parent):
    exact_subset = False
  standard_main_chain = True
  if is_not_standard_main_chain(code):
    standard_main_chain = False
    return is_not_standard_main_chain(code)
  return 'ok'

def get_useable_sorted_on_size(code):
  rc = get_aa_children(code)
  tmp = []
  overall = {}
  for code in rc:
    aa_type = get_aa_type(code)
    overall.setdefault(aa_type, [])
    overall[aa_type].append(code)
    if aa_type in ['ok']:
      tmp.append(code)
  def myFunc(e): return len(get_atom_names(e, heavy_atom_only=True))
  tmp.sort(key=myFunc)
  return tmp

def tst_types(code):
  rc = get_aa_children(code)
  overall = {}
  for code in rc:
    aa_type = get_aa_type(code)
    overall.setdefault(aa_type, [])
    overall[aa_type].append(code)
  print(overall)
  for key, item in overall.items():
    print(key, item)

if __name__ == '__main__':
  import os, sys
  if len(sys.argv)>1:
    aa_list = sys.argv[1:]
  else:
    aa_list = ['CYS', 'DAL', 'NWM', 'GLY']
  for resname in aa_list:
    rc = get_aa_parent(resname)
    print('  Parent %s : %s' % (resname, rc))
    rc = get_aa_children(resname)
    print('  Children %s : %s' % (resname, rc))
    print(get_useable_sorted_on_size(resname))
    tst_types(resname)
    continue
    for code in rc:
      print(code,get_aa_type(code))
    #   cmd = 'phenix.reel --chem %s' % code
    #   os.system(cmd)


 *******************************************************************************


 *******************************************************************************
iotbx/pdb/amino_acid_codes.py
"""One-letter and three-letter protein codes"""
from __future__ import absolute_import, division, print_function
one_letter_given_three_letter = {
"ALA": "A",
"ARG": "R",
"ASN": "N",
"ASP": "D",
"CYS": "C",
"GLN": "Q",
"GLU": "E",
"GLY": "G",
"HIS": "H",
"ILE": "I",
"LEU": "L",
"LYS": "K",
"MET": "M",
"MSE": "M",
"PHE": "F",
"PRO": "P",
'PYL': 'O',
'SEC': 'U',
"SER": "S",
"THR": "T",
"TRP": "W",
"TYR": "Y",
"VAL": "V",
"UNK": "X", # Not described in standard (pdb does not define one letter code)
}

one_letter_given_three_letter_modified_aa  = {
# modified or unusual AA
"CSO" : "C", # oxidized Cys
"LLP" : "K", # Lys + PLP
"MLY" : "K", # dimethyllysine
"PTR" : "Y", # phosphotyrosine
"SEP" : "S", # phosphoserine
"TPO" : "T", # phosphothreonine
"TYS" : "Y", # sulfonated tyrosine
# XXX https://lists.sdsc.edu/pipermail/pdb-l/2014-January/005899.html
#"PYL" : "O", # pyrrolysine
#"SEC" : "U", # selenocysteine
}

three_letter_given_one_letter = {
"A": "ALA",
"C": "CYS",
"D": "ASP",
"E": "GLU",
"F": "PHE",
"G": "GLY",
"H": "HIS",
"I": "ILE",
"K": "LYS",
"L": "LEU",
"M": "MET",
"N": "ASN",
'O': 'PYL',
"P": "PRO",
"Q": "GLN",
"R": "ARG",
"S": "SER",
"T": "THR",
'U': 'SEC',
"V": "VAL",
"W": "TRP",
"Y": "TYR",
"X": "UNK", # Not described in standard (pdb does not define one letter code)
}

three_letter_l_given_three_letter_d = {
"DAL": "ALA",
"DAR": "ARG",
"DAS": "ASP",
"DCY": "CYS",
"DGL": "GLU",
"DGN": "GLN",
"DHI": "HIS",
"DIL": "ILE",
"DLE": "LEU",
"DLY": "LYS",
"DPN": "PHE",
"DPR": "PRO",
"DSG": "ASN",
"DSN": "SER",
"DTH": "THR",
"DTR": "TRP",
"DTY": "TYR",
"DVA": "VAL",
"MED": "MET"}

three_letter_d_given_three_letter_l = {
"ALA": "DAL",
"ARG": "DAR",
"ASN": "DSG",
"ASP": "DAS",
"CYS": "DCY",
"GLN": "DGN",
"GLU": "DGL",
"HIS": "DHI",
"ILE": "DIL",
"LEU": "DLE",
"LYS": "DLY",
"MET": "MED",
"PHE": "DPN",
"PRO": "DPR",
"SER": "DSN",
"THR": "DTH",
"TRP": "DTR",
"TYR": "DTY",
"VAL": "DVA"}

def validate_sequence(sequence=None,
                      protein=True, strict_protein=True,
                      nucleic_acid=False, strict_nucleic_acid=True):
  '''

  =============================================================================
  Function for checking if a sequence conforms to the FASTA format.
  (http://www.ncbi.nlm.nih.gov/BLAST/blastcgihelp.shtml)

  Parameters:
  -----------
  sequence - str (None) - the sequence to be checked
  protein - bool (True) - check for protein letters if True
  strict_protein - bool (True) - only check for the 20 amino acids if True
  nucleic_acid - bool (False) - check for nucleic acid letters if True
  strict_nucleic_acid - bool (True) - only check for the 5 base pairs if True

  Return:
  -------
  The function returns a set of unknown letters. If no unknown letters are
  found, the set is of size 0.

  Notes:
  ------
  There is overlap between the letters used to represent amino aicds and the
  letters used to represent nucleic acids. So if both protein and nucleic_acid
  are set to True, the set of valid letters is the union of both. This will
  make the overall validation less strict.

  =============================================================================

  '''

  # construct set of FASTA letters to test against
  fasta_format = set()
  if (protein):
    fasta_format = fasta_format.union(
      set(three_letter_given_one_letter.keys()))
    #fasta_format.remove('U')     # non-standard letter
    if (not strict_protein):
      fasta_format = fasta_format.union(set(['B', 'U', 'Z', 'X', '*', '-']))
  if (nucleic_acid):
    fasta_format = fasta_format.union(set(['A', 'T', 'C', 'G', 'U']))
    if (not strict_nucleic_acid):
      fasta_format = fasta_format.union(set(['N', 'K', 'M', 'B', 'V', 'S', 'W',
                                             'D', 'Y', 'R', 'H', '-']))

  # test sequence
  unknown_letters = set(sequence.upper()).difference(fasta_format)

  return unknown_letters


 *******************************************************************************


 *******************************************************************************
iotbx/pdb/atom_name_interpretation.py
"""Interpret atom names"""
from __future__ import absolute_import, division, print_function
import sys

class dict_with_add(dict):

  def __add__(self, other):
    result = dict_with_add(self)
    result.update(other)
    return result

def alternative_hydrogen_pattern(pattern):
  if (len(pattern) > 1
      and pattern[1] == "h"
      and pattern[0] in "123456789"):
    return pattern[1:]+pattern[0]
  return None

class interpreter(object):

  def __init__(self,
        expected_patterns,
        synonym_patterns, non_hydrogens, hydrogens,
        mutually_exclusive_pairs=[]):
    expected_patterns_set = set()
    for expected_pattern in expected_patterns:
      expected_patterns_set.add(expected_pattern)
    assert len(expected_patterns_set) == len(expected_patterns)
    for synonym_pattern,expected_pattern in synonym_patterns.items():
      assert expected_pattern in expected_patterns_set
    for mep in mutually_exclusive_pairs:
      assert len(mep) == 3
      for expected_pattern in mep:
        if (expected_pattern not in expected_patterns_set):
          raise RuntimeError(
            "Inconsistent mutually_exclusive_pairs:\n"
            + "  given: %s\n" % str(mep)
            + "  pattern %s not in expected_patterns" % expected_pattern)
    expected = {}
    for expected_pattern in expected_patterns:
      assert expected_pattern.strip() == expected_pattern
      for h in ["H", "D"]:
        name = expected_pattern.replace("h", h)
        if (name in expected):
          raise RuntimeError(
            "Duplicate name %s given expected_patterns: %s" % (
              show_string(name), ", ".join([show_string(p)
                for p in expected_patterns])))
        expected[name] = expected_pattern
        if (name == expected_pattern): break
    synonym_patterns = dict(synonym_patterns)
    for expected_pattern in expected_patterns:
      alt = alternative_hydrogen_pattern(expected_pattern)
      if (alt is not None): synonym_patterns[alt] = expected_pattern
    for synonym_pattern,expected_pattern in list(synonym_patterns.items()):
      alt = alternative_hydrogen_pattern(synonym_pattern)
      if (alt is not None): synonym_patterns[alt] = expected_pattern
    synonyms = {}
    for synonym_pattern,expected_pattern in list(synonym_patterns.items()):
      for h in ["H", "D"]:
        name = synonym_pattern.replace("h", h)
        if (name in synonyms):
          raise RuntimeError(
            "Inconsistent synonym_patterns:\n"
            + "  synonym_pattern: %s\n" % synonym_pattern
            + "  name derived from synonym_pattern: %s\n" % name
            + "  Another synonym_pattern already lead to the same name.")
        synonyms[name] = expected_pattern.replace("h", h)
        if (name == synonym_pattern): break
    self.expected_patterns = expected_patterns
    self.synonym_patterns = synonym_patterns
    self.mutually_exclusive_pairs = mutually_exclusive_pairs
    self.expected = expected
    self.synonyms = synonyms
    self.non_hydrogens = non_hydrogens
    self.hydrogens = hydrogens

  def match_atom_names(self, atom_names):
    expected = {}
    unexpected = []
    for atom_name in atom_names:
      name = atom_name.strip().upper()
      expected_pattern = self.expected.get(self.synonyms.get(name, name))
      if (expected_pattern is None):
        unexpected.append(atom_name)
      else:
        expected.setdefault(expected_pattern, []).append(atom_name)
    return matched_atom_names(
      interpreter=self,
      atom_names=atom_names,
      expected=expected,
      unexpected=unexpected)

class matched_atom_names(object):

  def __init__(self, interpreter, atom_names, expected, unexpected):
    self.interpreter = interpreter
    self.atom_names = atom_names
    self.expected = expected
    self.unexpected = unexpected

  def __repr__(self):
    outl = "\n%s" % self.__class__.__name__
    for attr in ["atom_names",
                 "expected",
                 "unexpected",
                 ]:
      outl += "\n  %s" % attr
      for name in getattr(self, attr, []):
        outl += " %s" % name
    return outl

  def expected_patterns_with_multiple_matches(self):
    result = {}
    for expected_pattern,names in self.expected.items():
      if (len(names) != 1):
        result[expected_pattern] = names
    return result

  def mutually_exclusive_pairs(self):
    result = []
    for mep in self.interpreter.mutually_exclusive_pairs:
      if (    mep[0] in self.expected
          and mep[2] in self.expected):
        result.append((mep[0], mep[2]))
    return result

  def show_problems(self, out=None, prefix=""):
    result = 0
    if (out is None): out = sys.stdout
    if (len(self.unexpected) != 0):
      print(prefix+"unexpected atom names:", ", ".join(['"'+name+'"'
        for name in self.unexpected]), file=out)
      result += 1
    for expected_pattern,names in \
          self.expected_patterns_with_multiple_matches().items():
      print(prefix+"multiple matches: expected pattern=%s  names=%s" \
        % (expected_pattern, ", ".join(['"'+name+'"' for name in names])), file=out)
      result += 1
    for pair in self.mutually_exclusive_pairs():
      print(prefix+"mutually exclusive: %s" % " ".join(pair), file=out)
      result += 1
    return result

  def mon_lib_names(self):
    result = [None] * len(self.atom_names)
    name_indices = {}
    for i,name in enumerate(self.atom_names):
      name_indices.setdefault(name, []).append(i)
    mep_transl = {}
    for mep in self.interpreter.mutually_exclusive_pairs:
      if (mep[2] in self.expected):
        mep_transl[mep[1]] = mep[0]
        mep_transl[mep[2]] = mep[1]
      else:
        mep_transl[mep[0]] = mep[0]
        mep_transl[mep[1]] = mep[1]
    for expected_pattern,names in self.expected.items():
      expected_pattern = mep_transl.get(expected_pattern, expected_pattern)
      mon_lib_name = expected_pattern.upper()
      if (mon_lib_name[0] in "123456789"):
        mon_lib_name = mon_lib_name[1:] + mon_lib_name[0]
      for name in names:
        for i in name_indices[name]:
          result[i] = mon_lib_name
    return result

  def missing_atom_names(self, ignore_hydrogen=False):
    if ignore_hydrogen:
      return set(self.interpreter.non_hydrogens).difference(
        set(self.mon_lib_names()))
    else:
      return set(self.interpreter.non_hydrogens +
        self.interpreter.hydrogens).difference(
        set(self.mon_lib_names()))

peptide_expected_patterns = [
  "N", "h", "1h", "2h", "3h",
  "CA",
  "C", "O",
  "OXT", "hXT"]

peptide_synonym_patterns = dict_with_add({
  "OT1": "O",
  "OT2": "OXT",
  "OC":  "OXT",
  "hC":  "hXT",
  "hN": "h",
  "1hN": "1h",
  "2hN": "2h",
  "3hN": "3h",
  "1hT": "1h",
  "2hT": "2h",
  "3hT": "3h",
  "h0A": "1h",
  "h0B": "2h",
  "h0C": "3h"})

gly_interpreter = interpreter(
  peptide_expected_patterns + [
    "1hA", "2hA", "3hA"],
  peptide_synonym_patterns,
  mutually_exclusive_pairs=[
    ("1hA", "2hA", "3hA")],
  non_hydrogens=("N","CA","C","O"),
  hydrogens=("H","HA1","HA2"))

ala_interpreter = interpreter(
  peptide_expected_patterns + [
    "hA",
    "CB", "1hB", "2hB", "3hB"],
  peptide_synonym_patterns,
  non_hydrogens=("N","CA","C","O","CB"),
  hydrogens=("H","HA","HB1","HB2","HB3"))

val_interpreter = interpreter(
  peptide_expected_patterns + [
    "hA",
    "CB", "hB",
    "CG1", "1hG1", "2hG1", "3hG1",
    "CG2", "1hG2", "2hG2", "3hG2"],
  peptide_synonym_patterns,
  non_hydrogens=("N","CA","C","O","CB","CG1","CG2"),
  hydrogens=("H","HA","HB","HG11","HG12","HG13","HG21","HG22","HG23"))

leu_interpreter = interpreter(
  peptide_expected_patterns + [
    "hA",
    "CB", "1hB", "2hB", "3hB",
    "CG", "hG",
    "CD1", "1hD1", "2hD1", "3hD1",
    "CD2", "1hD2", "2hD2", "3hD2"],
  peptide_synonym_patterns + {"1hG": "hG"},
  mutually_exclusive_pairs=[
    ("1hB", "2hB", "3hB")],
  non_hydrogens=("N","CA","C","O","CB","CG","CD1","CD2"),
  hydrogens=("H","HA","HB1","HB2","HD11","HD12","HD13","HD21","HD22","HD23"))

ile_interpreter = interpreter(
  peptide_expected_patterns + [
    "hA",
    "CB", "hB",
    "CG1", "1hG1", "2hG1", "3hG1",
    "CG2", "1hG2", "2hG2", "3hG2",
    "CD1", "1hD1", "2hD1", "3hD1"],
  peptide_synonym_patterns + {
    "CD": "CD1",
    "1hD": "1hD1",
    "2hD": "2hD1",
    "3hD": "3hD1"},
  mutually_exclusive_pairs=[
    ("1hG1", "2hG1", "3hG1")],
  non_hydrogens=("N","CA","C","O","CB","CG1","CD1","CG2"),
  hydrogens=("H","HA","HB","HG11","HG12","HD11","HD12","HD13","HG21","HG22",
    "HG23"))

met_interpreter = interpreter(
  peptide_expected_patterns + [
    "hA",
    "CB", "1hB", "2hB", "3hB",
    "CG", "1hG", "2hG", "3hG",
    "SD",
    "CE", "1hE", "2hE", "3hE"],
  peptide_synonym_patterns,
  mutually_exclusive_pairs=[
    ("1hB", "2hB", "3hB"),
    ("1hG", "2hG", "3hG")],
  non_hydrogens=("N","CA","C","O","CB","CG","SD","CE"),
  hydrogens=("H","HA","HB1","HB2","HG1","HG2","HE1","HE2","HE3"))

mse_interpreter = interpreter(
  peptide_expected_patterns + [
    "hA",
    "CB", "1hB", "2hB", "3hB",
    "CG", "1hG", "2hG", "3hG",
    "SE",
    "CE", "1hE", "2hE", "3hE"],
  peptide_synonym_patterns + {"SED": "SE"},
  mutually_exclusive_pairs=[
    ("1hB", "2hB", "3hB"),
    ("1hG", "2hG", "3hG")],
  non_hydrogens=("N","CA","C","O","CB","CG","SE","CE"),
  hydrogens=("H","HA","HB1","HB2","HG1","HG2","HE1","HE2","HE3"))

pro_interpreter = interpreter(
  peptide_expected_patterns + [
    "hA",
    "CB", "1hB", "2hB", "3hB",
    "CG", "1hG", "2hG", "3hG",
    "CD", "1hD", "2hD", "3hD"],
  peptide_synonym_patterns,
  mutually_exclusive_pairs=[
    ("1hB", "2hB", "3hB"),
    ("1hG", "2hG", "3hG"),
    ("1hD", "2hD", "3hD")],
  non_hydrogens=("N","CA","C","O","CB","CG","CD"),
  hydrogens=("HA","HB1","HB2","HG1","HG2","HD1","HD2"))

phe_interpreter = interpreter(
  peptide_expected_patterns + [
    "hA",
    "CB", "1hB", "2hB", "3hB",
    "CG",
    "CD1", "hD1",
    "CD2", "hD2",
    "CE1", "hE1",
    "CE2", "hE2",
    "CZ", "hZ"],
  peptide_synonym_patterns + {"1hZ": "hZ"},
  mutually_exclusive_pairs=[
    ("1hB", "2hB", "3hB")],
  non_hydrogens=("N","CA","C","O","CB","CG","CD1","CE1","CZ","CE2","CD2"),
  hydrogens=("H","HA","HB1","HB2","HD1","HE1","HZ","HE2","HD2"))

trp_interpreter = interpreter(
  peptide_expected_patterns + [
    "hA",
    "CB", "1hB", "2hB", "3hB",
    "CG",
    "CD1", "hD1",
    "CD2",
    "NE1", "hE1",
    "CE2",
    "CE3", "hE3",
    "CZ2", "hZ2",
    "CZ3", "hZ3",
    "CH2", "hH2"],
  peptide_synonym_patterns,
  mutually_exclusive_pairs=[
    ("1hB", "2hB", "3hB")],
  non_hydrogens=("N","CA","C","O","CB","CG","CD1","CD2","NE1","CE2","CE3","CZ2",
    "CZ3","CH2"),
  hydrogens=("H","HA","HB2","HB3","HD1","HE1","HE3","HZ2","HZ3","HH2"))

ser_interpreter = interpreter(
  peptide_expected_patterns + [
    "hA",
    "CB", "1hB", "2hB", "3hB",
    "OG", "hG"],
  peptide_synonym_patterns,
  mutually_exclusive_pairs=[
    ("1hB", "2hB", "3hB")],
  non_hydrogens=("N","CA","C","O","CB","OG"),
  hydrogens=("H","HA","HB1","HB2","HG"))

thr_interpreter = interpreter(
  peptide_expected_patterns + [
    "hA",
    "CB", "hB",
    "OG1", "hG1",
    "CG2", "1hG2", "2hG2", "3hG2"],
  peptide_synonym_patterns,
  non_hydrogens=("N","CA","C","O","CB","OG1","CG2"),
  hydrogens=("H","HA","HB","HG1","HG21","HG22","HG23"))

asn_interpreter = interpreter(
  peptide_expected_patterns + [
    "hA",
    "CB", "1hB", "2hB", "3hB",
    "CG",
    "OD1",
    "ND2", "1hD2", "2hD2"],
  peptide_synonym_patterns,
  mutually_exclusive_pairs=[
    ("1hB", "2hB", "3hB")],
  non_hydrogens=("N","CA","C","O","CB","CG","OD1","ND2"),
  hydrogens=("H","HA","HB1","HB2","HD21","HD22"))

gln_interpreter = interpreter(
  peptide_expected_patterns + [
    "hA",
    "CB", "1hB", "2hB", "3hB",
    "CG", "1hG", "2hG", "3hG",
    "CD",
    "OE1",
    "NE2", "1hE2", "2hE2"],
  peptide_synonym_patterns,
  mutually_exclusive_pairs=[
    ("1hB", "2hB", "3hB"),
    ("1hG", "2hG", "3hG")],
  non_hydrogens=("N","CA","C","O","CB","CG","CD","OE1","NE2"),
  hydrogens=("H","HA","HB1","HB2","HG1","HG2","HE21","HE22"))

tyr_interpreter = interpreter(
  peptide_expected_patterns + [
    "hA",
    "CB",
    "1hB", # needs to be commented for v3
    "2hB", "3hB",
    "CG",
    "CD1", "hD1",
    "CD2", "hD2",
    "CE1", "hE1",
    "CE2", "hE2",
    "CZ",
    "OH", "hH"],
  peptide_synonym_patterns,
  # needs to be commented for v3
  mutually_exclusive_pairs=[
    ("1hB", "2hB", "3hB")],
  non_hydrogens=("N","CA","C","O","CB","CG","CD1","CE1","CZ","OH","CE2","CD2"),
  hydrogens=("H","HA","HB1","HB2","HD1","HE1","HH","HE2","HD2"))

cys_interpreter = interpreter(
  peptide_expected_patterns + [
    "hA",
    "CB", "1hB", "2hB", "3hB",
    "SG", "hG"],
  peptide_synonym_patterns + {"1hG": "hG"},
  mutually_exclusive_pairs=[
    ("1hB", "2hB", "3hB")],
  non_hydrogens=("N","CA","C","O","CB","SG"),
  hydrogens=("H","HA","HB1","HB2","HG"))

lys_interpreter = interpreter(
  peptide_expected_patterns + [
    "hA",
    "CB", "1hB", "2hB", "3hB",
    "CG", "1hG", "2hG", "3hG",
    "CD", "1hD", "2hD", "3hD",
    "CE", "1hE", "2hE", "3hE",
    "NZ", "1hZ", "2hZ", "3hZ"],
  peptide_synonym_patterns,
  mutually_exclusive_pairs=[
    ("1hB", "2hB", "3hB"),
    ("1hG", "2hG", "3hG"),
    ("1hD", "2hD", "3hD"),
    ("1hE", "2hE", "3hE")],
  non_hydrogens=("N","CA","C","O","CB","CG","CD","CE","NZ"),
  hydrogens=("H","HA","HB1","HB2","HG1","HG2","HD1","HD2","HE1","HE2","HZ1",
    "HZ2","HZ3"))

arg_interpreter = interpreter(
  peptide_expected_patterns + [
    "hA",
    "CB", "1hB", "2hB", "3hB",
    "CG", "1hG", "2hG", "3hG",
    "CD", "1hD", "2hD", "3hD",
    "NE", "hE",
    "CZ",
    "NH1", "1hH1", "2hH1",
    "NH2", "1hH2", "2hH2",
    ],
  peptide_synonym_patterns,
  mutually_exclusive_pairs=[
    ("1hB", "2hB", "3hB"),
    ("1hG", "2hG", "3hG"),
    ("1hD", "2hD", "3hD")],
  non_hydrogens=("N","CA","C","O","CB","CG","CD","NE","CZ","NH1","NH2"),
  hydrogens=("H","HA","HB1","HB2","HG1","HG2","HD1","HD2","HE","HH11","HH12",
    "HH21","HH22"))

his_interpreter = interpreter(
  peptide_expected_patterns + [
    "hA",
    "CB", "1hB", "2hB", "3hB",
    "CG",
    "ND1", "hD1",
    "CD2", "hD2",
    "CE1", "hE1",
    "NE2", "hE2"],
  peptide_synonym_patterns,
  mutually_exclusive_pairs=[
    ("1hB", "2hB", "3hB")],
  non_hydrogens=("N","CA","C","O","CB","CG","ND1","CE1","NE2","CD2"),
  hydrogens=("H","HA","HB1","HB2","HD1","HE1","HE2","HD2"))

asp_interpreter = interpreter(
  peptide_expected_patterns + [
    "hA",
    "CB", "1hB", "2hB", "3hB",
    "CG",
    "OD1", "hD1",
    "OD2", "hD2"],
  peptide_synonym_patterns,
  mutually_exclusive_pairs=[
    ("1hB", "2hB", "3hB"),
    ("hD1", "hD2", "hD2")],
  non_hydrogens=("N","CA","C","O","CB","CG","OD1","OD2"),
  hydrogens=("H","HA","HB1","HB2"))

glu_interpreter = interpreter(
  peptide_expected_patterns + [
    "hA",
    "CB", "1hB", "2hB", "3hB",
    "CG", "1hG", "2hG", "3hG",
    "CD",
    "OE1", "hE1",
    "OE2", "hE2"],
  peptide_synonym_patterns,
  mutually_exclusive_pairs=[
    ("1hB", "2hB", "3hB"),
    ("1hG", "2hG", "3hG")],
  non_hydrogens=("N","CA","C","O","CB","CG","CD","OE1","OE2"),
  hydrogens=("H","HA","HB1","HB2","HG1","HG2"))

interpreters = {
  "GLY": gly_interpreter,
  "ALA": ala_interpreter,
  "VAL": val_interpreter,
  "LEU": leu_interpreter,
  "ILE": ile_interpreter,
  "MET": met_interpreter,
  "MSE": mse_interpreter,
  "PRO": pro_interpreter,
  "PHE": phe_interpreter,
  "TRP": trp_interpreter,
  "SER": ser_interpreter,
  "THR": thr_interpreter,
  "ASN": asn_interpreter,
  "GLN": gln_interpreter,
  "TYR": tyr_interpreter,
  "CYS": cys_interpreter,
  "LYS": lys_interpreter,
  "ARG": arg_interpreter,
  "HIS": his_interpreter,
  "ASP": asp_interpreter,
  "GLU": glu_interpreter,
}


 *******************************************************************************


 *******************************************************************************
iotbx/pdb/atom_selection.py
"""
Tools for creating atom selection arrays (flex.bool or flex.size_t) based on
a simple keyword syntax and boolean operators.
"""

from __future__ import absolute_import, division, print_function
from iotbx import simple_parser
from iotbx import wildcard
from cctbx import crystal
from scitbx.array_family import flex
from scitbx import stl
import scitbx.stl.map
from libtbx.phil import tokenizer
from libtbx.utils import Sorry, format_exception
from libtbx import slots_getstate_setstate
from mmtbx.ncs.ncs_search import get_chains_info
from six.moves import range
from iotbx.pdb.hybrid_36 import hy36encode

abc="abcdefghijklmnopqrstuvwxyz"
ABC="ABCDEFGHIJKLMNOPQRSTUVWXYZ"

def _character_case_id(strings):
  have_upper = False
  have_lower = False
  for s in strings:
    for c in s:
      if   (c in ABC):
        if (have_lower): return 0
        have_upper = True
      elif (c in abc):
        if (have_upper): return 0
        have_lower = True
  if (have_upper): return 1
  if (have_lower): return -1
  return 0

def long_int_to_str(number):
  # if short, no need to transform
  if len(number) <=4:
    return number
  # make sure we deal with actual number
  for c in number:
    if c not in '0123456789':
      return number
  try:
    number_int = int(number)
  except Exception:
    return number
  if number_int < 0:
    return number
  return hy36encode(4, int(number_int))

def _get_map_string(
      map,
      pattern,
      wildcard_escape_char='\\',
      unconditionally_case_insensitive=True):
  pattern_was_quoted = True
  if (not isinstance(pattern, str)):
    if (pattern.quote_token is None):
      pattern_was_quoted = False
    pattern = pattern.value
    if (not pattern_was_quoted): pattern = pattern.strip()
    if (unconditionally_case_insensitive): pattern = pattern.upper()
  result = []
  def match():
    for key,value in map.items():
      if (not pattern_was_quoted): key = key.strip()
      if (unconditionally_case_insensitive): key = key.upper()
      if (wildcard.is_match(
            string=key,
            pattern=pattern,
            escape_char=wildcard_escape_char)):
        result.append(value)
  match()
  if (    len(result) == 0
      and not pattern_was_quoted
      and not unconditionally_case_insensitive
      and _character_case_id(strings=[pattern]) != 0):
    keys_case_id = _character_case_id(strings=map.keys())
    if (keys_case_id != 0):
      if (keys_case_id > 0):
        pattern = pattern.upper()
      else:
        pattern = pattern.lower()
      match()
  return result

def _get_serial_range(sel_keyword, map, start, stop):
  from iotbx.pdb import utils_base_256_ordinal as o
  o_start = None
  o_stop = None
  if (start is not None and start.count(" ") != len(start)):
    o_start = o(long_int_to_str(start))
  if (stop is not None and stop.count(" ") != len(stop)):
    o_stop = o(long_int_to_str(stop))
  if (    o_start is not None
      and o_stop is not None
      and o_start > o_stop):
    raise RuntimeError(
      "range with first index > last index: %s %s:%s" % (
        sel_keyword, start, stop))
  result = []
  for s,iselection in map.items():
    os = o(s)
    if (o_start is not None and os < o_start): continue
    if (o_stop  is not None and os > o_stop): continue
    result.append(iselection)
  return result

class selection_tokenizer(tokenizer.word_iterator):

  def __init__(self, string, contiguous_word_characters=None):
    if (contiguous_word_characters is None):
      contiguous_word_characters \
        = tokenizer.default_contiguous_word_characters \
        + r"\*?[]^+-.:"
    tokenizer.word_iterator.__init__(self,
      input_string=string,
      list_of_settings=[tokenizer.settings(
        contiguous_word_characters=contiguous_word_characters)])

  def pop_argument(self, keyword):
    word = self.try_pop()
    if (word is None): raise RuntimeError("Missing argument for %s." % keyword)
    return word

def has_icode(s):
  # Distinguish '773A' (residue 773, icode A) from 'A13L' (residue 11425)
  #  and from 'A13LC' (residue 11425 with icode C).
  s=s[:]
  s=s.replace(" ","")

  if len(s[:4])==4 and not s[0] in "0123456789": # this is hybrid-36
    if len(s)>4 and s[-1] in ABC:
      # hybrid 36 and length >4 and ends with letter :icode
      return True
    else:
      return False
  else: # not hybrid-36
    if s[-1] in ABC: # if ends with letter : icode
      return True
    else:
      return False

def resid_shift(s):
  # For icode residues keep the icode and do not pad with a space
  if has_icode(s):
    return s
  else:
    return s + " "

class AtomSelectionError(Sorry):
  __orig_module__ = __module__
  __module__ = "exceptions"

class cache(slots_getstate_setstate):
  """
  Manager for interpreting atom selection strings, with caching of partial
  selections.  This has some limited understanding of chemical identities via
  keywords like pepnames, water, or single_atom_residue, but more advanced
  selections require the use of a callback.  In practice this would usually
  involve wrapping the cache in another object, for example the class
  build_all_chain_proxies in mmtbx.monomer_library.pdb_interpretation.

  Because the selections available here are used in some situations where setup
  speed is important, the "within" keyword may optionally be supported if the
  special_position_settings attribute is not None.
  """

  __slots__ = [
    "root",
    "wildcard_escape_char",
    "n_seq",
    "name",
    "altloc",
    "resname",
    "chain_id",
    "resseq",
    "icode",
    "resid",
    "resid_list",
    "chain_break_list",
    "segid",
    "model_id",
    "element",
    "charge",
    "anisou",
    "pepnames",
    "protein",
    "nucleotide",
    "single_atom_residue",
    "water",
    "hetero",
    "backbone",
    "sidechain",
    "special_position_settings"]

  def __init__(self, root, wildcard_escape_char='\\',
      special_position_settings=None):
    self.root = root
    self.wildcard_escape_char = wildcard_escape_char
    root.get_atom_selection_cache(self)
    self.pepnames = None
    self.single_atom_residue = None
    self.protein = None
    self.nucleotide = None
    self.water = None
    self.hetero = None
    self.backbone = None
    self.sidechain = None
    self.special_position_settings = special_position_settings

  def get_name(self, pattern):
    return _get_map_string(
      map=self.name,
      pattern=pattern,
      wildcard_escape_char=self.wildcard_escape_char)

  def get_altloc(self, pattern):
    return _get_map_string(
      map=self.altloc,
      pattern=pattern,
      wildcard_escape_char=self.wildcard_escape_char,
      unconditionally_case_insensitive=False)

  def get_resname(self, pattern):
    return _get_map_string(
      map=self.resname,
      pattern=pattern,
      wildcard_escape_char=self.wildcard_escape_char)

  def get_chain_id(self, pattern):
    return _get_map_string(
      map=self.chain_id,
      pattern=pattern,
      wildcard_escape_char=self.wildcard_escape_char,
      unconditionally_case_insensitive=False)

  def get_resseq(self, pattern):
    pattern.value = long_int_to_str(pattern.value)
    return _get_map_string(
      map=self.resseq,
      pattern=pattern,
      wildcard_escape_char=self.wildcard_escape_char)

  def get_resseq_range(self, start, stop):
    return _get_serial_range(
      sel_keyword="resseq", map=self.resseq, start=start, stop=stop)

  def get_icode(self, pattern):
    return _get_map_string(
      map=self.icode,
      pattern=pattern,
      wildcard_escape_char=self.wildcard_escape_char)

  def get_resid(self, pattern):
    res = _get_map_string(
      map=self.resid,
      pattern=pattern,
      wildcard_escape_char=self.wildcard_escape_char)
    return res

  def get_resid_range(self, start, stop):
    from iotbx.pdb import utils_base_256_ordinal as o
    o_start = None
    o_stop = None
    if (start is not None and start.count(" ") != len(start)):
      o_start = o(resid_shift(start))
    if (stop is not None and stop.count(" ") != len(stop)):
      o_stop = o(resid_shift(stop))
    if (    o_start is not None
        and o_stop is not None
        and o_start > o_stop):
      raise RuntimeError(
        "range with first index > last index: resid %s:%s" % (start, stop))
    result = []
    for s,iselection in self.resid.items():
      os = o(s)
      if (o_start is not None and os < o_start): continue
      if (o_stop  is not None and os > o_stop): continue
      result.append(iselection)
    return result

  def get_resid_sequence(self, start, stop):
    assert (not None in [start, stop])
    import iotbx.pdb.hierarchy
    result = iotbx.pdb.hierarchy.get_resid_sequence(
      resid_list=self.resid_list,
      chain_break_list=self.chain_break_list,
      start=resid_shift(start),
      stop=resid_shift(stop))
    return [result]

  def get_segid(self, pattern):
    return _get_map_string(
      map=self.segid,
      pattern=pattern,
      wildcard_escape_char=self.wildcard_escape_char)

  def get_model_id(self, pattern):
    return _get_map_string(
      map=self.model_id,
      pattern=pattern,
      wildcard_escape_char=self.wildcard_escape_char)

  def get_model_id_range(self, start, stop):
    return _get_serial_range(
      sel_keyword="model", map=self.model_id, start=start, stop=stop)

  def get_element(self, pattern):
    return _get_map_string(
      map=self.element,
      pattern=pattern,
      wildcard_escape_char=self.wildcard_escape_char)

  def get_charge(self, pattern):
    return _get_map_string(
      map=self.charge,
      pattern=pattern,
      wildcard_escape_char=self.wildcard_escape_char)

  def get_anisou(self):
    return [self.anisou]

  def get_water(self):
    if (self.water is None):
      import iotbx.pdb
      get_class = iotbx.pdb.common_residue_names_get_class
      atoms = self.root.atoms()
      sentinel = atoms.reset_tmp(first_value=0, increment=0)
      for model in self.root.models():
        for chain in model.chains():
          for conformer in chain.conformers():
            for residue in conformer.residues():
              if(get_class(name = residue.resname) == "common_water"):
                for atom in residue.atoms():
                  atom.tmp = 1
      self.water = (atoms.extract_tmp_as_size_t() == 1).iselection()
    return [self.water]

  def get_protein(self):
    if self.protein is None:
      import iotbx.pdb
      get_class = iotbx.pdb.common_residue_names_get_class
      atoms = self.root.atoms()
      sentinel = atoms.reset_tmp(first_value=0, increment=0)
      for model in self.root.models():
        for chain in model.chains():
          for conformer in chain.conformers():
            for residue in conformer.residues():
              cl = get_class(name = residue.resname)
              if cl == "common_amino_acid" or cl == "modified_amino_acid":
                for atom in residue.atoms():
                  atom.tmp = 1
      self.protein = (atoms.extract_tmp_as_size_t() == 1).iselection()
    return [self.protein]

  def get_nucleotide(self):
    if self.nucleotide is None:
      import iotbx.pdb
      get_class = iotbx.pdb.common_residue_names_get_class
      atoms = self.root.atoms()
      sentinel = atoms.reset_tmp(first_value=0, increment=0)
      for model in self.root.models():
        for chain in model.chains():
          for conformer in chain.conformers():
            for residue in conformer.residues():
              cl = get_class(name = residue.resname)
              if cl == "common_rna_dna" or cl == "modified_rna_dna":
                for atom in residue.atoms():
                  atom.tmp = 1
      self.nucleotide = (atoms.extract_tmp_as_size_t() == 1).iselection()
    return [self.nucleotide]

  def get_hetero(self):
    if (self.hetero is None):
      atoms = self.root.atoms()
      self.hetero = atoms.extract_hetero()
    return [self.hetero]

  def get_pepnames(self):
    if (self.pepnames is None):
      import iotbx.pdb
      get_class = iotbx.pdb.common_residue_names_get_class
      n_ca_c_o = set([" N  ", " CA ", " C  ", " O  "])
      atoms = self.root.atoms()
      sentinel = atoms.reset_tmp(first_value=0, increment=0)
      for model in self.root.models():
        for chain in model.chains():
          for conformer in chain.conformers():
            for residue in conformer.residues():
              if(get_class(name = residue.resname) == "common_amino_acid"):
                for atom in residue.atoms():
                  atom.tmp = 1
              elif(residue.resname.strip() != "CA"):
                ca = residue.find_atom_by(name=" CA ")
                if (ca is not None):
                  if (residue.atoms_size() == 1):
                    ca.tmp = 1
                  else:
                    residue_atoms = residue.atoms()
                    if (n_ca_c_o.issubset(set([atom.name
                          for atom in residue_atoms]))):
                      for atom in residue_atoms:
                        atom.tmp = 1
      self.pepnames = (atoms.extract_tmp_as_size_t() == 1).iselection()
    return [self.pepnames]

  def get_single_atom_residue(self):
    if (self.single_atom_residue is None):
      atoms = self.root.atoms()
      sentinel = atoms.reset_tmp(first_value=0, increment=0)
      for model in self.root.models():
        for chain in model.chains():
          for rg in chain.residue_groups():
            for cf in rg.conformers():
              for res in cf.residues():
                if (res.atoms_size() == 1):
                  res.atoms()[0].tmp = 1
      self.single_atom_residue = (
        atoms.extract_tmp_as_size_t() == 1).iselection()
    return [self.single_atom_residue]

  def get_bfactor(self, op, value):
    assert (op in [">", "<", "="])
    atoms = self.root.atoms()
    b_iso = atoms.extract_b()
    selection = None
    if (op == ">"):
      selection = b_iso > value
    elif (op == "<"):
      selection = b_iso < value
    elif (op == "="):
      selection = b_iso == value
    return [ selection.iselection() ]

  def get_occupancy(self, op, value):
    assert (op in [">", "<", "="])
    atoms = self.root.atoms()
    occ = atoms.extract_occ()
    selection = None
    if (op == ">"):
      selection = occ > value
    elif (op == "<"):
      selection = occ < value
    elif (op == "="):
      selection = occ == value
    return [ selection.iselection() ]

  def union(self, iselections):
    return flex.union(
      size=self.n_seq,
      iselections=iselections)

  def intersection(self, iselections):
    return flex.intersection(
      size=self.n_seq,
      iselections=iselections)

  def sel_name(self, pattern):
    return self.union(iselections=self.get_name(pattern=pattern))

  def sel_altloc(self, pattern):
    return self.union(iselections=self.get_altloc(pattern=pattern))

  def sel_resname(self, pattern):
    return self.union(iselections=self.get_resname(pattern=pattern))

  def sel_chain_id(self, pattern):
    return self.union(iselections=self.get_chain_id(pattern=pattern))

  def sel_resseq(self, pattern):
    return self.union(iselections=self.get_resseq(pattern=pattern))

  def sel_resseq_range(self, start, stop):
    return self.union(iselections=self.get_resseq_range(start=start,stop=stop))

  def sel_icode(self, pattern):
    return self.union(iselections=self.get_icode(pattern=pattern))

  def sel_resid(self, pattern):
    return self.union(iselections=self.get_resid(pattern=pattern))

  def sel_resid_range(self, start, stop):
    return self.union(iselections=self.get_resid_range(start=start,stop=stop))

  def sel_resid_sequence(self, start, stop):
    return self.union(iselections=self.get_resid_sequence(start=start,
      stop=stop))

  def sel_segid(self, pattern):
    return self.union(iselections=self.get_segid(pattern=pattern))

  def sel_model_id(self, pattern):
    return self.union(iselections=self.get_model_id(pattern=pattern))

  def sel_model_id_range(self, start, stop):
    return self.union(iselections=self.get_model_id_range(
      start=start,stop=stop))

  def sel_element(self, pattern):
    return self.union(iselections=self.get_element(pattern=pattern))

  def sel_charge(self, pattern):
    return self.union(iselections=self.get_charge(pattern=pattern))

  def sel_anisou(self):
    return self.union(iselections=self.get_anisou())

  def sel_pepnames(self):
    return self.union(iselections=self.get_pepnames())

  def sel_single_atom_residue(self):
    return self.union(iselections=self.get_single_atom_residue())

  def sel_protein(self):
    return self.union(iselections=self.get_protein())

  def sel_nucleotide(self):
    return self.union(iselections=self.get_nucleotide())

  def sel_water(self):
    return self.union(iselections=self.get_water())

  def sel_hetero(self):
    return self.union(iselections=self.get_hetero())

  def sel_bfactor(self, op, value):
    return self.union(iselections=self.get_bfactor(op, value))

  def sel_occupancy(self, op, value):
    return self.union(iselections=self.get_occupancy(op, value))

  def sel_within(self, radius, primary_selection):
    assert radius > 0
    assert self.special_position_settings is not None
    return crystal.neighbors_fast_pair_generator(
      asu_mappings=self.special_position_settings.asu_mappings(
        buffer_thickness=radius,
        sites_cart=self.root.atoms().extract_xyz()),
      distance_cutoff=radius).neighbors_of(
        primary_selection=primary_selection)

  def sel_residues_within(self, radius, primary_selection):
    sel_within = self.sel_within(radius, primary_selection)
    atoms = self.root.atoms()
    residue_groups = []
    isel = sel_within.iselection()
    for sel in isel:
      atom = atoms[sel]
      res_id = atom.parent().parent().id_str()
      if res_id not in residue_groups:
        residue_groups.append(res_id)
        residue_group = atom.parent().parent()
        for at in residue_group.atoms():
          sel_within[at.i_seq] = True
    return sel_within

  def selection_tokenizer(self, string, contiguous_word_characters=None):
    return selection_tokenizer(string, contiguous_word_characters)

  def selection_parser(self,
        word_iterator,
        optional=True,
        callback=None,
        stop_word=None,
        expect_nonmatching_closing_parenthesis=False):
    have_optional = False
    result_stack = []
    for word,word_iterator in simple_parser.infix_as_postfix(
          word_iterator=word_iterator,
          stop_word=stop_word,
          expect_nonmatching_closing_parenthesis
            =expect_nonmatching_closing_parenthesis):
      lword = word.value.lower()
      def raise_syntax_error():
        raise RuntimeError(
          'Atom selection syntax error at word "%s".' % lword)
      if (lword == "optional"):
        if (len(result_stack) != 0):
          raise Sorry('"optional" can appear only at the beginning.')
        if (have_optional):
          raise Sorry('"optional" can appear only once.')
        have_optional = True
      elif (lword == "not"):
        assert len(result_stack) >= 1
        arg = result_stack.pop()
        result_stack.append(~arg)
      elif (lword in ["and", "or"]):
        assert len(result_stack) >= 2
        rhs = result_stack.pop()
        lhs = result_stack.pop()
        if (lword == "and"):
          result_stack.append(lhs & rhs)
        else:
          result_stack.append(lhs | rhs)
      else:
        if (lword == "all"):
          result_stack.append(flex.bool(self.n_seq, True))
        elif (lword == "none"):
          result_stack.append(flex.bool(self.n_seq, False))
        elif (lword == "name"):
          result_stack.append(
            self.sel_name(pattern=word_iterator.pop_argument(word.value)))
        elif (lword in ["altloc", "altid"]):
          result_stack.append(
            self.sel_altloc(pattern=word_iterator.pop_argument(word.value)))
        elif (lword == "resname"):
          result_stack.append(
            self.sel_resname(pattern=word_iterator.pop_argument(word.value)))
        elif (lword == "chain"):
          result_stack.append(
            self.sel_chain_id(pattern=word_iterator.pop_argument(word.value)))
        elif (lword in ["resseq", "resid", "resi", "model"]):
          arg = word_iterator.pop_argument(word.value)
          def try_compose_range():
            def is_cont():
              if (len(arg_cont.value) == 0): return False
              return ("0123456789".find(arg_cont.value[0]) >= 0)
            i_colon = arg.value.find(":")
            if (i_colon < 0):
              arg_cont = word_iterator.try_pop()
              if (arg_cont is None):
                return arg.value, -1
              if (not arg_cont.value.startswith(":")):
                word_iterator.backup()
                return arg.value, -1
              if (len(arg_cont.value) == 1):
                arg_cont = word_iterator.try_pop()
                if (arg_cont is None):
                  return arg.value+":", len(arg.value)
                if (not is_cont()):
                  word_iterator.backup()
                  return arg.value+":", len(arg.value)
                return arg.value+":"+arg_cont.value, len(arg.value)
              return arg.value+arg_cont.value, len(arg.value)
            elif (i_colon+1 == len(arg.value)):
              arg_cont = word_iterator.try_pop()
              if (arg_cont is not None):
                if (is_cont()):
                  return arg.value+arg_cont.value, i_colon
                word_iterator.backup()
            return arg.value, i_colon
          def try_compose_sequence():
            arg_next = word_iterator.try_pop()
            if (arg_next is None):
              word_iterator.backup()
              return None, None
            lnext = arg_next.value.lower()
            if (lnext == "through"):
              arg_final = word_iterator.pop_argument(arg_next.value)
              return arg.value, arg_final.value
            word_iterator.backup()
            return (None, None)
          val, i_colon = try_compose_range()
          if (i_colon < 0):
            # processing absence of colon, i.e. single residue/model or range with "through"
            if (lword == "resseq"):
              # "resseq 6", does not support "through"
              result_stack.append(self.sel_resseq(pattern=arg))
            elif (lword in ["resid", "resi"]):
              start, stop = try_compose_sequence()
              if (start is None):
                # "resid 6"
                result_stack.append(self.sel_resid(pattern=arg))
              else :
                # resid 5 through 6"
                result_stack.append(self.sel_resid_sequence(start=start,
                  stop=stop))
            else:
              result_stack.append(self.sel_model_id(pattern=arg))
          else:
            # processing colon
            start = val[:i_colon]
            stop = val[i_colon+1:]
            if (lword == "resseq"):
              result_stack.append(
                self.sel_resseq_range(start=start, stop=stop))
            elif (lword in ["resid", "resi"]):
              result_stack.append(
                self.sel_resid_range(start=start, stop=stop))
            else:
              result_stack.append(
                self.sel_model_id_range(start=start, stop=stop))
        elif (lword == "icode"):
          result_stack.append(
            self.sel_icode(pattern=word_iterator.pop_argument(word.value)))
        elif (lword == "segid"):
          result_stack.append(
            self.sel_segid(pattern=word_iterator.pop_argument(word.value)))
        elif (lword == "element"):
          result_stack.append(
            self.sel_element(pattern=word_iterator.pop_argument(word.value)))
        elif (lword == "charge"):
          result_stack.append(
            self.sel_charge(pattern=word_iterator.pop_argument(word.value)))
        elif (lword == "anisou"):
          result_stack.append(self.sel_anisou())
        elif (lword == "pepnames"):
          result_stack.append(self.sel_pepnames())
        elif ((lword == "protein" or lword == "peptide")
            and callback is None):
          # if there is callback, these keywords shoudl be processed there,
          # most likely it is pdb_interpretation
          result_stack.append(self.sel_protein())
        elif lword == "nucleotide" and callback is None:
          result_stack.append(self.sel_nucleotide())
        elif (lword == "single_atom_residue"):
          result_stack.append(self.sel_single_atom_residue())
        elif (lword == "water"):
          result_stack.append(self.sel_water())
        elif (lword == "hetero") or (lword == "hetatm"):
          result_stack.append(self.sel_hetero())
        elif (lword == "bfactor") or (lword == "occupancy"):
          op = word_iterator.pop_argument(word.value).value
          if (not op in [">", "<", "="]):
            raise_syntax_error()
          else :
            arg_next = word_iterator.try_pop()
            lnext = arg_next.value
            try :
              val = float(lnext)
            except ValueError :
              raise_syntax_error()
            else :
              if (lword == "bfactor"):
                result_stack.append(self.sel_bfactor(op, val))
              else :
                result_stack.append(self.sel_occupancy(op, val))
        elif ((lword == "within" or lword=='residues_within') and
              (self.special_position_settings is not None)):
          assert word_iterator.pop().value == "("
          radius = float(word_iterator.pop().value)
          assert word_iterator.pop().value == ","
          sel = self.selection_parser(
            word_iterator=word_iterator,
            callback=callback,
            expect_nonmatching_closing_parenthesis=True)
          if lword=='within':
            result_stack.append(self.sel_within(radius=radius,
                                                primary_selection=sel))
          elif lword=='residues_within':
            result_stack.append(self.sel_residues_within(radius=radius,
                                                         primary_selection=sel))
        elif (callback is not None):
          if (not callback(
                    word=word,
                    word_iterator=word_iterator,
                    result_stack=result_stack)):
            raise_syntax_error()
        else:
          raise_syntax_error()
    if (optional): have_optional = False
    if (len(result_stack) == 0):
      if (have_optional): return None
      return flex.bool(self.n_seq, False)
    selection = result_stack[0]
    for result in result_stack[1:]:
      selection &= result
    if (have_optional and selection.all_eq(False)):
      return None
    return selection

  def selection(self,
        string,
        optional=True,
        contiguous_word_characters=None,
        callback=None):
    """
    Given a selection string, return the corresponding flex.bool selection
    of the same size as root.atoms().
    """
    try:
      return self.selection_parser(
        word_iterator=self.selection_tokenizer(
          string=string,
          contiguous_word_characters=contiguous_word_characters),
        optional=optional,
        callback=callback)
    except (AtomSelectionError, KeyboardInterrupt): raise
    except Exception:
      msg = format_exception().splitlines()
      msg.extend(["Atom selection string leading to error:\n  %s" % string])
      raise AtomSelectionError("\n".join(msg))

  def iselection(self, string, optional=True, contiguous_word_characters=None):
    """
    Given a selection string, return the corresponding flex.size_t array
    specifying atom indices.
    """
    result = self.selection(
      string=string,
      optional=optional,
      contiguous_word_characters=contiguous_word_characters)
    if (result is None):
      return None
    return result.iselection()

  def get_labels(self,
        name=None,
        altloc=None,
        resname=None,
        chain_id=None,
        resseq=None,
        icode=None,
        segid=None,
        model_id=None):
    result = []
    for arg,attr in [(name, self.name),
                     (altloc, self.altloc),
                     (resname, self.resname),
                     (chain_id, self.chain_id),
                     (resseq, self.resseq),
                     (icode, self.icode),
                     (segid, self.segid),
                     (model_id, self.model_id)]:
      if (arg is not None):
        isel = attr.get(arg, None)
        if (isel is not None): result.append(isel)
    return result

  def link_iselections(self, link_record):
    sel_null = stl.vector.unsigned()
    fs = flex.size_t
    return [
                    fs(self.name.get(link_record.name1, sel_null))
      .intersection(fs(self.altloc.get(link_record.altloc1, sel_null)))
      .intersection(fs(self.resname.get(link_record.resname1, sel_null)))
      .intersection(fs(self.chain_id.get(link_record.chain_id1, sel_null)))
      .intersection(fs(self.resseq.get(link_record.resseq1, sel_null)))
      .intersection(fs(self.icode.get(link_record.icode1, sel_null))),
                    fs(self.name.get(link_record.name2, sel_null))
      .intersection(fs(self.altloc.get(link_record.altloc2, sel_null)))
      .intersection(fs(self.resname.get(link_record.resname2, sel_null)))
      .intersection(fs(self.chain_id.get(link_record.chain_id2, sel_null)))
      .intersection(fs(self.resseq.get(link_record.resseq2, sel_null)))
      .intersection(fs(self.icode.get(link_record.icode2, sel_null)))]

def expand_selection_to_entire_atom_groups(selection, pdb_atoms):
  assert not pdb_atoms.extract_i_seq().all_eq(0)
  selection_complete = flex.bool(pdb_atoms.size(), False)
  if (type(selection).__name__ == 'bool'):
    selection = selection.iselection()
  for i_seq in selection :
    atom_group = pdb_atoms[i_seq].parent()
    group_atoms = atom_group.atoms().extract_i_seq()
    selection_complete.set_selected(group_atoms, True)
  return selection_complete

def convert_wildcards_in_chain_id(chain_id):
  chain_id = chain_id.replace("?", r"\?")
  chain_id = chain_id.replace("*", r"\*")
  return chain_id

def chain_is_needed(selection, chain_selections):
  def inside(a,b,x):
    return a <= x <= b
  if len(chain_selections) == 0:
    return False
  result1 = (inside(chain_selections[0][0], chain_selections[-1][-1], selection[0]) or
    inside(chain_selections[0][0], chain_selections[-1][-1], selection[-1]))
  result2 = (inside(selection[0], selection[-1], chain_selections[0][0]) or
    inside(selection[0], selection[-1], chain_selections[-1][-1]))
  return result1 or result2

def selection_string_from_selection(pdb_h,
                                    selection,
                                    chains_info=None,
                                    atom_selection_cache=None):
  """
  !!! if selection contains alternative conformations, the assertion in the
  end will fail. This is to prevent using this function with such selections.
  This limits its application to search NCS only and at the same time asserts
  that found NCS groups don't contain alternative conformations.

  Convert a selection array to a selection string.
  The function tries to minimise the selection string as possible,
  using chain names, resseq ranges and when there is not other option
  residues IDs

  Limitations:
    When pdb_h contains multiple conformations, selection must
    not include residues with alternate locations

  Args:
    pdb_h : iotbx.pdb.hierarchy
    selection (flex.bool or flex.size_t)
    chains_info (dict): values are object containing
      res_name (list of str): list of residues names
      resid (list of str): list of residues sequence number, resid
      atom_names (list of flex.str): per residue atom names
      atom_selection (list of flex.size_t()): per residue atom selections
      chains_atom_number (int): list of number of atoms in each chain

  Returns:
    sel_str (str): atom selection string
  """
  if isinstance(selection,flex.bool): selection = selection.iselection(True)
  if selection.size() == 0: raise Sorry('Empty atom selection')
  # pdb_hierarchy_inp is a hierarchy
  selection_set = set(selection)
  sel_list = []
  # pdb_h.select(selection).write_pdb_file("selected_in.pdb")
  # using chains_info to improve performance
  if not chains_info:
    chains_info = get_chains_info(pdb_h)
  # print "chains_info"
  # for k, v in chains_info.iteritems():
  #   print k, v
  # print "\n\n"
  chain_ids = sorted(chains_info)
  for ch_id in chain_ids:
    # print "chains_info[ch_id].atom_selection", chains_info[ch_id].atom_selection
    # this "unfolds" the atom_selection array which is [[],[],[],[]...] into
    # a set
    if not chain_is_needed(selection, chains_info[ch_id].atom_selection): continue
    a_sel = set(chains_info[ch_id].flat_atom_selection)
    test_set = a_sel.intersection(selection_set)
    if not test_set: continue
    ch_sel = "chain '%s'" % convert_wildcards_in_chain_id(ch_id)
    # Chain should be present, so do all the work.
    # if there is water in chain, specify residues numbers
    water_present = (len(a_sel) != chains_info[ch_id].chains_atom_number)
    complete_ch_not_present = (test_set != a_sel) or water_present
    if bool(chains_info[ch_id].no_altloc):
      no_altloc = chains_info[ch_id].no_altloc
      no_altloc_present = no_altloc.count(False) > 0
    else:
      no_altloc_present = False
    # exclude residues with alternative locations
    complete_ch_not_present |= no_altloc_present
    # print "complete_ch_not_present", complete_ch_not_present
    res_sel = []
    if complete_ch_not_present:
      # collect continuous ranges of residues when possible
      res_len = len(chains_info[ch_id].resid)

      # prev_resid = None
      prev_all_atoms_present = None
      cur_all_atoms_present = None
      atoms_for_dumping = []
      # all_prev_atoms_in_range
      previous_res_selected_atom_names = []
      a_sel = set(chains_info[ch_id].atom_selection[0])
      cur_res_selected_atom_names = get_atom_names_from_test_set(
          a_sel.intersection(selection_set), a_sel, chains_info[ch_id].atom_names[0])
      atoms_in_current_range = cur_res_selected_atom_names
      sequence_was_broken = False

      first_resid = chains_info[ch_id].resid[0]
      last_resid = None
      for i in range(res_len):
        cur_resid = chains_info[ch_id].resid[i]
        # test that all atoms in residue are included in selection
        a_sel = set(chains_info[ch_id].atom_selection[i])
        # print "a_sel", a_sel
        test_set = a_sel.intersection(selection_set)
        # if not bool(test_set): continue
        if len(test_set) == 0:
          # None of residue's atoms are selected
          # print "Breaking 1"
          sequence_was_broken = True
          continue
        if no_altloc_present and not no_altloc[i]:
          # print "Breaking 2"
          sequence_was_broken = True
          continue
        all_atoms_present = (test_set == a_sel)
        if prev_all_atoms_present is None:
          prev_all_atoms_present = cur_all_atoms_present
        else:
          prev_all_atoms_present = cur_all_atoms_present and prev_all_atoms_present
        cur_all_atoms_present = all_atoms_present
        previous_res_selected_atom_names = cur_res_selected_atom_names
        cur_res_selected_atom_names = get_atom_names_from_test_set(
            test_set, a_sel, chains_info[ch_id].atom_names[i])

        # print "all_atoms_present (cur/prev), test_set", chains_info[ch_id].resid[i], cur_all_atoms_present, prev_all_atoms_present, test_set, chains_info[ch_id].atom_names[i]

        # prev_resid = cur_resid
        cur_resid = chains_info[ch_id].resid[i]
        # print "cur_resid", cur_resid

        # new range is needed when previous selection doesn't match current
        # selection.
        # print "cur/prev res_sel", cur_res_selected_atom_names, previous_res_selected_atom_names
        # print "atoms_for_dumping", atoms_for_dumping
        # print "atoms_in_current_range", atoms_in_current_range
        # print "intersecting sets:", set(cur_res_selected_atom_names) ^ set(previous_res_selected_atom_names)
        continue_range = False
        continue_range = ((cur_all_atoms_present and prev_all_atoms_present)
          or (len(set(cur_res_selected_atom_names) ^ set(atoms_in_current_range))==0))
        continue_range &= not chains_info[ch_id].gap_residue[i]
        # print "continue range 1", continue_range
        # residues are consequtive
        continue_range = continue_range and not sequence_was_broken
        # print "continue range 2", continue_range
        if len(atoms_for_dumping) > 0:
          continue_range = continue_range and (
              len(set(atoms_for_dumping)^set(cur_res_selected_atom_names))==0)
        sequence_was_broken = False
        # print "continue range 3", continue_range

        if continue_range:
          # continue range
          # print "Continuing range"
          last_resid = cur_resid
          atoms_in_current_range = list(set(atoms_in_current_range)|set(cur_res_selected_atom_names))
          if not cur_all_atoms_present:
            # all_prev_atoms_in_range |= set(cur_res_selected_atom_names)
            atoms_for_dumping = cur_res_selected_atom_names
        else:
          # dump previous range, start new one
          # print "Dumping range"
          if len(atoms_for_dumping) > 0:
            atoms_sel = get_atom_str(previous_res_selected_atom_names)
          else:
            atoms_sel = "" if prev_all_atoms_present else get_atom_str(previous_res_selected_atom_names)
            if prev_all_atoms_present is None:
              atoms_sel = "" if cur_all_atoms_present else get_atom_str(cur_res_selected_atom_names)
          res_sel = update_res_sel(
              res_sel=res_sel,
              first_resid=first_resid,
              last_resid=last_resid,
              atoms_selection=atoms_sel)
          # print "res_sel", res_sel
          first_resid = cur_resid
          last_resid = cur_resid
          atoms_in_current_range = cur_res_selected_atom_names
          if not cur_all_atoms_present:
            atoms_for_dumping = cur_res_selected_atom_names
          else:
            atoms_for_dumping = []
          prev_all_atoms_present = None

      # print "DUMPING THE LAST RANGE"
      # print "prev_all_atoms_present", prev_all_atoms_present
      atoms_sel = "" if prev_all_atoms_present else get_atom_str(previous_res_selected_atom_names)
      if prev_all_atoms_present or prev_all_atoms_present is None:
        atoms_sel = "" if cur_all_atoms_present else get_atom_str(cur_res_selected_atom_names)
      # print "atoms_sel", atoms_sel
      omit_resids = (first_resid == chains_info[ch_id].resid[0]
          and last_resid == chains_info[ch_id].resid[-1])
      res_sel = update_res_sel(
          res_sel,first_resid,last_resid, atoms_sel, omit_resids)

    s = get_clean_selection_string(ch_sel,res_sel)
    sel_list.append(s)
  # add parenthesis what selection is more than just a chain
  s_l = []
  sel_list.sort()
  for s in sel_list:
    if len(s) > 10:
      s = '(' + s + ')'
    s_l.append(s)
  sel_str = ' or '.join(s_l)
  # This check could take up to ~90% of runtime of this function...
  # Nevertheless, this helps to spot bugs early. So this should remain
  # here, let's say for a year. If no bugs discovered, this could be removed.
  # When ready to remove, don't forget to remove atom_selection_cache
  # parameter as well.
  # Current removal date: Jan 22, 2017
  # Removed on Feb, 7, 2018.
  # if atom_selection_cache is None:
  #   atom_selection_cache = pdb_h.atom_selection_cache()
  # isel = atom_selection_cache.iselection(sel_str)
  # # pdb_h.select(isel).write_pdb_file("selected_string.pdb")
  # # pdb_h.select(selection).write_pdb_file("selected_isel.pdb")
  # assert len(isel) == len(selection), ""+\
  #     "%d (result) != %d (input): conversion to string selects different number of atoms!.\n" \
  #     % (len(isel), len(selection)) +\
  #     "String lead to error: '%s'" % sel_str

  # This hack is implemented to allow a chain be completely in two alternative
  # conformations. Above check would fail. Selections outputted in refinement
  # are incorrect, but underlying iselections are actually correct and refinement
  # should be fine. General solution would be a universal procedure which can
  # handle alternative conformations correctly, but this is time-demanding project.
  # http://phenix-online.org/pipermail/phenixbb/2018-November/024006.html
  if sel_str == '':
    sel_str = "not all"
  return sel_str

def get_atom_str(atom_str):
  if atom_str is not None and len(atom_str) > 0:
    return 'name ' + ' or name '.join(atom_str)
  return ""

def get_atom_names_from_test_set(test_set, a_sel, atom_names):
  t_s = sorted(test_set)
  dx = min(a_sel)
  selected_atoms = [atom_names[x-dx] for x in t_s]
  return selected_atoms


def get_clean_selection_string(ch_sel,res_selection):
  """
  Args:
    ch_sel (str): such as 'chain A'
    res_selection (list of str): such as ['resseq 1:10','resid 27c and name CA']

  Returns:
    s (str): such as 'chain A and (resseq 1:10 or (resid 27c and name CA))'
  """
  if res_selection:
    if len(res_selection) > 1:
      s = ch_sel + ' and (' + ' or '.join(res_selection) + ')'
    else:
      s = ch_sel + ' and ' + res_selection[0]
  else:
    s = ch_sel
  # remove extra spaces
  s = s.replace('  ',' ')
  s = s.replace('  ',' ')
  return s

def update_res_sel(
    res_sel,
    first_resid,
    last_resid,
    atoms_selection="",
    omit_resids=False):
  """ update the residue selection list and markers of continuous section """
  if first_resid is None or last_resid is None:
    return res_sel
  res_seq = ""
  if last_resid != first_resid:
    # if last_resid.strip()[-1].isalpha() or first_resid.strip()[-1].isalpha():
    if True:
      # through works better with insertion codes!!!
      res_seq = 'resid {} through {}'.format(first_resid.strip(),last_resid.strip())
    else:
      res_seq = 'resid {}:{}'.format(first_resid.strip(),last_resid.strip())
  else:
    res_seq = 'resid {}'.format(first_resid.strip())
  if len(atoms_selection) > 0:
    if not omit_resids:
      res_seq = '(%s and (%s))' % (res_seq, atoms_selection)
    else:
      res_seq = '(%s)' % (atoms_selection)
  res_sel.append(res_seq)
  return res_sel


 *******************************************************************************


 *******************************************************************************
iotbx/pdb/cryst1_interpretation.py
"""Interpretation of CRYST1 records from PDB"""
from __future__ import absolute_import, division, print_function
import iotbx.pdb
from cctbx import crystal
from cctbx import sgtbx
from cctbx import uctbx

def is90(angle, eps=0.01):
  return abs(angle-90) < eps

def is120(angle, eps=0.01):
  return abs(angle-120) < eps

def equiv(r,s,t, eps=0.01):
  m = (r+s+t)/3.
  return abs(r-m) < eps and abs(s-m) < eps and abs(t-m) < eps

rhombohedral = {
  "R3": "R 3",
  "H3": "R 3",
  "R-3": "R -3",
  "H-3": "R -3",
  "R32": "R 3 2",
  "H32": "R 3 2",
  "R3M": "R 3 m",
  "H3M": "R 3 m",
  "R3C": "R 3 c",
  "H3C": "R 3 c",
  "R-3M": "R -3 m",
  "H-3M": "R -3 m",
  "R-3C": "R -3 c",
  "H-3C": "R -3 c",
}

short_mono = (
  "P2",
  "P21",
  "C2",
  "A2",
  "B2",
  "I2",
)

special = {
  "A1": "Hall:  P 1 (-x,-1/2*y+1/2*z,1/2*y+1/2*z)",
  "C1211": "Hall:  C 2y (x+1/4,y+1/4,z)",
  "C21": "Hall:  C 2y (x+1/4,y+1/4,z)",
  "I1211": "Hall:  C 2y (x+1/4,y+1/4,-x+z-1/4)",
  "I21": "Hall:  C 2y (x+1/4,y+1/4,-x+z-1/4)",
  "P21212A": "Hall:  P 2 2ab (x+1/4,y+1/4,z)",
  "F422": "Hall:  I 4 2 (1/2*x+1/2*y,-1/2*x+1/2*y,z)",
  "C4212": "Hall:  P 4 2 (1/2*x+1/2*y-1/4,-1/2*x+1/2*y-1/4,z)",
  #
  # from ccp4/lib/data/syminfo.lib 2010-10-29
  "P21212(A)": "Hall:  P 2 2ab (x+1/4,y+1/4,z)",
  "C2221A)": "Hall:  C 2c 2 (x+1/4,y,z)",
  "C222A": "Hall:  C 2 2 (x+1/4,y+1/4,z)",
  "F222A": "Hall:  F 2 2 (x,y,z+1/4)",
  "I222A": "Hall:  I 2 2 (x-1/4,y+1/4,z-1/4)",
  "P42212A": "Hall:  P 4n 2n (x-1/4,y-1/4,z-1/4)",
  "I23A": "Hall:  I 2 2 3 (x+1/4,y+1/4,z+1/4)"
}

_all = {}
for sym in rhombohedral.keys(): _all[sym] = rhombohedral
for sym in short_mono: _all[sym] = short_mono
for sym in special.keys(): _all[sym] = special

class categorize(object):

  def __init__(self, symbol):
    self.symbol = None
    try:
      self.symbol = symbol.strip().replace(" ","").upper()
      self.category = _all[self.symbol]
    except Exception:
      self.category = None

  def get_category(self):
    if (self.category == rhombohedral): return "rhombohedral"
    if (self.category == short_mono): return "short_mono"
    if (self.category == special): return "special"
    return None

  def space_group_info(self, unit_cell=None):
    if (self.symbol is None): return None
    if (self.category is None):
      try: return sgtbx.space_group_info(self.symbol)
      except RuntimeError: return None
    if (isinstance(unit_cell, uctbx.ext.unit_cell)):
      unit_cell = unit_cell.parameters()
    if (self.category == rhombohedral):
      if (unit_cell is None): return None
      (a, b, c, alpha, beta, gamma) = unit_cell
      if (abs(a - b) <= 0.01 and is90(alpha) and is90(beta) and is120(gamma)):
        basis_symbol = "H"
      elif (equiv(a,b,c) and equiv(alpha,beta,gamma)):
        basis_symbol = "R"
      else:
        return None
      return sgtbx.space_group_info(
        rhombohedral[self.symbol] + ":" + basis_symbol)
    if (self.category == short_mono):
      if (unit_cell is None): return None
      Z, T = self.symbol[0], self.symbol[1:]
      (a, b, c, alpha, beta, gamma) = unit_cell
      if (is90(alpha) and is90(gamma)):
        if (Z == "B"): return None
        return sgtbx.space_group_info(Z + " 1 " + T + " 1")
      if (is90(alpha) and is90(beta)):
        if (Z == "C"): return None
        return sgtbx.space_group_info(Z + " 1 1 " + T)
    if (self.category == special):
      return sgtbx.space_group_info(special[self.symbol])
    raise RuntimeError("Programming error (should be unreachable).")

def dummy_unit_cell(abc, abg, sg_symbol):
  def are_dummy_lengths(abc):
    for v in abc:
      if (v not in [0, 1]): return False
    return True
  def are_dummy_angles(abg):
    for v in abg:
      if (v not in [0, 90]): return False
    return True
  dummy_sg = sg_symbol is None or sg_symbol.replace(" ","") == "P1"
  return (    are_dummy_lengths(abc)
          and are_dummy_angles(abg)
          and dummy_sg)

def crystal_symmetry(cryst1_record):
  if (isinstance(cryst1_record, str)):
    cryst1_record = iotbx.pdb.records.cryst1(pdb_str=cryst1_record)
  u = cryst1_record.ucparams
  s = cryst1_record.sgroup
  if (    u is not None
      and len(u) == 6
      and dummy_unit_cell(u[:3], u[3:], s)):
    return crystal.symmetry(
      unit_cell=None,
      space_group_info=None)
  space_group_info = categorize(cryst1_record.sgroup).space_group_info(
    unit_cell=u)
  return crystal.symmetry(unit_cell=u, space_group_info=space_group_info)


 *******************************************************************************


 *******************************************************************************
iotbx/pdb/crystal_symmetry_from_pdb.py
"""Extract crystal symmetry from a PDB file"""
from __future__ import absolute_import, division, print_function
from iotbx.pdb import cryst1_interpretation
from iotbx.cns import pdb_remarks as cns_pdb_remarks
from libtbx import smart_open
from libtbx.utils import detect_binary_file

def extract_from(file_name=None, file=None, monitor_initial=None):
  assert [file_name, file].count(None) == 1
  if (file is None):
    file = smart_open.for_reading(file_name=file_name)
  lines = file.readlines()
  file.close()
  detect_binary = detect_binary_file(monitor_initial=monitor_initial)
  line_number = 0
  for line in lines:
    line_number += 1
    if (detect_binary is not None):
      is_binary = detect_binary.is_binary_file(block=line)
      if (is_binary is not None):
        if (is_binary): break
        detect_binary = None
    if (line.startswith("CRYST1")):
      return cryst1_interpretation.crystal_symmetry(
        cryst1_record=line)
    crystal_symmetry = cns_pdb_remarks.extract_symmetry(
      pdb_record=line)
    if (crystal_symmetry is not None):
      return crystal_symmetry
  raise RuntimeError("No CRYST1 record.")


 *******************************************************************************


 *******************************************************************************
iotbx/pdb/download.py
"""Download a file from storage on a server"""
from __future__ import absolute_import, division, print_function

# Storage methods
def no_storage(stream):

  return stream


def memory_storage(stream):

  import cStringIO
  return cStringIO.StringIO( stream.read() )


class named_storage(object):
  """
  Stores data in a given file
  """

  def __init__(self, filename, binary = True):

    self.filename = filename
    self.mode_suffix = "b" if binary else ""


  def __call__(self, stream):

    import shutil

    with open( self.filename, "w" + self.mode_suffix ) as fp:
      shutil.copyfileobj( stream, fp )

    return open( self.filename, "r" + self.mode_suffix )


class persistent_storage(object):
  """
  Stores data in a file that is named as a function of the url
  """

  def __init__(self, namer, binary = True):

    self.namer = namer
    self.mode_suffix = "b" if binary else ""


  def __call__(self, stream):

    filename = self.namer( stream.url )

    import shutil

    with open( filename, "w" + self.mode_suffix ) as fp:
      shutil.copyfileobj( stream, fp )

    return open( filename, "r" + self.mode_suffix )


class temporary_storage(object):
  """
  Stores data in a temporary file
  """

  def __init__(self, binary):

    self.mode = "w+b" if binary else "w+"


  def __call__(self, stream):

    import tempfile
    mytemp = tempfile.TemporaryFile( self.mode )

    import shutil
    shutil.copyfileobj( stream, mytemp )

    mytemp.seek(0)

    return mytemp

# Utility
class coupled_stream(object):
  """
  Couples associated streams so that they could be closed explicitly
  """

  def __init__(self, primary, auxiliaries):

    self.primary = primary
    self.auxiliaries = auxiliaries


  def close(self):

    self.primary.close()

    for stream in self.auxiliaries:
      stream.close()


  def read(self):

    return self.primary.read()


  def readline(self):

    return self.primary.readline()


  def readlines(self):

    return self.primary.readlines()


  def next(self):

    return next(self.primary)


  def __iter__(self):

    return self


  def __repr__(self):

    return "<coupled primary:%r>" % self.primary


# Encodings
class encoding(object):

  @classmethod
  def accept(cls, header):

    return header == cls.keyword


class identity_encoding(encoding):

  keyword = "identity"

  def __init__(self, storage = no_storage):

    self.storage = storage


  def process(self, stream):

    return self.storage( stream = stream )


  @classmethod
  def accept(cls, header):

    return not header or super( identity_encoding, cls ).accept( header = header )


class gzip_encoding(encoding):

  keyword = "gzip"

  def __init__(self, storage = memory_storage):

    self.storage = storage


  def process(self, stream):

    import gzip
    storage = self.storage( stream = stream )

    return coupled_stream(
      primary = gzip.GzipFile( fileobj = storage ),
      auxiliaries = [ storage ],
      )


class deflate_encoding_small(encoding):

  keyword = "deflate"

  def __init__(self, storage = no_storage):

    self.storage = storage


  def process(self, stream):

    storage = self.storage( stream = stream )

    import zlib
    data = zlib.decompress( storage.read() )
    storage.close()

    import cStringIO
    return cStringIO.StringIO( data )


#Exceptions
class DownloadException(Exception):
  """
  Base class
  """


class NotFound(DownloadException):
  """
  HTTP 404
  """


class NotAcceptable(DownloadException):
  """
  HTTP 406
  """


class ServerError(DownloadException):
  """
  HTTP 5XX
  """


class UnexpectedResponse(DownloadException):
  """
  Unexpected response from server
  """


def http_error_to_exception(error):

  if error.code == 404:
    return NotFound()

  elif error.code == 406:
    return NotAcceptable()

  elif 500 <= error.code < 600:
    return ServerError()

  else:
    return UnexpectedResponse( str( error ) )


class urlopener(object):
  """
  Configurable version of openurl function
  """

  def __init__(self, identity = identity_encoding(), extras = [ gzip_encoding() ]):

    self.identity = identity
    self.encoding_for = dict( ( ec.keyword, ec ) for ec in extras )


  def __call__(self, url, data = None):

    from six.moves import urllib

    request = urllib.request.Request(
      url = url,
      data = data,
      headers = {
        "Accept-encoding": ", ".join( self.encoding_for ),
        },
      )

    try:
      stream = urllib.request.urlopen( request )

    except urllib.error.HTTPError as e:
      raise http_error_to_exception( error = e )

    used = stream.info().get( "Content-Encoding" )
    encoding = self.encoding_for.get( used, self.identity )

    if not encoding.accept( header = used ):
      raise UnexpectedResponse("Unknown encoding: %s" % used)

    return encoding.process( stream = stream )


openurl = urlopener()


 *******************************************************************************


 *******************************************************************************
iotbx/pdb/experiment_type.py
"""Class for holding information about experiment method (type)."""
from __future__ import absolute_import, division, print_function

class experiment_type(object):
  """ Class for holding information about experiment method (type).

  It is recorded in EXPDTA field of PDB format and _exptl.method
  of mmCIF format. Additional information:
  https://www.wwpdb.org/documentation/file-format-content/format33/sect2.html#EXPDTA
  https://mmcif.wwpdb.org/dictionaries/mmcif_pdbx_v50.dic/Items/_exptl.method.html
  """

  def __init__(self, lines):
    """
      Initialization

    Args:
        lines (list of lines): list of lines with methods extracted
          from appropriate places
    """
    assert isinstance(lines, list)
    self.lines = []
    for l in lines:
      self.lines.append(l.strip().upper())

  def __repr__(self):
    return "; ".join(self.lines)

  def is_xray(self):
    return "X-RAY DIFFRACTION" in self.lines

  def is_electron_microscopy(self):
    return "ELECTRON MICROSCOPY" in self.lines

  def is_neutron(self):
    return "NEUTRON DIFFRACTION" in self.lines

  def is_join_xn(self):
    return self.is_xray() and self.is_neutron()

  def is_empty(self):
    return len(self.lines) == 0


 *******************************************************************************


 *******************************************************************************
iotbx/pdb/extract_rfactors_resolutions_sigma.py
"""Extract extract rfactors resolutions sigma from reflection file"""
from __future__ import absolute_import, division, print_function
import sys
from libtbx.str_utils import format_value
from libtbx import smart_open

class get_r_rfree_sigma(object):
  def __init__(self, remark_2_and_3_records, file_name):
    self.file_name = file_name
    self.r_work,self.r_free,self.sigma,self.high,self.low = \
      None,None,None,None,None
    self.r_works,self.r_frees,self.sigmas,self.highs,self.lows,\
      self.resolution = [],[],[],[],[],[]
    start_DataUsedInRefinement = False
    start_FitToDataUsedInRefinement = False
    for line in remark_2_and_3_records:
      line = line.strip()
      flds = line.split()
      if(len(flds) == 0): continue
      if(not start_DataUsedInRefinement):
        start_DataUsedInRefinement = self.is_DataUsedInRefinement(line)
      def get_value_at(i):
        if (len(flds) <= i): return None
        try: return float(flds[i])
        except ValueError: return None
      if(start_DataUsedInRefinement and self.is_ResolutionRangeHigh(line)):
        try:
          self.highs.append(float(get_value_at(i=7)))
        except: pass # intentional
      if(start_DataUsedInRefinement and self.is_ResolutionRangeLow(line)):
        try:
          self.lows.append(float(get_value_at(i=7)))
        except: pass # intentional
      if(start_DataUsedInRefinement and self.is_DataCutoffSigma(line)):
        try:
          self.sigmas.append(float(get_value_at(i=6)))
        except: pass # intentional
        try:
          self.sigmas.append(float(get_value_at(i=4)))
        except: pass # intentional
      if(not start_FitToDataUsedInRefinement):
        start_FitToDataUsedInRefinement = \
          self.is_FitToDataUsedInRefinement(line)
      if(start_FitToDataUsedInRefinement and self.is_RValueWorkingSet(line)):
        try: self.r_works.append(float(self.get_value(flds=flds)))
        except: pass # intentional
      if(start_FitToDataUsedInRefinement and self.is_FreeRValue(line)):
        try: self.r_frees.append(float(self.get_value(flds=flds)))
        except: pass # intentional
      if(self.is_Resolution(line)):
        tmp = get_value_at(i=3)
        if (self.resolution is None):
          try: tmp = float(line[22:28])
          except ValueError: pass
        self.resolution.append(tmp)
    if(len(self.r_works)==1): self.r_work = self.r_works[0]
    if(len(self.r_frees)==1): self.r_free = self.r_frees[0]
    if(len(self.sigmas)==1):  self.sigma  = self.sigmas[0]
    if(len(self.highs)==1):   self.high   = self.highs[0]
    if(len(self.lows)==1):    self.low    = self.lows[0]
    if(len(self.resolution)>1 or len(self.resolution)==0): self.resolution = None
    else: self.resolution = self.resolution[0]

  def get_value(self, flds):
    last = flds[-1]
    value = None
    try: value = float(last)
    except ValueError:
      try: value = float(last[1:])
      except ValueError: pass
    return value

  def is_Resolution(self, line):
    r1 = line.startswith("REMARK   2 RESOLUTION")
    r2 = line.endswith("ANGSTROMS") or line.endswith("ANGSTROMS.")
    return r1 and r2

  def is_DataUsedInRefinement(self, line):
    r1 = line.startswith("REMARK   3  DATA USED IN REFINEMENT")
    return r1

  def is_ResolutionRangeHigh(self, line):
    r1 = line.startswith("REMARK   3   RESOLUTION RANGE HIGH")
    return r1

  def is_ResolutionRangeLow(self, line):
    r1 = line.startswith("REMARK   3   RESOLUTION RANGE LOW")
    return r1

  def is_DataCutoffSigma(self, line):
    r1 = line.startswith("REMARK   3   DATA CUTOFF            (SIGMA(F)) :")
    r2 = line.startswith("REMARK   3   MIN(FOBS/SIGMA_FOBS)")
    return r1 or r2

  def is_RValueWorkingSet(self, line):
    r1 = line.startswith("REMARK   3   R VALUE            (WORKING SET) ")
    r2 = line.startswith(
      "REMARK   3   R VALUE          (WORKING SET, NO CUTOFF) ")
    #r3 = line.startswith("REMARK   3   R VALUE     (WORKING + TEST SET)")
    #return r1 or r2 or r3
    return r1 or r2

  def is_FreeRValue(self, line):
    r1 = line.startswith("REMARK   3   FREE R VALUE                     ")
    r2 = line.startswith(
      "REMARK   3   FREE R VALUE                  (NO CUTOFF) ")
    return r1 or r2

  def is_FitToDataUsedInRefinement(self, line):
    r1 = line.startswith("REMARK   3  FIT TO DATA USED IN REFINEMENT")
    r2 = line.startswith("REMARK   3  USING DATA ABOVE SIGMA CUTOFF.")
    r3 = line.startswith(
      "REMARK   3  FIT TO DATA USED IN REFINEMENT (NO CUTOFF).")
    result = r1 or r2 or r3
    return result

  def formatted_string(self):
    result = "%s %s %s %s %s %s %s" % (
      format_value("%6s",self.file_name),
      format_value("%6s",str(self.r_work)),
      format_value("%6s",str(self.r_free)),
      format_value("%6s",str(self.sigma)),
      format_value("%6s",str(self.high)),
      format_value("%6s",str(self.low)),
      format_value("%6s",str(self.resolution)))
    return result

  def show(self, log = None):
    if(log is None): log = sys.stdout
    print(self.formatted_string(), file=log)

def extract_remark_2_and_3_records(file_name, file_lines=None):
  result = []
  if (file_lines is None):
    file_lines = smart_open.for_reading(
      file_name = file_name).read().splitlines()
  else :
    assert (file_name is None)
  for rec in file_lines:
    if(rec.startswith("REMARK   3 ") or rec.startswith("REMARK   2 ")):
      start = True
      result.append(rec)
    else:
      if(rec.startswith("ATOM ") or rec.startswith("HETATM ")): # PDB OK
        break
  return result

def extract(file_name, file_lines=None):
  remarks_2_and_3 = extract_remark_2_and_3_records(file_name=file_name,
    file_lines=file_lines)
  if(len(remarks_2_and_3) == 0):
    return None
  result = get_r_rfree_sigma(
    remark_2_and_3_records = remarks_2_and_3,
    file_name              = file_name)
  return result


 *******************************************************************************


 *******************************************************************************
iotbx/pdb/fetch.py
"""Fetch data from PDB"""
# TODO other PDB sites?
#
# See RCSB documentation at:
# https://www.rcsb.org/pages/download/http
#
# File format  Compression   Example URL
# PDB  uncompressed https://files.rcsb.org/download/4hhb.pdb
# CIF  uncompressed https://files.rcsb.org/download/4hhb.cif
# XML  uncompressed https://files.rcsb.org/download/4hhb.xml
# Data uncompressed https://files.rcsb.org/download/1btn-sf.cif
# CIF  uncompressed https://files.rcsb.org/ligands/download/HEM.cif
#
# PDBe:
# https://www.ebi.ac.uk/pdbe-srv/view/files/2vz8.ent
# https://www.ebi.ac.uk/pdbe-srv/view/files/r2vz8sf.ent
#
# PDBj:
# ftp://ftp.pdbj.org/pub/pdb/data/structures/divided/pdb/vz/pdb2vz8.ent.gz
# ftp://ftp.pdbj.org/pub/pdb/data/structures/divided/structure_factors/vz/r2vz8sf.ent.gz
#
# PDB-REDO
# https://pdb-redo.eu/db/1aba/1aba_final.pdb
# https://pdb-redo.eu/db/1aba/1aba_final.cif

from __future__ import absolute_import, division, print_function
from collections import defaultdict
from libtbx.utils import Sorry, null_out
import libtbx.utils
import libtbx.load_env
from six.moves.urllib.error import HTTPError
import gzip
import re
import os


all_links_dict = {
    'rcsb': {
        'model_pdb': 'https://files.rcsb.org/pub/pdb/data/structures/divided/pdb/{mid_id}/pdb{pdb_id}.ent.gz',
        'model_cif': 'https://files.rcsb.org/pub/pdb/data/structures/divided/mmCIF/{mid_id}/{pdb_id}.cif.gz',
        'sequence': 'https://www.rcsb.org/fasta/entry/{pdb_id}',
        'sf': 'https://files.rcsb.org/download/{pdb_id}-sf.cif.gz',
        'em_map': 'https://files.rcsb.org/pub/emdb/structures/EMD-{emdb_number}/map/emd_{emdb_number}.map.gz',
        'em_half_map_1': 'https://files.rcsb.org/pub/emdb/structures/EMD-{emdb_number}/other/emd_{emdb_number}_half_map_1.map.gz',
        'em_half_map_2': 'https://files.rcsb.org/pub/emdb/structures/EMD-{emdb_number}/other/emd_{emdb_number}_half_map_2.map.gz',
        },
    'pdbe': {
        'model_pdb': 'https://ftp.ebi.ac.uk/pub/databases/pdb/data/structures/divided/pdb/{mid_id}/pdb{pdb_id}.ent.gz',
        'model_cif': 'https://ftp.ebi.ac.uk/pub/databases/pdb/data/structures/divided/mmCIF/{mid_id}/{pdb_id}.cif.gz',
        'sequence': 'https://www.ebi.ac.uk/pdbe/entry/pdb/{pdb_id}/fasta',
        'sf': 'https://www.ebi.ac.uk/pdbe/entry-files/download/r{pdb_id}sf.ent',
        'em_map': 'https://ftp.ebi.ac.uk/pub/databases/emdb/structures/EMD-{emdb_number}/map/emd_{emdb_number}.map.gz',
        'em_half_map_1': 'https://ftp.ebi.ac.uk/pub/databases/emdb/structures/EMD-{emdb_number}/other/emd_{emdb_number}_half_map_1.map.gz',
        'em_half_map_2': 'https://ftp.ebi.ac.uk/pub/databases/emdb/structures/EMD-{emdb_number}/other/emd_{emdb_number}_half_map_2.map.gz',
        },
    'pdbj': {
        'model_pdb': 'https://ftp.pdbj.org/pub/pdb/data/structures/divided/pdb/{mid_id}/pdb{pdb_id}.ent.gz',
        'model_cif': 'https://ftp.pdbj.org/pub/pdb/data/structures/divided/mmCIF/{mid_id}/{pdb_id}.cif.gz',
        'sequence': 'https://pdbj.org/rest/newweb/fetch/file?cat=pdb&type=fasta&id={pdb_id}',
        'sf': 'https://data.pdbjpw1.pdbj.org/pub/pdb/data/structures/divided/structure_factors/{mid_id}/r{pdb_id}sf.ent.gz',
        'em_map': 'https://ftp.pdbj.org/pub/emdb/structures/EMD-{emdb_number}/map/emd_{emdb_number}.map.gz',
        'em_half_map_1': 'https://ftp.pdbj.org/pub/databases/emdb/structures/EMD-{emdb_number}/other/emd_{emdb_number}_half_map_1.map.gz',
        'em_half_map_2': 'https://ftp.pdbj.org/pub/databases/emdb/structures/EMD-{emdb_number}/other/emd_{emdb_number}_half_map_2.map.gz',
        },
    # 'pdb-redo': {
    #     'model_pdb': 'https://pdb-redo.eu/db/{pdb_id}/{pdb_id}_final.pdb',
    #     'model_cif': 'https://pdb-redo.eu/db/{pdb_id}/{pdb_id}_final.cif',
    #     # these are from RCSB because PDB-redo does not have them
    #     'sequence': 'https://www.rcsb.org/fasta/entry/{pdb_id}',
    #     'sf': 'https://files.rcsb.org/download/{pdb_id}-sf.cif',
    #     'map': 'https://files.rcsb.org/pub/emdb/structures/EMD-{emdb_number}/map/emd_{emdb_number}.map.gz',
    #     },
}

def get_link(mirror, entity, pdb_id=None, emdb_number=None, link_templates=all_links_dict):
  assert mirror in link_templates.keys()
  if entity not in link_templates[mirror].keys():
    return None
  if entity.find('map') > 0:
    assert emdb_number
  else:
    assert pdb_id
  mid_pdb_id = pdb_id[1:3]
  return link_templates[mirror][entity].format(mid_id=mid_pdb_id, pdb_id=pdb_id, emdb_number=emdb_number)

def valid_pdb_id(id):
  return len(id) == 4 and re.match("[1-9]{1}[a-zA-Z0-9]{3}", id)

def fetch(id, entity='model_pdb', mirror="rcsb", emdb_number=None, link_templates=all_links_dict):
  """
  Locate and open a data file for the specified PDB ID and format, either in a
  local mirror or online.

  :param id: 4-character PDB ID (e.g. '1hbb')
  :param entity - one of 'model_pdb', 'model_cif', 'sequence', 'sf', 'em_map'
  :param mirror: remote site to use, either rcsb, pdbe, pdbj or pdb-redo

  :returns: a filehandle-like object (with read() method)
  """
  assert entity in ['model_pdb', 'model_cif', 'sequence', 'sf', 'em_map', 'em_half_map_1', 'em_half_map_2']
  assert mirror in ["rcsb", "pdbe", "pdbj"]
  id = id.lower()
  if not valid_pdb_id(id):
    raise Sorry("Invalid pdb id %s. Must be 4 characters, 1st is a number 1-9." % id)

  url = get_link(mirror, entity, pdb_id=id, emdb_number=emdb_number, link_templates=link_templates)
  need_to_decompress = url.split('.')[-1] == 'gz' and entity.find('map') < 0

  try :
    data = libtbx.utils.urlopen(url)
  except HTTPError as e :
    if e.getcode() == 404 or e.getcode() == 403 :
      raise RuntimeError("Couldn't download %s for %s at %s." % (entity, id, url))
    else :
      raise
  if need_to_decompress:
    return gzip.GzipFile(fileobj=data)
  return data

def write_data_to_disc(fname, data):
    with open(fname, "wb") as f:
      f.write(data.read())

def fetch_and_write(id, entity='model_pdb', mirror='rcsb', emdb_number=None, link_templates=all_links_dict, log=None):
  """
  Frontend for fetch(...), writes resulting data to disk.
  """
  try :
    data = fetch(id, entity, mirror=mirror, emdb_number=emdb_number, link_templates=link_templates)
  except RuntimeError as e :
    print(str(e),file=log)
    return None
  if (log is None) : log = null_out()
  default_value = (os.path.join(os.getcwd(), "{}.{}".format(id, format)), "Model")
  file_names_titles = defaultdict(lambda: default_value, {
      "model_pdb":  (os.path.join(os.getcwd(), "{}.pdb".format(id)), "Model in PDB format"),
      "model_cif":  (os.path.join(os.getcwd(), "{}.cif".format(id)), "Model in mmCIF format"),
      "sf":  (os.path.join(os.getcwd(), "{}-sf.cif".format(id)), "Structure factors"),
      "sequence": (os.path.join(os.getcwd(), "{}.fa".format(id)), "Sequence"),
      "em_map": (os.path.join(os.getcwd(), "emd_{}.map.gz".format(emdb_number)), "Cryo-EM map"),
      "em_half_map_1": (os.path.join(os.getcwd(), "emd_{}_half_map_1.map.gz".format(emdb_number)), "Cryo-EM half map 1"),
      "em_half_map_2": (os.path.join(os.getcwd(), "emd_{}_half_map_2.map.gz".format(emdb_number)), "Cryo-EM half map 2"),
  })
  file_name, title = file_names_titles[entity]
  write_data_to_disc(file_name, data)
  print("%s saved to %s" % (title, file_name), file=log)
  return file_name

def get_chemical_components_cif(code, return_none_if_already_present=False):
  assert (code is not None)
  if (len(code) == 0) or (len(code) > 3):
    raise Sorry(("Bad code '%s': PDB residue codes must be at least 1 but no "+
      "more than 3 characters.") % code)
  first_char = code[0].lower()
  code = code.upper()
  chem_comp_cif = libtbx.env.find_in_repositories(
    relative_path="chem_data/chemical_components/%s/data_%s.cif" % (first_char,
      code),
    test=os.path.isfile)
  chem_comp_cif = None
  if (chem_comp_cif is None):
    url = "https://files.rcsb.org/ligands/download/%s.cif" % code
    try :
      data = libtbx.utils.urlopen(url)
    except HTTPError as e :
      if e.getcode() == 404 :
        raise RuntimeError("Couldn't download sequence for %s." % id)
      else :
        raise
    else :
      file_name = "%s.cif" % code
      with open(file_name, "wb") as f:
        f.write(data.read())
      return file_name
  elif (not return_none_if_already_present):
    return chem_comp_cif
  return None



 *******************************************************************************


 *******************************************************************************
iotbx/pdb/forward_compatible_pdb_cif_conversion.py
'''
Methods to convert between a hierarchy object and a forward_compatible_pdb compatible string.
'''

from __future__ import absolute_import, division, print_function

'''
Rationale: Hierarchy object and mmcif representations can contain
  chain ID values with n-characters and residue names with 3 or 5
  characters.  PDB format only allows 2 chars for chain ID and 3 for
  residue names.

Approach: Convert all non-forward_compatible_pdb-compliant chain ID and residue names
  to suitable number of characters and save the conversion information
  as a conversion_info object and as RESNAM records (for residue names)
  and REMARK records (for chain ID) in PDB string representations of
  the hierarchy.

Examples of typical uses:

A. Write a forward_compatible_pdb compatible string with conversion information in REMARK
   and RESNAM records from any hierarchy (ph):
   NOTE: any kw and args for as_pdb_string() can be supplied

  from iotbx.pdb.forward_compatible_pdb_cif_conversion import hierarchy_as_forward_compatible_pdb_string
  forward_compatible_pdb_string =  hierarchy_as_forward_compatible_pdb_string(ph)

B. Read a forward_compatible_pdb compatible string (forward_compatible_pdb_string) with conversion
   information in REMARK/RESNAM records and convert to a hierarchy (
   inverse of A).
   NOTE: same function will read any mmcif string as well.

  from iotbx.pdb.forward_compatible_pdb_cif_conversion import pdb_or_mmcif_string_as_hierarchy
  ph = pdb_or_mmcif_string_as_hierarchy(forward_compatible_pdb_string).hierarchy

C. Get conversion info from any hierarchy (ph):

  from iotbx.pdb.forward_compatible_pdb_cif_conversion \
    import forward_compatible_pdb_cif_conversion
  conversion_info = forward_compatible_pdb_cif_conversion(hierarchy = ph)

D. convert any hierarchy to a forward_compatible one (changes chain.id and
   residue names:
  from iotbx.pdb.forward_compatible_pdb_cif_conversion \
    import forward_compatible_pdb_cif_conversion
  conversion_info = forward_compatible_pdb_cif_conversion(hierarchy = ph)
  conversion_info.convert_hierarchy_to_forward_compatible_pdb_representation(ph)

E. Convert forward compatible pdb back (done in place)
  conversion_info.convert_hierarchy_to_full_representation(ph)

F. TODO: Convert any hierarchy to forward compatible (method of hierarchy):
  ph.convert_to_forward_compatible_pdb()  # saves conversion info as attribute
    # Optionally supply conversion_info
    #  now ph._conversion_info is set

E. Get conversion info from unique chain_ids and residue names (
    unique_values_dict):

  from iotbx.pdb.forward_compatible_pdb_cif_conversion \
     import forward_compatible_pdb_cif_conversion
  conversion_info = forward_compatible_pdb_cif_conversion(
    unique_values_dict = unique_values_dict)

F. Get conversion info as REMARK and RESNAM string

  from iotbx.pdb.forward_compatible_pdb_cif_conversion \
     import forward_compatible_pdb_cif_conversion
  remark_hetnam_string = \
   forward_compatible_pdb_cif_conversion(ph).conversion_as_remark_hetnam_string()

E. Convert a forward_compatible_pdb compatible hierarchy to a full hierarchy
   with conversion information in conversion_info. This approach can be
   used to (1) save conversion information from a hierarchy,
   (2) write a forward_compatible_pdb file, (3) do something with the
     forward_compatible_pdb file that loses
   the header information, (4) read back the forward_compatible_pdb file that
   does not have REMARK records, and (5) restore the original structure in
   the new hierarchy.

  from iotbx.pdb.forward_compatible_pdb_cif_conversion \
    import forward_compatible_pdb_cif_conversion
  from iotbx.pdb.forward_compatible_pdb_cif_conversion \
    import hierarchy_as_forward_compatible_pdb_string
  from iotbx.pdb.forward_compatible_pdb_cif_conversion \
    import pdb_or_mmcif_string_as_hierarchy

  # Get conversion information
  conversion_info = forward_compatible_pdb_cif_conversion(ph)

  # Get a forward_compatible_pdb string with no remarks
  forward_compatible_pdb_string = hierarchy_as_forward_compatible_pdb_string(ph)
  forward_compatible_pdb_string_no_remarks = remove_remarks(
     forward_compatible_pdb_string)

  # convert back to hierarchy (this can be a new pdb string obtained
  #  after manipulations of the model but with residue names and chain id
  #  values matching the forward_compatible_pdb_string)
  ph = pdb_or_mmcif_string_as_hierarchy(
      forward_compatible_pdb_string_no_remarks).hierarchy

  # Apply the conversions to obtain a full representation in ph
  conversion_info.convert_hierarchy_to_full_representation(ph)
  '''

def hierarchy_as_forward_compatible_pdb_string(ph,
      conversion_info = None, *args, **kw):
  '''Convert a hierarchy into a forward_compatible_pdb compatible string,
   with any conversion information written as REMARK records

    parameters:
      ph: hierarchy object
      conversion_info: optional conversion_info object specifying conversion
      args, kw: any args and kw suitable for the hierarchy
          method ph.as_pdb_string()

    returns:  string
  '''

  if not conversion_info:
    conversion_info = forward_compatible_pdb_cif_conversion(hierarchy = ph)

  if (not conversion_info.conversion_required()):
    return ph.as_pdb_string(*args, **kw)
  else:
    ph_forward_compatible_pdb = ph.deep_copy()
    conversion_info.convert_hierarchy_to_forward_compatible_pdb_representation(
       ph_forward_compatible_pdb)
    remark_hetnam_string = conversion_info.conversion_as_remark_hetnam_string()
    forward_compatible_pdb_string = ph_forward_compatible_pdb.as_pdb_string(
       *args, **kw)
    full_string = remark_hetnam_string + forward_compatible_pdb_string
    return full_string

def pdb_or_mmcif_string_as_hierarchy(pdb_or_mmcif_string,
       conversion_info = None):
  '''Convert an mmcif string or a forward_compatible_pdb compatible string
      into a hierarchy object, using any conversion information written as
      REMARK records in the forward_compatible_pdb string, or using any supplied
      conversion information.

    parameters:
      pdb_or_mmcif_string: mmcif string or a forward_compatible_pdb compatible
      string conversion_info: optional forward_compatible_pdb_cif_conversion
      object to apply

    returns: group_args (hierarchy, pdb_inp, crystal_symmetry, conversion_info)
  '''
  import iotbx.pdb
  from iotbx.pdb.forward_compatible_pdb_cif_conversion \
     import forward_compatible_pdb_cif_conversion
  inp = iotbx.pdb.input(lines=pdb_or_mmcif_string, source_info=None)
  remark_hetnam_string = "\n".join(inp.remark_section())
  hetnam_string = "\n".join(inp.heterogen_section())
  remark_hetnam_string += "\n"+ hetnam_string
  crystal_symmetry = inp.crystal_symmetry()

  if (not conversion_info):
    conversion_info = forward_compatible_pdb_cif_conversion()
    conversion_info.set_conversion_tables_from_remark_hetnam_records(
      remark_hetnam_records = remark_hetnam_string.splitlines())
  assert conversion_info.is_initialized()

  # Get the hierarchy
  ph = inp.construct_hierarchy()
  from libtbx import group_args
  result = group_args(
    group_args_type = 'hierarchy and crystal_symmetry from text string',
    hierarchy = ph,
    pdb_inp = inp,
    crystal_symmetry = crystal_symmetry,
    conversion_info = conversion_info)

  # Determine if this is already in full format
  if forward_compatible_pdb_cif_conversion(ph).conversion_required():
    # already set
    assert not conversion_info.conversion_required(), \
      "Cannot apply forward_compatible_pdb conversions to a "+\
       "hierarchy that is not forward_compatible_pdb"
  else:
    conversion_info.convert_hierarchy_to_full_representation(ph)
  return result

def get_unique_values_dict(hierarchy_list):
  #  Get all the unique chain_id and resname values in all hierarchies

  chain_id_list = []
  resname_list = []
  for hierarchy in hierarchy_list:
    for model in hierarchy.models():
      for chain in model.chains():
        if not chain.id in chain_id_list:
          chain_id_list.append(chain.id)
        for residue_group in chain.residue_groups():
          for atom_group in residue_group.atom_groups():
            if not atom_group.resname in resname_list:
              resname_list.append(atom_group.resname)
  unique_values_dict = {
    'chain_id': chain_id_list,
    'resname': resname_list}
  return unique_values_dict

class forward_compatible_pdb_cif_conversion:
  ''' Class to generate and save forward_compatible_pdb representation
    of 5-character residue names and n-character chain IDs. Used to convert
    between forward_compatible_pdb and mmcif formatting.

    NOTE 1: marked as self._is_initialized when values are available
    NOTE 2: hierarchy object that has been converted to
      forward_compatible_pdb compatible will be marked with the attribute
       self._conversion_info, the conversion used.


    To modify these tables to add another field to check:
    1. Add new field to self._keys and self._max_chars_dict
    2. Add new methods like "def _unique_chain_ids_from_hierarchy"
    3. Use these new methods in "def _set_up_conversion_table"
    4. Add code at "Modify hierarchy here to convert to forward_compatible_pdb"
    5. Add at "Modify hierarchy here to convert from forward_compatible_pdb"
    6. Add to regression test at
       iotbx/regression/tst_hierarchy_forward_compatible_pdb.py
    '''

  def __init__(self, hierarchy = None,
     unique_values_dict = None,
     residue_conversion_as_remark = True,
     residue_conversion_as_hetnam = True,
     end_residue_names_with_tilde_if_possible = False,
     ):
    ''' Identify all unique chain_ids and residue names that are not compatible
        with forward_compatible_pdb. Generate dictionary relating original
        names and compatible names and for going backwards.

    parameters:  iotbx.pdb.hierarchy object (required unless unique_values_dict
           is supplied)
        unique_values_dict:  Optional dict with unique values for each key
        residue_conversion_as_remark:   read and write conversion for residue
            name as a REMARK
        residue_conversion_as_hetnam:   read and write conversion for residue
            name as a HETNAM record
        end_residue_names_with_tilde_if_possible:  try to make 3-char residue
                                                    names as 2 chars + "~"

    returns:  None

    '''


    # Fields in hierarchy that are limited in number of characters
    # in forward_compatible_pdb
    self._keys = ['chain_id', 'resname']
    self._max_chars_dict = {'chain_id':2, 'resname':3}
    self._end_with_tilde_dict = {'chain_id':False, 'resname':True}

    if unique_values_dict is not None:
      for key in self._keys:
        assert key in list(unique_values_dict.keys())

    self._remark_keys = ['chain_id']
    self._hetnam_keys = []
    self._residue_conversion_as_remark = residue_conversion_as_remark
    if self._residue_conversion_as_remark:
      self._remark_keys.append('resname')

    self._residue_conversion_as_hetnam = residue_conversion_as_hetnam
    if self._residue_conversion_as_hetnam:
      self._hetnam_keys.append('resname')

    self._is_initialized = False

    if hierarchy is None and unique_values_dict is None:
      self._conversion_table_info_dict = None
      self._conversion_required = None
      return

    # Set up conversion tables
    self._conversion_table_info_dict = {}

    # Flag that indicates if any conversion is necessary
    self._conversion_required = False

    for key in self._keys:
      self._set_up_conversion_table(key, hierarchy,
        unique_values_dict = unique_values_dict)

    self._is_initialized = True

  def is_initialized(self):

    '''Public method to return True if this is initialized
    parameters:  None
    returns: True if initialized
    '''
    return self._is_initialized

  def conversion_required(self):

    '''Public method to return True if conversion for forward_compatible_pdb
     is necessary
    parameters:  None
    returns: True if conversion is necessary
    '''
    assert self.is_initialized(), "Need to initialize"
    return self._conversion_required

  def conversion_as_remark_hetnam_string(self):
    '''Public method to return a PDB REMARK/HETNAM string representing all the
    conversions that are necessary
    '''

    assert self.is_initialized(), "Need to initialize"

    if not self.conversion_required():
      return ""  # No info needed


    from six.moves import cStringIO as StringIO
    f = StringIO()
    print(
      "REMARK 987 PDB_V3_CONVERSION  CONVERSIONS MADE FOR PDB_V3 COMPATIBILITY",
           file = f)

    # Set up conversion info that goes in REMARK records
    for key in self._remark_keys:
      info =  self._conversion_table_info_dict[key]
      if info:
        for full_text, forward_compatible_pdb_text in zip(
           info.full_representation_list,
           info.forward_compatible_pdb_representation_list,
           ):
          print(
            "REMARK 987 PDB_V3_CONVERSION  %s: %s  PDB_V3_TEXT: %s" %(
              key.upper(),
              full_text,
              forward_compatible_pdb_text),
            file = f)
    print(file = f)

    # Set conversion info that goes in HETNAM records
    """
HETNAM
Overview

This record gives the chemical name of the compound with the given hetID.

Record Format

COLUMNS       DATA  TYPE    FIELD           DEFINITION
----------------------------------------------------------------------------
 1 -  6       Record name   "HETNAM"
 9 - 10       Continuation  continuation    Allows concatenation of multiple records.
12 - 14       LString(3)    hetID           Het identifier, right-justified.
16 - 70       String        text            Chemical name.
    """
    for key in self._hetnam_keys:
      info =  self._conversion_table_info_dict[key]
      if info:
        for full_text, forward_compatible_pdb_text in zip(
           info.full_representation_list,
           info.forward_compatible_pdb_representation_list,
           ): # any text for 55 chars
          print("%6s  %2s %3s %55s%10s" %(
              "HETNAM".ljust(6),
              "".ljust(2),  # continuation chars
              forward_compatible_pdb_text.ljust(3),  # 3-char version
              "PDB_V3_CONVERSION (FULL NAME IN COLS 71-80)".ljust(55),
              full_text.ljust(10)),  # full version
            file = f)
    print(file = f)


    return f.getvalue()


  def convert_hierarchy_to_forward_compatible_pdb_representation(self,
      hierarchy):

    '''Public method to convert a hierarchy in place to
     forward_compatible_pdb compatible hierarchy using information
     in self._conversion_table_info_dict
    parameters: hierarchy (modified in place)
    output: None
    Hierarchy is marked with attribute _conversion_info

    '''

    assert self.is_initialized(), "Need to initialize"
    assert hierarchy is not None, "Need hierarchy for conversion"

    if hierarchy.is_forward_compatible_hierarchy():
      return # nothing to do because it was already converted

    if self.conversion_required():

      # Modify hierarchy here to convert to forward_compatible_pdb
      for model in hierarchy.models():
        for chain in model.chains():
          new_id = self.get_forward_compatible_pdb_text_from_full_text(
             key = 'chain_id',
             full_text = chain.id)
          if new_id and new_id != chain.id:
            chain.id = new_id  # Modify chain ID here

          for residue_group in chain.residue_groups():
            for atom_group in residue_group.atom_groups():
              new_resname = self.get_forward_compatible_pdb_text_from_full_text(
                  'resname',
                  atom_group.resname)
              if new_resname and (new_resname != atom_group.resname):
                atom_group.resname = new_resname  # Modify residue name here
    # Mark it
    hierarchy._conversion_info = self

  def convert_hierarchy_to_full_representation(self, hierarchy):
    '''Public method to convert a hierarchy in place from
      forward_compatible_pdb compatible hierarchy back to original
      hierarchy using information in self._conversion_table_info_dict
    parameters: hierarchy (modified in place)
    output: None

    '''
    assert hierarchy is not None, "Need hierarchy for conversion"
    assert self.is_initialized(), "Need to initialize"


    if self.conversion_required():
      # Modify hierarchy here to convert from forward_compatible_pdb

      for model in hierarchy.models():
        for chain in model.chains():
          new_id = self.get_full_text_from_forward_compatible_pdb_text(
            key = 'chain_id',
            forward_compatible_pdb_text = chain.id)
          if new_id and new_id != chain.id:
            chain.id = new_id  # Modify chain_id here

          for residue_group in chain.residue_groups():
            for atom_group in residue_group.atom_groups():
              new_resname = self.get_full_text_from_forward_compatible_pdb_text(
                key = 'resname',
                forward_compatible_pdb_text = atom_group.resname)
              if new_resname and (new_resname != atom_group.resname):
                atom_group.resname = new_resname # Modify residue name here

    if hasattr(hierarchy,'_conversion_info'):
       delattr(hierarchy,'_conversion_info')

  def set_conversion_tables_from_remark_hetnam_records(
       self, remark_hetnam_records, add_to_existing = False):
    ''' Public method to set conversion tables based on remarks and hetnam
        records written in standard form as by this class

    parameters:
      remark_hetnam_records:  list of lines, containing REMARK
                        and HETNAM lines with information
                        conversion_as_remark_hetnam_string
      add_to_existing: do not re-initialize if already initialized
    returns: None
    '''


    if not remark_hetnam_records:
      self._is_initialized = True
      return # nothing to do

    self._conversion_required = False

    if (self._is_initialized and add_to_existing):
      pass # keep existing dicts
    else: # usual...initialize
      full_representation_list_dict = {}
      forward_compatible_pdb_representation_list_dict = {}

      for key in self._keys:
        full_representation_list_dict[key] = []
        forward_compatible_pdb_representation_list_dict[key] = []
    self._is_initialized = True

    for line in remark_hetnam_records:
      if not line: continue
      spl = line.split()
      if (spl[0] == "REMARK") and (spl[1] == "987") and \
           (spl[2] == "PDB_V3_CONVERSION"):
        if len(spl) != 7: continue
        key = spl[3].lower()[:-1] # take off ":"
        if not key in self._remark_keys: continue
        full = spl[4]
        forward_compatible_pdb = spl[6]
      elif self._residue_conversion_as_hetnam and (spl[0] == "HETNAM"):
        key = "resname"
        if not key in self._hetnam_keys: continue
        forward_compatible_pdb = line[11:14].strip()
        full = line[69:80].strip()
        if not forward_compatible_pdb: continue
        if not full: continue
      else:
        continue

      if not full in full_representation_list_dict[key]:
        full_representation_list_dict[key].append(full)
        forward_compatible_pdb_representation_list_dict[key].append(
            forward_compatible_pdb)

      # there was something needing conversion
      self._conversion_required = True

    self._is_initialized = True

    if not self._conversion_required: # nothing to do
      return

    self._conversion_table_info_dict = {}
    from libtbx import group_args
    for key in self._keys:
      self._conversion_table_info_dict[key] = group_args(
        group_args_type = 'conversion tables for %s' %(key),
        full_representation_list = full_representation_list_dict[key],
        forward_compatible_pdb_representation_list = \
            forward_compatible_pdb_representation_list_dict[key])


  def _set_up_conversion_table(self, key, hierarchy, unique_values_dict = None):
    ''' Private method to set up conversion table from a hierarchy for
        field named by key and put it in self._conversion_table_info_dict[key].
        Also set self._conversion_required if conversion is needed.
        also set self._is_initialized'''

    if unique_values_dict is not None:
      unique_values = unique_values_dict[key]  # use supplied values
    elif key == 'chain_id':
      unique_values = self._unique_chain_ids_from_hierarchy(hierarchy)
    elif key == 'resname':
      unique_values = self._unique_resnames_from_hierarchy(hierarchy)
    else:
      raise "NotImplemented"

    end_with_tilde = self._end_with_tilde_dict[key]

    max_chars = self._max_chars_dict[key]
    allowed_ids, ids_needing_conversion = self._choose_allowed_ids(
        unique_values,
        max_chars = max_chars)

    forward_compatible_pdb_representation_list = \
      self._get_any_forward_compatible_pdb_representation(
        ids_needing_conversion, max_chars, exclude_list = allowed_ids,
        end_with_tilde = end_with_tilde)

    if ids_needing_conversion:
      assert len(ids_needing_conversion) == len(
        forward_compatible_pdb_representation_list)

    from libtbx import group_args
    self._conversion_table_info_dict[key] = group_args(
      group_args_type = 'conversion tables for %s' %(key),
      full_representation_list = ids_needing_conversion,
      forward_compatible_pdb_representation_list = \
        forward_compatible_pdb_representation_list)

    if forward_compatible_pdb_representation_list:
      # there was something needing conversion
      self._conversion_required = True

  def _unique_chain_ids_from_hierarchy(self, hierarchy):
    ''' Private method to identify all unique chain IDs in a hierarchy
    parameters:  hierarchy
    returns:  list of unique chain ids

    '''
    chain_ids = []
    for model in hierarchy.models():
      for chain in model.chains():
        if (not chain.id in chain_ids):
          chain_ids.append(chain.id)
    return chain_ids

  def _unique_resnames_from_hierarchy(self, hierarchy):
    ''' Private method to identify all unique residue names in a hierarchy
    parameters:  hierarchy
    returns:  list of unique residue names

    '''
    resnames = []
    for model in hierarchy.models():
      for chain in model.chains():
        for residue_group in chain.residue_groups():
          for atom_group in residue_group.atom_groups():
            if (not atom_group.resname in resnames):
              resnames.append(atom_group.resname)
    return resnames

  def _get_any_forward_compatible_pdb_representation(self,
       ids_needing_conversion,
     max_chars, exclude_list = None,
     end_with_tilde = None):
    '''Private method to try a few ways to generate unique
        forward_compatible_pdb
      representations for a set of strings.  Order to try:
      1. take first max_chars of each.
      2. if end_with_tilde, then generate max_chars-1 of numbers plus tilde,
      3. generate anything up to max_chars
    parameters:
      ids_needing_conversion:  list of strings to convert
      max_chars:  maximum characters in converted strings
      exclude_list: list of strings not to use as output
      end_with_tilde: try to end strings with a tilde ("~")
    returns:
      forward_compatible_pdb_representation_list:
       list of converted strings, same order and
        length as ids_needing_conversion
    '''

    if (not ids_needing_conversion):
       return [] # ok with nothing in it

    # Try just taking first n_chars of strings...ok if they are all unique
    forward_compatible_pdb_representation_list = \
      self._get_forward_compatible_pdb_representation(
        ids_needing_conversion, max_chars, exclude_list = exclude_list,
        take_first_n_chars = True)
    if forward_compatible_pdb_representation_list:
      return forward_compatible_pdb_representation_list

    # Generate unique strings for all the ids needing conversion, preventing
    #   duplications of existing ids
    forward_compatible_pdb_representation_list = \
     self._get_forward_compatible_pdb_representation(
        ids_needing_conversion, max_chars, exclude_list = exclude_list,
        end_with_tilde = end_with_tilde)
    if forward_compatible_pdb_representation_list:
      return forward_compatible_pdb_representation_list

    # Failed to get forward_compatible_pdb representation...
    from libtbx.utils import Sorry
    raise Sorry(
      "Unable to generate forward_compatible_pdb representation of %s" %(key))

  def _get_forward_compatible_pdb_representation(self, ids, max_chars,
      exclude_list = None, take_first_n_chars = False,
      end_with_tilde = None):

    '''Private method to try and get forward_compatible_pdb representation
        of ids that fit in
       max_chars and do not duplicate anything in exclude_list
    parameters:
      ids:  strings to convert
      max_chars:  maximum characters in output
      exclude_list: strings to not include in output
      take_first_n_chars: just take the first max_chars if set
      end_with_tilde: try to end strings with a tilde ("~")

    returns:
      list of converted strings of same order and length as ids, if successful
      otherwise, None
    '''

    forward_compatible_pdb_representation_list = []
    for id in ids:
      if take_first_n_chars:  # Just take the first n_chars
        new_id = id[:max_chars]
        if new_id in exclude_list + forward_compatible_pdb_representation_list:
          return None # cannot do it this way
      else:  # generate a new id
        new_id = self._get_new_unique_id(id, max_chars,
           exclude_list + forward_compatible_pdb_representation_list,
           end_with_tilde = end_with_tilde)
        if not new_id:
          return None # could not do this
      forward_compatible_pdb_representation_list.append(new_id)
    return forward_compatible_pdb_representation_list

  def _get_new_unique_id(self, id, max_chars, exclude_list,
     end_with_tilde):
    ''' Private method to get a unique ID with up to max_chars that is not
    in exclude_list. Start with max_chars and work down and use reverse order
    so as to generally create codes that are unlikely for others to have used.
    Also start with numbers, then numbers and letters, then everything
    '''
    for z in (
        [False, False, True, False],
        [True, False, True, False],
        [True, True, True, False],
        [True, True, True, True],):
      include_upper, include_lower, include_numbers, include_special_chars = z

      if end_with_tilde:
        id = self._get_new_id(max_chars, exclude_list, end_with_tilde = True,
          include_upper = include_upper,
          include_lower = include_lower,
          include_numbers = include_numbers,
          include_special_chars = include_special_chars,)
        if id:
          return id

      for n_chars_inv in range(max_chars):
        n_chars = max_chars - n_chars_inv
        id = self._get_new_id(n_chars, exclude_list,
          include_upper = include_upper,
          include_lower = include_lower,
          include_numbers = include_numbers,
          include_special_chars = include_special_chars,)
        if id:
          return id

  def _get_new_id(self, n_chars, exclude_list, end_with_tilde = None,
      include_upper = True,
      include_lower = True,
      include_numbers = True,
      include_special_chars = True,
       ):
    ''' Private method to get a unique ID with exactly n_chars that is not
    in exclude_list
    '''
    from iotbx.pdb.utils import generate_n_char_string
    x = generate_n_char_string(n_chars = n_chars,
       reverse_order = (not end_with_tilde),
       end_with_tilde = end_with_tilde,
       include_upper = include_upper,
       include_lower = include_lower,
       include_numbers = include_numbers,
       include_special_chars = include_special_chars,
      )
    while 1:
      new_id = x.next()
      if (not new_id):
        return None # failed
      elif (not new_id in exclude_list):
        return new_id

  def _choose_allowed_ids(self, unique_values, max_chars):
    ''' Private method to separate unique_values into those that are and
        are not compatible with forward_compatible_pdb (i.e., have max_chars or fewer)
    '''
    allowed = []
    not_allowed = []
    for u in unique_values:
      if self._is_allowed(u, max_chars):
        allowed.append(u)
      else:
        not_allowed.append(u)
    return allowed, not_allowed

  def _is_allowed(self, u, max_chars):
    ''' Private method to identify whether the string u is or is not
        compatible with forward_compatible_pdb (i.e., has max_chars or fewer)
    '''
    if len(u) <= max_chars:
      return True
    else:
      return False


  def _get_conversion_table_info(self, key):
    ''' Private method to return conversion table info for
        specified key (e.g., chain_id, resname)
    '''

    if not key in self._keys:
      return None
    elif (not self._conversion_required):
      return None
    else:
      return self._conversion_table_info_dict[key]

  def get_full_text_from_forward_compatible_pdb_text(self, key = None,
          forward_compatible_pdb_text = None):
    '''Public method to return full text from forward_compatible_pdb_text
       based on conversion table. Applies to one word.

    parameters:
      key: field to convert (e.g., chain_id, resname)
      forward_compatible_pdb_text: text to convert from
          forward_compatible_pdb to full text
    '''

    assert forward_compatible_pdb_text is not None

    if key is None:
      full_text = forward_compatible_pdb_text
      for key in list(self._conversion_table_info_dict.keys()):
        full_text = self.get_full_text_from_forward_compatible_pdb_text(
          key = key, forward_compatible_pdb_text = full_text)
      return full_text

    conversion_table_info = self._get_conversion_table_info(key)

    if conversion_table_info and (
        forward_compatible_pdb_text in
          conversion_table_info.forward_compatible_pdb_representation_list):
      index = \
        conversion_table_info.forward_compatible_pdb_representation_list.index(
          forward_compatible_pdb_text)
      full_text = conversion_table_info.full_representation_list[index]
    else:
      full_text = forward_compatible_pdb_text

    return full_text

  def convert_multi_word_text_to_forward_compatible(self,
     key = None, text = None):
    ''' Public method to take a block of text and convert all the words that
      are in the dictionary for key to forward_compatible_pdb.  Note:
      cannot be reversed.  Spacing in lines is not maintained.
       Suitable for converting restraint (mmcif) files).
    '''
    if key is None: # do all keys
      for key in list(self._conversion_table_info_dict.keys()):
        text = self.convert_multi_word_text_to_forward_compatible(
          key, text = text)
      return text

    if not key in list(self._conversion_table_info_dict.keys()):
      return text  # do nothing

    info =  self._conversion_table_info_dict[key]
    if info:
      for full_text, forward_compatible_pdb_text in zip(
           info.full_representation_list,
           info.forward_compatible_pdb_representation_list,
           ):
        text = text.replace(full_text,forward_compatible_pdb_text)
    return text

  def get_forward_compatible_pdb_text_from_full_text(self,
        key = None, full_text = None, require_allowed = True):
    '''Public method to return forward_compatible_pdb text from
      full text (full text is original text, just one word)
      based on conversion table

    parameters:
      key: field to convert (e.g., chain_id, resname)
      full_text: text to convert to forward_compatible_pdb
    '''

    assert full_text is not None

    if key is None: # run all of them
      for key in list(self._conversion_table_info_dict.keys()):
        full_text = self.get_forward_compatible_pdb_text_from_full_text(
          key, full_text = full_text)
      return full_text

    conversion_table_info = self._get_conversion_table_info(key)
    if conversion_table_info and (
        full_text in conversion_table_info.full_representation_list):
      index = conversion_table_info.full_representation_list.index(
        full_text)
      forward_compatible_pdb_text = \
        conversion_table_info.forward_compatible_pdb_representation_list[index]
    else:
      forward_compatible_pdb_text = full_text

    if require_allowed:
      # Make sure that the resulting text is allowed in forward_compatible_pdb
      assert self._is_allowed(
        forward_compatible_pdb_text, self._max_chars_dict[key])

    return forward_compatible_pdb_text


 *******************************************************************************


 *******************************************************************************
iotbx/pdb/hierarchy.py
"""
Classes representing hierarchy objects and tools for manipulation.
Note: contains boosted C++ code; view source code for methods
and documentation.
"""

from __future__ import absolute_import, division, print_function
import boost_adaptbx.boost.python as bp
ext = bp.import_ext("iotbx_pdb_hierarchy_ext")
from iotbx_pdb_hierarchy_ext import *
ext2 = bp.import_ext("iotbx_pdb_ext")
from iotbx_pdb_ext import xray_structures_simple_extension
from libtbx.str_utils import show_sorted_by_counts
from libtbx.utils import Sorry, plural_s, null_out
from libtbx import Auto, dict_with_default_0, group_args
from iotbx.pdb import hy36encode, hy36decode, common_residue_names_get_class
from iotbx.pdb.amino_acid_codes import one_letter_given_three_letter
from iotbx.pdb.modified_aa_names import lookup as aa_3_as_1_mod
from iotbx.pdb.modified_rna_dna_names import lookup as na_3_as_1_mod
from iotbx.pdb.utils import all_chain_ids, all_label_asym_ids
import iotbx.cif.model
from cctbx import crystal, adptbx, uctbx
from cctbx.array_family import flex
import six
from six.moves import cStringIO as StringIO
from six.moves import range, zip
import collections
import operator
import warnings
import math
import sys

class pickle_import_trigger(object): pass

level_ids = ["model", "chain", "residue_group", "atom_group", "atom"]

def _show_residue_group(rg, out, prefix):
  atoms = rg.atoms()
  if (atoms.size() == 0):
    ch = rg.parent()
    if (ch is None): ch = "  "
    else:            ch = "%s" % ch.id
    print(prefix+'empty: "%s%s"' % (ch, rg.resid()), file=out)
  else:
    def show_atom(atom):
      print(prefix+'"%s"' % atom.format_atom_record(
        replace_floats_with=".*."), file=out)
    if (atoms.size() <= 3):
      for atom in atoms: show_atom(atom)
    else:
      show_atom(atoms[0])
      print(prefix+'... %d atom%s not shown' % plural_s(
        atoms.size()-2), file=out)
      show_atom(atoms[-1])

class overall_counts(object):
  """Count the number of residues, chains, atoms and other attributes of a hierarchy"""

  def __init__(self):
    self._errors = None
    self._warnings = None

  def show(self,
        out=None,
        prefix="",
        flag_errors=True,
        flag_warnings=True,
        residue_groups_max_show=10,
        duplicate_atom_labels_max_show=10):
    """Summarize information about this hierarchy"""
    if (out is None): out = sys.stdout
    self._errors = []
    self._warnings = []
    def add_err(msg):
      if (flag_errors): print(prefix+msg, file=out)
      self._errors.append(msg.strip())
    def add_warn(msg):
      if (flag_warnings): print(prefix+msg, file=out)
      self._warnings.append(msg.strip())
    fmt = "%%%dd" % len(str(self.n_atoms))
    print(prefix+"total number of:", file=out)
    if (self.n_duplicate_model_ids != 0):
      add_err("  ### ERROR: duplicate model ids ###")
    if (self.n_empty_models != 0):
      add_warn("  ### WARNING: empty model ###")
    print(prefix+"  models:    ", fmt % self.n_models, end='', file=out)
    infos = []
    if (self.n_duplicate_model_ids != 0):
      infos.append("%d with duplicate model id%s" % plural_s(
        self.n_duplicate_model_ids))
    if (self.n_empty_models != 0):
      infos.append("%d empty" % self.n_empty_models)
    if (len(infos) != 0): print(" (%s)" % "; ".join(infos), end='', file=out)
    print(file=out)
    if (self.n_duplicate_chain_ids != 0):
      add_warn("  ### WARNING: duplicate chain ids ###")
    if (self.n_empty_chains != 0):
      add_warn("  ### WARNING: empty chain ###")
    print(prefix+"  chains:    ", fmt % self.n_chains, end='', file=out)
    infos = []
    if (self.n_duplicate_chain_ids != 0):
      infos.append("%d with duplicate chain id%s" % plural_s(
        self.n_duplicate_chain_ids))
    if (self.n_empty_chains != 0):
      infos.append("%d empty" % self.n_empty_chains)
    if (self.n_explicit_chain_breaks != 0):
      infos.append("%d explicit chain break%s" % plural_s(
        self.n_explicit_chain_breaks))
    if (len(infos) != 0): print(" (%s)" % "; ".join(infos), end='', file=out)
    print(file=out)
    print(prefix+"  alt. conf.:", fmt % self.n_alt_conf, file=out)
    print(prefix+"  residues:  ", fmt % (
      self.n_residues + self.n_residue_groups + self.n_empty_residue_groups), end='', file=out)
    if (self.n_residue_groups != 0):
      print(" (%d with mixed residue names)" % self.n_residue_groups, end='', file=out)
    print(file=out)
    if (self.n_duplicate_atom_labels != 0):
      add_err("  ### ERROR: duplicate atom labels ###")
    print(prefix+"  atoms:     ", fmt % self.n_atoms, end='', file=out)
    if (self.n_duplicate_atom_labels != 0):
      print(" (%d with duplicate labels)" %self.n_duplicate_atom_labels, end='', file=out)
    print(file=out)
    print(prefix+"  anisou:    ", fmt % self.n_anisou, file=out)
    if (self.n_empty_residue_groups != 0):
      add_warn("  ### WARNING: empty residue_group ###")
      print(prefix+"  empty residue_groups:", \
        fmt % self.n_empty_residue_groups, file=out)
    if (self.n_empty_atom_groups != 0):
      add_warn("  ### WARNING: empty atom_group ###")
      print(prefix+"  empty atom_groups:", \
        fmt % self.n_empty_atom_groups, file=out)
    #
    c = self.element_charge_types
    print(prefix+"number of atom element+charge types:", len(c), file=out)
    if (len(c) != 0):
      print(prefix+"histogram of atom element+charge frequency:", file=out)
      show_sorted_by_counts(c.items(), out=out, prefix=prefix+"  ")
    #
    c = self.resname_classes
    print(prefix+"residue name classes:", end='', file=out)
    if (len(c) == 0): print(" None", end='', file=out)
    print(file=out)
    show_sorted_by_counts(c.items(), out=out, prefix=prefix+"  ")
    #
    c = self.chain_ids
    print(prefix+"number of chain ids: %d" % len(c), file=out)
    if (len(c) != 0):
      print(prefix+"histogram of chain id frequency:", file=out)
      show_sorted_by_counts(c.items(), out=out, prefix=prefix+"  ")
    #
    c = self.alt_conf_ids
    print(prefix+"number of alt. conf. ids: %d" % len(c), file=out)
    if (len(c) != 0):
      print(prefix+"histogram of alt. conf. id frequency:", file=out)
      show_sorted_by_counts(c.items(), out=out, prefix=prefix+"  ")
      #
      fmt = "%%%dd" % len(str(max(
        self.n_alt_conf_none,
        self.n_alt_conf_pure,
        self.n_alt_conf_proper,
        self.n_alt_conf_improper)))
      print(prefix+"residue alt. conf. situations:", file=out)
      print(prefix+"  pure main conf.:    ", fmt%self.n_alt_conf_none, file=out)
      print(prefix+"  pure alt. conf.:    ", fmt%self.n_alt_conf_pure, file=out)
      print(prefix+"  proper alt. conf.:  ", fmt%self.n_alt_conf_proper, file=out)
      if (self.n_alt_conf_improper != 0):
        add_err("  ### ERROR: improper alt. conf. ###")
      print(prefix+"  improper alt. conf.:", \
        fmt % self.n_alt_conf_improper, file=out)
      self.show_chains_with_mix_of_proper_and_improper_alt_conf(
        out=out, prefix=prefix)
    #
    c = self.resnames
    print(prefix+"number of residue names: %d" % len(c), file=out)
    if (len(c) != 0):
      print(prefix+"histogram of residue name frequency:", file=out)
      annotation_appearance = {
        "common_amino_acid": None,
        "modified_amino_acid": "   modified amino acid",
        "common_rna_dna": None,
        "modified_rna_dna": "   modified rna/dna",
        "common_water": "   common water",
        "common_small_molecule": "   common small molecule",
        "common_element": "   common element",
        "other": "   other",
        'd_amino_acid' : '   D-amino acid',
        'common_saccharide' : '  common saccharide',
      }
      show_sorted_by_counts(c.items(), out=out, prefix=prefix+"  ",
        annotations=[
          annotation_appearance[common_residue_names_get_class(name=name)]
            for name in c.keys()])
    #
    if (len(self.consecutive_residue_groups_with_same_resid) != 0):
      add_warn("### WARNING: consecutive residue_groups with same resid ###")
    self.show_consecutive_residue_groups_with_same_resid(
      out=out, prefix=prefix, max_show=residue_groups_max_show)
    #
    if (len(self.residue_groups_with_multiple_resnames_using_same_altloc)!= 0):
      add_err("### ERROR: residue group with multiple resnames using"
        " same altloc ###")
      self.show_residue_groups_with_multiple_resnames_using_same_altloc(
        out=out, prefix=prefix, max_show=residue_groups_max_show)
    #
    self.show_duplicate_atom_labels(
      out=out, prefix=prefix, max_show=duplicate_atom_labels_max_show)

  def as_str(self,
        prefix="",
        residue_groups_max_show=10,
        duplicate_atom_labels_max_show=10):
    """Return summary as string"""
    out = StringIO()
    self.show(
      out=out,
      prefix=prefix,
      residue_groups_max_show=residue_groups_max_show,
      duplicate_atom_labels_max_show=duplicate_atom_labels_max_show)
    return out.getvalue()

  def errors(self):
    """Return errors in overall_counts"""
    if (self._errors is None): self.show(out=null_out())
    return self._errors

  def get_n_residues_of_classes(self, classes):
    """Get residues in each class (common_amino_acid,common_rna_dna) """
    result = 0
    for resname, count in self.resnames.items():
      if common_residue_names_get_class(resname) in classes:
        result += count
    return result

  def warnings(self):
    """Get warnings in overall_counts"""
    if (self._warnings is None): self.show(out=null_out())
    return self._warnings

  def errors_and_warnings(self):
    """Get errors and warnings in overall_counts"""
    return self.errors() + self.warnings()

  def show_improper_alt_conf(self, out=None, prefix=""):
    """Identify improper alt_conformations in overall_counts"""
    if (self.n_alt_conf_improper == 0): return
    if (out is None): out = sys.stdout
    for residue_group,label in [(self.alt_conf_proper, "proper"),
                                (self.alt_conf_improper, "improper")]:
      if (residue_group is None): continue
      print(prefix+"residue with %s altloc" % label, file=out)
      for ag in residue_group.atom_groups():
        for atom in ag.atoms():
          print(prefix+'  "%s"' % atom.format_atom_record(
            replace_floats_with=".*."), file=out)

  def raise_improper_alt_conf_if_necessary(self):
    """Stop if improper alt_conformations present"""
    sio = StringIO()
    self.show_improper_alt_conf(out=sio)
    msg = sio.getvalue()
    if (len(msg) != 0): raise Sorry(msg.rstrip())

  def show_chains_with_mix_of_proper_and_improper_alt_conf(self,
        out=None,
        prefix=""):
    """Show chains with mix of proper and improper alt_conformations """
    if (out is None): out = sys.stdout
    n = self.n_chains_with_mix_of_proper_and_improper_alt_conf
    print(prefix+"chains with mix of proper and improper alt. conf.:", n, file=out)
    if (n != 0): prefix += "  "
    self.show_improper_alt_conf(out=out, prefix=prefix)

  def raise_chains_with_mix_of_proper_and_improper_alt_conf_if_necessary(self):
    """Stop if chains with mix of proper and improper alt_conformations """
    if (self.n_chains_with_mix_of_proper_and_improper_alt_conf == 0):
      return
    sio = StringIO()
    self.show_chains_with_mix_of_proper_and_improper_alt_conf(out=sio)
    raise Sorry(sio.getvalue().rstrip())

  def show_consecutive_residue_groups_with_same_resid(self,
        out=None,
        prefix="",
        max_show=10):
    """Show consecutive residue groups with same resid"""
    cons = self.consecutive_residue_groups_with_same_resid
    if (len(cons) == 0): return
    if (out is None): out = sys.stdout
    print(prefix+"number of consecutive residue groups with same resid: %d" % \
        len(cons), file=out)
    if (max_show is None): max_show = len(cons)
    elif (max_show <= 0): return
    delim = prefix+"  "+"-"*42
    prev_rg = None
    for rgs in cons[:max_show]:
      for next,rg in zip(["", "next "], rgs):
        if (    prev_rg is not None
            and prev_rg.memory_id() == rg.memory_id()): continue
        elif (next == "" and prev_rg is not None):
          print(delim, file=out)
        prev_rg = rg
        print(prefix+"  %sresidue group:" % next, file=out)
        _show_residue_group(rg=rg, out=out, prefix=prefix+"    ")
    if (len(cons) > max_show):
      print(delim, file=out)
      print(prefix + "  ... %d remaining instance%s not shown" % \
        plural_s(len(cons)-max_show), file=out)

  def show_residue_groups_with_multiple_resnames_using_same_altloc(self,
        out=None,
        prefix="",
        max_show=10):
    """Show residue groups with multiple resnames using same altloc"""
    rgs = self.residue_groups_with_multiple_resnames_using_same_altloc
    if (len(rgs) == 0): return
    print(prefix+"residue groups with multiple resnames using" \
      " same altloc:", len(rgs), file=out)
    if (max_show is None): max_show = len(cons)
    elif (max_show <= 0): return
    for rg in rgs[:max_show]:
      print(prefix+"  residue group:", file=out)
      _show_residue_group(rg=rg, out=out, prefix=prefix+"    ")
    if (len(rgs) > max_show):
      print(prefix + "  ... %d remaining instance%s not shown" % \
        plural_s(len(rgs)-max_show), file=out)

  def \
    raise_residue_groups_with_multiple_resnames_using_same_altloc_if_necessary(
        self, max_show=10):
    """Stop if residue groups with multiple resnames using same altloc"""
    sio = StringIO()
    self.show_residue_groups_with_multiple_resnames_using_same_altloc(
      out=sio, max_show=max_show)
    msg = sio.getvalue()
    if (len(msg) != 0): raise Sorry(msg.rstrip())

  def show_duplicate_atom_labels(self, out=None, prefix="", max_show=10):
    """Show duplicate atom labels"""
    dup = self.duplicate_atom_labels
    if (len(dup) == 0): return
    if (out is None): out = sys.stdout
    fmt = "%%%dd" % len(str(self.n_duplicate_atom_labels))
    print(prefix+"number of groups of duplicate atom labels:", \
      fmt % len(dup), file=out)
    print(prefix+"  total number of affected atoms:         ", \
      fmt % self.n_duplicate_atom_labels, file=out)
    if (max_show is None): max_show = len(dup)
    elif (max_show <= 0): return
    for atoms in dup[:max_show]:
      prfx = "  group "
      for atom in atoms:
        atom_str = atom.format_atom_record(replace_floats_with=".*.")
        # replacing atom number with .*.
        a_s = atom_str[:4]+ "    .*." + atom_str[11:]
        print(prefix+prfx+'"%s"' % a_s, file=out)
        prfx = "        "
    if (len(dup) > max_show):
      print(prefix+"  ... %d remaining group%s not shown" % \
        plural_s(len(dup)-max_show), file=out)

  def raise_duplicate_atom_labels_if_necessary(self, max_show=10):
    """Stop if duplicate atom labels"""
    sio = StringIO()
    self.show_duplicate_atom_labels(out=sio, max_show=max_show)
    msg = sio.getvalue()
    if (len(msg) != 0): raise Sorry(msg.rstrip())

class __hash_eq_mixin(object):

  def __hash__(self):
    return hash(self.memory_id())

  def __eq__(self, other):
    if other == None:
      return False
    if (isinstance(other, self.__class__)):
      return (self.memory_id() == other.memory_id())
    return False

  def __ne__(self, other):
    return not ( self == other )

bp.inject(ext.root, __hash_eq_mixin)
@bp.inject_into(ext.root)
class _():

  __doc__ = """
  Root node of the PDB hierarchy object.  This is returned by the method
  construct_hierarchy() of the PDB/mmCIF input objects, but it may also be
  created programatically.  Note that it does not contain any reference to
  crystal symmetry or source scattering information, meaning that in practice
  it must often be tracked alongside an equivalent cctbx.xray.structure object.
  Pickling is supported, simply by writing out and reading back the PDB-format
  representation of the hierarchy.

  Examples
  --------
  >>> hierarchy = iotbx.pdb.hierarchy.root()
  """

  __getstate_manages_dict__ = True

  def __getstate__(self):
    # check that the only possible attributes that are set are
    #   _lai_lookup
    #   _label_seq_id_dict
    # these are not pickled and are not restored when unpickling
    # if more attributes are added to the hierarchy class in Python,
    # the pickling code needs to be updated.
    attribute_check = set(self.__dict__.keys()) - set(['_lai_lookup', '_label_seq_id_dict'])
    assert len(attribute_check) == 0, attribute_check
    version = 2
    pdb_string = StringIO()
    if self.fits_in_pdb_format():
      py3out = self._as_pdb_string_cstringio(  # NOTE py3out will be None in py2
        cstringio=pdb_string,
        append_end=True,
        interleaved_conf=0,
        atoms_reset_serial_first_value=None,
        atom_hetatm=True,
        sigatm=True,
        anisou=True,
        siguij=True)
      if six.PY3:
        pdb_string.write(py3out)
    else:
      cif_object = iotbx.cif.model.cif()
      cif_object['pickled'] = self.as_cif_block()
      cif_object.show(out=pdb_string)
    return (version, pickle_import_trigger(), self.info, pdb_string.getvalue())

  def __setstate__(self, state):
    assert len(state) >= 3
    if sys.version_info.major >= 3:
      from libtbx.easy_pickle import fix_py2_pickle
      state = fix_py2_pickle(state)
    version = state[0]
    if   (version == 1): assert len(state) == 3
    elif (version == 2): assert len(state) == 4
    else: raise RuntimeError("Unknown version of pickled state.")
    self.info = state[-2]
    import iotbx.pdb
    ph = iotbx.pdb.input(
      source_info="string",
      lines=flex.split_lines(state[-1])).construct_hierarchy(sort_atoms=False)

    self.pre_allocate_models(number_of_additional_models=len(ph.models()))
    for model in ph.models():
      self.append_model(model=model.detached_copy())

  def chains(self):
    """
    Iterate over all chains in all models.
    """
    for model in self.models():
      for chain in model.chains():
        yield chain

  def residue_groups(self):
    """Iterate over all residue groups (by model and then chain)"""
    for model in self.models():
      for chain in model.chains():
        for rg in chain.residue_groups():
          yield rg

  def atom_groups(self):
    """
    Iterate over all atom groups (by model, then chain, then residue group)
    """
    for model in self.models():
      for chain in model.chains():
        for rg in chain.residue_groups():
          for ag in rg.atom_groups():
            yield ag

  def only_model(self):
    """Return the only model in the hierarchy. Must be only 1"""
    assert self.models_size() == 1
    return self.models()[0]

  def only_chain(self):
    """Return the only chain in hierarchy. Must be only 1"""
    return self.only_model().only_chain()

  def only_residue_group(self):
    """Return the only residue in hierarchy. Must be only 1"""
    return self.only_chain().only_residue_group()

  def only_conformer(self):
    """Return the only conformer in hierarchy. Must be only 1"""
    return self.only_chain().only_conformer()

  def only_atom_group(self):
    """Return the only atom_group in hierarchy. Must be only 1"""
    return self.only_residue_group().only_atom_group()

  def only_residue(self):
    """Return the only residue in hierarchy. Must be only 1"""
    return self.only_conformer().only_residue()

  def only_atom(self):
    """Return the only atom in hierarchy. Must be only 1"""
    return self.only_atom_group().only_atom()

  def overall_counts(self,
    only_one_model = None):
    """
    Calculate basic statistics for contents of the PDB hierarchy, including
    number of residues of each type.

    :parameter only_one_model:  return results for first model only
    :returns: iotbx.pdb.hierarchy.overall_counts object
    """
    if only_one_model and len(list(self.models())) > 1:
      one_model_ph = iotbx.pdb.hierarchy.root()
      one_model_ph.append_model(self.models()[0].detached_copy())
      return one_model_ph.overall_counts()

    result = overall_counts()
    self.get_overall_counts(result)
    return result

  def occupancy_counts(self):
    """Return group_args object with information about occupancies"""
    eps = 1.e-6
    occ = self.atoms().extract_occ()
    mean = flex.mean(occ)
    negative = (occ<0).count(True)
    zero_count = (flex.abs(occ)<eps).count(True)
    zero_fraction = zero_count*100./occ.size()
    equal_to_1_count = ((occ>(1.-eps)) & (occ<(1.+eps))).count(True)
    equal_to_1_fraction = equal_to_1_count*100/occ.size()
    between_0_and_1_count = ((occ>(0.+eps)) & (occ<(1.-eps))).count(True)
    between_0_and_1_fraction = between_0_and_1_count*100/occ.size()
    greater_than_1_count = (occ>(1.+eps)).count(True)
    greater_than_1_fraction = greater_than_1_count*100./occ.size()
    number_of_residues = len(list(self.residue_groups()))
    number_of_alt_confs = 0
    alt_loc_dist = collections.Counter()
    for rg in self.residue_groups():
      n_confs = len(rg.conformers())
      if(n_confs > 1):
        number_of_alt_confs += 1
        alt_loc_dist[n_confs] += 1
    return group_args(
      mean                     = mean,
      negative                 = negative,
      zero_count               = zero_count,
      zero_fraction            = zero_fraction,
      equal_to_1_count         = equal_to_1_count,
      equal_to_1_fraction      = equal_to_1_fraction,
      between_0_and_1_count    = between_0_and_1_count,
      between_0_and_1_fraction = between_0_and_1_fraction,
      greater_than_1_count     = greater_than_1_count,
      greater_than_1_fraction  = greater_than_1_fraction,
      alt_conf_frac            = number_of_alt_confs*100/number_of_residues,
      alt_loc_dist             = alt_loc_dist)

  def composition(self):
    """Return group_args object with information about composition"""
    asc = self.atom_selection_cache()
    def rc(sel_str, as_atoms=False):
      sel = asc.selection(sel_str)
      if(as_atoms):
        return self.select(sel).atoms().size()
      else:
        return len(list(self.select(sel).residue_groups()))
    sel_str_other = "not (water or nucleotide or protein)"
    other_cnts = collections.Counter()
    for rg in self.select(asc.selection(sel_str_other)).residue_groups():
      for resname in rg.unique_resnames():
        other_cnts[resname]+=1
    return group_args(
      n_atoms      = self.atoms().size(),
      n_chains     = len(list(self.chains())),
      n_protein    = rc("protein"),
      n_nucleotide = rc("nucleotide"),
      n_water      = rc("water"),
      n_hd         = rc(sel_str="element H or element D",as_atoms=True),
      n_other      = rc(sel_str_other),
      other_cnts   = other_cnts,
      # atom counts for Table 1
      n_protein_atoms    = rc("protein and not (element H or element D)", as_atoms=True),
      n_nucleotide_atoms = rc("nucleotide and not (element H or element D)", as_atoms=True),
      n_water_atoms      = rc("water", as_atoms=True),
      n_other_atoms      = rc(sel_str_other, as_atoms=True))

  def show(self,
        out=None,
        prefix="",
        level_id=None,
        level_id_exception=ValueError):
    """
    Display a summary of hierarchy contents.
    """
    if (level_id == None): level_id = "atom"
    try: level_no = level_ids.index(level_id)
    except ValueError:
      raise level_id_exception('Unknown level_id="%s"' % level_id)
    if (out is None): out = sys.stdout
    if (self.models_size() == 0):
      print(prefix+'### WARNING: empty hierarchy ###', file=out)
    model_ids = dict_with_default_0()
    for model in self.models():
      model_ids[model.id] += 1
    for model in self.models():
      chains = model.chains()
      if (model_ids[model.id] != 1):
        s = "  ### ERROR: duplicate model id ###"
      else: s = ""
      print(prefix+'model id="%s"' % model.id, \
        "#chains=%d%s" % (len(chains), s), file=out)
      if (level_no == 0): continue
      if (model.chains_size() == 0):
        print(prefix+'  ### WARNING: empty model ###', file=out)
      model_chain_ids = dict_with_default_0()
      for chain in chains:
        model_chain_ids[chain.id] += 1
      for chain in chains:
        rgs = chain.residue_groups()
        if (model_chain_ids[chain.id] != 1):
          s = "  ### WARNING: duplicate chain id ###"
        else: s = ""
        print(prefix+'  chain id="%s"' % chain.id, \
          "#residue_groups=%d%s" % (len(rgs), s), file=out)
        if (level_no == 1): continue
        if (chain.residue_groups_size() == 0):
          print(prefix+'    ### WARNING: empty chain ###', file=out)
        suppress_chain_break = True
        prev_resid = ""
        for rg in rgs:
          if (not rg.link_to_previous and not suppress_chain_break):
            print(prefix+"    ### chain break ###", file=out)
          suppress_chain_break = False
          ags = rg.atom_groups()
          resnames = set()
          for ag in rg.atom_groups():
            resnames.add(ag.resname)
          infos = []
          if (len(resnames) > 1): infos.append("with mixed residue names")
          resid = rg.resid()
          if (prev_resid == resid): infos.append("same as previous resid")
          prev_resid = resid
          if (len(infos) != 0): s = "  ### Info: %s ###" % "; ".join(infos)
          else: s = ""
          print(prefix+'    resid="%s"' % resid, \
            "#atom_groups=%d%s" % (len(ags), s), file=out)
          if (level_no == 2): continue
          if (rg.atom_groups_size() == 0):
            print(prefix+'      ### WARNING: empty residue_group ###', file=out)
          for ag in ags:
            atoms = ag.atoms()
            print(prefix+'      altloc="%s"' % ag.altloc, \
              'resname="%s"' % ag.resname, \
              "#atoms=%d" % len(atoms), file=out)
            if (level_no == 3): continue
            if (ag.atoms_size() == 0):
              print(prefix+'        ### WARNING: empty atom_group ###', file=out)
            for atom in atoms:
              print(prefix+'        "%s"' % atom.name, file=out)

  def as_str(self,
        prefix="",
        level_id=None,
        level_id_exception=ValueError):
    """
    Alias for show().
    """
    out = StringIO()
    self.show(
      out=out,
      prefix=prefix,
      level_id=level_id,
      level_id_exception=level_id_exception)
    return out.getvalue()

  def is_forward_compatible_hierarchy(self):
    """ Determine if this is a forward_compatible hierarchy"""
    if hasattr(self,'_conversion_info'):
      return True
    else:
      return False

  def conversion_info(self):
    """ Get the conversion info for this forward_compatible hierarchy"""
    assert self.is_forward_compatible_hierarchy(),\
      "Only a forward_compatible hierarchy has conversion info"
    return self._conversion_info

  def convert_multi_word_text_to_forward_compatible(self, text):
    """ Use conversion info to convert words in a text string to
     forward-compatible equivalents
     :params text:  text to convert
     :returns modified text
    """
    c = self.conversion_info()
    return c.convert_multi_word_text_to_forward_compatible(text = text)

  def as_forward_compatible_hierarchy(self, conversion_info = None):
    """ Convert a standard hierarchy to a forward_compatible_hierarchy

     :params conversion_info

     :returns pdb_hierarchy with chain ID and residue names converted to
        strings compatible with PDB formatting.  Returned hierarchy is
        a deep_copy and contains the attribute _conversion_info with the
        conversion_info used

     Typical use: running a method with cmd_text (text commands) and supplying
        a hierarchy (or string from it).  Convert the hierarchy and the
        cmd_text, run the method, convert the results back:

     # Convert the hierarchy to forward compatible
     ph_fc = ph.as_forward_compatible_hierarchy()

     # Convert any commands. Can be done one word at a time also
     cmd_text_fc = ph_fc.convert_multi_word_text_to_forward_compatible(cmd_text)

     # Run the method with converted hierarchy and commands
     result = do_something(ph = ph_fc, command_text = cmd_text_fc)

     # Convert back any resulting hierarchy
     new_ph = result.ph.forward_compatible_hierarchy_as_standard(
              conversion_info = ph_fc.conversion_info())

     # Convert back any words in the results that referred to converted
     #  items. Keys are chain_id and resname
     new_result_items = []
     for result_item,key in zip(results.text_words, results.text_keys):
       new_result_item = ph_fc.conversion_info().\
          get_full_text_from_forward_compatible_pdb_text(key = key,
          forward_compatible_pdb_text = result_item)
       new_result_items.append(new_result_item)

    """
    assert not self.is_forward_compatible_hierarchy(), \
        "Cannot make a hierarchy forward compatible twice"
    if not conversion_info:
      from iotbx.pdb.forward_compatible_pdb_cif_conversion \
         import forward_compatible_pdb_cif_conversion
      conversion_info = forward_compatible_pdb_cif_conversion(hierarchy = self)
    ph = self.deep_copy() # do not alter original
    conversion_info.convert_hierarchy_to_forward_compatible_pdb_representation(
       ph)
    return ph

  def forward_compatible_hierarchy_as_standard(self, conversion_info = None):
    """ Convert a forward_compatible_hierarchy to a standard one.
     Inverse of as_forward_compatible_hierarchy.  Restores chain IDs and
     residue names using conversion_info object

    :params: conversion_info:  optional conversion_info object specifying
          conversion to be applied

    :returns pdb_hierarchy with original (standard) chain ID and residue names

    """

    assert self.is_forward_compatible_hierarchy() or \
        (conversion_info is not None), \
       "Only a forward_compatible_hierarchy or a "+\
        "hierarchy and conversion_info can be converted back to standard"
    if not conversion_info:
      conversion_info = self.conversion_info()
    ph = self.deep_copy() # do not alter original
    conversion_info.convert_hierarchy_to_full_representation(ph)
    return ph

  def as_forward_compatible_string(self, **kw):
    """ Create a forward_compatible PDB string from a hierarchy and
     throw away the conversion information.

     One-way conversion useful for creating a file that is in PDB format.

    :params **kw: any params suitable for as_pdb_string()
    :returns text string
    """

    from iotbx.pdb.forward_compatible_pdb_cif_conversion \
       import hierarchy_as_forward_compatible_pdb_string
    return hierarchy_as_forward_compatible_pdb_string(self, **kw)

  def as_pdb_or_mmcif_string(self,
       target_format = None,
       segid_as_auth_segid = False,
       remark_section = None,
       **kw):
    '''
     Shortcut for pdb_or_mmcif_string_info with write_file=False, returning
       only the string representing this hierarchy. The string may be in
       PDB or mmCIF format, with target_format used if it is feasible.

     Method to allow shifting from general writing as pdb to
     writing as mmcif, with the change in two places (here and model.py)
     Use default of segid_as_auth_segid=False here (same as in
       as_mmcif_string())
     :param target_format: desired output format, pdb or mmcif
     :param segid_as_auth_segid: use the segid in hierarchy as the auth_segid
          in mmcif output
     :param remark_section: if supplied and format is pdb, add this text
     :param **kw:  any keywords suitable for as_pdb_string()
        and as_mmcif_string()
     :returns text string representing this hierarchy
    '''

    info = self.pdb_or_mmcif_string_info(
       target_format = target_format,
       segid_as_auth_segid = segid_as_auth_segid,
       remark_section = remark_section,
       write_file = False,
       **kw)
    return info.pdb_string

  def write_pdb_or_mmcif_file(self,
       target_filename,
       target_format = None,
       data_manager = None,
       overwrite = True,
       segid_as_auth_segid = False,
       remark_section = None,
       **kw):
    '''
     Shortcut for pdb_or_mmcif_string_info with write_file=True, returning
       only the name of the file that is written. The file may be written
       in PDB or mmCIF format, with target_format used if feasible.

     Method to allow shifting from general writing as pdb to
     writing as mmcif, with the change in two places (here and model.py)
     Use default of segid_as_auth_segid=False here (same as in
       as_mmcif_string())
     :param target_format: desired output format, pdb or mmcif
     :param target_filename: desired output file name, to be modified to
        match the output format
     :param data_manager:  data_manager to write files
     :param overwrite:  parameter to set overwrite=True in data_manager if True
     :param segid_as_auth_segid: use the segid in hierarchy as the auth_segid
          in mmcif output
     :param remark_section: if supplied and format is pdb, add this text
     :param **kw:  any keywords suitable for as_pdb_string()
        and as_mmcif_string()
     :returns name of file that is written
    '''

    info = self.pdb_or_mmcif_string_info(
       target_filename = target_filename,
       target_format = target_format,
       data_manager = data_manager,
       overwrite = overwrite,
       segid_as_auth_segid = segid_as_auth_segid,
       remark_section = remark_section,
       write_file = True,
       **kw)
    return info.file_name

  def pdb_or_mmcif_string_info(self,
       target_format = None, target_filename = None,
       data_manager = None,
       overwrite = True,
       segid_as_auth_segid = False,
       write_file = False,
       remark_section = None,
       **kw):
    """
     NOTE: Normally use instead either as_pdb_or_mmcif_string
     write_pdb_or_mmcif_file.

     Method to allow shifting from general writing as pdb to
     writing as mmcif, with the change in two places (here and model.py)
     Use default of segid_as_auth_segid=False here (same as in
       as_mmcif_string())
     :param target_format: desired output format, pdb or mmcif
     :param target_filename: desired output file name, to be modified to
        match the output format
     :param data_manager:  data_manager to write files
     :param overwrite:  parameter to set overwrite=True in data_manager if True
     :param segid_as_auth_segid: use the segid in hierarchy as the auth_segid
          in mmcif output
     :param write_file: Write the string to the target file
     :param remark_section: if supplied and format is pdb, add this text
     :param **kw:  any keywords suitable for as_pdb_string()
        and as_mmcif_string()

     :returns group_args object with attributes
       pdb_string, file_name (the actual file name used) and is_mmcif
    """

    if target_format in ['None',None]:  # set the default format here
      target_format = 'pdb'
    assert target_format in ['pdb','mmcif']

    if target_format == 'pdb':
      if self.fits_in_pdb_format():
        pdb_str = self.as_pdb_string(**kw)
        is_mmcif = False
        if remark_section:
          pdb_str = "%s\n%s" %(remark_section, pdb_str)
      else:
        pdb_str = self.as_mmcif_string(
          segid_as_auth_segid = segid_as_auth_segid, **kw)
        is_mmcif = True
    else:
      pdb_str = self.as_mmcif_string(
        segid_as_auth_segid = segid_as_auth_segid, **kw)
      is_mmcif = True
    if target_filename:
      import os
      path,ext = os.path.splitext(target_filename)
      if is_mmcif:
        ext = ".cif"
      else:
        ext = ".pdb"
      target_filename = "%s%s" %(path,ext)
    if target_filename and write_file:
      if not data_manager:
        from iotbx.data_manager import DataManager
        data_manager = DataManager()
      target_filename = data_manager.write_model_file(pdb_str, target_filename,
        overwrite = overwrite)

    return group_args(group_args_type = 'pdb_string and filename',
      pdb_string = pdb_str,
      file_name = target_filename,
      is_mmcif = is_mmcif)

  def as_pdb_string(self,
        crystal_symmetry=None,
        cryst1_z=None,
        write_scale_records=True,
        append_end=False,
        interleaved_conf=0,
        atoms_reset_serial_first_value=None,
        atom_hetatm=True,
        sigatm=True,
        anisou=True,
        siguij=True,
        output_break_records=True, # TODO deprecate XXX no, this is still needed
        force_write = False,
        cstringio=None,
        return_cstringio=Auto):
    """
    Deprecated.  Use instead as_pdb_or_mmcif_string.
    Generate complete PDB-format string representation.  External crystal
    symmetry is strongly recommended if this is being output to a file.

    :param crystal_symmetry: cctbx.crystal.symmetry object or equivalent (such
      as an xray.structure object or Miller array)
    :param write_scale_records: write fractional scaling records (SCALE) if
      crystal symmetry is provided
    :param anisou: write ANISOU records for anisotropic atoms
    :param sigatm: write SIGATM records if applicable
    :param siguij: write SIGUIJ records if applicable
    :param force_write:  write even if it does not fit in pdb format
    :returns: Python str
    """
    if (not self.fits_in_pdb_format()) and (not force_write):
      return ""
    if (cstringio is None):
      cstringio = StringIO()
      if (return_cstringio is Auto):
        return_cstringio = False
    elif (return_cstringio is Auto):
      return_cstringio = True
    if (crystal_symmetry is not None or cryst1_z is not None):
      from iotbx.pdb import format_cryst1_and_scale_records
      print(format_cryst1_and_scale_records(
        crystal_symmetry=crystal_symmetry,
        cryst1_z=cryst1_z,
        write_scale_records=write_scale_records), file=cstringio)
    py3out = self._as_pdb_string_cstringio(
      cstringio=cstringio,
      append_end=append_end,
      interleaved_conf=interleaved_conf,
      atoms_reset_serial_first_value=atoms_reset_serial_first_value,
      atom_hetatm=atom_hetatm,
      sigatm=sigatm,
      anisou=anisou,
      siguij=siguij,
      output_break_records=output_break_records)
    if six.PY3:
      cstringio.write(py3out)
    if (return_cstringio):
      return cstringio
    return cstringio.getvalue()

  def as_list_of_residue_names(self):
    """Return list of residue names in this model (all chains)"""
    sequence=[]
    for model in self.models():
      for chain in model.chains():
        seq = chain.as_list_of_residue_names()
        if seq:
          sequence += seq
    return sequence

  def as_model_manager(self, crystal_symmetry,
       unit_cell_crystal_symmetry = None,
       shift_cart = None):
    ''' Returns simple version of model object based on this hierarchy
     Expects but does not require crystal_symmetry.
     Optional unit_cell_crystal_symmetry and shift_cart.

     Note that if crystal_symmetry is not supplied,
     this uses a text representation of the hierarchy so that
     values for xyz, occ, b, and crystal_symmetry are all rounded.
     '''
    import mmtbx.model

    # make up crystal_symmetry if not present
    crystal_symmetry = self.generate_crystal_symmetry(crystal_symmetry)

    mm = mmtbx.model.manager(
          model_input = None, # REQUIRED
          pdb_hierarchy = self,
          crystal_symmetry = crystal_symmetry,
          )
    mm.set_unit_cell_crystal_symmetry_and_shift_cart(
          unit_cell_crystal_symmetry = unit_cell_crystal_symmetry,
          shift_cart = shift_cart)
    mm.info().file_name = None
    return mm

  def as_dict_of_chain_id_resseq_as_int_residue_names(self):
    """Return dictionary keyed by chain ID. Values are
      dictionaries of residue names in chain keyed by resseq_as_int values"""
    dd =  {}
    m = self.only_model()
    for c in m.chains():
      new_dd = c.as_dict_of_resseq_as_int_residue_names()
      dd[c.id] = new_dd
    return dd

  def as_sequence(self,
      substitute_unknown='X',
      substitute_unknown_na = 'N',
      ignore_all_unknown = None,
      as_string = False,
      only_one_model = False):
    ''' Uses chain.as_sequence() for all chains and returns the catenation
    :param substitute_unknown: character to use for unrecognized 3-letter codes
    :param substitute_unknown_na: character to use for unrecognized na codes
    :param ignore_all_unknown: set substitute_unknown and substitute_unknown_na to ''
    :param as_string: return string (default is to return list)
    :param only_one_model: Only use the first model if more than one
    '''

    max_models = 1 if only_one_model else len(list(self.models()))
    seq =  []
    for m in self.models()[:max_models]:
      for c in m.chains():
        new_seq = c.as_sequence(
          substitute_unknown =substitute_unknown,
          substitute_unknown_na = substitute_unknown_na,
          ignore_all_unknown =ignore_all_unknown,
         )
        if new_seq:
          seq += new_seq
    if as_string:
      return "".join(seq)
    else: # usual
      return seq

  def format_fasta(self,
      substitute_unknown='X',
      substitute_unknown_na = 'N',
      ignore_all_unknown = None,
      as_string = False):
    ''' uses format_fasta for all chains and returns catenation
    :param substitute_unknown: character to use for unrecognized 3-letter codes
    :param substitute_unknown_na: character to use for unrecognized na codes
    :param ignore_all_unknown: set substitute_unknown and substitute_unknown_na to ''
    :param as_string: return string (default is to return list of lines)
    '''
    seq_fasta_lines = []
    for m in self.models():
      for c in m.chains():
        new_lines = c.format_fasta(
          substitute_unknown =substitute_unknown,
          substitute_unknown_na = substitute_unknown_na,
          ignore_all_unknown =ignore_all_unknown,
         )
        if new_lines:
          seq_fasta_lines += new_lines
    if as_string:
      return "\n".join(seq_fasta_lines)
    else: # usual
      return seq_fasta_lines

  def generate_crystal_symmetry(self, crystal_symmetry):
    """Generate crystal symmetry with box around atoms, use information
    from supplied crystal_symmetry if available"""
    cryst1_substitution_buffer_layer = None
    if (crystal_symmetry is None):
      crystal_symmetry = crystal.symmetry()
    if (crystal_symmetry.unit_cell() is None):
      crystal_symmetry = crystal_symmetry.customized_copy(
        unit_cell=uctbx.non_crystallographic_unit_cell(
          sites_cart=self.atoms().extract_xyz(),
          buffer_layer=cryst1_substitution_buffer_layer))
    if (crystal_symmetry.space_group_info() is None):
      crystal_symmetry = crystal_symmetry.cell_equivalent_p1()
    return crystal_symmetry

  def extract_xray_structure(self, crystal_symmetry=None,
     enable_scattering_type_unknown = False,
     min_distance_sym_equiv=None):
    """
    Generate the equivalent cctbx.xray.structure object.  If the crystal
    symmetry is not provided, this will be placed in a P1 box.  In practice it
    is usually best to keep the original xray structure object around, but this
    method is helpful in corner cases.
    """
    # Abbreviated copy-paste from iotbx/pdb/__init__.py: def xray_structures_simple()
    # Better than getting iotbx.pdb.input from hierarchy.as_pdb_string()
    from cctbx import xray
    import scitbx.stl.set
    non_unit_occupancy_implies_min_distance_sym_equiv_zero = True
    if min_distance_sym_equiv is None:
      min_distance_sym_equiv = 0.5

    # Make up crystal symmetry if not present
    crystal_symmetry = self.generate_crystal_symmetry(crystal_symmetry)
    unit_cell = crystal_symmetry.unit_cell()
    scale_r = (0,0,0,0,0,0,0,0,0)
    scale_t = (0,0,0)
    scale_matrix = None
    result = []
    from iotbx.pdb import default_atom_names_scattering_type_const
    atom_names_scattering_type_const = default_atom_names_scattering_type_const
    mi = flex.size_t([m.atoms_size() for m in self.models()])
    for i in range(1, len(mi)):
      mi[i] += mi[i-1]
    loop = xray_structures_simple_extension(
      False, # one_structure_for_each_model,
      False, # unit_cube_pseudo_crystal,
      False, # fractional_coordinates,
      False, # scattering_type_exact,
      enable_scattering_type_unknown,
      self.atoms_with_labels(),
      mi,
      scitbx.stl.set.stl_string(atom_names_scattering_type_const),
      unit_cell,
      scale_r,
      scale_t)
    special_position_settings = crystal_symmetry.special_position_settings(
      min_distance_sym_equiv=min_distance_sym_equiv)
    try :
      while (next(loop)):
        result.append(xray.structure(
          special_position_settings=special_position_settings,
          scatterers=loop.scatterers,
          non_unit_occupancy_implies_min_distance_sym_equiv_zero=
            non_unit_occupancy_implies_min_distance_sym_equiv_zero))
    except ValueError as e :
      raise Sorry(str(e))
    return result[0]

  def adopt_xray_structure(self, xray_structure):
    """
    Apply the current (refined) atomic parameters from the cctbx.xray.structure
    object to the atoms in the PDB hierarchy.
    """
    if(self.atoms_size() != xray_structure.scatterers().size()):
      raise RuntimeError("Incompatible size of hierarchy and scatterers array.")
      # raise RuntimeError("Incompatible size of hierarchy and scatterers array: %d and %d" % (
      #   self.atoms_size(), xray_structure.scatterers().size()))
    scatterers = xray_structure.scatterers()
    uc = xray_structure.unit_cell()
    orth = uc.orthogonalize
    for sc, a in zip(scatterers, self.atoms()):
      a.set_xyz(new_xyz=orth(sc.site))
      a.set_occ(new_occ=sc.occupancy)
      a.set_b(new_b=adptbx.u_as_b(sc.u_iso_or_equiv(uc)))
      if(sc.flags.use_u_aniso() and sc.u_star != (-1.0, -1.0, -1.0, -1.0, -1.0, -1.0)):
        # a.set_uij(new_uij = adptbx.u_star_as_u_cart(uc,sc.u_star))
        a.set_uij(new_uij = sc.u_cart_plus_u_iso(uc))
      else:
        a.uij_erase()
      a.set_fp(new_fp=sc.fp)
      a.set_fdp(new_fdp=sc.fdp)
      element, charge = sc.element_and_charge_symbols()
      a.set_element(element)
      a.set_charge(charge)

  def apply_rotation_translation(self, rot_matrices, trans_vectors):
    """
    Apply rotation-translation to coordinates in the hierarchy
    LIMITATION: ANISOU records in resulting hierarchy will be invalid!!!
    """
    roots=[]
    for r,t in zip(rot_matrices, trans_vectors):
      for model in self.models():
        root = iotbx.pdb.hierarchy.root()
        m = iotbx.pdb.hierarchy.model()
        for c in model.chains():
          c = c.detached_copy()
          xyz = c.atoms().extract_xyz()
          new_xyz = r.elems*xyz+t
          c.atoms().set_xyz(new_xyz)
          m.append_chain(c)
        root.append_model(m)
        roots.append(root)
    result = iotbx.pdb.hierarchy.join_roots(roots=roots)
    result.reset_i_seq_if_necessary()
    return result

  def remove_residue_groups_with_atoms_on_special_positions_selective(self,
        crystal_symmetry):
    """Remove residue groups that contain atoms on special positions.  Return
       list of removed groups"""
    self.reset_i_seq_if_necessary()
    special_position_settings = crystal.special_position_settings(
      crystal_symmetry = crystal_symmetry)
    # Using
    # unconditional_general_position_flags=(self.atoms().extract_occ() != 1)
    # will skip atoms on sp that have partial occupancy.
    site_symmetry_table = \
      special_position_settings.site_symmetry_table(
        sites_cart = self.atoms().extract_xyz())
    spi = site_symmetry_table.special_position_indices()
    removed = []
    for c in self.chains():
      for rg in c.residue_groups():
        keep=True
        for i in rg.atoms().extract_i_seq():
          if(i in spi):
            keep=False
            break
        if(not keep):
          for resname in rg.unique_resnames():
            if(common_residue_names_get_class(resname) == "common_amino_acid" or
               common_residue_names_get_class(resname) == "common_rna_dna"):
              raise RuntimeError(
                "Amino-acid residue or NA is on special position.")
          for resname in rg.unique_resnames():
            removed.append(",".join([c.id, rg.resid(), resname]))
          c.remove_residue_group(residue_group=rg)
    return removed

  def shift_to_origin(self, crystal_symmetry):
    """ Find and apply shift of coordinates to put center inside (0,1) in
     each direction"""
    uc = crystal_symmetry.unit_cell()
    sites_frac = uc.fractionalize(self.atoms().extract_xyz())
    l = abs(min(sites_frac.min()))
    r = abs(max(sites_frac.max()))
    rl = max(l, r)+2
    rr= range(int(-rl), int(rl))
    shift_best = None
    for x in rr:
      for y in rr:
        for z in rr:
          sf = sites_frac+[x,y,z]
          sc = uc.orthogonalize(sf)
          cmf = uc.fractionalize(sc.mean())
          if(cmf[0]>=0 and cmf[0]<1 and
             cmf[1]>=0 and cmf[1]<1 and
             cmf[2]>=0 and cmf[2]<1):
            shift_best = [x,y,z]
    assert shift_best is not None # should never happen
    self.atoms().set_xyz(uc.orthogonalize(sites_frac+shift_best))

  def expand_to_p1(self, crystal_symmetry, exclude_self=False):
    """ Expand model to P1.  ANISOU will be invalid"""
    import string
    import scitbx.matrix
    r = root()
    m = model()
    idl = [i for i in string.ascii_lowercase]
    idu = [i for i in string.ascii_uppercase]
    taken = [c.id for c in self.chains()]
    n_atoms = []
    for m_ in self.models():
      for smx in crystal_symmetry.space_group().all_ops():
        m3 = smx.r().as_double()
        m3 = scitbx.matrix.sqr(m3)
        if(exclude_self and m3.is_r3_identity_matrix()): continue
        t = smx.t().as_double()
        t = scitbx.matrix.col((t[0],t[1],t[2]))
        for c_ in m_.chains():
          n_at = len(c_.atoms())
          if(not n_at in n_atoms): n_atoms.append(n_at)
          c_ = c_.detached_copy()
          xyz = c_.atoms().extract_xyz()
          xyz = crystal_symmetry.unit_cell().fractionalize(xyz)
          new_xyz = crystal_symmetry.unit_cell().orthogonalize(m3.elems*xyz+t)
          c_.atoms().set_xyz(new_xyz)
          #
          if(not (smx.r().is_unit_mx() and smx.t().is_zero())):
            found = False
            for idu_ in idu:
              for idl_ in idl:
                id_ = idu_+idl_
                if(not id_ in taken):
                  taken.append(id_)
                  found = id_
                  break
              if(found): break
            c_.id = found
          #
          m.append_chain(c_)
    r.append_model(m)
    return r

  def write_pdb_file(self,
        file_name,
        open_append=False,
        crystal_symmetry=None,
        cryst1_z=None,
        write_scale_records=True,
        append_end=False,
        interleaved_conf=0,
        atoms_reset_serial_first_value=None,
        atom_hetatm=True,
        sigatm=True,
        anisou=True,
        siguij=True,
        link_records=None,
        ):
    """Deprecated.  Use instead write_pdb_or_mmcif_file"""
    if link_records:
      if (open_append): mode = "a"
      else:             mode = "w"
      with open(file_name, mode) as f:
        print(link_records, file=f)
      open_append = True
    if (crystal_symmetry is not None or cryst1_z is not None):
      if (open_append): mode = "a"
      else:             mode = "w"
      from iotbx.pdb import format_cryst1_and_scale_records
      with open(file_name, mode) as f:
        print(format_cryst1_and_scale_records(
          crystal_symmetry=crystal_symmetry,
          cryst1_z=cryst1_z,
          write_scale_records=write_scale_records), file=f)
      open_append = True
    self._write_pdb_file(
      file_name=file_name,
      open_append=open_append,
      append_end=append_end,
      interleaved_conf=interleaved_conf,
      atoms_reset_serial_first_value=atoms_reset_serial_first_value,
      atom_hetatm=atom_hetatm,
      sigatm=sigatm,
      anisou=anisou,
      siguij=siguij,
      )

  def get_label_alt_id_iseq(self, iseq):
    """Return the altloc value for the atom with index iseq """
    assert self.atoms_size() > iseq
    return self.get_label_alt_id_atom(self.atoms()[iseq])

  def get_label_alt_id_atom(self, atom):
    """Return the altloc value for this atom"""
    alt_id = atom.parent().altloc
    if alt_id == '': alt_id = '.'
    return alt_id

  def get_auth_asym_id_iseq(self, iseq):
    """Return auth_asym_id of atom with index iseq"""
    assert self.atoms_size() > iseq, "%d, %d" % (self.atoms_size(), iseq)
    return self.get_auth_asym_id(self.atoms()[iseq].parent().parent().parent())

  def get_auth_asym_id(self, chain, segid_as_auth_segid = False):
    """Return auth_asym_id of this chain"""
    auth_asym_id = chain.id
    if (not segid_as_auth_segid) and \
       len(chain.atoms()[0].segid.strip()) > len(auth_asym_id):
      auth_asym_id = chain.atoms()[0].segid.strip()
    if auth_asym_id.strip() == '':
      # chain id is empty, segid is empty, just duplicate label_asym_id
      # since we cannot read mmCIF with empty auth_asym_id. Outputting a file
      # that we cannot read - bad.
      auth_asym_id = self.get_label_asym_id(chain.residue_groups()[0])
    return auth_asym_id

  def get_label_asym_id_iseq(self, iseq):
    """Return the label_asym_id for atom with index iseq"""
    assert self.atoms_size() > iseq
    return self.get_label_asym_id(self.atoms()[iseq].parent().parent())

  def get_label_asym_id(self, residue_group):
    """Return the label_asym_id for this residue group"""
    if not hasattr(self, '_lai_lookup'):
      self._lai_lookup = {}
      # fill self._lai_lookup for the whole hierarchy
      number_label_asym_id = 0
      label_asym_ids = all_label_asym_ids()

      for model in self.models():
        for chain in model.chains():
          previous = None
          for rg in chain.residue_groups():
            resname = rg.atom_groups()[0].resname.strip()
            residue_class = common_residue_names_get_class(resname)
            rg_mid = rg.memory_id()
            if residue_class in ['common_amino_acid', 'modified_amino_acid',
                'common_rna_dna', 'modified_rna_dna']:
              if previous != 'poly' and previous is not None:
                number_label_asym_id += 1
              self._lai_lookup[rg_mid] = label_asym_ids[number_label_asym_id]
              previous = 'poly'
            elif residue_class in ['common_water']:
              if previous != 'water' and previous is not None:
                number_label_asym_id += 1
              previous = 'water'
              self._lai_lookup[rg_mid] = label_asym_ids[number_label_asym_id]
            else: # ligand
              if previous is not None:
                number_label_asym_id += 1
              previous = 'ligand'
              self._lai_lookup[rg_mid] = label_asym_ids[number_label_asym_id]
          number_label_asym_id += 1 # up for each chain
          previous = None
        number_label_asym_id += 1 # up for each model
    rg_mid = residue_group.memory_id()
    result = self._lai_lookup.get(rg_mid, None)
    if result is None:
      print (residue_group.id_str())
    return result

    # return self.number_label_asym_id, self.label_asym_ids[self.number_label_asym_id]

  def get_auth_seq_id_iseq(self, iseq):
    """Return auth_seq_id for atom with index iseq"""
    assert self.atoms_size() > iseq
    return self.get_auth_seq_id(self.atoms()[iseq].parent().parent())

  def get_auth_seq_id(self, rg):
    """Return auth_seq_id for this residue group"""
    resseq_strip = rg.resseq.strip()
    if len(resseq_strip) == 4:
      return str(hy36decode(4, rg.resseq.strip()))
    else:
      return resseq_strip

  def get_label_seq_id_iseq(self, iseq):
    """Return label_seq_id for atom with index iseq"""
    assert self.atoms_size() > iseq, "%d, %d" % (self.atoms_size(), iseq)
    return self.get_label_seq_id(self.atoms()[iseq].parent())

  def get_label_seq_id(self, atom_group):
    """Return label_seq_id for this atom_group"""
    if not hasattr(self, '_label_seq_id_dict'):
      # make it
      prev_ac_key = ''
      self._label_seq_id_dict = {}
      for model in self.models():
        for chain in model.chains():
          label_seq_id = 0
          for rg in chain.residue_groups():
            for ag in rg.atom_groups():
              cur_ac_key = chain.id + rg.resseq + rg.icode
              if cur_ac_key != prev_ac_key:
                label_seq_id += 1
                prev_ac_key = cur_ac_key
              label_seq_id_str='.'
              comp_id = ag.resname.strip()
              residue_class = common_residue_names_get_class(comp_id)
              if residue_class in ['common_amino_acid', 'modified_amino_acid']:
                label_seq_id_str = str(label_seq_id)
              self._label_seq_id_dict[ag.memory_id()] = label_seq_id_str
    return self._label_seq_id_dict[atom_group.memory_id()]

  def clear_label_asym_id_lookups(self):
    """ Make sure we have fresh lookups in case the hierarchy was modified since
        they were calculated."""
    if hasattr(self, '_lai_lookup'):
      del self._lai_lookup
    if hasattr(self, '_label_seq_id_dict'):
      del self._label_seq_id_dict

  def as_cif_block(self,
      crystal_symmetry=None,
      coordinate_precision=5,
      occupancy_precision=3,
      b_iso_precision=5,
      u_aniso_precision=5,
      segid_as_auth_segid=False,
      output_break_records=False):

    if crystal_symmetry is None:
      crystal_symmetry = crystal.symmetry()
    cs_cif_block = crystal_symmetry.as_cif_block(format="mmcif")
    self.clear_label_asym_id_lookups()

    h_cif_block = iotbx.cif.model.block()
    coord_fmt_str = "%%.%if" %coordinate_precision
    occ_fmt_str = "%%.%if" %occupancy_precision
    b_iso_fmt_str = "%%.%if" %b_iso_precision
    u_aniso_fmt_str = "%%.%if" %u_aniso_precision

    atom_site_header = [
      '_atom_site.group_PDB',
      '_atom_site.id',
      '_atom_site.label_atom_id',
      '_atom_site.label_alt_id',
      '_atom_site.label_comp_id',
      '_atom_site.auth_asym_id',
      '_atom_site.auth_seq_id',
      '_atom_site.pdbx_PDB_ins_code',
      '_atom_site.Cartn_x',
      '_atom_site.Cartn_y',
      '_atom_site.Cartn_z',
      '_atom_site.occupancy',
      '_atom_site.B_iso_or_equiv',
      '_atom_site.type_symbol',
      '_atom_site.pdbx_formal_charge',
      '_atom_site.phenix_scat_dispersion_real',
      '_atom_site.phenix_scat_dispersion_imag',
      '_atom_site.label_asym_id',
      '_atom_site.label_entity_id',
      '_atom_site.label_seq_id',
      #'_atom_site.auth_comp_id',
      #'_atom_site.auth_atom_id',
      '_atom_site.pdbx_PDB_model_num',
     ]
    if segid_as_auth_segid:
      atom_site_header.append('_atom_site.auth_segid',)
    if output_break_records:
      # Determine if there are any break records here to write out
      if not self.contains_break_records():
        output_break_records = False # no point
    if output_break_records:  # set up _atom_site.auth_break
      atom_site_header.append('_atom_site.auth_break',)

    atom_site_loop = iotbx.cif.model.loop(header=tuple(atom_site_header))

    aniso_loop = iotbx.cif.model.loop(header=(
      '_atom_site_anisotrop.id',
      '_atom_site_anisotrop.pdbx_auth_atom_id',
      '_atom_site_anisotrop.pdbx_label_alt_id',
      '_atom_site_anisotrop.pdbx_auth_comp_id',
      '_atom_site_anisotrop.pdbx_auth_asym_id',
      '_atom_site_anisotrop.pdbx_auth_seq_id',
      '_atom_site_anisotrop.pdbx_PDB_ins_code',
      '_atom_site_anisotrop.U[1][1]',
      '_atom_site_anisotrop.U[2][2]',
      '_atom_site_anisotrop.U[3][3]',
      '_atom_site_anisotrop.U[1][2]',
      '_atom_site_anisotrop.U[1][3]',
      '_atom_site_anisotrop.U[2][3]'
    ))

    # cache dictionary lookups to save time in inner loop
    atom_site_group_PDB = atom_site_loop['_atom_site.group_PDB']
    atom_site_id = atom_site_loop['_atom_site.id']
    atom_site_label_atom_id = atom_site_loop['_atom_site.label_atom_id']
    atom_site_label_alt_id = atom_site_loop['_atom_site.label_alt_id']
    atom_site_label_comp_id = atom_site_loop['_atom_site.label_comp_id']
    atom_site_auth_asym_id = atom_site_loop['_atom_site.auth_asym_id']
    atom_site_auth_seq_id = atom_site_loop['_atom_site.auth_seq_id']
    atom_site_pdbx_PDB_ins_code = atom_site_loop['_atom_site.pdbx_PDB_ins_code']
    atom_site_Cartn_x = atom_site_loop['_atom_site.Cartn_x']
    atom_site_Cartn_y = atom_site_loop['_atom_site.Cartn_y']
    atom_site_Cartn_z = atom_site_loop['_atom_site.Cartn_z']
    atom_site_occupancy = atom_site_loop['_atom_site.occupancy']
    atom_site_B_iso_or_equiv = atom_site_loop['_atom_site.B_iso_or_equiv']
    atom_site_type_symbol = atom_site_loop['_atom_site.type_symbol']
    atom_site_pdbx_formal_charge = atom_site_loop['_atom_site.pdbx_formal_charge']
    atom_site_phenix_scat_dispersion_real = \
      atom_site_loop['_atom_site.phenix_scat_dispersion_real']
    atom_site_phenix_scat_dispersion_imag = \
      atom_site_loop['_atom_site.phenix_scat_dispersion_imag']
    atom_site_label_asym_id = atom_site_loop['_atom_site.label_asym_id']
    atom_site_label_entity_id = atom_site_loop['_atom_site.label_entity_id']
    atom_site_label_seq_id = atom_site_loop['_atom_site.label_seq_id']
    #atom_site_loop['_atom_site.auth_comp_id'].append(comp_id)
    #atom_site_loop['_atom_site.auth_atom_id'].append(atom.name.strip())
    atom_site_pdbx_PDB_model_num = atom_site_loop['_atom_site.pdbx_PDB_model_num']
    if segid_as_auth_segid:
      atom_site_auth_segid = atom_site_loop['_atom_site.auth_segid']
    if output_break_records:
      atom_site_auth_break = atom_site_loop['_atom_site.auth_break']

    atom_site_anisotrop_id = aniso_loop['_atom_site_anisotrop.id']
    atom_site_anisotrop_pdbx_auth_atom_id = \
      aniso_loop['_atom_site_anisotrop.pdbx_auth_atom_id']
    atom_site_anisotrop_pdbx_label_alt_id = \
      aniso_loop['_atom_site_anisotrop.pdbx_label_alt_id']
    atom_site_anisotrop_pdbx_auth_comp_id = \
      aniso_loop['_atom_site_anisotrop.pdbx_auth_comp_id']
    atom_site_anisotrop_pdbx_auth_asym_id = \
      aniso_loop['_atom_site_anisotrop.pdbx_auth_asym_id']
    atom_site_anisotrop_pdbx_auth_seq_id = \
      aniso_loop['_atom_site_anisotrop.pdbx_auth_seq_id']
    atom_site_anisotrop_pdbx_PDB_ins_code = \
      aniso_loop['_atom_site_anisotrop.pdbx_PDB_ins_code']
    atom_site_anisotrop_U11 = aniso_loop['_atom_site_anisotrop.U[1][1]']
    atom_site_anisotrop_U22 = aniso_loop['_atom_site_anisotrop.U[2][2]']
    atom_site_anisotrop_U33 = aniso_loop['_atom_site_anisotrop.U[3][3]']
    atom_site_anisotrop_U12 = aniso_loop['_atom_site_anisotrop.U[1][2]']
    atom_site_anisotrop_U13 = aniso_loop['_atom_site_anisotrop.U[1][3]']
    atom_site_anisotrop_U23 = aniso_loop['_atom_site_anisotrop.U[2][3]']

    unique_chain_ids = set()
    auth_asym_ids = flex.std_string()
    label_asym_ids = flex.std_string()
    #
    chem_comp_loop = iotbx.cif.model.loop(header=(
      '_chem_comp.id',
      ))
    struct_asym_loop = iotbx.cif.model.loop(header=(
      '_struct_asym.id',
      ))
    chem_comp_ids = []
    chem_comp_atom_ids = []
    struct_asym_ids = []
    #
    chain_ids = all_chain_ids()
    for model in self.models():
      model_id = model.id
      is_first_in_chain = True
      if model_id == '': model_id = '1'
      for chain in model.chains():
        auth_asym_id = self.get_auth_asym_id(chain,
           segid_as_auth_segid = segid_as_auth_segid)
        for residue_group in chain.residue_groups():
          is_first_after_break = not (
            is_first_in_chain or residue_group.link_to_previous)
          label_asym_id = self.get_label_asym_id(residue_group)
          seq_id = self.get_auth_seq_id(residue_group)
          icode = residue_group.icode
          if icode == ' ' or icode == '': icode = '?'
          for atom_group in residue_group.atom_groups():
            comp_id = atom_group.resname.strip()
            entity_id = '?' # XXX how do we determine this?
            for atom in atom_group.atoms():

              group_pdb = "ATOM"
              if atom.hetero: group_pdb = "HETATM"
              x, y, z = [coord_fmt_str %i for i in atom.xyz]
              atom_charge = atom.charge_tidy()
              if atom_charge is None:
                atom_charge = "?"
              else:
                atom_charge = atom_charge.strip()
              if atom_charge == "": atom_charge = "?"
              fp, fdp = atom.fp, atom.fdp
              if fp == 0 and fdp == 0:
                fp = '.'
                fdp = '.'
              else:
                fp = "%.4f" %fp
                fdp = "%.4f" %fdp
              atom_site_group_PDB.append(group_pdb)
              atom_site_id.append(str(hy36decode(width=5, s=atom.serial)))
              atom_site_label_atom_id.append(atom.name.strip())
              if atom.name.strip() not in chem_comp_atom_ids:
                chem_comp_atom_ids.append(atom.name.strip())
              atom_site_label_alt_id.append(self.get_label_alt_id_atom(atom))
              atom_site_label_comp_id.append(comp_id)
              if comp_id not in chem_comp_ids: chem_comp_ids.append(comp_id)
              atom_site_auth_asym_id.append(auth_asym_id)
              atom_site_auth_seq_id.append(seq_id)
              atom_site_pdbx_PDB_ins_code.append(icode)
              atom_site_Cartn_x.append(x)
              atom_site_Cartn_y.append(y)
              atom_site_Cartn_z.append(z)
              atom_site_occupancy.append(occ_fmt_str % atom.occ)
              atom_site_B_iso_or_equiv.append(b_iso_fmt_str % atom.b)
              atom_site_type_symbol.append(atom.element.strip())
              atom_site_pdbx_formal_charge.append(atom_charge)
              atom_site_phenix_scat_dispersion_real.append(fp)
              atom_site_phenix_scat_dispersion_imag.append(fdp)
              atom_site_label_asym_id.append(label_asym_id.strip())
              if label_asym_id.strip() not in struct_asym_ids:
                struct_asym_ids.append(label_asym_id.strip())
              atom_site_label_entity_id.append(entity_id)
              atom_site_label_seq_id.append(self.get_label_seq_id(atom_group))
              #atom_site_loop['_atom_site.auth_comp_id'].append(comp_id)
              #atom_site_loop['_atom_site.auth_atom_id'].append(atom.name.strip())
              atom_site_pdbx_PDB_model_num.append(model_id.strip())
              if segid_as_auth_segid:
                atom_site_auth_segid.append(atom.segid)
              if output_break_records:
                atom_site_auth_break.append("1" if is_first_after_break else "0")

              if atom.uij_is_defined():
                u11, u22, u33, u12, u13, u23 = [
                  u_aniso_fmt_str %i for i in atom.uij]
                atom_site_anisotrop_id.append(
                  str(hy36decode(width=5, s=atom.serial)))
                atom_site_anisotrop_pdbx_auth_atom_id.append(atom.name.strip())
                atom_site_anisotrop_pdbx_label_alt_id.append(self.get_label_alt_id_atom(atom))
                atom_site_anisotrop_pdbx_auth_comp_id.append(comp_id)
                atom_site_anisotrop_pdbx_auth_asym_id.append(auth_asym_id)
                atom_site_anisotrop_pdbx_auth_seq_id.append(seq_id)
                atom_site_anisotrop_pdbx_PDB_ins_code.append(icode)
                atom_site_anisotrop_U11.append(u11)
                atom_site_anisotrop_U22.append(u22)
                atom_site_anisotrop_U33.append(u33)
                atom_site_anisotrop_U12.append(u12)
                atom_site_anisotrop_U13.append(u13)
                atom_site_anisotrop_U23.append(u23)
              is_first_in_chain = False
              is_first_after_break = False
              # end of atom loop

    for key in ('_atom_site.phenix_scat_dispersion_real',
                '_atom_site.phenix_scat_dispersion_imag'):
      if atom_site_loop[key].all_eq('.'):
        del atom_site_loop[key]
    h_cif_block.add_loop(atom_site_loop)
    if aniso_loop.size() > 0:
      h_cif_block.add_loop(aniso_loop)
    h_cif_block.update(cs_cif_block)
    #
    chem_comp_ids.sort()
    for row in chem_comp_ids: chem_comp_loop.add_row([row])
    h_cif_block.add_loop(chem_comp_loop)
    chem_comp_atom_ids.sort()
    for row in struct_asym_ids: struct_asym_loop.add_row([row])
    h_cif_block.add_loop(struct_asym_loop)
    #
    return h_cif_block

  def remove_segid(self):
    """Remove all segid information"""
    for model in self.models():
      for chain in model.chains():
        for residue_group in chain.residue_groups():
          for atom_group in residue_group.atom_groups():
            for atom in atom_group.atoms():
              atom.set_segid('    ')

  def remove_hetero(self):
    """Remove all hetero atoms"""
    for model in self.models():
      for chain in model.chains():
        for residue_group in chain.residue_groups():
          for atom_group in residue_group.atom_groups():
            have_het = False
            for atom in atom_group.atoms():
              if atom.hetero:
                have_het = True
                break
            if have_het:
              residue_group.remove_atom_group(atom_group)
    # clean up
    need_fixing = True
    while need_fixing:
      need_fixing = False
      for model in self.models():
        if len(list(model.chains())) == 0:
          self.remove_model(model)
          need_fixing = True
        for chain in model.chains():
          if len(list(chain.residue_groups())) == 0:
            model.remove_chain(chain)
            need_fixing = True
          for residue_group in chain.residue_groups():
            if len(list(residue_group.atom_groups())) == 0:
              chain.remove_residue_group(residue_group)
              need_fixing = True
            for atom_group in residue_group.atom_groups():
              if len(list(atom_group.atoms())) == 0:
                residue_group.remove_atom_group(atom_group)
                need_fixing = True

  def contains_hetero(self):
    """Return True if hierarchy contains hetero atoms"""
    for model in self.models():
      for chain in model.chains():
        for residue_group in chain.residue_groups():
          for atom_group in residue_group.atom_groups():
            for atom in atom_group.atoms():
              if atom.hetero:
                return True
    return False

  def contains_break_records(self):
    """Return True if hierarchy contains break records"""
    for model in self.models():
      for chain in model.chains():
        is_first_in_chain = True
        for rg in chain.residue_groups():
          is_first_after_break = not (is_first_in_chain or rg.link_to_previous)
          if is_first_after_break:
            return True
          is_first_in_chain = False
    return False

  def guess_chemical_elements(self,
     check_pseudo = False,
     convert_atom_names_to_uppercase = True,
     allow_incorrect_spacing = None):
    ''' Attempt to guess chemical elements for all atoms in hierarchy
       where this is not set.  Normally used only just after reading in
       PDB-formatted files that do not have elements specified
    '''
    # Standard set of chemical elements based on atom names (and leading spaces)
    atoms = self.atoms()
    if convert_atom_names_to_uppercase:
      for at in atoms:
        at.name = at.name.upper()
    atoms.set_chemical_element_simple_if_necessary()

    # Check to see if all have an element now
    elements = atoms.extract_element().strip()
    if elements.all_ne(""): # all done
      return

    # Check for incorrect spacings (atom name has space before it but should
    #  not or opposite)
    if allow_incorrect_spacing:
      from iotbx.pdb.utils import set_element_ignoring_spacings
      set_element_ignoring_spacings(self)

    # Check for pseudo-atoms (ZU ZC etc that represent groups of atoms)
    if check_pseudo:
      from iotbx.pdb.utils import check_for_pseudo_atoms
      check_for_pseudo_atoms(self)

  def as_mmcif_string(self,
                       crystal_symmetry=None,
                       data_block_name=None,
                       segid_as_auth_segid=False,
                       output_break_records=False):
    """Return mmCIF string representation of this hierarchy"""
    cif_object = iotbx.cif.model.cif()
    if data_block_name is None:
      data_block_name = "phenix"
    cif_object[data_block_name] = self.as_cif_block(
      crystal_symmetry=crystal_symmetry,
      segid_as_auth_segid = segid_as_auth_segid,
      output_break_records = output_break_records)
    f = StringIO()
    cif_object.show(out = f)
    return f.getvalue()

  def write_mmcif_file(self,
                       file_name,
                       crystal_symmetry=None,
                       data_block_name=None,
                       segid_as_auth_segid=False,
                       output_break_records=False):
    """Write mmCIF file representing this hierarchy. Normally
       use instead write_pdb_or_mmcif_file"""
    cif_object = iotbx.cif.model.cif()
    if data_block_name is None:
      data_block_name = "phenix"
    cif_object[data_block_name] = self.as_cif_block(
      crystal_symmetry=crystal_symmetry,
      segid_as_auth_segid = segid_as_auth_segid,
      output_break_records = output_break_records)
    with open(file_name, "w") as f:
      print(cif_object, file=f)

  def atoms_with_labels(self):
    """
    Generator for atom_with_labels objects, presented in the same order as
    the array returned by the atoms() method.
    """
    for model in self.models():
      for chain in model.chains():
        is_first_in_chain = True
        for rg in chain.residue_groups():
          is_first_after_break = not (is_first_in_chain or rg.link_to_previous)
          for ag in rg.atom_groups():
            for atom in ag.atoms():
              yield atom_with_labels(
                atom=atom,
                model_id=model.id,
                chain_id=chain.id,
                resseq=rg.resseq,
                icode=rg.icode,
                altloc=ag.altloc,
                resname=ag.resname,
                is_first_in_chain=is_first_in_chain,
                is_first_after_break=is_first_after_break)
              is_first_in_chain = False
              is_first_after_break = False

  def get_conformer_indices(self):
    n_seq = self.atoms_size()
    conformer_indices = flex.size_t(n_seq, 0)
    altloc_indices = self.altloc_indices()
    if ("" in altloc_indices): p = 0
    else:                      p = 1
    altlocs = sorted(altloc_indices.keys())
    index_altloc_mapping = {}
    for i,altloc in enumerate(altlocs):
      if (altloc == ""):
        index_altloc_mapping[altloc]=0
        continue
      conformer_indices.set_selected(altloc_indices[altloc], i+p)
      index_altloc_mapping[altloc]=i+p
    return group_args(
      conformer_indices = conformer_indices,
      index_altloc_mapping = index_altloc_mapping)

  def sort_chains_by_id(self):
    chain_ids = self.chain_ids()
    if len(chain_ids) < 2:
      return # nothing to do

    unique_chain_ids = []
    have_dups = False
    for chain_id in chain_ids:
      if chain_id in unique_chain_ids:
        have_dups = True
      else:
        unique_chain_ids.append(chain_id)
    if not have_dups:
      return  # nothing to do

    import iotbx.pdb.hierarchy
    new_ph = iotbx.pdb.hierarchy.root()
    for m0 in self.models():
      detached_chain_dict = {}
      m1 = iotbx.pdb.hierarchy.model()
      m1.id = m0.id
      new_ph.append_model(m1)
      for c0 in m0.chains():
        if not c0.id in list(detached_chain_dict.keys()):
          detached_chain_dict[c0.id] = []
        detached_chain_dict[c0.id].append(c0.detached_copy())
      for chain_id in unique_chain_ids:
        for c in detached_chain_dict[chain_id]:
          m1.append_chain(c)

    # Now clear out the original and attach new models to the original hierarchy
    for m0 in self.models():
      for c0 in m0.chains():
        m0.remove_chain(chain = c0)

    for m0, m1 in zip(self.models(), new_ph.models()):
      for c1 in  m1.chains():
        m0.append_chain(c1.detached_copy())

    # and reset i_seq
    atoms = self.atoms()
    atoms.reset_i_seq()

  def remove_ter_or_break(self):
    """Remove TER and BREAK by setting residue_group.link_to_previous=True"""
    import iotbx.pdb.hierarchy
    new_ph = iotbx.pdb.hierarchy.root()
    # Sort by chain ID first
    self.sort_chains_by_id()
    for m0 in self.models():
        m1 = iotbx.pdb.hierarchy.model()
        m1.id = m0.id
        new_ph.append_model(m1)
        last_chain = None
        for c0 in m0.chains():
         if (not last_chain) or (last_chain and c0.id != last_chain.id) :
           new_chain = True
           first = True
           c1 = c0.detached_copy()
           m1.append_chain(c1)
           last_chain = c0
         else:
           for residue_group in c0.residue_groups():
             c1.append_residue_group(residue_group.detached_copy())
    for m1 in new_ph.models():
      for c1 in m1.chains():
        first = True
        for residue_group in c1.residue_groups():
           if not first:
             residue_group.link_to_previous = True
           first = False

    # Now clear out the original and attach new models to the original hierarchy
    for m0 in self.models():
      for c0 in m0.chains():
        m0.remove_chain(chain = c0)

    for m0, m1 in zip(self.models(), new_ph.models()):
      for c1 in  m1.chains():
        m0.append_chain(c1.detached_copy())

    # and reset i_seq
    atoms = self.atoms()
    atoms.reset_i_seq()

  def remove_incomplete_main_chain_protein(self,
       required_atom_names=['CA','N','C','O']):
    """Remove each residue_group that does not contain CA N C O of protein"""
    hierarchy = self
    for model in hierarchy.models():
      for chain in model.chains():
        for residue_group in chain.residue_groups():
          all_atom_names_found=[]
          atom_groups = residue_group.atom_groups()
          for atom_group in atom_groups:
            for atom in atom_group.atoms():
              atom_name=atom.name.strip()
              if not atom_name in all_atom_names_found:
                all_atom_names_found.append(atom_name)
          for r in required_atom_names:
            if not r in all_atom_names_found:
              chain.remove_residue_group(residue_group=residue_group)
              break
        if (len(chain.residue_groups()) == 0):
          model.remove_chain(chain=chain)

  def altlocs_present(self, skip_blank = True):
    """Return True if any altlocs (alternative conformations) are present"""
    hierarchy = self
    altlocs_present = []
    for model in hierarchy.models():
      for chain in model.chains():
        for residue_group in chain.residue_groups():
          for atom_group in residue_group.atom_groups():
            if skip_blank and (atom_group.altloc.strip() == ''):
              continue  # ignore blanks
            if not atom_group.altloc in altlocs_present:
              altlocs_present.append(atom_group.altloc)
    return altlocs_present

  def remove_alt_confs(self, always_keep_one_conformer, altloc_to_keep = None,
                             keep_occupancy = False):
    """Remove all alternative conformations.  Required parameter is
     always_keep_one_conformer (recommended: True)"""
    hierarchy = self
    for model in hierarchy.models():
      for chain in model.chains():
        for residue_group in chain.residue_groups():
          atom_groups = residue_group.atom_groups()
          assert (len(atom_groups) > 0)
          cleanup_needed = True
          if always_keep_one_conformer :
            if (len(atom_groups) == 1) and (atom_groups[0].altloc == ''):
              continue
            atom_groups_and_occupancies = []
            altlocs_found = []
            for atom_group in atom_groups :
              if (atom_group.altloc == ''): # always keep ''
                continue

              mean_occ = flex.mean(atom_group.atoms().extract_occ())
              atom_groups_and_occupancies.append((atom_group, mean_occ))
              altlocs_found.append(atom_group.altloc)

            if (altloc_to_keep is not None) and (altloc_to_keep in
                    altlocs_found): # put altloc_to_keep first
              for atom_group_and_occupancy in atom_groups_and_occupancies:
                if atom_group_and_occupancy[0].altloc == altloc_to_keep:
                  atom_groups_and_occupancies.remove(atom_group_and_occupancy)
                  atom_groups_and_occupancies = [atom_group_and_occupancy] + \
                     atom_groups_and_occupancies
                  break
            else: # put atom_group with highest occupancy first
              atom_groups_and_occupancies.sort(key=operator.itemgetter(1),
                 reverse=True)

            for atom_group, occ in atom_groups_and_occupancies[1:]:
              residue_group.remove_atom_group(atom_group=atom_group)
            single_conf, occ = atom_groups_and_occupancies[0]
            single_conf.altloc = ''
          else :
            for atom_group in atom_groups :
              if (not atom_group.altloc in ["",
                  altloc_to_keep if (altloc_to_keep is not None) else "A"]):
                residue_group.remove_atom_group(atom_group=atom_group)
              else :
                atom_group.altloc = ""
            if (len(residue_group.atom_groups()) == 0):
              chain.remove_residue_group(residue_group=residue_group)
              cleanup_needed = False
          if cleanup_needed and residue_group.atom_groups_size() > 1:
            ags = residue_group.atom_groups()
            for i in range(len(ags)-1, 0, -1):
              residue_group.merge_atom_groups(ags[0], ags[i])
              residue_group.remove_atom_group(ags[i])
        if (len(chain.residue_groups()) == 0):
          model.remove_chain(chain=chain)
    if not keep_occupancy:
      atoms = hierarchy.atoms()
      new_occ = flex.double(atoms.size(), 1.0)
      atoms.set_occ(new_occ)

  def average_alt_confs(self, pinch_limit=1.):
    """Average coordinates from alternative conformations"""
    def average(xyz1, xyz2):
      a=[]
      for i in range(3):
        a.append((xyz1[i]+xyz2[i])/2)
      return tuple(a)
    def dist2(xyz1, xyz2):
      d2 = 0
      for i in range(3):
        d2 += (xyz1[i]-xyz2[i])**2
      return d2

    pinch_limit*=pinch_limit

    hierarchy = self
    asel=flex.size_t()
    for model in hierarchy.models():
      for chain in model.chains():
        for residue_group in chain.residue_groups():
          atom_groups = residue_group.atom_groups()
          assert (len(atom_groups) > 0)
          if (len(atom_groups) == 1): continue

          done=[]
          for atom in residue_group.atoms():
            if atom.element_is_hydrogen(): continue
            if atom.name in done: continue
            done.append(atom.name)
            atoms=[]
            for atom_group in atom_groups:
              atom_alt_conf = atom_group.get_atom(atom.name.strip())
              if atom_alt_conf is None: continue
              atoms.append(atom_group.get_atom(atom.name.strip()))
            inputs = []
            for atom in atoms:
              inputs.append(atom.xyz)
            if len(inputs)==1: continue
            elif len(inputs)>2:
              raise Sorry('more than two alt confs not supported')
            d2=dist2(*inputs)
            # print('d2',d2,atom.quote())
            if d2<pinch_limit:
              ave = average(*inputs)
              for atom in atoms:
                atom.xyz=ave
                asel.append(atom.i_seq)
    return asel

  def rename_chain_id(self, old_id, new_id):
    """Replace old_id chain ID with new_id"""
    for model in self.models():
      for chain in model.chains():
        if(chain.id == old_id):
          chain.id = new_id

  def remove_atoms(self, fraction):
    """Return hierarchy with random fraction of atoms removed"""
    assert fraction>0 and fraction<1.
    n_atoms_to_keep = int(self.atoms_size() * (1-fraction))
    sel_keep = flex.random_selection(self.atoms_size(), n_atoms_to_keep)
    return self.select(sel_keep)

  def set_atomic_charge(self, iselection, charge):
    """Set atomic charge for indices marked with iselection"""
    assert isinstance(charge, int)
    if(iselection is None):
      raise Sorry("Specify an atom selection to apply a charge to.")
    if(abs(charge) >= 10):
      raise Sorry("The charge must be in the range from -9 to 9.")
    if(iselection.size() == 0):
      raise Sorry("Empty selection for charge modification")
    if(charge == 0):
      charge = "  "
    elif (charge < 0):
      charge = "%1d-" % abs(charge)
    else:
      charge = "%1d+" % charge
    atoms = self.atoms()
    for i_seq in iselection:
      atom = atoms[i_seq]
      atom.set_charge(charge)

  def truncate_to_poly(self, atom_names_set=set()):
    """Truncate all residues to atom names in atom_names_set (protein only)"""
    pdb_atoms = self.atoms()
    pdb_atoms.reset_i_seq()
    aa_resnames = one_letter_given_three_letter
    for model in self.models():
      for chain in model.chains():
        for rg in chain.residue_groups():
          def have_amino_acid():
            for ag in rg.atom_groups():
              if (ag.resname in aa_resnames):
                return True
            return False
          if (have_amino_acid()):
            for ag in rg.atom_groups():
              for atom in ag.atoms():
                if (atom.name not in atom_names_set):
                  ag.remove_atom(atom=atom)

  def truncate_to_poly_gly(self):
    """Truncate all residues to gly (protein only)"""
    self.truncate_to_poly(
        atom_names_set=set([" N  ", " CA ", " C  ", " O  "]))

  def truncate_to_poly_ala(self):
    """Truncate all residues to ala (protein only)"""
    self.truncate_to_poly(
        atom_names_set=set([" N  ", " CA ", " C  ", " O  ", " CB "]))

  def convert_semet_to_met(self):
    """Convert all SeMet to MET"""
    for model in self.models():
      for chain in model.chains():
        for residue_group in chain.residue_groups():
          for atom_group in residue_group.atom_groups():
            if(atom_group.resname == "MSE"):
              atom_group.resname = "MET"
              for atom in atom_group.atoms():
                atom.hetero = False
                if((atom.name.strip()=="SE") and (
                    atom.element.strip().upper()=="SE")):
                  atom.name = " SD "
                  atom.element = " S"

  def convert_met_to_semet(self):
    """Convert all MET to SeMET"""
    for model in self.models():
      for chain in model.chains():
        for residue_group in chain.residue_groups():
          for atom_group in residue_group.atom_groups():
            if(atom_group.resname == "MET"):
              atom_group.resname = "MSE"
              for atom in atom_group.atoms():
                atom.hetero = True
                if((atom.name.strip()=="SD") and (
                    atom.element.strip().upper()=="S")):
                  atom.name = " SE "
                  atom.element = "SE"

  def transfer_chains_from_other(self, other):
    """Transfer chains from other into this hierarchy"""
    i_model = 0
    other_models = other.models()
    for md,other_md in zip(self.models(), other_models):
      i_model += 1
      md.id = hy36encode(width=4, value=i_model)
      md.transfer_chains_from_other(other=other_md)
    msz, omsz = self.models_size(), other.models_size()
    if (omsz > msz):
      for other_md in other_models[msz:]:
        i_model += 1
        md = model(id = hy36encode(width=4, value=i_model))
        md.transfer_chains_from_other(other=other_md)
        self.append_model(model=md)

  def atom_selection_cache(self, special_position_settings=None):
    """Return the atom_selection cache"""
    from iotbx.pdb.atom_selection import cache
    return cache(root=self,
      special_position_settings=special_position_settings)

  def apply_atom_selection(self, atom_selection):
    ''' Apply atom selection string and return deep copy with selected atoms'''
    asc=self.atom_selection_cache()
    sel = asc.selection(string = atom_selection)
    return self.select(sel, copy_atoms=True)  # independent copy is required

  def occupancy_groups_simple(self, common_residue_name_class_only=None,
                              always_group_adjacent=True,
                              ignore_hydrogens=True):
    """Return a list occupancy groups for all chains."""
    if(ignore_hydrogens):
      sentinel = self.atoms().reset_tmp_for_occupancy_groups_simple()
    else:
      sentinel = self.atoms().reset_tmp(first_value=0, increment=1)
    result = []
    for chain in self.chains():
      if(common_residue_name_class_only is None):
        if(chain.is_protein()):
          common_residue_name_class_only = "common_amino_acid"
        if(chain.is_na()):
          common_residue_name_class_only = "common_rna_dna"
      result.extend(chain.occupancy_groups_simple(
        common_residue_name_class_only=common_residue_name_class_only,
        always_group_adjacent=always_group_adjacent))
    del sentinel
    return result

  def round_occupancies_in_place(self, ndigits):
    """Round occupancies of those alternative conformations that cannot be
    rounded properly to the sum of 1 by standard round procedure in the output.
    The rest occupancies left intact.

    Args:
        ndigits (int): number of significant digits after the dot
    """
    h_atoms = self.atoms()
    ogs = self.occupancy_groups_simple()
    for occ_group in ogs:
      # check conditions
      can_be_rounded = True
      occs = []
      occs_values = []
      for g in occ_group:
        occs.append(h_atoms.select(flex.size_t(g)).extract_occ())
      for o in occs:
        # occupancy of all atoms is the same?
        if len(set(o)) == 1:
          occs_values.append(o[0])
        else:
          can_be_rounded = False
      if sum(occs_values) != 1.00:
        can_be_rounded = False
      # now round them up, values in occs_values are the ones to round
      if can_be_rounded:
        round_occs = group_rounding(occs_values, ndigits)
        for i, g in enumerate(occ_group):
          h_atoms.select(flex.size_t(g)).set_occ(flex.double([round_occs[i]]*len(g)))

  def chunk_selections(self, residues_per_chunk):
    """Get a set of selections for residues_per_chunk at a time"""
    result = []
    if(residues_per_chunk<1): return result
    for model in self.models():
      for chain in model.chains():
        residue_range_sel = flex.size_t()
        cntr = 0
        for rg in chain.residue_groups():
          i_seqs = rg.atoms().extract_i_seq()
          last_added=True
          if(cntr!=residues_per_chunk):
            residue_range_sel.extend(i_seqs)
            last_added=False
          else:
            result.append(residue_range_sel)
            residue_range_sel = flex.size_t()
            residue_range_sel.extend(i_seqs)
            cntr = 0
            last_added=False
          cntr += 1
        if(len(result)==0 or not last_added):
          assert residue_range_sel.size()>0
          result.append(residue_range_sel)
    return result

  def merge_atoms_at_end_to_residues(self):
    """Transfered from qrefine for merging single H/D atoms from the end of the
    PDB input to the correct residue object
    """
    for model_id, model in enumerate(self.models()):
      residues = {}
      for ag in model.atom_groups():
        # complication with alt.loc.
        key = '%s %s' % (model_id, ag.id_str())
        previous_instance = residues.setdefault(key, None)
        if previous_instance:
          # move atoms from here to there
          for atom in ag.atoms():
            previous_instance.append_atom(atom.detached_copy())
            ag.remove_atom(atom)
          rg = ag.parent()
          rg.remove_atom_group(ag)
          chain = rg.parent()
          chain.remove_residue_group(rg)
          if chain.atoms_size() == 0:
            model.remove_chain(chain)
        else:
          residues[key] = ag

  def is_hierarchy_altloc_consistent(self, verbose=False):
    """Return True if altlocs are consistent"""
    altlocs = {}
    for residue_group in self.residue_groups():
      if not residue_group.have_conformers(): continue
      for atom_group in residue_group.atom_groups():
        rc = altlocs.setdefault(residue_group.id_str(), [])
        if atom_group.altloc: rc.append(atom_group.altloc)
    lens=[]
    for key, item in altlocs.items():
      l=len(item)
      if l not in lens: lens.append(l)
    if len(lens)>1:
      outl = '  Uneven Alt. Locs.\n'
      for key, item in altlocs.items():
        outl += '    "%s" : %s\n' % (key, item)
      if verbose: print(outl)
      return False
    return True

  def format_correction_for_H(self, verbose=False): # remove 1-JUL-2024
    """Deprecated.  Format a correction for H atoms"""
    for atom in self.atoms():
      if atom.element_is_hydrogen():
        if len(atom.name.strip())<4:
          if (atom.name.find(atom.name.strip())==0 and
              atom.name[0] not in ['1', '2', '3']):
            atom.name=' %-3s' % atom.name.strip()
            if verbose: print('corrected PDB format of %s' % atom.quote())

  def flip_symmetric_amino_acids(self):
    """Swap atom names in symmetric or chiral amino acids"""
    import time
    from scitbx.math import dihedral_angle
    def chirality_delta(sites, volume_ideal, both_signs):
      d_01 = sites[1] - sites[0]
      d_02 = sites[2] - sites[0]
      d_03 = sites[3] - sites[0]
      d_02_cross_d_03 = d_02.cross(d_03)
      volume_model = d_01.dot(d_02_cross_d_03)
      delta_sign = -1;
      if both_signs and volume_model < 0:
        delta_sign = 1
      delta = volume_ideal + delta_sign * volume_model
      return delta[0]
    data = {
      "ARG" : {"dihedral" : ["CD", "NE", "CZ", "NH1"],
               "value"    : [0, 1],
               "pairs"    : [["NH1", "NH2"],
                             ["HH11","HH21"], # should this also be periodicty
                             ["HH12","HH22"], # of 1
                            ],
             },
      "ASP" : {"dihedral" : ["CA", "CB", "CG", "OD1"],
               "value"    : [0, 1],
               "pairs"    : [["OD1", "OD2"]],
             },
      "GLU" : {"dihedral" : ["CB", "CG", "CD", "OE1"],
               "value"    : [0, 1],
               "pairs"    : [["OE1", "OE2"]],
             },
      "PHE" : {"dihedral" : ["CA", "CB", "CG", "CD1"],
               "value"    : [0, 1],
               "pairs"    : [["CD1", "CD2"],
                             ["CE1", "CE2"],
                             ["HD1", "HD2"],
                             ["HE1", "HE2"],
                            ],
             },
      # even less symmetric flips - based on chirals
      'VAL' : {'chiral' : ['CB', 'CA', 'CG1', 'CG2'],
               'value'  : [-2.5, False, 1],
               'pairs'  : [['CG1', 'CG2'],
                           ['HG11','HG21'],
                           ['HG12','HG22'],
                           ['HG13','HG23'],
                           ],
               },
      'LEU' : {'chiral' : ['CG', 'CB', 'CD1', 'CD2'],
               'value'  : [-2.5, False, 1],
               'pairs'  : [['CD1', 'CD2'],
                           ['HD11','HD21'],
                           ['HD12','HD22'],
                           ['HD13','HD23'],
                           ],
               },
    }
    data["TYR"]=data["PHE"]

    for code, item in data.items():
      current = item.get('pairs', [])
      adds = []
      for a1, a2 in current:
        if a1[0]=='H' and a2[0]=='H':
          adds.append(['D%s'%a1[1:], 'D%s'%a2[1:]])
      item['pairs']+=adds

    sites_cart = self.atoms().extract_xyz()
    t0=time.time()
    info = ""
    flips=0
    for rg in self.residue_groups():
      flip_it=False
      for ag in rg.atom_groups():
        flip_data = data.get(ag.resname, None)
        if flip_data is None: continue
        assert not ('dihedral' in flip_data and 'chiral' in flip_data)
        if not flip_it:
          if 'dihedral' in flip_data:
            sites = []
            for d in flip_data["dihedral"]:
              atom = ag.get_atom(d)
              if atom is None: break
              sites.append(atom.xyz)
            if len(sites)!=4: continue
            dihedral = dihedral_angle(sites=sites, deg=True)
            if abs(dihedral)>360./flip_data["value"][1]/4:
              flip_it=True
          elif 'chiral' in flip_data:
            sites = []
            for d in flip_data["chiral"]:
              atom = ag.get_atom(d)
              if atom is None: break
              sites.append(atom.xyz)
            if len(sites)!=4: continue
            delta = chirality_delta(sites=[flex.vec3_double([xyz]) for xyz in sites],
                                    volume_ideal=flip_data["value"][0],
                                    both_signs=flip_data['value'][1],
                                    )
            if abs(delta)>2.:
              flip_it=True
        if flip_it:
          flips_stored = []
          atoms = ag.atoms()
          for pair in flip_data["pairs"]:
            atom1 = ag.get_atom(pair[0])
            atom2 = ag.get_atom(pair[1])
            if atom1 is None and atom2 is None: continue
            if len(list(filter(None, [atom1, atom2]))) == 1:
              flips_stored=[]
              info += '    Residue "%s %s %s": not complete - not flipped' % (
                rg.parent().id,
                ag.resname,
                rg.resseq,
              )
              break
            flips_stored.append([atom1,atom2])
          for atom1, atom2 in flips_stored:
            for attr in ['xyz', 'b']:
              tmp = getattr(atom1, attr)
              setattr(atom1, attr, getattr(atom2, attr))
              setattr(atom2, attr, tmp)
          flips+=1
    if flips or info:
      info += '  Time to flip %d residue(s): %0.2fs\n' % (flips, time.time()-t0)
    return info

  def distance_based_simple_two_way_bond_sets(self,
        fallback_expected_bond_length=1.4,
        fallback_search_max_distance=2.5):
    """Return result of
       crystal.distance_based_connectivity.build_simple_two_way_bond_sets"""
    from cctbx.crystal import distance_based_connectivity
    atoms = self.atoms().deep_copy() # XXX potential bottleneck
    atoms.set_chemical_element_simple_if_necessary()
    sites_cart = atoms.extract_xyz()
    elements = atoms.extract_element()
    conformer_indices = self.get_conformer_indices().conformer_indices
    return distance_based_connectivity.build_simple_two_way_bond_sets(
      sites_cart=sites_cart,
      elements=elements,
      conformer_indices=conformer_indices,
      fallback_expected_bond_length=fallback_expected_bond_length,
      fallback_search_max_distance=fallback_search_max_distance)

  def reset_i_seq_if_necessary(self):
    """Reset the indices of all atoms if necessary"""
    atoms = self.atoms()
    i_seqs = atoms.extract_i_seq()
    if (i_seqs.all_eq(0)):
      atoms.reset_i_seq()

  def get_peptide_c_alpha_selection(self):
    """
    Extract atom selection (flex.size_t) for protein C-alpha atoms.
    """
    result = flex.size_t()
    i_seqs = self.atoms().extract_i_seq()
    if(i_seqs.size()>1): assert i_seqs[1:].all_ne(0)
    for model in self.models():
      for chain in model.chains():
        for rg in chain.residue_groups():
          for ag in rg.atom_groups():
            if(common_residue_names_get_class(ag.resname) == "common_amino_acid"):
              for atom in ag.atoms():
                if(atom.name.strip() == "CA"):
                  result.append(atom.i_seq)
    return result

  def contains_protein(self, min_content=0, oc = None):
    """
    Inspect residue names and counts to determine if enough of them are protein.
    """
    if not oc:
      oc = self.overall_counts()
    n_prot_residues = oc.get_n_residues_of_classes(
        classes=['common_amino_acid', 'modified_amino_acid'])
    n_water_residues = oc.get_n_residues_of_classes(
        classes=['common_water'])
    if oc.n_residues-n_water_residues > 0:
      return n_prot_residues / (oc.n_residues-n_water_residues) > min_content
    return n_prot_residues > min_content

  def contains_nucleic_acid(self, min_content=0, oc = None):
    """
    Inspect residue names and counts to determine if enough of
    them are RNA or DNA.
    """
    if not oc:
      oc = self.overall_counts()
    n_na_residues = oc.get_n_residues_of_classes(
        classes=['common_rna_dna', 'modified_rna_dna'])
    n_water_residues = oc.get_n_residues_of_classes(
        classes=['common_water'])
    if oc.n_residues-n_water_residues > 0:
      return n_na_residues / (oc.n_residues-n_water_residues) > min_content
    return n_na_residues > min_content

  def contains_rna(self, oc = None):
    """
    Inspect residue names and counts to determine if any of
    them are RNA.
    """
    if not oc:
      oc = self.overall_counts()
    for resname, count in oc.resnames.items():
      if ( common_residue_names_get_class(resname) == "common_rna_dna"
          and "D" not in resname.upper() ):
        return True
    return False

  def contains_dna(self, oc = None):
    """
    Inspect residue names and counts to determine if any of
    them are DNA.
    """
    if not oc:
      oc = self.overall_counts()
    for resname, count in oc.resnames.items():
      if ( common_residue_names_get_class(resname) == "common_rna_dna"
          and "D" in resname.upper() ):
        return True
    return False

  def chain_types(self):
    """
    Inspect residue names and counts to determine what chain types are present
    """
    oc = self.overall_counts()
    chain_types = []
    if self.contains_protein(oc = oc):
      chain_types.append("PROTEIN")
    if self.contains_dna(oc = oc):
      chain_types.append("DNA")
    if self.contains_rna(oc = oc):
      chain_types.append("RNA")
    return chain_types

  def chain_type(self):
    """
    Inspect residue names and counts to determine what chain types are present
    If only one chain type, return it. Otherwise return None
    """
    chain_types = self.chain_types()
    if chain_types and len(chain_types) == 1:
      return chain_types[0]
    else:
      return None

  def first_resseq_as_int(self, chain_id = None):
    ''' Return residue number of first residue in specified chain, as integer.
        If chain not specified, first residue in hierarchy.
    '''
    for model in self.models():
      for chain in model.chains():
        if (chain_id is not None) and chain.id != chain_id: continue
        for rg in chain.residue_groups():
          return rg.resseq_as_int()

  def last_resseq_as_int(self, chain_id = None):
    ''' Return residue number of last residue in specified chain, as integer.
        If chain not specified, last residue in hierarchy.
    '''
    last_resno=None
    for model in self.models():
      for chain in model.chains():
        if (chain_id is not None) and chain.id != chain_id: continue
        for rg in chain.residue_groups():
          last_resno=rg.resseq_as_int()
    return last_resno


  def has_icodes(self):
    for m in self.models():
      for chain in m.chains():
        for rg in chain.residue_groups():
          if rg.icode and rg.icode != ' ':
            return True

  def chain_ids(self, unique_only = False):
    ''' Get list of chain IDS, return unique set if unique_only=True'''
    chain_ids=[]
    for model in self.models():
      for chain in model.chains():
        if (not unique_only) or (not chain.id in chain_ids):
          chain_ids.append(chain.id)
    return chain_ids

  def first_chain_id(self):
    ''' Get first chain ID '''
    chain_ids = self.chain_ids()
    if chain_ids:
      return chain_ids[0]
    else:
      return None

  def remove_hd(self, reset_i_seq=False):
    """
    Remove all hydrogen/deuterium atoms in-place.  Returns the number of atoms
    deleted.
    """
    n_removed = 0
    for pdb_model in self.models():
      for pdb_chain in pdb_model.chains():
        for pdb_residue_group in pdb_chain.residue_groups():
          for pdb_atom_group in pdb_residue_group.atom_groups():
            for pdb_atom in pdb_atom_group.atoms():
              if (pdb_atom.element.strip().upper() in ["H","D"]):
                pdb_atom_group.remove_atom(pdb_atom)
                n_removed += 1
            if (pdb_atom_group.atoms_size() == 0):
              pdb_residue_group.remove_atom_group(pdb_atom_group)
          if (pdb_residue_group.atom_groups_size() == 0):
            pdb_chain.remove_residue_group(pdb_residue_group)
        if (pdb_chain.residue_groups_size() == 0):
          pdb_model.remove_chain(pdb_chain)
      if (pdb_model.chains_size() == 0):
        self.remove_model(pdb_model)
    if (reset_i_seq):
      self.atoms().reset_i_seq()
    return n_removed

  def exchangeable_hd_selections(self):
    result = []
    for model in self.models():
      for chain in model.chains():
        for residue_group in chain.residue_groups():
          for i_gr1, atom_group_1 in enumerate(residue_group.atom_groups()):
            elements_group1 = [
              e.strip() for e in atom_group_1.atoms().extract_element()]
            non_H_atoms_group1 = list(set(elements_group1) - set(['H','D']))
            for i_gr2, atom_group_2 in enumerate(residue_group.atom_groups()):
              elements_group2 = [
                e.strip() for e in atom_group_2.atoms().extract_element()]
              non_H_atoms_group2 = list(set(elements_group2) - set(['H','D']))
              if non_H_atoms_group1 and non_H_atoms_group2: continue
              if(atom_group_1.altloc != atom_group_2.altloc and i_gr2 > i_gr1):
                for atom1 in atom_group_1.atoms():
                  e1 = atom1.element.strip()
                  n1 = atom1.name.strip()[1:]
                  for atom2 in atom_group_2.atoms():
                    e2 = atom2.element.strip()
                    n2 = atom2.name.strip()[1:]
                    if(e1 in ["H","D"] and e2 in ["H","D"] and e1 != e2 and
                       n1 == n2):
                      result.append([[int(atom1.i_seq)], [int(atom2.i_seq)]])
    return result

  def de_deuterate(self):
    """
    Remove all D atoms and replace with H. Keep only H at hydrogen/deuterium
    sites. Changes hierarchy in place.
    """
    atoms = self.atoms()
    # Get exchanged sites
    hd_group_selections = self.exchangeable_hd_selections()
    hd_site_d_iseqs, hd_site_h_iseqs = [], []
    for gsel in hd_group_selections:
      i,j = gsel[0][0], gsel[1][0]
      for _i in [i,j]:
        if atoms[_i].element.strip().upper() == 'D':
          hd_site_d_iseqs.append(_i)
        if atoms[_i].element.strip().upper() == 'H':
          hd_site_h_iseqs.append(_i)
    #
    get_class = iotbx.pdb.common_residue_names_get_class
    for m in self.models():
      for c in m.chains():
        for rg in c.residue_groups():
          for ag in rg.atom_groups():
            for a in ag.atoms():
              i = a.i_seq
              # remove D atoms at exchanged sites
              if a.element.strip().upper() == 'D' and i in hd_site_d_iseqs:
                ag.remove_atom(a)
                continue
              # remove D/H atoms in water and rename residue to HOH
              resname = (a.parent().resname).strip()
              if(get_class(name = resname) == "common_water"):
                if a.element.strip().upper() == 'O':
                  a.parent().resname = 'HOH'
              # reset occ and altloc for H at exchanged sites
              if a.element.strip().upper() == 'H' and i in hd_site_h_iseqs:
                a.occ = 1.0
                a.parent().altloc = ""
              # transform all other D atoms to H: change element and rename
              if a.element.strip().upper() == 'D':
                a.element = 'H'
                new_name = a.name.replace('D','H',1)
                a.name = new_name

  def is_ca_only(self):
    """
    Determine if hierarchy consists only from CA atoms.
    Upgrade options:
      - implement threshold for cases where several residues are present in
        full;
      - figure out how to deal with HETATM records of the same chain.
      - Ignore possible incorrect alignment of atom names.
    """
    result = True
    for model in self.models():
      result = result and model.is_ca_only()
    return result

bp.inject(ext.model, __hash_eq_mixin)
@bp.inject_into(ext.model)
class _():

  """
  Class representing MODEL blocks in a PDB file (or equivalent mmCIF).  There
  will always be at least one of these in a hierarchy root extracted from a
  PDB file even if no MODEL records are present.

  Example
  -------
  >>> hierarchy = iotbx.pdb.hierarchy.root()
  >>> model = iotbx.pdb.hierarchy.model(id="1")
  >>> hierarchy.append_model(model)
  >>> model = hierarchy.only_model()
  """

  def residue_groups(self):
    for chain in self.chains():
      for rg in chain.residue_groups():
        yield rg

  def atom_groups(self):
    for chain in self.chains():
      for rg in chain.residue_groups():
        for ag in rg.atom_groups():
          yield ag

  def only_chain(self):
    """Return the only chain in model. Must be only 1"""
    assert self.chains_size() == 1
    return self.chains()[0]

  def only_residue_group(self):
    """Return the only residue_group in model. Must be only 1"""
    return self.only_chain().only_residue_group()

  def only_conformer(self):
    """Return the only conformer in model. Must be only 1"""
    return self.only_chain().only_conformer()

  def only_atom_group(self):
    """Return the only atom_group in model. Must be only 1"""
    return self.only_residue_group().only_atom_group()

  def only_residue(self):
    """Return the only residue in model. Must be only 1"""
    return self.only_conformer().only_residue()

  def only_atom(self):
    """Return the only atom in model. Must be only 1"""
    return self.only_atom_group().only_atom()

  def is_ca_only(self):
    """
    Determine if hierarchy consists only from CA atoms.
    Upgrade options:
      - implement threshold for cases where several residues are present in
        full;
      - figure out how to deal with HETATM records of the same chain.
      - Ignore possible incorrect alignment of atom names.
    """
    result = True
    for chain in self.chains():
      result = result and chain.is_ca_only()
    return result

bp.inject(ext.chain, __hash_eq_mixin)
@bp.inject_into(ext.chain)
class _():

  """
  Class representing a continuous chain of atoms, as defined by the combination
  of chain ID field and TER records (or the chain index in mmCIF format).  Note
  that this does not necessarily correspond to a covalently linked entity, as
  it may be used to group various heteroatoms (including water), but
  chemically distinct protein or nucleic acid chains will typically be
  grouped into exactly one chain object apiece.
  """

  def atom_groups(self):
    """Return all atom_groups in the chain"""
    for rg in self.residue_groups():
      for ag in rg.atom_groups():
        yield ag

  def only_residue_group(self):
    """Return the only residue_group in chain. Must be only 1"""
    assert self.residue_groups_size() == 1
    return self.residue_groups()[0]

  def only_conformer(self):
    """Return the only conformer in chain. Must be only 1"""
    conformers = self.conformers()
    assert len(conformers) == 1
    return conformers[0]

  def only_atom_group(self):
    """Return the only atom_group in chain. Must be only 1"""
    return self.only_residue_group().only_atom_group()

  def only_residue(self):
    """Return the only residue in chain. Must be only 1"""
    return self.only_conformer().only_residue()

  def only_atom(self):
    """Return the only atom in chain. Must be only 1"""
    return self.only_atom_group().only_atom()

  def residues(self):
    """Return the residues in the unique conformer in this chain"""
    return self.only_conformer().residues()

  def occupancy_groups_simple(self, common_residue_name_class_only=None,
        always_group_adjacent=True):
    """Return a list of constraint groups based on occupancies.
    Each group has a list of conformers, each conformer has a list of
    atom indices."""

    result = []
    residue_groups = self.residue_groups()
    n_rg = len(residue_groups)
    done = [False] * n_rg
    def process_range(i_begin, i_end):
      isolated_var_occ = []
      groups = {}
      for i_rg in range(i_begin, i_end):
        done[i_rg] = True
        rg = residue_groups[i_rg]
        for ag in residue_groups[i_rg].atom_groups():
          altloc = ag.altloc
          if (altloc == ""):
            for atom in ag.atoms():
              if (atom.tmp < 0): continue
              if (atom.occ > 0 and atom.occ < 1):
                isolated_var_occ.append(atom.tmp)
          else:
            group = []
            for atom in ag.atoms():
              if (atom.tmp < 0): continue
              group.append(atom.tmp)
            if (len(group) != 0):
              groups.setdefault(altloc, []).extend(group)
      groups = list(groups.values())
      if (len(groups) != 0):
        for group in groups: group.sort()
        groups.sort(key=operator.itemgetter(0))
        result.append(groups)
      for i in isolated_var_occ:
        result.append([[i]])
    for i_begin,i_end in self.find_pure_altloc_ranges(
          common_residue_name_class_only=common_residue_name_class_only):
      # use always_group_adjacent
      do_this_step = True
      nc = None
      for i_rg in range(i_begin, i_end):
        rg = residue_groups[i_rg]
        n_conf = len(residue_groups[i_rg].conformers())
        if(nc is None): nc = n_conf
        else:
          if(nc != n_conf):
            do_this_step = False
      #
      if(always_group_adjacent):
        process_range(i_begin, i_end)
      else:
        if(do_this_step):
          process_range(i_begin, i_end)
    for i_rg in range(n_rg):
      if (done[i_rg]): continue
      process_range(i_rg, i_rg+1)
    result.sort(key=lambda element: element[0][0])
    return result

  def get_residue_names_and_classes(self):
    """
    Extract the residue names and counts of each residue type (protein,
    nucleic acid, etc) within the chain.

    :returns: a tuple containing a list of residue names, and a dictionary of
      residue type frequencies.
    """
    from iotbx.pdb import residue_name_plus_atom_names_interpreter
    rn_seq = []
    residue_classes = dict_with_default_0()
    for residue_group in self.residue_groups():
      # XXX should we iterate over all atom_groups or just take the first one?
      #for atom_group in residue_group.atom_groups():
      atom_group = residue_group.atom_groups()[0]
      rnpani = residue_name_plus_atom_names_interpreter(
        residue_name=atom_group.resname,
        atom_names=[atom.name for atom in atom_group.atoms()])
      rn = rnpani.work_residue_name
      rn_seq.append(rn)
      if (rn is None):
        c = None
      else:
        c = common_residue_names_get_class(name=rn)
      residue_classes[c] += 1
    return (rn_seq, residue_classes)

  def as_new_hierarchy(self):
    """Return a new hierarchy that copies this one chain"""
    new_h = iotbx.pdb.hierarchy.root()
    mm = iotbx.pdb.hierarchy.model()
    new_h.append_model(mm)
    mm.append_chain(self.detached_copy())
    return new_h

  def as_list_of_residue_names(self):
    """Return list of residue names in this chain"""
    sequence=[]
    for rg in self.residue_groups():
      for atom_group in rg.atom_groups():
        sequence.append(atom_group.resname)
        break
    return sequence

  def as_dict_of_resseq_residue_names(self, strip_resseq = True):
    """Return dictionary of residue names in this chain keyed by resseq values"""
    dd = {}
    for rg in self.residue_groups():
      for atom_group in rg.atom_groups():
        if strip_resseq:
          resseq = rg.resseq.strip()
        else:
          resseq = rg.resseq
        dd[resseq] = atom_group.resname
        break
    return dd

  def as_dict_of_resseq_as_int_residue_names(self):
    """Return dictionary of residue names in this chain keyed by resseq_as_int values"""
    dd = {}
    for rg in self.residue_groups():
      for atom_group in rg.atom_groups():
        dd[rg.resseq_as_int()] = atom_group.resname
        break
    return dd

  def as_sequence(self, substitute_unknown='X',
     substitute_unknown_na = 'N',
     ignore_all_unknown = None,
     as_string = False):
    """
    Naively extract single-character protein or nucleic acid sequence in
    this chain, without
    accounting for residue numbering.

    :param substitute_unknown: character to use for unrecognized 3-letter codes
    :param substitute_unknown_na: character to use for unrecognized na codes
    :param ignore_all_unknown: set substitute_unknown and substitute_unknown_na to ''
    :param as_string: return string (default is to return list)
    """

    if ignore_all_unknown:
      substitute_unknown = ''
      substitute_unknown_na = ''
    assert ((isinstance(substitute_unknown, str)) and
            (len(substitute_unknown) == 1))
    assert ((isinstance(substitute_unknown_na, str)) and
            (len(substitute_unknown_na) == 1))
    common_rna_dna_codes = {
      "A": "A",
      "C": "C",
      "G": "G",
      "U": "U",
      "DA": "A",
      "DC": "C",
      "DG": "G",
      "DT": "T"}
    rn_seq, residue_classes = self.get_residue_names_and_classes()
    n_aa = residue_classes["common_amino_acid"] + residue_classes["modified_amino_acid"]
    n_na = residue_classes["common_rna_dna"] + residue_classes["modified_rna_dna"]
    seq = []
    if (n_aa > n_na):
      aa_3_as_1 = one_letter_given_three_letter
      for rn in rn_seq:
        if (rn in aa_3_as_1_mod):
          seq.append(aa_3_as_1_mod.get(rn, substitute_unknown))
        else :
          seq.append(aa_3_as_1.get(rn, substitute_unknown))
    elif (n_na != 0):
      for rn in rn_seq:
        if rn not in common_rna_dna_codes and rn in na_3_as_1_mod:
          rn = na_3_as_1_mod.get(rn, "N")
        seq.append(common_rna_dna_codes.get(rn, "N"))
    if as_string:
      return "".join(seq)
    else: # usual
      return seq

  def format_fasta(self,
      max_line_length=79,
      substitute_unknown='X',
      substitute_unknown_na = 'N',
      ignore_all_unknown = None,
      as_string = False):
    ''' Format this chain as Fasta
    :param max_line_length: length of lines in formatted output
    :param substitute_unknown: character to use for unrecognized 3-letter codes
    :param substitute_unknown_na: character to use for unrecognized na codes
    :param ignore_all_unknown: set substitute_unknown and substitute_unknown_na to ''
    :param as_string: return string (default is to return list of lines)
    '''
    seq = self.as_sequence(
          substitute_unknown =substitute_unknown,
          substitute_unknown_na = substitute_unknown_na,
          ignore_all_unknown =ignore_all_unknown,
    )
    n = len(seq)
    if (n == 0): return None
    comment = [">"]
    comment.append('chain "%2s"' % self.id)
    seq_lines = [" ".join(comment)]
    i = 0
    while True:
      j = min(n, i+max_line_length)
      if (j == i): break
      seq_lines.append("".join(seq[i:j]))
      i = j

    if as_string:
      return "\n".join(seq_lines)
    else:
      return seq_lines

  def _residue_is_aa_or_na(self, residue_name, include_modified=True):
    """
    Helper function for checking if a residue is an amino acid or
    nucleic acid

    Parameters
    ----------
      residue_name: str
        The residue name
      include_modified: bool
        If set, include modified amino and nucleic acids

    Returns
    -------
      bool
        True if the residue is an amino or nucleic acid, false otherwise
    """
    residue_class = common_residue_names_get_class(residue_name)
    acceptable_classes = ['common_amino_acid', 'common_rna_dna']
    if include_modified:
      acceptable_classes += ['d_amino_acid', 'modified_amino_acid', 'modified_rna_dna']
    return residue_class in acceptable_classes

  def as_padded_sequence(self, missing_char='X', skip_insertions=False,
                         pad=True, substitute_unknown='X', pad_at_start=True,
                         ignore_hetatm=False):
    """
    Extract protein or nucleic acid sequence, taking residue numbering into
    account so that apparent gaps will be filled with substitute characters.
    """
    seq = self.as_sequence()
    padded_seq = []
    last_resseq = 0
    last_icode = " "
    i = 0
    for i, residue_group in enumerate(self.residue_groups()):
      if (skip_insertions) and (residue_group.icode != " "):
        continue
      if ignore_hetatm and not self._residue_is_aa_or_na(residue_group.unique_resnames()[0]):
        continue
      resseq = residue_group.resseq_as_int()
      if (pad) and (resseq > (last_resseq + 1)):
        for x in range(resseq - last_resseq - 1):
          if last_resseq == 0 and not pad_at_start: break
          padded_seq.append(missing_char)
      last_resseq = resseq
      padded_seq.append(seq[i])
    return "".join(padded_seq)

  def get_residue_ids(self, skip_insertions=False, pad=True, pad_at_start=True,
                      ignore_hetatm=False):
    """Return list of residue names for all residues in conformer.  Pad with
    None for residues in gaps."""
    resids = []
    last_resseq = 0
    last_icode = " "
    for i, residue_group in enumerate(self.residue_groups()):
      if (skip_insertions) and (residue_group.icode != " "):
        continue
      if ignore_hetatm and not self._residue_is_aa_or_na(residue_group.unique_resnames()[0]):
        continue
      resseq = residue_group.resseq_as_int()
      if (pad) and (resseq > (last_resseq + 1)):
        for x in range(resseq - last_resseq - 1):
          if last_resseq == 0 and not pad_at_start: break
          resids.append(None)
      last_resseq = resseq
      resids.append(residue_group.resid())
    return resids

  def get_residue_names_padded(
      self, skip_insertions=False, pad=True, pad_at_start=True,
      ignore_hetatm=False):
    """Return list of residue names for all residues in conformer.  Pad with
    None for residues in gaps."""
    resnames = []
    last_resseq = 0
    last_icode = " "
    for i, residue_group in enumerate(self.residue_groups()):
      if (skip_insertions) and (residue_group.icode != " "):
        continue
      if ignore_hetatm and not self._residue_is_aa_or_na(residue_group.unique_resnames()[0]):
        continue
      resseq = residue_group.resseq_as_int()
      if (pad) and (resseq > (last_resseq + 1)):
        for x in range(resseq - last_resseq - 1):
          if last_resseq == 0 and not pad_at_start: break
          resnames.append(None)
      last_resseq = resseq
      resnames.append(residue_group.unique_resnames()[0])
    return resnames

  def is_water(self):
    """Return True if this is entirely water"""
    for rg in self.residue_groups():
      if common_residue_names_get_class(rg.atom_groups()[0].resname) != "common_water":
        return False
    return True

  def is_protein(self, min_content=0.8, ignore_water=True):
    """
    Determine whether the chain represents an amino acid polymer, based on the
    frequency of residue names.
    Very slow due to usage of residue_name_plus_atom_names_interpreter in
    get_residue_names_and_classes (majority of the processing is unnecessary)
    """
    rn_seq, residue_classes = self.get_residue_names_and_classes()
    n_aa = residue_classes["common_amino_acid"] + residue_classes['modified_amino_acid']
    n_na = residue_classes["common_rna_dna"] + residue_classes['modified_rna_dna']
    if (ignore_water):
      while rn_seq.count("HOH") > 0 :
        rn_seq.remove("HOH")
    if (len(rn_seq) == 0):
      return False
    elif ((n_aa > n_na) and ((n_aa / len(rn_seq)) >= min_content)):
      return True
    elif (rn_seq == (["UNK"] * len(rn_seq))):
      return True
    return False

  def is_na(self, min_content=0.8, ignore_water=True):
    """
    Determine whether the chain represents a nucleic acid polymer, based on the
    frequency of base names.
    Very slow due to usage of residue_name_plus_atom_names_interpreter in
    get_residue_names_and_classes (majority of the processing is unnecessary)
    """
    rn_seq, residue_classes = self.get_residue_names_and_classes()
    n_aa = residue_classes["common_amino_acid"] + residue_classes['modified_amino_acid']
    n_na = residue_classes["common_rna_dna"] + residue_classes['modified_rna_dna']
    if (ignore_water):
      while rn_seq.count("HOH") > 0 :
        rn_seq.remove("HOH")
    if (len(rn_seq) == 0):
      return False
    elif ((n_na > n_aa) and ((n_na / len(rn_seq)) >= min_content)):
      return True
    return False

  def is_ca_only(self):
    """
    Determine if chain consists only from CA atoms.
    Upgrade options:
      - implement threshold for cases where several residues are present in
        full;
      - figure out how to deal with HETATM records of the same chain.
      - Ignore possible incorrect alignment of atom names.
    """
    atom_names = self.atoms().extract_name()
    return atom_names.all_eq(" CA ")

bp.inject(ext.residue_group, __hash_eq_mixin)
@bp.inject_into(ext.residue_group)
class _():

  def only_atom_group(self):
    """Return the only atom_group in residue_group. Must be only 1"""
    assert self.atom_groups_size() == 1
    return self.atom_groups()[0]

  def only_atom(self):
    """Return the only atom in residue_group. Must be only 1"""
    return self.only_atom_group().only_atom()

  def id_str(self):
    """Return an ID string for this residue group like 'F 5934A'"""
    chain_id = ""
    chain = self.parent()
    if (chain is not None):
      chain_id = chain.id
    return "%2s%4s%1s" % (chain_id, self.resseq, self.icode)

bp.inject(ext.atom_group, __hash_eq_mixin)
@bp.inject_into(ext.atom_group)
class _():

  def only_atom(self):
    """Return the only atom in atom_group. Must be only 1"""
    assert self.atoms_size() == 1
    return self.atoms()[0]

  # FIXME suppress_segid has no effect here
  def id_str(self, suppress_segid=None):
    """Return ID string for this atom_group like 'AGLY F 2356' """
    chain_id = ""
    resid = ""
    rg = self.parent()
    if (rg is not None):
      resid = rg.resid()
      chain = rg.parent()
      if (chain is not None):
        chain_id = chain.id
    return "%1s%3s%2s%5s" % (self.altloc, self.resname, chain_id, resid)

  def occupancy(self, raise_error_if_non_uniform=False):
    """
    Calculate the mean occupancy for atoms in this group, with option of
    raising ValueError if they differ.
    """
    atom_occupancies = self.atoms().extract_occ()
    assert (len(atom_occupancies) > 0)
    min_max_mean = atom_occupancies.min_max_mean()
    if (min_max_mean.min != min_max_mean.max):
      if (raise_error_if_non_uniform):
        raise ValueError(("Non-uniform occupancies for atom group %s "+
          "(range: %.2f - %.2f).") % (self.id_str(), min_max_mean.min,
          min_max_mean.max))
    return min_max_mean.mean

bp.inject(ext.atom, __hash_eq_mixin)
@bp.inject_into(ext.atom)
class _():
  __doc__ = """
  The basic unit of the PDB hierarchy (or the PDB input object in general),
  representing a single point scatterer corresponding to an ATOM or HETATM
  record in PDB format (plus associated ANISOU or related records if present).
  Note that this does not directly store attributes of higher-level entities
  whose identity is also recorded in ATOM records, such as the chain ID or
  residue name.  These may be retrieved either by walking up the hierarchy
  starting with atom.parent(), or by calling atom.fetch_labels().
  """
  def chain(self):
    """
    Convenience method for fetching the chain object associated with this
    atom (or None of not defined).
    """
    ag = self.parent()
    if (ag is not None):
      rg = ag.parent()
      if (rg is not None):
        return rg.parent()
    return None

  def is_in_same_conformer_as(self, other):
    """
    Indicate whether two atoms are part of the same conformer and thus are
    capable of interacting directly, as defined by the parent atom_group and
    model object(s).
    """
    ag_i = self.parent(optional=False)
    ag_j = other.parent(optional=False)
    altloc_i = ag_i.altloc
    altloc_j = ag_j.altloc
    if (    len(altloc_i) != 0
        and len(altloc_j) != 0
        and altloc_i != altloc_j):
      return False
    def p3(ag):
      return ag.parent(optional=False) \
               .parent(optional=False) \
               .parent(optional=False)
    model_i = p3(ag_i)
    model_j = p3(ag_j)
    return model_i.memory_id() == model_j.memory_id()

  def set_element_and_charge_from_scattering_type_if_necessary(self,
        scattering_type):
    """Guess the element and charge for this atom_group
    from the string representation of
    scattering_type and set them"""
    from cctbx.eltbx.xray_scattering \
      import get_element_and_charge_symbols \
        as gec
    sct_e, sct_c = gec(scattering_type=scattering_type, exact=False)
    pdb_ec = self.element.strip() + self.charge.strip()
    if (len(pdb_ec) != 0):
      if (sct_e == "" and sct_c == ""):
        return False
      pdb_e, pdb_c = gec(scattering_type=pdb_ec, exact=False)
      if (    pdb_e == sct_e
          and pdb_c == sct_c):
        return False
    self.element = "%2s" % sct_e.upper()
    self.charge = "%-2s" % sct_c
    return True

  def charge_as_int(self):
    """
    Extract the atomic charge from the (string) charge field.

    :returns: Python int, defaulting to zero
    """
    charge = self.charge_tidy()
    if charge is None:
      return 0
    if charge.endswith("-"):
      sign = -1
    else:
      sign = 1
    charge = charge.strip(" -+")
    if charge != "":
      return sign * int(charge)
    else:
      return 0

@bp.inject_into(ext.conformer)
class _():

  __doc__ = """
  Alternate view into a chain object, grouping sequential residues with
  equivalent altlocs.  As a general rule it is preferrable to iterate over
  chain.residue_groups() instead.
  """
  def only_residue(self):
    """Return the only residue in conformer. Must be only 1"""
    residues = self.residues()
    assert len(residues) == 1
    return residues[0]

  def only_atom(self):
    """Return the only atom in conformer. Must be only 1"""
    return self.only_residue().only_atom()

  def get_residue_names_and_classes(self):
    """
    Extract the residue names and counts of each residue type (protein,
    nucleic acid, etc) within the conformer
     XXX This function should probably be deprecated, since it has been
     duplicated in chain.get_residue_names_and_classes which should probably
     be preferred to this function"""
    rn_seq = []
    residue_classes = dict_with_default_0()
    for residue in self.residues():
      rnpani = residue.residue_name_plus_atom_names_interpreter()
      rn = rnpani.work_residue_name
      rn_seq.append(rn)
      if (rn is None):
        c = None
      else:
        c = common_residue_names_get_class(name=rn)
      residue_classes[c] += 1
    return (rn_seq, residue_classes)

  def is_protein(self, min_content=0.8):
    """XXX DEPRECATED.  Return True if this is protein.
    Used only in mmtbx/validation and wxtbx. Easy to eliminate."""
    rn_seq, residue_classes = self.get_residue_names_and_classes()
    n_aa = residue_classes["common_amino_acid"] + residue_classes['modified_amino_acid']
    n_na = residue_classes["common_rna_dna"] + residue_classes['modified_rna_dna']
    non_water = len(rn_seq)-residue_classes.get('common_water', 0)
    if ((n_aa > n_na) and ((n_aa / non_water) >= min_content)):
      return True
    return False

  def is_na(self, min_content=0.8):
    """XXX DEPRECATED. Return True if this is nucleic acid.
    Used only in mmtbx/validation and wxtbx. Easy to eliminate."""
    rn_seq, residue_classes = self.get_residue_names_and_classes()
    n_aa = residue_classes["common_amino_acid"] + residue_classes['modified_amino_acid']
    n_na = residue_classes["common_rna_dna"] + residue_classes['modified_rna_dna']
    non_water = len(rn_seq)-residue_classes.get('common_water', 0)
    if ((n_na > n_aa) and ((n_na / non_water) >= min_content)):
      return True
    return False

  def as_sequence(self, substitute_unknown='X'):
    """Return list with 1-letter code representation of this conformer
    This function should probably be deprecated, since it has been
    duplicated in chain.as_sequence which should probably be preferred to
    this function"""
    assert ((isinstance(substitute_unknown, str)) and
            (len(substitute_unknown) == 1))
    common_rna_dna_codes = {
      "A": "A",
      "C": "C",
      "G": "G",
      "U": "U",
      "DA": "A",
      "DC": "C",
      "DG": "G",
      "DT": "T"}
    rn_seq, residue_classes = self.get_residue_names_and_classes()
    n_aa = residue_classes["common_amino_acid"] + residue_classes["modified_amino_acid"]
    n_na = residue_classes["common_rna_dna"] + residue_classes["modified_rna_dna"]
    seq = []
    if (n_aa > n_na):
      aa_3_as_1 = one_letter_given_three_letter
      for rn in rn_seq:
        if (rn in aa_3_as_1_mod):
          seq.append(aa_3_as_1_mod.get(rn, substitute_unknown))
        else :
          seq.append(aa_3_as_1.get(rn, substitute_unknown))
    elif (n_na != 0):
      for rn in rn_seq:
        if rn not in common_rna_dna_codes and rn in na_3_as_1_mod:
          rn = na_3_as_1_mod.get(rn, "N")
        seq.append(common_rna_dna_codes.get(rn, "N"))
    return seq

  def format_fasta(self, max_line_length=79):
    """Represent conformer in fasta format. """
    seq = self.as_sequence()
    n = len(seq)
    if (n == 0): return None
    comment = [">"]
    p = self.parent()
    if (p is not None):
      comment.append('chain "%2s"' % p.id)
    comment.append('conformer "%s"' % self.altloc)
    result = [" ".join(comment)]
    i = 0
    while True:
      j = min(n, i+max_line_length)
      if (j == i): break
      result.append("".join(seq[i:j]))
      i = j
    return result

  def as_padded_sequence(self, missing_char='X', skip_insertions=False,
      pad=True, substitute_unknown='X', pad_at_start=True):
    """Represent conformer as a padded sequence (include missing_char for
    all residues in gaps in the sequence).
    XXX This function should probably be deprecated, since it has been
    duplicated in chain.as_padded_sequence which should probably be preferred
    to this function"""
    seq = self.as_sequence()
    padded_seq = []
    last_resseq = 0
    last_icode = " "
    i = 0
    for i, residue in enumerate(self.residues()):
      if (skip_insertions) and (residue.icode != " "):
        continue
      resseq = residue.resseq_as_int()
      if (pad) and (resseq > (last_resseq + 1)):
        for x in range(resseq - last_resseq - 1):
          if last_resseq == 0 and not pad_at_start: break
          padded_seq.append(missing_char)
      last_resseq = resseq
      padded_seq.append(seq[i])
    return "".join(padded_seq)

  def as_sec_str_sequence(self, helix_sele, sheet_sele, missing_char='X',
                           pad=True, pad_at_start=True):
    """Return string representing secondary structure of each residue in
     this conformer"""
    ss_seq = []
    last_resseq = 0
    for i, residue in enumerate(self.residues()):
      resseq = residue.resseq_as_int()
      if pad and resseq > (last_resseq + 1):
        for x in range(resseq - last_resseq - 1):
          if last_resseq == 0 and not pad_at_start: break
          ss_seq.append(missing_char)
      found = False
      for atom in residue.atoms():
        if helix_sele[atom.i_seq] :
          ss_seq.append('H')
          found = True
          break
        elif sheet_sele[atom.i_seq] :
          ss_seq.append('S')
          found = True
          break
      if not found :
        ss_seq.append('L')
      last_resseq = resseq
    return "".join(ss_seq)

  def get_residue_ids(self, skip_insertions=False, pad=True, pad_at_start=True):
    """Return list of resseq_as_int values representing all residues in
    this conformer.
    XXX This function should probably be deprecated, since it has been
     duplicated in chain.get_residue_ids which should probably be preferred
     to this function"""
    resids = []
    last_resseq = 0
    last_icode = " "
    for i, residue in enumerate(self.residues()):
      if (skip_insertions) and (residue.icode != " "):
        continue
      resseq = residue.resseq_as_int()
      if (pad) and (resseq > (last_resseq + 1)):
        for x in range(resseq - last_resseq - 1):
          if last_resseq == 0 and not pad_at_start: break
          resids.append(None)
      last_resseq = resseq
      resids.append(residue.resid())
    return resids

  def get_residue_names_padded(
      self, skip_insertions=False, pad=True, pad_at_start=True):
    """Return list of residue names for all residues in conformer.  Pad with
    None for residues in gaps.
     XXX This function should probably be deprecated, since it has been
     duplicated in chain.get_residue_names_padded which should probably be
     preferred to this function"""
    resnames = []
    last_resseq = 0
    last_icode = " "
    for i, residue in enumerate(self.residues()):
      if (skip_insertions) and (residue.icode != " "):
        continue
      resseq = residue.resseq_as_int()
      if (pad) and (resseq > (last_resseq + 1)):
        for x in range(resseq - last_resseq - 1):
          if last_resseq == 0 and not pad_at_start: break
          resnames.append(None)
      last_resseq = resseq
      resnames.append(residue.resname)
    return resnames


@bp.inject_into(ext.residue)
class _():

  def __getinitargs__(self):
    result_root = self.root()
    if (result_root is None):
      orig_conformer = self.parent()
      assert orig_conformer is not None
      orig_chain = orig_conformer.parent()
      assert orig_chain is not None
      orig_model = orig_chain.parent()
      assert orig_model is not None
      result_atom_group = atom_group(
        altloc=orig_conformer.altloc, resname=self.resname)
      result_residue_group = residue_group(
        resseq=self.resseq, icode=self.icode)
      result_chain = chain(id=orig_chain.id)
      result_model = model(id=orig_model.id)
      result_root = root()
      result_root.append_model(result_model)
      result_model.append_chain(result_chain)
      result_chain.append_residue_group(result_residue_group)
      result_residue_group.append_atom_group(result_atom_group)
      for atom in self.atoms():
        result_atom_group.append_atom(atom.detached_copy())
    return (result_root,)

  def standalone_copy(self):
    """Return a stand-alone copy of this residue"""
    return residue(root=self.__getinitargs__()[0])

  def only_atom(self):
    """Return the only atom in residue. Must be only 1"""
    assert self.atoms_size() == 1
    return self.atoms()[0]

  def residue_name_plus_atom_names_interpreter(self,
        translate_cns_dna_rna_residue_names=None,
        return_mon_lib_dna_name=False):
    """Return an interpreter for this residue with standard values of
     work_residue_name and atom_name_interpretation"""
    from iotbx.pdb import residue_name_plus_atom_names_interpreter
    return residue_name_plus_atom_names_interpreter(
      residue_name=self.resname,
      atom_names=[atom.name for atom in self.atoms()],
      translate_cns_dna_rna_residue_names=translate_cns_dna_rna_residue_names,
      return_mon_lib_dna_name=return_mon_lib_dna_name)


@bp.inject_into(ext.atom_with_labels)
class _():

  __doc__ = """
  Stand-in for atom object, which explicitly records the attributes normally
  reserved for parent classes such as residue name, chain ID, etc.
  """
  def __getstate__(self):
    labels_dict = {}
    for attr in [ "xyz", "sigxyz", "occ", "sigocc", "b", "sigb", "uij",
                  "siguij", "hetero", "serial", "name", "segid", "element",
                  "charge", "model_id", "chain_id", "resseq", "icode",
                  "altloc", "resname", ] :
      labels_dict[attr] = getattr(self, attr, None)
    return labels_dict

  def __setstate__(self, state):
    from iotbx.pdb import make_atom_with_labels
    state = dict(state)
    make_atom_with_labels(self, **state)

  def fetch_labels(self):
    return self

# MARKED_FOR_DELETION_OLEG
# Reason: so far found only in iotbx/file_reader.py for no clear reason.
# Tried, problems encountered:
#   - used in file_reader.any_file to return results of reading model
#   - any_file is used 100s times across all repositories including phaser, so
#     coordinated effort is needed.

class input_hierarchy_pair(object):
  """Class to map order of atoms in input model to atoms in a hierarchy"""
  def __init__(self,
               input,
               hierarchy=None,
               sort_atoms=False,
              ):
    self.input = input
    if (hierarchy is None):
      hierarchy = self.input.construct_hierarchy(
          set_atom_i_seq=True, sort_atoms=sort_atoms)
    self.hierarchy = hierarchy

  def __getinitargs__(self):
    from pickle import PicklingError
    raise PicklingError

  def hierarchy_to_input_atom_permutation(self):
    """
    Return the permutation selection
    (:py:class:`scitbx.array_family.flex.size_t`) mapping the atoms as ordered
    by the hierarchy to their original positions in the PDB/mmCIF file.
    """
    h_atoms = self.hierarchy.atoms()
    sentinel = h_atoms.reset_tmp(first_value=0, increment=1)
    return self.input.atoms().extract_tmp_as_size_t()

  def input_to_hierarchy_atom_permutation(self):
    """
    Return the permutation selection
    (:py:class:`scitbx.array_family.flex.size_t`) mapping the atoms as ordered
    in the original PDB/mmCIF file to their positions in the hierarchy.
    """
    i_atoms = self.input.atoms()
    sentinel = i_atoms.reset_tmp(first_value=0, increment=1)
    return self.hierarchy.atoms().extract_tmp_as_size_t()

  def xray_structure_simple(self, *args, **kwds):
    """
    Wrapper for the equivalent method of the input object - extracts the
    :py:class:`cctbx.xray.structure` with scatterers in the same order as in
    the hierarchy.
    """
    perm = self.input_to_hierarchy_atom_permutation()
    xrs = self.input.xray_structure_simple(*args, **kwds)
    return xrs.select(perm)

  def construct_hierarchy(self, *args, **kwds) : # TODO remove eventually
    """
    Returns a reference to the existing hierarchy.  For backwards compatibility
    only, and issues a :py:class:`warnings.DeprecationWarning`.
    """
    # import traceback
    # traceback.print_stack()
    warnings.warn("Please access input.hierarchy directly.",
      DeprecationWarning)
    return self.hierarchy

  def crystal_symmetry(self, *args, **kwds):
    return self.input.crystal_symmetry(*args, **kwds)

class input(input_hierarchy_pair):
  """
  Class used for reading a PDB hierarchy from a file or string.

  Attributes
  ----------
  input : iotbx.pdb.pdb_input_from_any
  hierarchy : iotbx.pdb.hierarchy.root

  Examples
  --------
  >>> import iotbx.pdb.hierarchy
  >>> pdb_in = iotbx.pdb.hierarchy.input(pdb_string='''
  ... ATOM      1  N   ASP A  37      10.710  14.456   9.568  1.00 15.78           N
  ... ATOM      2  CA  ASP A  37       9.318  14.587   9.999  1.00 18.38           C
  ... ''')
  >>> print pdb_in.hierarchy.atoms_size()
  2
  "")
  """

  def __init__(self, file_name=None,
      pdb_string=None, source_info=Auto, sort_atoms=True):
    """
    Initializes an input from a file or string.

    Parameters
    ----------
    file_name : str, optional
    pdb_string : str, optional
    source_info : str, optional
        Indicates where this PDB came from (i.e. "string")
    """
    assert [file_name, pdb_string].count(None) == 1
    import iotbx.pdb
    if (file_name is not None):
      assert source_info is Auto
      pdb_inp = iotbx.pdb.input(file_name=file_name)
    else:
      if (source_info is Auto): source_info = "string"
      pdb_inp = iotbx.pdb.input(
        source_info=source_info, lines=flex.split_lines(pdb_string))
    super(input, self).__init__(input=pdb_inp, sort_atoms=sort_atoms)
# END_MARKED_FOR_DELETION_OLEG

# MARKED_FOR_DELETION_OLEG
# Reason: functionality is moved to mmtbx.model and uses better all_chain_ids
# function from iotbx.pdb.utils
# Not until used in iotbx/pdb/__init__py: join_fragment_files:
# GUI app: Combine PDB files
# CL app: iotbx.pdb.join_fragment_files
def suffixes_for_chain_ids(suffixes=Auto):
  """Return suitable suffixes for chain_ids. Deprecated"""
  if (suffixes is Auto):
    suffixes="123456789" \
             "ABCDEFGHIJKLMNOPQRSTUVWXYZ" \
             "abcdefghijklmnopqrstuvwxyz"
  return suffixes

def append_chain_id_suffixes(roots, suffixes=Auto):
  """Append chain ID suffixes. Deprecated"""
  suffixes = suffixes_for_chain_ids(suffixes=suffixes)
  assert len(roots) <= len(suffixes)
  for root,suffix in zip(roots, suffixes):
    for model in root.models():
      for chain in model.chains():
        assert len(chain.id) == 1, len(chain.id)
        chain.id += suffix

def join_roots(roots, chain_id_suffixes=Auto):
  """
  Combine two root objects. Deprecated
  """
  if (chain_id_suffixes is not None):
    append_chain_id_suffixes(roots=roots, suffixes=chain_id_suffixes)
  result = root()
  for rt in roots:
    result.transfer_chains_from_other(other=rt)
  return result
# END_MARKED_FOR_DELETION_OLEG

# XXX: Nat's utility functions
# also used in ncs_search.py
def new_hierarchy_from_chain(chain):
  """
  Given a chain object, create an entirely new hierarchy object contaning only
  this chain (using a new copy).
  """
  import iotbx.pdb.hierarchy
  hierarchy = iotbx.pdb.hierarchy.root()
  model = iotbx.pdb.hierarchy.model()
  model.append_chain(chain.detached_copy())
  hierarchy.append_model(model)
  return hierarchy

def find_and_replace_chains(original_hierarchy, partial_hierarchy,
    log=sys.stdout):
  """
  Delete and replace the first chain in the original hierarchy corresponding
  to each model/ID combination in the partial hierarchy.  Note that this means
  that if waters and heteroatoms are given the same ID as a protein chain
  (separated by other chains or TER record(s)), but the partial hierarchy only
  contains a substitute protein chain, the heteroatom chain will be kept.
  """
  for original_model in original_hierarchy.models():
    for partial_model in partial_hierarchy.models():
      if original_model.id == partial_model.id :
        #print >> log, "    found model '%s'" % partial_model.id
        i = 0
        while i < len(original_model.chains()):
          original_chain = original_model.chains()[i]
          j = 0
          while j < len(partial_model.chains()):
            partial_chain = partial_model.chains()[j]
            if original_chain.id == partial_chain.id :
              #print >> log, "      found chain '%s' at index %d" % (
              #  partial_chain.id, i)
              original_model.remove_chain(i)
              original_model.insert_chain(i, partial_chain.detached_copy())
              partial_model.remove_chain(j)
              break
            j += 1
          i += 1

def get_contiguous_ranges(hierarchy):
  """Get continuous ranges within a hierarchy"""
  assert (len(hierarchy.models()) == 1)
  chain_clauses = []
  for chain in hierarchy.models()[0].chains():
    resid_ranges = []
    start_resid = None
    last_resid = None
    last_resseq = - sys.maxsize
    for residue_group in chain.residue_groups():
      resseq = residue_group.resseq_as_int()
      resid = residue_group.resid()
      if (resseq != last_resseq) and (resseq != (last_resseq + 1)):
        if (start_resid is not None):
          resid_ranges.append((start_resid, last_resid))
        start_resid = resid
        last_resid = resid
      else :
        if (start_resid is None):
          start_resid = resid
        last_resid = resid
      last_resseq = resseq
    if (start_resid is not None):
      resid_ranges.append((start_resid, last_resid))
    resid_clauses = []
    for r1, r2 in resid_ranges :
      if (r1 == r2):
        resid_clauses.append("resid %s" % r1)
      else :
        resid_clauses.append("resid %s through %s" % (r1,r2))
    sele = ("chain '%s' and ((" + ") or (".join(resid_clauses) + "))") % \
      chain.id
    chain_clauses.append(sele)
  return chain_clauses

# used for reporting build results in phenix
def get_residue_and_fragment_count(pdb_file=None, pdb_hierarchy=None):
  """Count residues and fragments in a hierarchy"""
  from libtbx import smart_open
  if (pdb_file is not None):
    raw_records = flex.std_string()
    with smart_open.for_reading(file_name=pdb_file) as f:
      lines = f.read()
    raw_records.extend(flex.split_lines(lines))
    pdb_in = iotbx.pdb.input(source_info=pdb_file, lines=raw_records)
    pdb_hierarchy = pdb_in.construct_hierarchy()
  assert (pdb_hierarchy is not None)
  models = pdb_hierarchy.models()
  if len(models) == 0 :
    return (0, 0, 0)
  chains = models[0].chains()
  if len(chains) == 0 :
    return (0, 0, 0)
  n_res = 0
  n_frag = 0
  n_h2o = 0
  for chain in chains :
    i = -999
    for res in chain.conformers()[0].residues():
      residue_type = common_residue_names_get_class(
          res.resname, consider_ccp4_mon_lib_rna_dna=True)
      if ( ('amino_acid' in residue_type) or ('rna_dna' in residue_type) ):
        n_res += 1
        resseq = res.resseq_as_int()
        if resseq > (i + 1):
          n_frag += 1
        i = resseq
      elif ('water' in residue_type):
        n_h2o += 1
  return (n_res, n_frag, n_h2o)

def sites_diff(hierarchy_1,
                hierarchy_2,
                exclude_waters=True,
                return_hierarchy=True,
                log=None):
  """
  Given two PDB hierarchies, calculate the shift of each atom (accounting for
  possible insertions/deletions) and (optionally) apply it to the B-factor for
  display in PyMOL, plotting in PHENIX GUI, etc.
  """
  if (log is None) : log = null_out()
  atom_lookup = {}
  deltas = flex.double(hierarchy_2.atoms_size(), -1.)
  for atom in hierarchy_1.atoms_with_labels():
    if (atom.resname in ["HOH", "WAT"]) and (exclude_waters):
      continue
    atom_id = atom.id_str()
    if (atom_id in atom_lookup):
      raise RuntimeError("Duplicate atom ID - can't extract coordinates.")
    atom_lookup[atom_id] = atom.xyz
  for i_seq, atom in enumerate(hierarchy_2.atoms_with_labels()):
    if (atom.resname in ["HOH", "WAT"]) and (exclude_waters):
      continue
    atom_id = atom.id_str()
    if (atom_id in atom_lookup):
      x1,y1,z1 = atom_lookup[atom_id]
      x2,y2,z2 = atom.xyz
      delta = math.sqrt((x2-x1)**2 + (y2-y1)**2 + (z2-z1)**2)
      deltas[i_seq] = delta
  if (return_hierarchy):
    hierarchy_new = hierarchy_2.deep_copy()
    hierarchy_new.atoms().set_b(deltas)
    return hierarchy_new
  else :
    return deltas

def substitute_atom_group(
    current_group,
    new_group):
  """
  Substitute sidechain atoms from one residue for another, using
  least-squares superposition to align the backbone atoms.
  Limited functionality:
    1) Amino-acids only, 2) side chain atoms only.
  """
  from scitbx.math import superpose
  new_atoms = new_group.detached_copy().atoms()
  selection_fixed = flex.size_t()
  selection_moving = flex.size_t()
  res_class = common_residue_names_get_class(current_group.resname)
  if(res_class != "common_amino_acid"):
    raise Sorry("Only common amino-acid residues supported.")
  aa_backbone_atoms_1 = [" CA ", " C  ", " N  ", " O  "]
  aa_backbone_atoms_2 = [" CA ", " C  ", " N  ", " CB "]
  aa_backbone_atoms_1.sort()
  aa_backbone_atoms_2.sort()
  #
  def get_bb_atoms(current_group, aa_backbone_atoms):
    result = []
    for atom in current_group.atoms():
      if(atom.name in aa_backbone_atoms_1):
        result.append(atom.name)
    result.sort()
    return result
  aa_backbone_atoms_current = get_bb_atoms(current_group, aa_backbone_atoms_1)
  aa_backbone_atoms_new     = get_bb_atoms(new_group, aa_backbone_atoms_1)
  if(aa_backbone_atoms_current != aa_backbone_atoms_1 or
     aa_backbone_atoms_new     != aa_backbone_atoms_1):
    outl = ''
    for atom in current_group.atoms():
      outl += '\n%s' % atom.quote()
    raise Sorry("Main chain must be complete. %s" % outl)
  #
  for i_seq, atom in enumerate(current_group.atoms()):
    if(not atom.name in aa_backbone_atoms_2): continue
    for j_seq, other_atom in enumerate(new_group.atoms()):
      if(atom.name == other_atom.name):
        selection_fixed.append(i_seq)
        selection_moving.append(j_seq)
  sites_fixed = current_group.atoms().extract_xyz().select(selection_fixed)
  sites_moving = new_atoms.extract_xyz().select(selection_moving)
  assert sites_fixed.size() == sites_moving.size()
  lsq_fit = superpose.least_squares_fit(
    reference_sites = sites_fixed,
    other_sites     = sites_moving)
  sites_new = new_atoms.extract_xyz()
  sites_new = lsq_fit.r.elems * sites_new + lsq_fit.t.elems
  new_atoms.set_xyz(sites_new)
  atom_b_iso = {}
  atom_occ = {}
  mean_b = flex.mean(current_group.atoms().extract_b())
  for atom in current_group.atoms():
    if(not atom.name in aa_backbone_atoms_1):
      current_group.remove_atom(atom)
      atom_b_iso[atom.name] = atom.b
      atom_occ[atom.name] = atom.occ
  for atom in new_atoms:
    if(not atom.name in aa_backbone_atoms_1):
      if(atom.name in atom_b_iso): atom.b = atom_b_iso[atom.name]
      else:                        atom.b = mean_b
      if(atom.name in atom_occ): atom.occ = atom_occ[atom.name]
      else:                      atom.occ = 1.
      current_group.append_atom(atom)
  current_group.resname = new_group.resname
  return current_group

def group_rounding(values, digits):
  """Round values to number of digits after the dot maintaining the sum of 1.
  Currently used for rounding occupancies, so when the total sum is != 1,
  no rounding occurs.
  Taken from: https://explainextended.com/2009/09/21/rounding-numbers-preserving-their-sum/

  Args:
      values (list): list of occupancies
      digits (integer): how many digits after the dot should be left

  Returns:
      list: rounded occupancies
  """
  def sort_index(s):
    # helper function to get sorted indices in reverse order, much like reindexing_array.
    # used here for simplicity
    return sorted(range(len(s)), key=lambda k: s[k], reverse=True)

  if len(values) < 2:
    return values
  total_occs = sum(values)
  if round(total_occs, 6) != 1:
    return values
  # Try standard rounding first.
  result = [round(i, digits) for i in values]
  if round(sum(result), digits) == 1:
    return result
  # Now when all the above failed, do the trick ourselves.
  p_10 = pow(10,digits)
  result = [i*p_10 for i in values]
  total_occs *= p_10
  sum_all_floor = sum([math.floor(i) for i in result])
  n_to_ceil = int(total_occs - sum_all_floor)
  sorted_index = sort_index([i % 1 for i in result])
  for i in range(n_to_ceil):
    result[sorted_index[i]] = math.ceil(result[sorted_index[i]])/p_10
  for i in range(n_to_ceil, len(result)):
    result[sorted_index[i]] = math.floor(result[sorted_index[i]])/p_10
  return result


 *******************************************************************************
