

 *******************************************************************************
cctbx/omz/__init__.py
"omz = unique spelling of optimization"
from __future__ import absolute_import, division, print_function


 *******************************************************************************


 *******************************************************************************
cctbx/omz/bfgs.py
from __future__ import absolute_import, division, print_function
from six.moves import range

def h0_scaling(sk, yk):
  "Nocedal & Wright (1999) Eq. 8.20; same as Eq. 9.6"
  yty = yk.dot(yk)
  assert yty > 0
  return yk.dot(sk) / yty

def h_update(hk, sk, yk):
  """Nocedal & Wright (1999) Eq. 9.2
     Pre-condition: hk must be positive definite"""
  yts = yk.dot(sk)
  assert yts > 0
  rho = 1 / yts
  v = -rho * yk.matrix_outer_product(sk)
  v.matrix_diagonal_add_in_place(1)
  hl = v.matrix_transpose_multiply(hk).matrix_multiply(v)
  hl += rho * sk.matrix_outer_product(sk)
  return hl

def b_update(bk, sk, yk):
  """Nocedal & Wright (1999) Eq. 8.19
     Pre-condition: bk must be positive definite"""
  yts = yk.dot(sk)
  assert yts > 0
  bsstb = bk.matrix_multiply(sk.matrix_outer_product(sk)).matrix_multiply(bk)
  stbs = sk.dot(bk.matrix_multiply(sk))
  assert stbs > 0
  yyt = yk.matrix_outer_product(yk)
  bl = bk - bsstb / stbs + yyt / yts
  return bl

class memory_element(object):

  __slots__ = ["s", "y", "rho"]

  def __init__(O, s, y):
    O.s = s
    O.y = y
    yts = y.dot(s)
    if (yts > 0):
      O.rho = 1 / yts
    else:
      O.rho = None

  def get(O):
    return O.s, O.y, O.rho

def hg_two_loop_recursion(memory, hk0, gk):
  """Nocedal & Wright (1999) Algorithm 9.1
     Pre-condition: hk0 must be positive definite"""
  q = gk.deep_copy()
  m = len(memory)
  alpha = [None] * m
  for i in range(m-1,-1,-1):
    s, y, rho = memory[i].get()
    alpha[i] = a = rho * s.dot(q)
    q = q - a * y
  if (hk0.is_square_matrix()):
    r = hk0.matrix_multiply(q)
  elif (hk0.is_trivial_1d()):
    r = hk0 * q
  else:
    raise ValueError("Improper hk0")
  for i in range(m):
    s, y, rho = memory[i].get()
    beta = rho * y.dot(r)
    r = r + s * (alpha[i] - beta)
  return r


 *******************************************************************************


 *******************************************************************************
cctbx/omz/cif_refine.py
from __future__ import absolute_import, division, print_function
from six.moves import range
from six.moves import zip
def report_fraction_of_negative_observations_if_any(id_code, obs):
  d = obs.data()
  n_neg = (d < 0).count(True)
  n_all = d.size()
  if (n_neg != 0 and n_all != 0):
    print(obs.info())
    print("fraction_of_negative_obs: %.6g (%d of %d)" % (
      n_neg / n_all, n_neg, n_all))
    neg = d.select(d < 0)
    pos = d.select(d >= 0)
    from cctbx.array_family import flex
    def hist(data):
      from six.moves import cStringIO as StringIO
      sio = StringIO()
      flex.histogram(data=data, n_slots=10) \
        .show(f=sio, prefix="  ", format_cutoffs="%8.2f")
      return sio.getvalue().splitlines()
    lines_neg = hist(-neg)
    lines_pos = hist(pos)
    pair_fmt = "%-35s | %s"
    print(pair_fmt % (
      "Histogram of negative observations:",
        "positive observations:"))
    for pair in zip(lines_neg, lines_pos):
      print(pair_fmt % pair)

class extract_from_cif_files(object):

  __slots__ = [
    "c_obs",
    "xray_structure",
    "non_hydrogen_selection",
    "non_hydrogen_iselection",
    "edge_list"]

  def init_slots_with_none(O):
    for slot in O.__slots__:
      setattr(O, slot, None)

  def __init__(O, report_id, refl_file, refl_cif, model_file, model_cif):
    O.init_slots_with_none()
    O.process(report_id, refl_file, refl_cif, model_file, model_cif)

  def process(O, report_id, refl_file, refl_cif, model_file, model_cif):
    from_coordinate_files = []
    from_reflection_files = []
    import iotbx.cif.builders
    def get_cs(cif, buffer):
      for cif_block in cif.model().values():
        cs = iotbx.cif.builders.crystal_symmetry_builder(
          cif_block=cif_block).crystal_symmetry
        buffer.append(cs)
    get_cs(refl_cif, from_reflection_files)
    get_cs(model_cif, from_coordinate_files)
    import cctbx.crystal
    combined_cs = cctbx.crystal.select_crystal_symmetry(
      from_coordinate_files=from_coordinate_files,
      from_reflection_files=from_reflection_files)
    if (combined_cs.unit_cell() is None):
      raise RuntimeError("Unit cell not found in both cif and hkl files.")
    if (combined_cs.space_group_info() is None):
      raise RuntimeError("Space group not found in both cif and hkl file.")
    #
    miller_arrays = refl_cif.as_miller_arrays()
    meas_a = []
    meas_i = []
    for ma in miller_arrays:
      s = str(ma.info())
      if (s.find("_meas") >= 0):
        if (ma.is_xray_intensity_array()):
          meas_i.append(ma)
        elif (ma.is_xray_amplitude_array()):
          meas_a.append(ma)
        else:
          continue
        report_fraction_of_negative_observations_if_any(report_id, ma)
    if (len(meas_i) != 0):
      O.c_obs = meas_i[0]
    elif (len(meas_a) != 0):
      O.c_obs = meas_a[0]
    else:
      raise RuntimeError("Missing diffraction data.")
    O.c_obs = O.c_obs.customized_copy(
      crystal_symmetry=combined_cs)
    print("."*79)
    O.c_obs.show_comprehensive_summary()
    print("."*79)
    #
    # TODO verify that this values is not a dictionary call
    rc = cctbx.xray.structure.from_cif(
      file_path=model_file)
    key, O.xray_structure = rc.popitem()
    O.xray_structure = O.xray_structure.customized_copy(
      crystal_symmetry=combined_cs)
    O.xray_structure.show_summary().show_scatterers()
    print("."*79)
    #
    O.non_hydrogen_selection = ~O.xray_structure.hd_selection()
    O.non_hydrogen_iselection = O.non_hydrogen_selection.iselection()
    #
    O.edge_list = O.process_geom_bond(model_cif)
    if (O.edge_list is not None):
      print("len(edge_list):", len(O.edge_list), report_id)

  def process_geom_bond(O, model_cif):
    xs = O.xray_structure
    scs = xs.scatterers()
    i_seq_by_lbl = dict(zip(scs.extract_labels(), range(scs.size())))
    if (len(i_seq_by_lbl) != scs.size()):
      return None
    edge_set = set()
    for cif_block in model_cif.model().values():
      lbl_lists = [cif_block.get("_geom_bond_atom_site_label_"+s)
        for s in "12"]
      if (lbl_lists.count(None) != 0):
        return None
      if (len(lbl_lists[0]) != len(lbl_lists[1])):
        return None
      for lbl_pair in zip(*lbl_lists):
        i_seqs = tuple(sorted([i_seq_by_lbl.get(lbl) for lbl in lbl_pair]))
        if (i_seqs.count(None) != 0):
          return None
        if (i_seqs in edge_set):
          return None
        edge_set.add(i_seqs)
    return sorted(edge_set)

def run(args):
  import cctbx.omz.dev
  import iotbx.cif
  import cctbx.xray
  #
  import random
  random.seed(0)
  from cctbx.array_family import flex
  flex.set_random_seed(0)
  #
  master_phil = cctbx.omz.dev.get_master_phil(
    iteration_limit=100,
    additional_phil_string="""\
remove_hydrogen = True
  .type = bool
f_obs_is_f_calc = True
  .type = bool
reset_u_iso = None
  .type = float
""")
  argument_interpreter = master_phil.command_line_argument_interpreter()
  phil_objects = []
  remaining_args = []
  for arg in args:
    if (arg.find("=") >= 0):
      phil_objects.append(argument_interpreter.process(arg=arg))
    else:
      remaining_args.append(arg)
  work_phil = master_phil.fetch(sources=phil_objects)
  work_phil.show()
  params = work_phil.extract()
  print()
  #
  assert len(remaining_args) == 2, "refl_cif.hkl model.cif"
  refl_file = remaining_args[0]
  model_file = remaining_args[1]
  refl_cif = iotbx.cif.reader(file_path=refl_file)
  model_cif = iotbx.cif.reader(file_path=model_file)
  #
  mgr = extract_from_cif_files(
    report_id="cif_refine",
    refl_file=refl_file,
    refl_cif=refl_cif,
    model_file=model_file,
    model_cif=model_cif)
  #
  structure_ideal = mgr.xray_structure.deep_copy_scatterers()
  structure_ideal.convert_to_isotropic()
  if (params.remove_hydrogen):
    sel = mgr.non_hydrogen_selection
    print("Removing hydrogen atoms:", sel.count(False))
    structure_ideal = structure_ideal.select(selection=sel)
    print()
  #
  c_obs = mgr.c_obs
  if (params.f_obs_is_f_calc):
    c_obs = c_obs.structure_factors_from_scatterers(
      xray_structure=structure_ideal,
      algorithm="direct",
      cos_sin_table=False).f_calc().amplitudes() \
        .set_observation_type_xray_amplitude()
  #
  assert c_obs.is_xray_intensity_array() or c_obs.is_xray_amplitude_array()
  if (c_obs.is_xray_intensity_array()):
    i_obs = c_obs
    f_obs = c_obs.f_sq_as_f(algorithm="xtal_3_7")
  else:
    f_obs = c_obs
    i_obs = c_obs.f_as_f_sq(algorithm="shelxl")
  #
  structure_shake = structure_ideal.deep_copy_scatterers()
  structure_shake.shake_sites_in_place(rms_difference=params.shake_sites_rmsd)
  if (params.reset_u_iso is None):
    structure_shake.shake_adp(spread=params.shake_adp_spread)
  else:
    structure_shake.set_u_iso(value=params.reset_u_iso)
  #
  cctbx.omz.dev.run_refinement(
    structure_ideal=structure_ideal,
    structure_shake=structure_shake,
    params=params,
    f_obs=f_obs,
    i_obs=i_obs)

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/omz/cod_refine.py
from __future__ import absolute_import, division, print_function
from cctbx import omz
import cctbx.omz.dev
from cctbx.array_family import flex
from libtbx.test_utils import approx_equal
from libtbx import easy_run
from libtbx import easy_pickle
from libtbx.utils import date_and_time, user_plus_sys_time
import libtbx.load_env
from libtbx import Auto
from six.moves import cStringIO as StringIO
import traceback
import sys, os
from six.moves import range
from six.moves import zip
op = os.path

def get_master_phil(
      max_atoms=99,
      f_calc_options_algorithm="*direct fft",
      bulk_solvent_correction=False):
  return omz.dev.get_master_phil(
    iteration_limit=100,
    show_distances_threshold=0.5,
    bulk_solvent_correction=bulk_solvent_correction,
    grads_mean_sq_threshold=1e-6,
    f_calc_options_algorithm=f_calc_options_algorithm,
    additional_phil_string="""\
      max_atoms = %(max_atoms)s
        .type = int
      f_obs_f_calc_fan_outliers = *remove keep
        .type = choice
        .optional = False
      use_f_calc_as_f_obs = False
        .type = bool
      reset_u_iso = 0.05
        .type = float
      sites_mod_short = True
        .type = bool
      optimizers = *dev ls_simple ls_lm shelxl_fm shelxl_cg shelx76
        .type = choice(multi=True)
      ls_simple_iterations = 12
        .type = int
      shelxl_wght = None
        .type = str
        .help = '''
          SHELX-97 Manual 7-31:
            Refinement against F2 requires different weights to refinement
            against F; in particular, making all the weights equal ('unit
            weights'), although useful in the initial stages of refinement
            against F, is NEVER a sensible option for F2.'''
      shelxl_reset_sigmas = None
        .type = float
      shelxl_fm_iterations = 12
        .type = int
      shelxl_cg_iterations = 12
        .type = int
      shelx76_iterations = 12
        .type = int
      apply_iteration_limit_to_all = False
        .type = bool
      keep_tmp_files = False
        .type = bool
      export_refined = False
        .type = bool
      pickle_refined_dir = None
        .type = str
      wdir_root = None
        .type = str
      sorting_of_pickle_files = *down up
        .type = choice
        .optional = True
      random_subset {
        size = None
          .type = int
        seed = 0
          .type = int
      }
      tardy_samples {
        iq = None
          .type = int
        qmin = -180
          .type = float
        qmax = 180
          .type = float
        qstep = 3
          .type = float
      }
""" % vars())

def shelxl_weights_a_b(fo_sq, sigmas, fc_sq, osf_sq, a, b):
  assert sigmas.size() == fo_sq.size()
  assert fc_sq.size() == fo_sq.size()
  from cctbx.xray.targets.tst_shelxl_wght_ls import calc_w
  assert sigmas.all_ge(0.01)
  return calc_w(
    wa=a, wb=b, i_obs=fo_sq, i_sig=sigmas, i_calc=fc_sq, k=osf_sq**0.5)

def shelxl_weights(fo_sq, sigmas, fc_sq, osf_sq, shelxl_wght):
  if (shelxl_wght is None):
    shelxl_wght = ""
  vals = [float(s) for s in shelxl_wght.split()]
  assert len(vals) <= 6
  a, b, c, d, e, f = vals + [0.1, 0, 0, 0, 0, 0.33333][len(vals):]
  assert c == 0
  assert d == 0
  assert e == 0
  assert f == 0.33333
  return shelxl_weights_a_b(fo_sq, sigmas, fc_sq, osf_sq, a, b)

def show_cc_r1(
      params,
      label,
      f_obs,
      xray_structure=None,
      fc_abs=None,
      scale_factor=Auto):
  assert [xray_structure, fc_abs].count(None) == 1
  if (fc_abs is None):
    p = params.f_calc_options
    fc_abs = f_obs.structure_factors_from_scatterers(
      xray_structure=xray_structure,
      algorithm=p.algorithm,
      cos_sin_table=p.cos_sin_table).f_calc().amplitudes()
  corr = flex.linear_correlation(x=f_obs.data(), y=fc_abs.data())
  assert corr.is_well_defined()
  cc = corr.coefficient()
  r1 = f_obs.r1_factor(
    other=fc_abs, scale_factor=scale_factor, assume_index_matching=True)
  print("%-12s cc, r1: %.4f %.4f" % (label, cc, r1))
  sys.stdout.flush()
  return fc_abs, cc, r1

def run_smtbx_ls(mode, cod_id, i_obs, f_obs, xray_structure, params):
  import smtbx.refinement
  fo_sq = i_obs
  assert fo_sq.sigmas() is not None
  sel = (fo_sq.data() == 0) & (fo_sq.sigmas() == 0)
  fo_sq = fo_sq.select(~sel)
  fo_sq.select(fo_sq.sigmas() <= 0).show_array()
  assert fo_sq.sigmas().all_gt(0)
  if (1): # work around bug currently in smtbx weighting scheme implementation
    fo_sq = fo_sq.customized_copy(sigmas=flex.double(fo_sq.data().size(), 1))
  xobs = fo_sq.as_xray_observations()
  tm = user_plus_sys_time()
  rm = smtbx.refinement.model(
    fo_sq=xobs,
    xray_structure=xray_structure,
    constraints=[],
    restraints_manager=smtbx.refinement.restraints.manager(),
    weighting_scheme=smtbx.refinement.least_squares.unit_weighting())
  ls = rm.least_squares()
  if (mode == "simple"):
    for i_cycle in range(params.ls_simple_iterations):
      ls.build_up()
      try:
        ls.solve_and_step_forward()
      except RuntimeError as e:
        if (str(e).find("cholesky.failure") <= 0): raise
        print('Aborting run_smtbx_ls("simple"): cholesky.failure: %s' \
          % cod_id)
        break
      for sc in xray_structure.scatterers():
        if (sc.u_iso <= 0 or sc.u_iso > 1):
          sc.u_iso = 0.05
      show_cc_r1(params, "ls%02d" % (i_cycle+1), f_obs, xray_structure)
    tm.show_elapsed(prefix="time smtbx_ls_simple_iterations: ")
  elif (mode == "lm"):
    from scitbx.lstbx import normal_eqns_solving
    thresh = 1e-6
    try:
      cycles = normal_eqns_solving.levenberg_marquardt_iterations(
        ls,
        gradient_threshold=thresh,
        step_threshold=thresh,
        tau=1e-7)
    except RuntimeError as e:
      if (not str(e).startswith(
            "cctbx::adptbx::debye_waller_factor_exp: arg_limit exceeded")):
        raise
      print('Aborting run_smtbx_ls("lm"):' \
        ' debye_waller_factor_exp failure: %s' % cod_id)
    show_cc_r1(params, "smtbx_lm", f_obs, xray_structure)
    tm.show_elapsed(prefix="time levenberg_marquardt_iterations: ")
  else:
    raise RuntimeError('Unknown run_smtbx_ls(mode="%s")' % mode)

def remove_tmp_files(file_names):
  for fn in file_names:
    if (op.isfile(fn)):
      os.remove(fn)
    assert not op.exists(fn)

def run_shelxl(
      mode,
      cod_id,
      i_obs,
      f_obs,
      xray_structure,
      params,
      reference_structure,
      expected_n_refinable_parameters):
  if (mode == "fm"):
    if (params.apply_iteration_limit_to_all):
      fm_cycles = params.iteration_limit
    else:
      fm_cycles = params.shelxl_fm_iterations
    cg_cycles = None
  elif (mode == "cg"):
    fm_cycles = None
    if (params.apply_iteration_limit_to_all):
      cg_cycles = params.iteration_limit
    else:
      cg_cycles = params.shelxl_cg_iterations
  else:
    raise RuntimeError("Unknown mode: " + mode)
  cwd_orig = os.getcwd()
  wdir = "wdir_%s_shelxl_%s_%s" % (cod_id, mode, os.getpid())
  if (params.wdir_root is not None):
    wdir = op.join(params.wdir_root, wdir)
  wdir_is_new = False
  if (not op.isdir(wdir)):
    os.mkdir(wdir)
    wdir_is_new = True
  remove_wdir = False
  try:
    os.chdir(wdir)
    tmp_file_names = ["tmp.ins", "tmp.hkl", "tmp.res", "tmp.lst"]
    remove_tmp_files(tmp_file_names)
    fo_sq = i_obs
    if (params.shelxl_reset_sigmas):
      fo_sq = fo_sq.customized_copy(
        sigmas=flex.double(fo_sq.indices().size(), params.shelxl_reset_sigmas))
    import iotbx.shelx
    open("tmp.ins", "w").writelines(iotbx.shelx.writer.generator(
      xray_structure=xray_structure,
      data_are_intensities=True,
      title="cod_id=%s mode=%s" % (cod_id, mode),
      wavelength=fo_sq.minimum_wavelength_based_on_d_min(),
      full_matrix_least_squares_cycles=fm_cycles,
      conjugate_gradient_least_squares_cycles=cg_cycles,
      weighting_scheme_params=params.shelxl_wght,
      sort_scatterers=False))
    fo_sq.export_as_shelx_hklf(file_object=open("tmp.hkl", "w"))
    import iotbx.shelx.hklf
    fo_sq = iotbx.shelx.hklf.reader(file_name="tmp.hkl") \
      .as_miller_arrays(crystal_symmetry=fo_sq)[0]
    buffers = easy_run.fully_buffered("shelxl tmp")
    buffers.raise_if_errors()
    refinement_unstable = False
    for line in buffers.stdout_lines:
      if (line.find("** REFINEMENT UNSTABLE **") >= 0):
        refinement_unstable = True
        print("Aborted: shelxl %s refinement unstable: %s" % (mode, cod_id))
        break
    res = open("tmp.res").read()
    try:
      refined = xray_structure.from_shelx(
        file=StringIO(res),
        min_distance_sym_equiv=0,
        strictly_shelxl=False)
    except iotbx.shelx.error as e:
      if (str(e).find("scatterer parameter") < 0):
        raise
      print("Aborted: shelxl %s refinement apparently unstable: %s" % (
        mode, cod_id))
      refined = None
    if (refined is not None):
      assert refined.crystal_symmetry().is_similar_symmetry(
        xray_structure)
      for sc,rsc in zip(xray_structure.scatterers(), refined.scatterers()):
        assert rsc.label == sc.label
        assert approx_equal(rsc.occupancy, sc.weight(), 1e-4)
        rsc.occupancy = sc.occupancy # XXX bug in res file reader
      def check_special_positions():
        result = True
        uc = xray_structure.unit_cell()
        sstab = xray_structure.site_symmetry_table()
        for i_sc in xray_structure.special_position_indices():
          sc = refined.scatterers()[i_sc]
          site_symmetry = sstab.get(i_sc)
          assert not site_symmetry.is_point_group_1()
          site_special = site_symmetry.special_op() * sc.site
          d = uc.mod_short_distance(sc.site, site_special)
          if (d > 1e-3):
            print("site moved off special position:")
            print("  %s" % sc.label)
            print("    shelxl res: %11.6f %11.6f %11.6f" % sc.site)
            print("    special_op: %11.6f %11.6f %11.6f" % site_special)
            print("    distance moved: %.3f" % d)
            result = False
        return result
      assert check_special_positions()
      xray_structure.replace_scatterers(refined.scatterers())
      res_osf = None
      res_hkl_count = None
      res_r1 = None
      res_n_parameters = None
      res_n_restraints = None
      for line in res.splitlines():
        if (line.startswith("FVAR ")):
          flds = line.split()
          assert len(flds) == 2
          res_osf = float(flds[1])
          continue
        if (not line.startswith("REM ")): continue
        assert not refinement_unstable
        if (line.startswith("REM R1 =")):
          flds = line.split()
          assert len(flds) == 15
          res_hkl_count = int(flds[13])
          res_r1 = float(flds[10])
        elif (line.find(" parameters refined ") >= 0):
          assert line.endswith(" restraints")
          flds = line.split()
          assert len(flds) == 7
          res_n_parameters = int(flds[1])
          res_n_restraints = int(flds[-2])
      if (not refinement_unstable):
        assert res_osf is not None
        assert res_hkl_count is not None
        assert res_r1 is not None
        assert res_n_parameters is not None
        assert res_n_restraints is not None
        #
        assert res_hkl_count == fo_sq.indices().size()
        def raise_unexpected_restraints(n_expected):
          raise RuntimeError(
            "Unexpected number of SHELXL restraints: %d (vs. %d expected)" % (
              res_n_restraints, n_expected))
        if (mode == "fm"):
          n_caos = fo_sq.space_group_info() \
            .number_of_continuous_allowed_origin_shifts()
          if (res_n_restraints != n_caos):
            sg_symbol = str(fo_sq.space_group_info())
            if (sg_symbol in ["P 63 m c", "P 63 c m"]):
              assert n_caos == 1
              assert res_n_restraints == 0
              print("INFO: SHELXL restraint count incorrect? code_code:", \
                cod_id)
            else:
              raise_unexpected_restraints(n_caos)
        elif (mode == "cg"):
          if (res_n_restraints != 0):
            raise_unexpected_restraints(0)
        else:
          raise RuntimeError("Unknown mode: " + mode)
        assert res_n_parameters == expected_n_refinable_parameters + 1
        fc_abs, _, r1_fvar = show_cc_r1(
          params, "fvar_"+mode, f_obs, xray_structure, scale_factor=res_osf)
        r1_diff = r1_fvar - res_r1
        print("R1 recomputed - shelxl_%s.res: %.4f - %.4f = %.4f %s" % (
          mode, r1_fvar, res_r1, r1_diff, cod_id))
        if (abs(r1_diff) > 0.01):
          raise RuntimeError("R1 MISMATCH %s" % cod_id)
        _, _, r1_auto = show_cc_r1(
          params, "shelxl_"+mode, f_obs, fc_abs=fc_abs)
        print("R1 FVAR-Auto %s: %.4f" % (cod_id, r1_fvar - r1_auto))
        #
        lst_r1 = None
        lst_wr2 = None
        for line in open("tmp.lst").read().splitlines():
          l = line.strip()
          if (l.startswith("R1 = ")):
            lst_r1 = float(l.split()[9])
          elif (l.startswith("wR2 = ") and l.endswith(" for all data")):
            lst_wr2 = float(l.replace(","," ").split()[2])
        assert lst_r1 is not None
        assert lst_wr2 is not None
        assert lst_r1 == res_r1
        #
        fc_sq = fc_abs.f_as_f_sq()
        weights = shelxl_weights(
          fo_sq=fo_sq.data(),
          sigmas=fo_sq.sigmas(),
          fc_sq=fc_sq.data(),
          osf_sq=res_osf**2,
          shelxl_wght=params.shelxl_wght)
        num = flex.sum(
          weights * flex.pow2(fo_sq.data() / res_osf**2 - fc_sq.data()))
        den = flex.sum(
          weights * flex.pow2(fo_sq.data() / res_osf**2))
        assert den != 0
        wr2 = (num / den)**0.5
        wr2_diff = wr2 - lst_wr2
        if (abs(wr2_diff) > 0.01):
          info = " significantly different"
        else:
          info = ""
        print("wR2 recomputed - shelxl_%s.lst: %.4f - %.4f = %.4f %s%s" % (
          mode, wr2, lst_wr2, wr2_diff, cod_id, info))
        if (abs(wr2_diff) / max(lst_wr2, wr2) > 0.2):
          raise RuntimeError("wR2 MISMATCH %s" % cod_id)
    if (not params.keep_tmp_files):
      remove_tmp_files(tmp_file_names)
      remove_wdir = wdir_is_new
  finally:
    os.chdir(cwd_orig)
    if (remove_wdir):
      try: os.rmdir(wdir)
      except Exception: pass

def run_shelx76(
      cod_id,
      f_obs,
      xray_structure,
      fvars,
      encoded_sites,
      params,
      reference_structure):
  if (params.apply_iteration_limit_to_all):
    ls_cycles = params.iteration_limit
  else:
    ls_cycles = params.shelx76_iterations
  cwd_orig = os.getcwd()
  wdir = "wdir_%s_shelx76_%s" % (cod_id, os.getpid())
  if (params.wdir_root is not None):
    wdir = op.join(params.wdir_root, wdir)
  wdir_is_new = False
  if (not op.isdir(wdir)):
    os.mkdir(wdir)
    wdir_is_new = True
  remove_wdir = False
  try:
    os.chdir(wdir)
    tmp_file_names = [
      "tmp.ins", "tmp.lst", "fort.2", "fort.3", "fort.4", "fort.7"]
    remove_tmp_files(tmp_file_names)
    assert not op.exists("tmp.ins")
    from cctbx.development import run_shelx76
    run_shelx76.write_shelx76_ls(
      f_obs=f_obs,
      xray_structure=xray_structure,
      fvars=fvars,
      encoded_sites=encoded_sites,
      l_s_parameters=str(ls_cycles))
    assert op.exists("tmp.ins")
    buffers = easy_run.fully_buffered("shelx76 < tmp.ins > tmp.lst")
    buffers.raise_if_errors_or_output()
    lst = open("tmp.lst").read().splitlines()
    r_from_lst = None
    for line in lst:
      l = line.lstrip()
      if (l.startswith("R = ")):
        print(l)
        flds = l.split()
        assert len(flds) == 12
        if (flds[2].lower() == "nan"):
          print("Aborted: shelx76 refinement apparently unstable: %s" % (
            cod_id))
          r_from_lst = "nan"
          break
        r_from_lst = float(flds[2])
    assert r_from_lst is not None
    if (r_from_lst != "nan"):
      print("%-12s cc, r1: None %.4f" % ("shelx76", r_from_lst))
      if (not params.keep_tmp_files):
        remove_tmp_files(tmp_file_names)
        remove_wdir = wdir_is_new
  finally:
    os.chdir(cwd_orig)
    if (remove_wdir):
      try: os.rmdir(wdir)
      except Exception: pass

def process(params, pickle_file_name):
  cod_id = op.basename(pickle_file_name).split(".",1)[0]
  print("cod_id:", cod_id)
  c_obs, structure_prep, edge_list = easy_pickle.load(
    file_name=pickle_file_name)
  changes = structure_prep.make_scatterer_labels_shelx_compatible_in_place()
  if (params.sites_mod_short):
    structure_prep = structure_prep.sites_mod_short()
  from iotbx.shelx import fvar_encoding
  structure_prep = \
    fvar_encoding.move_sites_if_necessary_for_shelx_fvar_encoding(
      xray_structure=structure_prep)
  structure_prep.show_summary().show_scatterers()
  if (len(changes) != 0):
    from libtbx.utils import plural_s
    print("INFO: %d atom name%s changed for compatibility with SHELXL:" \
      % plural_s(len(changes)))
    for change in changes:
      print('  changed: "%s" -> "%s"' % change)
  structure_prep.scattering_type_registry(table="it1992").show()
  fvar_encoding.dev_build_shelx76_fvars(structure_prep) # only an exercise
  print("."*79)
  #
  if (len(params.optimizers) == 0):
    return
  #
  assert c_obs.is_xray_intensity_array() or c_obs.is_xray_amplitude_array()
  if (c_obs.is_xray_intensity_array()):
    i_obs = c_obs
    f_obs = c_obs.f_sq_as_f(algorithm="xtal_3_7")
  else:
    f_obs = c_obs
    i_obs = c_obs.f_as_f_sq(algorithm="shelxl")
  process_continue(
    params=params,
    cod_id=cod_id,
    c_obs=c_obs, i_obs=i_obs, f_obs=f_obs,
    structure_prep=structure_prep)

def process_continue(params, cod_id, c_obs, i_obs, f_obs, structure_prep):
  p = params.f_calc_options
  f_calc = f_obs.structure_factors_from_scatterers(
    xray_structure=structure_prep,
    algorithm=p.algorithm,
    cos_sin_table=p.cos_sin_table).f_calc()
  sel = f_obs.f_obs_f_calc_fan_outlier_selection(f_calc=f_calc)
  assert sel is not None
  n_outliers = sel.count(True)
  if (n_outliers != 0):
    action = params.f_obs_f_calc_fan_outliers
    print("INFO: f_obs_f_calc_fan_outliers = %s: %d" % (action, n_outliers))
    if (action == "remove"):
      i_obs = i_obs.select(~sel)
      f_obs = f_obs.select(~sel)
  if (f_obs.anomalous_flag()):
    print("INFO: converting anomalous i+f_obs to non-anomalous.")
    i_obs = i_obs.average_bijvoet_mates()
    f_obs = f_obs.average_bijvoet_mates()
  sel = ((i_obs.data() == 0) & (i_obs.sigmas() == 0)) \
      | ((f_obs.data() == 0) & (f_obs.sigmas() == 0))
  n_zero_d_and_s = sel.count(True)
  if (n_zero_d_and_s != 0):
    print("INFO: removing reflections with i+f_obs=0 and sigma=0:", \
      n_zero_d_and_s)
    i_obs = i_obs.select(~sel)
    f_obs = f_obs.select(~sel)
  p = params.f_calc_options
  f_calc = f_obs.structure_factors_from_scatterers(
    xray_structure=structure_prep,
    algorithm=p.algorithm,
    cos_sin_table=p.cos_sin_table).f_calc()
  if (params.use_f_calc_as_f_obs):
    print("INFO: using f_calc as i+f_obs")
    i_obs = f_calc.intensities().customized_copy(
      sigmas=flex.double(f_calc.indices().size(), 0.01))
    f_obs = f_calc.amplitudes().customized_copy(
      sigmas=flex.double(f_calc.indices().size(), 0.01))
  else:
    # scaling applied so that the data written in shelx hklf format
    # have sufficient significant digits, and FVAR is 1 (shelx76 seems
    # to be especially sensitive to FVAR >> 1)
    k = f_obs.scale_factor(f_calc=f_calc)
    assert k != 0
    s = 1/k**2
    print("INFO: scaling i_obs to f_calc by multiplying i_obs with: %.6g" % s)
    i_obs = i_obs.apply_scaling(factor=s)
    s = 1/k
    print("INFO: scaling f_obs to f_calc by multiplying f_obs with: %.6g" % s)
    f_obs = f_obs.apply_scaling(factor=s)
  def show(obs):
    obs.show_comprehensive_summary()
    from cctbx.omz.cif_refine import \
      report_fraction_of_negative_observations_if_any as _
    _(cod_id, obs)
  if (c_obs.is_xray_intensity_array()):
    show(i_obs)
  else:
    show(f_obs)
  print("."*79)
  #
  structure_work = structure_prep.deep_copy_scatterers()
  sel = structure_work.hd_selection()
  print("Removing hydrogen atoms:", sel.count(True))
  structure_work = structure_work.select(selection=~sel)
  sdt = params.show_distances_threshold
  if (sdt > 0):
    print("Distances smaller than %.6g A:" % sdt)
    structure_work.show_distances(distance_cutoff=sdt)
    print("."*79)
  #
  if (params.tardy_samples.iq is not None):
    from cctbx.omz import tardy_adaptor
    print()
    tardy_adaptor.sample_e_pot(
      id_code=cod_id,
      f_obs=f_obs,
      xray_structure=structure_prep,
      edge_list=edge_list,
      params=params.tardy_samples)
    print()
    return
  #
  from iotbx.shelx import fvar_encoding
  fvars, encoded_sites = fvar_encoding.dev_build_shelx76_fvars(structure_work)
  print("Number of FVARs for special position constraints:", len(fvars)-1)
  print("."*79)
  #
  show_cc_r1(params, "prep", f_obs, structure_prep)
  def cc_r1(label):
    show_cc_r1(params, label, f_obs, structure_work)
  cc_r1("no_h")
  structure_work.convert_to_isotropic()
  cc_r1("iso")
  structure_iso = structure_work.deep_copy_scatterers()
  #
  if (params.reset_u_iso is not None):
    structure_work.set_u_iso(value=params.reset_u_iso)
    cc_r1("setu")
  if (params.shake_sites_rmsd is not None):
    mt = flex.mersenne_twister(seed=0)
    structure_work.shift_sites_in_place(
      shift_length=params.shake_sites_rmsd,
      mersenne_twister=mt)
    print("rms difference after shift_sites_in_place: %.3f" \
      % structure_iso.rms_difference(structure_work))
    cc_r1("shift_xyz")
  #
  if (params.max_atoms is not None):
    n = structure_work.scatterers().size()
    if (n > params.max_atoms):
      print("Skipping refinement of large model: %d atoms COD %s" % (
        n, cod_id))
      return
  #
  structure_work.scatterers().flags_set_grads(state=False)
  for sc in structure_work.scatterers():
    sc.flags.set_grad_site(True)
    assert sc.flags.use_u_iso_only()
    sc.flags.set_grad_u_iso(True)
  n_refinable_parameters = structure_work.n_parameters(
    considering_site_symmetry_constraints=True)
  print("Number of refinable parameters:", n_refinable_parameters)
  #
  if (params.iteration_limit < 1):
    return
  #
  if ("dev" not in params.optimizers):
    structure_dev = None
  else:
    structure_dev = structure_work.deep_copy_scatterers()
    omz.dev.refinement(
      i_obs=i_obs,
      f_obs=f_obs,
      xray_structure=structure_dev,
      params=params,
      reference_structure=structure_iso,
      expected_n_refinable_parameters=n_refinable_parameters,
      plot_samples_id=cod_id)
    show_cc_r1(params, "dev", f_obs, structure_dev)
    if (params.export_refined):
      file_name = "dev_%s_%s_%s.pdb" % (
        params.target_type, params.target_obs_type.lower(), cod_id)
      open(file_name, "w").write(structure_dev.as_pdb_file(
        remarks=[file_name]))
    if (params.pickle_refined_dir is not None):
      easy_pickle.dump(
        file_name=op.join(params.pickle_refined_dir, cod_id+".pickle"),
        obj=(c_obs, structure_dev, None))
      print((
        structure_dev.scatterers().size(),
        c_obs.space_group().order_p(),
        c_obs.indices().size(),
        c_obs.d_min()), file=open("%s/qi_%s" % (params.pickle_refined_dir, cod_id), "w"))
  #
  def use_smtbx_ls(mode):
    if ("ls_"+mode not in params.optimizers):
      return None
    if (not libtbx.env.has_module(name="smtbx")):
      print("INFO: smtbx not available: refinement skipped.")
      return None
    result = structure_work.deep_copy_scatterers()
    run_smtbx_ls(
      mode=mode,
      cod_id=cod_id,
      i_obs=i_obs,
      f_obs=f_obs,
      xray_structure=result,
      params=params)
    show_cc_r1(params, "ls_"+mode, f_obs, result)
    return result
  structure_ls_simple = use_smtbx_ls("simple")
  structure_ls_lm = use_smtbx_ls("lm")
  #
  def use_shelxl(mode):
    if ("shelxl_"+mode not in params.optimizers):
      return None
    result = structure_work.deep_copy_scatterers()
    run_shelxl(
      mode=mode,
      cod_id=cod_id,
      i_obs=i_obs,
      f_obs=f_obs,
      xray_structure=result,
      params=params,
      reference_structure=structure_iso,
      expected_n_refinable_parameters=n_refinable_parameters)
    if (params.export_refined):
      file_name = "shelxl_%s_%s.pdb" % (mode, cod_id)
      open(file_name, "w").write(result.as_pdb_file(
        remarks=[file_name]))
    return result
  structure_shelxl_fm = use_shelxl("fm")
  structure_shelxl_cg = use_shelxl("cg")
  #
  if ("shelx76" not in params.optimizers):
    structure_shelx76 = None
  else:
    structure_shelx76 = structure_work.deep_copy_scatterers()
    run_shelx76(
      cod_id=cod_id,
      f_obs=f_obs,
      xray_structure=structure_shelx76,
      fvars=fvars,
      encoded_sites=encoded_sites,
      params=params,
      reference_structure=structure_iso)
    if (params.export_refined):
      file_name = "shelx76_%s.pdb" % cod_id
      open(file_name, "w").write(structure_shelx76.as_pdb_file(
        remarks=[file_name]))

def run(args):
  from iotbx.option_parser import option_parser as iotbx_option_parser
  import libtbx.utils
  show_times = libtbx.utils.show_times(time_start="now")
  command_call = ["iotbx.python", __file__]
  command_line = (iotbx_option_parser(
    usage=" ".join(command_call) + " [options] directory|file...")
    .enable_chunk(easy_all=True)
    .enable_multiprocessing()
  ).process(args=args, min_nargs=1)
  if (command_line.run_multiprocessing_chunks_if_applicable(
        command_call=command_call)):
    show_times()
    return
  co = command_line.options
  #
  print("TIME BEGIN cod_refine:", date_and_time())
  print()
  #
  master_phil = get_master_phil()
  argument_interpreter = master_phil.command_line_argument_interpreter()
  phil_objects = []
  remaining_args = []
  for arg in command_line.args:
    if (arg.find("=") >= 0):
      phil_objects.append(argument_interpreter.process(arg=arg))
    else:
      remaining_args.append(arg)
  work_phil = master_phil.fetch(sources=phil_objects)
  work_phil.show()
  print()
  params = work_phil.extract()
  #
  qi_dict = {}
  all_pickles = []
  for arg in remaining_args:
    if (op.isdir(arg)):
      for node in sorted(os.listdir(arg)):
        if (node.endswith(".pickle")):
          all_pickles.append(op.join(arg, node))
        elif (node.startswith("qi_") and len(node) == 10):
          qi = open(op.join(arg, node)).read().splitlines()
          if (len(qi) == 1):
            cod_id = node[3:]
            quick_info = eval(qi[0])
            assert cod_id not in qi_dict
            qi_dict[cod_id] = quick_info
    elif (op.isfile(arg)):
      all_pickles.append(arg)
    else:
      raise RuntimeError("Not a file or directory: %s" % arg)
  print("Number of pickle files:", len(all_pickles))
  print("Number of quick_infos:", len(qi_dict))
  sort_choice = params.sorting_of_pickle_files
  if (len(qi_dict) != 0 and sort_choice is not None):
    print("Sorting pickle files by n_atoms * n_refl:", sort_choice)
    assert sort_choice in ["down", "up"]
    def sort_pickle_files():
      if (sort_choice == "down"): i_sign = -1
      else:                       i_sign = 1
      buffer = []
      for i,path in enumerate(all_pickles):
        cod_id = op.basename(path).split(".",1)[0]
        qi = qi_dict.get(cod_id)
        if (qi is None): nn = 2**31
        else:            nn = qi[0] * qi[1] * qi[2]
        buffer.append((nn, i_sign*i, path))
      buffer.sort()
      if (i_sign < 0):
        buffer.reverse()
      result = []
      for elem in buffer:
        result.append(elem[-1])
      return result
    all_pickles = sort_pickle_files()
  print()
  #
  rss = params.random_subset.size
  if (rss is not None and rss > 0):
    seed = params.random_subset.seed
    print("Selecting subset of %d pickle files using random seed %d" % (
      rss, seed))
    mt = flex.mersenne_twister(seed=seed)
    perm = mt.random_permutation(size=len(all_pickles))[:rss]
    flags = flex.bool(len(all_pickles), False).set_selected(perm, True)
    all_pickles = flex.select(all_pickles, permutation=flags.iselection())
    print()
  #
  from libtbx.path import makedirs_race
  if (params.wdir_root is not None):
    makedirs_race(path=params.wdir_root)
  if (params.pickle_refined_dir is not None):
    makedirs_race(path=params.pickle_refined_dir)
  #
  n_caught = 0
  for i_pickle,pickle_file_name in enumerate(all_pickles):
    if (i_pickle % command_line.chunk.n != command_line.chunk.i): continue
    tm = user_plus_sys_time()
    try:
      process(params, pickle_file_name)
    except KeyboardInterrupt:
      print("CAUGHT EXCEPTION: KeyboardInterrupt", file=sys.stderr)
      traceback.print_exc()
      print(file=sys.stderr)
      sys.stderr.flush()
      return
    except Exception:
      sys.stdout.flush()
      print("CAUGHT EXCEPTION: %s" % pickle_file_name, file=sys.stderr)
      traceback.print_exc()
      print(file=sys.stderr)
      sys.stderr.flush()
      n_caught += 1
    else:
      print("done_with: %s (%.2f seconds)" % (pickle_file_name, tm.elapsed()))
      print()
      sys.stdout.flush()
  print()
  print("Number of exceptions caught:", n_caught)
  #
  show_times()
  print()
  print("TIME END cod_refine:", date_and_time())

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/omz/cod_select_and_pickle.py
from __future__ import absolute_import, division, print_function
import traceback
import sys, os
op = os.path

from cctbx.omz.cif_refine import extract_from_cif_files

class cod_data(extract_from_cif_files):

  __slots__ = [
    "cod_id"] + extract_from_cif_files.__slots__

  def __init__(O, cod_id, hkl_cif_pair):
    O.init_slots_with_none()
    O.cod_id = cod_id
    refl_file, model_file = hkl_cif_pair
    print("refl_file:", refl_file)
    print("model_file:", model_file)
    import iotbx.cif
    refl_cif = iotbx.cif.reader(file_path=refl_file)
    model_cif = iotbx.cif.reader(file_path=model_file)
    for cif_obj in [model_cif, refl_cif]:
      for cif_block in cif_obj.model().values():
        value = cif_block.get("_cod_error_flag")
        if (value in ["errors", "retracted"]):
          print("SKIPPING: _cod_error_flag %s: %s" % (value, cod_id))
          return
        keys = set(cif_block.keys())
        if (len(set([
              "_space_group_symop_ssg_operation_algebraic",
              "_space_group_ssg_name"]).intersection(keys)) != 0):
          print("SKIPPING: COD entry with super-space group:", cod_id)
          return
        if (len(set([
              "_refln_index_m",
              "_refln_index_m_1"]).intersection(keys)) != 0):
          print("SKIPPING: COD entry with _refln_index_m:", cod_id)
          return
        for key in keys:
          if (key.startswith("_pd_")):
            print("SKIPPING: COD entry with powder data:", cod_id)
            return
    O.process(
      report_id=cod_id,
      refl_file=refl_file,
      refl_cif=refl_cif,
      model_file=model_file,
      model_cif=model_cif)

  def have_zero_occupancies(O):
    return not O.xray_structure.scatterers().extract_occupancies().all_ne(0)

  def have_shelxl_compatible_scattering_types(O):
    from cctbx.eltbx.xray_scattering import \
      shelxl_97_2_980324_tabulated_chemical_elements as known
    for sc in O.xray_structure.scatterers():
      if (sc.scattering_type.strip().upper() not in known):
        return False
    return True

  def have_close_contacts(O, min_distance):
    if (min_distance <= 0):
      return False
    xs = O.xray_structure.select(selection=O.non_hydrogen_iselection)
    pat = xs.pair_asu_table(distance_cutoff=min_distance)
    pst = pat.extract_pair_sym_table()
    from cctbx import crystal
    from cctbx.array_family import flex
    dists = crystal.get_distances(
      pair_sym_table=pst,
      orthogonalization_matrix=xs.unit_cell().orthogonalization_matrix(),
      sites_frac=xs.sites_frac())
    print("Close contacts:", dists.size())
    if (dists.size() != 0):
      pat.show_distances(sites_frac=xs.sites_frac())
      return True
    return False

  def have_sys_absent(O):
    return (O.c_obs.sys_absent_flags().data().count(True) != 0)

  def have_redundant_data(O):
    return not O.c_obs.is_unique_set_under_symmetry()

  def have_bad_sigmas(O):
    if (O.c_obs.sigmas() is None):
      print("Missing sigmas:", O.cod_id)
      return True
    sel = (O.c_obs.data() == 0) & (O.c_obs.sigmas() == 0)
    result = not O.c_obs.select(~sel).sigmas().all_gt(0)
    if (result):
      print("Zero or negative sigmas:", O.cod_id)
    return result

  def f_obs_and_f_calc_agree_well(O, co):
    if (O.c_obs.indices().size() == 0): return False
    from cctbx.array_family import flex
    f_obs = O.c_obs.as_amplitude_array(algorithm="xtal_3_7")
    f_calc = f_obs.structure_factors_from_scatterers(
      xray_structure=O.xray_structure).f_calc().amplitudes()
    fan_out_sel = f_obs.f_obs_f_calc_fan_outlier_selection(
      f_calc=f_calc,
      offset_low=co.fan_offset_low,
      offset_high=co.fan_offset_high,
      also_return_x_and_y=True)
    if (fan_out_sel is None):
      return False
    if (co.i_obs_i_calc_plot and f_obs.indices().size() != 0):
      from libtbx import pyplot
      xs = O.c_obs.as_intensity_array(algorithm="simple").data()
      ys = flex.pow2(f_calc.data())
      pyplot.plot(xs.as_numpy_array(), ys.as_numpy_array(), "ro")
      pyplot.show()
    fan_out_sel, x, y = fan_out_sel
    fan_in_sel = ~fan_out_sel
    if (co.f_obs_f_calc_plot):
      from libtbx import pyplot
      xs = x.select(fan_out_sel)
      ys = y.select(fan_out_sel)
      if (xs.size() == 0):
        pyplot.plot(x.as_numpy_array(), y.as_numpy_array(), "bo")
      else:
        pyplot.plot(xs.as_numpy_array(), ys.as_numpy_array(), "ro")
        xs = x.select(fan_in_sel)
        ys = y.select(fan_in_sel)
        if (xs.size() != 0):
          pyplot.plot(xs.as_numpy_array(), ys.as_numpy_array(), "bo")
      pyplot.plot_pairs(
        [(co.fan_offset_low,0), (1,1-co.fan_offset_high)], "r-")
      pyplot.plot_pairs(
        [(0,co.fan_offset_low), (1-co.fan_offset_high,1)], "r-")
      pyplot.plot_pairs([(0,0), (1,1)], "k--")
      pyplot.show()
    fan_outlier_fraction = fan_out_sel.count(True) / fan_out_sel.size()
    def cc_r1(fo, fc):
      lc = flex.linear_correlation(fo.data(), fc.data())
      assert lc.is_well_defined()
      cc = lc.coefficient()
      from libtbx import Auto
      r1 = f_obs.r1_factor(other=f_calc, scale_factor=Auto)
      return cc, r1
    cc_all, r1_all = cc_r1(f_obs, f_calc)
    cc_in, r1_in = cc_r1(f_obs.select(fan_in_sel), f_calc.select(fan_in_sel))
    print("f_obs_f_calc %s" % O.cod_id, \
      "| cc_all %.4f | r1_all %.4f | out %.4f | cc_in %.4f | r1_in %.4f |" % (
        cc_all, r1_all, fan_outlier_fraction, cc_in, r1_in))
    if (fan_outlier_fraction > co.max_fan_outlier_fraction):
      return False
    if (cc_all < co.min_f_obs_f_calc_correlation):
      return False
    return True

  def is_useful(O, co):
    if (O.c_obs is None): return False
    if (O.non_hydrogen_iselection.size() > co.max_atoms): return False
    if (O.have_zero_occupancies()): return False
    if (O.have_close_contacts(co.min_distance)): return False
    if (not O.have_shelxl_compatible_scattering_types()): return False
    if (O.have_sys_absent()): return False
    if (O.have_redundant_data()): return False
    if (O.have_bad_sigmas()): return False
    if (not O.f_obs_and_f_calc_agree_well(co)): return False
    if (    co.at_least_one_special_position
        and O.xray_structure.special_position_indices().size() == 0):
      return False
    return True

  def quick_info(O):
    return (
      O.non_hydrogen_iselection.size(),
      O.c_obs.space_group().order_p(),
      O.c_obs.indices().size(),
      O.c_obs.d_min())

def run(args, command_name):
  from iotbx.option_parser import option_parser as iotbx_option_parser
  from libtbx import easy_pickle
  import libtbx.utils
  show_times = libtbx.utils.show_times(time_start="now")
  command_line = (iotbx_option_parser(
    usage=command_name+" [options] [cod_id...]")
    .enable_chunk(easy_all=True)
    .enable_multiprocessing()
    .option(None, "--max_atoms",
      type="int",
      default=99,
      metavar="INT")
    .option(None, "--min_distance",
      type="float",
      default=0.5,
      metavar="FLOAT")
    .option(None, "--i_obs_i_calc_plot",
      action="store_true",
      default=False)
    .option(None, "--f_obs_f_calc_plot",
      action="store_true",
      default=False)
    .option(None, "--max_fan_outlier_fraction",
      type="float",
      default=0.05,
      metavar="FLOAT")
    .option(None, "--fan_offset_low",
      type="float",
      default=0.05,
      metavar="FLOAT")
    .option(None, "--fan_offset_high",
      type="float",
      default=0.10,
      metavar="FLOAT")
    .option(None, "--min_f_obs_f_calc_correlation",
      type="float",
      default=0.99,
      metavar="FLOAT")
    .option(None, "--at_least_one_special_position",
      action="store_true",
      default=False)
    .option(None, "--pickle_dir",
      type="str",
      default="cod_ma_xs",
      metavar="PATH")
  ).process(args=args)
  if (command_line.run_multiprocessing_chunks_if_applicable(
        command_call=[command_name])):
    show_times()
    return
  co = command_line.options
  #
  from iotbx.cif import cod_tools
  hkl_cif = cod_tools.build_hkl_cif(cod_ids=command_line.args)
  hkl_cif.show_summary()
  #
  pickle_dir = co.pickle_dir
  if (co.at_least_one_special_position):
    pickle_dir += "_special"
  if (not op.isdir(pickle_dir)):
    from libtbx.path import makedirs_race
    makedirs_race(path=pickle_dir)
  n_caught = 0
  for i_pair,pair in enumerate(hkl_cif.hkl_cif_pairs.values()):
    cod_id = op.basename(pair[0])[:-4]
    if (i_pair % command_line.chunk.n != command_line.chunk.i): continue
    try:
      cd = cod_data(cod_id=cod_id, hkl_cif_pair=pair)
    except KeyboardInterrupt:
      print("CAUGHT EXCEPTION: KeyboardInterrupt")
      return
    except Exception as e:
      sys.stdout.flush()
      print("CAUGHT EXCEPTION: %s: %s: %s" % (command_name, cod_id, str(e)), file=sys.stderr)
      traceback.print_exc()
      print(file=sys.stderr)
      sys.stderr.flush()
      n_caught += 1
    else:
      if (cd.is_useful(co)):
        easy_pickle.dump(
          file_name="%s/%s.pickle" % (pickle_dir, cod_id),
          obj=(cd.c_obs, cd.xray_structure, cd.edge_list))
        print(cd.quick_info(), file=open("%s/qi_%s" % (pickle_dir, cod_id), "w"))
      else:
        print("filtering out:", cod_id)
      print("done_with:", cod_id)
      print()
  print()
  print("Number of exceptions caught:", n_caught)
  #
  show_times()


 *******************************************************************************


 *******************************************************************************
cctbx/omz/dev.py
from __future__ import absolute_import, division, print_function
from cctbx.omz import bfgs
from cctbx import xray
import cctbx.xray.targets
from cctbx.array_family import flex
from scitbx import matrix
import libtbx.phil
from libtbx import Auto, group_args
from itertools import count
from math import pi, atan2
import sys
from six.moves import range
from six.moves import zip

def delta_estimation_minus_cos(limit, grad, curv):
  return limit/pi * atan2(pi/limit*grad, curv)

class shift_limit_pair(object):

  __slots__ = ["neg", "pos", "curv_est_factor"]

  def __init__(O, neg, pos=None, curv_est_factor=0.1):
    assert neg > 0
    if (pos is None):
      pos = neg
    else:
      assert pos > 0
    assert curv_est_factor > 0
    assert curv_est_factor <= 1
    O.neg = neg
    O.pos = pos
    O.curv_est_factor = curv_est_factor

  def get(O, grad):
    if (grad < 0): return O.neg
    return O.pos

  def curv_est_shift(O, grad):
    if (grad < 0):
      return O.neg * curv_est_factor
    return -O.pos * curv_est_factor

class dynamic_shift_limit_site(object):
  """neg, pos estimation: xrefine_pot first_negative_after_min(curv)
  neg = pos = d_min / 2
  """

  __slots__ = ["width"]

  def __init__(O, width):
    O.width = width

  def pair(O, x):
    return shift_limit_pair(neg=O.width)

class dynamic_shift_limit_u_iso(object):

  __slots__ = ["d_min"]

  def __init__(O, d_min):
    O.d_min = d_min

  def pair(O, x):
    """neg, pos estimation: xrefine_pot first_negative(curv)
    d_min y_interc slope
      0.5   0.04    1.6
      1     0.06    1.5
      2     0.2     1.4
      3     0.4     1.3
      4     0.6     1.2
      5     1.4     1.1
    """
    u_iso = x
    y_interc = 0.05 * O.d_min**2
    slope = max(1., 1.6 - 0.1 * O.d_min)
    slope_attenuation = 0.5 # XXX to be optimized
    pos = slope_attenuation * slope * max(0., u_iso) + y_interc
    neg = max(0.01, u_iso)
    return shift_limit_pair(neg=neg, pos=pos)

class xfgc_info(object):

  __slots__ = ["x", "funcl", "grads", "curvs", "is_iterate", "approx_quads"]

  def __init__(k, work_obj, is_iterate):
    k.x = work_obj.x.deep_copy()
    k.funcl = work_obj.funcl
    k.grads = work_obj.grads
    k.curvs = work_obj.curvs
    k.is_iterate = is_iterate
    k.approx_quads = None

  def check_strong_wolfe(k, l, pk, ak, c1, c2):
    assert l is not k
    fk = k.funcl
    fl = l.funcl
    gk = k.grads
    gl = l.grads
    decr_cond = (fl <= fk + c1 * ak * gk.dot(pk))
    curv_cond = (abs(gl.dot(pk)) <= c2 * abs(gk.dot(pk)))
    if (0): print("CHECK Wolfe decr curv", decr_cond, curv_cond)
    if (1): # verify that curv cond can be reformulated using sk
      sk = l.x - k.x
      curv_cond_sk = (abs(gl.dot(sk)) <= c2 * abs(gk.dot(sk)))
      assert curv_cond_sk == curv_cond
    return decr_cond and curv_cond

def sign0(x):
  if (x < 0): return -1
  if (x > 0): return 1
  return 0

class refinement(object):

  def __init__(O,
        i_obs,
        f_obs,
        xray_structure,
        params,
        reference_structure,
        expected_n_refinable_parameters=None,
        plot_samples_id=None):
    O.params = params
    O.i_obs = i_obs
    O.f_obs = f_obs
    O.xray_structure = xray_structure
    O.setup_bulk_solvent_correction()
    O.reference_structure = reference_structure
    O.grads = None
    O.curvs = None
    O.grads_mean_sq = None
    O.show_rms_info()
    if (O.reference_structure is None):
      O.x_reference = None
    else:
      O.pack_variables(xray_structure=O.reference_structure)
      O.x_reference = O.x
    O.pack_variables()
    print("Number of variables:", O.x.size())
    if (expected_n_refinable_parameters is not None):
      assert O.x.size() == expected_n_refinable_parameters
    #
    O.plot_samples_id = plot_samples_id
    O.ps_target = None
    if (len(O.params.plot_samples.stages) != 0):
      p = O.params.plot_samples
      if (p.ix is not None):
        if (p.ix < 0 or p.ix >= O.x.size()):
          raise RuntimeError(
            "Out of range: plot_samples.ix = %d (max is %d)" % (
              p.ix, O.x.size()-1))
        if (p.ix_auto is not None):
          raise RuntimeError(
            "Incompatible parameter combination:"
              " plot_samples.ix=%d and plot_samples.ix_auto=%s" % (
                p.ix, p.ix_auto))
      elif (p.ix_auto is None):
        raise RuntimeError(
          "Either plot_samples.ix or plot_samples.ix_auto must be defined.")
      if (len(p.pyplot) == 0 and p.file_prefix is None):
        raise RuntimeError(
          "Incompatible parameter combination:"
          " plot_samples.pyplot=None and plot_samples.file_prefix=None")
      def select(main, sub):
        if (sub == "Auto"): return main # XXX phil bug?
        return sub
      O.ps_target = group_args(
        type = select(
          O.params.target.type, p.target.type),
        obs_type = select(
          O.params.target.obs_type, p.target.obs_type),
        weighting_scheme = select(
          O.params.target.weighting_scheme, p.target.weighting_scheme))
    #
    O.calc_weights_if_needed()
    #
    O.xfgc_infos = []
    O.update_fgc(is_iterate=True)
    O.pseudo_curvs = None
    O.pseudo_curvs_i_info = None
    O.termination_remark = " UNDEFINED"
    #
    O.plot_samples("initial")
    #
    if (O.params.use_classic_lbfgs):
      O.classic_lbfgs()
    elif (O.params.use_lbfgs_emulation):
      O.lbfgs_emulation()
    else:
      O.developmental_algorithms()
    print("Number of iterations, evaluations: %d %d%s" % (
      O.i_step+1, len(O.xfgc_infos), O.termination_remark))
    #
    O.plot_samples("final")

  def plot_samples(O, stage):
    p = O.params.plot_samples
    if (stage not in p.stages):
      return
    if (p.ix is not None):
      O.plot_samples_ix(stage, p.ix)
    elif (p.ix_auto == "all"):
      for ix in range(O.x.size()):
        O.plot_samples_ix(stage, ix)
    elif (p.ix_auto == "random"):
      assert p.ix_random.samples_each_scattering_type is not None
      assert p.ix_random.samples_each_scattering_type > 0
      assert p.ix_random.random_seed is not None
      mt = flex.mersenne_twister(seed=p.ix_random.random_seed)
      # TODO: verify this values is not a dictionary method
      i_seqs_grouped = O.xray_structure.scatterers() \
        .extract_scattering_types().i_seqs_by_value().values()
      i_seqs_selected = flex.bool(O.x.size(), False)
      for i_seqs in i_seqs_grouped:
        ps = i_seqs.size()
        ss = min(ps, p.ix_random.samples_each_scattering_type)
        isel = mt.random_selection(population_size=ps, sample_size=ss)
        i_seqs_selected.set_selected(i_seqs.select(isel), True)
      for ix,(i_sc,_) in enumerate(O.x_info):
        if (i_seqs_selected[i_sc]):
          O.plot_samples_ix(stage, ix)
    else:
      raise RuntimeError("Unknown plot_samples.ix_auto = %s" % p.ix_auto)

  def plot_samples_ix(O, stage, ix):
    p = O.params.plot_samples
    i_sc, x_type = O.x_info[ix]
    def f_calc_without_moving_scatterer():
      sc = O.xray_structure.scatterers()[i_sc]
      occ = sc.occupancy
      try:
        sc.occupancy = 0
        result = O.get_f_calc().data()
      finally:
        sc.occupancy = occ
      return result
    f_calc_fixed = f_calc_without_moving_scatterer()
    xs = O.xray_structure.select(flex.size_t([i_sc]))
    def f_calc_moving():
      return O.f_obs.structure_factors_from_scatterers(
        xray_structure=xs,
        algorithm="direct",
        cos_sin_table=False).f_calc().data()
    sc = xs.scatterers()[0]
    ss = xs.site_symmetry_table().get(0)
    def build_info_str():
      return "%s|%03d|%03d|%s|%s|occ=%.2f|%s|%s" % (
        O.plot_samples_id,
        ix,
        i_sc,
        sc.label,
        sc.scattering_type,
        sc.occupancy,
        ss.special_op_simplified(),
        x_type)
    info_str = build_info_str()
    print("plot_samples:", info_str)
    sys.stdout.flush()
    ys = []
    def ys_append():
      tg = O.__get_tg(
        f_cbs=O.get_f_cbs(
          f_calc=O.f_obs.customized_copy(data=f_calc_moving()+f_calc_fixed)),
        derivatives_depth=0,
        target=O.ps_target,
        weights=O.ps_weights)
      y = tg.target_work()
      ys.append(y)
      return y
    xyv = []
    if (x_type == "u"):
      assert p.u_min < p.u_max
      assert p.u_steps > 0
      for i_step in range(p.u_steps+1):
        u = p.u_min + i_step / p.u_steps * (p.u_max - p.u_min)
        sc.u_iso = u
        y = ys_append()
        xyv.append((u,y,sc.u_iso))
    else:
      assert p.x_radius > 0
      assert p.x_steps > 0
      ss_constr = ss.site_constraints()
      ss_np = ss_constr.n_independent_params()
      ss_ip = "xyz".find(x_type)
      assert ss_ip >= 0
      ixx = ix - ss_ip
      indep = list(O.x[ixx:ixx+ss_np])
      i_inp = indep[ss_ip]
      from libtbx.test_utils import approx_equal
      assert approx_equal(
        ss_constr.all_params(independent_params=indep), sc.site)
      site_inp = sc.site
      indep[ss_ip] = i_inp + 1
      sc.site = ss_constr.all_params(independent_params=indep)
      dist = xs.unit_cell().distance(sc.site, site_inp)
      assert dist != 0
      x_scale = p.x_radius / dist
      for i_step in range(-p.x_steps//2, p.x_steps//2+1):
        x = i_step / p.x_steps * 2 * x_scale
        indep[ss_ip] = i_inp + x
        sc.site = ss_constr.all_params(independent_params=indep)
        y = ys_append()
        dist = xs.unit_cell().distance(sc.site, site_inp)
        if (i_step < 0): dist *= -1
        xyv.append((dist,y,indep[ss_ip]))
    #
    base_name_plot_files = "%s_%03d_%s" % (p.file_prefix, ix, stage)
    def write_xyv():
      if (p.file_prefix is None): return
      f = open(base_name_plot_files+".xy", "w")
      print("# %s" % info_str, file=f)
      print("# %s" % str(xs.unit_cell()), file=f)
      print("# %s" % str(xs.space_group_info().symbol_and_number()), file=f)
      for x,y,v in xyv:
        print(x, y, v, file=f)
    write_xyv()
    if (len(p.pyplot) != 0):
      from libtbx import pyplot
      fig = pyplot.figure()
      ax = fig.add_subplot(1, 1, 1)
      x,y,v = zip(*xyv)
      ax.plot(x,y, "r-")
      x = O.x[ix]
      ax.plot([x, x], [min(ys), max(ys)], "k--")
      if (O.x_reference is not None):
        x = O.x_reference[ix]
        ax.plot([x, x], [min(ys), max(ys)], "r--")
      ax.set_title(info_str, fontsize=12)
      ax.axis([xyv[0][0], xyv[-1][0], None, None])
      def write_pdf():
        if (p.file_prefix is None): return
        fig.savefig(base_name_plot_files+".pdf", bbox_inches="tight")
      if ("pdf" in p.pyplot):
        write_pdf()
      if ("gui" in p.pyplot):
        pyplot.show()

  def setup_bulk_solvent_correction(O):
    O.epsilons = None
    O.centric_flags = None
    O.r_free_flags = None
    O.f_bulk = None
    O.fb_cart = None
    O.alpha_beta = None
    if (not O.params.bulk_solvent_correction):
      return
    if (O.params.plot_samples.target.type == "ml"):
      O.epsilons = O.f_obs.epsilons()
      O.centric_flags = O.f_obs.centric_flags()
      print("INFO: generating R-free flags for plot_samples.target.type = ml")
      O.r_free_flags = O.f_obs.generate_r_free_flags(
        fraction=0.05,
        max_free=None,
        use_lattice_symmetry=True)
    print("Computing bulk-solvent model and anisotropic scaling correction ...", end=' ')
    sys.stdout.flush()
    import mmtbx.f_model
    fmm = mmtbx.f_model.manager(
      f_obs=O.f_obs,
      r_free_flags=O.r_free_flags,
      xray_structure=O.xray_structure)
    fmm.update_all_scales()
    fmm.optimize_mask()
    print("done.")
    sys.stdout.flush()
    print("bulk-solvent correction:")
    print("  k_sols:", numstr(fmm.k_sols()))
    print("  b_sol: %.6g" % fmm.b_sol())
    print("  b_cart:", numstr(fmm.b_cart(), zero_threshold=1e-6))
    O.f_bulk = fmm.f_bulk()
    O.fb_cart = O.f_obs.customized_copy(data=fmm.fb_cart())
    print("  mean of f_bulk.amplitudes():")
    bulk_ampl = O.f_bulk.amplitudes()
    bulk_ampl.setup_binner(n_bins=8)
    bulk_ampl.mean(use_binning=True).show(prefix="    ")
    if (O.r_free_flags is not None):
      print("Computing alpha-beta for ml target ...", end=' ')
      sys.stdout.flush()
      O.alpha_beta = fmm.alpha_beta()
      print("done.")
    sys.stdout.flush()

  def classic_lbfgs(O):
    import scitbx.lbfgs
    O.i_step = 0
    scitbx.lbfgs.run(target_evaluator=O)

  def compute_functional_and_gradients(O):
    O.update_fgc()
    return O.funcl, O.grads

  def callback_after_step(O, minimizer):
    O.update_fgc(is_iterate=True)
    print("%4d: %s" % (O.i_step+1, O.format_rms_info()))
    sys.stdout.flush()
    if (O.grads_mean_sq < O.params.grads_mean_sq_threshold):
      O.termination_remark = ""
      return True
    if (O.i_step+1 == O.params.iteration_limit):
      O.termination_remark = " (iteration limit reached)"
      return True
    O.i_step += 1

  def lbfgs_emulation(O, memory_range=5):
    assert len(O.xfgc_infos) == 1
    for O.i_step in range(O.params.iteration_limit):
      if (O.i_step == 0):
        dests = -O.grads
        stp = 1 / O.grads.norm()
      else:
        active_infos = O.get_active_infos()
        assert len(active_infos) > 1
        if (memory_range is not None):
          active_infos = active_infos[-(memory_range+1):]
        memory = O.build_bfgs_memory(active_infos=active_infos)
        assert memory is not None
        k_1 = active_infos[-1]
        k_2 = active_infos[-2]
        gamma = bfgs.h0_scaling(
          sk=k_1.x-k_2.x,
          yk=k_1.grads-k_2.grads)
        hk0 = flex.double(O.x.size(), gamma)
        dests = -bfgs.hg_two_loop_recursion(
          memory=memory, hk0=hk0, gk=O.grads)
        stp = 1
      stp = O.line_search(dests, stp=stp)
      assert stp is not None
      O.update_fgc(is_iterate=True)
      print("%4d: %s" % (O.i_step+1, O.format_rms_info()))
      sys.stdout.flush()
      if (O.grads_mean_sq < O.params.grads_mean_sq_threshold):
        O.termination_remark = ""
        break
    else:
      O.termination_remark = " (iteration limit reached)"

  def developmental_algorithms(O):
    for O.i_step in range(O.params.iteration_limit):
      O.compute_step()
      s = "%4d: %s" % (O.i_step+1, O.format_rms_info())
      if (O.aq_sel_size is not None):
        s += " aq(%d, %d)" % (O.aq_sel_size, O.aq_n_used)
      print(s)
      sys.stdout.flush()
      if (O.grads_mean_sq < O.params.grads_mean_sq_threshold):
        O.termination_remark = ""
        break
    else:
      O.termination_remark = " (iteration limit reached)"

  def pack_variables(O, xray_structure=None):
    if (xray_structure is None):
      xray_structure = O.xray_structure
    O.x = flex.double()
    O.x_info = []
    O.gact_indices = flex.size_t()
    O.dynamic_shift_limits = []
    site_limits = [0.15/p for p in xray_structure.unit_cell().parameters()[:3]]
    d_min = O.f_obs.d_min()
    i_all = 0
    sstab = xray_structure.site_symmetry_table()
    for i_sc,sc in enumerate(xray_structure.scatterers()):
      assert sc.flags.use_u_iso()
      assert not sc.flags.use_u_aniso()
      #
      site_symmetry = sstab.get(i_sc)
      if (site_symmetry.is_point_group_1()):
        p = sc.site
        l = site_limits
      else:
        p = site_symmetry.site_constraints().independent_params(
          all_params=sc.site)
        l = site_symmetry.site_constraints().independent_params(
          all_params=site_limits)
      O.x.extend(flex.double(p))
      O.x_info.extend([(i_sc,"xyz"[i]) for i in range(len(p))])
      O.dynamic_shift_limits.extend(
        [dynamic_shift_limit_site(width=width) for width in l])
      for i in range(len(p)):
        O.gact_indices.append(i_all)
        i_all += 1
      #
      O.x.append(sc.u_iso)
      O.x_info.append((i_sc,"u"))
      O.dynamic_shift_limits.append(dynamic_shift_limit_u_iso(d_min=d_min))
      O.gact_indices.append(i_all)
      i_all += 1
      #
      i_all += 3 # occ, fp, fdp

  def __unpack_variables(O):
    ix = 0
    sstab = O.xray_structure.site_symmetry_table()
    for i_sc,sc in enumerate(O.xray_structure.scatterers()):
      site_symmetry = sstab.get(i_sc)
      if (site_symmetry.is_point_group_1()):
        sc.site = tuple(O.x[ix:ix+3])
        ix += 3
      else:
        constr = site_symmetry.site_constraints()
        np = constr.n_independent_params()
        sc.site = constr.all_params(independent_params=tuple(O.x[ix:ix+np]))
        ix += np
      sc.u_iso = O.x[ix]
      ix += 1
    assert ix == O.x.size()

  def show_dests(O, dests):
    from libtbx.str_utils import format_value
    ix = 0
    sstab = O.xray_structure.site_symmetry_table()
    for i_sc,sc in enumerate(O.xray_structure.scatterers()):
      site_symmetry = sstab.get(i_sc)
      if (site_symmetry.is_point_group_1()):
        vals = list(dests[ix:ix+3])
        ix += 3
      else:
        constr = site_symmetry.site_constraints()
        np = constr.n_independent_params()
        vals = list(dests[ix:ix+np]) + [None] * (3-np)
        ix += np
      vals.append(dests[ix])
      ix += 1
      print(" ".join([format_value("%15.6f", v) for v in vals]))
    assert ix == O.x.size()

  def get_f_calc(O):
    p = O.params.f_calc_options
    return O.f_obs.structure_factors_from_scatterers(
      xray_structure=O.xray_structure,
      algorithm=p.algorithm,
      cos_sin_table=p.cos_sin_table).f_calc()

  def get_f_cbs(O, f_calc=None):
    if (f_calc is None):
      f_calc = O.get_f_calc()
    if (O.f_bulk is None):
      return f_calc
    return f_calc.customized_copy(
      data=O.fb_cart.data()*(f_calc.data()+O.f_bulk.data()))

  def r1_factor(O):
    return O.f_obs.r1_factor(
      other=O.get_f_cbs(), scale_factor=Auto, assume_index_matching=True)

  def calc_shelxl_wght_ls(O, f_cbs, need):
    assert need in ["w", "t"]
    i_calc = flex.norm(f_cbs)
    from cctbx.xray.targets.tst_shelxl_wght_ls import calc_k, calc_w, calc_t
    k = calc_k(f_obs=O.f_obs.data(), i_calc=i_calc)
    assert O.i_obs.sigmas().all_ge(0.01)
    w = calc_w(
      wa=0.1,
      wb=0,
      i_obs=O.i_obs.data(),
      i_sig=O.i_obs.sigmas(),
      i_calc=i_calc,
      k=k)
    if (need == "w"):
      return w
    class wrapper(object):
      def __init__(W):
        W.t = calc_t(O.i_obs.data(), i_calc, k, w)
      def target_work(W):
        return W.t
    return wrapper()

  def calc_weights_if_needed(O):
    O.weights = None
    O.ps_weights = None
    main_need = (O.params.target.weighting_scheme == "shelxl_wght_once")
    plot_need = (O.ps_target is not None
                   and O.ps_target.weighting_scheme == "shelxl_wght_once")
    if (main_need):
      assert O.params.target.obs_type == "I"
    if (plot_need):
      assert O.ps_target.obs_type == "I"
    if (main_need or plot_need):
      weights = O.calc_shelxl_wght_ls(f_cbs=O.get_f_cbs().data(), need="w")
      if (main_need):
        O.weights = weights
      if (plot_need):
        O.ps_weights = weights

  def __unpack_variables_get_tg(O):
    O.__unpack_variables()
    return O.__get_tg(f_cbs=O.get_f_cbs())

  def __get_tg(O, f_cbs, derivatives_depth=2, target=Auto, weights=Auto):
    if (target is Auto): target = O.params.target
    if (weights is Auto): weights = O.weights
    if (target.obs_type == "F"):
      obs = O.f_obs
    else:
      obs = O.i_obs
    if (target.type == "ls"):
      if (target.weighting_scheme in ["unit", "shelxl_wght_once"]):
        return xray.targets_least_squares(
          compute_scale_using_all_data=True,
          obs_type=target.obs_type,
          obs=obs.data(),
          weights=O.weights,
          r_free_flags=None,
          f_calc=f_cbs.data(),
          derivatives_depth=derivatives_depth,
          scale_factor=0)
      if (target.weighting_scheme != "shelxl_wght"):
        raise RuntimeError(
          "Unknown: target.weighting_scheme = %s" % target.weighting_scheme)
      assert target.obs_type == "I"
      if (derivatives_depth == 0):
        return O.calc_shelxl_wght_ls(f_cbs=f_cbs.data(), need="t")
      return xray.targets.shelxl_wght_ls(
        f_obs=O.f_obs.data(),
        i_obs=O.i_obs.data(),
        i_sig=O.i_obs.sigmas(),
        f_calc=f_cbs.data(),
        i_calc=None,
        wa=0.1,
        wb=0)
    elif (target.type == "cc"):
      return xray.targets_correlation(
        obs_type=target.obs_type,
        obs=obs.data(),
        weights=O.weights,
        r_free_flags=None,
        f_calc=f_cbs.data(),
        derivatives_depth=derivatives_depth)
    elif (target.type == "r1"):
      assert target.obs_type == "F"
      assert target.weighting_scheme == "unit"
      from cctbx.xray.targets import r1
      return r1.target(
        f_obs=O.f_obs.data(),
        f_calc=f_cbs.data())
    elif (target.type == "ml"):
      assert derivatives_depth in [0,1]
      if (O.epsilons is None):
        raise RuntimeError(
          "target.type=ml can only be used if bulk_solvent_correction=True")
      return xray.mlf_target_and_gradients(
        f_obs=O.f_obs.data(),
        r_free_flags=O.r_free_flags.data(),
        f_calc=f_cbs.data(),
        alpha=O.alpha_beta[0].data(),
        beta=O.alpha_beta[1].data(),
        scale_factor=1,
        epsilons=O.epsilons.data().as_double(),
        centric_flags=O.centric_flags.data(),
        compute_gradients=bool(derivatives_depth))
    raise RuntimeError("Unknown target_type: %s" % target.type)

  def update_fgc(O, is_iterate=False):
    if (len(O.xfgc_infos) != 0):
      prev_xfgc = O.xfgc_infos[-1]
      if (prev_xfgc.x.all_eq(O.x)):
        if (not prev_xfgc.is_iterate):
          prev_xfgc.is_iterate = is_iterate
        return
    tg = O.__unpack_variables_get_tg()
    assert tg.target_work() is not None
    gact = O.xray_structure.grads_and_curvs_target_simple(
      miller_indices=O.f_obs.indices(),
      da_db=tg.gradients_work(),
      daa_dbb_dab=tg.hessians_work())
    O.funcl = tg.target_work()
    O.grads = gact.grads.select(O.gact_indices)
    O.curvs = gact.curvs.select(O.gact_indices)
    O.grads_mean_sq = flex.mean_sq(O.grads)
    O.xfgc_infos.append(xfgc_info(work_obj=O, is_iterate=is_iterate))

  def get_active_infos(O, i_start=0):
    result = []
    for info in O.xfgc_infos[i_start:]:
      if (info.is_iterate):
        result.append(info)
    return result

  def build_bfgs_memory(O, active_infos):
    result = []
    for iinfo in range(len(active_infos)-1):
      k = active_infos[iinfo]
      l = active_infos[iinfo+1]
      m = bfgs.memory_element(s=l.x-k.x, y=l.grads-k.grads)
      if (m.rho is None):
        return None
      result.append(m)
    return result

  def update_dests_using_bfgs_formula(O, dests):
    O.aq_sel_size = -2
    O.aq_n_used = -2
    if (O.params.bfgs_estimate_limit_factor <= 0):
      return
    aq_sel = flex.size_t()
    aq_sel_size_start = 0
    iinfo_active = []
    for iinfo in range(len(O.xfgc_infos)-1,-1,-1):
      info = O.xfgc_infos[iinfo]
      if (info.is_iterate):
        if (aq_sel_size_start == 0):
          aq_sel = info.approx_quads
          aq_sel_size_start = aq_sel.size()
          if (aq_sel_size_start < 2):
            return
        else:
          next_aq_sel = aq_sel.intersection(other=info.approx_quads)
          if (    next_aq_sel.size() < aq_sel_size_start * 0.9
              and len(iinfo_active) > 1):
            break
          aq_sel = next_aq_sel
        iinfo_active.append(iinfo)
    iinfo_active.sort()
    O.aq_sel_size = aq_sel.size()
    if (len(iinfo_active) < 2 or O.aq_sel_size < 2):
      return
    O.aq_n_used = -1
    assert iinfo_active[-1] == len(O.xfgc_infos)-1
    curvs = O.xfgc_infos[iinfo_active[-1]].curvs.select(aq_sel)
    assert curvs.all_gt(0)
    hk0 = 1 / curvs
    memory = []
    for iinfo in iinfo_active[:-1]:
      k = O.xfgc_infos[iinfo]
      l = O.xfgc_infos[iinfo+1]
      xk = k.x.select(aq_sel)
      xl = l.x.select(aq_sel)
      gk = k.grads.select(aq_sel)
      gl = l.grads.select(aq_sel)
      m = bfgs.memory_element(s=xl-xk, y=gl-gk)
      gks = gk.dot(m.s)
      gls = gl.dot(m.s)
      wolfe_curv_cond = (gls >= 0.9 * gks)
        # Nocedal & Wright (1999) Equation 3.7b
        # reformulated using sk instead of pk
      if (not wolfe_curv_cond):
        return
      if (m.rho is None):
        print("Warning: rho <= 0")
        return
      memory.append(m)
    aq_dests = -bfgs.hg_two_loop_recursion(
      memory=memory, hk0=hk0, gk=O.xfgc_infos[-1].grads.select(aq_sel))
    O.aq_n_used = 0
    for aq_dest,ix in zip(aq_dests, aq_sel):
      dsl = O.dynamic_shift_limits[ix]
      limit = dsl.pair(x=O.x[ix]).get(grad=O.grads[ix])
      if (abs(aq_dest) <= O.params.bfgs_estimate_limit_factor * limit):
        dests[ix] = aq_dest
        O.aq_n_used += 1

  def approx_curvs(O, shift_limit_factor=0.1):
    x_on_entry = O.x
    shifts = flex.double()
    for ix,dsl,g in zip(count(), O.dynamic_shift_limits, O.grads):
      shift = dsl.pair(x=O.x[ix]).get(grad=g) * shift_limit_factor
      if (g > 0):
        shift *= -1
      assert shift != 0
      shifts.append(shift)
    if (0): print("shifts:", list(shifts))
    grads_z = O.grads
    O.x = x_on_entry + shifts
    O.update_fgc()
    grads_p = O.grads
    O.x = x_on_entry - shifts
    O.update_fgc()
    grads_m = O.grads
    O.x = x_on_entry
    O.update_fgc()
    O.xfgc_infos.pop()
    O.xfgc_infos.pop()
    O.xfgc_infos.pop()
    apprx = (grads_p - grads_m) / (2*shifts)
    if (0):
      print("curvs:", list(O.curvs))
      print("apprx:", list(apprx))
      flex.linear_correlation(O.curvs, apprx).show_summary()
    O.curvs = apprx

  def compute_step(O):
    if (O.params.use_curvs):
      O.compute_step_using_curvs()
    else:
      O.compute_step_just_grads()

  def compute_step_just_grads(O):
    inp_i_info = len(O.xfgc_infos) - 1
    inp_info = O.xfgc_infos[-1]
    limits = flex.double()
    for ix,dsl,g in zip(count(), O.dynamic_shift_limits, inp_info.grads):
      limits.append(dsl.pair(x=O.x[ix]).get(grad=g))
    assert limits.all_gt(0)
    def get_pseudo_curvs():
      ag_max = flex.max(flex.abs(inp_info.grads))
      assert ag_max != 0
      dests = (-inp_info.grads/ag_max) * (limits/2)
      assert flex.abs(dests).all_le(limits/2*(1+1e-6))
      assert (dests > 0).all_eq(inp_info.grads < 0)
      O.pseudo_curvs_i_info = inp_i_info
      return dests
    if (O.pseudo_curvs is None):
      dests = get_pseudo_curvs()
    else:
      active_infos = O.get_active_infos(O.pseudo_curvs_i_info)
      assert len(active_infos) > 1
      memory = O.build_bfgs_memory(active_infos=active_infos)
      if (memory is None):
        O.pseudo_curvs = None
        dests = get_pseudo_curvs()
      else:
        hk0 = 1 / O.pseudo_curvs
        dests = -bfgs.hg_two_loop_recursion(
          memory=memory, hk0=hk0, gk=inp_info.grads)
        madl = flex.max(flex.abs(dests / limits))
        if (madl > 1):
          print("madl:", madl)
          dests *= (1/madl)
        assert flex.abs(dests).all_le(limits*(1+1e-6))
    dest_adj = O.line_search(dests, stpmax=2.0)
    print("dest_adj:", dest_adj)
    if (dest_adj is not None):
      dests *= dest_adj
    elif (O.pseudo_curvs is not None):
      O.pseudo_curvs = None
      dests = get_pseudo_curvs()
      dest_adj = O.line_search(dests, stpmax=2.0)
      if (dest_adj is not None):
        dests *= dest_adj
    if (O.pseudo_curvs is None):
      assert (dests > 0).all_eq(inp_info.grads < 0)
      assert flex.abs(dests).all_le(limits*(1+1e-6))
      O.pseudo_curvs = -inp_info.grads / dests
      assert O.pseudo_curvs.all_gt(0)
    O.x = inp_info.x + dests
    O.update_fgc(is_iterate=True)
    O.aq_sel_size = None
    O.aq_n_used = None

  def compute_step_using_curvs(O):
    if (len(O.xfgc_infos) > 1 and O.params.use_gradient_flips):
      prev = O.xfgc_infos[-2]
    else:
      prev = None
    dests = flex.double()
    approx_quads = flex.size_t()
    if (O.params.try_approx_curvs):
      O.approx_curvs()
    for ix,dsl,g,c in zip(count(), O.dynamic_shift_limits, O.grads, O.curvs):
      limit = dsl.pair(x=O.x[ix]).get(grad=g)
      dest = None
      if (prev is not None):
        prev_g = prev.grads[ix]
        if (sign0(g) != sign0(prev_g)):
          x = O.x[ix]
          prev_x = prev.x[ix]
          xm = (g*prev_x - prev_g*x) / (g - prev_g)
          dest = xm - x
          if   (dest >  limit): dest =  limit
          elif (dest < -limit): dest = -limit
      if (dest is None):
        if (c > 0
              and O.params.approx_quad_limit_factor > 0
              and abs(g) < O.params.approx_quad_limit_factor * limit * c):
          dest = -g / c
          approx_quads.append(ix)
        else:
          dest = -delta_estimation_minus_cos(
            limit=limit, grad=g, curv=c)
      dests.append(dest)
    O.xfgc_infos[-1].approx_quads = approx_quads
    O.update_dests_using_bfgs_formula(dests)
    O.x_before_line_search = O.xfgc_infos[-1].x
    if (O.params.use_line_search):
      dest_adj = O.line_search(dests, stpmax=1.0)
      print("dest_adj:", dest_adj)
      if (dest_adj is not None and dest_adj < 1):
        dests *= dest_adj
    if (O.params.show_dests): O.show_dests(dests)
    O.x = O.x_before_line_search + dests
    O.update_fgc(is_iterate=True)

  def line_search(O, dests, stp=1, stpmax=None):
    import scitbx.math
    k = O.xfgc_infos[-1]
    line_search = scitbx.math.line_search_more_thuente_1994()
    line_search.ftol = 1e-4
    line_search.gtol = 0.9
    if (stpmax is not None):
      assert stp <= stpmax
      line_search.stpmax = stpmax
    try:
      line_search.start(
        x=O.x,
        functional=O.funcl,
        gradients=O.grads,
        search_direction=dests,
        initial_estimate_of_satisfactory_step_length=stp)
    except RuntimeError as e:
      if (str(e) != "Search direction not descent."):
        raise
      return None
    assert line_search.info_code == -1
    O.update_fgc()
    while (line_search.info_code == -1):
      chk = k.check_strong_wolfe(
        l=O.xfgc_infos[-1],
        pk=dests,
        ak=line_search.stp,
        c1=line_search.ftol,
        c2=line_search.gtol)
      line_search.next(x=O.x, functional=O.funcl, gradients=O.grads)
      if (chk):
        assert line_search.info_code != -1
      elif (line_search.info_code == 5):
        assert line_search.info_meaning \
            == "The step is at the upper bound stpmax."
        return None
      elif (line_search.info_code == 6):
        assert line_search.info_meaning.startswith(
          "Rounding errors prevent further progress.")
        return None
      else:
        assert line_search.info_code == -1, (
          line_search.info_code, line_search.info_meaning)
      O.update_fgc()
    return line_search.stp

  def get_rms_info(O):
    if (O.reference_structure is None):
      return None
    xs = O.xray_structure
    rs = O.reference_structure
    xf = xs.sites_frac()
    rf = rs.sites_frac()
    cd = xf - rf
    # TODO: use scattering power as weights, move to method of xray.structure
    ave_csh = matrix.col(cd.mean())
    ave_csh_perp = matrix.col(xs.space_group_info()
      .subtract_continuous_allowed_origin_shifts(translation_frac=ave_csh))
    caosh_corr = ave_csh_perp - ave_csh
    ad = cd + caosh_corr
    ud = xs.scatterers().extract_u_iso() \
       - rs.scatterers().extract_u_iso()
    omx = xs.unit_cell().orthogonalization_matrix()
    O.crmsd = (omx * cd).rms_length()
    O.armsd = (omx * ad).rms_length()
    O.urmsd = flex.mean_sq(ud)**0.5
    if (O.params.show_distances_to_reference_structure):
      for sc, a, u in zip(xs.scatterers(), omx * ad, ud):
        print("    %-10s" % sc.label, \
          " ".join(["%6.3f" % v for v in a]), \
          "%6.3f" % u)
    return (O.crmsd, O.armsd, O.urmsd)

  def format_rms_info(O):
    s = ""
    info = O.get_rms_info()
    if (info is not None):
      for r in info:
        s += " %5.3f" % r
    if (O.grads_mean_sq is not None):
      s += " f=%8.2e |g|=%8.2e" % (O.funcl, O.grads_mean_sq)
    s += " r1=%.4f" % O.r1_factor()
    return s

  def show_rms_info(O):
    s = O.format_rms_info()
    if (len(s) != 0):
       print(" cRMSD aRMSD uRMSD")
       print(s)
       sys.stdout.flush()

def run_refinement(
      structure_ideal,
      structure_shake,
      params,
      i_obs=None,
      f_obs=None):
  assert (i_obs is None) == (f_obs is None)
  print("Ideal structure:")
  structure_ideal.show_summary().show_scatterers()
  print()
  print("Modified structure:")
  structure_shake.show_summary().show_scatterers()
  print()
  print("rms difference:", \
    structure_ideal.rms_difference(other=structure_shake))
  print()
  sdt = params.show_distances_threshold
  if (sdt > 0):
    print("structure_shake inter-atomic distances:")
    structure_shake.show_distances(distance_cutoff=sdt)
    print()
  if (f_obs is None):
    i_obs = structure_ideal.structure_factors(
      anomalous_flag=False,
      d_min=1,
      algorithm="direct",
      cos_sin_table=False).f_calc().intensities()
    f_obs = i_obs.array(data=flex.sqrt(i_obs.data()))
  return refinement(
    i_obs=i_obs,
    f_obs=f_obs,
    xray_structure=structure_shake,
    params=params,
    reference_structure=structure_ideal)

def get_master_phil(
      iteration_limit=50,
      show_distances_threshold=0,
      bulk_solvent_correction=False,
      grads_mean_sq_threshold=1e-6,
      f_calc_options_algorithm="*direct fft",
      additional_phil_string=""):
  def build_target_scope(auto="", ml=""):
    return """\
      target {
        type = *%(auto)sls cc r1%(ml)s
          .type = choice
        obs_type = *%(auto)sF I
          .type = choice
        weighting_scheme = *%(auto)sunit shelxl_wght shelxl_wght_once
          .type = choice
      }
      """ % vars()
  main_target_scope = build_target_scope()
  plot_samples_target_scope = build_target_scope("Auto ", " ml")
  return libtbx.phil.parse("""
    general_positions_only = True
      .type = bool
    shake_sites_rmsd = 0.5
      .type = float
    shake_adp_spread = 20
      .type = float
    show_distances_threshold = %(show_distances_threshold)s
      .type = float
    bulk_solvent_correction = %(bulk_solvent_correction)s
      .type = bool
    %(main_target_scope)s
    iteration_limit = %(iteration_limit)s
      .type = int
    grads_mean_sq_threshold = %(grads_mean_sq_threshold)s
      .type = float
    use_classic_lbfgs = False
      .type = bool
    use_lbfgs_emulation = False
      .type = bool
    use_curvs = True
      .type = bool
    approx_quad_limit_factor = 1.0
      .type = float
    bfgs_estimate_limit_factor = 1.0
      .type = float
    use_line_search = False
      .type = bool
    use_gradient_flips = True
      .type = bool
    try_approx_curvs = False
      .type = bool
    show_dests = False
      .type = bool
    show_distances_to_reference_structure = False
      .type = bool
    f_calc_options {
      algorithm = %(f_calc_options_algorithm)s
        .type = choice
      cos_sin_table = False
        .type = bool
    }
    plot_samples {
      stages = initial final
        .type = choice(multi=True)
      ix = None
        .type = int
      ix_auto = all random
        .type = choice
      ix_random {
        samples_each_scattering_type = 3
          .type = int
        random_seed = 0
          .type = int
      }
      %(plot_samples_target_scope)s
      x_radius = 5
        .type = float
      x_steps = 100
        .type = int
      u_min = -0.05
        .type = float
      u_max = 0.45
        .type = float
      u_steps = 100
        .type = int
      file_prefix = None
        .type = str
      pyplot = *gui pdf
        .type = choice(multi=True)
    }
""" % vars() + additional_phil_string)


 *******************************************************************************


 *******************************************************************************
cctbx/omz/eval_iso_vs_refined.py
from __future__ import absolute_import, division, print_function
import sys, os
op = os.path

def eval_logs(file_names, out=None):
  if (out is None): out = sys.stdout
  from scitbx.array_family import flex
  from libtbx.str_utils import format_value
  min_secs_epoch = None
  max_secs_epoch = None
  n_refinements_initialized = 0
  gaps = flex.double()
  infos = flex.std_string()
  n_stale = 0
  n_unfinished = 0
  n_exception = 0
  n_traceback = 0
  n_abort = 0
  seconds = []
  space_groups_by_cod_id = {}
  for file_name in file_names:
    have_time_end = False
    cod_id = None
    n_scatt = None
    iso = None
    file_str = open(file_name).read()
    if (file_str.find(chr(0)) >= 0):
      n_stale += 1
      continue
    for line in file_str.splitlines():
      if (line.startswith("cod_id: ")):
        cod_id = line[10:]
        iso = None
      elif (line.startswith("Space group: ")):
        assert cod_id is not None
        space_group = line.split(None, 2)[2]
        tabulated = space_groups_by_cod_id.setdefault(cod_id, space_group)
        assert tabulated == space_group
      elif (line.startswith("Number of scatterers: ")):
        assert cod_id is not None
        n_scatt = int(line.split(": ",1)[1])
      elif (line.startswith("Number of refinable parameters: ")):
        assert cod_id is not None
        n_refinements_initialized += 1
      elif (line.startswith("iso          cc, r1: ")):
        assert cod_id is not None
        assert iso is None
        iso = line.split(": ",1)[1]
      elif (   line.startswith("dev          cc, r1: ")
            or line.startswith("ls_simple    cc, r1: ")
            or line.startswith("ls_lm        cc, r1: ")
            or line.startswith("shelxl_fm    cc, r1: ")
            or line.startswith("shelxl_cg    cc, r1: ")
            or line.startswith("shelx76      cc, r1: ")):
        assert iso is not None
        ref = line.split(": ",1)[1]
        gap = float(ref.split()[1]) - float(iso.split()[1])
        gaps.append(gap)
        infos.append(" : ".join([
          cod_id, iso, ref, "%.3f" % gap, str(n_scatt),
          space_groups_by_cod_id[cod_id]]))
        cod_id = None
        n_scatt = None
        iso = None
      else:
        def get_secs_epoch():
          return float(line.split()[-2][1:])
        if (line.find("EXCEPTION") >= 0):
          n_exception += 1
        if (line.startswith("Traceback")):
          n_traceback += 1
        if (line.find("Abort") >= 0):
          n_abort += 1
        if (line.startswith("wall clock time: ")):
          if (line.endswith(" seconds")):
            secs = float(line.split()[-2])
          else:
            _, fld = line.split("(", 1)
            assert fld.endswith(" seconds total)")
            secs = float(fld.split()[0])
          seconds.append(secs)
        elif (line.startswith("TIME BEGIN cod_refine: ")):
          s = get_secs_epoch()
          if (min_secs_epoch is None or s < min_secs_epoch): min_secs_epoch = s
        elif (line.startswith("TIME END cod_refine: ")):
          s = get_secs_epoch()
          if (max_secs_epoch is None or s > max_secs_epoch): max_secs_epoch = s
          have_time_end = True
    if (not have_time_end):
      n_unfinished += 1
  perm = flex.sort_permutation(gaps)
  gaps = gaps.select(perm)
  n_missing = n_refinements_initialized - gaps.size()
  print("Number of results: %d (%d missing)" % (gaps.size(), n_missing), file=out)
  assert n_missing >= 0
  print("Stale, Unfinished, Exceptions, Tracebacks, Abort:", \
    n_stale, n_unfinished, n_exception, n_traceback, n_abort, file=out)
  if (n_exception + n_abort < n_missing):
    print("WARNING: more missing results than expected.")
  if (len(seconds) != 0):
    if (min_secs_epoch is not None and max_secs_epoch is not None):
      g = max_secs_epoch - min_secs_epoch
    else:
      g = None
    print("min, max, global seconds: %.2f %.2f %s" % (
      min(seconds), max(seconds), format_value("%.2f", g)), file=out)
  print(file=out)
  def stats(f):
    n = f.count(True)
    return "%6d = %5.2f %%" % (n, 100 * n / max(1,n_refinements_initialized))
  print("gaps below -0.05:", stats(gaps < -0.05), file=out)
  print("gaps below -0.01:", stats(gaps < -0.01), file=out)
  print("gaps below  0.01:", stats(gaps <  0.01), file=out)
  print("gaps above  0.01:", stats(gaps >  0.01), file=out)
  print("gaps above  0.05:", stats(gaps >  0.05), file=out)
  print(file=out)
  print("Histogram of gaps:", file=out)
  flex.histogram(gaps, n_slots=10).show(f=out)
  print(file=out)
  infos = infos.select(perm)
  for info in infos:
    print(info, file=out)
  return (len(file_names), n_unfinished, min_secs_epoch, max_secs_epoch)

def run(args):
  file_names = []
  dir_names = []
  for arg in args:
    if (op.isfile(arg)):
      file_names.append(arg)
    elif (op.isdir(arg)):
      dir_names.append(arg)
  assert len(file_names) == 0 or len(dir_names) == 0
  n_files_accu = [0]
  n_unfinished_accu = [0]
  min_max_secs_epoch = [None, None]
  def track_times(stats):
    n_files, n_unfinished, min_secs, max_secs = stats
    n_unfinished_accu[0] += n_unfinished
    n_files_accu[0] += n_files
    a, b = min_max_secs_epoch[0], min_secs
    if (b is not None):
      if (a is None or a > b): min_max_secs_epoch[0] = b
    a, b = min_max_secs_epoch[1], max_secs
    if (b is not None):
      if (a is None or a < b): min_max_secs_epoch[1] = b
  if (len(file_names) != 0):
    track_times(eval_logs(file_names))
  else:
    for dir_name in dir_names:
      file_names = []
      for node in sorted(os.listdir(dir_name)):
        if (node.startswith("log")):
          path = op.join(dir_name, node)
          if (op.isfile(path)):
            file_names.append(path)
      if (len(file_names) != 0):
        outfn = op.join(dir_name, "stats")
        print(outfn, len(file_names))
        sys.stdout.flush()
        track_times(eval_logs(file_names, out=open(outfn, "w")))
  if (min_max_secs_epoch.count(None) == 0):
    print("global seconds: %.2f" % (
      min_max_secs_epoch[1] - min_max_secs_epoch[0]))
  print("Number of files:", n_files_accu[0])
  n = n_unfinished_accu[0]
  if (n == 0):
    print("unfinished:", n)
  else:
    print("UNFINISHED:", n)
  sys.stdout.flush()

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/omz/pdb_dev.py
from __future__ import absolute_import, division, print_function
from libtbx.utils import date_and_time, user_plus_sys_time
from libtbx.str_utils import show_string
import traceback
import os
op = os.path

def process(params, mtz_pdb_pair):
  fn_mtz, fn_pdb = mtz_pdb_pair
  #
  import iotbx.pdb
  xs = iotbx.pdb.input(file_name=fn_pdb).xray_structure_simple()
  xs.show_summary()
  xs.scattering_type_registry(table="it1992").show()
  print()
  #
  f_obs = None
  i_obs = None
  import iotbx.mtz
  mtz_obj = iotbx.mtz.object(file_name=fn_mtz)
  for ma in mtz_obj.as_miller_arrays(crystal_symmetry=xs):
    print(ma.info())
    if (f_obs is None and ma.is_xray_amplitude_array()):
      f_obs = ma
    elif (i_obs is None and ma.is_xray_intensity_array()):
      i_obs = ma
  print()
  if (i_obs is None):
    assert f_obs is not None
    c_obs = f_obs
    f_obs.show_comprehensive_summary()
    i_obs = f_obs.f_as_f_sq(algorithm="shelxl")
  else:
    c_obs = i_obs
    i_obs.show_comprehensive_summary()
    f_obs = i_obs.f_sq_as_f(algorithm="xtal_3_7")
  print()
  #
  if (len(params.optimizers) == 0):
    return
  #
  from cctbx.omz.cod_refine import process_continue
  process_continue(
    params=params,
    cod_id=op.basename(fn_pdb),
    c_obs=c_obs, i_obs=i_obs, f_obs=f_obs,
    structure_prep=xs)

def run(args):
  from iotbx.option_parser import option_parser as iotbx_option_parser
  import libtbx.utils
  show_times = libtbx.utils.show_times(time_start="now")
  command_call = ["iotbx.python", __file__]
  command_line = (iotbx_option_parser(
    usage=" ".join(command_call) + " [options] directory|file...")
    .enable_chunk(easy_all=True)
    .enable_multiprocessing()
  ).process(args=args, min_nargs=1)
  if (command_line.run_multiprocessing_chunks_if_applicable(
        command_call=command_call)):
    show_times()
    return
  co = command_line.options
  #
  print("TIME BEGIN pdb_dev:", date_and_time())
  print()
  libtbx.utils.host_and_user().show()
  print()
  sys.stdout.flush()
  #
  from cctbx.omz import cod_refine
  master_phil = cod_refine.get_master_phil(
    max_atoms=None,
    f_calc_options_algorithm="direct *fft",
    bulk_solvent_correction=True)
  argument_interpreter = master_phil.command_line_argument_interpreter()
  phil_objects = []
  remaining_args = []
  for arg in command_line.args:
    if (arg.find("=") >= 0):
      phil_objects.append(argument_interpreter.process(arg=arg))
    else:
      remaining_args.append(arg)
  work_phil = master_phil.fetch(sources=phil_objects)
  work_phil.show()
  print()
  params = work_phil.extract()
  #
  mtz_pdb_pairs = []
  arg_iter = iter(remaining_args)
  pdb_v3_mirror_dir = os.environ.get("PDB_MIRROR_PDB")
  assert pdb_v3_mirror_dir is None or op.isdir(pdb_v3_mirror_dir)
  cci_pdbmtz_path = os.environ.get("CCI_PDBMTZ")
  assert cci_pdbmtz_path is None or op.isdir(cci_pdbmtz_path)
  for arg in arg_iter:
    def get_next(expected_exts):
      def raise_bad_file(what, fn=None):
        msg = "%s file name (%s expected)" % (what, " or ".join(expected_exts))
        if (fn is None):
          msg += "."
        else:
          msg += ": " + show_string(fn)
        raise RuntimeError(msg)
      try:
        arg = next(arg_iter)
      except StopIteration:
        raise_bad_file("Missing")
      if (not arg.endswith(tuple(expected_exts))):
        raise_bad_file("Unexpected", arg)
      return arg
    if (op.isfile(arg) and arg.endswith((".mtz", ".pdb", ".ent"))):
      if (arg.endswith(".mtz")):
        fn_mtz = arg
        fn_pdb = get_next([".pdb", ".ent"])
      else:
        fn_pdb = arg
        fn_mtz = get_next([".mtz"])
    else:
      fn_mtz = arg+".mtz"
      def raise_mtz_but_no_pdb():
        raise RuntimeError(
          "MTZ file found but no PDB file: %s" % show_string(fn_mtz))
      if (op.isfile(fn_mtz)):
        for ext in [".pdb", ".ent"]:
          fn_pdb = arg+ext
          if (op.isfile(fn_pdb)):
            break
        else:
          raise_mtz_but_no_pdb()
      else:
        fn_mtz = op.join(cci_pdbmtz_path, arg+".mtz")
        if (not op.isfile(fn_mtz)):
          raise RuntimeError(
            "MTZ file not found: %s" % show_string(fn_mtz))
        fn_pdb = op.join(pdb_v3_mirror_dir, arg[1:3], "pdb"+arg+".ent.gz")
        if (not op.isfile(fn_pdb)):
          raise_mtz_but_no_pdb()
    mtz_pdb_pairs.append((fn_mtz, fn_pdb))
  #
  n_caught = 0
  for i_pair,mtz_pdb_pair in enumerate(mtz_pdb_pairs):
    if (i_pair % command_line.chunk.n != command_line.chunk.i): continue
    tm = user_plus_sys_time()
    try:
      process(params, mtz_pdb_pair)
    except KeyboardInterrupt:
      print("CAUGHT EXCEPTION: KeyboardInterrupt", file=sys.stderr)
      traceback.print_exc()
      print(file=sys.stderr)
      sys.stderr.flush()
      return
    except Exception:
      sys.stdout.flush()
      print("CAUGHT EXCEPTION: %s" % ", ".join(mtz_pdb_pair), file=sys.stderr)
      traceback.print_exc()
      print(file=sys.stderr)
      sys.stderr.flush()
      n_caught += 1
    else:
      print("done_with: %s, %s (%.2f seconds)" % (
        mtz_pdb_pair + (tm.elapsed(),)))
      print()
      sys.stdout.flush()
  print()
  print("Number of exceptions caught:", n_caught)
  #
  show_times()
  print()
  print("TIME END pdb_dev:", date_and_time())
  sys.stdout.flush()

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/omz/tardy_adaptor.py
from __future__ import absolute_import, division, print_function
class potential_object(object):

  def __init__(O, f_obs, xray_structure):
    O.f_obs = f_obs
    O.xray_structure = xray_structure
    O.last_sites_moved = None
    O.f = None

  def e_pot(O, sites_moved):
    if (   O.last_sites_moved is None
        or O.last_sites_moved.id() != sites_moved.id()):
      O.last_sites_moved = sites_moved
      xs = O.xray_structure
      assert len(sites_moved) == xs.scatterers().size()
      xs.set_sites_cart(sites_cart=sites_moved)
      f_calc = O.f_obs.structure_factors_from_scatterers(
        xray_structure=xs, algorithm="direct", cos_sin_table=False).f_calc()
      from cctbx import xray
      tg = xray.targets_least_squares(
        compute_scale_using_all_data=True,
        obs_type="F",
        obs=O.f_obs.data(),
        weights=None,
        r_free_flags=None,
        f_calc=f_calc.data(),
        derivatives_depth=0,
        scale_factor=0)
      O.f = tg.target_work()
    return O.f

def sample_e_pot(id_code, f_obs, xray_structure, edge_list, params):
  if (edge_list is None):
    print("NO_TARDY: no edge_list")
    return
  #
  xs = xray_structure
  if (xs.special_position_indices().size() != 0):
    print("NO_TARDY: special positions")
    return
  sites_cart = xs.sites_cart()
  labels = xs.scatterers().extract_labels()
  pat = xs.pair_asu_table(distance_cutoff=2.5)
  if (0):
    pat.show_distances(sites_cart=sites_cart, site_labels=labels)
  pst = pat.extract_pair_sym_table()
  for i,j in edge_list:
    assert i <= j
    sym_dict = pst[i].get(j)
    if (sym_dict is None):
      print("NO_TARDY: large distance for edge:", labels[i], labels[j])
      return
  #
  import scitbx.graph.tardy_tree
  tt = scitbx.graph.tardy_tree.construct(
    sites=sites_cart, edge_list=edge_list)
  import scitbx.rigid_body
  tardy_model = scitbx.rigid_body.tardy_model(
    labels=labels,
    sites=sites_cart,
    masses=xs.atomic_weights(),
    tardy_tree=tt,
    potential_obj=potential_object(f_obs, xs),
    near_singular_hinges_angular_tolerance_deg=5)
  if (tardy_model.number_of_trees != 1):
    print("NO_TARDY: multiple trees")
    return
  #
  print("Single tardy tree:", \
    id_code, xs.scatterers().size(), xs.space_group_info())
  tt.show_summary(vertex_labels=labels, prefix="  ")
  print("dof each joint:", list(tardy_model.degrees_of_freedom_each_joint()))
  print("q_size each joint:", list(tardy_model.q_size_each_joint()))
  q_packed = tardy_model.pack_q()
  print("q_packed.size():", q_packed.size())
  print("q_packed:", numstr(q_packed))
  if (params.iq < 0):
    return
  assert params.iq < q_packed.size()
  #
  xy = []
  from libtbx.utils import xsamples
  from math import pi
  for q_deg in xsamples(params.qmin, params.qmax, params.qstep):
    q_packed[params.iq] = q_deg*pi/180
    tardy_model.unpack_q(q_packed=q_packed)
    e_pot = tardy_model.e_pot()
    xy.append((q_deg,e_pot))
  from libtbx import pyplot
  pyplot.plot_pairs(xy, "r-")
  pyplot.show()


 *******************************************************************************


 *******************************************************************************
cctbx/omz/tst_bfgs.py
from __future__ import absolute_import, division, print_function
from cctbx.omz import bfgs
import scitbx.lbfgs
from scitbx.array_family import flex
from scitbx.linalg import eigensystem
from scitbx import matrix
from libtbx.test_utils import approx_equal
from math import cos, sin

def exercise_two_loop_recursion(fgh):
  x0 = flex.double([3.0, -4.0])
  g0 = fgh.g(x0)
  h0 = flex.double([[1,0],[0,1]])
  memory = []
  hg0 = bfgs.hg_two_loop_recursion(memory, hk0=h0, gk=g0)
  assert approx_equal(hg0, h0.matrix_multiply(g0))
  #
  x1 = x0 - 1/3 * hg0
  g1 = fgh.g(x1)
  h1 = bfgs.h_update(hk=h0, sk=x1-x0, yk=g1-g0)
  memory.append(bfgs.memory_element(s=x1-x0, y=g1-g0))
  hg1 = bfgs.hg_two_loop_recursion(memory, hk0=h0, gk=g1)
  assert approx_equal(hg1, h1.matrix_multiply(g1))
  #
  x2 = x1 - 1/5 * hg1
  g2 = fgh.g(x2)
  h2 = bfgs.h_update(hk=h1, sk=x2-x1, yk=g2-g1)
  memory.append(bfgs.memory_element(s=x2-x1, y=g2-g1))
  hg2 = bfgs.hg_two_loop_recursion(memory, hk0=h0, gk=g2)
  assert approx_equal(hg2, h2.matrix_multiply(g2))
  #
  x3 = x2 - 3/8 * hg2
  g3 = fgh.g(x3)
  h3 = bfgs.h_update(hk=h2, sk=x3-x2, yk=g3-g2)
  memory.append(bfgs.memory_element(s=x3-x2, y=g3-g2))
  hg3 = bfgs.hg_two_loop_recursion(memory, hk0=h0, gk=g3)
  assert approx_equal(hg3, h3.matrix_multiply(g3))

class refinery(object):

  def __init__(O, fgh):
    O.fgh = fgh
    O.x = flex.double([3,-4])
    O.prev_x = O.x.deep_copy()
    O.memory = []
    scitbx.lbfgs.run(target_evaluator=O)

  def compute_functional_and_gradients(O):
    return O.fgh.f(O.x), O.fgh.g(O.x)

  def callback_after_step(O, minimizer):
    xk = O.prev_x
    xl = O.x
    gk = O.fgh.g(xk)
    gl = O.fgh.g(xl)
    def check(bk, hk):
      hl = bfgs.h_update(hk, xl-xk, gl-gk)
      bl = bfgs.b_update(bk, xl-xk, gl-gk)
      assert approx_equal(matrix.sqr(hl).inverse(), bl)
      es = eigensystem.real_symmetric(bl)
      assert es.values().all_gt(0)
      assert bfgs.h0_scaling(sk=xl-xk, yk=gl-gk) > 0
    #
    bk = flex.double([[1,0],[0,1]])
    hk = bk
    check(bk, hk)
    #
    bk = O.fgh.h(xk)
    es = eigensystem.real_symmetric(bk)
    # TODO: verify es is not a dictionary yet has a values method
    if (es.values().all_gt(0)):
      hk = bk.deep_copy()
      hk.matrix_inversion_in_place()
      check(bk, hk)
    #
    h0 = flex.double([[0.9,0.1],[-0.2,0.8]])
    hg_tlr = bfgs.hg_two_loop_recursion(memory=O.memory, hk0=h0, gk=gl)
    h_upd = h0
    for m in O.memory:
      h_upd = bfgs.h_update(hk=h_upd, sk=m.s, yk=m.y)
    hg_upd = h_upd.matrix_multiply(gl)
    assert approx_equal(hg_tlr, hg_upd)
    #
    O.memory.append(bfgs.memory_element(s=xl-xk, y=gl-gk))
    O.prev_x = O.x.deep_copy()

class fgh1(object):

  def f(O, x):
    assert x.size() == 2
    a,b = x
    return (a-1)**2 + (b-2)**2

  def g(O, x):
    a,b = x
    return flex.double([2*(a-1), 2*(b-2)])

  def h(O, x):
    return flex.double([
      [2, 0],
      [0, 2]])

class fgh2(object):

  def f(O, x):
    assert x.size() == 2
    a,b = x
    return (a-1)**2 + sin(b-2)

  def g(O, x):
    a,b = x
    return flex.double([2*(a-1), cos(b-2)])

  def h(O, x):
    a,b = x
    return flex.double([
      [2, 0],
      [0, -sin(b-2)]])

def run(args):
  assert len(args) == 0
  for fgh in [fgh1, fgh2]:
    exercise_two_loop_recursion(fgh=fgh())
    refinery(fgh=fgh())
  print("OK")

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/omz/tst_dev.py
from __future__ import absolute_import, division, print_function
from cctbx.omz import dev
from cctbx.development import random_structure
from cctbx.development import debug_utils
from cctbx.array_family import flex
import random
import sys

if (1):
  random.seed(0)
  flex.set_random_seed(0)

def run_call_back(flags, space_group_info, params):
  structure_shake = random_structure.xray_structure(
    space_group_info,
    elements=("N", "C", "O"),
    volume_per_atom=200,
    min_distance=2.0,
    general_positions_only=params.general_positions_only,
    random_u_iso=True)
  structure_ideal = structure_shake.deep_copy_scatterers()
  structure_shake.shake_sites_in_place(rms_difference=params.shake_sites_rmsd)
  structure_shake.shake_adp(spread=params.shake_adp_spread)
  #
  r1 = dev.run_refinement(
    structure_ideal=structure_ideal,
    structure_shake=structure_shake,
    params=params).r1_factor()
  print("R1: %.4f" % r1)
  print()

def run(args):
  master_phil = dev.get_master_phil()
  argument_interpreter = master_phil.command_line_argument_interpreter()
  phil_objects = []
  remaining_args = []
  for arg in args:
    if (arg.find("=") >= 0):
      phil_objects.append(argument_interpreter.process(arg=arg))
    else:
      remaining_args.append(arg)
  work_phil = master_phil.fetch(sources=phil_objects)
  work_phil.show()
  print()
  params = work_phil.extract()
  debug_utils.parse_options_loop_space_groups(
    argv=remaining_args, call_back=run_call_back, params=params)

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************
