

 *******************************************************************************
cctbx/examples/__init__.py


 *******************************************************************************


 *******************************************************************************
cctbx/examples/adp_symmetry_constraints.py
from __future__ import absolute_import, division, print_function
from cctbx import sgtbx
from cctbx import uctbx
from cctbx import adptbx
import math

def run():
  #
  # try these Hall symbols:
  #   "P 1", "P 2", "P 3", "P 3*", "P 4", "P 6", "P 2 2 3"
  #
  space_group = sgtbx.space_group("P 3*") # Hall symbol

  #
  # initialization of space group symmetry constraints
  #
  adp_constraints = sgtbx.tensor_rank_2_constraints(
    space_group=space_group,
    reciprocal_space=True)

  #
  # number of independent u_star parameters
  #
  n_indep = adp_constraints.n_independent_params()

  #
  # arbitrary Miller index and u_star tensor
  #
  h = (3,1,2)
  u_star=(0.000004, 0.000004, 0.000007, 0.000002, 0.0000000, 0.0000000)
  # optional: enforce symmetry at the beginning
  u_star = space_group.average_u_star(u_star)

  #
  # pass u_indep to the minimizer
  #
  u_indep = adp_constraints.independent_params(all_params=u_star)
  assert len(u_indep) == n_indep

  #
  # "expand" the independent parameters modified by the minimizer
  #
  u_star = adp_constraints.all_params(independent_params=u_indep)
  assert len(u_star) == 6

  #
  # these calculations are completely independent of the symmetry
  #
  dwf = adptbx.debye_waller_factor_u_star(h, u_star)
  gc = adptbx.debye_waller_factor_u_star_gradient_coefficients(h)
  # all_gradients is an array of six values
  all_gradients = [-2*math.pi**2 * dwf * c for c in gc]
  assert len(all_gradients) == 6
  cc = adptbx.debye_waller_factor_u_star_curvature_coefficients(h)
  # all_curvatures is an array of 21 values (upper triangle of 6x6 matrix)
  all_curvatures = (-2*math.pi**2)**2 * dwf * cc
  assert len(all_curvatures) == 6*(6+1)//2

  #
  # here we apply the symmetry constraints to the gradients and curvatures
  #
  # g_indep is an array of n_indep values
  g_indep = adp_constraints.independent_gradients(
    all_gradients=all_gradients)
  assert len(g_indep) == n_indep
  # c_indep is an array of n_indep*(n_indep+1)/2 values (upper triangle)
  c_indep = adp_constraints.independent_curvatures(
    all_curvatures=all_curvatures)
  assert len(c_indep) == n_indep*(n_indep+1)//2
  # feed g_indep and c_indep to the minimizer

  #
  # initialization of site symmetry constraints
  # (for sites on special positions)
  #
  unit_cell = uctbx.unit_cell((12,12,15,90,90,120))
  space_group = sgtbx.space_group_info("P 6").group()
  site_symmetry = sgtbx.site_symmetry(
    unit_cell=unit_cell,
    space_group=space_group,
    original_site=(1/3.,2/3.,0), # site on 3-fold axis
    min_distance_sym_equiv=0.5)
  assert len(site_symmetry.matrices()) == 3
  adp_constraints = site_symmetry.adp_constraints()
  # use adp_constraints as before

  print("OK")

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/all_axes.py
from __future__ import absolute_import, division, print_function
# List all axes in the unit cell.

# usage:
#   cctbx.python all_axes.py     - show axes for the 230 reference settings.
#   cctbx.python all_axes.py P2  - show axes for (e.g.) space group P2

# XXX Some further refinement is required:
# XXX   - List only the axes of highest order (e.g. only 4, not 4 and 2).
# XXX   - List only the axes with the smallest intrinsic component
# XXX     (e.g. list only 3(1), not both 3(1) and 3(2)).
# XXX See also: comment regarding shift_range below.

from cctbx import sgtbx
import sys
from six.moves import range

def str_ev(ev):
  return "[%d,%d,%d]" % ev

def rt_mx_analysis(s):
  r_info = sgtbx.rot_mx_info(s.r())
  t_info = sgtbx.translation_part_info(s)
  t_intrinsic = str(t_info.intrinsic_part().mod_positive())
  t_shift = str(t_info.origin_shift().mod_positive())
  if (r_info.type() == 1):
    return ("1", "-", "-", "-")
  if (r_info.type() == -1):
    return (str(r_info.type()), "-", "-", "(%s)" % (t_shift,))
  if (abs(r_info.type()) == 2):
    return (str(r_info.type()),
            str_ev(r_info.ev()),
            "(%s)" % (t_intrinsic,),
            "(%s)" % (t_shift,))
  return (str(r_info.type()),
          str_ev(r_info.ev()),
          "(%s)" % (t_intrinsic,),
          "(%s)" % (t_shift,))

def list_all_axes(space_group_symbol=None, space_group_info=None):
  assert space_group_symbol is None or space_group_info is None
  shift_range = 1 # XXX Works for the 230 reference settings; it is not
                  # XXX clear to me (rwgk) what value is needed in general.
  if (space_group_symbol is not None):
    space_group_info = sgtbx.space_group_info(symbol=space_group_symbol)
  space_group_info.show_summary()
  print()
  print("Rotation type, Axis direction, Intrinsic part, Origin shift")
  axes_dict = {}
  for s in space_group_info.group():
    r = s.r()
    t = s.t()
    shift = [0,0,0]
    for shift[0] in range(-shift_range,shift_range+1):
      for shift[1] in range(-shift_range,shift_range+1):
        for shift[2] in range(-shift_range,shift_range+1):
          ts = t.plus(sgtbx.tr_vec(shift, 1)).new_denominator(t.den())
          ss = sgtbx.rt_mx(r, ts)
          axes_dict[rt_mx_analysis(ss)] = 0
  axes_list = list(axes_dict.keys())
  axes_list.sort()
  for a in axes_list:
    print(a)
  print()

def run():
  if (len(sys.argv) == 1):
    for i in range(230):
      list_all_axes(i + 1)
  else:
    for symbol in sys.argv[1:]:
      list_all_axes(symbol)

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/analyze_adp.py
from __future__ import absolute_import, division, print_function
# Simple example for the use of the adptbx.

from cctbx import crystal
from cctbx import adptbx # anisotropic displacement parameter toolbox
from six.moves import range

def run():
  symmetry = crystal.symmetry(
    unit_cell=(10.67, 10.67, 4.68, 90, 90, 120),
    space_group_symbol="P 3")

  special_position_settings = crystal.special_position_settings(
    crystal_symmetry=symmetry,
    min_distance_sym_equiv=0.5)

  site = (0, 0, 0.236)
  u_cif = ((0.17, 0.17, 0.19, 0.09, 0, 0))

  site_symmetry = special_position_settings.site_symmetry(site)

  print("Input Ucif:", u_cif)
  u_star = adptbx.u_cif_as_u_star(symmetry.unit_cell(), u_cif)
  if (not site_symmetry.is_compatible_u_star(u_star)):
    print("Warning: ADP tensor is incompatible with site symmetry.")
  u_star = site_symmetry.average_u_star(u_star)
  u_cif = adptbx.u_star_as_u_cif(symmetry.unit_cell(), u_star)
  print("Averaged Ucif:", u_cif)

  u_cart = adptbx.u_star_as_u_cart(symmetry.unit_cell(), u_star)
  eigenvalues = adptbx.eigenvalues(u_cart)
  if (not adptbx.is_positive_definite(eigenvalues)):
    print("ADP tensor is not positive definite.")

  print("Eigenvectors and values:")
  eigensystem = adptbx.eigensystem(u_cart)
  for i in range(3):
    print("  v=(%.5f %.5f %.5f) " % eigensystem.vectors(i), end=' ')
    print("lambda=%.4f" % (eigensystem.values()[i],))

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/ccp4_map.py
from __future__ import absolute_import, division, print_function

from iotbx.file_reader import any_file
import iotbx
from cctbx.maptbx import shift_origin_if_needed
from cctbx.array_family import flex

import sys

def run(args):
  map_fname = args[0]
  af = any_file(map_fname)
  assert af.file_type == "ccp4_map"
  ccp4_map = af.file_content
  print("origin:", ccp4_map.origin)
  # see how access this info in cctbx_project/iotbx/ccp4_map/__init__.py: def show_summary
  print("summary:", ccp4_map.show_summary())
  xc = yc = zc = 1 # real coordinates
  # fractional coordinates
  xf,yf,zf = ccp4_map.unit_cell().fractionalize([xc,yc,zc])
  print( "map value:", ccp4_map.map_data().eight_point_interpolation([xf, yf, zf]))
  shifted_map_data = shift_origin_if_needed(ccp4_map.map_data()).map_data
  print( "map value on shifted map:", shifted_map_data.eight_point_interpolation([xf, yf, zf]))
  print( "shifted origin:", shifted_map_data.origin())
  # This does not work for non 0-based (non-shifted) map
  print( "map value at closes grid point:", shifted_map_data.value_at_closest_grid_point([xf, yf, zf]))

  cs = ccp4_map.crystal_symmetry()
  # writing shifted map
  iotbx.mrcfile.write_ccp4_map(
            file_name="shifted_map.map",
            unit_cell=cs.unit_cell(),
            space_group=cs.space_group(),
            map_data=shifted_map_data,
            labels=flex.std_string([""]))

if __name__ == '__main__':
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/examples/change_hand_p31.py
"""
This example shows that a change of hand ("flipping coordinates") involves
changing the space group if the space group is enantimorphic.
Note that the interatomic distances do not change if the space group
symmetry is transformed correctly, but do change if the original space
group symmetry is simply retained.
"""
from __future__ import absolute_import, division, print_function

from cctbx import xray
from cctbx import crystal
from cctbx.array_family import flex

def run():
  print(__doc__)
  crystal_symmetry = crystal.symmetry(
    unit_cell=(5, 5, 6, 90, 90, 120),
    space_group_symbol="P 31")
  distance_cutoff = 2.5
  scatterers = flex.xray_scatterer()
  for i,site in enumerate([(0.7624, 0.5887, 0.3937),
                           (0.2813, 0.9896, 0.9449),
                           (0.4853, 0.8980, 0.4707)]):
    scatterers.append(xray.scatterer(
      label="Se%d"%(i+1), site=site))
  given_structure = xray.structure(
    crystal_symmetry=crystal_symmetry,
    scatterers=scatterers)
  print("==================")
  print("Original structure")
  print("==================")
  given_structure.show_summary().show_scatterers()
  print("Interatomic distances:")
  given_structure.show_distances(distance_cutoff=distance_cutoff)
  print()
  print()
  print("=====================================================")
  print("Other hand with sites flipped and space group changed")
  print("=====================================================")
  other_hand = given_structure.change_hand()
  other_hand.show_summary().show_scatterers()
  print("Interatomic distances:")
  other_hand.show_distances(distance_cutoff=distance_cutoff)
  print()
  print("==================================")
  print("Other hand with sites flipped only")
  print("==================================")
  other_sites_orig_symmetry = xray.structure(
    crystal_symmetry=crystal_symmetry,
    scatterers=other_hand.scatterers())
  other_sites_orig_symmetry.show_summary().show_scatterers()
  print("Interatomic distances:")
  other_sites_orig_symmetry.show_distances(distance_cutoff=distance_cutoff)
  print()

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/convert_ccp4_symop_lib.py
from __future__ import absolute_import, division, print_function
# Example by Kevin Cowtan, 2001. Public Domain.
# Converted to Python by Ralf W. Grosse-Kunstleve.
# This little program reads the CCP4 symmetry library file, and interprets
# the symops. It then returns the Hall code for the spacegroup. Used to
# create a new library file to allow compatible spacegroup naming between
# CCP4 and cctbx.
#
# usage: convert_ccp4_symop_lib < symop.lib

from cctbx import sgtbx
import sys
from six.moves import range

def run():
  while 1:
    line = sys.stdin.readline()[:-1]
    flds = line.split(None, 2)
    if (len(flds) == 0): break
    nspgrp = int(flds[0]) # read spacegroup number
    nsym = int(flds[1]) # read nsym
    print(nspgrp, nsym, flds[2]) # print it all
    group = sgtbx.space_group() # now interpret the symops
    for i in range(nsym):
      line = sys.stdin.readline()[:-1] # get the i'th symop
      # print line
      group.expand_smx(sgtbx.rt_mx(line)) # and interpret
    info = sgtbx.space_group_info(group=group)
    print(info.type().hall_symbol()) # now produce the sg symbol
    print(info)

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/cr2o3_consistency_checks.py
from __future__ import absolute_import, division, print_function
from cctbx import xray
from cctbx import crystal
import cctbx.crystal.coordination_sequences
from cctbx.array_family import flex
from six.moves import zip

def demo():
  """
  Result of ICSD query:
    N * -Cr2O3-[R3-CH] Baster, M.;Bouree, F.;Kowalska, A.;Latacz, Z(2000)
    C 4.961950 4.961950 13.597400 90.000000 90.000000 120.000000
    S GRUP R -3 C
    A Cr1    0.000000 0.000000 0.347570 0.000000
    A O1    0.305830 0.000000 0.250000
  """
  crystal_symmetry = crystal.symmetry(
    unit_cell="4.961950 4.961950 13.597400 90.000000 90.000000 120.000000",
    space_group_symbol="R -3 C")
  scatterers = flex.xray_scatterer()
  scatterers.append(xray.scatterer(
    label="Cr1", site=(0.000000,0.000000,0.347570)))
  scatterers.append(xray.scatterer(
    label="O1", site=(0.305830,0.000000,0.250000)))
  icsd_structure = xray.structure(
    crystal_symmetry=crystal_symmetry,
    scatterers=scatterers)
  icsd_structure.show_summary().show_scatterers()
  print()
  icsd_pairs = icsd_structure.show_distances(
    distance_cutoff=2.5, keep_pair_asu_table=True)
  print()
  primitive_structure = icsd_structure.primitive_setting()
  primitive_structure.show_summary().show_scatterers()
  print()
  p1_structure = primitive_structure.expand_to_p1()
  p1_structure.show_summary().show_scatterers()
  print()
  p1_pairs = p1_structure.show_distances(
    distance_cutoff=2.5, keep_pair_asu_table=True)
  print()
  for label,structure,pairs in [("ICSD", icsd_structure,icsd_pairs),
                                ("P1", p1_structure,p1_pairs)]:
    print("Coordination sequences for", label, "structure")
    term_table = crystal.coordination_sequences.simple(
      pair_asu_table=pairs.pair_asu_table,
      max_shell=10)
    crystal.coordination_sequences.show_terms(
      structure=structure,
      term_table=term_table)
    print()
  icsd_f_calc = icsd_structure.structure_factors(
    d_min=1, algorithm="direct").f_calc()
  icsd_f_calc_in_p1 = icsd_f_calc.primitive_setting().expand_to_p1()
  p1_f_calc = icsd_f_calc_in_p1.structure_factors_from_scatterers(
    xray_structure=p1_structure, algorithm="direct").f_calc()
  for h,i,p in zip(icsd_f_calc_in_p1.indices(),
                   icsd_f_calc_in_p1.data(),
                   p1_f_calc.data()):
    print(h, abs(i), abs(p)*3)
  print("OK")

if (__name__ == "__main__"):
  demo()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/cr2o3_primitive_cell.py
from __future__ import absolute_import, division, print_function
from cctbx import xray
from cctbx import crystal
from cctbx.array_family import flex

def demo():
  """
  Result of ICSD query:
    N * -Cr2O3-[R3-CH] Baster, M.;Bouree, F.;Kowalska, A.;Latacz, Z(2000)
    C 4.961950 4.961950 13.597400 90.000000 90.000000 120.000000
    S GRUP R -3 C
    A Cr1    0.000000 0.000000 0.347570 0.000000
    A O1    0.305830 0.000000 0.250000
  """
  crystal_symmetry = crystal.symmetry(
    unit_cell="4.961950 4.961950 13.597400 90.000000 90.000000 120.000000",
    space_group_symbol="R -3 C")
  scatterers = flex.xray_scatterer()
  scatterers.append(xray.scatterer(
    label="Cr1", site=(0.000000,0.000000,0.347570)))
  scatterers.append(xray.scatterer(
    label="O1", site=(0.305830,0.000000,0.250000)))
  icsd_structure = xray.structure(
    crystal_symmetry=crystal_symmetry,
    scatterers=scatterers)
  icsd_structure.show_summary().show_scatterers()
  print()
  icsd_structure.show_distances(distance_cutoff=2.5)
  print()
  primitive_structure = icsd_structure.primitive_setting()
  primitive_structure.show_summary().show_scatterers()
  print()
  p1_structure = primitive_structure.expand_to_p1()
  p1_structure.show_summary().show_scatterers()
  print()
  print("OK")

if (__name__ == "__main__"):
  demo()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/exp_i_alpha_derivatives.py
from __future__ import absolute_import, division, print_function
import cmath
import math
from six.moves import zip

class least_squares:

  def __init__(self, obs, calc):
    self.obs = obs
    self.calc = calc
    a, b = self.calc.real, self.calc.imag
    self.abs_calc = math.sqrt(a**2 + b**2)
    self.delta = self.obs - self.abs_calc

  def f(self):
    "Mathematica: f=(obs-Sqrt[a^2+b^2])^2"
    return self.delta**2

  def da(self):
    "Mathematica: D[f,a]"
    if (self.abs_calc == 0): return 0
    return -2 * self.delta * self.calc.real / self.abs_calc

  def db(self):
    "Mathematica: D[f,b]"
    if (self.abs_calc == 0): return 0
    return -2 * self.delta * self.calc.imag / self.abs_calc

  def daa(self):
    "Mathematica: FortranForm[FullSimplify[D[f,a,a]]]"
    ac = self.abs_calc
    if (ac == 0):
      if (self.obs == 0): return 2
      return -1.e160
    return 2 - (2*self.calc.imag**2*self.obs)/ac/ac/ac

  def dbb(self):
    "Mathematica: FortranForm[FullSimplify[D[f,b,b]]]"
    ac = self.abs_calc
    if (ac == 0):
      if (self.obs == 0): return 2
      return -1.e160
    return 2 - (2*self.calc.real**2*self.obs)/ac/ac/ac

  def dab(self):
    "Mathematica: FortranForm[FullSimplify[D[f,a,b]]]"
    ac = self.abs_calc
    if (ac == 0):
      if (self.obs == 0): return 0
      return 1.e160
    return (2*self.calc.real*self.calc.imag*self.obs)/ac/ac/ac

class exp_i_alpha_sum:

  def __init__(self, alphas):
    self.alphas = alphas

  def f(self):
    "Mathematica: f=Exp[I alpha]"
    result = 0
    for alpha in self.alphas:
      result += cmath.exp(1j*alpha)
    return result

  def d_alphas(self):
    "Mathematica: D[f,alpha]"
    return [1j*cmath.exp(1j*alpha) for alpha in self.alphas]

  def d2_alphas(self):
    "Mathematica: D[f,alpha,alpha]"
    return [-cmath.exp(1j*alpha) for alpha in self.alphas]

  def d_target_d_alphas(self, target):
    "Rule for derivatives of sum of roots of unity."
    da, db = target.da(), target.db()
    return [da * d.real + db * d.imag for d in self.d_alphas()]

  def d2_target_d_alphas(self, target):
    "Product rule applied to da * d.real + db * d.imag."
    result = []
    da, db = target.da(), target.db()
    daa, dbb, dab = target.daa(), target.dbb(), target.dab()
    d = self.d_alphas()
    d2 = self.d2_alphas()
    for di,d2i in zip(d, d2):
      row = []
      for dj in d:
        sum = daa * di.real * dj.real \
            + dbb * di.imag * dj.imag \
            + dab * (di.real * dj.imag + di.imag * dj.real)
        if (di is dj):
          sum += da * d2i.real + db * d2i.imag
        row.append(sum)
      result.append(row)
    return result


 *******************************************************************************


 *******************************************************************************
cctbx/examples/f_model_example.py
from __future__ import absolute_import, division, print_function
from cctbx.array_family import flex
from cctbx import xray
from cctbx import sgtbx
from cctbx.development import random_structure as rs

def f_model_example():
  """ This example illustrates the use of the f_model class"""

  # make up some structure factors
  random_structure = rs.xray_structure(
    sgtbx.space_group_info( 'P1' ),
    elements=['C']*310,
    n_scatterers=310)

  # here f_atoms, f_mask and f_part are all the same
  # doens't make sense of course
  sfs = random_structure.structure_factors( False, 3.5,  ).f_calc()
  f_model_structure_factors =  xray.f_model_core_data( hkl = sfs.indices(),
                                             f_atoms= sfs.data(),
                                             f_mask = sfs.data(),
                                             unit_cell = sfs.unit_cell(),
                                             k_overall=1.0,
                                             u_star=(0,0,0,0,0,0),
                                             k_sol=1.0,
                                             u_sol=1.0,
                                             f_part=None,
                                             k_part=0,
                                             u_part=0 )

  #Resetting model parameters
  #
  # over all scale parameters; scale and aniso Ustar
  f_model_structure_factors.renew_overall_scale_parameters(
    3.0,(0,0,0,0,0,0) )
  # bulk solvent scale parameters; scale and B
  f_model_structure_factors.renew_bulk_solvent_scale_parameters(0.55,50.0)
  # partial structure scale parameters; scale and B
  f_model_structure_factors.renew_partial_structure_scale_parameters(0.05,25.0)

  # is is also possible to reset the values term by term ratrher then grouped
  f_model_structure_factors.ksol( 1.0 )
  f_model_structure_factors.usol( 3.0 )
  f_model_structure_factors.kpart( 1.0 )
  f_model_structure_factors.upart( 3.0 )
  f_model_structure_factors.koverall( 1.0 )
  f_model_structure_factors.ustar( (0,0,0,0,0,0) )
  # the cached arrays of various scale factor as updated automatically.

  # Obtaining the current parameters
  ksol = f_model_structure_factors.ksol()
  bsol = f_model_structure_factors.usol()
  kpart = f_model_structure_factors.kpart()
  bpart = f_model_structure_factors.upart()
  koverall = f_model_structure_factors.koverall()
  ustar = f_model_structure_factors.ustar()

  # Derivatives
  #
  #
  #derivates can be obtained accumalated over the full dataset
  # or on a struct term by term bases
  #what is needed in any case are one of the following arrays or floats
  # - d(target)/d(|F_model|)
  # - d(target)/d(Re[F_model]), d(target)/d(Im[F_model])
  #
  # which derivates are computed, is controlled by an array of gradient flags:
  # the order is (koverall, ustar, ksol, bsol, kpart, bpart )
  #
  gradient_flags = flex.bool([True,True,
                              True,True,
                              True,True])
  #
  # Use this function call is your target function returns
  # d(target)/d(|Fmodel|)
  dt_dabsfmodel = flex.double( sfs.data().size(), 1 )
  dtdall = f_model_structure_factors.d_target_d_all(
    dt_dabsfmodel,gradient_flags )

  # Use this function call is your target function returns
  # d(target)/d(Re[Fmodel]), d(target)/d(Im[Fmodel])
  dtda = dt_dabsfmodel
  dtdb = dt_dabsfmodel

  dtdall = f_model_structure_factors.d_target_d_all(
    dtda, dtdb, gradient_flags)
  # if desired (likely in c++, not in python) you can do it term by term.
  hkl_no=123
  dtdsingle = f_model_structure_factors.d_target_d_all(
    dtda[hkl_no], dtdb[hkl_no], hkl_no, gradient_flags)

  # the resulting gradients are delivered as a
  # 'f_model_derivative_holder'
  # it has methods both to set as well as to get items.
  #
  # getting the values
  tmp = dtdsingle.koverall()
  tmp = dtdsingle.ustar()
  tmp = dtdsingle.ksol()
  tmp = dtdsingle.usol()
  tmp = dtdsingle.kpart()
  tmp = dtdsingle.upart()
  #
  # if desired, you can set values as well
  dtdsingle.koverall(1)
  dtdsingle.ustar(  (1,1,1,1,1,1)  )
  dtdsingle.ksol(1)
  dtdsingle.usol(1)
  dtdsingle.kpart(1)
  dtdsingle.upart(1)



  #if desired, a selection can be made on the f_model object.
  #currently, only an integer selection is supported
  new_f_model_object = f_model_structure_factors.select( flex.int([1,2,3]) )
  assert  new_f_model_object.f_model().size()==3


if (__name__ == "__main__" ):
  f_model_example()
  print("OK")


 *******************************************************************************


 *******************************************************************************
cctbx/examples/fft_map_electron_density_around_atom.py
from __future__ import absolute_import, division, print_function
from cctbx import xray
from cctbx import miller
from cctbx import crystal
from cctbx import maptbx
from cctbx.adptbx import u_as_b
from cctbx.array_family import flex
from scitbx import matrix
from libtbx.math_utils import ifloor
from libtbx.test_utils import approx_equal
from six.moves import range

def rho_stats(
      xray_structure,
      d_min,
      resolution_factor,
      electron_sum_radius,
      zero_out_f000):
  n_real = []
  n_half_plus = []
  n_half_minus = []
  s2 = d_min * resolution_factor * 2
  for l in xray_structure.unit_cell().parameters()[:3]:
    nh = ifloor(l / s2)
    n_real.append(2*nh+1)
    n_half_plus.append(nh)
    n_half_minus.append(-nh)
  n_real = tuple(n_real)
  n_real_product = matrix.col(n_real).product()
  crystal_gridding = maptbx.crystal_gridding(
    unit_cell=xray_structure.unit_cell(),
    space_group_info=xray_structure.space_group_info(),
    pre_determined_n_real=n_real)
  miller_indices = flex.miller_index()
  miller_indices.reserve(n_real_product)
  for h in flex.nested_loop(n_half_minus, n_half_plus, open_range=False):
    miller_indices.append(h)
  assert miller_indices.size() == n_real_product
  #
  miller_set = miller.set(
    crystal_symmetry=xray_structure,
    anomalous_flag=True,
    indices=miller_indices).sort(by_value="resolution")
  assert miller_set.indices()[0] == (0,0,0)
  f_calc = miller_set.structure_factors_from_scatterers(
    xray_structure=xray_structure,
    algorithm="direct",
    cos_sin_table=False).f_calc()
  if (zero_out_f000):
    f_calc.data()[0] = 0j
  #
  unit_cell_volume = xray_structure.unit_cell().volume()
  voxel_volume = unit_cell_volume / n_real_product
  number_of_miller_indices = []
  rho_max = []
  electron_sums_around_atoms = []
  densities_along_x = []
  for f in [f_calc, f_calc.resolution_filter(d_min=d_min)]:
    assert f.indices()[0] == (0,0,0)
    number_of_miller_indices.append(f.indices().size())
    fft_map = miller.fft_map(
      crystal_gridding=crystal_gridding,
      fourier_coefficients=f)
    assert fft_map.n_real() == n_real
    rho = fft_map.real_map_unpadded() / unit_cell_volume
    assert approx_equal(voxel_volume*flex.sum(rho), f_calc.data()[0])
    if (xray_structure.scatterers().size() == 1):
      assert flex.max_index(rho) == 0
      rho_max.append(rho[0])
    else:
      rho_max.append(flex.max(rho))
    site_cart = xray_structure.sites_cart()[0]
    gias = maptbx.grid_indices_around_sites(
      unit_cell=xray_structure.unit_cell(),
      fft_n_real=n_real,
      fft_m_real=n_real,
      sites_cart=flex.vec3_double([site_cart]),
      site_radii=flex.double([electron_sum_radius]))
    electron_sums_around_atoms.append(
      flex.sum(rho.as_1d().select(gias))*voxel_volume)
    #
    a = xray_structure.unit_cell().parameters()[0]
    nx = n_real[0]
    nxh = nx//2
    x = []
    y = []
    for ix in range(-nxh,nxh+1):
      x.append(a*ix/nx)
      y.append(rho[(ix%nx,0,0)])
    densities_along_x.append((x,y))
  #
  print("%3.1f %4.2f %-12s %5d %5d | %6.3f %6.3f | %6.3f %6.3f | %4.2f %5.1f" % (
      d_min,
      resolution_factor,
      n_real,
      number_of_miller_indices[0],
      number_of_miller_indices[1],
      electron_sums_around_atoms[0],
      electron_sums_around_atoms[1],
      rho_max[0],
      rho_max[1],
      f_calc.data()[0].real,
      u_as_b(xray_structure.scatterers()[0].u_iso)))
  #
  return densities_along_x

table_header = """\
                          hkl     |    electrons  |     rho max
res fac  grid           all Ewald |    all  Ewald |    all  Ewald | F000  Biso\
"""

def build_xray_structure_with_carbon_along_x(a, b_iso, x=[0]):
  result = xray.structure(
    crystal_symmetry=crystal.symmetry(
      unit_cell=(a,a,a,90,90,90),
      space_group_symbol="P1"))
  for i,v in enumerate(x):
    result.add_scatterer(xray.scatterer(
      label="C%d" % (i+1), scattering_type="C", site=(v,0,0), b=b_iso))
  reg = result.scattering_type_registry(table="n_gaussian", d_min=1/12)
  g = reg.as_type_gaussian_dict()["C"]
  assert g.n_terms() == 5
  assert not g.use_c()
  return result

def loop_res_fac(b, electron_sum_radius=2, zero_out_f000=False):
  xray_structure = build_xray_structure_with_carbon_along_x(a=10, b_iso=b)
  xray_structure.show_scatterers()
  print(table_header)
  for d_min in [4, 3, 2, 1]:
    for resolution_factor in [1/2, 1/3, 1/4]:
      rho_stats(
        xray_structure=xray_structure,
        d_min=d_min,
        resolution_factor=resolution_factor,
        electron_sum_radius=electron_sum_radius,
        zero_out_f000=False)

def run(args):
  assert len(args) == 0
  for b in [0, 5, 20]:
    loop_res_fac(b=b)
  print("OK")

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/examples/find_distances_using_cpp_objects.py
from __future__ import absolute_import, division, print_function
import cctbx.crystal.direct_space_asu
import cctbx.sgtbx.direct_space_asu.reference_table
from cctbx.sgtbx.direct_space_asu import proto
from cctbx.array_family import flex
import sys

"""
Distance calculations using C++ classes as directly as possible.

This example is rather unusual as a Python example. There are much
higher-level Python interfaces building on the C++ classes used below
(e.g. cctbx.xray.structure.show_distances()). There is no significant
runtime penalty using the Python interfaces since all numerically
intensive calculations are implemented in C++.

The C++ implementation of the direct_space_asu class is still work in
progress (cctbx/sgtbx/direct_space_asu/proto). Currently this example
uses the Python implementation. Therefore the first part of the
find_distances() function does not directly translate into C++.
The second part of find_distances() is easily converted into C++.
"""

def find_distances(unit_cell, space_group, sites_frac, distance_cutoff):
  space_group_type = space_group.type()

  # reference_asu, metric_free_asu, and asu are Python objects
  reference_asu = cctbx.sgtbx.direct_space_asu.reference_table.get_asu(
    space_group_type.number())
  metric_free_asu = reference_asu.change_basis(
    space_group_type.cb_op() # change_of_basis_op_to_reference_setting
      .inverse())
  asu = cctbx.crystal.direct_space_asu.direct_space_asu(
      asu=metric_free_asu, unit_cell=unit_cell)

  proto_asu = proto.direct_space_asu(space_group_type) # C++ type
  # todo in C++: convert proto_asu cuts to as_float_cut_plane()

  # all objects below are wrapped C++ objects
  float_asu = cctbx.crystal.direct_space_asu_float_asu(
    unit_cell=unit_cell,
    cuts=[cut.as_float_cut_plane() for cut in metric_free_asu.cuts],
    is_inside_epsilon=1.e-6)
  asu_mappings = cctbx.crystal.direct_space_asu_asu_mappings(
    space_group=space_group,
    asu=float_asu,
    buffer_thickness=distance_cutoff)
  asu_mappings.process_sites_frac(
    original_sites=sites_frac, min_distance_sym_equiv=0.5)
  pair_asu_table = cctbx.crystal.pair_asu_table(asu_mappings=asu_mappings)
  pair_asu_table.add_all_pairs(distance_cutoff=distance_cutoff)
  pair_sym_table = pair_asu_table.extract_pair_sym_table()
  for i,pair_sym_dict in enumerate(pair_sym_table):
    print("i:", i)
    for j,sym_ops in pair_sym_dict.items():
      print("  j:", j)
      for sym_op in sym_ops:
        frac_i = sites_frac[i]
        frac_j = sites_frac[j]
        frac_ji = sym_op * frac_j
        print("    %-20s %8.3f" % (
          str(sym_op), unit_cell.distance(frac_i, frac_ji)))

def run(args):
  assert len(args) == 0
  # quartz structure
  # http://cci.lbl.gov/publications/download/iucrcompcomm_jan2003.pdf
  unit_cell = cctbx.uctbx.unit_cell((5.01,5.01,5.47,90,90,120))
  space_group = cctbx.sgtbx.space_group_info(symbol="P6222").group()
  sites_frac = flex.vec3_double([(1/2.,1/2.,1/3.), (0.197,-0.197,0.83333)])
  find_distances(
    unit_cell=unit_cell,
    space_group=space_group,
    sites_frac=sites_frac,
    distance_cutoff=5)

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/examples/find_sys_abs_equiv_space_groups.py
"""
Determination of sets of space groups that cannot be distinguished by
inspection of systematic absences.

From first principles; inelegant theoretically, but compact and practical.

See also: International Tables for Crystallography, Volume A, section 3.
"""
from __future__ import absolute_import, division, print_function
from six.moves import range

def run(args):
  assert args in [[], ["python"], ["c++"]]
  #
  sgno_list_by_index_list_by_cs = {}
  from cctbx import sgtbx
  from cctbx import miller
  for symbols in sgtbx.space_group_symbol_iterator():
    psgi = sgtbx.space_group_info(symbols.universal_hermann_mauguin()) \
      .primitive_setting()
    p_indices = miller.index_generator(
      space_group_type=psgi.type(),
      anomalous_flag=False,
      max_index=[4]*3).to_array()
        # 4 is the smallest value leading to correct results; any larger
        # value will work, too, but will make this procedure slower
    p1_indices = miller.expand_to_p1_iselection(
      space_group=psgi.group(),
      anomalous_flag=False,
      indices=p_indices,
      build_iselection=False).indices
    from cctbx.array_family import flex
    sort_perm = flex.sort_permutation(
      data=miller.index_span(p1_indices).pack(p1_indices))
    p1_indices = p1_indices.select(sort_perm)
    index_list = tuple(p1_indices)
    sgno = psgi.type().number()
    sgno_list_by_index_list = sgno_list_by_index_list_by_cs \
      .setdefault(symbols.crystal_system(), {})
    sgno_list_by_index_list.setdefault(index_list, []).append(sgno)
  from scitbx.graph import tardy_tree
  cluster_manager = tardy_tree.cluster_manager(n_vertices=231)
  for cs,sgno_list_by_index_list in sgno_list_by_index_list_by_cs.items():
    for sgno_list in sgno_list_by_index_list.values():
      i = sgno_list[0]
      for j in sgno_list[1:]:
        cluster_manager.connect_vertices(i=i, j=j, optimize=True)
  cluster_manager.tidy()
  #
  # everything below is just to format the results
  #
  if (args == []):
    for cluster in cluster_manager.clusters:
      if (len(cluster) == 1): break
      print(cluster)
  else:
    note = ("""\
Output of: cctbx/examples/find_sys_abs_equiv_space_groups.py %s
If you have to edit this table, please send email to: cctbx@cci.lbl.gov
""" % args[0]).splitlines()
    #
    if (args == ["python"]):
      print("space_group_numbers = [")
      for line in note:
        print("  #", line)
      ci = cluster_manager.cluster_indices
      cl = cluster_manager.clusters
      for sgno in range(231):
        cluster = list(cl[ci[sgno]])
        cluster.remove(sgno)
        if (len(cluster) == 0): s = "None"
        else:                   s = str(tuple(cluster))
        if (sgno == 230): comma = ""
        else:             comma = ","
        print("  %s%s" % (s, comma))
      print("]")
    else:
      print("""\
#ifndef CCTBX_SGTBX_SYS_ABS_EQUIV_H
#define CCTBX_SGTBX_SYS_ABS_EQUIV_H

namespace cctbx { namespace sgtbx { namespace sys_abs_equiv {
""")
      data = []
      ci = cluster_manager.cluster_indices
      cl = cluster_manager.clusters
      for line in note:
        print("  //", line)
      for sgno in range(231):
        cluster = list(cl[ci[sgno]])
        cluster.remove(sgno)
        if (len(cluster) == 0):
          data.append("0")
        else:
          cid = "data_%03d" % sgno
          data.append(cid)
          print("  static const unsigned %s[] = {%d, %s};" % (
            cid, len(cluster), ", ".join([str(i) for i in cluster])))
      print("")
      print("  static const unsigned* space_group_numbers[] = {")
      print("   ", ",\n    ".join(data))
      print("""\
    };

}}}

#endif // GUARD""")

if (__name__ == "__main__"):
  import sys
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/examples/g_exp_i_alpha_derivatives.py
from __future__ import absolute_import, division, print_function
import cmath
from six.moves import zip

class parameters:

  def __init__(self, alpha, g, ffp, fdp):
    self.alpha = alpha
    self.g = g
    self.ffp = ffp
    self.fdp = fdp

  def as_list(self):
    return [self.alpha, self.g, self.ffp, self.fdp]

class gradients(parameters): pass

class curvatures:

  def __init__(self, alpha_alpha, alpha_g, alpha_ffp, alpha_fdp, g_ffp, g_fdp):
    self.alpha_alpha = alpha_alpha
    self.alpha_g = alpha_g
    self.alpha_ffp = alpha_ffp
    self.alpha_fdp = alpha_fdp
    self.g_ffp = g_ffp
    self.g_fdp = g_fdp

def pack_parameters(params):
  result = []
  for p in params:
    result.extend(p.as_list())
  return result

def pack_gradients(grads):
  return pack_parameters(grads)

class g_exp_i_alpha_sum:

  def __init__(self, params):
    self.params = params

  def f(self):
    "Mathematica: f=g Exp[I alpha]"
    result = 0
    for p in self.params:
      result += p.g * (p.ffp + 1j*p.fdp) * cmath.exp(1j*p.alpha)
    return result

  def d_params(self):
    "Mathematica: D[f,g]; D[f,ffp]; D[f,fdp]; D[f,alpha]"
    result = []
    for p in self.params:
      eja = cmath.exp(1j*p.alpha)
      ffpifdp = p.ffp + 1j*p.fdp
      result.append(gradients(
        alpha=p.g*ffpifdp*1j*eja,
        g=ffpifdp*eja,
        ffp=p.g*eja,
        fdp=p.g*1j*eja))
    return result

  def d2_params(self):
    """Mathematica:
         D[f,alpha,alpha]; D[f,alpha,g]; D[f,alpha,ffp]; D[f,alpha,fdp]
         D[f,g,    alpha]; D[f,g,    g]; D[f,g,    ffp]; D[f,g,    fdp]
         D[f,ffp,  alpha]; D[f,ffp,  g]; D[f,ffp,  ffp]; D[f,ffp,  fdp]
         D[f,fdp,  alpha]; D[f,fdp,  g]; D[f,fdp,  ffp]; D[f,fdp,  fdp]
       Zeros/non-zeros in upper triangle:
         . . . .
           0 . .
             0 0
               0
    """
    result = []
    for p in self.params:
      eja = cmath.exp(1j*p.alpha)
      ffpifdp = p.ffp + 1j*p.fdp
      result.append(curvatures(
        alpha_alpha=-p.g*ffpifdp*eja,
        alpha_g=ffpifdp*1j*eja,
        alpha_ffp=p.g*1j*eja,
        alpha_fdp=-p.g*eja,
        g_ffp=eja,
        g_fdp=1j*eja))
    return result

  def d_target_d_params(self, target):
    "Rule for derivatives of sum of roots of unity."
    result = []
    da, db = target.da(), target.db()
    for d_params in self.d_params():
      result.append(gradients(*[da * d.real + db * d.imag
        for d in d_params.as_list()]))
    return result

  def d2_target_d_params(self, target):
    "Product rule applied to da * d.real + db * d.imag."
    da, db = target.da(), target.db()
    daa, dbb, dab = target.daa(), target.dbb(), target.dab()
    d = self.d_params()
    d2 = self.d2_params()
    i4 = 0
    for di,d2i in zip(d, d2):
      for ixi,dix in enumerate(di.as_list()):
        row = []
        for dj in d:
          for ixj,djx in enumerate(dj.as_list()):
            sum = daa * dix.real * djx.real \
                + dbb * dix.imag * djx.imag \
                + dab * (dix.real * djx.imag + dix.imag * djx.real)
            row.append(sum)
        if (ixi == 0): # (0,0)
          row[i4] += da * d2i.alpha_alpha.real \
                   + db * d2i.alpha_alpha.imag
        if (ixi == 0 or ixi == 1): # (0,1) or (1,0)
          row[i4+1-ixi] += da * d2i.alpha_g.real \
                         + db * d2i.alpha_g.imag
        if (ixi == 0 or ixi == 2): # (0,2) or (2,0)
          row[i4+2-ixi] += da * d2i.alpha_ffp.real \
                         + db * d2i.alpha_ffp.imag
        if (ixi == 0 or ixi == 3): # (0,3) or (3,0)
          row[i4+3-ixi] += da * d2i.alpha_fdp.real \
                         + db * d2i.alpha_fdp.imag
        if (ixi == 1 or ixi == 2): # (1,2) or (2,1)
          row[i4+3-ixi] += da * d2i.g_ffp.real \
                         + db * d2i.g_ffp.imag
        if (ixi == 1 or ixi == 3): # (1,3) or (3,1)
          row[i4+4-ixi] += da * d2i.g_fdp.real \
                         + db * d2i.g_fdp.imag
        yield row
      i4 += 4


 *******************************************************************************


 *******************************************************************************
cctbx/examples/g_exp_i_partial_derivatives.py
from __future__ import absolute_import, division, print_function
from libtbx.test_utils import approx_equal
import cmath
import math
from six.moves import range

def empirical_proof(g, ffp, fdp, alpha):
  # Mathematica: f = g (ffp + I fdp) Exp[I alpha]
  c = g * (ffp + 1j*fdp) * cmath.exp(1j*alpha)
  a = g * ffp * math.cos(alpha) - g * fdp * math.sin(alpha)
  b = g * ffp * math.sin(alpha) + g * fdp * math.cos(alpha)
  assert approx_equal(a, c.real)
  assert approx_equal(b, c.imag)
  #
  # Mathematica: D[f,alpha]
  d_c_d_alpha = g * (ffp + 1j*fdp) * 1j*cmath.exp(1j*alpha)
  d_a_d_alpha = g * ffp * -math.sin(alpha) - g * fdp * math.cos(alpha)
  d_b_d_alpha = g * ffp *  math.cos(alpha) - g * fdp * math.sin(alpha)
  assert approx_equal(d_a_d_alpha, d_c_d_alpha.real)
  assert approx_equal(d_b_d_alpha, d_c_d_alpha.imag)
  #
  # Mathematica: D[f,g]
  d_c_d_g = (ffp + 1j*fdp) * cmath.exp(1j*alpha)
  d_a_d_g = ffp * math.cos(alpha) - fdp * math.sin(alpha)
  d_b_d_g = ffp * math.sin(alpha) + fdp * math.cos(alpha)
  assert approx_equal(d_a_d_g, d_c_d_g.real)
  assert approx_equal(d_b_d_g, d_c_d_g.imag)
  #
  # Mathematica: D[f,ffp]
  d_c_d_ffp = g * cmath.exp(1j*alpha)
  d_a_d_ffp = g * math.cos(alpha)
  d_b_d_ffp = g * math.sin(alpha)
  assert approx_equal(d_a_d_ffp, d_c_d_ffp.real)
  assert approx_equal(d_b_d_ffp, d_c_d_ffp.imag)
  #
  # Mathematica: D[f,fdp]
  d_c_d_fdp = g * 1j * cmath.exp(1j*alpha)
  d_a_d_fdp = -g * math.sin(alpha)
  d_b_d_fdp =  g * math.cos(alpha)
  assert approx_equal(d_a_d_fdp, d_c_d_fdp.real)
  assert approx_equal(d_b_d_fdp, d_c_d_fdp.imag)

def exercise():
  for g in range(-3,4):
    for ffp in range(-3,4):
      for fdp in range(-3,4):
        for alpha_deg in range(0,360,15):
          empirical_proof(g, ffp, fdp, alpha_deg*math.pi/180)
  print("OK")

if (__name__ == "__main__"):
  exercise()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/getting_started.py
from __future__ import absolute_import, division, print_function
from cctbx import crystal

def run():
  symmetry = crystal.symmetry(
    unit_cell=(11, 12, 13, 90, 100, 90),
    space_group_symbol="C 2")
  symmetry.show_summary()
  for s in symmetry.space_group(): print(s)

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/hirshfeld_test.py
from __future__ import absolute_import, division, print_function
from cctbx import crystal, adp_restraints, xray
from six.moves import zip

def run(structure_file_path):
  xs = xray.structure.from_shelx(filename=structure_file_path,
                                 strictly_shelxl=False)

  asu_mappings = xs.asu_mappings(buffer_thickness=2)
  bond_table = crystal.pair_asu_table(asu_mappings)
  bond_table.add_covalent_pairs(xs.scattering_types())
  pair_sym_table = bond_table.extract_pair_sym_table()

  rigid_bonds = adp_restraints.shared_rigid_bond_proxy()
  scatterer = xs.scatterers()
  for sym_pair in pair_sym_table.iterator():
    i, j, op = sym_pair.i_seq, sym_pair.j_seq, sym_pair.rt_mx_ji
    if 'H' in [ scatterer[idx].scattering_type for idx in (i,j) ]: continue
    rigid_bonds.append(adp_restraints.rigid_bond_proxy((i,j), 1.))
  deltas = rigid_bonds.deltas(
    sites_cart=xs.sites_cart(),
    u_cart=xs.scatterers().extract_u_cart(xs.unit_cell()))
  for bond, delta in zip(rigid_bonds, deltas):
    i, j = bond.i_seqs
    sc_1, sc_2 = scatterer[i], scatterer[j]
    print("%s <-> %s: %.3g" % (sc_1.label, sc_2.label, delta))



if __name__ == '__main__':
  import sys
  run(sys.argv[1])


 *******************************************************************************


 *******************************************************************************
cctbx/examples/le_page_1982_vs_lebedev_2005.py
"""
Plot of Le Page 1982 deltas vs. Lebedev 2005 perturbations based on
random sampling of distorted unit cells compatible with the 81 2-fold
symmetry operations possible for reduced cells.
"""
from __future__ import absolute_import, division, print_function

from cctbx import sgtbx
from cctbx import uctbx
from cctbx.array_family import flex
import random
from six.moves import range
from six.moves import zip

random.seed(0)

def enumerate_reduced_cell_two_folds():
  result = []
  for elements in flex.nested_loop([-1]*9,[1+1]*9):
    r = sgtbx.rot_mx(elements)
    if (r.determinant() != 1): continue
    if (r.inverse() != r): continue
    if (r.is_unit_mx()): continue
    result.append(r)
  return result

def sample(two_folds, fudge_factor, deltas, perturbations):
  for two_fold in two_folds:
    group = sgtbx.space_group()
    group.expand_smx(sgtbx.rt_mx(two_fold))
    assert group.order_z() == 2
    sym = sgtbx.space_group_info(group=group).any_compatible_crystal_symmetry(
      volume=1000)
    for i_trial in range(30):
      while True:
        uc_fudge = list(sym.unit_cell().parameters())
        for i in range(6): uc_fudge[i] *= 1+(random.random()*2-1)*fudge_factor
        try: uc_fudge = uctbx.unit_cell(uc_fudge)
        except ValueError: pass
        else: break
      deltas.append(
        two_fold.le_page_1982_delta(reduced_cell=uc_fudge, deg=True))
      perturbations.append(
        two_fold.lebedev_2005_perturbation(reduced_cell=uc_fudge))

def run():
  two_folds = enumerate_reduced_cell_two_folds()
  assert len(two_folds) == 81
  deltas = flex.double()
  perturbations = flex.double()
  for fudge_factor in [0.002, 0.01, 0.02, 0.05, 0.1]:
    sample(
      two_folds=two_folds,
      fudge_factor=fudge_factor,
      deltas=deltas,
      perturbations=perturbations)
  perm = flex.sort_permutation(data=deltas)
  deltas = deltas.select(perm)
  perturbations = perturbations.select(perm)
  f = open("le_page_1982_vs_lebedev_2005_plot", "w")
  for x,y in zip(deltas, perturbations):
    print(x, y, file=f)
  print("OK")

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/lebedev_2005_perturbation.py
"""
Andrey A. Lebedev, Alexei A. Vagin & Garib N. Murshudov
Acta Cryst. (2006). D62, 83-95.
http://journals.iucr.org/d/issues/2006/01/00/ba5089/index.html
Appendix A1. Algorithms used in the determination of twinning operators
and their type of merohedry

The formula for the perturbation mentioned in the appendix and the
matrices_from_email below kindly provided by Andrey.

This script reproduces the perturbations ("scores") given by Andrey.
It also shows the Le Page (1982, J. Appl. Cryst. 15, 255-259) deltas
in radians for comparison.
"""
from __future__ import absolute_import, division, print_function

from cctbx import sgtbx
from cctbx import uctbx
from scitbx import matrix
from six.moves import range

matrices_from_email = """
CRYST1   82.053   66.612   84.904  99.00 111.29 105.00 P 1

S:
   6732.6948  -1414.6310  -2529.5033
  -1414.6310   4437.1585   -884.7347
  -2529.5033   -884.7347   7208.6892

M:
           0           0          -1
           0          -1           0
          -1           0           0

Score:
  0.06996537

------------------------------------------
CRYST1   85.053   36.612   22.904  91.00 101.29 110.00 P 1

S:
   6176.9399    260.7664    128.5781
    260.7664   1340.4385    -14.6349
    128.5781    -14.6349    524.5932

M:
          -1           0           0
           0          -1           0
           1           0           1

Score:
  0.06177181

------------------------------------------
CRYST1   87.053   86.612   84.904  92.00 101.29 105.00 P 1

S:
   7578.2248  -1951.4527  -1447.0019
  -1951.4527   7501.6385   -256.6406
  -1447.0019   -256.6406   7208.6892

M:
          -1           0           0
           0           0          -1
           0          -1           0

Score:
  0.03867617

------------------------------------------
CRYST1   89.053   96.612   84.904  93.00 101.29 110.00 P 1

S:
   7930.4368  -2942.6005  -1480.2461
  -2942.6005   9333.8785   -429.2985
  -1480.2461   -429.2985   7208.6892

M:
           0          -1           0
          -1           0           0
           0           0          -1

Score:
  0.11207609

------------------------------------------
CRYST1   92.053   66.612   84.904  94.00  91.29 105.00 P 1

S:
   8473.7548  -1587.0355   -175.9529
  -1587.0355   4437.1585   -394.5165
   -175.9529   -394.5165   7208.6892

M:
          -1           0           0
           0          -1           0
           0           0           1

Score:
  0.06714734

------------------------------------------
CRYST1  102.053   46.612   74.904  95.00  71.29  95.00 P 1

S:
  10414.8148   -414.5907   2452.0864
   -414.5907   2172.6785   -304.2978
   2452.0864   -304.2978   5610.6092

M:
           1           0           0
           0          -1           0
          -1           0          -1

Score:
  0.06543032

------------------------------------------
CRYST1  102.053   66.612   64.904  96.00 111.29  90.00 P 1

S:
   9817.4017   -451.9168   1807.5581
   -451.9168   4437.1585   -451.9168
   1807.5581   -451.9168   4212.5292

M:
           1           0           0
           0          -1           0
          -1           0          -1

Score:
  0.05202084

------------------------------------------
CRYST1   53.053   96.612   54.904  97.00  91.29  85.00 P 1

S:
   2814.6208    446.7217    -65.5759
    446.7217   9333.8785   -646.4419
    -65.5759   -646.4419   3014.4492

M:
           0           0           1
           0          -1           0
           1           0           0

Score:
  0.03361885

------------------------------------------
CRYST1  102.053   36.612   44.904  98.00 111.29  80.00 P 1

S:
   9103.4130    420.0088    352.4837
    420.0088   1340.4385   -228.8041
    352.4837   -228.8041   2016.3692

M:
           1           0           0
          -1          -1           0
           0           0          -1

Score:
  0.10323493

------------------------------------------
CRYST1  102.053   66.612   34.904 100.00 111.29  75.00 P 1

S:
   9046.4187   1355.7037    -75.0535
   1355.7037   4437.1585   -403.7364
    -75.0535   -403.7364   1218.2892

M:
          -1           0           0
           0          -1           0
           0          -1           1

Score:
  0.08193190
"""

def run():
  lines = iter(matrices_from_email.splitlines())
  while True:
    for line in lines:
      if (line.rstrip() == "S:"): break
    else:
      break
    s = []
    for i in range(3):
      s.extend([float(v) for v in next(lines).split()])
    for line in lines:
      if (line.rstrip() == "M:"): break
    else:
      raise RuntimeError("S: found but not M:")
    m = []
    for i in range(3):
      m.extend([int(v) for v in next(lines).split()])
    for line in lines:
      if (line.rstrip() == "Score:"): break
    else:
      raise RuntimeError("S: and M: found but not Score:")
    score = float(next(lines).strip())
    s = matrix.sqr(s)
    m = matrix.sqr(m)
    print(s.mathematica_form(label="s", one_row_per_line=True))
    print(m.mathematica_form(label="m", one_row_per_line=True))
    r = sgtbx.rot_mx(m, 1)
    print("rotation type:", r.info().type())
    print("axis direction:", r.info().ev())
    u = uctbx.unit_cell(metrical_matrix=s.as_sym_mat3())
    p = r.lebedev_2005_perturbation(reduced_cell=u)
    print("score given:     ", score)
    print("score reproduced:", p)
    assert abs(p-score) < 1.e-6
    delta = r.le_page_1982_delta(reduced_cell=u)
    print("Le Page delta:   ", delta)
    print()
  print("OK")

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/list_non_principal_continuous_shifts.py
from __future__ import absolute_import, division, print_function
import libtbx.load_env
from cctbx import sgtbx
import os

def run():
  """ List seminvariants whose continuous shifts aren't principal,
      drawing from the spacegroup settings specified in phenix_regression
  """
  namespace = {}
  exec(open(os.path.join(libtbx.env.find_in_repositories("phenix_regression"),
                         "settings.py")).read(),
           namespace)
  for setting in namespace['settings']:
    sgi = sgtbx.space_group_info(setting)
    seminvar = sgtbx.structure_seminvariants(sgi.group())
    if seminvar.continuous_shifts_are_principal(): continue
    print(str(sgi))
    for vm in seminvar.vectors_and_moduli():
      if vm.m != 0: continue
      print("\t", vm.v)

if __name__ == '__main__':
  run()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/location_part.py
from __future__ import absolute_import, division, print_function
from cctbx import sgtbx

class symmetries_with_nonzero_location_parts(object):

  def browse(self):
    for self.symbol in sgtbx.space_group_symbol_iterator():
      self.sg = sgtbx.space_group(self.symbol.hall()).make_tidy()
      self.z2p_op = self.sg.z2p_op()
      self.sg_p = self.sg.change_basis(self.z2p_op)
      self.on_new_space_group()
      for self.op in self.sg_p:
        self.rot_info = self.op.r().info()
        self.tr_info = sgtbx.translation_part_info(self.op)
        if self.tr_info.origin_shift().is_zero(): continue
        self.on_new_symmetry()

  def on_new_space_group(self):
    self.space_group_printout = (
      "%s (%i) [ %s ]"
      % (self.symbol.hall(), self.symbol.number(), self.z2p_op.as_xyz()))


  def on_new_symmetry(self):
    if self.space_group_printout is not None:
      print()
      print(self.space_group_printout)
      self.space_group_printout = None
    print("\t% i |%s +(%s) @(%s)" % (self.rot_info.type(), self.rot_info.ev(),
                                    self.tr_info.intrinsic_part(),
                                    self.tr_info.origin_shift()))


class a_theorem_in_primitive_settings(symmetries_with_nonzero_location_parts):
  """ For any space group in a primitive setting, if it were to contain
      two elements (R|t) and (R|t+d) where t is the intrinsic part,
      then d is a lattice translation.
  """

  def on_new_symmetry(self):
    r = self.op.r()
    self.n_translations.setdefault(r, 0)
    self.n_translations[r] += 1
    if self.n_translations[r] > 1:
      yield super(a_theorem_in_primitive_settings, self).on_new_symmetry()

  def on_new_space_group(self):
    self.n_translations.clear()
    super(a_theorem_in_primitive_settings, self).on_new_space_group()

  def verify(self):
    print(self.__class__.__doc__)
    print()
    print("Let's try to find a counter-example ...")
    self.n_translations = {}
    self.browse()
    print("The search is over!")


class symmetries_with_both_nonzero_location_and_intrinsic_parts(
  symmetries_with_nonzero_location_parts):

  def on_new_symmetry(self):
    if (not self.tr_info.intrinsic_part().is_zero()
        and not self.tr_info.location_part().is_zero()):
      super(symmetries_with_both_nonzero_location_and_intrinsic_parts,
            self).on_new_symmetry()

def run():
  import sys
  if sys.argv[1] == "browse":
    symmetries_with_nonzero_location_parts().browse()
  elif sys.argv[1] == "verify":
    a_theorem_in_primitive_settings().verify()
  elif sys.argv[1] == "nonzero-location-and-intrinsic":
    symmetries_with_both_nonzero_location_and_intrinsic_parts().browse()

if __name__ == '__main__':
  run()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/map_skewness.py
"""- Generates random structures
   - Computes structure factors
   - Randomizes phases given a fudge factor
   - Computes fft map
   - Determines skewness of map
"""
from __future__ import absolute_import, division, print_function

from cctbx import sgtbx
from cctbx.development import random_structure
from cctbx.array_family import flex
from six.moves import range

def randomize_phases(f_calc, fudge_factor):
  assert 0 <= fudge_factor <= 1
  phases = flex.arg(f_calc.data(), True)
  centric_flags = f_calc.centric_flags().data()
  acentric_flags = ~centric_flags
  centric_phases = phases.select(centric_flags)
  acentric_phases = phases.select(acentric_flags)
  sel = flex.random_double(size=centric_phases.size()) < (0.5 * fudge_factor)
  centric_phases.set_selected(sel, centric_phases.select(sel) + 180)
  acentric_phases += (flex.random_double(size=acentric_phases.size())
                      * 360 - 180) * fudge_factor
  phases.set_selected(centric_flags, centric_phases)
  phases.set_selected(acentric_flags, acentric_phases)
  return f_calc.phase_transfer(phases, deg=True)

def skewness_calculation(space_group_info, n_test_points=10,
                         n_sites=20, d_min=3, volume_per_atom=200):
  structure = random_structure.xray_structure(
    space_group_info=space_group_info,
    elements=["Se"]*n_sites,
    volume_per_atom=volume_per_atom,
    random_u_iso=True)
  structure.show_summary()
  print()
  f_calc = structure.structure_factors(
    d_min=d_min, anomalous_flag=False).f_calc()
  f_calc.show_summary()
  print()
  for i_fudge_factor in range(n_test_points+1):
    fudge_factor = i_fudge_factor/float(n_test_points)
    randomized_f_calc = randomize_phases(f_calc, fudge_factor)
    mwpe = f_calc.mean_weighted_phase_error(randomized_f_calc)
    rho = randomized_f_calc.fft_map().real_map_unpadded()
    # <(rho-rho_bar)**3>/<(rho-rho_bar)**2>**3/2
    rho_rho_bar = rho - flex.mean(rho)
    num = flex.mean(flex.pow(rho_rho_bar, 3))
    den = flex.mean(flex.pow(rho_rho_bar, 2))**(3/2.)
    assert den != 0
    skewness = num / den
    print("fudge factor, phase difference, map skewness:", end=' ')
    print("%4.2f, %5.2f, %.4g" % (fudge_factor, mwpe, skewness))
  print()

def run():
  for space_group_symbol in ("P 1", "C 2", "P 21 21 21", "R 32", "F 4 3 2"):
    skewness_calculation(sgtbx.space_group_info(space_group_symbol))

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/maximum_subgroups.py
"""
Construct all subgroup graphs and their relations between them from a single space group.
"""
from __future__ import absolute_import, division, print_function


from cctbx import sgtbx
from cctbx.sgtbx import show_cosets
from cctbx.sgtbx import pointgroup_tools
from cctbx.development import debug_utils
import sys


def reverse_dict( dict ):
  new_dict = {}
  for item in dict:
    for value in dict[item]:
      if value is not None:
        if value in new_dict:
          tmp = new_dict[ value ]
          tmp.append( item )
          new_dict.update( {value:tmp} )
        else:
          new_dict.update( {value:[item]} )
  return new_dict

def get_maximal_subgroup( sg_name, reverse_graph ):
  subgroups = []
  if sg_name in reverse_graph:
    subgroups = reverse_graph[ sg_name ]

  maximal = {}
  for sg in subgroups:
    maximal.update( {sg:True} )
  result = []
  for trial_sg in subgroups:
    tmp = {}
    if trial_sg in reverse_graph:
      tmp = reverse_graph[ trial_sg ]
    is_trial_sg_a_subgroup_of_items_in_subgroups=False
    for item in tmp:
      if item in subgroups:
        maximal.update( {item:False} )
        is_trial_sg_a_subgroup_of_subgroups=True
  for item in maximal:
    if maximal[item]:
      result.append( item )
  return result





def create_all_subgroups( sg1,show_all=True, reverse=False ):
  sg_high = sgtbx.space_group_info( sg1  ).group()
  sg_low  = sgtbx.space_group_info( "p1" ).group()
  graph_object =  pointgroup_tools.point_group_graph( sg_low, sg_high, False,True)
  highest_sg = str( sgtbx.space_group_info( sg1  ) )
  rev_dict = reverse_dict( graph_object.graph.o )
  maximal_subgroups = get_maximal_subgroup( highest_sg, rev_dict )
  if show_all:
    print("Subgroups of input space groups which can be constructed by introducing one single operator (and group completion) in the subgroup:")
    for sg in rev_dict[ highest_sg ]:
      line = "       "
      line += sg+(30-len(sg))*" "+str(graph_object.graph.edge_objects[ sg ][highest_sg])+(90-len( str(graph_object.graph.edge_objects[ sg ][highest_sg]) ))*" "
      print(line)

    print()
    print("Maximal subgroup detected in the full sub-group-graph: ")
    for sg in maximal_subgroups:
      line = "       "
      line += sg
      print(line)

    print()
    print()
    print()
    print(" Cosets for each maximal sub-group and the input space group are listed:")
    for sg in maximal_subgroups:
      print("-----------------------------------------------------------------")
      show_cosets.run( sg,highest_sg )
      print("-----------------------------------------------------------------")
      print()
      print()
      print()
      print()

  else:
    print("Maximal subgroups of %s: "%(sg1))
    for sg in maximal_subgroups:
      line = "       "
      line += sg
      print(line)
    print()
    print()
    print()

  if reverse:
    print("Minimal supergroups generated by the sub-groups of the input space group:")
    tmp_sg = sgtbx.space_group_info( sg1 )
    for sg in maximal_subgroups:
      tmp_sgsg = sgtbx.space_group_info( sg )
      cb_op = tmp_sgsg.change_of_basis_op_to_reference_setting()
      okai=False
      try:
        new_sg = tmp_sg.change_basis( cb_op )
        okai=True
        print(new_sg ," is a minimal supergroup of ", tmp_sgsg.change_basis(cb_op))
      except Exception: pass
      if not okai:
        print("%s (%s) is a minimal supergroup of %s     [*]"%(tmp_sg,cb_op, tmp_sgsg.change_basis(cb_op)))
    print()
    print()
    print()




def run_single(sg1, show=False, reverse=False):
  create_all_subgroups( sg1, show, reverse )

def run_all():
  sglist = debug_utils.get_test_space_group_symbols( False, False, True, False)
  for sg in sglist:
    run_single(sg)


if __name__=="__main__":
  if len(sys.argv)>1:
    run_single( sys.argv[1],True,True )
  else:
    run_all()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/merging/__init__.py
from __future__ import absolute_import, division, print_function
from scitbx.examples import bevington # import dependency
import boost_adaptbx.boost.python as bp
ext = bp.import_ext("cctbx_large_scale_merging_ext")
from cctbx_large_scale_merging_ext import *


 *******************************************************************************


 *******************************************************************************
cctbx/examples/merging/data_subset.py
from __future__ import absolute_import, division, print_function
from six.moves import range
from scitbx.array_family import flex

"""The mapper_unmapper class solves the problem of selecting a subset of the data
   that is "visited" in the simulation.  In other words, selecting
   Miller indices that are actually measured, and frames that actually have observations.
   Otherwise, there would be I-parameters and G-parameters with undefined gradients.
"""

def mapper_factory(base_class):
  class mapper_unmapper(base_class):
    def __init__(self,Ibase,Gbase,I_visited,G_visited,FSIM,**kwargs):
      g_counter=0; forward_map_G=flex.size_t(len(G_visited)); backward_map_G=flex.size_t()
      for s in range(len(G_visited)):
        #print s, G_visited[s], c[len_I + s], c[len_I + len(Gbase) + s]
        if G_visited[s]:
          forward_map_G[s] = g_counter
          backward_map_G.append(s)
          g_counter+=1

      subsetGbase = Gbase.select(backward_map_G)
      remapped_frame = forward_map_G.select(FSIM.frame)

      i_counter=0; forward_map_I=flex.size_t(len(I_visited)); backward_map_I=flex.size_t()
      for s in range(len(I_visited)):
        #print s,I_visited[s], c[s]
        if I_visited[s]:
          forward_map_I[s] = i_counter
          backward_map_I.append(s)
          i_counter+=1
      subsetIbase = Ibase.select(backward_map_I)
      remapped_miller = forward_map_I.select(FSIM.miller)

      from cctbx.examples.merging import intensity_data
      remapped_FSIM = intensity_data()
      remapped_FSIM.raw_obs = FSIM.raw_obs
      remapped_FSIM.exp_var = FSIM.exp_var
      remapped_FSIM.stol_sq = FSIM.stol_sq
      remapped_FSIM.origHKL = FSIM.origHKL
      remapped_FSIM.frame   = remapped_frame
      remapped_FSIM.miller  = remapped_miller

      if 'experiments' in kwargs:
        # XXX seems like we need to implement a proper select statement for ExperimentList
        # kwargs["experiments"] = kwargs["experiments"].select(G_visited==1)
        from dxtbx.model import ExperimentList
        new_experiments = ExperimentList()
        for idx in range(len(G_visited)):
          if G_visited[idx]==1:
            new_experiments.append(kwargs["experiments"][idx])
        kwargs["experiments"] = new_experiments

      base_class.__init__(self,subsetIbase,subsetGbase,remapped_FSIM,**kwargs)
      fitted = self.unpack()
      fitted_stddev = self.unpack_stddev()

      def help_expand_data(data):
        result = {}
        for key in data.keys():
          if key=="I":
            ex = flex.double(len(Ibase))
            for s in range(len(I_visited)):
              if I_visited[s]:
                ex[s] = data[key][forward_map_I[s]]
            result[key]=ex
          elif key in ["G", "B", "D", "Ax", "Ay"]:
            ex = flex.double(len(Gbase))
            for s in range(len(G_visited)):
              if G_visited[s]:
                ex[s] = data[key][forward_map_G[s]]
            result[key]=ex
        return result
      self.expanded = help_expand_data(fitted)
      self.expanded_stddev = help_expand_data(fitted_stddev)
      print("DONE UNMAPPING HERE")

    def e_unpack(self):
      return self.expanded

    def e_unpack_stddev(self):
      return self.expanded_stddev

  return mapper_unmapper

def mapper_factory_with_explicit_B(base_class):
  class mapper_unmapper(base_class):
    def __init__(self,Ibase,Gbase,Bbase,I_visited,G_visited,FSIM,**kwargs):
      g_counter=0; forward_map_G=flex.size_t(len(G_visited)); backward_map_G=flex.size_t()
      for s in range(len(G_visited)):
        #print s, G_visited[s], c[len_I + s], c[len_I + len(Gbase) + s]
        if G_visited[s]:
          forward_map_G[s] = g_counter
          backward_map_G.append(s)
          g_counter+=1

      subsetGbase = Gbase.select(backward_map_G)
      subsetBbase = Bbase.select(backward_map_G)
      remapped_frame = forward_map_G.select(FSIM.frame)

      i_counter=0; forward_map_I=flex.size_t(len(I_visited)); backward_map_I=flex.size_t()
      for s in range(len(I_visited)):
        #print s,I_visited[s], c[s]
        if I_visited[s]:
          forward_map_I[s] = i_counter
          backward_map_I.append(s)
          i_counter+=1
      subsetIbase = Ibase.select(backward_map_I)
      remapped_miller = forward_map_I.select(FSIM.miller)

      from cctbx.examples.merging import intensity_data
      remapped_FSIM = intensity_data()
      remapped_FSIM.raw_obs = FSIM.raw_obs
      remapped_FSIM.exp_var = FSIM.exp_var
      remapped_FSIM.stol_sq = FSIM.stol_sq
      remapped_FSIM.frame   = remapped_frame
      remapped_FSIM.miller  = remapped_miller

      base_class.__init__(self,subsetIbase,subsetGbase,subsetBbase,remapped_FSIM,**kwargs)
      fitted_I,fitted_G,fitted_B = self.unpack()

      self.expanded_G = flex.double(len(Gbase))
      self.expanded_B = flex.double(len(Gbase))
      for s in range(len(G_visited)):
        if G_visited[s]:
          self.expanded_G[s]=fitted_G[ forward_map_G[s] ]
          self.expanded_B[s]=fitted_B[ forward_map_G[s] ]

      self.expanded_I = flex.double(len(Ibase))
      for s in range(len(I_visited)):
        if I_visited[s]:
          self.expanded_I[s]=fitted_I[ forward_map_I[s] ]

      print("DONE UNMAPPING HERE")

    def e_unpack(self): return (self.expanded_I, self.expanded_G,self.expanded_B)

  return mapper_unmapper


 *******************************************************************************


 *******************************************************************************
cctbx/examples/merging/data_utilities.py
from __future__ import absolute_import, division, print_function
from six.moves import range
from scitbx.array_family import flex

def I_and_G_base_estimate(data,params=None):
  """Estimate I and G, based on simple weighted averages, nothing fancy"""
  Nframes = flex.max(data.frame) + 1
  # worth some explanation.  For a half_data_set on 1000 images, one of the
  # halves will only have a data.frame max of 999. An apparent discrepancy,
  # not functionally important.
  Nmiller = flex.max(data.miller) + 1

  # figure out if d_max, d_min were requested
  inv_d_max_sq = 0.0
  inv_d_min_sq = 0.0
  if params is not None:
    if params.d_max is not None: inv_d_max_sq = (1./params.d_max)*(1./params.d_max)
    inv_d_min_sq = (1./params.d_min)*(1./params.d_min)

  G,G_visited = data.estimate_G(Nframes,inv_d_max_sq,inv_d_min_sq)
  I,I_visited = data.estimate_I(Nmiller,inv_d_max_sq,inv_d_min_sq)
  return I,I_visited,G,G_visited

def plot_it(fit, sim, mode=None):
  sub_fit = []
  sub_sim = []
  for i in range(len(fit)):
    if sim[i] > 0:
      sub_fit.append(fit[i])
      sub_sim.append(sim[i])
  from matplotlib import pyplot as plt
  if mode=="I":
    plt.loglog(sub_sim, sub_fit, "b,")
    plt.title("Log plot of fitted intensity vs. simulated intensity")
  else:
    plt.plot(sub_sim, sub_fit, "b.")
    if max(sub_sim)>1E8:
      plt.axes().set_xlim(0,5E7)
    if max(sub_fit)>1E8:
      plt.axes().set_ylim(0,5E7)
  if mode=="G":
    plt.title("Fitted scale-factor G vs. simulated scale-factor")
  elif mode=="B":
    plt.axes().set_ylim(-12,12)
    plt.title("Fitted B-factor vs. simulated B-factor")

  plt.show()

def show_correlation(A, B, selection, message):
  data_A = A.select(selection==1)
  data_B = B.select(selection==1)
  LC = flex.linear_correlation(data_A,data_B)
  print(message,LC.coefficient(),"on %d values"%LC.n())

def show_histogram(data,title):
  from matplotlib import pyplot as plt

  nbins = 40
  n,bins,patches = plt.hist(data,
    nbins, normed=0, facecolor="orange", alpha=0.75)

  plt.xlabel("Rotational angle (degrees)")
  plt.title(title)
  #plt.axis([0,maxangle,0,1450])
  #plt.plot([median],[1375],"b|")
  #plt.plot([rmsd],[1375],"b|")
  plt.show()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/merging/samosa/__init__.py


 *******************************************************************************


 *******************************************************************************
cctbx/examples/merging/samosa/join.py
from __future__ import absolute_import, division, print_function
from six.moves import range

from rstbx.dials_core.integration_core import show_observations
import iotbx.phil
from cctbx.array_family import flex
from cctbx import miller
from cctbx import uctbx
from libtbx.utils import Usage, multi_out
from libtbx import easy_pickle
from libtbx import adopt_init_args, group_args, Auto
import os
import math
import time
import sys
from scitbx import matrix
import six
from six.moves import zip
op = os.path

from xfel.command_line.cxi_merge import master_phil
from xfel.command_line.cxi_merge import get_observations
from xfel.command_line.cxi_merge import frame_data, null_data
from xfel.command_line.cxi_merge import consistent_set_and_model

class unit_cell_distribution(object):
  """
  Container for collecting unit cell edge length statistics - for frames
  included in the final dataset.
  (Frames with incompatible indexing solutions will not be included.)
  """
  # TODO make this more general - currently assumes that angles are fixed,
  # which is true for the systems studied so far
  def __init__(self):
    self.all_uc_a_values = flex.double()
    self.all_uc_b_values = flex.double()
    self.all_uc_c_values = flex.double()

  def add_cell(self, unit_cell, rejected=False):
    if (unit_cell is None):
      return
    (a,b,c,alpha,beta,gamma) = unit_cell.parameters()
    self.all_uc_a_values.append(a)
    self.all_uc_b_values.append(b)
    self.all_uc_c_values.append(c)

  def add_cells(self, uc):
    """Addition operation for unit cell statistics."""
    self.all_uc_a_values.extend(uc.all_uc_a_values)
    self.all_uc_b_values.extend(uc.all_uc_b_values)
    self.all_uc_c_values.extend(uc.all_uc_c_values)

  def show_histograms(self, reference, out, n_slots=20):
    [a0,b0,c0,alpha0,beta0,gamma0] = reference.parameters()
    print("", file=out)
    labels = ["a","b","c"]
    ref_edges = [a0,b0,c0]
    def _show_each(edges):
      for edge, ref_edge, label in zip(edges, ref_edges, labels):
        h = flex.histogram(edge, n_slots=n_slots)
        smin, smax = flex.min(edge), flex.max(edge)
        stats = flex.mean_and_variance(edge)
        print("  %s edge" % label, file=out)
        print("     range:     %6.2f - %.2f" % (smin, smax), file=out)
        print("     mean:      %6.2f +/- %6.2f on N = %d" % (
          stats.mean(), stats.unweighted_sample_standard_deviation(), edge.size()), file=out)
        print("     reference: %6.2f" % ref_edge, file=out)
        h.show(f=out, prefix="    ", format_cutoffs="%6.2f")
        print("", file=out)
    edges = [self.all_uc_a_values, self.all_uc_b_values, self.all_uc_c_values]
    print("Unit cell length distribution (all frames with compatible indexing):", file=out)
    _show_each(edges)

  def get_average_cell_dimensions(self):
    a = flex.mean(self.all_uc_a_values)
    b = flex.mean(self.all_uc_b_values)
    c = flex.mean(self.all_uc_c_values)
    return a,b,c

#-----------------------------------------------------------------------
from xfel.command_line.cxi_merge import scaling_manager as scaling_manager_base
class scaling_manager(scaling_manager_base):
  def __init__(self, miller_set, i_model, params, log=None):
    scaling_manager_base.__init__(self, miller_set, i_model, params, log)

  def reset(self):
    self.n_processed = 0
    self.n_accepted = 0
    self.n_file_error = 0
    self.n_low_signal = 0
    self.n_wrong_bravais = 0
    self.n_wrong_cell = 0
    self.observations = flex.int()
    self.corr_values = flex.double()
    self.rejected_fractions = flex.double()
    self.uc_values = unit_cell_distribution()
    self.d_min_values = flex.double()
    self.wavelength = flex.double()
    self.initialize()

  def scale_all(self, file_names):
    t1 = time.time()
    if self.params.backend == 'MySQL':
      from xfel.merging.database.merging_database import manager
    elif self.params.backend == 'SQLite':
      from xfel.merging.database.merging_database_sqlite3 import manager
    elif self.params.backend == 'FS':
      from xfel.merging.database.merging_database_fs import manager
    elif self.params.backend == 'Flex':
      from xfel.merging.database.merging_database_flex import manager

    import multiprocessing
    print("Allocating intensities")
    intensity_proxy = multiprocessing.Array('d',self.params.memory.shared_array_allocation,lock=True)
    print("Allocating sigmas")
    sigma_proxy = multiprocessing.Array('d',self.params.memory.shared_array_allocation,lock=True)
    print("Allocating frame_id")
    frame_proxy = multiprocessing.Array('l',self.params.memory.shared_array_allocation,lock=True)
    print("Allocating miller_id")
    miller_proxy = multiprocessing.Array('l',self.params.memory.shared_array_allocation,lock=True)
    H_proxy = multiprocessing.Array('i',self.params.memory.shared_array_allocation,lock=True)
    K_proxy = multiprocessing.Array('i',self.params.memory.shared_array_allocation,lock=True)
    L_proxy = multiprocessing.Array('i',self.params.memory.shared_array_allocation,lock=True)
    xtal_proxy = multiprocessing.Array('c',self.params.memory.shared_array_allocation,lock=True)
    print("Finished allocating")
    rows_observation = multiprocessing.Array('l',[0],lock=True)

    data_dict = dict(intensity_proxy=intensity_proxy,
                     sigma_proxy=sigma_proxy,
                     frame_proxy=frame_proxy,
                     miller_proxy=miller_proxy,
                     H_proxy=H_proxy,
                     K_proxy=K_proxy,
                     L_proxy=L_proxy,
                     rows=rows_observation,
                     xtal_proxy=xtal_proxy
                     )
    db_mgr = manager(self.params,data_dict)
    db_mgr.initialize_db(self.miller_set)
    # Unless the number of requested processes is greater than one,
    # try parallel multiprocessing on a parallel host.  Block until
    # all database commands have been processed.
    nproc = self.params.nproc
    if (nproc is None) or (nproc is Auto):
      nproc = libtbx.introspection.number_of_processors()
    if nproc > 1:
      try :
        import multiprocessing
        self._scale_all_parallel(file_names, db_mgr)
      except ImportError as e :
        print("multiprocessing module not available (requires Python >= 2.6)\n" \
          "will scale frames serially", file=self.log)
        self._scale_all_serial(file_names, db_mgr)
    else:
      self._scale_all_serial(file_names, db_mgr)
    pickled_data = db_mgr.join(data_dict)

    t2 = time.time()
    print("", file=self.log)
    print("#" * 80, file=self.log)
    print("FINISHED MERGING", file=self.log)
    print("  Elapsed time: %.1fs" % (t2 - t1), file=self.log)
    print("  %d of %d integration files were accepted" % (
      self.n_accepted, len(file_names)), file=self.log)
    print("  %d rejected due to wrong Bravais group" % \
      self.n_wrong_bravais, file=self.log)
    print("  %d rejected for unit cell outliers" % \
      self.n_wrong_cell, file=self.log)
    print("  %d rejected for low signal" % \
      self.n_low_signal, file=self.log)
    print("  %d rejected for file errors or no reindex matrix" % \
      self.n_file_error, file=self.log)
    checksum = self.n_accepted  + self.n_file_error \
               + self.n_low_signal \
               + self.n_wrong_bravais + self.n_wrong_cell
    assert checksum == len(file_names)

    self.join_obs = pickled_data

  def _scale_all_parallel(self, file_names, db_mgr):
    import multiprocessing
    import libtbx.introspection

    nproc = self.params.nproc
    if (nproc is None) or (nproc is Auto):
      nproc = libtbx.introspection.number_of_processors()

    # Input files are supplied to the scaling processes on demand by
    # means of a queue.
    #
    # XXX The input queue may need to either allow non-blocking
    # put():s or run in a separate process to prevent the procedure
    # from blocking here if the list of file paths does not fit into
    # the queue's buffer.
    input_queue = multiprocessing.Manager().JoinableQueue()
    for file_name in file_names:
      input_queue.put(file_name)

    pool = multiprocessing.Pool(processes=nproc)
    # Each process accumulates its own statistics in serial, and the
    # grand total is eventually collected by the main process'
    # _add_all_frames() function.
    for i in range(nproc):
      sm = scaling_manager(self.miller_set, self.i_model, self.params)
      pool.apply_async(
        func=sm,
        args=[input_queue, db_mgr],
        callback=self._add_all_frames)
    pool.close()
    pool.join()

    # Block until the input queue has been emptied.
    input_queue.join()


  def _scale_all_serial(self, file_names, db_mgr):
    """
    Scale frames sequentially (single-process).  The return value is
    picked up by the callback.
    """
    for file_name in file_names :
      scaled = self.scale_frame(file_name, db_mgr)
      if (scaled is not None):
        self.add_frame(scaled)
    return (self)

  def add_frame(self, data):
    """
    Combine the scaled data from a frame with the current overall dataset.
    Also accepts None or null_data objects, when data are unusable but we
    want to record the file as processed.
    """
    self.n_processed += 1
    if (data is None):
      return None
    #data.show_log_out(self.log)
    #self.log.flush()
    if (isinstance(data, null_data)):
      if (data.file_error):
        self.n_file_error += 1
      elif (data.low_signal):
        self.n_low_signal += 1
      elif (data.wrong_bravais):
        self.n_wrong_bravais += 1
      elif (data.wrong_cell):
        self.n_wrong_cell += 1
      return
    if (data.accept):
      self.n_accepted    += 1
      self.completeness  += data.completeness
      self.summed_N      += data.summed_N
      self.summed_weight += data.summed_weight
      self.summed_wt_I   += data.summed_wt_I
      for index, isigi in six.iteritems(data.ISIGI):
        if (index in self.ISIGI):
          self.ISIGI[index] += isigi
        else:
          self.ISIGI[index] = isigi

    self.uc_values.add_cell(data.indexed_cell,
      rejected=(not data.accept))
    self.observations.append(data.n_obs)
    if (data.n_obs > 0):
      frac_rejected = data.n_rejected / data.n_obs
      self.rejected_fractions.append(frac_rejected)
      self.d_min_values.append(data.d_min)
    self.corr_values.append(data.corr)
    self.wavelength.append(data.wavelength)

  def _add_all_frames(self, data):
    """The _add_all_frames() function collects the statistics accumulated
    in @p data by the individual scaling processes in the process
    pool.  This callback function is run in serial, so it does not
    need a lock.
    """
    self.n_accepted += data.n_accepted
    self.n_file_error += data.n_file_error
    self.n_low_signal += data.n_low_signal
    self.n_processed += data.n_processed
    self.n_wrong_bravais += data.n_wrong_bravais
    self.n_wrong_cell += data.n_wrong_cell

    for index, isigi in six.iteritems(data.ISIGI):
      if (index in self.ISIGI):
        self.ISIGI[index] += isigi
      else:
        self.ISIGI[index] = isigi

    self.completeness += data.completeness
    self.summed_N += data.summed_N
    self.summed_weight += data.summed_weight
    self.summed_wt_I += data.summed_wt_I

    self.corr_values.extend(data.corr_values)
    self.d_min_values.extend(data.d_min_values)
    self.observations.extend(data.observations)
    self.rejected_fractions.extend(data.rejected_fractions)
    self.wavelength.extend(data.wavelength)

    self.uc_values.add_cells(data.uc_values)

  def get_plot_statistics(self):
    return plot_statistics(
      prefix=self.params.output.prefix,
      unit_cell_statistics=self.uc_values,
      reference_cell=self.miller_set.unit_cell(),
      correlations=self.corr_values,
      rejected_fractions=self.rejected_fractions,
      frame_d_min=self.d_min_values)

  def scale_frame_detail(self, result, file_name, db_mgr, out):
    # If the pickled integration file does not contain a wavelength,
    # fall back on the value given on the command line.  XXX The
    # wavelength parameter should probably be removed from master_phil
    # once all pickled integration files contain it.
    if ("wavelength" in result):
      wavelength = result["wavelength"]
    elif (self.params.wavelength is not None):
      wavelength = self.params.wavelength
    else:
      # XXX Give error, or raise exception?
      return None
    assert (wavelength > 0)

    observations = result["observations"][0]
    cos_two_polar_angle = result["cos_two_polar_angle"]

    assert observations.size() == cos_two_polar_angle.size()
    tt_vec = observations.two_theta(wavelength)
    #print "mean tt degrees",180.*flex.mean(tt_vec.data())/math.pi
    cos_tt_vec = flex.cos( tt_vec.data() )
    sin_tt_vec = flex.sin( tt_vec.data() )
    cos_sq_tt_vec = cos_tt_vec * cos_tt_vec
    sin_sq_tt_vec = sin_tt_vec * sin_tt_vec
    P_nought_vec = 0.5 * (1. + cos_sq_tt_vec)

    F_prime = -1.0 # Hard-coded value defines the incident polarization axis
    P_prime = 0.5 * F_prime * cos_two_polar_angle * sin_sq_tt_vec
    # XXX added as a diagnostic
    prange=P_nought_vec - P_prime

    other_F_prime = 1.0
    otherP_prime = 0.5 * other_F_prime * cos_two_polar_angle * sin_sq_tt_vec
    otherprange=P_nought_vec - otherP_prime
    diff2 = flex.abs(prange - otherprange)
    print("mean diff is",flex.mean(diff2), "range",flex.min(diff2), flex.max(diff2))
    # XXX done
    observations = observations / ( P_nought_vec - P_prime )
    # This corrects observations for polarization assuming 100% polarization on
    # one axis (thus the F_prime = -1.0 rather than the perpendicular axis, 1.0)
    # Polarization model as described by Kahn, Fourme, Gadet, Janin, Dumas & Andre
    # (1982) J. Appl. Cryst. 15, 330-337, equations 13 - 15.

    print("Step 3. Correct for polarization.")
    indexed_cell = observations.unit_cell()

    observations_original_index = observations.deep_copy()
    if result.get("model_partialities",None) is not None and result["model_partialities"][0] is not None:
      # some recordkeeping useful for simulations
      partialities_original_index = observations.customized_copy(
        crystal_symmetry=self.miller_set.crystal_symmetry(),
        data = result["model_partialities"][0]["data"],
        sigmas = flex.double(result["model_partialities"][0]["data"].size()), #dummy value for sigmas
        indices = result["model_partialities"][0]["indices"],
        ).resolution_filter(d_min=self.params.d_min)

    assert len(observations_original_index.indices()) == len(observations.indices())

    # Now manipulate the data to conform to unit cell, asu, and space group
    # of reference.  The resolution will be cut later.
    # Only works if there is NOT an indexing ambiguity!
    observations = observations.customized_copy(
      anomalous_flag=not self.params.merge_anomalous,
      crystal_symmetry=self.miller_set.crystal_symmetry()
      ).map_to_asu()

    observations_original_index = observations_original_index.customized_copy(
      anomalous_flag=not self.params.merge_anomalous,
      crystal_symmetry=self.miller_set.crystal_symmetry()
      )
    print("Step 4. Filter on global resolution and map to asu")
    print("Data in reference setting:", file=out)
    #observations.show_summary(f=out, prefix="  ")
    show_observations(observations, out=out)

    #if self.params.significance_filter.apply is True:
    #  raise Exception("significance filter not implemented in samosa")
    if self.params.significance_filter.apply is True: #------------------------------------
      # Apply an I/sigma filter ... accept resolution bins only if they
      #   have significant signal; tends to screen out higher resolution observations
      #   if the integration model doesn't quite fit
      N_obs_pre_filter = observations.size()
      N_bins_small_set = N_obs_pre_filter // self.params.significance_filter.min_ct
      N_bins_large_set = N_obs_pre_filter // self.params.significance_filter.max_ct

      # Ensure there is at least one bin.
      N_bins = max(
        [min([self.params.significance_filter.n_bins,N_bins_small_set]),
         N_bins_large_set, 1]
      )
      print("Total obs %d Choose n bins = %d"%(N_obs_pre_filter,N_bins))
      bin_results = show_observations(observations, out=out, n_bins=N_bins)
      #show_observations(observations, out=sys.stdout, n_bins=N_bins)
      acceptable_resolution_bins = [
        bin.mean_I_sigI > self.params.significance_filter.sigma for bin in bin_results]
      acceptable_nested_bin_sequences = [i for i in range(len(acceptable_resolution_bins))
                                         if False not in acceptable_resolution_bins[:i+1]]
      if len(acceptable_nested_bin_sequences)==0:
        return null_data(
          file_name=file_name, log_out=out.getvalue(), low_signal=True)
      else:
        N_acceptable_bins = max(acceptable_nested_bin_sequences) + 1
        imposed_res_filter = float(bin_results[N_acceptable_bins-1].d_range.split()[2])
        imposed_res_sel = observations.resolution_filter_selection(
          d_min=imposed_res_filter)
        observations = observations.select(
          imposed_res_sel)
        observations_original_index = observations_original_index.select(
          imposed_res_sel)
        print("New resolution filter at %7.2f"%imposed_res_filter,file_name)
      print("N acceptable bins",N_acceptable_bins)
      print("Old n_obs: %d, new n_obs: %d"%(N_obs_pre_filter,observations.size()))
      print("Step 5. Frame by frame resolution filter")
      # Finished applying the binwise I/sigma filter---------------------------------------

    if self.params.raw_data.sdfac_auto is True:
      raise Exception("sdfac auto not implemented in samosa.")

    print("Step 6.  Match to reference intensities, filter by correlation, filter out negative intensities.")
    assert len(observations_original_index.indices()) \
      ==   len(observations.indices())

    data = frame_data(self.n_refl, file_name)
    data.set_indexed_cell(indexed_cell)
    data.d_min = observations.d_min()

    # Ensure that match_multi_indices() will return identical results
    # when a frame's observations are matched against the
    # pre-generated Miller set, self.miller_set, and the reference
    # data set, self.i_model.  The implication is that the same match
    # can be used to map Miller indices to array indices for intensity
    # accumulation, and for determination of the correlation
    # coefficient in the presence of a scaling reference.
    if self.i_model is not None:
      assert len(self.i_model.indices()) == len(self.miller_set.indices()) \
        and  (self.i_model.indices() ==
              self.miller_set.indices()).count(False) == 0

    matches = miller.match_multi_indices(
      miller_indices_unique=self.miller_set.indices(),
      miller_indices=observations.indices())

    use_weights = False # New facility for getting variance-weighted correlation
    if self.params.scaling.algorithm in ['mark1','levmar']:
      # Because no correlation is computed, the correlation
      # coefficient is fixed at zero.  Setting slope = 1 means
      # intensities are added without applying a scale factor.
      sum_x = 0
      sum_y = 0
      for pair in matches.pairs():
        data.n_obs += 1
        if not self.params.include_negatives and observations.data()[pair[1]] <= 0:
          data.n_rejected += 1
        else:
          sum_y += observations.data()[pair[1]]
      N = data.n_obs - data.n_rejected

    # Early return if there are no positive reflections on the frame.
    if data.n_obs <= data.n_rejected:
      return null_data(
        file_name=file_name, log_out=out.getvalue(), low_signal=True)

    # Update the count for each matched reflection.  This counts
    # reflections with non-positive intensities, too.
    data.completeness += matches.number_of_matches(0).as_int()
    data.wavelength = wavelength

    if not self.params.scaling.enable: # Do not scale anything
      print("Scale factor to an isomorphous reference PDB will NOT be applied.")
      slope = 1.0
      offset = 0.0

    observations_original_index_indices = observations_original_index.indices()
    if db_mgr is None: return unpack(MINI.x) # special exit for two-color indexing

    kwargs = {'wavelength': wavelength,
              'beam_x': result['xbeam'],
              'beam_y': result['ybeam'],
              'distance': result['distance'],
              'unique_file_name': data.file_name}

    ORI = result["current_orientation"][0]
    Astar = matrix.sqr(ORI.reciprocal_matrix())

    kwargs['res_ori_1'] = Astar[0]
    kwargs['res_ori_2'] = Astar[1]
    kwargs['res_ori_3'] = Astar[2]
    kwargs['res_ori_4'] = Astar[3]
    kwargs['res_ori_5'] = Astar[4]
    kwargs['res_ori_6'] = Astar[5]
    kwargs['res_ori_7'] = Astar[6]
    kwargs['res_ori_8'] = Astar[7]
    kwargs['res_ori_9'] = Astar[8]
    assert self.params.scaling.report_ML is True
    kwargs['half_mosaicity_deg'] = result["ML_half_mosaicity_deg"][0]
    kwargs['domain_size_ang'] = result["ML_domain_size_ang"][0]

    frame_id_0_base = db_mgr.insert_frame(**kwargs)

    xypred = result["mapped_predictions"][0]
    indices = flex.size_t([pair[1] for pair in matches.pairs()])

    sel_observations = flex.intersection(
      size=observations.data().size(),
      iselections=[indices])
    set_original_hkl = observations_original_index_indices.select(
      flex.intersection(
        size=observations_original_index_indices.size(),
        iselections=[indices]))
    set_xypred = xypred.select(
      flex.intersection(
        size=xypred.size(),
        iselections=[indices]))

    kwargs = {'hkl_id_0_base': [pair[0] for pair in matches.pairs()],
              'i': observations.data().select(sel_observations),
              'sigi': observations.sigmas().select(sel_observations),
              'detector_x': [xy[0] for xy in set_xypred],
              'detector_y': [xy[1] for xy in set_xypred],
              'frame_id_0_base': [frame_id_0_base] * len(matches.pairs()),
              'overload_flag': [0] * len(matches.pairs()),
              'original_h': [hkl[0] for hkl in set_original_hkl],
              'original_k': [hkl[1] for hkl in set_original_hkl],
              'original_l': [hkl[2] for hkl in set_original_hkl]}

    db_mgr.insert_observation(**kwargs)

    print("Lattice: %d reflections" % (data.n_obs - data.n_rejected), file=out)
    print("average obs", sum_y / (data.n_obs - data.n_rejected), \
      "average calc", sum_x / (data.n_obs - data.n_rejected), file=out)
    print("Rejected %d reflections with negative intensities" % \
        data.n_rejected, file=out)

    data.accept = True
    for pair in matches.pairs():
      if not self.params.include_negatives and (observations.data()[pair[1]] <= 0):
        continue
      Intensity = observations.data()[pair[1]]
      # Super-rare exception. If saved sigmas instead of I/sigmas in the ISIGI dict, this wouldn't be needed.
      if Intensity == 0:
        continue

      # Add the reflection as a two-tuple of intensity and I/sig(I)
      # to the dictionary of observations.
      index = self.miller_set.indices()[pair[0]]
      isigi = (Intensity,
               observations.data()[pair[1]] / observations.sigmas()[pair[1]],
               1.0)
      if index in data.ISIGI:
        data.ISIGI[index].append(isigi)
      else:
        data.ISIGI[index] = [isigi]

      sigma = observations.sigmas()[pair[1]]
      variance = sigma * sigma
      data.summed_N[pair[0]] += 1
      data.summed_wt_I[pair[0]] += Intensity / variance
      data.summed_weight[pair[0]] += 1 / variance


    data.set_log_out(out.getvalue())
    return data

#-----------------------------------------------------------------------
def run(args):
  phil = iotbx.phil.process_command_line(args=args, master_string=master_phil).show()
  work_params = phil.work.extract()
  from xfel.merging.phil_validation import application,samosa
  application(work_params)
  samosa(work_params)
  if ("--help" in args):
    libtbx.phil.parse(master_phil.show())
    return

  if ((work_params.d_min is None) or
      (work_params.data is None) ):
    command_name = os.environ["LIBTBX_DISPATCHER_NAME"]
    raise Usage(command_name + " "
                "d_min=4.0 "
                "data=~/scratch/r0220/006/strong/ "
                "model=3bz1_3bz2_core.pdb")
  if ((work_params.rescale_with_average_cell) and
      (not work_params.set_average_unit_cell)):
    raise Usage("If rescale_with_average_cell=True, you must also specify "+
      "set_average_unit_cell=True.")
  if work_params.raw_data.sdfac_auto and work_params.raw_data.sdfac_refine:
    raise Usage("Cannot specify both sdfac_auto and sdfac_refine")

  # Read Nat's reference model from an MTZ file.  XXX The observation
  # type is given as F, not I--should they be squared?  Check with Nat!
  log = open("%s.log" % work_params.output.prefix, "w")
  out = multi_out()
  out.register("log", log, atexit_send_to=None)
  out.register("stdout", sys.stdout)
  print("I model", file=out)
  if work_params.model is not None:
    from xfel.merging.general_fcalc import run
    i_model = run(work_params)
    work_params.target_unit_cell = i_model.unit_cell()
    work_params.target_space_group = i_model.space_group_info()
    i_model.show_summary()
  else:
    i_model = None

  print("Target unit cell and space group:", file=out)
  print("  ", work_params.target_unit_cell, file=out)
  print("  ", work_params.target_space_group, file=out)

  miller_set, i_model = consistent_set_and_model(work_params,i_model)

  frame_files = get_observations(work_params)
  scaler = scaling_manager(
    miller_set=miller_set,
    i_model=i_model,
    params=work_params,
    log=out)
  scaler.scale_all(frame_files)
  if scaler.n_accepted == 0:
    return None
  scaler.show_unit_cell_histograms()
  if (work_params.rescale_with_average_cell):
    average_cell_abc = scaler.uc_values.get_average_cell_dimensions()
    average_cell = uctbx.unit_cell(list(average_cell_abc) +
      list(work_params.target_unit_cell.parameters()[3:]))
    work_params.target_unit_cell = average_cell
    print("", file=out)
    print("#" * 80, file=out)
    print("RESCALING WITH NEW TARGET CELL", file=out)
    print("  average cell: %g %g %g %g %g %g" % \
      work_params.target_unit_cell.parameters(), file=out)
    print("", file=out)
    scaler.reset()
    scaler.scale_all(frame_files)
    scaler.show_unit_cell_histograms()
  if False : #(work_params.output.show_plots):
    try :
      plot_overall_completeness(completeness)
    except Exception as e :
      print("ERROR: can't show plots")
      print("  %s" % str(e))
  print("\n", file=out)

  # Sum the observations of I and I/sig(I) for each reflection.
  sum_I = flex.double(miller_set.size(), 0.)
  sum_I_SIGI = flex.double(miller_set.size(), 0.)
  for i in range(miller_set.size()):
    index = miller_set.indices()[i]
    if index in scaler.ISIGI :
      for t in scaler.ISIGI[index]:
        sum_I[i] += t[0]
        sum_I_SIGI[i] += t[1]

  miller_set_avg = miller_set.customized_copy(
    unit_cell=work_params.target_unit_cell)
  table1 = show_overall_observations(
    obs=miller_set_avg,
    redundancy=scaler.completeness,
    summed_wt_I=scaler.summed_wt_I,
    summed_weight=scaler.summed_weight,
    ISIGI=scaler.ISIGI,
    n_bins=work_params.output.n_bins,
    title="Statistics for all reflections",
    out=out,
    work_params=work_params)
  print("", file=out)
  n_refl, corr = ((scaler.completeness > 0).count(True), 0)
  print("\n", file=out)
  table2 = show_overall_observations(
    obs=miller_set_avg,
    redundancy=scaler.summed_N,
    summed_wt_I=scaler.summed_wt_I,
    summed_weight=scaler.summed_weight,
    ISIGI=scaler.ISIGI,
    n_bins=work_params.output.n_bins,
    title="Statistics for reflections where I > 0",
    out=out,
    work_params=work_params)
  #from libtbx import easy_pickle
  #easy_pickle.dump(file_name="stats.pickle", obj=stats)
  #stats.report(plot=work_params.plot)
  #miller_counts = miller_set_p1.array(data=stats.counts.as_double()).select(
  #  stats.counts != 0)
  #miller_counts.as_mtz_dataset(column_root_label="NOBS").mtz_object().write(
  #  file_name="nobs.mtz")
  if work_params.data_subsubsets.subsubset is not None and work_params.data_subsubsets.subsubset_total is not None:
    easy_pickle.dump("scaler_%d.pickle"%work_params.data_subsubsets.subsubset, scaler)
  print("", file=out)
  mtz_file, miller_array = scaler.finalize_and_save_data()
  #table_pickle_file = "%s_graphs.pkl" % work_params.output.prefix
  #easy_pickle.dump(table_pickle_file, [table1, table2])
  loggraph_file = os.path.abspath("%s_graphs.log" % work_params.output.prefix)
  f = open(loggraph_file, "w")
  f.write(table1.format_loggraph())
  f.write("\n")
  f.write(table2.format_loggraph())
  f.close()
  result = scaling_result(
    miller_array=miller_array,
    plots=scaler.get_plot_statistics(),
    mtz_file=mtz_file,
    loggraph_file=loggraph_file,
    obs_table=table1,
    all_obs_table=table2,
    n_reflections=n_refl,
    overall_correlation=corr)
  easy_pickle.dump("%s.pkl" % work_params.output.prefix, result)
  return result

from xfel.command_line.cxi_merge import show_overall_observations

class scaling_result(group_args):
  """
  Container for any objects that might need to be saved for future use (e.g.
  in a GUI).  Must be pickle-able!
  """
  pass

#-----------------------------------------------------------------------
# graphical goodies
def plot_overall_completeness(completeness):
  completeness_range = range(-1,flex.max(completeness)+1)
  completeness_counts = [completeness.count(n) for n in completeness_range]
  from matplotlib import pyplot as plt
  plt.plot(completeness_range,completeness_counts,"r+")
  plt.show()

from xfel.command_line.cxi_merge import plot_statistics as plot_base
class plot_statistics(plot_base):
  """
  Container for assorted histograms of frame statistics.  The resolution bin
  plots are stored separately, since they can be displayed using the loggraph
  viewer.
  """
  def __init__(self,
                prefix,
                unit_cell_statistics,
                reference_cell,
                correlations,
                rejected_fractions,
                frame_d_min):
    adopt_init_args(self, locals())

  def show_all_pyplot(self, n_slots=20):
    """
    Display histograms using pyplot.  For use in a wxPython GUI the figure
    should be created separately in a wx.Frame.
    """
    from matplotlib import pyplot as plt
    fig = plt.figure(figsize=(9,12))
    self.plot_unit_cell_histograms(
      figure=fig,
      a_values=self.unit_cell_statistics.all_uc_a_values,
      b_values=self.unit_cell_statistics.all_uc_b_values,
      c_values=self.unit_cell_statistics.all_uc_c_values,
      n_slots=n_slots,
      title=\
        "Unit cell length distribution (all frames with compatible indexing): %s" % self.prefix)
    plt.show()
    fig = plt.figure(figsize=(9,12))
    self.plot_statistics_histograms(
      figure=fig,
      n_slots=n_slots)
    plt.show()

  def plot_statistics_histograms(self,
      figure,
      n_slots=20):
    ax3 = figure.add_axes([0.1, 0.7, 0.8, 0.25])
    ax3.hist(self.frame_d_min, n_slots, color=[0.0,0.5,1.0])
    ax3.set_xlabel("Integrated resolution limit")
    ax3.set_title("Resolution by frame (%s)" % self.prefix)

if (__name__ == "__main__"):
  show_plots = False
  if ("--plots" in sys.argv):
    sys.argv.remove("--plots")
    show_plots = True
  result = run(args=sys.argv[1:])
  if result is None:
    sys.exit(1)
  if (show_plots):
    result.plots.show_all_pyplot()
    from wxtbx.command_line import loggraph
    loggraph.run([result.loggraph_file])


 *******************************************************************************


 *******************************************************************************
cctbx/examples/merging/samosa/per_lattice_postrefinement.py
from __future__ import absolute_import, division, print_function
from six.moves import range
import math
from scitbx import matrix
from cctbx import miller
from dials.array_family import flex
from scitbx.math.tests.tst_weighted_correlation import simple_weighted_correlation
from libtbx import adopt_init_args, group_args

class legacy_cxi_merge_postrefinement(object):
  def __init__(self,measurements_orig, params, i_model, miller_set, result, out):
    measurements = measurements_orig.deep_copy()

    # Now manipulate the data to conform to unit cell, asu, and space group
    # of reference.  The resolution will be cut later.
    # Only works if there is NOT an indexing ambiguity!
    observations = measurements.customized_copy(
      anomalous_flag=not params.merge_anomalous,
      crystal_symmetry=miller_set.crystal_symmetry()
      ).map_to_asu()

    observations_original_index = measurements.customized_copy(
      anomalous_flag=not params.merge_anomalous,
      crystal_symmetry=miller_set.crystal_symmetry()
      )

    # Ensure that match_multi_indices() will return identical results
    # when a frame's observations are matched against the
    # pre-generated Miller set, self.miller_set, and the reference
    # data set, self.i_model.  The implication is that the same match
    # can be used to map Miller indices to array indices for intensity
    # accumulation, and for determination of the correlation
    # coefficient in the presence of a scaling reference.

    assert len(i_model.indices()) == len(miller_set.indices()) \
        and  (i_model.indices() ==
              miller_set.indices()).count(False) == 0

    matches = miller.match_multi_indices(
      miller_indices_unique=miller_set.indices(),
      miller_indices=observations.indices())

    pair1 = flex.int([pair[1] for pair in matches.pairs()])
    pair0 = flex.int([pair[0] for pair in matches.pairs()])
    # narrow things down to the set that matches, only
    observations_pair1_selected = observations.customized_copy(
      indices = flex.miller_index([observations.indices()[p] for p in pair1]),
      data = flex.double([observations.data()[p] for p in pair1]),
      sigmas = flex.double([observations.sigmas()[p] for p in pair1]),
    )
    observations_original_index_pair1_selected = observations_original_index.customized_copy(
      indices = flex.miller_index([observations_original_index.indices()[p] for p in pair1]),
      data = flex.double([observations_original_index.data()[p] for p in pair1]),
      sigmas = flex.double([observations_original_index.sigmas()[p] for p in pair1]),
    )
###################
    I_observed = observations_pair1_selected.data()
    MILLER = observations_original_index_pair1_selected.indices()
    ORI = result["current_orientation"][0]
    Astar = matrix.sqr(ORI.reciprocal_matrix())
    WAVE = result["wavelength"]
    BEAM = matrix.col((0.0,0.0,-1./WAVE))
    BFACTOR = 0.

    #calculation of correlation here
    I_reference = flex.double([i_model.data()[pair[0]] for pair in matches.pairs()])
    use_weights = False # New facility for getting variance-weighted correlation

    if use_weights:
       #variance weighting
      I_weight = flex.double(
        [1./(observations_pair1_selected.sigmas()[pair[1]])**2 for pair in matches.pairs()])
    else:
      I_weight = flex.double(len(observations_pair1_selected.sigmas()), 1.)

    """Explanation of 'include_negatives' semantics as originally implemented in cxi.merge postrefinement:
       include_negatives = True
       + and - reflections both used for Rh distribution for initial estimate of RS parameter
       + and - reflections both used for calc/obs correlation slope for initial estimate of G parameter
       + and - reflections both passed to the refinery and used in the target function (makes sense if
                           you look at it from a certain point of view)

       include_negatives = False
       + and - reflections both used for Rh distribution for initial estimate of RS parameter
       +       reflections only used for calc/obs correlation slope for initial estimate of G parameter
       + and - reflections both passed to the refinery and used in the target function (makes sense if
                           you look at it from a certain point of view)
    """
    if params.include_negatives:
      SWC = simple_weighted_correlation(I_weight, I_reference, I_observed)
    else:
      non_positive = ( observations_pair1_selected.data() <= 0 )
      SWC = simple_weighted_correlation(I_weight.select(~non_positive),
            I_reference.select(~non_positive), I_observed.select(~non_positive))

    print("Old correlation is", SWC.corr, file=out)
    if params.postrefinement.algorithm=="rs":
      Rhall = flex.double()
      for mill in MILLER:
        H = matrix.col(mill)
        Xhkl = Astar*H
        Rh = ( Xhkl + BEAM ).length() - (1./WAVE)
        Rhall.append(Rh)
      Rs = math.sqrt(flex.mean(Rhall*Rhall))

      RS = 1./10000. # reciprocal effective domain size of 1 micron
      RS = Rs        # try this empirically determined approximate, monochrome, a-mosaic value
      current = flex.double([SWC.slope, BFACTOR, RS, 0., 0.])

      parameterization_class = rs_parameterization
      refinery = rs_refinery(ORI=ORI, MILLER=MILLER, BEAM=BEAM, WAVE=WAVE,
        ICALCVEC = I_reference, IOBSVEC = I_observed)

    elif params.postrefinement.algorithm=="eta_deff":
      eta_init = 2. * result["ML_half_mosaicity_deg"][0] * math.pi/180.
      D_eff_init = 2.*result["ML_domain_size_ang"][0]
      current = flex.double([SWC.slope, BFACTOR, eta_init, 0., 0.,D_eff_init,])

      parameterization_class = eta_deff_parameterization
      refinery = eta_deff_refinery(ORI=ORI, MILLER=MILLER, BEAM=BEAM, WAVE=WAVE,
        ICALCVEC = I_reference, IOBSVEC = I_observed)

    func = refinery.fvec_callable(parameterization_class(current))
    functional = flex.sum(func*func)
    print("functional",functional, file=out)
    self.current = current; self.parameterization_class = parameterization_class
    self.refinery = refinery; self.out=out; self.params = params;
    self.miller_set = miller_set
    self.observations_pair1_selected = observations_pair1_selected;
    self.observations_original_index_pair1_selected = observations_original_index_pair1_selected

  def run_plain(self):
    self.MINI = lbfgs_minimizer_derivatives( current_x = self.current,
        parameterization = self.parameterization_class, refinery = self.refinery,
        out = self.out )

  def result_for_cxi_merge(self, file_name):
    scaler = self.refinery.scaler_callable(self.parameterization_class(self.MINI.x))
    if self.params.postrefinement.algorithm=="rs":
      fat_selection = (self.refinery.lorentz_callable(self.parameterization_class(self.MINI.x)) > 0.2)
    else:
      fat_selection = (self.refinery.lorentz_callable(self.parameterization_class(self.MINI.x)) < 0.9)
    fat_count = fat_selection.count(True)

    #avoid empty database INSERT, if insufficient centrally-located Bragg spots:
    # in samosa, handle this at a higher level, but handle it somehow.
    if fat_count < 3:
      raise ValueError
    print("On total %5d the fat selection is %5d"%(
      len(self.observations_pair1_selected.indices()), fat_count), file=self.out)
    observations_original_index = \
      self.observations_original_index_pair1_selected.select(fat_selection)

    observations = self.observations_pair1_selected.customized_copy(
      indices = self.observations_pair1_selected.indices().select(fat_selection),
      data = (self.observations_pair1_selected.data()/scaler).select(fat_selection),
      sigmas = (self.observations_pair1_selected.sigmas()/scaler).select(fat_selection)
    )
    matches = miller.match_multi_indices(
      miller_indices_unique=self.miller_set.indices(),
      miller_indices=observations.indices())
    return observations_original_index,observations,matches

  def result_for_samosa(self):
    values = self.parameterization_class(self.MINI.x)
    return self.refinery.get_eff_Astar(values), values.RS

class refinery_base(group_args):
    def __init__(self, **kwargs):
      group_args.__init__(self,**kwargs)
      mandatory = ["ORI","MILLER","BEAM","WAVE","ICALCVEC","IOBSVEC"]
      for key in mandatory: getattr(self,key)
      self.DSSQ = self.ORI.unit_cell().d_star_sq(self.MILLER)

    """Refinery class takes reference and observations, and implements target
    functions and derivatives for a particular model paradigm."""
    def get_Rh_array(self, values):
      Rh = flex.double()
      eff_Astar = self.get_eff_Astar(values)
      for mill in self.MILLER:
        x = eff_Astar * matrix.col(mill)
        Svec = x + self.BEAM
        Rh.append(Svec.length() - (1./self.WAVE))
      return Rh

    def get_s1_array(self, values):
      miller_vec = self.MILLER.as_vec3_double()
      ref_ori = matrix.sqr(self.ORI.reciprocal_matrix())
      Rx = matrix.col((1,0,0)).axis_and_angle_as_r3_rotation_matrix(values.thetax)
      Ry = matrix.col((0,1,0)).axis_and_angle_as_r3_rotation_matrix(values.thetay)
      s_array = flex.mat3_double(len(self.MILLER),Ry * Rx * ref_ori) * miller_vec
      s1_array = s_array + flex.vec3_double(len(self.MILLER), self.BEAM)
      return s1_array

    def get_eff_Astar(self, values):
      thetax = values.thetax; thetay = values.thetay;
      effective_orientation = self.ORI.rotate_thru((1,0,0),thetax
         ).rotate_thru((0,1,0),thetay
         )
      return matrix.sqr(effective_orientation.reciprocal_matrix())

    def scaler_callable(self, values):
      PB = self.get_partiality_array(values)
      EXP = flex.exp(-2.*values.BFACTOR*self.DSSQ)
      terms = values.G * EXP * PB
      return terms

    def fvec_callable(self, values):
      PB = self.get_partiality_array(values)
      EXP = flex.exp(-2.*values.BFACTOR*self.DSSQ)
      terms = (values.G * EXP * PB * self.ICALCVEC - self.IOBSVEC)
      # Ideas for improvement
      #   straightforward to also include sigma weighting
      #   add extra terms representing rotational excursion: terms.concatenate(1.e7*Rh)
      return terms

class rs_refinery(refinery_base):
    def lorentz_callable(self,values):
      return self.get_partiality_array(values)

    def get_partiality_array(self,values):
      rs = values.RS
      Rh = self.get_Rh_array(values)
      rs_sq = rs*rs
      PB = rs_sq / ((2. * (Rh * Rh)) + rs_sq)
      """
      hard_sphere_partial =(rs_sq-(Rh*Rh))/rs_sq
      immersion = Rh/rs
      from matplotlib import pyplot as plt
      plt.plot (immersion, PB, "r.")
      plt.plot (immersion, hard_sphere_partial,"b.")
      plt.plot ([-1.0,1.0],[0,0],"k-")
      plt.show()
      """
      return PB

    def jacobian_callable(self,values):
      PB = self.get_partiality_array(values)
      EXP = flex.exp(-2.*values.BFACTOR*self.DSSQ)
      G_terms = (EXP * PB * self.ICALCVEC)
      B_terms = (values.G * EXP * PB * self.ICALCVEC)*(-2.*self.DSSQ)
      P_terms = (values.G * EXP * self.ICALCVEC)

      thetax = values.thetax; thetay = values.thetay;
      Rx = matrix.col((1,0,0)).axis_and_angle_as_r3_rotation_matrix(thetax)
      dRx_dthetax = matrix.col((1,0,0)).axis_and_angle_as_r3_derivative_wrt_angle(thetax)
      Ry = matrix.col((0,1,0)).axis_and_angle_as_r3_rotation_matrix(thetay)
      dRy_dthetay = matrix.col((0,1,0)).axis_and_angle_as_r3_derivative_wrt_angle(thetay)
      ref_ori = matrix.sqr(self.ORI.reciprocal_matrix())
      miller_vec = self.MILLER.as_vec3_double()
      ds1_dthetax = flex.mat3_double(len(self.MILLER),Ry * dRx_dthetax * ref_ori) * miller_vec
      ds1_dthetay = flex.mat3_double(len(self.MILLER),dRy_dthetay * Rx * ref_ori) * miller_vec

      s1vec = self.get_s1_array(values)
      s1lenvec = flex.sqrt(s1vec.dot(s1vec))
      dRh_dthetax = s1vec.dot(ds1_dthetax)/s1lenvec
      dRh_dthetay = s1vec.dot(ds1_dthetay)/s1lenvec
      rs = values.RS
      Rh = self.get_Rh_array(values)
      rs_sq = rs*rs
      dPB_dRh = -PB * 4. * Rh / (2. * Rh * Rh + rs_sq)
      dPB_dthetax = dPB_dRh * dRh_dthetax
      dPB_dthetay = dPB_dRh * dRh_dthetay
      Px_terms = P_terms * dPB_dthetax; Py_terms = P_terms * dPB_dthetay

      return [G_terms,B_terms,0,Px_terms,Py_terms]

class nave1_refinery(rs_refinery):

    def jacobian_callable(self,values):
      PB = self.get_partiality_array(values)
      EXP = flex.exp(-2.*values.BFACTOR*self.DSSQ)
      G_terms = (EXP * PB * self.ICALCVEC)
      B_terms = (values.G * EXP * PB * self.ICALCVEC)*(-2.*self.DSSQ)
      P_terms = (values.G * EXP * self.ICALCVEC)

      thetax = values.thetax; thetay = values.thetay;
      Rx = matrix.col((1,0,0)).axis_and_angle_as_r3_rotation_matrix(thetax)
      dRx_dthetax = matrix.col((1,0,0)).axis_and_angle_as_r3_derivative_wrt_angle(thetax)
      Ry = matrix.col((0,1,0)).axis_and_angle_as_r3_rotation_matrix(thetay)
      dRy_dthetay = matrix.col((0,1,0)).axis_and_angle_as_r3_derivative_wrt_angle(thetay)
      ref_ori = matrix.sqr(self.ORI.reciprocal_matrix())
      miller_vec = self.MILLER.as_vec3_double()
      ds1_dthetax = flex.mat3_double(len(self.MILLER),Ry * dRx_dthetax * ref_ori) * miller_vec
      ds1_dthetay = flex.mat3_double(len(self.MILLER),dRy_dthetay * Rx * ref_ori) * miller_vec

      s1vec = self.get_s1_array(values)
      s1lenvec = flex.sqrt(s1vec.dot(s1vec))
      dRh_dthetax = s1vec.dot(ds1_dthetax)/s1lenvec
      dRh_dthetay = s1vec.dot(ds1_dthetay)/s1lenvec
      rs = values.RS
      Rh = self.get_Rh_array(values)
      rs_sq = rs*rs
      denomin = (2. * Rh * Rh + rs_sq)
      dPB_dRh = -PB * 4. * Rh / denomin
      dPB_dthetax = dPB_dRh * dRh_dthetax
      dPB_dthetay = dPB_dRh * dRh_dthetay
      Px_terms = P_terms * dPB_dthetax; Py_terms = P_terms * dPB_dthetay

      dPB_drs = 4 * rs * Rh * Rh / (denomin * denomin)
      Prs_terms = P_terms * dPB_drs

      return [G_terms,B_terms,Prs_terms,Px_terms,Py_terms]


class eta_deff_refinery(refinery_base):
    def __init__(self, **kwargs):
      refinery_base.__init__(self,**kwargs)
      self.DVEC = self.ORI.unit_cell().d(self.MILLER)

    def lorentz_callable(self,values):
      Rh = self.get_Rh_array(values)
      Rs = flex.double(len(self.MILLER),1./values.DEFF)+flex.double(len(self.MILLER),values.ETA/2.)/self.DVEC
      ratio = Rh / Rs
      ratio_abs = flex.abs(ratio)
      return ratio_abs

    def get_partiality_array(self,values):
      Rh = self.get_Rh_array(values)
      Rs = flex.double(len(self.MILLER),1./values.DEFF)+flex.double(len(self.MILLER),values.ETA/2.)/self.DVEC
      Rs_sq = Rs * Rs
      Rh_sq = Rh * Rh
      numerator = Rs_sq - Rh_sq
      denominator = values.DEFF * Rs * Rs_sq
      partiality = numerator / denominator
      return partiality

class unpack_base(object):
  "abstract interface"
  def __init__(YY,values):
    YY.reference = values # simply the flex double list of parameters
  def __getattr__(YY,item):
    raise NotImplementedError
  def show(values,out):
    raise NotImplementedError

class rs_parameterization(unpack_base):
  def __getattr__(YY,item):
    if item=="thetax" : return YY.reference[3]
    if item=="thetay" : return YY.reference[4]
    if item=="G" :      return YY.reference[0]
    if item=="BFACTOR": return YY.reference[1]
    if item=="RS":      return YY.reference[2]
    return getattr(YY,item)

  def show(YY, out):
    print("G: %10.7f"%YY.G, end=' ', file=out)
    print("B: %10.7f"%YY.BFACTOR, \
        "RS: %10.7f"%YY.RS, \
        "%7.3f deg %7.3f deg"%(
        180.*YY.thetax/math.pi,180.*YY.thetay/math.pi), file=out)

class eta_deff_parameterization(unpack_base):
  def __getattr__(YY,item):
    if item=="thetax" : return YY.reference[3]
    if item=="thetay" : return YY.reference[4]
    if item=="G" :      return YY.reference[0]
    if item=="BFACTOR": return YY.reference[1]
    if item=="ETA":      return YY.reference[2]
    if item=="DEFF":      return YY.reference[5]
    return getattr(YY,item)

  def show(YY, out):
    print("%10.7f"%YY.G, end=' ', file=out)
    print("%10.7f"%YY.BFACTOR, \
          "eta %10.7f"%YY.ETA, \
          "Deff %10.2f"%YY.DEFF, \
          "%7.3f deg %7.3f deg"%(
      180.*YY.thetax/math.pi,180.*YY.thetay/math.pi), file=out)

class lbfgs_minimizer_base:

  def __init__(self, current_x=None, parameterization=None, refinery=None, out=None,
               min_iterations=0, max_calls=1000, max_drop_eps=1.e-5):
    adopt_init_args(self, locals())
    self.n = current_x.size()
    self.x = current_x
    from scitbx import lbfgs
    self.minimizer = lbfgs.run(
      target_evaluator=self,
      termination_params=lbfgs.termination_parameters(
        traditional_convergence_test=False,
        drop_convergence_test_max_drop_eps=max_drop_eps,
        min_iterations=min_iterations,
        max_iterations = None,
        max_calls=max_calls),
      exception_handling_params=lbfgs.exception_handling_parameters(
         ignore_line_search_failed_rounding_errors=True,
         ignore_line_search_failed_step_at_lower_bound=True,#the only change from default
         ignore_line_search_failed_step_at_upper_bound=False,
         ignore_line_search_failed_maxfev=False,
         ignore_line_search_failed_xtol=False,
         ignore_search_direction_not_descent=False)
      )

  def compute_functional_and_gradients(self):
    values = self.parameterization(self.x)
    assert -150. < values.BFACTOR < 150. # limits on the exponent, please
    self.func = self.refinery.fvec_callable(values)
    functional = flex.sum(self.func*self.func)
    self.f = functional
    DELTA = 1.E-7
    self.g = flex.double()
    for x in range(self.n):
      templist = list(self.x)
      templist[x]+=DELTA
      dvalues = flex.double(templist)

      dfunc = self.refinery.fvec_callable(self.parameterization(dvalues))
      dfunctional = flex.sum(dfunc*dfunc)
      #calculate by finite_difference
      self.g.append( ( dfunctional-functional )/DELTA )
    self.g[2]=0.
    print("rms %10.3f"%math.sqrt(flex.mean(self.func*self.func)), end=' ', file=self.out)
    values.show(self.out)
    return self.f, self.g

  def __del__(self):
    values = self.parameterization(self.x)
    print("FINALMODEL", end=' ', file=self.out)
    print("rms %10.3f"%math.sqrt(flex.mean(self.func*self.func)), end=' ', file=self.out)
    values.show(self.out)

class lbfgs_minimizer_derivatives(lbfgs_minimizer_base):

  def compute_functional_and_gradients_test_code(self):
    values = self.parameterization(self.x)
    assert -150. < values.BFACTOR < 150. # limits on the exponent, please
    self.func = self.refinery.fvec_callable(values)
    functional = flex.sum(self.func*self.func)
    self.f = functional
    jacobian = self.refinery.jacobian_callable(values)
    self.gg_0 = flex.sum(2. * self.func * jacobian[0])
    self.gg_1 = flex.sum(2. * self.func * jacobian[1])
    self.gg_3 = flex.sum(2. * self.func * jacobian[3])
    self.gg_4 = flex.sum(2. * self.func * jacobian[4])
    DELTA = 1.E-7
    self.g = flex.double()
    for x in range(self.n):
      templist = list(self.x)
      templist[x]+=DELTA
      dvalues = flex.double(templist)

      dfunc = self.refinery.fvec_callable(self.parameterization(dvalues))
      dfunctional = flex.sum(dfunc*dfunc)
      #calculate by finite_difference
      self.g.append( ( dfunctional-functional )/DELTA )
    self.g[2]=0.

    print("rms %10.3f"%math.sqrt(flex.mean(self.func*self.func)), end=' ', file=self.out)
    values.show(self.out)
    print("derivatives--> %15.5f    %15.5f    %9.7f   %5.2f   %5.2f"%tuple(self.g), file=self.out)
    print("  analytical-> %15.5f    %15.5f                %5.2f   %5.2f"%(
      self.gg_0,self.gg_1, self.gg_3,self.gg_4), file=self.out)
    self.g[0]=self.gg_0
    self.g[1]=self.gg_1
    self.g[3]=self.gg_3
    self.g[4]=self.gg_4
    return self.f, self.g
  def compute_functional_and_gradients(self):
    values = self.parameterization(self.x)
    assert -150. < values.BFACTOR < 150. # limits on the exponent, please
    self.func = self.refinery.fvec_callable(values)
    functional = flex.sum(self.func*self.func)
    self.f = functional
    jacobian = self.refinery.jacobian_callable(values)
    self.g = flex.double(self.n)
    for ix in range(self.n):
      self.g[ix] = flex.sum(2. * self.func * jacobian[ix])
    print("rms %10.3f"%math.sqrt(flex.mean(self.func*self.func)), end=' ', file=self.out)
    values.show(self.out)
    return self.f, self.g



 *******************************************************************************


 *******************************************************************************
cctbx/examples/merging/samosa/scale.py
from __future__ import absolute_import, division, print_function
from six.moves import range
import os,sys
import libtbx
import iotbx.phil
from libtbx.development.timers import Timer
from cctbx.array_family import flex
from cctbx.examples.merging.task4 import prepare_observations_for_scaling
from cctbx.examples.merging.data_utilities import I_and_G_base_estimate, plot_it, show_correlation
from cctbx.examples.merging.data_utilities import show_histogram
from cctbx.examples.merging.data_subset import mapper_factory
from cctbx import miller
from xfel.merging.database.merging_database_flex import read_experiments
from cctbx.examples.merging.test_levenberg_sparse import xscale6e

class execute_case(object):
 def __init__(self,datadir,work_params,plot=False,esd_plot=False,half_data_flag=0):
  casetag = work_params.output.prefix
  # read the ground truth values back in
  from six.moves import cPickle as pickle
  # it is assumed (for now) that the reference millers contain a complete asymmetric unit
  # of indices, within the (d_max,d_min) region of interest and possibly outside the region.
  reference_millers = pickle.load(open(os.path.join(datadir,casetag+"_miller.pickle"),"rb"))
  experiment_manager = read_experiments(work_params)

  obs = pickle.load(open(os.path.join(datadir,casetag+"_observation.pickle"),"rb"))
  print("Read in %d observations"%(len(obs["observed_intensity"])))
  reference_millers.show_summary(prefix="Miller index file ")

  print(len(obs["frame_lookup"]),len(obs["observed_intensity"]), flex.max(obs['miller_lookup']),flex.max(obs['frame_lookup']))
  max_frameno = flex.max(obs["frame_lookup"])

  from iotbx import mtz
  mtz_object = mtz.object(file_name=work_params.scaling.mtz_file)
  #for array in mtz_object.as_miller_arrays():
  #  this_label = array.info().label_string()
  #  print this_label, array.observation_type()
  I_sim = mtz_object.as_miller_arrays()[0].as_intensity_array()
  I_sim.show_summary()
  MODEL_REINDEX_OP = work_params.model_reindex_op
  I_sim = I_sim.change_basis(MODEL_REINDEX_OP).map_to_asu()

  #match up isomorphous (the simulated fake F's) with experimental unique set
  matches = miller.match_multi_indices(
      miller_indices_unique=reference_millers.indices(),
      miller_indices=I_sim.indices())

  print("original unique",len(reference_millers.indices()))
  print("isomorphous set",len(I_sim.indices()))
  print("pairs",len(matches.pairs()))
  iso_data = flex.double(len(reference_millers.indices()))

  for pair in matches.pairs():
    iso_data[pair[0]] = I_sim.data()[pair[1]]

  reference_data = miller.array(miller_set = reference_millers,
                                data = iso_data)
  reference_data.set_observation_type_xray_intensity()

  FOBS = prepare_observations_for_scaling(work_params,obs=obs,
                                          reference_intensities=reference_data,
                                          files = experiment_manager.get_files(),
                                          half_data_flag=half_data_flag)

  I,I_visited,G,G_visited = I_and_G_base_estimate(FOBS,params=work_params)
  print("I length",len(I), "G length",len(G), "(Reference set; entire asymmetric unit)")
  assert len(reference_data.data()) == len(I)

  #presumably these assertions fail when half data are taken for CC1/2 or d_min is cut
  model_I = reference_data.data()[0:len(I)]

  T = Timer("%d frames"%(len(G), ))

  mapper = mapper_factory(xscale6e)
  minimizer = mapper(I,G,I_visited,G_visited,FOBS,params=work_params,
                     experiments=experiment_manager.get_experiments())

  del T
  minimizer.show_summary()

  Fit = minimizer.e_unpack()
  Gstats=flex.mean_and_variance(Fit["G"].select(G_visited==1))
  print("G mean and standard deviation:",Gstats.mean(),Gstats.unweighted_sample_standard_deviation())
  if "Bfactor" in work_params.levmar.parameter_flags:
    Bstats=flex.mean_and_variance(Fit["B"].select(G_visited==1))
    print("B mean and standard deviation:",Bstats.mean(),Bstats.unweighted_sample_standard_deviation())
  show_correlation(Fit["I"],model_I,I_visited,"Correlation of I:")
  Fit_stddev = minimizer.e_unpack_stddev()

  # XXX FIXME known bug:  the length of Fit["G"] could be smaller than the length of experiment_manager.get_files()
  # Not sure if this has any operational drawbacks.  It's a result of half-dataset selection.

  if plot:
    plot_it(Fit["I"], model_I, mode="I")
    if "Rxy" in work_params.levmar.parameter_flags:
      show_histogram(Fit["Ax"],"Histogram of x rotation (degrees)")
      show_histogram(Fit["Ay"],"Histogram of y rotation (degrees)")
  print()

  if esd_plot:
    minimizer.esd_plot()

  from cctbx.examples.merging.show_results import show_overall_observations
  table1,self.n_bins,self.d_min = show_overall_observations(
           Fit["I"],Fit_stddev["I"],I_visited,
           reference_data,FOBS,title="Statistics for all reflections",
           work_params = work_params)

  self.FSIM=FOBS
  self.ordered_intensities=reference_data
  self.reference_millers=reference_millers
  self.Fit_I=Fit["I"]
  self.Fit_I_stddev=Fit_stddev["I"]
  self.I_visited=I_visited
  self.Fit = Fit
  self.experiments = experiment_manager

def run(show_plots,args):
  from xfel.command_line.cxi_merge import master_phil
  phil = iotbx.phil.process_command_line(args=args, master_string=master_phil).show()
  work_params = phil.work.extract()
  from xfel.merging.phil_validation import application,samosa
  application(work_params)
  samosa(work_params)
  if ("--help" in args):
    libtbx.phil.parse(master_phil.show())
    return

  datadir = "."
  written_files = []
  if work_params.levmar.compute_cc_half:

    for half_data_flag in [1,2,0]:
      case = execute_case(datadir, work_params, plot=show_plots, half_data_flag=half_data_flag)
      assert len(case.Fit_I)==len(case.ordered_intensities.indices())==len(case.reference_millers.indices())
      model_subset = case.reference_millers[0:len(case.Fit_I)]
      fitted_miller_array = miller.array (miller_set = model_subset,
                                        data = case.Fit_I, sigmas = case.Fit_I_stddev)
      fitted_miller_array.set_observation_type_xray_intensity()
      output_result = fitted_miller_array.select(case.I_visited==1)
      outfile = "%s_s%1d_levmar.mtz"%(work_params.output.prefix,half_data_flag)
      output_result.show_summary(prefix="%s: "%outfile)
      mtz_out = output_result.as_mtz_dataset(column_root_label="Iobs",title=outfile,wavelength=None)
      mtz_obj = mtz_out.mtz_object()
      mtz_obj.write(outfile)
      written_files.append(outfile)
      print("OK s%1d"%half_data_flag)
      #raw_input("OK?")

    """Guest code to retrieve the modified orientations after rotational fitting is done"""
    if "Rxy" in work_params.levmar.parameter_flags:
      all_A = [e.crystal.get_A() for e in case.experiments.get_experiments()]
      all_files = case.experiments.get_files()
      all_x = case.Fit["Ax"]
      all_y = case.Fit["Ay"]

      from scitbx import matrix
      x_axis = matrix.col((1.,0.,0.))
      y_axis = matrix.col((0.,1.,0.))
      out = open("aaaaa","w")
      for x in range(len(all_A)):
        Rx = x_axis.axis_and_angle_as_r3_rotation_matrix(angle=all_x[x], deg=True)
        Ry = y_axis.axis_and_angle_as_r3_rotation_matrix(angle=all_y[x], deg=True)
        modified_A = Rx * Ry * all_A[x]
        filename = all_files[x]
        print(filename, " ".join([str(a) for a in modified_A.elems]), file=out)



    work_params.scaling.algorithm="levmar"
    from xfel.cxi.cxi_cc import run_cc
    run_cc(work_params,work_params.model_reindex_op,sys.stdout)

  else:
    execute_case(datadir, work_params, plot=show_plots)


 *******************************************************************************


 *******************************************************************************
cctbx/examples/merging/show_results.py
from __future__ import absolute_import, division, print_function
from six.moves import range
import sys
from cctbx.array_family import flex
from libtbx.str_utils import format_value
from iotbx import data_plots
from libtbx import adopt_init_args

class n_frames_worker(object):
  def __init__(self,obs_arrays,unique_set,d_max,d_min,n_bins):
    from cctbx import miller
    self.obs_arrays = obs_arrays
    extended_indices = unique_set.indices().select(obs_arrays.miller)
    self.obs_set = unique_set.customized_copy(indices=extended_indices, data=obs_arrays.frame)
    self.obs_set.setup_binner(d_max=d_max,
                              d_min=d_min,
                              n_bins=n_bins)
    self.n_meas_cache = flex.size_t(n_bins+1)
    self.n_neg_cache = flex.size_t(n_bins+1)

  def per_bin_frames(self,i_bin):
    sel_w = self.obs_set.binner().selection(i_bin)
    this_bin_frames = self.obs_set.data().select(sel_w)
    this_set = set(this_bin_frames)
    self.n_meas_cache[i_bin]=len(this_bin_frames)
    this_bin_neg = (self.obs_arrays.raw_obs.select(sel_w)<0.).count(True)
    self.n_neg_cache[i_bin]=this_bin_neg

    return len(this_set)

  def all_frames(self):
    this_set = set(self.obs_set.data())
    return len(this_set)

  def per_bin_meas(self,i_bin): return self.n_meas_cache[i_bin]
  def per_bin_neg(self,i_bin): return self.n_neg_cache[i_bin]
  def all_meas(self): return flex.sum(self.n_meas_cache)
  def all_neg(self): return flex.sum(self.n_neg_cache)

def show_overall_observations(Fit_I,Fit_I_stddev,I_visited,ordered,sim,
  out = None,title = None,work_params = None):

  # at minimum we need the Miller set of merged intensities and sigmas
  # assert len(ordered.indices())==len(Fit_I)
  # have to assert this because the "ordered" indices may not in fact be ordered.
  # but can not assert this in the test1.py test suite.
  model_subset = ordered[0:len(Fit_I)]
  uc = ordered.unit_cell()
  model_subset.crystal_symmetry().show_summary()

  if work_params is not None:
    d_min = work_params.d_min
    d_max = work_params.d_max
    n_bins = work_params.output.n_bins
  else:
    d_min = flex.min(uc.d(model_subset.indices())) # extent of data
    d_max = None
    n_bins = min( len(Fit_I)//20, 15 )

  #obs, redundancy, summed_wt_I, summed_weight, ISIGI, n_bins=15, out=None, title=None, work_params=None):
  if out is None:
    out = sys.stdout
  model_subset.setup_binner(d_max=(d_max or 100000), d_min=d_min, n_bins=n_bins)
  result = []
  multiplicity = flex.int(len(Fit_I))
  for iraw in range(len(sim.miller)):
    multiplicity[sim.miller[iraw]] += 1
  cumulative_unique = 0
  cumulative_meas   = 0
  cumulative_theor  = 0
  cumulative_In     = 0
  cumulative_I      = 0.0
  cumulative_Isigma = 0.0
  frame_worker = n_frames_worker(obs_arrays=sim, unique_set=model_subset,
                                 d_max=(d_max or 100000),d_min=d_min,n_bins=n_bins)

  for i_bin in model_subset.binner().range_used():
    sel_w = model_subset.binner().selection(i_bin)
    sel_fo_all = model_subset.select(sel_w)
    d_range = model_subset.binner().bin_legend(
      i_bin=i_bin, show_bin_number=False, show_counts=False)

    sel_multiplicity = multiplicity.select(sel_w)
    sel_absent = sel_multiplicity.count(0)
    n_present = sel_multiplicity.size() - sel_absent
    sel_complete_tag = "[%d/%d]" % (n_present, sel_multiplicity.size())
    sel_measurements = flex.sum(sel_multiplicity)

    # Alternatively, redundancy (or multiplicity) is calculated as the
    # average number of observations for the observed
    # reflections--missing reflections do not affect the redundancy
    # adversely, and the reported value becomes
    # completeness-independent.
    val_multiplicity_obs = 0
    if n_present > 0:
      val_multiplicity_obs = flex.sum(sel_multiplicity) / n_present
    sel_frames = frame_worker.per_bin_frames(i_bin)

    # Per-bin sum of I and I/sig(I).  For any reflection, the weight
    # of the merged intensity must be positive for this to make sense.
    sel_o = (sel_w & (Fit_I_stddev > 0.))
    selected_intensity = Fit_I.select(sel_o)
    selected_stddev    = Fit_I_stddev.select(sel_o)
    I_sum = flex.sum(selected_intensity)
    assert selected_stddev.count(0.) == 0
    I_sigI_sum = flex.sum(selected_intensity / selected_stddev)
    I_n = sel_o.count(True)

    assert sel_measurements == frame_worker.per_bin_meas(i_bin)

    if sel_measurements > 0:
      mean_I = mean_I_sigI = 0
      if I_n > 0:
        mean_I = I_sum / I_n
        mean_I_sigI = I_sigI_sum / I_n
      bin = resolution_bin(
        i_bin=i_bin,
        d_range=d_range,
        d_min=model_subset.binner().bin_d_min(i_bin),
        redundancy_asu=flex.mean(sel_multiplicity.as_double()),
        redundancy_obs=val_multiplicity_obs,
        frames=sel_frames,
        complete_tag=sel_complete_tag,
        completeness=n_present / sel_multiplicity.size(),
        measurements=sel_measurements,
        negative=frame_worker.per_bin_neg(i_bin),
        percent_neg=100.*frame_worker.per_bin_neg(i_bin)/frame_worker.per_bin_meas(i_bin),
        mean_I=mean_I,
        mean_I_sigI=mean_I_sigI
        )
      result.append(bin)
    cumulative_unique += n_present
    cumulative_meas   += sel_measurements
    cumulative_theor  += sel_multiplicity.size()
    cumulative_In     += I_n
    cumulative_I      += I_sum
    cumulative_Isigma += I_sigI_sum

  if (title is not None):
    print(title, file=out)
  from libtbx import table_utils
  table_header = ["","","","<asu","<obs",""," #"," %","","",""]
  table_header2 = ["Bin","Resolution Range","Completeness","multi>","multi>","n_meas"," neg"," neg","n_xtal","<I>","<I/sig(I)>"]
  table_data = []
  table_data.append(table_header)
  table_data.append(table_header2)
  for bin in result:
    table_row = []
    table_row.append("%3d" % bin.i_bin)
    table_row.append("%-13s" % bin.d_range)
    table_row.append("%13s" % bin.complete_tag)
    table_row.append("%6.2f" % bin.redundancy_asu)
    table_row.append("%6.2f" % bin.redundancy_obs)
    table_row.append("%6d" % bin.measurements)
    table_row.append("%4d" % bin.negative)
    table_row.append("%5.2f"%bin.percent_neg)
    table_row.append("%6d" % bin.frames)
    table_row.append("%8.3f" % bin.mean_I)
    table_row.append("%8.3f" % bin.mean_I_sigI)
    table_data.append(table_row)
  table_data.append([""]*len(table_header))
  table_data.append(  [
      format_value("%3s",   "All"),
      format_value("%-13s", "                 "),
      format_value("%13s",  "[%d/%d]"%(cumulative_unique,cumulative_theor)),
      format_value("%6.2f", cumulative_meas/cumulative_theor),
      format_value("%6.2f", cumulative_meas/cumulative_unique),
      format_value("%6d",   cumulative_meas),
      format_value("%4d",   frame_worker.all_neg()),
      format_value("%5.2f", 100.*frame_worker.all_neg()/frame_worker.all_meas()),
      format_value("%6d",   frame_worker.all_frames()),
      format_value("%8.3f", cumulative_I/cumulative_In),
      format_value("%8.3f", cumulative_Isigma/cumulative_In),
  ])

  print()
  print(table_utils.format(table_data,has_header=2,justify='center',delim=" "), file=out)

  # XXX generate table object for displaying plots
  if (title is None):
    title = "Data statistics by resolution"
  table = data_plots.table_data(
    title=title,
    x_is_inverse_d_min=True,
    force_exact_x_labels=True)
  table.add_column(
    column=[1 / bin.d_min**2 for bin in result],
    column_name="d_min",
    column_label="Resolution")
  table.add_column(
    column=[bin.redundancy_asu for bin in result],
    column_name="redundancy",
    column_label="Redundancy")
  table.add_column(
    column=[bin.completeness for bin in result],
    column_name="completeness",
    column_label="Completeness")
  table.add_column(
    column=[bin.mean_I_sigI for bin in result],
    column_name="mean_i_over_sigI",
    column_label="<I/sig(I)>")
  table.add_graph(
    name="Redundancy vs. resolution",
    type="GRAPH",
    columns=[0,1])
  table.add_graph(
    name="Completeness vs. resolution",
    type="GRAPH",
    columns=[0,2])
  table.add_graph(
    name="<I/sig(I)> vs. resolution",
    type="GRAPH",
    columns=[0,3])
  return table,n_bins,d_min

class resolution_bin(object):
  def __init__(self,
               i_bin=None,
               d_range=None,
               d_min=None,
               redundancy_asu=None,
               redundancy_obs=None,
               frames=None,
               absent=None,
               complete_tag=None,
               completeness=None,
               measurements=None,
               negative=None,
               percent_neg=None,
               mean_I=None,
               mean_I_sigI=None,
               sigmaa=None):
    adopt_init_args(self, locals())


 *******************************************************************************


 *******************************************************************************
cctbx/examples/merging/sigma_correction.py
from __future__ import absolute_import, division, print_function
from six.moves import range
from scitbx.array_family import flex
class ccp4_model(object):
  """Implement a sigma correction for semi-datasets, inspired by the classic
     treatment of SDFAC, SDB, SDADD as discussed by Phil Evans;
     Evans (2011) Acta Cryst D67, 282-292.
     Evans (2006) Acta Cryst D62, 72-82.
     http://ccp4wiki.org/~ccp4wiki/wiki/index.php?title=Symmetry%2C_Scale%2C_Merge#Analysis_of_Standard_Deviations
  """

  def __init__(self):
    #from libtbx import adopt_init_args
    #adopt_init_args(self, locals())
    return
    """An assumption of the class is that semi-datasets A and B are actually drawn from the
    same population.
    """

  @staticmethod
  def plots(a_data, b_data, a_sigmas, b_sigmas):

    # Diagnostic use of the (I - <I>) / sigma distribution, should have mean=0, std=1
    a_variance = a_sigmas * a_sigmas
    b_variance = b_sigmas * b_sigmas
    mean_num = (a_data/ (a_variance) ) + (b_data/ (b_variance) )
    mean_den = (1./ (a_variance) ) + (1./ (b_variance) )
    mean_values = mean_num / mean_den

    delta_I_a = a_data - mean_values
    normal_a = delta_I_a / (a_sigmas)
    stats_a = flex.mean_and_variance(normal_a)
    print("\nA mean %7.4f std %7.4f"%(stats_a.mean(),stats_a.unweighted_sample_standard_deviation()))
    order_a = flex.sort_permutation(normal_a)

    delta_I_b = b_data - mean_values
    normal_b = delta_I_b / (b_sigmas)
    stats_b = flex.mean_and_variance(normal_b)
    print("B mean %7.4f std %7.4f"%(stats_b.mean(),stats_b.unweighted_sample_standard_deviation()))
    order_b = flex.sort_permutation(normal_b)
    # plots for debugging
    from matplotlib import pyplot as plt
    cumnorm = plt.subplot(321)
    cumnorm.plot(range(len(order_a)),normal_a.select(order_a),"b.")
    cumnorm.plot(range(len(order_b)),normal_b.select(order_b),"r.")
    #plt.show()
    logger = plt.subplot(324)
    logger.loglog(a_data,b_data,"r.")
    delta = plt.subplot(322)
    delta.plot(a_data, delta_I_a, "g.")
    #plt.show()
    #nselection = (flex.abs(normal_a) < 2.).__and__(flex.abs(normal_b) < 2.)
    gam = plt.subplot(323)
    gam.plot(mean_values,normal_a,"b.")
    sigs = plt.subplot(326)
    sigs.plot(a_sigmas,b_sigmas,"g.")
    mean_order = flex.sort_permutation(mean_values)
    scatters = flex.double(50)
    scattersb = flex.double(50)
    for isubsection in range(50):
      subselect = mean_order[isubsection*len(mean_order)//50:(isubsection+1)*len(mean_order)//50]
      vals = normal_a.select(subselect)
      #scatters[isubsection] = flex.mean_and_variance(vals).unweighted_sample_standard_deviation()
      scatters[isubsection] = flex.mean_and_variance(vals).unweighted_sample_variance()

      valsb = normal_b.select(subselect)
      #scatters[isubsection] = flex.mean_and_variance(vals).unweighted_sample_standard_deviation()
      scattersb[isubsection] = flex.mean_and_variance(valsb).unweighted_sample_variance()
    aaronsplot = plt.subplot(325)
    aaronsplot.plot(range(50), 2. * scatters, "b.")
    plt.show()

  @staticmethod
  def apply_sd_error_params(vector, a_data, b_data, a_sigmas, b_sigmas):
    sdfac, sdb, sdadd = vector[0],0,vector[1]
    a_variance = a_sigmas * a_sigmas
    b_variance = b_sigmas * b_sigmas
    mean_num = (a_data/ (a_variance) ) + (b_data/ (b_variance) )
    mean_den = (1./ (a_variance) ) + (1./ (b_variance) )
    mean_values = mean_num / mean_den

    I_mean_dependent_part = sdb * mean_values + flex.pow(sdadd * mean_values, 2)
    a_new_variance = sdfac*sdfac * ( a_variance + I_mean_dependent_part )
    b_new_variance = sdfac*sdfac * ( b_variance + I_mean_dependent_part )
    return a_new_variance, b_new_variance

  @staticmethod
  def optimize(a_data, b_data, a_sigmas, b_sigmas):


    print("""Fit the parameters SDfac, SDB and SDAdd using Nelder-Mead simplex method.""")

    from scitbx.simplex import simplex_opt
    class simplex_minimizer(object):
      """Class for refining sdfac, sdb and sdadd"""
      def __init__(self):
        """
        """
        self.n = 2
        self.x = flex.double([0.5,0.0])
        self.starting_simplex = []
        for i in range(self.n+1):
          self.starting_simplex.append(flex.random_double(self.n))

        self.optimizer = simplex_opt( dimension = self.n,
                                      matrix    = self.starting_simplex,
                                      evaluator = self,
                                      tolerance = 1e-1)
        self.x = self.optimizer.get_solution()

      def target(self, vector):
        """ Compute the functional by first applying the current values for the sd parameters
        to the input data, then computing the complete set of normalized deviations and finally
        using those normalized deviations to compute the functional."""
        sdfac, sdb, sdadd = vector[0],0.0,vector[1]

        a_new_variance, b_new_variance = ccp4_model.apply_sd_error_params(
          vector, a_data, b_data, a_sigmas, b_sigmas)

        mean_num = (a_data/ (a_new_variance) ) + (b_data/ (b_new_variance) )
        mean_den = (1./ (a_new_variance) ) + (1./ (b_new_variance) )
        mean_values = mean_num / mean_den

        delta_I_a = a_data - mean_values
        normal_a = delta_I_a / flex.sqrt(a_new_variance)

        delta_I_b = b_data - mean_values
        normal_b = delta_I_b / flex.sqrt(b_new_variance)

        mean_order = flex.sort_permutation(mean_values)
        scatters = flex.double(50)
        scattersb = flex.double(50)
        for isubsection in range(50):
          subselect = mean_order[isubsection*len(mean_order)//50:(isubsection+1)*len(mean_order)//50]
          vals = normal_a.select(subselect)
          scatters[isubsection] = flex.mean_and_variance(vals).unweighted_sample_variance()

          valsb = normal_b.select(subselect)
          scattersb[isubsection] = flex.mean_and_variance(valsb).unweighted_sample_variance()

        f = flex.sum( flex.pow(1.-scatters, 2) )
        print("f: % 12.1f, sdfac: %8.5f, sdb: %8.5f, sdadd: %8.5f"%(f, sdfac, sdb, sdadd))
        return f
    optimizer = simplex_minimizer()
    print("new parameters:",list(optimizer.x))
    return ccp4_model.apply_sd_error_params(optimizer.x,a_data, b_data, a_sigmas, b_sigmas)


 *******************************************************************************


 *******************************************************************************
cctbx/examples/merging/task4.py
from __future__ import absolute_import, division, print_function
from six.moves import range
from cctbx.array_family import flex
from cctbx.uctbx import unit_cell
from six.moves import cPickle as pickle

from cctbx.examples.merging import intensity_data
def prepare_simulation_with_noise(sim, transmittance,
                                       apply_noise,
                                       ordered_intensities=None,
                                       half_data_flag = 0):
  result = intensity_data()
  result.frame = sim["frame_lookup"]
  result.miller= sim['miller_lookup']
  raw_obs_no_noise = transmittance * sim['observed_intensity']
  if apply_noise:
    import scitbx.random
    from scitbx.random import variate, normal_distribution
         # bernoulli_distribution, gamma_distribution, poisson_distribution
    scitbx.random.set_random_seed(321)
    g = variate(normal_distribution())
    noise = flex.sqrt(raw_obs_no_noise) * g(len(raw_obs_no_noise))
    # adds in Gauss noise to signal
  else:
    noise = flex.double(len(raw_obs_no_noise),0.)

  raw_obs = raw_obs_no_noise + noise

  if half_data_flag in [1,2]:  # apply selection after random numbers have been applied
    half_data_selection = (sim["frame_lookup"]%2)==(half_data_flag%2)
    result.frame  = sim["frame_lookup"].select(half_data_selection)
    result.miller = sim['miller_lookup'].select(half_data_selection)
    raw_obs       = raw_obs.select(half_data_selection)

  mean_signal = flex.mean(raw_obs)

  sigma_obs = flex.sqrt(flex.abs(raw_obs))
  mean_sigma = flex.mean(sigma_obs)
  print("<I> / <sigma>", (mean_signal/ mean_sigma))

  scale_factor = mean_signal/10.
  print("Mean signal is",mean_signal,"Applying a constant scale factor of ",scale_factor)

  #most important line; puts input data on a numerically reasonable scale
  result.raw_obs = raw_obs / scale_factor
  scaled_sigma = sigma_obs / scale_factor

  result.exp_var = scaled_sigma * scaled_sigma

  #ordered intensities gets us the unit cell & miller indices to
  # gain a static array of (sin theta over lambda)**2
  if ordered_intensities is not None:
    uc = ordered_intensities.unit_cell()
    stol_sq = flex.double()
    for i in range(len(result.miller)):
      this_hkl = ordered_intensities.indices()[result.miller[i]]
      stol_sq_item = uc.stol_sq(this_hkl)
      stol_sq.append(stol_sq_item)
    result.stol_sq = stol_sq
  return result

def prepare_observations_for_scaling(work_params,obs,reference_intensities=None,
                                       half_data_flag = 0,files = None):
  result = intensity_data()
  result.frame = obs["frame_lookup"]
  result.miller= obs['miller_lookup']
  result.origHKL = flex.miller_index(obs["original_H"],obs["original_K"],obs["original_L"])
  raw_obs = obs["observed_intensity"]
  sigma_obs = obs["observed_sigI"]

  if half_data_flag in [1,2]:  # apply selection after random numbers have been applied
    if files==None:
      half_data_selection = (obs["frame_lookup"]%2)==(half_data_flag%2)
    else:
      # if file names are available, base half data selection on the last digit in filename.
      extension = work_params.filename_extension
      frame_selection = flex.bool([
          (half_data_flag==1 and (int(item.split("."+extension)[0][-1])%2==1)) or \
          (half_data_flag==2 and (int(item.split("."+extension)[0][-1])%2==0))
           for item in files])
      half_data_selection = frame_selection.select(obs["frame_lookup"])

    result.frame  = obs["frame_lookup"].select(half_data_selection)
    result.miller = obs['miller_lookup'].select(half_data_selection)
    result.origHKL = result.origHKL.select(half_data_selection)
    raw_obs       = raw_obs.select(half_data_selection)
    sigma_obs     = sigma_obs.select(half_data_selection)

  mean_signal = flex.mean(raw_obs)
  mean_sigma = flex.mean(sigma_obs)
  print("<I> / <sigma>", (mean_signal/ mean_sigma))

  scale_factor = mean_signal/10.
  print("Mean signal is",mean_signal,"Applying a constant scale factor of ",scale_factor)
  SDFAC_FROM_CHISQ = work_params.levmar.sdfac_value
  #most important line; puts input data on a numerically reasonable scale
  # XXX
  result.raw_obs = raw_obs / scale_factor
  scaled_sigma = SDFAC_FROM_CHISQ * sigma_obs / scale_factor

  result.exp_var = scaled_sigma * scaled_sigma

  #reference intensities gets us the unit cell & miller indices to
  # gain a static array of (sin theta over lambda)**2
  if reference_intensities is not None:
    uc = reference_intensities.unit_cell()
    stol_sq = flex.double()
    for i in range(len(result.miller)):
      this_hkl = reference_intensities.indices()[result.miller[i]]
      stol_sq_item = uc.stol_sq(this_hkl)
      stol_sq.append(stol_sq_item)
    result.stol_sq = stol_sq
  return result

if __name__=="__main__":

  ordered_intensities = pickle.load(open("intensities.pickle","rb"))
  frames = pickle.load(open("frames.pickle","rb"))
  case = 1000
  sim = pickle.load(open("simulated%05d_0.pickle"%case,"rb"))
  print()
  #print "accepted %d obs"%(len(sim["miller_lookup"]))
  #print "accepted frames %d"%(len(sim["frame_lookup"]))
  print("accepted obs %d"%(len(sim["observed_intensity"])))
  #print list(sim["frame_lookup"])
  #print list(sim["miller_lookup"])
  #print list(sim["observed_intensity"])

  transmittance = 0.00001
  apply_noise = True
  FSIM = prepare_simulation_with_noise(sim, transmittance=transmittance,
                                       apply_noise=apply_noise)


  print("OK")


 *******************************************************************************


 *******************************************************************************
cctbx/examples/merging/test1.py
from __future__ import absolute_import, division, print_function
import os,sys
from cctbx.examples.merging import test_levenberg_sparse as test
import libtbx.load_env

# test script assumes that you get the data files directly from the author (NKS) and
# install them in the directory "xscale_reserve" at the same dir-level as cctbx_project

if __name__=="__main__":
  modules_dist = os.path.abspath(os.path.join(libtbx.env.dist_path("cctbx"),"../.."))
  datadir = os.path.join(modules_dist,"xscale_reserve") # Get files directly from author, NKS
  plot_flag=False
  esd_plot_flag=False
  for N in [25, 200, 300, 400, 500, 800, 1000, 2000, 5000]:
   for trans in [1.0, 0.1, 0.01, 0.001, 0.0001, 0.00001]:
    test.execute_case(datadir, n_frame=N, transmittance=trans, apply_noise=True,
      plot=plot_flag, esd_plot = esd_plot_flag)
    print("OK")
    #raw_input("OK")
    sys.stdout.flush()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/merging/test_cc_half.py
from __future__ import absolute_import, division, print_function
import os,sys
from cctbx.examples.merging import test_levenberg_sparse as test
import libtbx.load_env
import math

# test script assumes that you get the data files directly from the author (NKS) and
# install them in the directory "xscale_reserve" at the same dir-level as cctbx_project

def get_model_intensities(work_params,ordered_intensities):
  ordered_intensities.set_observation_type_xray_intensity()
  ordered_intensities.show_summary()
  mtz_out = ordered_intensities.as_mtz_dataset(column_root_label="Iobs",title="PSI simulation",wavelength=None)
  mtz_obj = mtz_out.mtz_object()
  mtz_obj.write(work_params.scaling.mtz_file)

if __name__=="__main__":
  modules_dist = os.path.abspath(os.path.join(libtbx.env.dist_path("cctbx"),"../.."))
  datadir = os.path.join(modules_dist,"xscale_reserve") # Get files directly from author, NKS
  plot_flag=False
  esd_plot_flag=False
  written_files = []

  #for N in [25, 200, 300, 400, 500, 800, 1000, 2000, 5000]:
  for N in [400]:
    #for trans in [1.0, 0.1, 0.01, 0.001, 0.0001, 0.00001]:
    for trans in [0.001,]:
      tagbase = "PSIfulls"
      tag = "%s_N%04d_tE%1d"%(tagbase,N,-math.log10(trans))
      for half_data_flag in [1,2,0]:
        case = test.execute_case(datadir, n_frame=N, transmittance=trans, apply_noise=True,
               plot=plot_flag, esd_plot = esd_plot_flag,half_data_flag = half_data_flag)
        model_subset = case.ordered_intensities[0:len(case.Fit_I)]
        from cctbx.xray import observation_types
        fitted_miller_array = model_subset.customized_copy(data = case.Fit_I, sigmas = case.Fit_I_stddev,
          observation_type=observation_types.intensity())
        output_result = fitted_miller_array.select(case.I_visited==1)
        outfile = "%s_s%1d_levmar.mtz"%(tag,half_data_flag)
        output_result.show_summary(prefix="%s: "%outfile)
        mtz_out = output_result.as_mtz_dataset(column_root_label="Iobs",title=outfile,wavelength=None)
        mtz_obj = mtz_out.mtz_object()
        mtz_obj.write(outfile)
        written_files.append(outfile)
        print("OK")
        #raw_input("OK")
        sys.stdout.flush()

      from xfel.command_line.cxi_merge import master_phil
      import iotbx.phil
      args = ["output.prefix=%s"%tag,"scaling.algorithm=levmar",
              "d_min=%f"%(case.d_min),"output.n_bins=%d"%(case.n_bins),"model=%s"%(os.path.join(datadir,"not_used.pdb")),
              "mtz_file=%s"%("rigged_filename.mtz"),
              "mtz_column_F=iobs",
              "merge_anomalous=True","scaling.show_plots=False","log_cutoff=-20"]
      phil = iotbx.phil.process_command_line(args=args, master_string=master_phil)# .show()
      work_params = phil.work.extract()
      from xfel.merging.phil_validation import application
      application(work_params)
      get_model_intensities(work_params,case.ordered_intensities)
      from xfel.cxi.cxi_cc import run_cc
      run_cc(work_params,"h,k,l",sys.stdout)


 *******************************************************************************


 *******************************************************************************
cctbx/examples/merging/test_levenberg_sparse.py
from __future__ import absolute_import, division, print_function
from six.moves import range
import os
import math
import iotbx.phil
from libtbx.development.timers import Timer
from dials.array_family import flex
from cctbx.examples.merging.task4 import prepare_simulation_with_noise
from cctbx.examples.merging.data_utilities import I_and_G_base_estimate, plot_it, show_correlation
from cctbx.examples.merging.data_subset import mapper_factory
from scitbx.lstbx import normal_eqns
from scitbx.lstbx import normal_eqns_solving
from scitbx.matrix import sqr,col

from cctbx.uctbx import unit_cell
uc_params = (281,281,165,90,90,120)
uc = unit_cell(uc_params)

def choice_as_bitflag(choices):
  from cctbx.examples.merging import ParameterFlags as p
  flags = 0
  for choice in choices:
    flags |= dict(Bfactor = p.Bfactor,
                  Rxy = p.Rxy,
                  Eta = p.Eta,
                  Deff = p.Deff,
                  PartialityDeff = p.PartialityDeff,
                  PartialityEtaDeff = p.PartialityEtaDeff)[choice]
  return flags

def choice_as_helper_base(choices):
 if "Deff" in choices or "Rxy" in choices:
    from cctbx.examples.merging import postrefine_base as base_class
 else:
    from cctbx.examples.merging import xscale6e as base_class

 class levenberg_helper(base_class, normal_eqns.non_linear_ls_mixin):
  def __init__(pfh, initial_estimates):
    super(levenberg_helper, pfh).__init__(n_parameters=len(initial_estimates))
    pfh.x_0 = flex.double(initial_estimates)
    pfh.restart()
    pfh.counter = 0
    # do this outside the factory function pfh.set_cpp_data(fsim, NI, NG)

  def restart(pfh):
    pfh.x = pfh.x_0.deep_copy()
    pfh.old_x = None

  def step_forward(pfh):
    pfh.old_x = pfh.x.deep_copy()
    pfh.x += pfh.step()

  def step_backward(pfh):
    assert pfh.old_x is not None
    pfh.x, pfh.old_x = pfh.old_x, None

  def parameter_vector_norm(pfh):
    return pfh.x.norm()

  def build_up(pfh, objective_only=False):
    if not objective_only: pfh.counter+=1
    pfh.reset()
    pfh.access_cpp_build_up_directly_eigen_eqn(objective_only, current_values = pfh.x)
 return levenberg_helper

class xscale6e(object):

  def __init__(self,Ibase,Gbase,FSIM,curvatures=False,**kwargs):
    # For backward compatibility handle the case where phil is undefined
    if "params" in kwargs:
      self.params = kwargs["params"]
    else:
      from xfel.command_line.cxi_merge import master_phil
      phil = iotbx.phil.process_command_line(args=[], master_string=master_phil).show()
      self.params = phil.work.extract()
      self.params.levmar.parameter_flags.append("Bfactor") # default example refines Bfactor

    self.counter = 0

    self.x = flex.double(list(Ibase) + list(Gbase))
    self.N_I = len(Ibase)
    self.N_G = len(Gbase)
    self.N_raw_obs = FSIM.raw_obs.size()
    print("# structure factors:",self.N_I, "# frames:",self.N_G, "(Visited set; refined parameters)")

    step_threshold = self.params.levmar.termination.step_threshold
    objective_decrease_threshold = self.params.levmar.termination.objective_decrease_threshold
    if "Bfactor" in self.params.levmar.parameter_flags:
        self.x = self.x.concatenate(flex.double(len(Gbase),0.0))
    if "Deff" in self.params.levmar.parameter_flags:
        D_values = flex.double([2.*e.crystal.domain_size for e in kwargs["experiments"]])
        self.x = self.x.concatenate(D_values)
    if "Rxy" in self.params.levmar.parameter_flags:
        self.x = self.x.concatenate(flex.double(2*len(Gbase),0.0))

    levenberg_helper = choice_as_helper_base(self.params.levmar.parameter_flags)
    self.helper = levenberg_helper(initial_estimates = self.x)
    self.helper.set_cpp_data(FSIM, self.N_I, self.N_G)
    if "experiments" in kwargs:
      self.helper.set_wavelength([e.beam.get_wavelength() for e in kwargs["experiments"]])
      self.helper.set_domain_size([2.*e.crystal.get_domain_size_ang() for e in kwargs["experiments"]])#ad hoc factor of 2
      self.helper.set_Astar_matrix([e.crystal.get_A() for e in kwargs["experiments"]])

    bitflags = choice_as_bitflag(self.params.levmar.parameter_flags)
    self.helper.set_parameter_flags(bitflags)
    self.helper.restart()

    iterations = normal_eqns_solving.levenberg_marquardt_iterations_encapsulated_eqns(
               non_linear_ls = self.helper,
               n_max_iterations = 5000,
               track_all=True,
               step_threshold = step_threshold,
               objective_decrease_threshold = objective_decrease_threshold,
               verbose_iterations = True,
    )
    if "Deff" in self.params.levmar.parameter_flags:
      newDeff = self.helper.x[self.N_I+self.N_G:] # XXX specific
      Dstats=flex.mean_and_variance(newDeff)
      print("Refined Deff mean & standard deviation:", end=' ')
      print(Dstats.mean(),Dstats.unweighted_sample_standard_deviation())
    if "Rxy" in self.params.levmar.parameter_flags:
      AX = self.helper.x[self.N_I+self.N_G:self.N_I+2*self.N_G] # XXX specific
      AY = self.helper.x[self.N_I+2*self.N_G:self.N_I+3*self.N_G] # XXX specific
      stats=flex.mean_and_variance(AX)
      print("Rx rotational increments in degrees: %8.6f +/- %8.6f"%(
           stats.mean(),stats.unweighted_sample_standard_deviation()))
      stats=flex.mean_and_variance(AY)
      print("Ry rotational increments in degrees: %8.6f +/- %8.6f"%(
           stats.mean(),stats.unweighted_sample_standard_deviation()))

    print("End of minimisation: Converged", self.helper.counter,"cycles")
    chi_squared = self.helper.objective() * 2.
    print("obj",chi_squared)
    print("# of obs:",FSIM.raw_obs.size())
    dof = FSIM.raw_obs.size() - ( len(self.x) )
    print("degrees of freedom =",dof)
    print("chisq/dof: %7.3f"%(chi_squared / dof))
    print()

  def packed_to_all(self,packed):
    Nx = len(self.helper.x)
    all_elems = flex.double(Nx*Nx)
    ctr = 0
    for x in range(Nx):
      x_0 = ctr
      for y in range(Nx-1,x-1,-1):
        all_elems[ Nx*x+y ] = packed[x_0+(y-x)]
        ctr += 1
        if x!= y:
          all_elems[ Nx*y+x ] = packed[x_0+(y-x)]
    return all_elems
  def pretty(self, matrix, max_col=67,format="%6.0g",zformat="%6.0f"):
    Nx = len(self.helper.x)
    for islow in range(Nx):
      for ifast in range(min(max_col,Nx)):
        if matrix(islow,ifast)==0.:
          print(zformat%0, end=' ')
        else:
          print(format%(matrix(islow,ifast)), end=' ')
      print()
    print()
  def prettynz(self, matrix, max_col=67,format="%6.0g",zformat="%6.0f"):
    Nx = len(self.helper.x)
    for x in range(Nx):
      for y in range(min(max_col,Nx)):
          if abs(matrix(x,y))< 1E-10:
            print(zformat%0, end=' ')
          else:
            print(format%(matrix(x,y)), end=' ')
      print()
  def permutation_ordering_to_matrix(self,ordering):
    matcode = flex.int(ordering.size()**2)
    Nx = ordering.size()
    for islow in range(Nx):
      matcode[Nx*islow + ordering[islow]] = 1
    return sqr(matcode)
  def lower_triangular_packed_to_matrix(self,lower):
    Nx = len(self.helper.x)
    lower_elem = flex.double(Nx*Nx)
    ctr = 0
    for irow in range(Nx): # loop over rows
      for icol in range(irow + 1): # loop over columns
        lower_elem[Nx*irow + icol] = lower[ctr]
        ctr+=1
    return sqr(lower_elem)
  def diagonal_vector_to_matrix(self,diag):
    diag_elem = flex.double(diag.size()**2)
    for irow in range(diag.size()): # loop over rows
      diag_elem[diag.size()*irow + irow] = diag[irow]
    return sqr(diag_elem)
  def unstable_matrix_inversion_diagonal(self,Lower,Diag,Transpose):
    ### Can't use the Cholesky factorization to derive the Variance-Covariance matrix
    ### Demonstrate that inverting the matrix is numerically unstable
    Nx = len(self.helper.x)
    error_diagonal_elems = flex.double(Nx)
    for j_element in range(Nx):

      # now solve for the vector p = D * LT * x by substitution in eqn L * p = b
      # b is the column vector of zeroes except jth_element is 1.
      p = flex.double(Nx)
      p[j_element] = 1.
      for p_idx in range(j_element+1,Nx):
        for subs_idx in range(j_element,p_idx):
          p[p_idx] -= Lower(p_idx,subs_idx) * p[subs_idx]

      Pvec = col(p)

      # now solve for the vector q = LT * x by division in eqn D * q = b
      q = flex.double([ p[i] / Diag(i,i) for i in range(Nx)] )
      #  this is the unstable step.  We can't divide by tiny denominators
      Qvec = col(q)

      # now solve for the jth element of x in the eqn LT * x = q
      xelem = flex.double(Qvec.elems)

      for x_idx in range(Nx-1,j_element-1,-1):  #comment this in for production
      #for x_idx in range(Nx-1,-1,-1):
        for subs_idx in range(x_idx+1, Nx):
          xelem[x_idx] -= Transpose(x_idx,subs_idx) * xelem[subs_idx]
      Xvec = col(xelem) # got the whole vector; only need j_element for the error matrix diagonal
      error_diagonal_elems[j_element] = xelem[j_element]
    return col(error_diagonal_elems)

  def esd_plot(self):
    print("OK esd")

    ### working on the esd problem:
    self.helper.build_up()
    norm_mat_packed_upper = self.helper.get_normal_matrix()
    norm_mat_all_elems = self.packed_to_all(norm_mat_packed_upper)
    diagonal_curvatures = self.helper.get_normal_matrix_diagonal()
    NM = sqr(norm_mat_all_elems)

    print("The normal matrix is:")
    self.pretty(NM)

    from scitbx.linalg.svd import inverse_via_svd
    svd_inverse,sigma = inverse_via_svd(NM.as_flex_double_matrix())

    print("ia",len(svd_inverse),len(sigma))
    IA = sqr(svd_inverse)
    for i in range(self.helper.x.size()):
      if i == self.N_I or i == self.N_I + self.N_G:  print()
      print("%2d %10.4f %10.4f %10.4f"%(
        i, self.helper.x[i], math.sqrt(1./diagonal_curvatures[i]), math.sqrt(IA(i,i))))

    from matplotlib import pyplot as plt
    plt.plot(flex.sqrt(flex.double([IA(i,i) for i in range(self.N_I)])),
             flex.sqrt(1./diagonal_curvatures[:self.N_I]), "r.")
    plt.title("Structure factor e.s.d's from normal matrix curvatures vs. SVD variance diagonal")
    plt.axes().set_aspect("equal")
    plt.show()
    return

    # additional work to validate the Cholesky factorization and investigate stability:
    identity = IA * NM

    print("verify identity:")
    self.pretty(identity,max_col=58,format="%7.1g")
    # we can fool ourselves that the SVD gave us a perfect inverse:
    self.pretty(identity,max_col=72,format="%4.0f")

    ### figure out stuff about permutation matrices
    self.helper.build_up()

    ordering = self.helper.get_eigen_permutation_ordering()
    print("ordering:",list(ordering))
    matcode = self.permutation_ordering_to_matrix(ordering)

    print("matcode:")
    self.pretty(matcode,max_col=72,format="%1d",zformat="%1d")

    permuted_normal_matrix = (matcode.inverse())* NM *matcode
    print("product")
    self.pretty(permuted_normal_matrix)

    ### Now work with the Cholesky factorization
    cholesky_fac_packed_lower = self.helper.get_cholesky_lower()
    Lower = self.lower_triangular_packed_to_matrix(cholesky_fac_packed_lower)
    print("lower:")
    self.pretty(Lower,max_col=59,format="%7.0g",zformat="%7.0g")

    Transpose = Lower.transpose()
    print("transpose")
    self.pretty(Transpose,max_col=59,format="%7.0g",zformat="%7.0g")

    diagonal_factor = self.helper.get_cholesky_diagonal()
    Diag = self.diagonal_vector_to_matrix(diagonal_factor)
    print("diagonal:")
    self.pretty(Diag,max_col=59,format="%7.0g",zformat="%7.0g")

    Composed = Lower * Diag * Transpose
    print("composed")
    self.pretty(Composed,max_col=67,format="%6.0g",zformat="%6.0g")

    Diff = Composed - permuted_normal_matrix
    print("diff")
    self.prettynz(Diff,max_col=67,format="%6.0g",zformat="%6.0g")
    #  OK, this proves that L * D * LT = P * A * P-1
    #  in other words, Eigen has correctly factored the permuted normal matrix
    ############

    Variance_diagonal = self.unstable_matrix_inversion_diagonal(Lower,Diag,Transpose)

    for i in range(self.helper.x.size()):
      if i == self.N_I or i == self.N_I + self.N_G:  print()
      print("%2d %10.4f %10.4f %10.4f"%(
        i, self.helper.x[i], math.sqrt(1./diagonal_curvatures[i]), math.sqrt(IA(i,i))), end=' ')
      print("svd err diag: %10.4f"%(IA(i,i)),"eigen: %15.4f"%(Variance_diagonal[ordering[i]]))

  def fitted_as_annotated(self,data):
    result = {}
    result["I"] = data[ 0 : self.N_I ] # intensity data always packed first
    last = self.N_I
    result["G"] = data[ last : last+self.N_G ] # scale factor next
    last += self.N_G
    if "Bfactor" in self.params.levmar.parameter_flags:
      result["B"] = data[ last : last+self.N_G ] # B factor
      last += self.N_G
    if "Deff" in self.params.levmar.parameter_flags:
      result["D"] = data[ last : last+self.N_G ] # mosaic block size
      last += self.N_G
    if "Rxy" in self.params.levmar.parameter_flags:
      result["Ax"] = data[ last : last+self.N_G ] # Rotation-x in degrees
      last += self.N_G
      result["Ay"] = data[ last : last+self.N_G ] # Rotation-y in degrees
      last += self.N_G
    return result

  def unpack(self):
    return self.fitted_as_annotated(self.helper.x)

  def unpack_stddev(self):
    # the data-to_parameter ratio will control which method for returning e.s.d's
    data_to_parameter = float(self.N_raw_obs) / self.helper.x.size()
    self.helper.build_up()
    if data_to_parameter <= 4. and self.helper.x.size() < 500:
      # estimate standard deviations by singular value decomposition
      norm_mat_packed_upper = self.helper.get_normal_matrix()
      norm_mat_all_elems = self.packed_to_all(norm_mat_packed_upper)
      NM = sqr(norm_mat_all_elems)
      from scitbx.linalg.svd import inverse_via_svd
      svd_inverse,sigma = inverse_via_svd(NM.as_flex_double_matrix())
      IA = sqr(svd_inverse)
      estimated_stddev = flex.double([math.sqrt(IA(i,i)) for i in range(self.helper.x.size())])
    else:
      # estimate standard deviations by normal matrix curvatures
      diagonal_curvatures = self.helper.get_normal_matrix_diagonal()
      estimated_stddev = flex.sqrt(1./diagonal_curvatures)
    return self.fitted_as_annotated(estimated_stddev)

  def show_summary(self):
    print("%d cycles"%self.counter)
    self.helper.show_eigen_summary()

class execute_case(object):
 def __init__(self,datadir,n_frame,transmittance,apply_noise,plot=False,esd_plot=False,half_data_flag=0):
  # read the ground truth values back in
  from six.moves import cPickle as pickle
  ordered_intensities = pickle.load(open(os.path.join(datadir,"intensities.pickle"),"rb"))
  frames = pickle.load(open(os.path.join(datadir,"frames.pickle"),"rb"))

  sim = pickle.load(open(os.path.join(datadir,"simulated%05d_0.pickle"%n_frame),"rb"))
  print("accepted obs %d"%(len(sim["observed_intensity"])))

  FSIM = prepare_simulation_with_noise(sim, transmittance=transmittance,
                                       apply_noise=apply_noise,
                                       ordered_intensities=ordered_intensities,
                                       half_data_flag=half_data_flag)

  I,I_visited,G,G_visited = I_and_G_base_estimate(FSIM)
  model_I = ordered_intensities.data()[0:len(I)]
  model_G = frames["scale_factors"][0:len(G)]
  model_B = frames["B_factors"][0:len(G)]

  T = Timer("%d frames, %f transmittance, %s noise"%(
             n_frame, transmittance, {False:"NO", True:"YES"}[apply_noise]))

  mapper = mapper_factory(xscale6e)
  minimizer = mapper(I,G,I_visited,G_visited,FSIM)

  del T
  minimizer.show_summary()

  Fit = minimizer.e_unpack()
  show_correlation(Fit["G"],model_G,G_visited,"Correlation of G:")
  show_correlation(Fit["B"],model_B,G_visited,"Correlation of B:")
  show_correlation(Fit["I"],model_I,I_visited,"Correlation of I:")
  Fit_stddev = minimizer.e_unpack_stddev()

  if plot:
    plot_it(Fit["G"], model_G, mode="G")
    plot_it(Fit["B"], model_B, mode="B")
    plot_it(Fit["I"], model_I, mode="I")
  print()

  if esd_plot:
    minimizer.esd_plot()

  from cctbx.examples.merging.show_results import show_overall_observations
  table1,self.n_bins,self.d_min = show_overall_observations(
           Fit["I"],Fit_stddev["I"],I_visited,
           ordered_intensities,FSIM,title="Statistics for all reflections")

  self.FSIM=FSIM
  self.ordered_intensities=ordered_intensities
  self.Fit_I=Fit["I"]
  self.Fit_I_stddev=Fit_stddev["I"]
  self.I_visited=I_visited

if __name__=="__main__":

  datadir = os.path.join(os.environ["HOME"],"rosie_xds","xscale_reserve") # Get files directly from author, NKS
  plot_flag=False
  execute_case(datadir, n_frame=400, transmittance=0.00001, apply_noise=True, plot=plot_flag)
  print("OK")


 *******************************************************************************


 *******************************************************************************
cctbx/examples/merging/tst_permutations.py
"""A completely standalone example that explains what a permutation
matrix is and how it is applied in practice.
"""
from __future__ import absolute_import, division, print_function
from six.moves import range
from scitbx.array_family import flex
from scitbx.matrix import sqr,col
def stuff_about_permutations():
    trial = sqr((1,2,3,4,5,6,7,8,9))
    for x in range(3):
      for y in range(3):
        print(trial(x,y), end=' ')
      print()

    ordering = col((3,1,2))
    matcode = flex.int(9)
    for islow in range(3):
      matcode[3*islow + ordering[islow]-1] = 1
    matcode = sqr(matcode)
    print("matcode")
    for x in range(3):
      for y in range(3):
        print(matcode(x,y), end=' ')
      print()
    prod = matcode * trial *(matcode.inverse())
    print("product",prod.elems)
    for x in range(3):
      for y in range(3):
        print(prod(x,y), end=' ')
      print()

stuff_about_permutations()
print("OK")


 *******************************************************************************


 *******************************************************************************
cctbx/examples/miller_common_sets.py
from __future__ import absolute_import, division, print_function
from cctbx import miller
from cctbx import crystal
from cctbx.array_family import flex

def demo():
  #
  # create toy lists of Miller indices
  #
  crystal_symmetry = crystal.symmetry(
    unit_cell=(13,14,15,90,90,90),
    space_group_symbol="P212121")
  miller_set_a = miller.set(
    crystal_symmetry=crystal_symmetry,
    anomalous_flag=False,
    indices=flex.miller_index([
      (0, -1, 2),
      (-1, -2, 3),
      (2, 3, 4),
      (-3, 4, 5),
      (4, -5, 6)]))
  miller_set_b = miller_set_a.customized_copy(
    indices=flex.miller_index([
      (-5, -6, 7),
      (0, 1, 2),
      (3, -4, 5),
      (-1, -2, 3),
      (-4, -5, 6)]))
  #
  # map all indices to the asymmetric unit
  #
  asu_a = miller_set_a.map_to_asu()
  asu_b = miller_set_b.map_to_asu()
  for h in asu_a.indices():
    print("asu a:", h)
  print()
  for h in asu_b.indices():
    print("asu b:", h)
  print()
  #
  # obtain the common index sets
  #
  common_a, common_b = asu_a.common_sets(asu_b)
  for h in common_a.indices():
    print("common a:", h)
  print()
  for h in common_b.indices():
    print("common b:", h)
  print()
  #
  # obtain the "lone" index sets
  #
  lone_set_a, lone_set_b = asu_a.lone_sets(asu_b)
  for h in lone_set_a.indices():
    print("lone a:", h)
  print()
  for h in lone_set_b.indices():
    print("lone b:", h)
  print()
  #
  # now the same again, but with data (i.e. miller.array instances)
  #
  miller_array_a = miller_set_a.array(
    data=flex.random_double(size=miller_set_a.indices().size()))
  miller_array_b = miller_set_b.array(
    data=flex.random_double(size=miller_set_a.indices().size()))
  #
  # map all indices to the asymmetric unit
  #
  asu_a = miller_array_a.map_to_asu()
  asu_b = miller_array_b.map_to_asu()
  asu_a.show_array(prefix="asu a: ")
  print()
  asu_b.show_array(prefix="asu b: ")
  print()
  #
  # obtain the common index sets
  #
  common_a, common_b = asu_a.common_sets(asu_b)
  common_a.show_array(prefix="common a: ")
  print()
  common_b.show_array(prefix="common b: ")
  print()
  #
  # obtain the "lone" index sets
  #
  lone_a, lone_b = asu_a.lone_sets(asu_b)
  lone_a.show_array(prefix="lone a: ")
  print()
  lone_b.show_array(prefix="lone b: ")
  print()
  print("OK")

if (__name__ == "__main__"):
  demo()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/miller_transform.py
from __future__ import absolute_import, division, print_function
from cctbx import miller
from cctbx import crystal
from cctbx import sgtbx
from cctbx.array_family import flex
from cmath import exp, pi
from scitbx.matrix import row, col
from libtbx.test_utils import approx_equal
from six.moves import zip

def exercise():
  ma = miller.array(
    miller.set(crystal.symmetry(unit_cell=(5,5,5, 90, 90, 90),
                                space_group=sgtbx.space_group('P 2x')),
               indices=flex.miller_index(
                 [(1,0,0), (0,1,0), (0,0,1),
                  (-1,0,0), (0,-1,0), (0,0,-1),
                  (1,1,0), (1,0,1), (0,1,1),
                  (-1,-1,0), (-1,0,-1), (0,-1,-1),
                  (1,-1,0), (1,0,-1), (0,1,-1),
                  (-1,1,0), (-1,0,1), (0,-1,1),
                  (1,1,1), (-1,1,1), (1,-1,1), (1,1,-1),
                  (-1,-1,-1), (1,-1,-1), (-1,1,-1), (-1,-1,1)])),
    data=flex.complex_double(flex.random_double(26), flex.random_double(26)))
  f_at_h = dict(zip(ma.indices(), ma.data()))
  for op in ("-x, y+1/2, -z", "x+1/2, -y, z-1/2"):
    op = sgtbx.rt_mx(op)
    original, transformed = ma.common_sets(
      ma.change_basis(sgtbx.change_of_basis_op(op.inverse())))
    for h, f in original:
      assert f == f_at_h[h]
    for h, op_f in transformed:
      assert approx_equal(
        op_f,
        f_at_h[h*op.r()]*exp(1j*2*pi*row(h).dot(col(op.t().as_double()))))

def run():
  exercise()
  print('OK')

if __name__ == '__main__':
  run()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/neutron_structure_factors.py
from __future__ import absolute_import, division, print_function
from cctbx import neutron
from cctbx import crystal

def run():
  quartz_structure = neutron.structure(
    special_position_settings=crystal.special_position_settings(
      crystal_symmetry=crystal.symmetry(
        unit_cell=(5.01,5.01,5.47,90,90,120),
        space_group_symbol="P6222")),
    scatterers=[
      neutron.scatterer(
        label="Si",
        site=(1/2.,1/2.,1/3.),
        u=0.2),
      neutron.scatterer(
        label="O",
        site=(0.197,-0.197,0.83333),
        u=(.01,0.01,0.01,0,0,0))])
  quartz_structure.show_summary().show_scatterers()
  f_calc = quartz_structure.structure_factors(d_min=1)
  f_calc.show_summary().show_array()

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/phase_o_phrenia.py
from __future__ import absolute_import, division, print_function
from cctbx import miller
from cctbx import maptbx
from cctbx import crystal
from cctbx import sgtbx
from cctbx.array_family import flex
from scitbx.python_utils import dicts

def peak_cluster_reduction(crystal_symmetry, peak_list,
                           min_peak_distance, max_reduced_peaks):
  special_position_settings = crystal.special_position_settings(
    crystal_symmetry=crystal_symmetry,
    min_distance_sym_equiv=min_peak_distance)
  peaks = []
  for i,site in enumerate(peak_list.sites()):
    peaks.append(dicts.easy(
      site=special_position_settings.site_symmetry(site).exact_site(),
      height=peak_list.heights()[i]))
  reduced_peaks = []
  for peak in peaks:
    site_symmetry = special_position_settings.site_symmetry(peak.site)
    equiv_sites = sgtbx.sym_equiv_sites(site_symmetry)
    keep = True
    for reduced_peak in reduced_peaks:
      dist = sgtbx.min_sym_equiv_distance_info(
        equiv_sites, reduced_peak.site).dist()
      if (dist < min_peak_distance):
        keep = False
        break
    if (keep == True):
      reduced_peaks.append(peak)
      if (len(reduced_peaks) == max_reduced_peaks): break
  return reduced_peaks

def calculate_exp_i_two_phi_peaks(xray_structure, d_min,
                                  min_peak_distance,
                                  max_reduced_peaks):
  f_h = xray_structure.structure_factors(
    anomalous_flag=False,
    d_min=d_min).f_calc()
  two_i_phi_h = miller.array(
    miller_set=f_h,
    data=flex.polar(1, flex.arg(f_h.data())*2))
  fft_map = two_i_phi_h.fft_map(
    d_min=d_min,
    symmetry_flags=maptbx.use_space_group_symmetry)
  real_map = fft_map.real_map()
  real_map = maptbx.copy(real_map, flex.grid(real_map.focus()))
  stats = maptbx.statistics(real_map)
  if (stats.max() != 0):
    real_map /= abs(stats.max())
  grid_tags = maptbx.grid_tags(real_map.focus())
  grid_tags.build(fft_map.space_group_info().type(), fft_map.symmetry_flags())
  grid_tags.verify(real_map)
  peak_list = maptbx.peak_list(
    data=real_map,
    tags=grid_tags.tag_array(),
    max_peaks=10*max_reduced_peaks,
    interpolate=True)
  reduced_peaks = peak_cluster_reduction(
    crystal_symmetry=xray_structure,
    peak_list=peak_list,
    min_peak_distance=min_peak_distance,
    max_reduced_peaks=max_reduced_peaks)
  return reduced_peaks


 *******************************************************************************


 *******************************************************************************
cctbx/examples/quartz_structure.py
"""\
Updated example from IUCr Computing Commission Newsletter No. 1:
http://cci.lbl.gov/publications/download/iucrcompcomm_jan2003.pdf
"""
from __future__ import absolute_import, division, print_function

from cctbx import xray
from cctbx import crystal
from cctbx.array_family import flex

def run():
  quartz_structure = xray.structure(
    special_position_settings=crystal.special_position_settings(
      crystal_symmetry=crystal.symmetry(
        unit_cell=(5.01,5.01,5.47,90,90,120),
        space_group_symbol="P6222")),
    scatterers=flex.xray_scatterer([
      xray.scatterer(
        label="Si",
        site=(1/2.,1/2.,1/3.),
        u=0.2),
      xray.scatterer(
        label="O",
        site=(0.197,-0.197,0.83333),
        u=0)]))

  quartz_structure.show_summary().show_scatterers()

  from libtbx import easy_pickle
  easy_pickle.dump("beach", quartz_structure)

  from libtbx import easy_pickle
  quartz_structure = easy_pickle.load("beach")

  for scatterer in quartz_structure.scatterers():
    print("%s:" % scatterer.label, "%8.4f %8.4f %8.4f" % scatterer.site)
    site_symmetry = quartz_structure.site_symmetry(scatterer.site)
    print("  point group type:", site_symmetry.point_group_type())
    print("  special position operator:", site_symmetry.special_op_simplified())

  for table in ["xray", "electron"]:
    print("Scattering type table:", table)

    reg = quartz_structure.scattering_type_registry(table=table)
    reg.show_summary()

    f_calc = quartz_structure.structure_factors(d_min=2).f_calc()
    f_calc.show_summary().show_array()

    f_calc.d_spacings().show_array()

    low_resolution_only = f_calc.select(f_calc.d_spacings().data() > 2.5)
    low_resolution_only.show_array()

    print()

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/random_f_calc.py
"""
usage: cctbx.python random_f_calc.py space_group_symbol

Example:
  cctbx.python random_f_calc.py P212121

This will write a file map_coeff.pickle that can be used to
view the electron density map with PyMOL (see view_fft_map.py).
"""
from __future__ import absolute_import, division, print_function

from cctbx.development import random_structure
from cctbx import sgtbx
from libtbx import easy_pickle
import sys

def generate_random_f_calc(space_group_info, n_elements=10, d_min=1.5):
  structure = random_structure.xray_structure(
    space_group_info,
    elements=["Si"]*n_elements,
    volume_per_atom=1000,
    min_distance=3.,
    general_positions_only=False)
  structure.show_summary().show_scatterers()
  print()
  f_calc = structure.structure_factors(
    d_min=d_min, anomalous_flag=False).f_calc()
  f_calc.show_summary()
  print()
  print("Writing file: map_coeff.pickle")
  easy_pickle.dump("map_coeff.pickle", f_calc)
  print()

def run():
  if (len(sys.argv) != 2):
    print(__doc__)
    return
  generate_random_f_calc(sgtbx.space_group_info(sys.argv[1]))

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/random_puckers.py
"""
Simple experiment: using only bond and angle restraints of
RNA sugar ring, performing geometry minimization starting with
random coordinates, how many configurations are found?
"""

from __future__ import absolute_import, division, print_function
import cctbx.geometry_restraints.manager
import cctbx.geometry_restraints.lbfgs
from cctbx.array_family import flex
import scitbx.math.superpose
from scitbx import matrix
from libtbx.test_utils import approx_equal, is_below_limit
from libtbx.utils import null_out
import libtbx.load_env
import math
import sys
from six.moves import range
from six.moves import zip

def pentagon_sites_cart(start_vector=(0,1.5,0), normal=(0,0,1)):
  result = flex.vec3_double([(0,0,0)])
  start_vector = matrix.col(start_vector)
  prev_point = matrix.col((0,0,0))
  axis = matrix.col(normal)
  for i in range(4):
    r = axis.axis_and_angle_as_r3_rotation_matrix(angle=72*i, deg=True)
    point = prev_point + r * start_vector
    result.append(point)
    prev_point = point
  result -= result.mean()
  return result

atom_names = ["C1*", "C2*", "C3*", "C4*", "O4*"]
sites_cart_3p = flex.vec3_double([
  ( 8.601, 4.966, 0.033),
  ( 9.377, 6.271, 0.220),
  (10.287, 5.917, 1.394),
  (10.617, 4.459, 1.120),
  ( 9.403, 3.919, 0.539)])
sites_cart_2p = flex.vec3_double([
  ( 8.737, 4.960, 0.436),
  ( 9.554, 6.172, 0.859),
  (10.975, 5.614, 0.795),
  (10.788, 4.167, 1.250),
  ( 9.396, 3.833, 0.982)])
sites_cart_a = flex.vec3_double([
  (-0.39261304551933057, -1.2111974846191393, -0.1918152103139639),
  (0.39219750675929338, -0.69245062624473341, -1.397143005372731),
  (0.74981053833774947, 0.71778140495030018, -0.93667092439227351),
  (-0.49160057744166064, 1.1302189390923427, -0.1625948805803917),
  (-1.2450130796799763, -0.099026532456832558, -0.017936067449894347)])
sites_cart_b = flex.vec3_double([
  (0.47201858938285846, -0.9732520102518486, 0.33234891424712004),
  (0.83025465586861957, -0.74430566630400175, -1.1363551031011303),
  (-0.52892729188995369, -0.37071088386699969, -1.7209296245715191),
  (-1.155038969928043, 0.43588047818273268, -0.59496579629060031),
  (-0.28134783946407743, 0.20324959096386705, 0.53735380630632812)])

def run(args):
  assert args in [[], ["--verbose"]]
  if (len(args) != 0):
    cout = sys.stdout
  else:
    cout = null_out()
  edge_list_bonds = [(0,1),(0,4),(1,2),(2,3),(3,4)]
  bond_list = [
    (("C1*", "C2*"), 1.529),
    (("C1*", "O4*"), 1.412),
    (("C2*", "C3*"), 1.526),
    (("C3*", "C4*"), 1.520),
    (("C4*", "O4*"), 1.449)]
  angle_list = [
    (("C1*", "C2*", "C3*"), 101.3),
    (("C2*", "C3*", "C4*"), 102.3),
    (("C3*", "C4*", "O4*"), 104.2),
    (("C4*", "O4*", "C1*"), 110.0)]
  sites_cart, geo_manager = cctbx.geometry_restraints.manager \
    .construct_non_crystallographic_conserving_bonds_and_angles(
      sites_cart=sites_cart_3p,
      edge_list_bonds=edge_list_bonds,
      edge_list_angles=[])
  for bond_atom_names,distance_ideal in bond_list:
    i,j = [atom_names.index(atom_name) for atom_name in bond_atom_names]
    bond_params = geo_manager.bond_params_table[i][j]
    assert approx_equal(bond_params.distance_ideal, distance_ideal, eps=1.e-2)
    bond_params.distance_ideal = distance_ideal
    bond_params.weight = 1/0.02**2
  assert geo_manager.angle_proxies is None
  geo_manager.angle_proxies = cctbx.geometry_restraints.shared_angle_proxy()
  for angle_atom_names,angle_ideal in angle_list:
    i_seqs = [atom_names.index(atom_name) for atom_name in angle_atom_names]
    geo_manager.angle_proxies.append(cctbx.geometry_restraints.angle_proxy(
      i_seqs=i_seqs,
      angle_ideal=angle_ideal,
      weight=1/3**2))
  geo_manager.show_sorted(
    site_labels=atom_names, sites_cart=sites_cart, f=cout)
  def lbfgs(sites_cart):
    for i_lbfgs_restart in range(3):
      minimized = cctbx.geometry_restraints.lbfgs.lbfgs(
        sites_cart=sites_cart,
        geometry_restraints_manager=geo_manager)
      assert is_below_limit(value=minimized.final_target_value, limit=1e-10)
    return minimized
  lbfgs(sites_cart=sites_cart_3p)
  lbfgs(sites_cart=sites_cart_2p)
  conformer_counts = [0] * 4
  sites_cart = sites_cart.deep_copy()
  mt = flex.mersenne_twister(seed=0)
  for i_trial in range(20):
    while True:
      for i in range(sites_cart.size()):
        sites_cart[i] = mt.random_double_point_on_sphere()
      try:
        lbfgs(sites_cart=sites_cart)
      except RuntimeError as e:
        if (not str(e).startswith(
              "Bond distance > max_reasonable_bond_distance: ")):
          raise
      else:
        break
    rmsd_list = flex.double()
    for reference_sites in [
          sites_cart_3p,
          sites_cart_2p,
          sites_cart_a,
          sites_cart_b]:
      sup = scitbx.math.superpose.least_squares_fit(
        reference_sites=reference_sites,
        other_sites=sites_cart)
      rmsd = reference_sites.rms_difference(sup.other_sites_best_fit())
      rmsd_list.append(rmsd)
    oline = " ".join(["%.3f" % rmsd for rmsd in rmsd_list])
    print(oline, file=cout)
    assert is_below_limit(min(rmsd_list), 1e-3)
    conformer_counts[flex.min_index(rmsd_list)] += 1
  print("conformer_counts:", conformer_counts)
  #
  if (libtbx.env.has_module("iotbx")):
    import iotbx.pdb.hierarchy
    hierarchy = iotbx.pdb.hierarchy.root()
    model = iotbx.pdb.hierarchy.model(id="")
    chain = iotbx.pdb.hierarchy.chain(id="A")
    model.append_chain(chain)
    hierarchy.append_model(model)
    #
    sites_cart_pentagon = pentagon_sites_cart()
    for i_stack,sites_cart in enumerate([
          sites_cart_3p,
          sites_cart_2p,
          sites_cart_a,
          sites_cart_b]):
      atom_group = iotbx.pdb.hierarchy.atom_group(resname="  U", altloc="")
      sup = scitbx.math.superpose.least_squares_fit(
        reference_sites=sites_cart_pentagon,
        other_sites=sites_cart)
      sites_cart_out = sup.other_sites_best_fit()
      for site_label,site_cart in zip(atom_names, sites_cart_out):
        atom = iotbx.pdb.hierarchy.atom()
        atom.name = " %-3s" % site_label
        atom.xyz = matrix.col(site_cart) + matrix.col((0,0,i_stack*1.5))
        atom.occ = 1
        atom.b = 20
        atom.element = " " + site_label[0]
        atom_group.append_atom(atom)
      residue_group = iotbx.pdb.hierarchy.residue_group(
        resseq="%4d" % (i_stack+1), icode=" ")
      residue_group.append_atom_group(atom_group)
      chain.append_residue_group(residue_group)
    hierarchy.atoms().reset_serial()
    pdb_str = hierarchy.as_pdb_string(append_end=True)
    file_name = "puckers.pdb"
    print("Writing file:", file_name)
    open(file_name, "w").write("""\
REMARK random_puckers.py
REMARK 1 = 3'
REMARK 2 = 2'
REMARK 3 = A
REMARK 4 = B
""" + pdb_str)
  #
  print("OK")

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/examples/reduced_cell_two_folds.py
"""
Enumeration of the 81 2-fold symmetry operations possible for reduced cells.
Show the matrix elements and the axis directions in direct space and
reciprocal space.
"""
from __future__ import absolute_import, division, print_function

from cctbx import sgtbx
from cctbx.array_family import flex

def run():
  for elements in flex.nested_loop([-1]*9,[1+1]*9):
    r = sgtbx.rot_mx(elements)
    if (r.determinant() != 1): continue
    if (not r.multiply(r).is_unit_mx()): continue
    if (r.is_unit_mx()): continue
    print(elements, r.info().ev(), r.transpose().info().ev())
  print("OK")

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/site_symmetry_constraints.py
from __future__ import absolute_import, division, print_function
from cctbx import crystal
from cctbx.array_family import flex

def run():
  #
  # Initialization of a crystal symmetry.
  #
  crystal_symmetry = crystal.symmetry(
    unit_cell=(12,12,15,90,90,120),
    space_group_symbol="P 6")
  crystal_symmetry.show_summary()

  #
  # Definition of tolerance for determination of special positions.
  # min_distance_sym_equiv is the minimum distance between
  # symmetry-equivalent sites. If the distance is smaller than
  # min_distance_sym_equiv, the site is moved to the exact
  # location of the closest special position.
  #
  special_position_settings = crystal_symmetry.special_position_settings(
    min_distance_sym_equiv=0.5)

  #
  # Computation of the site symmetry for a site located
  # (almost) on 3-fold axis.
  #
  site_symmetry = special_position_settings.site_symmetry(site=(0.33,0.67,0))
  print("special position operator:", site_symmetry.special_op())
  print("exact location of special position:", site_symmetry.exact_site())

  #
  # The site_symmetry object caches the site constraints, which
  # are generated on demand when the site_constraints() method
  # is called the first time.
  #
  site_constraints = site_symmetry.site_constraints()

  #
  # Number of independent coordinates.
  #
  n_indep = site_constraints.n_independent_params()
  print("n_indep:", n_indep)

  #
  # For refinement we need only the independent parameters.
  #
  site_indep = site_constraints.independent_params(
    all_params=site_symmetry.exact_site())
  assert len(site_indep) == n_indep

  #
  # During refinement the site is shifted.
  #
  site_indep_shifted = list(site_indep) # copy site_indep
  site_indep_shifted[0] += 0.1

  #
  # "Expand" the independent parameters modified by the refinement.
  # site_shifted is certain to move only along the 3-fold axis.
  #
  site_shifted = site_constraints.all_params(
    independent_params=site_indep_shifted)
  print("site_shifted:", site_shifted)

  #
  # During refinement gradients are calculated.
  # These calculations can be performed without considering the
  # site symmetry, which simplifies the algorithms. The full set
  # of gradients can easily be transformed to the smaller set of
  # gradients w.r.t. the independent parameters.
  #
  independent_gradients = site_constraints.independent_gradients(
    all_gradients=flex.double([-0.01, 0.03, 0.02]))
  print("independent_gradients:", independent_gradients)

  #
  # Refinement with second derivatives (curvatures) is supported
  # in a similar way.
  # all_curvatures is the upper triangle of the symmetric 3x3 matrix
  # of second derivatives, i.e. an array with 3*(3+1)/2 elements.
  # independent_curvatures is the upper triangle of the constraint
  # curvature matrix with n_indep*(n_indep+1)/2 values.
  #
  independent_curvatures = site_constraints.independent_curvatures(
    all_curvatures=flex.double([-1, 2, -3, 4, -5, 6]))
  print("independent_curvatures:", independent_curvatures)

  #
  # See also the comprehensive unit test exercising the
  # site_constraints class:
  #   cctbx/regression/tst_sgtbx_site_constraints.py
  #

  print("OK")

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/site_symmetry_table.py
from __future__ import absolute_import, division, print_function
from cctbx import sgtbx
from cctbx import uctbx

def demo():
  #
  # define unit cell parameters and a compatible space group
  #
  unit_cell = uctbx.unit_cell((10,10,15,90,90,120))
  space_group = sgtbx.space_group("-P 3 2") # Hall symbol
  #
  # define a site_symmetry_table with a few sites
  #
  site_symmetry_table = sgtbx.site_symmetry_table()
  site_symmetry_table.reserve(3) # optional: optimizes memory allocation
  for site_frac in [(0,0,0), (0.5,0.5,0.5), (0.25,0.66,0.0), (0.75,0.66,0.0)]:
    site_symmetry = sgtbx.site_symmetry(
      unit_cell=unit_cell,
      space_group=space_group,
      original_site=site_frac,
      min_distance_sym_equiv=0.5,
      assert_min_distance_sym_equiv=True)
    site_symmetry_table.process(site_symmetry_ops=site_symmetry)
  #
  # there are two sets of indices:
  #   1. "i_seq" = index into the sequence of sites as passed to
  #      site_symmetry.process().
  #   2. The indices of the tabulated special_position_ops instances.
  # site_symmetry_table.indices() establishes the relation between
  # these two sets of indices:
  #   site_symmetry_table.indices().size() = number of sites processed
  #   site_symmetry_table.indices()[i_seq] = index of special_position_ops
  #     instance in the internal site_symmetry_table.table()
  assert list(site_symmetry_table.indices()) == [1, 2, 0, 0]
  #
  # table entry 0 is always the general position
  #
  assert str(site_symmetry_table.table()[0].special_op()) == "x,y,z"
  #
  # all other table entries are special positions
  #
  assert str(site_symmetry_table.table()[1].special_op()) == "0,0,0"
  assert str(site_symmetry_table.table()[2].special_op()) == "1/2,1/2,1/2"
  #
  # To obtain the special_position_ops for a certain i_seq:
  #
  for i_seq in [0,1,2]:
    print(site_symmetry_table.get(i_seq=i_seq).special_op())
  #
  # Most of the time the (many) general positions don't need a
  # special treatment, and it is much more convenient to loop
  # only over the (few) special positions. For example, to
  # define symmetry constraints for anisotropic displacement
  # parameters:
  #
  for i_seq in site_symmetry_table.special_position_indices():
    site_constraints = site_symmetry_table.get(i_seq=i_seq).site_constraints()
    adp_constraints = site_symmetry_table.get(i_seq=i_seq).adp_constraints()
  #
  # See also:
  #   cctbx/examples/site_symmetry_constraints.py
  #   cctbx/examples/adp_symmetry_constraints.py
  #   C++ reference documentation for
  #     cctbx::sgtbx::site_symmetry_ops
  #     cctbx::sgtbx::site_symmetry
  #
  print("OK")

if (__name__ == "__main__"):
  demo()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/space_group_matrices.py
from __future__ import absolute_import, division, print_function
from cctbx import sgtbx
import sys

def run(args):
  for symbol in args:
    space_group_info = sgtbx.space_group_info(symbol=symbol)
    space_group_info.show_summary()
    for m in space_group_info.group():
      rt = m.as_rational().as_float()
      print(" ", list(rt.r) + list(rt.t))
    print()

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/examples/space_subgroups.py
"""
Rough script, generating space-group subgroups including super cells.
Shows the Universal Hermann-Mauguin Symbol (Zwart et al., 2008) for all
subgroups.

LIMITATION of the current implementation: settings with
fractional rotation matrix elements cannot be handled.

References:
  Grosse-Kunstleve (1999). Acta Cryst. A55, 383-395.
  Zwart et al. (2008). Acta Cryst. D64, 99-107. Section 2.1
"""
from __future__ import absolute_import, division, print_function

from cctbx import sgtbx
from libtbx.utils import Usage
from libtbx.str_utils import show_sorted_by_counts
from libtbx import dict_with_default_0
import sys
from six.moves import range

def loop_over_super_cells(max_index, all_subgroups, subgroup):
  assert subgroup.n_ltr() == 1
  for ia in range(1,max_index+1):
    for ib in range(1,max_index+1):
      for ic in range(1,max_index+1):
        cb_op = sgtbx.change_of_basis_op("x/%d,y/%d,z/%d" % (ia,ib,ic))
        try:
          scsubgroup = subgroup.change_basis(cb_op=cb_op)
        except RuntimeError as e:
          if (str(e).endswith(
                "Unsuitable value for rational rotation matrix.")):
            all_subgroups["incompatible_rotation_denominator"] += 1
          elif (str(e).endswith(
                "Unsuitable value for rational translation vector.")):
            all_subgroups["incompatible_translation_denominator"] += 1
          else:
            raise RuntimeError
        else:
          def remove_lattice_translations(g):
            result = sgtbx.space_group(
              hall_symbol="P1", t_den=subgroup.t_den())
            for i_inv in range(g.f_inv()):
              for i_smx in range(g.n_smx()):
                result.expand_smx(g(0, i_inv, i_smx))
            return result
          subsubgroup = remove_lattice_translations(scsubgroup)
          uhm = sgtbx.space_group_type(group=subsubgroup) \
            .universal_hermann_mauguin_symbol()
          all_subgroups[uhm] += 1

def run(args):
  if (len(args) != 2):
    raise Usage("""\
cctbx.python space_subgroups.py max_index space_group_symbol
  Example: cctbx.python space_subgroups.py 2 P41212""")
  #
  max_index = int(args[0])
  print("max_index:", max_index)
  assert max_index >= 1
  print()
  space_group_t_den = 144
  sginfo = sgtbx.space_group_info(
    symbol=args[1], space_group_t_den=space_group_t_den)
  sginfo.show_summary()
  print()
  cb_op_to_p = sginfo.change_of_basis_op_to_primitive_setting()
  sginfo_p = sginfo.change_basis(cb_op=cb_op_to_p)
  if (sginfo_p.group() != sginfo.group()):
    print("Primitive setting:")
    sginfo_p.show_summary()
    print()
  #
  all_subgroups = dict_with_default_0()
  sg_p = sginfo_p.group()
  sg_p_a = sg_p.build_derived_acentric_group()
  if (sg_p.is_centric()):
    inv_mx = sg_p(0, 1, 0).t()
  else:
    inv_mx = None
  for symx1 in sg_p_a:
    subgr1 = sgtbx.space_group(hall_symbol="P1", t_den=space_group_t_den)
    subgr1.expand_smx(symx1)
    for symx2 in sg_p_a:
      subgr2 = sgtbx.space_group(subgr1)
      subgr2.expand_smx(symx2)
      loop_over_super_cells(
        max_index=max_index, all_subgroups=all_subgroups, subgroup=subgr2)
      if (inv_mx is not None):
        subgr3 = sgtbx.space_group(subgr2)
        subgr3.expand_inv(inv_mx)
        loop_over_super_cells(
          max_index=max_index, all_subgroups=all_subgroups, subgroup=subgr3)
  #
  show_sorted_by_counts(label_count_pairs=list(all_subgroups.items()))

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/examples/steve_collins.py
from __future__ import absolute_import, division, print_function
from six.moves import zip
def examples():
  # Generate space groups (in matrix/vector form) based on spacegroup number
  # (names are *not* a pain)
  # See also: http://cctbx.sourceforge.net/current/c_plus_plus/classcctbx_1_1sgtbx_1_1space__group__symbols.html#_details
  from cctbx import sgtbx
  for s in sgtbx.space_group_info(symbol="I41/amd").group():
    print(s) # in "xyz" notation
    print(s.r().as_rational().mathematica_form(), \
          s.t().as_rational().transpose().mathematica_form())
  print()

  # now with a space group number
  space_group_info = sgtbx.space_group_info(number=123)
  space_group_info.show_summary()
  print()

  # Generate conditions for allowed reflections etc
  from cctbx import crystal
  from cctbx import miller
  crystal_symmetry = crystal.symmetry(
    unit_cell=(10,10,13,90,90,90),
    space_group_info=space_group_info)
  miller_set = miller.build_set(
    crystal_symmetry=crystal_symmetry,
    anomalous_flag=False,
    d_min=4)
  # change the space group in order to get a few systematic absences
  miller_set = miller_set.customized_copy(
    space_group_info=sgtbx.space_group_info(symbol="I41/amd"))
  sys_absent_flags = miller_set.sys_absent_flags()
  for h,f in zip(sys_absent_flags.indices(), sys_absent_flags.data()):
    print(h, f)
  print()
  # try also (from the command line): libtbx.help cctbx.miller

  # Generate point group of space group in matrix form
  point_group = miller_set.space_group().build_derived_point_group()
  point_group_info = sgtbx.space_group_info(group=point_group)
  point_group_info.show_summary()
  for s in point_group:
    print(s)
  print()

  # Generate point-group matrices for given coordinate
  # first we have to define what we consider as special position
  special_position_settings = crystal.special_position_settings(
    crystal_symmetry=miller_set,
    min_distance_sym_equiv=0.5) # <<<<< here
  site_symmetry = special_position_settings.site_symmetry(
    site=(0,0.48,0))
  print("special position operator:", site_symmetry.special_op_simplified())
  print("distance to original site:", site_symmetry.distance_moved())
  print("point group of the special position:")
  for s in site_symmetry.matrices():
    print(s)
  print()
  # See also: http://cci.lbl.gov/~rwgk/my_papers/iucr/au0265_reprint.pdf

  # Access database for form factors
  from cctbx.eltbx import xray_scattering
  si_form_factor = xray_scattering.it1992("Si")
  gaussians = si_form_factor.fetch()
  for stol in [0, 0.01, 0.02, 0.5]:
    print(stol, gaussians.at_stol(stol))
  print()

  # anomalous scattering factors: Sasaki tables
  from cctbx.eltbx import sasaki
  si_table = sasaki.table("Si")
  for wavelength in [0.5, 0.8, 0.9]:
    data = si_table.at_angstrom(wavelength)
    print(wavelength, data.fp(), data.fdp())
  print()

  # anomalous scattering factors: Henke tables
  from cctbx.eltbx import henke
  si_table = henke.table("Si")
  for wavelength in [0.5, 0.8, 0.9]:
    data = si_table.at_angstrom(wavelength)
    print(wavelength, data.fp(), data.fdp())
  print()
  print("OK")

if (__name__ == "__main__"):
  examples()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/structure_factor_calculus/__init__.py


 *******************************************************************************


 *******************************************************************************
cctbx/examples/structure_factor_calculus/site_derivatives.py
from __future__ import absolute_import, division, print_function
from scitbx import matrix
from scitbx.array_family import flex
from libtbx.test_utils import approx_equal
import math
from six.moves import cStringIO as StringIO
import sys
from six.moves import range

flex.set_random_seed(0)

class cos_alpha:

  def __init__(self, site, ops, hkl):
    self.site = site
    self.ops = ops
    self.hkl = hkl

  def f(self):
    result = 0
    for op in self.ops:
      op_site = op * self.site
      result += math.cos(self.hkl.dot(op_site))
    return result

  def d_site(self):
    result = flex.double(3, 0)
    for op in self.ops:
      op_site = op * self.site
      hkl_op_site = self.hkl.dot(op_site)
      d_op_site = -math.sin(hkl_op_site) * self.hkl
      gtmx = op.transpose()
      d_site = gtmx * d_op_site.transpose()
      result += flex.double(d_site)
    return result

  def d2_site(self):
    result = flex.double(3*3, 0)
    d_alpha_d_site = self.hkl.outer_product()
    for op in self.ops:
      op_site = op * self.site
      hkl_op_site = self.hkl.dot(op_site)
      d2_op_site = -math.cos(hkl_op_site) * d_alpha_d_site
      result += flex.double(op.transpose() * d2_op_site * op)
    return result

def d_cos_alpha_d_site_finite(site, ops, hkl, eps=1.e-6):
  result = flex.double()
  site_eps = list(site)
  for ip in range(3):
    vs = []
    for signed_eps in [eps, -eps]:
      site_eps[ip] = site[ip] + signed_eps
      ca = cos_alpha(site=matrix.col(site_eps), ops=ops, hkl=hkl)
      vs.append(ca.f())
    site_eps[ip] = site[ip]
    result.append((vs[0]-vs[1])/(2*eps))
  return result

def d2_cos_alpha_d_site_finite(site, ops, hkl, eps=1.e-6):
  result = flex.double()
  site_eps = list(site)
  for ip in range(3):
    vs = []
    for signed_eps in [eps, -eps]:
      site_eps[ip] = site[ip] + signed_eps
      ca = cos_alpha(site=matrix.col(site_eps), ops=ops, hkl=hkl)
      vs.append(ca.d_site())
    site_eps[ip] = site[ip]
    result.extend((vs[0]-vs[1])/(2*eps))
  return result

def exercise(args):
  verbose =  "--verbose" in args
  if (not verbose):
    out = StringIO()
  else:
    out = sys.stdout
  for i_trial in range(100):
    ops = []
    for i in range(3):
      ops.append(matrix.sqr(flex.random_double(size=9, factor=4)-2))
    site = matrix.col(flex.random_double(size=3, factor=4)-2)
    hkl = matrix.row(flex.random_double(size=3, factor=4)-2)
    ca = cos_alpha(site=site, ops=ops, hkl=hkl)
    grads_fin = d_cos_alpha_d_site_finite(site=site, ops=ops, hkl=hkl)
    print("grads_fin:", list(grads_fin), file=out)
    grads_ana = ca.d_site()
    print("grads_ana:", list(grads_ana), file=out)
    assert approx_equal(grads_ana, grads_fin)
    curvs_fin = d2_cos_alpha_d_site_finite(site=site, ops=ops, hkl=hkl)
    print("curvs_fin:", list(curvs_fin), file=out)
    curvs_ana = ca.d2_site()
    print("curvs_ana:", list(curvs_ana), file=out)
    assert approx_equal(curvs_ana, curvs_fin)
    print(file=out)
  print("OK")

if (__name__ == "__main__"):
  exercise(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/examples/structure_factor_calculus/sites_derivatives.py
from __future__ import absolute_import, division, print_function
from scitbx import matrix
from scitbx.array_family import flex
from libtbx.test_utils import approx_equal
import math
from six.moves import cStringIO as StringIO
import sys
from six.moves import range

flex.set_random_seed(0)

class cos_alpha:

  def __init__(self, sites, ops, hkl):
    self.sites = sites
    self.ops = ops
    self.hkl = hkl

  def f(self):
    result = 0
    for site in self.sites:
      for op in self.ops:
        op_site = op * site
        result += math.cos(self.hkl.dot(op_site))
    return result

  def d_sites(self):
    result = flex.double()
    for site in self.sites:
      d_site = flex.double(3, 0)
      for op in self.ops:
        op_site = op * site
        hkl_op_site = self.hkl.dot(op_site)
        d_op_site = -math.sin(hkl_op_site) * self.hkl
        gtmx = op.transpose()
        d_site += flex.double(gtmx * d_op_site.transpose())
      result.extend(d_site)
    return result

  def d2_sites(self):
    n = len(self.sites) * 3
    result = flex.double(flex.grid(n,n), 0)
    d_alpha_d_site = self.hkl.outer_product()
    for js,site in enumerate(self.sites):
      d2_site = flex.double(flex.grid(3,3), 0)
      for op in self.ops:
        op_site = op * site
        hkl_op_site = self.hkl.dot(op_site)
        d2_op_site = -math.cos(hkl_op_site) * d_alpha_d_site
        d2_site += flex.double(op.transpose() * d2_op_site * op)
      result.matrix_paste_block_in_place(d2_site, js*3, js*3)
    return result

def d_cos_alpha_d_sites_finite(sites, ops, hkl, eps=1.e-8):
  result = flex.double()
  sites_eps = list(sites)
  for js,site in enumerate(sites):
    site_eps = list(site)
    for jp in range(3):
      vs = []
      for signed_eps in [eps, -eps]:
        site_eps[jp] = site[jp] + signed_eps
        sites_eps[js] = matrix.col(site_eps)
        ca = cos_alpha(sites=sites_eps, ops=ops, hkl=hkl)
        vs.append(ca.f())
      result.append((vs[0]-vs[1])/(2*eps))
    sites_eps[js] = sites[js]
  return result

def d2_cos_alpha_d_sites_finite(sites, ops, hkl, eps=1.e-8):
  result = flex.double()
  sites_eps = list(sites)
  for js,site in enumerate(sites):
    site_eps = list(site)
    for jp in range(3):
      vs = []
      for signed_eps in [eps, -eps]:
        site_eps[jp] = site[jp] + signed_eps
        sites_eps[js] = matrix.col(site_eps)
        ca = cos_alpha(sites=sites_eps, ops=ops, hkl=hkl)
        vs.append(ca.d_sites())
      result.extend((vs[0]-vs[1])/(2*eps))
    sites_eps[js] = sites[js]
  return result

def exercise(args):
  verbose =  "--verbose" in args
  if (not verbose):
    out = StringIO()
  else:
    out = sys.stdout
  for i_trial in range(100):
    ops = []
    for i in range(3):
      ops.append(matrix.sqr(flex.random_double(size=9, factor=4)-2))
    sites = []
    for i in range(2):
      sites.append(matrix.col(flex.random_double(size=3, factor=4)-2))
    hkl = matrix.row(flex.random_double(size=3, factor=4)-2)
    ca = cos_alpha(sites=sites, ops=ops, hkl=hkl)
    grads_fin = d_cos_alpha_d_sites_finite(sites=sites, ops=ops, hkl=hkl)
    print("grads_fin:", list(grads_fin), file=out)
    grads_ana = ca.d_sites()
    print("grads_ana:", list(grads_ana), file=out)
    assert approx_equal(grads_ana, grads_fin)
    curvs_fin = d2_cos_alpha_d_sites_finite(sites=sites, ops=ops, hkl=hkl)
    print("curvs_fin:", list(curvs_fin), file=out)
    curvs_ana = ca.d2_sites()
    print("curvs_ana:", list(curvs_ana), file=out)
    assert approx_equal(curvs_ana, curvs_fin, 1.e-5)
    print(file=out)
  print("OK")

if (__name__ == "__main__"):
  exercise(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/examples/structure_factor_calculus/sites_least_squares_derivatives.py
from __future__ import absolute_import, division, print_function
from cctbx.examples.exp_i_alpha_derivatives import least_squares
from scitbx import matrix
from scitbx.array_family import flex
from libtbx.test_utils import approx_equal
import cmath
from six.moves import cStringIO as StringIO
import sys
from six.moves import range
from six.moves import zip

flex.set_random_seed(0)

class exp_i_hx:

  def __init__(self, sites, ops, hkl):
    self.sites = sites
    self.ops = ops
    self.hkl = hkl

  def f(self):
    result = 0
    for site in self.sites:
      for op in self.ops:
        op_site = op * site
        result += cmath.exp(1j*self.hkl.dot(op_site))
    return result

  def d_sites(self):
    result = []
    for site in self.sites:
      d_site = flex.complex_double(3, 0)
      for op in self.ops:
        op_site = op * site
        hkl_op_site = self.hkl.dot(op_site)
        d_op_site = cmath.exp(1j*self.hkl.dot(op_site)) * 1j * self.hkl
        gtmx = op.transpose()
        d_site += flex.complex_double(gtmx * d_op_site.transpose())
      result.append(d_site)
    return result

  def d2_sites(self):
    hkl_outer = self.hkl.outer_product()
    for js,site in enumerate(self.sites):
      d2_site = flex.complex_double(flex.grid(3,3), 0)
      for op in self.ops:
        op_site = op * site
        hkl_op_site = self.hkl.dot(op_site)
        d2_op_site = cmath.exp(1j*self.hkl.dot(op_site)) * (-1) * hkl_outer
        d2_site += flex.complex_double(op.transpose() * d2_op_site * op)
      yield d2_site

  def d_target_d_sites(self, target):
    da, db = target.da(), target.db()
    return flex.double([[da * d.real + db * d.imag
      for d in d_site]
        for d_site in self.d_sites()])

  def d2_target_d_sites(self, target):
    result = []
    da, db = target.da(), target.db()
    daa, dbb, dab = target.daa(), target.dbb(), target.dab()
    ds = self.d_sites()
    d2s = iter(self.d2_sites())
    for di0,d2i in zip(ds, d2s):
      d2ij_iter = iter(d2i)
      for di in di0:
        row = []
        for dj0 in ds:
          for dj in dj0:
            sum = daa * di.real * dj.real \
                + dbb * di.imag * dj.imag \
                + dab * (di.real * dj.imag + di.imag * dj.real)
            if (di0 is dj0):
              d2ij = next(d2ij_iter)
              sum += da * d2ij.real + db * d2ij.imag
            row.append(sum)
        result.append(row)
    return flex.double(result)

def d_exp_i_hx_d_sites_finite(sites, ops, hkl, obs, eps=1.e-8):
  result = flex.double()
  sites_eps = list(sites)
  for js,site in enumerate(sites):
    site_eps = list(site)
    for jp in range(3):
      vs = []
      for signed_eps in [eps, -eps]:
        site_eps[jp] = site[jp] + signed_eps
        sites_eps[js] = matrix.col(site_eps)
        sf = exp_i_hx(sites=sites_eps, ops=ops, hkl=hkl)
        tf = least_squares(obs=obs, calc=sf.f())
        vs.append(tf.f())
      result.append((vs[0]-vs[1])/(2*eps))
    sites_eps[js] = sites[js]
  return result

def d2_exp_i_hx_d_sites_finite(sites, ops, hkl, obs, eps=1.e-8):
  result = flex.double()
  sites_eps = list(sites)
  for js,site in enumerate(sites):
    site_eps = list(site)
    for jp in range(3):
      vs = []
      for signed_eps in [eps, -eps]:
        site_eps[jp] = site[jp] + signed_eps
        sites_eps[js] = matrix.col(site_eps)
        sf = exp_i_hx(sites=sites_eps, ops=ops, hkl=hkl)
        tf = least_squares(obs=obs, calc=sf.f())
        vs.append(sf.d_target_d_sites(target=tf))
      result.extend(((vs[0]-vs[1])/(2*eps)).as_1d())
    sites_eps[js] = sites[js]
  return result

def compare_derivatives(ana, fin):
  s = max(1, flex.max(flex.abs(ana)))
  assert approx_equal(ana/s, fin/s)

def exercise(args):
  verbose =  "--verbose" in args
  if (not verbose):
    out = StringIO()
  else:
    out = sys.stdout
  for i_trial in range(10):
    for n_sites in range(2,5+1):
      ops = []
      for i in range(3):
        ops.append(matrix.sqr(flex.random_double(size=9, factor=2)-1))
      sites = []
      for i in range(n_sites):
        sites.append(matrix.col(flex.random_double(size=3, factor=4)-2))
      hkl = matrix.row(flex.random_double(size=3, factor=4)-2)
      sf = exp_i_hx(sites=sites, ops=ops, hkl=hkl)
      for obs_factor in [1, 1.1]:
        obs = abs(sf.f()) * obs_factor
        grads_fin = d_exp_i_hx_d_sites_finite(
          sites=sites, ops=ops, obs=obs, hkl=hkl)
        print("grads_fin:", list(grads_fin), file=out)
        tf = least_squares(obs=obs, calc=sf.f())
        grads_ana = sf.d_target_d_sites(target=tf)
        print("grads_ana:", list(grads_ana), file=out)
        compare_derivatives(grads_ana, grads_fin)
        curvs_fin = d2_exp_i_hx_d_sites_finite(
          sites=sites, ops=ops, obs=obs, hkl=hkl)
        print("curvs_fin:", list(curvs_fin), file=out)
        curvs_ana = sf.d2_target_d_sites(target=tf)
        print("curvs_ana:", list(curvs_ana), file=out)
        compare_derivatives(curvs_ana, curvs_fin)
        print(file=out)
  print("OK")

if (__name__ == "__main__"):
  exercise(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/examples/structure_factor_calculus/u_star_derivatives.py
from __future__ import absolute_import, division, print_function
from scitbx import matrix
from scitbx.array_family import flex
from scitbx.math import tensor_rank_2_gradient_transform_matrix
from libtbx.test_utils import approx_equal
import math
from six.moves import cStringIO as StringIO
import sys
from six.moves import range

flex.set_random_seed(0)

mtps = -2 * math.pi**2

class debye_waller:

  def __init__(self, u, ops, hkl):
    self.u = u
    self.ops = ops
    self.hkl = hkl

  def f(self):
    result = 0
    for op in self.ops:
      op_u = (op*matrix.sym(sym_mat3=self.u)*op.transpose()).as_sym_mat3()
      huh = (matrix.row(self.hkl) \
          * matrix.sym(sym_mat3=op_u)).dot(matrix.col(self.hkl))
      result += math.exp(mtps * huh)
    return result

  def d_u(self):
    result = flex.double(6, 0)
    h,k,l = self.hkl
    d_exp_huh_d_u = matrix.col([h**2, k**2, l**2, 2*h*k, 2*h*l, 2*k*l])
    for op in self.ops:
      op_u = (op*matrix.sym(sym_mat3=self.u)*op.transpose()).as_sym_mat3()
      huh = (matrix.row(self.hkl) \
          * matrix.sym(sym_mat3=op_u)).dot(matrix.col(self.hkl))
      d_op_u = math.exp(mtps * huh) * mtps * d_exp_huh_d_u
      gtmx = tensor_rank_2_gradient_transform_matrix(op)
      d_u = gtmx.matrix_multiply(flex.double(d_op_u))
      result += d_u
    return result

  def d2_u(self):
    result = flex.double(flex.grid(6,6), 0)
    h,k,l = self.hkl
    d_exp_huh_d_u = flex.double([h**2, k**2, l**2, 2*h*k, 2*h*l, 2*k*l])
    d2_exp_huh_d_uu = d_exp_huh_d_u.matrix_outer_product(d_exp_huh_d_u)
    for op in self.ops:
      op_u = (op*matrix.sym(sym_mat3=self.u)*op.transpose()).as_sym_mat3()
      huh = (matrix.row(self.hkl) \
          * matrix.sym(sym_mat3=op_u)).dot(matrix.col(self.hkl))
      d2_op_u = math.exp(mtps * huh) * mtps**2 * d2_exp_huh_d_uu
      gtmx = tensor_rank_2_gradient_transform_matrix(op)
      d2_u = gtmx.matrix_multiply(d2_op_u).matrix_multiply(
        gtmx.matrix_transpose())
      result += d2_u
    return result

def d_debye_waller_d_u_finite(u, ops, hkl, eps=1.e-8):
  result = flex.double()
  u_eps = list(u)
  for ip in range(6):
    vs = []
    for signed_eps in [eps, -eps]:
      u_eps[ip] = u[ip] + signed_eps
      a = debye_waller(u=matrix.col(u_eps), ops=ops, hkl=hkl)
      vs.append(a.f())
    u_eps[ip] = u[ip]
    result.append((vs[0]-vs[1])/(2*eps))
  return result

def d2_debye_waller_d_u_finite(u, ops, hkl, eps=1.e-8):
  result = flex.double()
  u_eps = list(u)
  for ip in range(6):
    vs = []
    for signed_eps in [eps, -eps]:
      u_eps[ip] = u[ip] + signed_eps
      a = debye_waller(u=matrix.col(u_eps), ops=ops, hkl=hkl)
      vs.append(a.d_u())
    u_eps[ip] = u[ip]
    result.extend((vs[0]-vs[1])/(2*eps))
  return result

def compare_derivatives(ana, fin):
  s = max(1, flex.max(flex.abs(ana)))
  assert approx_equal(ana/s, fin/s)

def exercise(args):
  verbose =  "--verbose" in args
  if (not verbose):
    out = StringIO()
  else:
    out = sys.stdout
  for i_trial in range(100):
    ops = []
    for i in range(3):
      ops.append(matrix.sqr(flex.random_double(size=9, factor=4)-2))
    u = matrix.col((flex.random_double(size=6, factor=2)-1)*1.e-3)
    hkl = matrix.row(flex.random_double(size=3, factor=4)-2)
    dw = debye_waller(u=u, ops=ops, hkl=hkl)
    grads_fin = d_debye_waller_d_u_finite(u=u, ops=ops, hkl=hkl)
    print("grads_fin:", list(grads_fin), file=out)
    grads_ana = dw.d_u()
    print("grads_ana:", list(grads_ana), file=out)
    compare_derivatives(grads_ana, grads_fin)
    curvs_fin = d2_debye_waller_d_u_finite(u=u, ops=ops, hkl=hkl)
    print("curvs_fin:", list(curvs_fin), file=out)
    curvs_ana = dw.d2_u()
    print("curvs_ana:", list(curvs_ana), file=out)
    compare_derivatives(curvs_ana, curvs_fin)
    print(file=out)
  print("OK")

if (__name__ == "__main__"):
  exercise(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/examples/structure_factor_derivatives.py
from __future__ import absolute_import, division, print_function
from cctbx.examples import g_exp_i_alpha_derivatives
from scitbx import matrix
import math
from six.moves import zip

class parameters:

  def __init__(self, xyz, u, w, fp, fdp):
    self.xyz = tuple(xyz)
    self.u = u
    self.w = w
    self.fp = fp
    self.fdp = fdp

  def as_list(self):
    return list(self.xyz) + [self.u, self.w, self.fp, self.fdp]

  def as_g_alpha(self, hkl, d_star_sq):
    return g_exp_i_alpha_derivatives.parameters(
      g = self.w * math.exp(-2 * math.pi**2 * self.u * d_star_sq),
      ffp = 1 + self.fp,
      fdp = self.fdp,
      alpha = 2 * math.pi * matrix.col(self.xyz).dot(matrix.col(hkl)))

class gradients(parameters): pass

class curvatures:

  def __init__(self, uu, uw):
    self.uu = uu
    self.uw = uw

def pack_parameters(params):
  result = []
  for p in params:
    result.extend(p.as_list())
  return result

def pack_gradients(grads):
  return pack_parameters(grads)

class structure_factor:

  def __init__(self, hkl, d_star_sq, params):
    self.hkl = hkl
    self.d_star_sq = d_star_sq
    self.params = params

  def as_exp_i_sum(self):
    return g_exp_i_alpha_derivatives.g_exp_i_alpha_sum(
      params=[p.as_g_alpha(hkl=self.hkl, d_star_sq=self.d_star_sq)
        for p in self.params])

  def f(self):
    return self.as_exp_i_sum().f()

  def d_g_alpha_d_params(self):
    """Mathematica:
         alpha = 2 Pi {h,k,l}.{x,y,z}
         g = w Exp[-2 Pi^2 u dss]
         D[alpha,x]; D[alpha,y]; D[alpha,z]; D[g,u]; D[g,w]"
    """
    result = []
    c = -2 * math.pi**2 * self.d_star_sq
    d_xyz = 2 * math.pi * matrix.col(self.hkl)
    for p in self.params:
      e = math.exp(c * p.u)
      result.append(gradients(xyz=d_xyz, u=p.w*c*e, w=e, fp=1, fdp=1))
    return result

  def d2_g_alpha_d_params(self):
    """Mathematica:

         alpha = 2 Pi {h,k,l}.{x,y,z}
         g = w Exp[-2 Pi^2 u dss]
         D[alpha,x,x]; D[alpha,x,y]; D[alpha,x,z]; D[g,x,u]; D[g,x,w]"
         D[alpha,y,x]; D[alpha,y,y]; D[alpha,y,z]; D[g,y,u]; D[g,y,w]"
         D[alpha,z,x]; D[alpha,z,y]; D[alpha,z,z]; D[g,z,u]; D[g,z,w]"
         D[alpha,u,x]; D[alpha,u,y]; D[alpha,u,z]; D[g,u,u]; D[g,u,w]"
         D[alpha,w,x]; D[alpha,w,y]; D[alpha,w,z]; D[g,w,u]; D[g,w,w]"

    This curvature matrix is symmetric.
    All D[alpha, x|y|z, x|y|z|u|w] are 0.

       D[g,u,u] = (4 dss^2 Pi^4) w Exp[-2 Pi^2 u dss]
       D[g,u,w] = (-2 dss Pi^2)    Exp[-2 Pi^2 u dss]
       D[g,w,w] = 0
    """
    result = []
    c = -2 * math.pi**2 * self.d_star_sq
    for p in self.params:
      e = math.exp(c * p.u)
      result.append(curvatures(uu=c**2*p.w*e, uw=c*e))
    return result

  def d_target_d_params(self, target):
    result = []
    dts = self.as_exp_i_sum().d_target_d_params(target=target)
    ds = self.d_g_alpha_d_params()
    for dt,d in zip(dts, ds):
      result.append(gradients(
        xyz = dt.alpha * matrix.col(d.xyz),
        u = dt.g * d.u,
        w = dt.g * d.w,
        fp = dt.ffp,
        fdp = dt.fdp))
    return result

  def d2_target_d_params(self, target):
    """Combined application of chain rule and product rule.
       d_target_d_.. matrix:

         aa ag a' a"
         ga gg g' g"
         'a 'g '' '"
         "a "g "' ""

       Block in resulting matrix:

         xx xy xz xu xw x' x"
         yx yy yz yu yw y' y"
         zx zy zz zu zw z' z"
         ux uy uz uu uw '' '"
         wx wy wz wu ww "' ""
         'x 'y 'z 'u 'w '' '"
         "x "y "z "u "w "' ""
    """
    result = []
    exp_i_sum = self.as_exp_i_sum()
    dts = exp_i_sum.d_target_d_params(target=target)
    d2ti = iter(exp_i_sum.d2_target_d_params(target=target))
    ds = self.d_g_alpha_d_params()
    d2s = self.d2_g_alpha_d_params()
    idt2 = 0
    for dt,di,d2 in zip(dts, ds, d2s):
      # dx. dy. dz.
      d2ti0 = next(d2ti)
      for dxi in di.xyz:
        row = []; ra = row.append
        d2tij = iter(d2ti0)
        for dj in ds:
          d2t = next(d2tij)
          for dxj in dj.xyz:
            ra(d2t * dxi * dxj)
          d2t = next(d2tij)
          ra(d2t * dxi * dj.u)
          ra(d2t * dxi * dj.w)
          ra(next(d2tij) * dxi)
          ra(next(d2tij) * dxi)
        result.append(row)
      # d2u.
      row = []; ra = row.append
      d2ti0 = next(d2ti)
      d2tij = iter(d2ti0)
      for dj in ds:
        d2t = next(d2tij)
        for dxj in dj.xyz:
          ra(d2t * dxj * di.u)
        d2t = next(d2tij)
        ra(d2t * di.u * dj.u)
        if (di is dj): row[-1] += dt.g * d2.uu
        ra(d2t * di.u * dj.w)
        if (di is dj): row[-1] += dt.g * d2.uw
        ra(next(d2tij) * di.u)
        ra(next(d2tij) * di.u)
      result.append(row)
      # d2w.
      row = []; ra = row.append
      d2tij = iter(d2ti0)
      for dj in ds:
        d2t = next(d2tij)
        for dxj in dj.xyz:
          ra(d2t * dxj * di.w)
        d2t = next(d2tij)
        ra(d2t * di.w * dj.u)
        if (di is dj): row[-1] += dt.g * d2.uw
        ra(d2t * di.w * dj.w)
        ra(next(d2tij) * di.w)
        ra(next(d2tij) * di.w)
      result.append(row)
      # d2'. and d2"
      for ip in [0,1]:
        row = []; ra = row.append
        d2tij = iter(next(d2ti))
        for dj in ds:
          d2t = next(d2tij)
          for dxj in dj.xyz:
            ra(d2t * dxj)
          d2t = next(d2tij)
          ra(d2t * dj.u)
          ra(d2t * dj.w)
          ra(next(d2tij))
          ra(next(d2tij))
        result.append(row)
    return result


 *******************************************************************************


 *******************************************************************************
cctbx/examples/structure_factor_derivatives_2.py
from __future__ import absolute_import, division, print_function
from cctbx import xray
from cctbx.examples import g_exp_i_alpha_derivatives
from scitbx import matrix
from scitbx.array_family import flex
import math
from six.moves import zip

def scatterer_as_list(self):
  return list(self.site) + [self.u_iso, self.occupancy, self.fp, self.fdp]

def scatterer_from_list(l):
  return xray.scatterer(
    site=l[:3],
    u=l[3],
    occupancy=l[4],
    scattering_type="const",
    fp=l[5],
    fdp=l[6])

def scatterer_as_g_alpha(scatterer, hkl, d_star_sq):
  return g_exp_i_alpha_derivatives.parameters(
    g = scatterer.occupancy
        * math.exp(-2 * math.pi**2 * scatterer.u_iso * d_star_sq),
    ffp = 1 + scatterer.fp,
    fdp = scatterer.fdp,
    alpha = 2 * math.pi * matrix.col(scatterer.site).dot(matrix.col(hkl)))

class gradients:

  def __init__(self, site, u_iso, occupancy, fp, fdp):
    self.site = site
    self.u_iso = u_iso
    self.occupancy = occupancy
    self.fp = fp
    self.fdp = fdp

class curvatures:

  def __init__(self, uu, uw):
    self.uu = uu
    self.uw = uw

def pack_gradients(grads):
  result = []
  for g in grads:
    result.extend(scatterer_as_list(g))
  return result

class structure_factor:

  def __init__(self, xray_structure, hkl):
    self.unit_cell = xray_structure.unit_cell()
    self.scatterers = xray_structure.scatterers()
    self.hkl = hkl
    self.d_star_sq = self.unit_cell.d_star_sq(hkl)

  def as_exp_i_sum(self):
    params = []
    for scatterer in self.scatterers:
      params.append(scatterer_as_g_alpha(
        scatterer=scatterer, hkl=self.hkl, d_star_sq=self.d_star_sq))
    return g_exp_i_alpha_derivatives.g_exp_i_alpha_sum(params=params)

  def f(self):
    return self.as_exp_i_sum().f()

  def d_g_alpha_d_params(self):
    """Mathematica:
         alpha = 2 Pi {h,k,l}.{x,y,z}
         g = w Exp[-2 Pi^2 u dss]
         D[alpha,x]; D[alpha,y]; D[alpha,z]; D[g,u]; D[g,w]"
    """
    result = []
    c = -2 * math.pi**2 * self.d_star_sq
    for scatterer in self.scatterers:
      e = math.exp(c * scatterer.u_iso)
      result.append(gradients(
        site=2*math.pi*matrix.col(self.hkl),
        u_iso=scatterer.occupancy*c*e,
        occupancy=e,
        fp=1,
        fdp=1))
    return result

  def d2_g_alpha_d_params(self):
    """Mathematica:

         alpha = 2 Pi {h,k,l}.{x,y,z}
         g = w Exp[-2 Pi^2 u dss]
         D[alpha,x,x]; D[alpha,x,y]; D[alpha,x,z]; D[g,x,u]; D[g,x,w]"
         D[alpha,y,x]; D[alpha,y,y]; D[alpha,y,z]; D[g,y,u]; D[g,y,w]"
         D[alpha,z,x]; D[alpha,z,y]; D[alpha,z,z]; D[g,z,u]; D[g,z,w]"
         D[alpha,u,x]; D[alpha,u,y]; D[alpha,u,z]; D[g,u,u]; D[g,u,w]"
         D[alpha,w,x]; D[alpha,w,y]; D[alpha,w,z]; D[g,w,u]; D[g,w,w]"

    This curvature matrix is symmetric.
    All D[alpha, x|y|z, x|y|z|u|w] are 0.

       D[g,u,u] = (4 dss^2 Pi^4) w Exp[-2 Pi^2 u dss]
       D[g,u,w] = (-2 dss Pi^2)    Exp[-2 Pi^2 u dss]
       D[g,w,w] = 0
    """
    result = []
    c = -2 * math.pi**2 * self.d_star_sq
    for scatterer in self.scatterers:
      e = math.exp(c * scatterer.u_iso)
      result.append(curvatures(uu=c**2*scatterer.occupancy*e, uw=c*e))
    return result

  def d_target_d_params(self, target):
    result = []
    dts = self.as_exp_i_sum().d_target_d_params(target=target)
    ds = self.d_g_alpha_d_params()
    for dt,d in zip(dts, ds):
      result.append(gradients(
        site = dt.alpha * matrix.col(d.site),
        u_iso = dt.g * d.u_iso,
        occupancy = dt.g * d.occupancy,
        fp = dt.ffp,
        fdp = dt.fdp))
    return result

  def d2_target_d_params(self, target):
    """Combined application of chain rule and product rule.
       d_target_d_.. matrix:

         aa ag a' a"
         ga gg g' g"
         'a 'g '' '"
         "a "g "' ""

       Block in resulting matrix:

         xx xy xz xu xw x' x"
         yx yy yz yu yw y' y"
         zx zy zz zu zw z' z"
         ux uy uz uu uw '' '"
         wx wy wz wu ww "' ""
         'x 'y 'z 'u 'w '' '"
         "x "y "z "u "w "' ""
    """
    result = []
    exp_i_sum = self.as_exp_i_sum()
    dts = exp_i_sum.d_target_d_params(target=target)
    d2ti = iter(exp_i_sum.d2_target_d_params(target=target))
    ds = self.d_g_alpha_d_params()
    d2s = self.d2_g_alpha_d_params()
    for dt,di,d2 in zip(dts, ds, d2s):
      # dx. dy. dz.
      d2ti0 = next(d2ti)
      for dxi in di.site:
        row = []; ra = row.append
        d2tij = iter(d2ti0)
        for dj in ds:
          d2t = next(d2tij)
          for dxj in dj.site:
            ra(d2t * dxi * dxj)
          d2t = next(d2tij)
          ra(d2t * dxi * dj.u_iso)
          ra(d2t * dxi * dj.occupancy)
          ra(next(d2tij) * dxi)
          ra(next(d2tij) * dxi)
        result.append(row)
      # d2u.
      row = []; ra = row.append
      d2ti0 = next(d2ti)
      d2tij = iter(d2ti0)
      for dj in ds:
        d2t = next(d2tij)
        for dxj in dj.site:
          ra(d2t * dxj * di.u_iso)
        d2t = next(d2tij)
        ra(d2t * di.u_iso * dj.u_iso)
        if (di is dj): row[-1] += dt.g * d2.uu
        ra(d2t * di.u_iso * dj.occupancy)
        if (di is dj): row[-1] += dt.g * d2.uw
        ra(next(d2tij) * di.u_iso)
        ra(next(d2tij) * di.u_iso)
      result.append(row)
      # d2w.
      row = []; ra = row.append
      d2tij = iter(d2ti0)
      for dj in ds:
        d2t = next(d2tij)
        for dxj in dj.site:
          ra(d2t * dxj * di.occupancy)
        d2t = next(d2tij)
        ra(d2t * di.occupancy * dj.u_iso)
        if (di is dj): row[-1] += dt.g * d2.uw
        ra(d2t * di.occupancy * dj.occupancy)
        ra(next(d2tij) * di.occupancy)
        ra(next(d2tij) * di.occupancy)
      result.append(row)
      # d2'. and d2"
      for ip in [0,1]:
        row = []; ra = row.append
        d2tij = iter(next(d2ti))
        for dj in ds:
          d2t = next(d2tij)
          for dxj in dj.site:
            ra(d2t * dxj)
          d2t = next(d2tij)
          ra(d2t * dj.u_iso)
          ra(d2t * dj.occupancy)
          ra(next(d2tij))
          ra(next(d2tij))
        result.append(row)
    return result

class structure_factors:

  def __init__(self, xray_structure, miller_set):
    assert xray_structure.is_similar_symmetry(miller_set)
    self.xray_structure = xray_structure
    self.miller_indices = miller_set.indices()
    self.number_of_parameters = xray_structure.scatterers().size()*7

  def fs(self):
    result = flex.complex_double()
    for hkl in self.miller_indices:
      result.append(structure_factor(
        xray_structure=self.xray_structure, hkl=hkl).f())
    return result

  def f(self):
    return flex.sum(self.fs())

  def d_target_d_params(self, f_obs, target_type):
    result = flex.double(self.number_of_parameters, 0)
    for hkl,obs in zip(self.miller_indices, f_obs.data()):
      sf = structure_factor(xray_structure=self.xray_structure, hkl=hkl)
      target = target_type(obs=obs, calc=sf.f())
      result += flex.double(
        pack_gradients(sf.d_target_d_params(target=target)))
    return result

  def d2_target_d_params(self, f_obs, target_type):
    result = flex.double(self.number_of_parameters**2, 0)
    for hkl,obs in zip(self.miller_indices, f_obs.data()):
      sf = structure_factor(xray_structure=self.xray_structure, hkl=hkl)
      target = target_type(obs=obs, calc=sf.f())
      result += flex.double(sf.d2_target_d_params(target=target))
    return result


 *******************************************************************************


 *******************************************************************************
cctbx/examples/structure_factor_derivatives_3.py
from __future__ import absolute_import, division, print_function
from cctbx import xray
from scitbx.math import tensor_rank_2_gradient_transform_matrix
from scitbx import matrix
from scitbx.array_family import flex
import cmath
import math
from six.moves import zip

def scatterer_as_list(self):
  if (self.flags.use_u_iso_only()):
    return list(self.site) + [self.u_iso, self.occupancy, self.fp, self.fdp]
  return list(self.site) + list(self.u_star) \
       + [self.occupancy, self.fp, self.fdp]

def scatterer_from_list(l):
  if (len(l) == 7):
    return xray.scatterer(
      site=l[:3],
      u=l[3],
      occupancy=l[4],
      scattering_type="const",
      fp=l[5],
      fdp=l[6])
  return xray.scatterer(
    site=l[:3],
    u=l[3:9],
    occupancy=l[9],
    scattering_type="const",
    fp=l[10],
    fdp=l[11])

class gradients:

  def __init__(self, site, u_iso, u_star, occupancy, fp, fdp):
    self.site = site
    self.u_iso = u_iso
    self.u_star = u_star
    self.flags = xray.scatterer_flags()
    self.flags.set_use_u(
      iso=(u_iso is not None),
      aniso=(u_star is not None))
    self.occupancy = occupancy
    self.fp = fp
    self.fdp = fdp

def pack_gradients(grads):
  result = []
  for g in grads:
    result.extend(scatterer_as_list(g))
  return result

mtps = -2 * math.pi**2

class structure_factor:

  def __init__(self, xray_structure, hkl):
    self.unit_cell = xray_structure.unit_cell()
    self.space_group = xray_structure.space_group()
    self.scatterers = xray_structure.scatterers()
    self.hkl = hkl
    self.d_star_sq = self.unit_cell.d_star_sq(hkl)

  def f(self):
    result = 0
    tphkl = 2 * math.pi * matrix.col(self.hkl)
    for scatterer in self.scatterers:
      assert scatterer.scattering_type == "const"
      w = scatterer.occupancy
      if (not scatterer.flags.use_u_aniso()):
        huh = scatterer.u_iso * self.d_star_sq
        dw = math.exp(mtps * huh)
      ffp = 1 + scatterer.fp
      fdp = scatterer.fdp
      ff = ffp + 1j * fdp
      for s in self.space_group:
        s_site = s * scatterer.site
        alpha = matrix.col(s_site).dot(tphkl)
        if (scatterer.flags.use_u_aniso()):
          r = s.r().as_rational().as_float()
          s_u_star_s = r*matrix.sym(sym_mat3=scatterer.u_star)*r.transpose()
          huh = (matrix.row(self.hkl) * s_u_star_s).dot(matrix.col(self.hkl))
          dw = math.exp(mtps * huh)
        e = cmath.exp(1j*alpha)
        result += w * dw * ff * e
    return result

  def df_d_params(self):
    result = []
    tphkl = 2 * math.pi * matrix.col(self.hkl)
    h,k,l = self.hkl
    d_exp_huh_d_u_star = matrix.col([h**2, k**2, l**2, 2*h*k, 2*h*l, 2*k*l])
    for scatterer in self.scatterers:
      assert scatterer.scattering_type == "const"
      w = scatterer.occupancy
      if (not scatterer.flags.use_u_aniso()):
        huh = scatterer.u_iso * self.d_star_sq
        dw = math.exp(mtps * huh)
      ffp = 1 + scatterer.fp
      fdp = scatterer.fdp
      ff = ffp + 1j * fdp
      d_site = matrix.col([0,0,0])
      if (not scatterer.flags.use_u_aniso()):
        d_u_iso = 0
        d_u_star = None
      else:
        d_u_iso = None
        d_u_star = matrix.col([0,0,0,0,0,0])
      d_occ = 0
      d_fp = 0
      d_fdp = 0
      for s in self.space_group:
        r = s.r().as_rational().as_float()
        s_site = s * scatterer.site
        alpha = matrix.col(s_site).dot(tphkl)
        if (scatterer.flags.use_u_aniso()):
          s_u_star_s = r*matrix.sym(sym_mat3=scatterer.u_star)*r.transpose()
          huh = (matrix.row(self.hkl) * s_u_star_s).dot(matrix.col(self.hkl))
          dw = math.exp(mtps * huh)
        e = cmath.exp(1j*alpha)
        site_gtmx = r.transpose()
        d_site += site_gtmx * (
          w * dw * ff * e * 1j * tphkl)
        if (not scatterer.flags.use_u_aniso()):
          d_u_iso += w * dw * ff * e * mtps * self.d_star_sq
        else:
          u_star_gtmx = matrix.sqr(tensor_rank_2_gradient_transform_matrix(r))
          d_u_star += u_star_gtmx * (
            w * dw * ff * e * mtps * d_exp_huh_d_u_star)
        d_occ += dw * ff * e
        d_fp += w * dw * e
        d_fdp += w * dw * e * 1j
      result.append(gradients(
        site=d_site,
        u_iso=d_u_iso,
        u_star=d_u_star,
        occupancy=d_occ,
        fp=d_fp,
        fdp=d_fdp))
    return result

  def d2f_d_params(self):
    tphkl = 2 * math.pi * matrix.col(self.hkl)
    tphkl_outer = tphkl.outer_product()
    h,k,l = self.hkl
    d_exp_huh_d_u_star = matrix.col([h**2, k**2, l**2, 2*h*k, 2*h*l, 2*k*l])
    d2_exp_huh_d_u_star_u_star = d_exp_huh_d_u_star.outer_product()
    for scatterer in self.scatterers:
      assert scatterer.scattering_type == "const"
      w = scatterer.occupancy
      if (not scatterer.flags.use_u_aniso()):
        huh = scatterer.u_iso * self.d_star_sq
        dw = math.exp(mtps * huh)
      ffp = 1 + scatterer.fp
      fdp = scatterer.fdp
      ff = (ffp + 1j * fdp)
      d2_site_site = flex.complex_double(flex.grid(3,3), 0j)
      if (not scatterer.flags.use_u_aniso()):
        d2_site_u_iso = flex.complex_double(flex.grid(3,1), 0j)
        d2_site_u_star = None
      else:
        d2_site_u_iso = None
        d2_site_u_star = flex.complex_double(flex.grid(3,6), 0j)
      d2_site_occ = flex.complex_double(flex.grid(3,1), 0j)
      d2_site_fp = flex.complex_double(flex.grid(3,1), 0j)
      d2_site_fdp = flex.complex_double(flex.grid(3,1), 0j)
      if (not scatterer.flags.use_u_aniso()):
        d2_u_iso_u_iso = 0j
        d2_u_iso_occ = 0j
        d2_u_iso_fp = 0j
        d2_u_iso_fdp = 0j
      else:
        d2_u_star_u_star = flex.complex_double(flex.grid(6,6), 0j)
        d2_u_star_occ = flex.complex_double(flex.grid(6,1), 0j)
        d2_u_star_fp = flex.complex_double(flex.grid(6,1), 0j)
        d2_u_star_fdp = flex.complex_double(flex.grid(6,1), 0j)
      d2_occ_fp = 0j
      d2_occ_fdp = 0j
      for s in self.space_group:
        r = s.r().as_rational().as_float()
        s_site = s * scatterer.site
        alpha = matrix.col(s_site).dot(tphkl)
        if (scatterer.flags.use_u_aniso()):
          s_u_star_s = r*matrix.sym(sym_mat3=scatterer.u_star)*r.transpose()
          huh = (matrix.row(self.hkl) * s_u_star_s).dot(matrix.col(self.hkl))
          dw = math.exp(mtps * huh)
        e = cmath.exp(1j*alpha)
        site_gtmx = r.transpose()
        d2_site_site += flex.complex_double(
          site_gtmx *
            (w * dw * ff * e * (-1) * tphkl_outer)
               * site_gtmx.transpose())
        if (not scatterer.flags.use_u_aniso()):
          d2_site_u_iso += flex.complex_double(site_gtmx * (
            w * dw * ff * e * 1j * mtps * self.d_star_sq * tphkl))
        else:
          u_star_gtmx = matrix.sqr(tensor_rank_2_gradient_transform_matrix(r))
          d2_site_u_star += flex.complex_double(
              site_gtmx
            * ((w * dw * ff * e * 1j * tphkl).outer_product(
                mtps * d_exp_huh_d_u_star))
            * u_star_gtmx.transpose())
        d2_site_occ += flex.complex_double(site_gtmx * (
          dw * ff * e * 1j * tphkl))
        d2_site_fp += flex.complex_double(site_gtmx * (
          w * dw * e * 1j * tphkl))
        d2_site_fdp += flex.complex_double(site_gtmx * (
          w * dw * e * (-1) * tphkl))
        if (not scatterer.flags.use_u_aniso()):
          d2_u_iso_u_iso += w * dw * ff * e * (mtps * self.d_star_sq)**2
          d2_u_iso_occ += dw * ff * e * mtps * self.d_star_sq
          d2_u_iso_fp += w * dw * e * mtps * self.d_star_sq
          d2_u_iso_fdp += 1j * w * dw * e * mtps * self.d_star_sq
        else:
          d2_u_star_u_star += flex.complex_double(
              u_star_gtmx
            * (w * dw * ff * e * mtps**2 * d2_exp_huh_d_u_star_u_star)
            * u_star_gtmx.transpose())
          d2_u_star_occ += flex.complex_double(u_star_gtmx * (
            dw * ff * e * mtps * d_exp_huh_d_u_star))
          d2_u_star_fp += flex.complex_double(u_star_gtmx * (
            w * dw * e * mtps * d_exp_huh_d_u_star))
          d2_u_star_fdp += flex.complex_double(u_star_gtmx * (
            w * dw * 1j * e * mtps * d_exp_huh_d_u_star))
        d2_occ_fp += dw * e
        d2_occ_fdp += dw * e * 1j
      if (not scatterer.flags.use_u_aniso()):
        i_occ, i_fp, i_fdp, np = 4, 5, 6, 7
      else:
        i_occ, i_fp, i_fdp, np = 9, 10, 11, 12
      dp = flex.complex_double(flex.grid(np,np), 0j)
      paste = dp.matrix_paste_block_in_place
      paste(d2_site_site, 0,0)
      if (not scatterer.flags.use_u_aniso()):
        paste(d2_site_u_iso, 0,3)
        paste(d2_site_u_iso.matrix_transpose(), 3,0)
      else:
        paste(d2_site_u_star, 0,3)
        paste(d2_site_u_star.matrix_transpose(), 3,0)
      paste(d2_site_occ, 0,i_occ)
      paste(d2_site_occ.matrix_transpose(), i_occ,0)
      paste(d2_site_fp, 0,i_fp)
      paste(d2_site_fp.matrix_transpose(), i_fp,0)
      paste(d2_site_fdp, 0,i_fdp)
      paste(d2_site_fdp.matrix_transpose(), i_fdp,0)
      if (not scatterer.flags.use_u_aniso()):
        dp[3*7+3] = d2_u_iso_u_iso
        dp[3*7+4] = d2_u_iso_occ
        dp[4*7+3] = d2_u_iso_occ
        dp[3*7+5] = d2_u_iso_fp
        dp[5*7+3] = d2_u_iso_fp
        dp[3*7+6] = d2_u_iso_fdp
        dp[6*7+3] = d2_u_iso_fdp
      else:
        paste(d2_u_star_u_star, 3,3)
        paste(d2_u_star_occ, 3, 9)
        paste(d2_u_star_occ.matrix_transpose(), 9, 3)
        paste(d2_u_star_fp, 3, 10)
        paste(d2_u_star_fp.matrix_transpose(), 10, 3)
        paste(d2_u_star_fdp, 3, 11)
        paste(d2_u_star_fdp.matrix_transpose(), 11, 3)
      dp[i_occ*np+i_fp] = d2_occ_fp
      dp[i_fp*np+i_occ] = d2_occ_fp
      dp[i_occ*np+i_fdp] = d2_occ_fdp
      dp[i_fdp*np+i_occ] = d2_occ_fdp
      yield dp

  def d_target_d_params(self, target):
    da, db = target.da(), target.db()
    return flex.double([[da * d.real + db * d.imag
      for d in scatterer_as_list(d_scatterer)]
        for d_scatterer in self.df_d_params()])

  def d2_target_d_params(self, target):
    result = []
    da, db = target.da(), target.db()
    daa, dbb, dab = target.daa(), target.dbb(), target.dab()
    ds = self.df_d_params()
    d2s = self.d2f_d_params()
    for di0,d2i in zip(ds, d2s):
      d2ij_iter = iter(d2i)
      for di in scatterer_as_list(di0):
        row = []
        for dj0 in ds:
          for dj in scatterer_as_list(dj0):
            sum = daa * di.real * dj.real \
                + dbb * di.imag * dj.imag \
                + dab * (di.real * dj.imag + di.imag * dj.real)
            if (di0 is dj0):
              d2ij = next(d2ij_iter)
              sum += da * d2ij.real + db * d2ij.imag
            row.append(sum)
        result.append(row)
    return flex.double(result)

class structure_factors:

  def __init__(self, xray_structure, miller_set):
    assert xray_structure.is_similar_symmetry(miller_set)
    self.xray_structure = xray_structure
    self.miller_indices = miller_set.indices()
    np = 0
    for scatterer in xray_structure.scatterers():
      if (not scatterer.flags.use_u_aniso()):
        np += 7
      else:
        np += 12
    self.number_of_parameters = np

  def fs(self):
    result = flex.complex_double()
    for hkl in self.miller_indices:
      result.append(structure_factor(
        xray_structure=self.xray_structure, hkl=hkl).f())
    return result

  def f(self):
    return flex.sum(self.fs())

  def d_target_d_params(self, f_obs, target_type):
    result = flex.double(self.number_of_parameters, 0)
    for hkl,obs in zip(self.miller_indices, f_obs.data()):
      sf = structure_factor(xray_structure=self.xray_structure, hkl=hkl)
      target = target_type(obs=obs, calc=sf.f())
      result += sf.d_target_d_params(target=target)
    return result

  def d2_target_d_params(self, f_obs, target_type):
    np = self.number_of_parameters
    result = flex.double(flex.grid(np, np), 0)
    for hkl,obs in zip(self.miller_indices, f_obs.data()):
      sf = structure_factor(xray_structure=self.xray_structure, hkl=hkl)
      target = target_type(obs=obs, calc=sf.f())
      result += sf.d2_target_d_params(target=target)
    return result


 *******************************************************************************


 *******************************************************************************
cctbx/examples/structure_factor_derivatives_4.py
from __future__ import absolute_import, division, print_function
from scitbx.math import tensor_rank_2_gradient_transform_matrix
from scitbx import matrix
from scitbx.array_family import flex
import cmath
import math
from six.moves import zip

mtps = -2 * math.pi**2

class structure_factor:

  def __init__(self, xray_structure, hkl):
    self.unit_cell = xray_structure.unit_cell()
    self.space_group = xray_structure.space_group()
    self.scatterers = xray_structure.scatterers()
    self.site_symmetry_table = xray_structure.site_symmetry_table()
    self.scattering_type_registry = xray_structure.scattering_type_registry()
    self.hkl = hkl
    self.d_star_sq = self.unit_cell.d_star_sq(hkl)

  def f(self):
    result = 0
    tphkl = 2 * math.pi * matrix.col(self.hkl)
    for scatterer in self.scatterers:
      w = scatterer.weight()
      if (not scatterer.flags.use_u_aniso()):
        huh = scatterer.u_iso * self.d_star_sq
        dw = math.exp(mtps * huh)
      gaussian = self.scattering_type_registry.gaussian_not_optional(
        scattering_type=scatterer.scattering_type)
      f0 = gaussian.at_d_star_sq(self.d_star_sq)
      ffp = f0 + scatterer.fp
      fdp = scatterer.fdp
      ff = ffp + 1j * fdp
      for s in self.space_group:
        s_site = s * scatterer.site
        alpha = matrix.col(s_site).dot(tphkl)
        if (scatterer.flags.use_u_aniso()):
          r = s.r().as_rational().as_float()
          s_u_star_s = r*matrix.sym(sym_mat3=scatterer.u_star)*r.transpose()
          huh = (matrix.row(self.hkl) * s_u_star_s).dot(matrix.col(self.hkl))
          dw = math.exp(mtps * huh)
        e = cmath.exp(1j*alpha)
        result += w * dw * ff * e
    return result

  def df_d_params(self):
    tphkl = 2 * math.pi * matrix.col(self.hkl)
    h,k,l = self.hkl
    d_exp_huh_d_u_star = matrix.col([h**2, k**2, l**2, 2*h*k, 2*h*l, 2*k*l])
    for i_scatterer,scatterer in enumerate(self.scatterers):
      site_symmetry_ops = None
      if (self.site_symmetry_table.is_special_position(i_scatterer)):
        site_symmetry_ops = self.site_symmetry_table.get(i_scatterer)
        site_constraints = site_symmetry_ops.site_constraints()
        if (scatterer.flags.use_u_aniso()):
          adp_constraints = site_symmetry_ops.adp_constraints()
      w = scatterer.weight()
      wwo = scatterer.weight_without_occupancy()
      if (not scatterer.flags.use_u_aniso()):
        huh = scatterer.u_iso * self.d_star_sq
        dw = math.exp(mtps * huh)
      gaussian = self.scattering_type_registry.gaussian_not_optional(
        scattering_type=scatterer.scattering_type)
      f0 = gaussian.at_d_star_sq(self.d_star_sq)
      ffp = f0 + scatterer.fp
      fdp = scatterer.fdp
      ff = ffp + 1j * fdp
      d_site = matrix.col([0,0,0])
      if (not scatterer.flags.use_u_aniso()):
        d_u_iso = 0
        d_u_star = None
      else:
        d_u_iso = None
        d_u_star = matrix.col([0,0,0,0,0,0])
      d_occ = 0j
      d_fp = 0j
      d_fdp = 0j
      for s in self.space_group:
        r = s.r().as_rational().as_float()
        s_site = s * scatterer.site
        alpha = matrix.col(s_site).dot(tphkl)
        if (scatterer.flags.use_u_aniso()):
          s_u_star_s = r*matrix.sym(sym_mat3=scatterer.u_star)*r.transpose()
          huh = (matrix.row(self.hkl) * s_u_star_s).dot(matrix.col(self.hkl))
          dw = math.exp(mtps * huh)
        e = cmath.exp(1j*alpha)
        site_gtmx = r.transpose()
        d_site += site_gtmx * (
          w * dw * ff * e * 1j * tphkl)
        if (not scatterer.flags.use_u_aniso()):
          d_u_iso += w * dw * ff * e * mtps * self.d_star_sq
        else:
          u_star_gtmx = matrix.sqr(tensor_rank_2_gradient_transform_matrix(r))
          d_u_star += u_star_gtmx * (
            w * dw * ff * e * mtps * d_exp_huh_d_u_star)
        d_occ += wwo * dw * ff * e
        d_fp += w * dw * e
        d_fdp += w * dw * e * 1j
      if (site_symmetry_ops is not None):
        gsm = site_constraints.gradient_sum_matrix()
        gsm = matrix.rec(elems=gsm, n=gsm.focus())
        d_site = gsm * d_site
        if (scatterer.flags.use_u_aniso()):
          gsm = adp_constraints.gradient_sum_matrix()
          gsm = matrix.rec(elems=gsm, n=gsm.focus())
          d_u_star = gsm * d_u_star
      result = flex.complex_double(d_site)
      if (not scatterer.flags.use_u_aniso()):
        result.append(d_u_iso)
      else:
        result.extend(flex.complex_double(d_u_star))
      result.extend(flex.complex_double([d_occ, d_fp, d_fdp]))
      yield result

  def d2f_d_params(self):
    tphkl = 2 * math.pi * flex.double(self.hkl)
    tphkl_outer = tphkl.matrix_outer_product(tphkl) \
      .matrix_symmetric_as_packed_u()
    h,k,l = self.hkl
    d_exp_huh_d_u_star = flex.double([h**2, k**2, l**2, 2*h*k, 2*h*l, 2*k*l])
    d2_exp_huh_d_u_star_u_star = d_exp_huh_d_u_star.matrix_outer_product(
      d_exp_huh_d_u_star).matrix_symmetric_as_packed_u()
    for i_scatterer,scatterer in enumerate(self.scatterers):
      site_symmetry_ops = None
      if (self.site_symmetry_table.is_special_position(i_scatterer)):
        site_symmetry_ops = self.site_symmetry_table.get(i_scatterer)
        site_constraints = site_symmetry_ops.site_constraints()
        if (scatterer.flags.use_u_aniso()):
          adp_constraints = site_symmetry_ops.adp_constraints()
      w = scatterer.weight()
      wwo = scatterer.weight_without_occupancy()
      if (not scatterer.flags.use_u_aniso()):
        huh = scatterer.u_iso * self.d_star_sq
        dw = math.exp(mtps * huh)
      gaussian = self.scattering_type_registry.gaussian_not_optional(
        scattering_type=scatterer.scattering_type)
      f0 = gaussian.at_d_star_sq(self.d_star_sq)
      ffp = f0 + scatterer.fp
      fdp = scatterer.fdp
      ff = (ffp + 1j * fdp)
      d2_site_site = flex.complex_double(3*(3+1)//2, 0j)
      if (not scatterer.flags.use_u_aniso()):
        d2_site_u_iso = flex.complex_double(flex.grid(3,1), 0j)
        d2_site_u_star = None
      else:
        d2_site_u_iso = None
        d2_site_u_star = flex.complex_double(flex.grid(3,6), 0j)
      d2_site_occ = flex.complex_double(flex.grid(3,1), 0j)
      d2_site_fp = flex.complex_double(flex.grid(3,1), 0j)
      d2_site_fdp = flex.complex_double(flex.grid(3,1), 0j)
      if (not scatterer.flags.use_u_aniso()):
        d2_u_iso_u_iso = 0j
        d2_u_iso_occ = 0j
        d2_u_iso_fp = 0j
        d2_u_iso_fdp = 0j
      else:
        d2_u_star_u_star = flex.complex_double(6*(6+1)//2, 0j)
        d2_u_star_occ = flex.complex_double(flex.grid(6,1), 0j)
        d2_u_star_fp = flex.complex_double(flex.grid(6,1), 0j)
        d2_u_star_fdp = flex.complex_double(flex.grid(6,1), 0j)
      d2_occ_fp = 0j
      d2_occ_fdp = 0j
      for s in self.space_group:
        r = s.r().as_rational().as_float()
        s_site = s * scatterer.site
        alpha = tphkl.dot(flex.double(s_site))
        if (scatterer.flags.use_u_aniso()):
          s_u_star_s = r*matrix.sym(sym_mat3=scatterer.u_star)*r.transpose()
          huh = (matrix.row(self.hkl) * s_u_star_s).dot(matrix.col(self.hkl))
          dw = math.exp(mtps * huh)
        e = cmath.exp(1j*alpha)
        site_gtmx = flex.double(r.transpose())
        site_gtmx.reshape(flex.grid(3,3))
        d2_site_site += (w * dw * ff * e * (-1)) * (
          site_gtmx.matrix_multiply_packed_u_multiply_lhs_transpose(
            tphkl_outer))
        if (not scatterer.flags.use_u_aniso()):
          d2_site_u_iso += (w * dw * ff * e * 1j * mtps * self.d_star_sq) \
            * site_gtmx.matrix_multiply(tphkl)
        else:
          u_star_gtmx = tensor_rank_2_gradient_transform_matrix(r)
          d2_site_u_star += (w * dw * ff * e * 1j * mtps) \
            * site_gtmx.matrix_multiply(
                tphkl.matrix_outer_product(d_exp_huh_d_u_star)) \
                  .matrix_multiply(u_star_gtmx.matrix_transpose())
        site_gtmx_tphkl = site_gtmx.matrix_multiply(tphkl)
        d2_site_occ += (wwo * dw * ff * e * 1j) * site_gtmx_tphkl
        d2_site_fp += (w * dw * e * 1j) * site_gtmx_tphkl
        d2_site_fdp += (w * dw * e * (-1)) * site_gtmx_tphkl
        if (not scatterer.flags.use_u_aniso()):
          d2_u_iso_u_iso += w * dw * ff * e * (mtps * self.d_star_sq)**2
          d2_u_iso_occ += wwo * dw * ff * e * mtps * self.d_star_sq
          d2_u_iso_fp += w * dw * e * mtps * self.d_star_sq
          d2_u_iso_fdp += 1j * w * dw * e * mtps * self.d_star_sq
        else:
          d2_u_star_u_star +=(w * dw * ff * e * mtps**2) \
            * u_star_gtmx.matrix_multiply_packed_u_multiply_lhs_transpose(
                d2_exp_huh_d_u_star_u_star)
          u_star_gtmx_d_exp_huh_d_u_star = u_star_gtmx.matrix_multiply(
            d_exp_huh_d_u_star)
          d2_u_star_occ += (wwo * dw * ff * e * mtps) \
            * u_star_gtmx_d_exp_huh_d_u_star
          d2_u_star_fp += (w * dw * e * mtps) \
            * u_star_gtmx_d_exp_huh_d_u_star
          d2_u_star_fdp += (w * dw * 1j * e * mtps) \
            * u_star_gtmx_d_exp_huh_d_u_star
        d2_occ_fp += wwo * dw * e
        d2_occ_fdp += wwo * dw * e * 1j
      if (site_symmetry_ops is None):
        i_u = 3
      else:
        i_u = site_constraints.n_independent_params()
      if (not scatterer.flags.use_u_aniso()):
        i_occ = i_u + 1
      elif (site_symmetry_ops is None):
        i_occ = i_u + 6
      else:
        i_occ = i_u + adp_constraints.n_independent_params()
      i_fp, i_fdp, np = i_occ+1, i_occ+2, i_occ+3
      if (site_symmetry_ops is not None):
        gsm = site_constraints.gradient_sum_matrix()
        d2_site_site = gsm.matrix_multiply_packed_u_multiply_lhs_transpose(
          packed_u=d2_site_site)
        if (not scatterer.flags.use_u_aniso()):
          d2_site_u_iso = gsm.matrix_multiply(d2_site_u_iso)
        else:
          d2_site_u_star = gsm.matrix_multiply(d2_site_u_star)
        d2_site_occ = gsm.matrix_multiply(d2_site_occ)
        d2_site_fp = gsm.matrix_multiply(d2_site_fp)
        d2_site_fdp = gsm.matrix_multiply(d2_site_fdp)
        if (scatterer.flags.use_u_aniso()):
          gsm = adp_constraints.gradient_sum_matrix()
          d2_site_u_star = d2_site_u_star.matrix_multiply(
            gsm.matrix_transpose())
          d2_u_star_u_star = gsm \
            .matrix_multiply_packed_u_multiply_lhs_transpose(
              packed_u=d2_u_star_u_star)
          d2_u_star_occ = gsm.matrix_multiply(d2_u_star_occ)
          d2_u_star_fp = gsm.matrix_multiply(d2_u_star_fp)
          d2_u_star_fdp = gsm.matrix_multiply(d2_u_star_fdp)
      dp = flex.complex_double(flex.grid(np,np), 0j)
      paste = dp.matrix_paste_block_in_place
      paste(d2_site_site.matrix_packed_u_as_symmetric(), 0,0)
      if (not scatterer.flags.use_u_aniso()):
        paste(d2_site_u_iso, 0,i_u)
        paste(d2_site_u_iso.matrix_transpose(), i_u,0)
      else:
        paste(d2_site_u_star, 0,i_u)
        paste(d2_site_u_star.matrix_transpose(), i_u,0)
      paste(d2_site_occ, 0,i_occ)
      paste(d2_site_occ.matrix_transpose(), i_occ,0)
      paste(d2_site_fp, 0,i_fp)
      paste(d2_site_fp.matrix_transpose(), i_fp,0)
      paste(d2_site_fdp, 0,i_fdp)
      paste(d2_site_fdp.matrix_transpose(), i_fdp,0)
      if (not scatterer.flags.use_u_aniso()):
        dp[i_u*np+i_u] = d2_u_iso_u_iso
        dp[i_u*np+i_occ] = d2_u_iso_occ
        dp[i_occ*np+i_u] = d2_u_iso_occ
        dp[i_u*np+i_fp] = d2_u_iso_fp
        dp[i_fp*np+i_u] = d2_u_iso_fp
        dp[i_u*np+i_fdp] = d2_u_iso_fdp
        dp[i_fdp*np+i_u] = d2_u_iso_fdp
      else:
        paste(d2_u_star_u_star.matrix_packed_u_as_symmetric(), i_u, i_u)
        paste(d2_u_star_occ, i_u, i_occ)
        paste(d2_u_star_occ.matrix_transpose(), i_occ, i_u)
        paste(d2_u_star_fp, i_u, i_fp)
        paste(d2_u_star_fp.matrix_transpose(), i_fp, i_u)
        paste(d2_u_star_fdp, i_u, i_fdp)
        paste(d2_u_star_fdp.matrix_transpose(), i_fdp, i_u)
      dp[i_occ*np+i_fp] = d2_occ_fp
      dp[i_fp*np+i_occ] = d2_occ_fp
      dp[i_occ*np+i_fdp] = d2_occ_fdp
      dp[i_fdp*np+i_occ] = d2_occ_fdp
      yield dp

  def d2f_d_params_diag(self):
    tphkl = 2 * math.pi * flex.double(self.hkl)
    tphkl_outer = tphkl.matrix_outer_product(tphkl) \
      .matrix_symmetric_as_packed_u()
    h,k,l = self.hkl
    d_exp_huh_d_u_star = flex.double([h**2, k**2, l**2, 2*h*k, 2*h*l, 2*k*l])
    d2_exp_huh_d_u_star_u_star = d_exp_huh_d_u_star.matrix_outer_product(
      d_exp_huh_d_u_star).matrix_symmetric_as_packed_u()
    for i_scatterer,scatterer in enumerate(self.scatterers):
      site_symmetry_ops = None
      if (self.site_symmetry_table.is_special_position(i_scatterer)):
        site_symmetry_ops = self.site_symmetry_table.get(i_scatterer)
        site_constraints = site_symmetry_ops.site_constraints()
        if (scatterer.flags.use_u_aniso()):
          adp_constraints = site_symmetry_ops.adp_constraints()
      w = scatterer.weight()
      if (not scatterer.flags.use_u_aniso()):
        huh = scatterer.u_iso * self.d_star_sq
        dw = math.exp(mtps * huh)
      gaussian = self.scattering_type_registry.gaussian_not_optional(
        scattering_type=scatterer.scattering_type)
      f0 = gaussian.at_d_star_sq(self.d_star_sq)
      ffp = f0 + scatterer.fp
      fdp = scatterer.fdp
      ff = (ffp + 1j * fdp)
      d2_site_site = flex.complex_double(3*(3+1)//2, 0j)
      if (not scatterer.flags.use_u_aniso()):
        d2_u_iso_u_iso = 0j
      else:
        d2_u_star_u_star = flex.complex_double(6*(6+1)//2, 0j)
      for s in self.space_group:
        r = s.r().as_rational().as_float()
        s_site = s * scatterer.site
        alpha = tphkl.dot(flex.double(s_site))
        if (scatterer.flags.use_u_aniso()):
          s_u_star_s = r*matrix.sym(sym_mat3=scatterer.u_star)*r.transpose()
          huh = (matrix.row(self.hkl) * s_u_star_s).dot(matrix.col(self.hkl))
          dw = math.exp(mtps * huh)
        e = cmath.exp(1j*alpha)
        site_gtmx = flex.double(r.transpose())
        site_gtmx.reshape(flex.grid(3,3))
        d2_site_site += (w * dw * ff * e * (-1)) * (
          site_gtmx.matrix_multiply_packed_u_multiply_lhs_transpose(
            tphkl_outer))
        if (not scatterer.flags.use_u_aniso()):
          d2_u_iso_u_iso += w * dw * ff * e * (mtps * self.d_star_sq)**2
        else:
          u_star_gtmx = tensor_rank_2_gradient_transform_matrix(r)
          d2_u_star_u_star +=(w * dw * ff * e * mtps**2) \
            * u_star_gtmx.matrix_multiply_packed_u_multiply_lhs_transpose(
                d2_exp_huh_d_u_star_u_star)
      if (site_symmetry_ops is None):
        i_u = 3
      else:
        i_u = site_constraints.n_independent_params()
      if (not scatterer.flags.use_u_aniso()):
        i_occ = i_u + 1
      elif (site_symmetry_ops is None):
        i_occ = i_u + 6
      else:
        i_occ = i_u + adp_constraints.n_independent_params()
      np = i_occ+3
      if (site_symmetry_ops is not None):
        gsm = site_constraints.gradient_sum_matrix()
        d2_site_site = gsm.matrix_multiply_packed_u_multiply_lhs_transpose(
          packed_u=d2_site_site)
        if (scatterer.flags.use_u_aniso()):
          gsm = adp_constraints.gradient_sum_matrix()
          d2_u_star_u_star = gsm \
            .matrix_multiply_packed_u_multiply_lhs_transpose(
              packed_u=d2_u_star_u_star)
      #
      dpd = flex.complex_double(flex.grid(np,1), 0j)
      def paste(d, i):
        d.reshape(flex.grid(d.size(),1))
        dpd.matrix_paste_block_in_place(d, i,0)
      paste(d2_site_site.matrix_packed_u_diagonal(), 0)
      if (not scatterer.flags.use_u_aniso()):
        dpd[i_u] = d2_u_iso_u_iso
      else:
        paste(d2_u_star_u_star.matrix_packed_u_diagonal(), i_u)
      yield dpd

  def d_target_d_params(self, target):
    result = flex.double()
    da, db = target.da(), target.db()
    for d_scatterer in self.df_d_params():
      result.extend(flex.double([da * d.real + db * d.imag
        for d in d_scatterer]))
    return result

  def d2_target_d_params(self, target):
    result = []
    da, db = target.da(), target.db()
    daa, dbb, dab = target.daa(), target.dbb(), target.dab()
    ds = list(self.df_d_params())
    d2s = self.d2f_d_params()
    for di0,d2i in zip(ds, d2s):
      d2ij_iter = iter(d2i)
      for di in di0:
        row = []
        for dj0 in ds:
          for dj in dj0:
            sum = daa * di.real * dj.real \
                + dbb * di.imag * dj.imag \
                + dab * (di.real * dj.imag + di.imag * dj.real)
            if (di0 is dj0):
              d2ij = next(d2ij_iter)
              sum += da * d2ij.real + db * d2ij.imag
            row.append(sum)
        result.append(row)
    return flex.double(result)

  def d2_target_d_params_diag(self, target):
    result = flex.double()
    da, db = target.da(), target.db()
    daa, dbb, dab = target.daa(), target.dbb(), target.dab()
    ds = self.df_d_params()
    d2sd = self.d2f_d_params_diag()
    for i_scatterer,(di0,d2id) in enumerate(zip(ds, d2sd)):
      for di,d2ij in zip(di0, d2id):
        sum = daa * di.real * di.real \
            + dbb * di.imag * di.imag \
            + dab * 2 * di.real * di.imag \
            + da * d2ij.real + db * d2ij.imag
        result.append(sum)
    return result

class structure_factors:

  def __init__(self, xray_structure, miller_set):
    assert xray_structure.is_similar_symmetry(miller_set)
    self.xray_structure = xray_structure
    self.miller_indices = miller_set.indices()

  def fs(self):
    result = flex.complex_double()
    for hkl in self.miller_indices:
      result.append(structure_factor(
        xray_structure=self.xray_structure, hkl=hkl).f())
    return result

  def f(self):
    return flex.sum(self.fs())

  def d_target_d_params(self, f_obs, target_type):
    result = None
    for hkl,obs in zip(self.miller_indices, f_obs.data()):
      sf = structure_factor(xray_structure=self.xray_structure, hkl=hkl)
      target = target_type(obs=obs, calc=sf.f())
      contribution = sf.d_target_d_params(target=target)
      if (result is None): result = contribution
      else:                result += contribution
    return result

  def d2_target_d_params(self, f_obs, target_type):
    result = None
    for hkl,obs in zip(self.miller_indices, f_obs.data()):
      sf = structure_factor(xray_structure=self.xray_structure, hkl=hkl)
      target = target_type(obs=obs, calc=sf.f())
      contribution = sf.d2_target_d_params(target=target)
      if (result is None): result = contribution
      else:                result += contribution
    return result

  def d2_target_d_params_diag(self, f_obs, target_type):
    result = None
    for hkl,obs in zip(self.miller_indices, f_obs.data()):
      sf = structure_factor(xray_structure=self.xray_structure, hkl=hkl)
      target = target_type(obs=obs, calc=sf.f())
      contribution = sf.d2_target_d_params_diag(target=target)
      if (result is None): result = contribution
      else:                result += contribution
    return result

  def d2_target_d_params_diag_cpp(self, f_obs, target_type):
    da_db = flex.complex_double()
    daa_dbb_dab = flex.vec3_double()
    for hkl,obs in zip(self.miller_indices, f_obs.data()):
      sf = structure_factor(xray_structure=self.xray_structure, hkl=hkl)
      target = target_type(obs=obs, calc=sf.f())
      da_db.append(complex(target.da(), target.db()))
      daa_dbb_dab.append((target.daa(), target.dbb(), target.dab()))
    return self.xray_structure.grads_and_curvs_target_simple(
      miller_indices=f_obs.indices(), da_db=da_db, daa_dbb_dab=daa_dbb_dab)


 *******************************************************************************


 *******************************************************************************
cctbx/examples/sub_group_graph.py
"""
Construct all subgroup graphs and their relations between them from a single space group.
"""
from __future__ import absolute_import, division, print_function


from cctbx import sgtbx
from cctbx.sgtbx import pointgroup_tools
import sys

def run(sg1):
  sg_high = sgtbx.space_group_info( sg1  ).group()
  sg_low  = sgtbx.space_group_info( "p1" ).group()
  graph_object =  pointgroup_tools.point_group_graph( sg_low, sg_high, False,True)
  graph_object.graph.show()
  out = """ """
  out += "digraph f { "
  out += "rankdir=LR"
  for pg in graph_object.graph.node_objects:
    for next_pg in graph_object.graph.edge_objects[ pg ]:
      pg = pg.replace( "\"","''" )
      next_pg = next_pg.replace( "\"","''" )
      out += "\""+pg+"\" -> \""+next_pg+"\" ;"
  out += "}"
  cmnd = """dot -Tpng > sg_graph.png << EOF
%s
EOF
  """%(out)
  print()
  print("Command for dot (graphviz package) to show relations between groups: ")
  print(cmnd)

if __name__=="__main__":
  run( sys.argv[1] )


 *******************************************************************************


 *******************************************************************************
cctbx/examples/symops_530.py
"""\
Loop over 530 conventional settings of the 230 space groups,
show symmetry operations in various formats.

See also:
  List of 530 settings:
    Shmueli U, Hall SR, Grosse-Kunstleve RW:
    Space-Group Symbols for numeric and symbolic computations.
    In International Tables for Crystallography, Volume B:
    Reciprocal space, U. Shmueli, Ed.,
    Kluwer Academic Publishers (Dordrecht), 2001, 107-119.

  Universal Hermann-Mauguin symbols: section 2.1 of:
    Zwart P, Grosse-Kunstleve RW, Lebedev AA, Murshudov GN, Adams PD:
    Surprises and pitfalls arising from(pseudo)symmetry
    Acta Cryst. 2008, D64, 99-107.
    http://scripts.iucr.org/cgi-bin/paper?ba5111
"""
from __future__ import absolute_import, division, print_function

from cctbx import sgtbx

def run():
  for symbols in sgtbx.space_group_symbol_iterator():
    symbol = symbols.universal_hermann_mauguin()
    print(symbol)
    space_group_info = sgtbx.space_group_info(symbol=symbol)
    for s in space_group_info.group():
      print(s.as_xyz())
    for s in space_group_info.group():
      sr = s.as_rational()
      print(sr.r.elems, sr.t.elems)
    for s in space_group_info.group():
      print(s.r().num(), s.r().den(), s.t().num(), s.t().den())
    print()

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/trigonal_r_vs_tetragonal_i.py
"""
The rhombohedral space groups have two commonly used settings, using
two different basis systems: "hexagonal basis", and "rhombohedral
basis". This confused me (rwgk) for the longest time.

The best way to think about this is to compare to, e.g. the
tetragonal case, where you have two "Bravais types", "tetragonal P"
and "tetragonal I". Now, you can transform the tetragonal I groups to
a primitive setting. It is still the "tetragonal I Bravais type", just
in a primitive setting, which leads to "weird" unit cell parameters
that nobody wants to use.

In the trigonal system you'll find "trigonal P" and "trigonal R".
As in the case of the tetragonal I, you can convert the trigonal R
groups to a primitive setting. However, in contrast to the tetragonal
case, you get "nice" unit cell parameters.

See also: http://en.wikipedia.org/wiki/Bravais_lattice

Note that "trigonal P" and "hexagonal P" are the same Bravais type.
"""
from __future__ import absolute_import, division, print_function

from cctbx import crystal
import sys

def run(args):
  assert len(args) == 0
  #
  print('This is the "tetragonal I" setting humans like:')
  tetragonal_i = crystal.symmetry(
    unit_cell=(10,10,13,90,90,90),
    space_group_symbol="I4")
  tetragonal_i.show_summary()
  print()
  print('Exact same symmetry, but using a basis system that is not very')
  print('accessible to humans:')
  cb_op = tetragonal_i.change_of_basis_op_to_primitive_setting()
  print('Change of basis:', cb_op)
  tetragonal_i.change_basis(cb_op=cb_op).show_summary()
  print()
  #
  print('This is the "trigonal R" setting most humans like best:')
  trigonal_r = crystal.symmetry(
    unit_cell=(10,10,13,90,90,120),
    space_group_symbol="R3")
  trigonal_r.show_summary()
  print()
  print('Same symmetry, sometimes preferred:')
  cb_op = trigonal_r.change_of_basis_op_to_primitive_setting()
  print('Change of basis:', cb_op)
  trigonal_r.change_basis(cb_op).show_summary()
  print()

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/examples/tst_exp_i_alpha_derivatives.py
from __future__ import absolute_import, division, print_function
from cctbx.examples.exp_i_alpha_derivatives \
  import least_squares, exp_i_alpha_sum
from libtbx.test_utils import approx_equal
import random
import math
from six.moves import cStringIO as StringIO
import sys
from six.moves import range
from six.moves import zip

random.seed(0)

def d_target_d_alphas_finite(obs, alphas, eps=1.e-8):
  result = []
  for i_alpha in range(len(alphas)):
    alphas_eps = list(alphas)
    ts = []
    for signed_eps in [eps, -eps]:
      alphas_eps[i_alpha] = alphas[i_alpha] + signed_eps
      exp_sum = exp_i_alpha_sum(alphas=alphas_eps)
      target = least_squares(obs=obs, calc=exp_sum.f())
      ts.append(target.f())
    result.append((ts[0]-ts[1])/(2*eps))
  return result

def d2_target_d_alphas_finite(obs, alphas, eps=1.e-8):
  result = []
  for i_alpha in range(len(alphas)):
    alphas_eps = list(alphas)
    gs = []
    for signed_eps in [eps, -eps]:
      alphas_eps[i_alpha] = alphas[i_alpha] + signed_eps
      exp_sum = exp_i_alpha_sum(alphas=alphas_eps)
      target = least_squares(obs=obs, calc=exp_sum.f())
      dalphas = exp_sum.d_target_d_alphas(target=target)
      gs.append(dalphas)
    result.append([(gp-gm)/(2*eps) for gp,gm in zip(gs[0],gs[1])])
  return result

def compare_analytical_and_finite(obs, alphas, out):
  grads_fin = d_target_d_alphas_finite(obs=obs, alphas=alphas)
  print("grads_fin:", grads_fin, file=out)
  exp_sum = exp_i_alpha_sum(alphas=alphas)
  target = least_squares(obs=obs, calc=exp_sum.f())
  grads_ana = exp_sum.d_target_d_alphas(target=target)
  print("grads_ana:", grads_ana, file=out)
  assert approx_equal(grads_ana, grads_fin)
  curvs_fin = d2_target_d_alphas_finite(obs=obs, alphas=alphas)
  print("curvs_fin:", curvs_fin, file=out)
  curvs_ana = exp_sum.d2_target_d_alphas(target=target)
  print("curvs_ana:", curvs_ana, file=out)
  assert approx_equal(curvs_ana, curvs_fin)
  print(file=out)

def exercise(args):
  verbose =  "--verbose" in args
  if (not verbose):
    out = StringIO()
  else:
    out = sys.stdout
  for n_alphas in range(2,5):
    for i_trial in range(5):
      alphas = [2*math.pi*random.random() for i in range(n_alphas)]
      exp_sum = exp_i_alpha_sum(alphas=alphas)
      obs = abs(exp_sum.f())
      compare_analytical_and_finite(
        obs=obs,
        alphas=alphas,
        out=out)
      compare_analytical_and_finite(
        obs=obs*(random.random()+0.5),
        alphas=alphas,
        out=out)
  for obs in [0, 0.1]:
    for calc in [0j, 1.e-200j]:
      target = least_squares(obs=obs, calc=calc)
      assert target.f() == obs**2
      assert target.da() == 0
      assert target.db() == 0
      if (obs == 0):
        assert target.daa() == 2
        assert target.dbb() == 2
        assert target.dab() == 0
      else:
        assert target.daa() == -1.e160
        assert target.dbb() == -1.e160
        assert target.dab() == 1.e160
    calc = 1+1j
    while (calc != 0):
      target = least_squares(obs=obs, calc=calc)
      # exercise numerical stability without checking the results
      target.f()
      target.da()
      target.db()
      target.daa()
      target.dbb()
      target.dab()
      calc /= 2
  print("OK")

if (__name__ == "__main__"):
  exercise(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/examples/tst_g_exp_i_alpha_derivatives.py
from __future__ import absolute_import, division, print_function
from cctbx.examples.g_exp_i_alpha_derivatives \
  import parameters, gradients, pack_gradients, g_exp_i_alpha_sum
from cctbx.examples.exp_i_alpha_derivatives import least_squares
from libtbx.test_utils import approx_equal
import random
import math
import copy
from six.moves import cStringIO as StringIO
import sys
from six.moves import range
from six.moves import zip

random.seed(0)

def d_target_d_params_finite(obs, params, eps=1.e-8):
  result = []
  params_eps = copy.deepcopy(params)
  for i_param in range(len(params)):
    dx = []
    for ix in range(4):
      ts = []
      for signed_eps in [eps, -eps]:
        pi_eps = params[i_param].as_list()
        pi_eps[ix] += signed_eps
        params_eps[i_param] = parameters(*pi_eps)
        exp_sum = g_exp_i_alpha_sum(params=params_eps)
        target = least_squares(obs=obs, calc=exp_sum.f())
        ts.append(target.f())
      dx.append((ts[0]-ts[1])/(2*eps))
    result.append(gradients(*dx))
    params_eps[i_param] = params[i_param]
  return result

def d2_target_d_params_finite(obs, params, eps=1.e-8):
  result = []
  params_eps = copy.deepcopy(params)
  for i_param in range(len(params)):
    for ix in range(4):
      gs = []
      for signed_eps in [eps, -eps]:
        pi_eps = params[i_param].as_list()
        pi_eps[ix] += signed_eps
        params_eps[i_param] = parameters(*pi_eps)
        exp_sum = g_exp_i_alpha_sum(params=params_eps)
        target = least_squares(obs=obs, calc=exp_sum.f())
        dp = exp_sum.d_target_d_params(target=target)
        gs.append(pack_gradients(dp))
      result.append([(gp-gm)/(2*eps) for gp,gm in zip(gs[0],gs[1])])
    params_eps[i_param] = params[i_param]
  return result

def compare_analytical_and_finite(obs, params, out):
  grads_fin = d_target_d_params_finite(obs=obs, params=params)
  print("grads_fin:", pack_gradients(grads_fin), file=out)
  exp_sum = g_exp_i_alpha_sum(params=params)
  target = least_squares(obs=obs, calc=exp_sum.f())
  grads_ana = exp_sum.d_target_d_params(target=target)
  print("grads_ana:", pack_gradients(grads_ana), file=out)
  assert approx_equal(pack_gradients(grads_ana), pack_gradients(grads_fin))
  curvs_fin = d2_target_d_params_finite(obs=obs, params=params)
  print("curvs_fin:", curvs_fin, file=out)
  curvs_ana = list(exp_sum.d2_target_d_params(target=target))
  print("curvs_ana:", curvs_ana, file=out)
  assert approx_equal(curvs_ana, curvs_fin)
  print(file=out)

def exercise(args):
  verbose =  "--verbose" in args
  if (not verbose):
    out = StringIO()
  else:
    out = sys.stdout
  for n_params in range(2,5):
    for i_trial in range(5):
      params = []
      for i in range(n_params):
        params.append(parameters(
          g=(random.random()-0.5)*2,
          ffp=(random.random()-0.5)*2,
          fdp=(random.random()-0.5)*2,
          alpha=2*math.pi*random.random()))
      exp_sum = g_exp_i_alpha_sum(params=params)
      obs = abs(exp_sum.f())
      compare_analytical_and_finite(
        obs=obs,
        params=params,
        out=out)
      compare_analytical_and_finite(
        obs=obs*(random.random()+0.5),
        params=params,
        out=out)
  print("OK")

if (__name__ == "__main__"):
  exercise(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/examples/tst_phase_o_phrenia.py
from __future__ import absolute_import, division, print_function
from cctbx.examples import phase_o_phrenia
from cctbx.development import random_structure
from cctbx.development import debug_utils
import sys

def exercise(space_group_info, n_scatterers=1, d_min=2, verbose=0):
  structure = random_structure.xray_structure(
    space_group_info,
    elements=["Hg"]*n_scatterers,
    volume_per_atom=500,
    min_distance=2.,
    general_positions_only=True)
  if (1 or verbose):
    structure.show_summary().show_scatterers()
  reduced_peaks = phase_o_phrenia.calculate_exp_i_two_phi_peaks(
    structure, d_min, min_peak_distance=3, max_reduced_peaks=20)
  for peak in reduced_peaks:
    print("%.6g" % peak.height, "%8.5f %8.5f %8.5f" % peak.site)

def run_call_back(flags, space_group_info):
  exercise(space_group_info, verbose=flags.Verbose)

def run():
  debug_utils.parse_options_loop_space_groups(sys.argv[1:], run_call_back)

if (__name__ == "__main__"):
  run()


 *******************************************************************************


 *******************************************************************************
cctbx/examples/tst_space_subgroups.py
from __future__ import absolute_import, division, print_function
from cctbx.examples import space_subgroups
import sys

def exercise(args):
  assert len(args) == 0
  space_subgroups.run(args=["1", "P1"])
  space_subgroups.run(args=["2", "P1"])
  space_subgroups.run(args=["2", "Pnnn:1"])
  space_subgroups.run(args=["2", "Fmmm"])
  print("OK")

if (__name__ == "__main__"):
  exercise(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/examples/tst_structure_factor_derivatives.py
from __future__ import absolute_import, division, print_function
from cctbx.examples.structure_factor_derivatives \
  import parameters, gradients, pack_gradients, structure_factor
from cctbx.examples.exp_i_alpha_derivatives import least_squares
from libtbx.test_utils import approx_equal
import random
import copy
from six.moves import cStringIO as StringIO
import sys
from six.moves import range
from six.moves import zip

random.seed(0)

def d_target_d_params_finite(obs, hkl, d_star_sq, params, eps=1.e-8):
  result = []
  params_eps = copy.deepcopy(params)
  for i_param in range(len(params)):
    dx = []
    for ix in range(7):
      ts = []
      for signed_eps in [eps, -eps]:
        pi_eps = params[i_param].as_list()
        pi_eps[ix] += signed_eps
        params_eps[i_param] = parameters(pi_eps[:3], *pi_eps[3:])
        sf = structure_factor(hkl=hkl, d_star_sq=d_star_sq, params=params_eps)
        target = least_squares(obs=obs, calc=sf.f())
        ts.append(target.f())
      dx.append((ts[0]-ts[1])/(2*eps))
    result.append(gradients(dx[:3], *dx[3:]))
    params_eps[i_param] = params[i_param]
  return result

def d2_target_d_params_finite(obs, hkl, d_star_sq, params, eps=1.e-8):
  result = []
  params_eps = copy.deepcopy(params)
  for i_param in range(len(params)):
    for ix in range(7):
      gs = []
      for signed_eps in [eps, -eps]:
        pi_eps = params[i_param].as_list()
        pi_eps[ix] += signed_eps
        params_eps[i_param] = parameters(pi_eps[:3], *pi_eps[3:])
        sf = structure_factor(hkl=hkl, d_star_sq=d_star_sq, params=params_eps)
        target = least_squares(obs=obs, calc=sf.f())
        dp = sf.d_target_d_params(target=target)
        gs.append(pack_gradients(dp))
      result.append([(gp-gm)/(2*eps) for gp,gm in zip(gs[0],gs[1])])
    params_eps[i_param] = params[i_param]
  return result

def compare_analytical_and_finite(obs, hkl, d_star_sq, params, out):
  grads_fin = d_target_d_params_finite(
    obs=obs, hkl=hkl, d_star_sq=d_star_sq, params=params)
  print("grads_fin:", pack_gradients(grads_fin), file=out)
  sf = structure_factor(hkl=hkl, d_star_sq=d_star_sq, params=params)
  target = least_squares(obs=obs, calc=sf.f())
  grads_ana = sf.d_target_d_params(target=target)
  print("grads_ana:", pack_gradients(grads_ana), file=out)
  assert approx_equal(pack_gradients(grads_ana), pack_gradients(grads_fin))
  curvs_fin = d2_target_d_params_finite(
    obs=obs, hkl=hkl, d_star_sq=d_star_sq, params=params)
  print("curvs_fin:", curvs_fin, file=out)
  curvs_ana = sf.d2_target_d_params(target=target)
  print("curvs_ana:", curvs_ana, file=out)
  assert approx_equal(curvs_ana, curvs_fin, 1.e-5)
  print(file=out)

def exercise(args):
  verbose =  "--verbose" in args
  if (not verbose):
    out = StringIO()
  else:
    out = sys.stdout
  hkl = (1,2,3)
  d_star_sq = 1e-3
  for n_params in range(2,5):
    for i_trial in range(5):
      params = []
      for i in range(n_params):
        params.append(parameters(
          xyz=[random.random() for i in range(3)],
          u=random.random()*0.1,
          w=random.random(),
          fp=(random.random()-0.5)*2,
          fdp=(random.random()-0.5)*2))
      sf = structure_factor(hkl=hkl, d_star_sq=d_star_sq, params=params)
      obs = abs(sf.f())
      compare_analytical_and_finite(
        obs=obs,
        hkl=hkl,
        d_star_sq=d_star_sq,
        params=params,
        out=out)
      compare_analytical_and_finite(
        obs=obs*(random.random()+0.5),
        hkl=hkl,
        d_star_sq=d_star_sq,
        params=params,
        out=out)
  print("OK")

if (__name__ == "__main__"):
  exercise(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/examples/tst_structure_factor_derivatives_2.py
from __future__ import absolute_import, division, print_function
from cctbx import xray
from cctbx import miller
from cctbx import crystal
from cctbx.examples.structure_factor_derivatives_2 \
  import scatterer_as_list, scatterer_from_list, structure_factors
from cctbx.examples.exp_i_alpha_derivatives import least_squares
from cctbx.array_family import flex
from libtbx.test_utils import approx_equal
import random
from six.moves import cStringIO as StringIO
import sys
from six.moves import range
from six.moves import zip

random.seed(0)
flex.set_random_seed(0)

def d_target_d_params_finite(f_obs, xray_structure, eps=1.e-8):
  result = flex.double()
  scatterers = xray_structure.scatterers()
  xray_structure_eps = xray_structure.deep_copy_scatterers()
  scatterers_eps = xray_structure_eps.scatterers()
  for i_scatterer in range(len(scatterers)):
    dx = []
    for ix in range(7):
      ts = []
      for signed_eps in [eps, -eps]:
        si_eps = scatterer_as_list(scatterers[i_scatterer])
        si_eps[ix] += signed_eps
        scatterers_eps[i_scatterer] = scatterer_from_list(si_eps)
        sf = structure_factors(
          xray_structure=xray_structure_eps, miller_set=f_obs)
        sum_target_f = 0
        for obs,f in zip(f_obs.data(), sf.fs()):
          target = least_squares(obs=obs, calc=f)
          sum_target_f += target.f()
        ts.append(sum_target_f)
      result.append((ts[0]-ts[1])/(2*eps))
    scatterers_eps[i_scatterer] = scatterers[i_scatterer]
  return result

def d2_target_d_params_finite(f_obs, xray_structure, eps=1.e-8):
  result = flex.double()
  scatterers = xray_structure.scatterers()
  xray_structure_eps = xray_structure.deep_copy_scatterers()
  scatterers_eps = xray_structure_eps.scatterers()
  for i_scatterer in range(len(scatterers)):
    for ix in range(7):
      gs = []
      for signed_eps in [eps, -eps]:
        si_eps = scatterer_as_list(scatterers[i_scatterer])
        si_eps[ix] += signed_eps
        scatterers_eps[i_scatterer] = scatterer_from_list(si_eps)
        sf = structure_factors(
          xray_structure=xray_structure_eps, miller_set=f_obs)
        dp = sf.d_target_d_params(f_obs=f_obs, target_type=least_squares)
        gs.append(dp)
      result.extend((gs[0]-gs[1])/(2*eps))
    scatterers_eps[i_scatterer] = scatterers[i_scatterer]
  return result

def compare_analytical_and_finite(f_obs, xray_structure, out):
  grads_fin = d_target_d_params_finite(
    f_obs=f_obs, xray_structure=xray_structure)
  print("grads_fin:", list(grads_fin), file=out)
  sf = structure_factors(
    xray_structure=xray_structure, miller_set=f_obs)
  grads_ana = sf.d_target_d_params(f_obs=f_obs, target_type=least_squares)
  print("grads_ana:", list(grads_ana), file=out)
  assert approx_equal(grads_ana, grads_fin)
  curvs_fin = d2_target_d_params_finite(
    f_obs=f_obs, xray_structure=xray_structure)
  print("curvs_fin:", list(curvs_fin), file=out)
  curvs_ana = sf.d2_target_d_params(f_obs=f_obs, target_type=least_squares)
  print("curvs_ana:", list(curvs_ana), file=out)
  assert approx_equal(curvs_ana, curvs_fin, 1.e-5)
  print(file=out)

def exercise(args):
  verbose =  "--verbose" in args
  if (not verbose):
    out = StringIO()
  else:
    out = sys.stdout
  crystal_symmetry = crystal.symmetry(
    unit_cell=(8,9,10,83,97,113),
    space_group_symbol="P1")
  miller_set = miller.set(
    crystal_symmetry=crystal_symmetry,
    indices=flex.miller_index([(1,2,3), (2,3,4), (-1,3,-2)]),
    anomalous_flag=False)
  for n_scatterers in range(2,2+5):
    for i_trial in range(5):
      scatterers = flex.xray_scatterer()
      for i in range(n_scatterers):
        scatterers.append(xray.scatterer(
          site=[random.random() for i in range(3)],
          u=random.random()*0.1,
          occupancy=random.random(),
          scattering_type="const",
          fp=(random.random()-0.5)*2,
          fdp=(random.random()-0.5)*2))
      xray_structure = xray.structure(
        crystal_symmetry=crystal_symmetry,
        scatterers=scatterers)
      sf = structure_factors(
        xray_structure=xray_structure,
        miller_set=miller_set)
      f_calc = miller_set.structure_factors_from_scatterers(
        xray_structure=xray_structure,
        algorithm="direct",
        cos_sin_table=False).f_calc()
      assert approx_equal(sf.fs(), f_calc.data())
      f_obs = miller_set.array(data=flex.abs(sf.fs()))
      compare_analytical_and_finite(
        f_obs=f_obs,
        xray_structure=xray_structure,
        out=out)
      compare_analytical_and_finite(
        f_obs=f_obs.customized_copy(
          data=f_obs.data()*(flex.random_double(size=f_obs.size())+0.5)),
        xray_structure=xray_structure,
        out=out)
  print("OK")

if (__name__ == "__main__"):
  exercise(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/examples/tst_structure_factor_derivatives_3.py
from __future__ import absolute_import, division, print_function
from cctbx import miller
from cctbx.examples.structure_factor_derivatives_3 \
  import scatterer_as_list, scatterer_from_list, structure_factors
from cctbx.examples.exp_i_alpha_derivatives import least_squares
from cctbx.array_family import flex
from cctbx.development import random_structure
from cctbx.development import debug_utils
from libtbx.test_utils import approx_equal
import random
from six.moves import cStringIO as StringIO
import sys
from six.moves import range
from six.moves import zip

random.seed(0)
flex.set_random_seed(0)

def d_target_d_params_finite(f_obs, xray_structure, eps=1.e-8):
  result = flex.double()
  scatterers = xray_structure.scatterers()
  xray_structure_eps = xray_structure.deep_copy_scatterers()
  scatterers_eps = xray_structure_eps.scatterers()
  for i_scatterer in range(len(scatterers)):
    if (not scatterers[i_scatterer].flags.use_u_aniso()):
      np = 7
    else:
      np = 12
    dx = []
    for ix in range(np):
      ts = []
      for signed_eps in [eps, -eps]:
        si_eps = scatterer_as_list(scatterers[i_scatterer])
        si_eps[ix] += signed_eps
        scatterers_eps[i_scatterer] = scatterer_from_list(si_eps)
        sf = structure_factors(
          xray_structure=xray_structure_eps, miller_set=f_obs)
        sum_target_f = 0
        for obs,f in zip(f_obs.data(), sf.fs()):
          target = least_squares(obs=obs, calc=f)
          sum_target_f += target.f()
        ts.append(sum_target_f)
      result.append((ts[0]-ts[1])/(2*eps))
    scatterers_eps[i_scatterer] = scatterers[i_scatterer]
  return result

def d2_target_d_params_finite(f_obs, xray_structure, eps=1.e-8):
  result = flex.double()
  scatterers = xray_structure.scatterers()
  xray_structure_eps = xray_structure.deep_copy_scatterers()
  scatterers_eps = xray_structure_eps.scatterers()
  for i_scatterer in range(len(scatterers)):
    if (not scatterers[i_scatterer].flags.use_u_aniso()):
      np = 7
    else:
      np = 12
    dx = []
    for ix in range(np):
      gs = []
      for signed_eps in [eps, -eps]:
        si_eps = scatterer_as_list(scatterers[i_scatterer])
        si_eps[ix] += signed_eps
        scatterers_eps[i_scatterer] = scatterer_from_list(si_eps)
        sf = structure_factors(
          xray_structure=xray_structure_eps, miller_set=f_obs)
        dp = sf.d_target_d_params(f_obs=f_obs, target_type=least_squares)
        gs.append(dp)
      result.extend((gs[0]-gs[1])/(2*eps))
    scatterers_eps[i_scatterer] = scatterers[i_scatterer]
  return result

def compare_analytical_and_finite(f_obs, xray_structure, out):
  grads_fin = d_target_d_params_finite(
    f_obs=f_obs, xray_structure=xray_structure)
  print("grads_fin:", list(grads_fin), file=out)
  sf = structure_factors(
    xray_structure=xray_structure, miller_set=f_obs)
  grads_ana = sf.d_target_d_params(f_obs=f_obs, target_type=least_squares)
  print("grads_ana:", list(grads_ana), file=out)
  flex.compare_derivatives(grads_ana, grads_fin)
  curvs_fin = d2_target_d_params_finite(
    f_obs=f_obs, xray_structure=xray_structure)
  print("curvs_fin:", list(curvs_fin), file=out)
  curvs_ana = sf.d2_target_d_params(f_obs=f_obs, target_type=least_squares)
  print("curvs_ana:", list(curvs_ana), file=out)
  flex.compare_derivatives(curvs_ana.as_1d(), curvs_fin)
  print(file=out)

def exercise(
      space_group_info,
      use_u_aniso,
      anomalous_flag,
      max_n_indices=5,
      verbose=0):
  if (not verbose):
    out = StringIO()
  else:
    out = sys.stdout
  for n_scatterers in range(3,3+1):
    for i_trial in range(1):
      xray_structure = random_structure.xray_structure(
        space_group_info=space_group_info,
        elements=["const"]*n_scatterers,
        volume_per_atom=100,
        general_positions_only=True,
        random_f_prime_d_min=1,
        random_f_double_prime=anomalous_flag,
        use_u_aniso = use_u_aniso,
        use_u_iso = (not use_u_aniso),
        random_u_iso=True,
        random_u_iso_scale=0.3,
        random_occupancy=True)
      xray_structure.show_summary(f=out).show_scatterers(f=out)
      miller_set = miller.build_set(
        crystal_symmetry=xray_structure,
        anomalous_flag=anomalous_flag,
        d_min=max(1, min(xray_structure.unit_cell().parameters()[:3])/2.5))
      n_indices = miller_set.indices().size()
      if (n_indices > max_n_indices):
        miller_set = miller_set.select(
          flex.random_size_t(size=max_n_indices) % n_indices)
      sf = structure_factors(
        xray_structure=xray_structure,
        miller_set=miller_set)
      f_calc = miller_set.structure_factors_from_scatterers(
        xray_structure=xray_structure,
        algorithm="direct",
        cos_sin_table=False).f_calc()
      f_calc.show_summary(f=out)
      assert approx_equal(sf.fs(), f_calc.data())
      f_obs = miller_set.array(data=flex.abs(sf.fs()))
      compare_analytical_and_finite(
        f_obs=f_obs,
        xray_structure=xray_structure,
        out=out)
      compare_analytical_and_finite(
        f_obs=f_obs.customized_copy(
          data=f_obs.data()*(flex.random_double(size=f_obs.size())+0.5)),
        xray_structure=xray_structure,
        out=out)

def run_call_back(flags, space_group_info):
  if (flags.isotropic):
    use_u_aniso = [False]
  elif (flags.anisotropic):
    use_u_aniso = [True]
  else:
    use_u_aniso_flags = [False, True]
  for use_u_aniso in use_u_aniso_flags:
    exercise(
      space_group_info=space_group_info,
      use_u_aniso=use_u_aniso,
      anomalous_flag=True,
      verbose=flags.Verbose)

def run(args):
  debug_utils.parse_options_loop_space_groups(args, run_call_back, (
    "isotropic",
    "anisotropic"))

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************
