

 *******************************************************************************
cctbx/maptbx/__init__.py
"""Tools for map analysis and manipulation"""
from __future__ import absolute_import, division, print_function
import cctbx.sgtbx

import boost_adaptbx.boost.python as bp
from six.moves import range
from six.moves import zip
ext = bp.import_ext("cctbx_maptbx_ext")
from cctbx_maptbx_ext import *

from cctbx import crystal
from cctbx import sgtbx
from cctbx.array_family import flex
from scitbx import matrix
from scitbx.python_utils import dicts
from libtbx import adopt_init_args
from libtbx.utils import Sorry
import libtbx.load_env
import math
import sys, os
import scitbx.math
from cctbx import adptbx
from libtbx import group_args
from scitbx import fftpack
from libtbx.test_utils import approx_equal
from cctbx import uctbx
import scitbx.math

debug_peak_cluster_analysis = os.environ.get(
  "CCTBX_MAPTBX_DEBUG_PEAK_CLUSTER_ANALYSIS", "")

@bp.inject_into(connectivity)
class _():

  def get_blobs_boundaries_tuples(self):
    """
    get lists of minimum and maximum coordinates for each connected
    region.
    returns 2 lists of tuples: first is minimum, second is maximum coordinates.
    [(x0, y0, z0), (x1, y1, z1), ...] where 0, 1, ... - number of region
    """
    boundaries = self.get_blobs_boundaries()
    regs = self.regions()
    min_boundaries = []
    max_boundaries = []
    for i in range(len(regs)):
      minb = (boundaries[0, i, 0], boundaries[0, i, 1], boundaries[0, i, 2])
      maxb = (boundaries[1, i, 0], boundaries[1, i, 1], boundaries[1, i, 2])
      min_boundaries.append(minb)
      max_boundaries.append(maxb)
    return min_boundaries, max_boundaries

def smooth_map(map, crystal_symmetry, rad_smooth, method = "exp",
     non_negative = True):
  from cctbx import miller
  assert method in ["exp", "box_average", "top_hat"]
  map_smooth = None
  if (method == "exp"):
    f_map = miller.structure_factor_box_from_map(
      map              = map,
      crystal_symmetry = crystal_symmetry,
      include_000      = True)
    ddd = f_map.d_spacings().data()
    ddd.set_selected(ddd  ==  -1 , 1.e+10)  # d for (0, 0, 0) was set to -1
    ss = 1./flex.pow2(ddd) / 4.
    b_smooth = 8*math.pi**2*rad_smooth**2
    smooth_scale = flex.exp(-b_smooth*ss)
    f_map = f_map.array(data = f_map.data()*smooth_scale)
    from cctbx.maptbx import crystal_gridding
    cg = crystal_gridding(
      unit_cell             = crystal_symmetry.unit_cell(),
      space_group_info      = crystal_symmetry.space_group_info(),
      pre_determined_n_real = map.all())
    fft_map = miller.fft_map(
      crystal_gridding     = cg,
      fourier_coefficients = f_map)
    fft_map.apply_volume_scaling()
    map_smooth = fft_map.real_map_unpadded()
    if non_negative:
      map_smooth = map_smooth.set_selected(map_smooth<0., 0)

  elif (method  == "top_hat"):

    # use same grid as original
    from cctbx.maptbx import crystal_gridding
    cg = crystal_gridding(
        unit_cell = crystal_symmetry.unit_cell(),
        space_group_info = crystal_symmetry.space_group_info(),
        pre_determined_n_real = map.all())

    average_value = map.as_1d().min_max_mean().mean

    # Get structure factors with f_000
    f_map = miller.structure_factor_box_from_map(
      map              = map,
      crystal_symmetry = crystal_symmetry,
      include_000      = True)

    # The d_spacings get a value of -1 for the f000 term. Set it to a big number
    ddd = f_map.d_spacings().data()
    ddd.set_selected(ddd < 0, 1.e+10)
    d_min = f_map.d_min()

    # G-function for top hat (FT of top hat)
    #complete_set = f_map.complete_set(include_f000 = True)
    sphere_reciprocal = f_map.g_function(R=rad_smooth) # top hat function

    # FT (map) * FT(top hat) = FT (convolution of map and top hat)
    fourier_coeff = f_map.array(data=f_map.data()*sphere_reciprocal)

    # Convolution of map and top hat
    fft_map = fourier_coeff.fft_map(d_min = d_min, crystal_gridding = cg)
    fft_map.apply_volume_scaling()
    map_smooth = fft_map.real_map_unpadded()


    if non_negative:
      map_smooth = map_smooth.set_selected(map_smooth<0., 0)

  elif(method == "box_average"): # assume 0/1 binary map
    assert abs(flex.max(map)-1.)<1.e-6
    mmin = flex.min(map)
    assert mmin<1.e-6 and mmin>= 0.0
    map_smooth = map.deep_copy()
    for i in range(3):
      maptbx.map_box_average(
        map_data      = map_smooth,
        index_span    = 1)
    for i in range(3):
      maptbx.map_box_average(
        map_data      = map_smooth,
        cutoff        = 0.99,
        index_span    = 1)
  return map_smooth

class d99(object):
  def __init__(self, map = None, f_map = None, crystal_symmetry = None):
    adopt_init_args(self, locals())
    if(map is not None):
      assert f_map is None
      assert crystal_symmetry is not None
      map = shift_origin_if_needed(map_data = map).map_data
      from cctbx import miller
      self.f_map = miller.structure_factor_box_from_map(
        map = map, crystal_symmetry = crystal_symmetry)
    else:
      assert [map, crystal_symmetry].count(None) == 2
    self.d_spacings = self.f_map.d_spacings().data()
    self.d_max, self.d_min = flex.max(self.d_spacings), flex.min(self.d_spacings)
    o = ext.d99(
      f          = self.f_map.data(),
      d_spacings = self.d_spacings,
      hkl        = self.f_map.indices(),
      cutoff     = 0.99)
    self.result = group_args(
      d99 = o.d_min())

  def show(self, log):
    fmt = "%12.6f %8.6f"
    for d_min, cc in zip(self.result.d_mins, self.result.ccs):
      print(fmt%(d_min, cc), file = log)

def assert_same_gridding(map_1, map_2,
                         Sorry_message = "Maps have different gridding."):
  f1 = map_1.focus() == map_2.focus()
  f2 = map_1.origin() == map_2.origin()
  f3 = map_1.all() == map_2.all()
  if([f1, f2, f3].count(True)!= 3):
    raise Sorry(Sorry_message)

def shift_origin_if_needed(map_data = None,
    sites_cart = None,
    crystal_symmetry = None,
    ncs_object = None,
    origin_grid_units = None,
    n_xyz = None,
    ):

  if not map_data:
    assert origin_grid_units and n_xyz
    shift_needed = True

  else: # usual
    shift_needed = not \
    (map_data.focus_size_1d() > 0 and map_data.nd()  ==  3 and
     map_data.is_0_based())

  shift_frac = None
  shift_cart = None
  if(shift_needed):
    if map_data:
      N = map_data.all()
      O = map_data.origin()
      map_data = map_data.shift_origin()
    else:
      N = n_xyz
      O = origin_grid_units

    original_origin_grid_units = O
    original_origin_cart = (0, 0, 0)
    if crystal_symmetry:
      if(not crystal_symmetry.space_group().type().number() in [0, 1]):
        raise Sorry("Space groups other than P1 are not supported.")
      a, b, c = crystal_symmetry.unit_cell().parameters()[:3]
      fm = crystal_symmetry.unit_cell().fractionalization_matrix()
      sx, sy, sz = O[0]/N[0], O[1]/N[1], O[2]/N[2]
      shift_frac = [-sx, -sy, -sz]
      shift_cart = crystal_symmetry.unit_cell().orthogonalize(shift_frac)
      original_origin_cart = tuple(-matrix.col(shift_cart))
      if(sites_cart is not None):
        sites_cart = sites_cart + flex.vec3_double(sites_cart.size(), shift_cart)
      if ncs_object:
        ncs_object = ncs_object.deep_copy(coordinate_offset = shift_cart)
    else:
      original_origin_grid_units = None
      original_origin_cart = None
  else:
    original_origin_grid_units = (0, 0, 0)
    original_origin_cart = (0, 0, 0)
  return group_args(
    map_data   = map_data,
    ncs_object = ncs_object,
    sites_cart = sites_cart,
    shift_frac = shift_frac,
    shift_cart = shift_cart,
    original_origin_grid_units = original_origin_grid_units,
    original_origin_cart = original_origin_cart)

def value_at_closest_grid_point(map, x_frac):
  return map[closest_grid_point(map.accessor(), x_frac)]

flex.int.value_at_closest_grid_point = value_at_closest_grid_point
flex.double.value_at_closest_grid_point = value_at_closest_grid_point
flex.double.eight_point_interpolation = eight_point_interpolation
flex.double.eight_point_interpolation_with_gradients = \
  eight_point_interpolation_with_gradients
flex.double.quadratic_interpolation_with_gradients = \
  quadratic_interpolation_with_gradients
flex.double.tricubic_interpolation = tricubic_interpolation
flex.double.tricubic_interpolation_with_gradients = tricubic_interpolation_with_gradients

def cc_peak(cutoff, map_1 = None, map_2 = None, map_coeffs_1 = None, map_coeffs_2 = None):
  """
  Compute CCpeak as described in
    Acta Cryst. (2014). D70, 2593-2606
    Metrics for comparison of crystallographic maps
    A. Urzhumtsev, P. V. Afonine, V. Y. Lunin, T. C. Terwilliger and P. D. Adams
  """
  from cctbx import miller
  assert [map_1, map_2].count(None) in [0, 2]
  assert [map_coeffs_1, map_coeffs_2].count(None) in [0, 2]
  if([map_1, map_2].count(None) == 0):
    # Maps are assumed to be quantile rank scaled (HE).
    return ext.cc_peak(map_1 = map_1, map_2 = map_2, cutoff = cutoff)
  elif([map_coeffs_1, map_coeffs_2].count(None) == 0):
    d_min = min(map_coeffs_1.d_min(), map_coeffs_2.d_min())
    crystal_gridding = map_coeffs_1.crystal_gridding(
      d_min             = d_min,
      symmetry_flags    = use_space_group_symmetry,
      resolution_factor = 0.25)
    fft_map = miller.fft_map(
      crystal_gridding     = crystal_gridding,
      fourier_coefficients = map_coeffs_1)
    map_1 = fft_map.real_map_unpadded()
    fft_map = miller.fft_map(
      crystal_gridding     = crystal_gridding,
      fourier_coefficients = map_coeffs_2)
    map_2 = fft_map.real_map_unpadded()
    m1_he = volume_scale(map = map_1,  n_bins = 10000).map_data()
    m2_he = volume_scale(map = map_2,  n_bins = 10000).map_data()
    return ext.cc_peak(map_1 = m1_he, map_2 = m2_he, cutoff = cutoff)
  else:
    raise Sorry("Combination of inputs not supported.")

def map_accumulator(n_real, use_max_map, smearing_b = 5, max_peak_scale = 2,
                    smearing_span = 10, use_exp_table = True):
  """
  Good defaults for 2mFo-DFc type maps:
    smearing_b = 1, max_peak_scale = 100, smearing_span = 5
  """
  return ext.map_accumulator(n_real = n_real, smearing_b = smearing_b,
    max_peak_scale = max_peak_scale, smearing_span = smearing_span,
      use_exp_table = use_exp_table, use_max_map = use_max_map)

def peak_volume_estimate(map_data, sites_cart, crystal_symmetry, cutoff,
      atom_radius = 1.5):
  v = flex.double()
  sites_frac = crystal_symmetry.unit_cell().fractionalize(sites_cart)
  for sc, sf in zip(sites_cart, sites_frac):
    if(map_data.value_at_closest_grid_point(sf)>= cutoff):
      sel = grid_indices_around_sites(
        unit_cell  = crystal_symmetry.unit_cell(),
        fft_n_real = map_data.focus(),
        fft_m_real = map_data.all(),
        sites_cart = flex.vec3_double([sc]),
        site_radii = flex.double([atom_radius]*1))
      v.append((map_data.select(sel)>= cutoff).count(True))
  r = flex.min_default(v, None)
  if(r == 0): return None
  return r

def truncate(map_data, by_sigma_less_than, scale_by, set_value = 0):
  """
  Trunate map inplace by standard deviation (sigma) while scale it with
  specified scale, such as volume (scale_by = 1/volume) or sigma
  (scale_by = 1/standard_deviation). Input map_data is expected to be unscaled (
  right out of FT).
  """
  sigma = statistics(map_data).sigma()
  if(sigma  ==  0):
    map_data = map_data*scale_by
    return
  ext.truncate(
    map_data           = map_data,
    standard_deviation = sigma,
    by_sigma_less_than = by_sigma_less_than,
    scale_by           = scale_by,
    set_value          = set_value)

def mask(xray_structure,
         n_real,
         mask_value_inside_molecule = 0,
         mask_value_outside_molecule = 1,
         solvent_radius = 0,
         atom_radius = None):
  xrs_p1 = xray_structure.expand_to_p1(sites_mod_positive = True)
  if(atom_radius is None):
    from cctbx.masks import vdw_radii_from_xray_structure
    atom_radii = vdw_radii_from_xray_structure(xray_structure = xrs_p1)
  else:
    atom_radii = flex.double(xrs_p1.scatterers().size(), atom_radius)
  return ext.mask(
    sites_frac                  = xrs_p1.sites_frac(),
    unit_cell                   = xrs_p1.unit_cell(),
    n_real                      = n_real,
    mask_value_inside_molecule  = mask_value_inside_molecule,
    mask_value_outside_molecule = mask_value_outside_molecule,
    radii                       = atom_radii + solvent_radius)

class statistics(ext.statistics):

  def __init__(self, map):
    ext.statistics.__init__(self, map)

@bp.inject_into(ext.statistics)
class _():

  def show_summary(self, f = None, prefix = ""):
    if (f is None): f = sys.stdout
    print(prefix + "max %.6g" % (self.max()), file = f)
    print(prefix + "min %.6g" % (self.min()), file = f)
    print(prefix + "mean %.6g" % (self.mean()), file = f)
    print(prefix + "sigma %.6g" % (self.sigma()), file = f)

use_space_group_symmetry = sgtbx.search_symmetry_flags(
  use_space_group_symmetry = True)

@bp.inject_into(ext.histogram)
class _():

  """
  Injector for extending cctbx.maptbx.histogram
  """
  # XXX make a method of scitbx
  def get_percentile_cutoffs(self, map, vol_cutoff_plus_percent,
      vol_cutoff_minus_percent):
    """
    For the double-step filtration in cctbx.miller (used as part of the
    procedure for replacing missing F-obs in maps), we need to calculate upper
    and lower cutoffs for the data based on percentile values.  This can be
    done in just a few lines of code by using flex.sort_permutation over the
    entire map, but this has a huge memory overhead (and possibly computational
    overhead as well).  Since we are only interested in subsets of values at
    the extreme ends of the distribution, we can perform the sort for these
    subsets instead, which should cut down on memory use.

    Returns the upper and lower map value cutoffs (as Python floats).
    """
    map_values = map.as_1d()
    size = map_values.size()
    # upper limit
    i_bin_plus = -1
    for i_bin, value in enumerate(self.v_values()):
      if ((value*100) <=  vol_cutoff_plus_percent):
        i_bin_plus = i_bin - 1
        break
    assert (i_bin_plus >=  0)
    cutoffp_lower_limit = self.arguments()[i_bin_plus]
    top_values = map_values.select(map_values >=  cutoffp_lower_limit)
    i_upper = min(int(size * (vol_cutoff_plus_percent / 100.)),
                  top_values.size())
    s = flex.sort_permutation(top_values)
    top_values_sorted = top_values.select(s)
    del s
    assert (top_values_sorted.size() >=  i_upper)
    cutoffp = top_values_sorted[-i_upper]
    del top_values
    del top_values_sorted
    # lower limit
    i_bin_minus = -1
    for i_bin, value in enumerate(self.c_values()):
      if ((value*100) > vol_cutoff_minus_percent):
        i_bin_minus = i_bin
        break
    assert (i_bin_minus >=  0)
    cutoffm_upper_limit = self.arguments()[i_bin_minus]
    bottom_values = map_values.select(map_values <=  cutoffm_upper_limit)
    i_lower = min(int(size * (vol_cutoff_minus_percent / 100.)),
                  bottom_values.size() - 1)
    s = flex.sort_permutation(bottom_values)
    bottom_values_sorted = bottom_values.select(s)
    del s
    assert (bottom_values_sorted.size() > i_lower)
    cutoffm = bottom_values_sorted[i_lower]
    del bottom_values
    del bottom_values_sorted
    return cutoffp, cutoffm

class peak_list(ext.peak_list):

  def __init__(self, data,
                     tags,
                     peak_search_level = 1,
                     max_peaks = 0,
                     peak_cutoff = None,
                     interpolate = True):
    if (peak_cutoff is None):
      ext.peak_list.__init__(self,
        data, tags, peak_search_level, max_peaks, interpolate)
    else:
      ext.peak_list.__init__(self,
        data, tags, peak_search_level, peak_cutoff, max_peaks, interpolate)

def as_CObjectZYX(map_unit_cell, first, last, apply_sigma_scaling = True):
  return ext.as_CObjectZYX(map_unit_cell, first, last, apply_sigma_scaling)

structure_factors = dicts.easy(
  to_map = structure_factors_to_map,
  from_map = structure_factors_from_map)

class crystal_gridding(object):

  def __init__(self, unit_cell,
                     d_min = None,
                     resolution_factor = None,
                     step = None,
                     symmetry_flags = None,
                     space_group_info = None,
                     mandatory_factors = None,
                     max_prime = 5,
                     assert_shannon_sampling = True,
                     pre_determined_n_real = None):
    if (pre_determined_n_real is None):
      assert [d_min, step].count(None)  ==  1
      if (step is not None):
        d_min = step*2
        resolution_factor = 0.5
      elif (resolution_factor is None):
        resolution_factor = 1/3
      if (symmetry_flags is not None): assert space_group_info is not None
      if (mandatory_factors is None): mandatory_factors = (1, 1, 1)
      assert len(mandatory_factors)  ==  3
    else:
      assert d_min is None
      assert step is None
      assert mandatory_factors is None
    adopt_init_args(self, locals(), hide = True)
    if (pre_determined_n_real is not None):
      self._n_real = pre_determined_n_real
    elif (symmetry_flags is not None):
      self._n_real = determine_gridding(
        unit_cell, d_min, resolution_factor,
        symmetry_flags, space_group_info.type(),
        mandatory_factors, max_prime, assert_shannon_sampling)
    else:
      self._n_real = determine_gridding(
        unit_cell, d_min, resolution_factor,
        mandatory_factors, max_prime, assert_shannon_sampling)

  def _copy_constructor(self, other):
    self._unit_cell = other._unit_cell
    self._d_min = other._d_min
    self._resolution_factor = other._resolution_factor
    self._symmetry_flags = other._symmetry_flags
    self._space_group_info = other._space_group_info
    self._mandatory_factors = other._mandatory_factors
    self._max_prime = other._max_prime
    self._n_real = other._n_real

  def unit_cell(self):
    return self._unit_cell

  def d_min(self):
    return self._d_min

  def resolution_factor(self):
    return self._resolution_factor

  def symmetry_flags(self):
    return self._symmetry_flags

  def space_group_info(self):
    return self._space_group_info

  def change_space_group(self, space_group_info):
    assert (space_group_info.group().refine_gridding(self.n_real())
             ==  self.n_real())
    self._space_group_info = space_group_info

  def mandatory_factors(self):
    return self._mandatory_factors

  def max_prime(self):
    return self._max_prime

  def n_real(self):
    return self._n_real

  def space_group(self):
    assert self.space_group_info() is not None
    return self.space_group_info().group()

  def crystal_symmetry(self):
    assert self.space_group_info() is not None
    return crystal.symmetry(
      unit_cell = self.unit_cell(),
      space_group_info = self.space_group_info())

  def n_grid_points(self):
    result = 1
    for n in self.n_real():
      result *=  n
    return result

  def tags(self):
    return crystal_gridding_tags(self)

class crystal_gridding_tags(crystal_gridding):

  def __init__(self, gridding):
    crystal_gridding._copy_constructor(self, gridding)
    assert gridding.symmetry_flags() is not None
    self._tags = grid_tags(dim = self.n_real())
    self._tags.build(
      space_group_type = self.space_group_info().type(),
      symmetry_flags = self.symmetry_flags())
    assert self._tags.n_grid_misses()  ==  0

  def tags(self):
    return self._tags

  def peak_search(self, parameters, map, verify_symmetry = True):
    if (parameters is None):
      parameters = peak_search_parameters()
    if (verify_symmetry and libtbx.env.full_testing):
      assert self._tags.verify(map)
    if (map.accessor().is_padded()):
      map = copy(map, flex.grid(map.focus()))
    grid_peaks = peak_list(
      data = map,
      tags = self._tags.tag_array(),
      peak_search_level = parameters.peak_search_level(),
      max_peaks = parameters.max_peaks(),
      peak_cutoff = parameters.peak_cutoff(),
      interpolate = parameters.interpolate())
    if (parameters.min_distance_sym_equiv() is None):
      return grid_peaks
    return peak_cluster_analysis(
      peak_list = grid_peaks,
      special_position_settings = crystal.special_position_settings(
        crystal_symmetry = self.crystal_symmetry(),
        min_distance_sym_equiv = parameters.min_distance_sym_equiv()),
      general_positions_only = parameters.general_positions_only(),
      effective_resolution = parameters.effective_resolution(),
      significant_height_fraction = parameters.significant_height_fraction(),
      cluster_height_fraction = parameters.cluster_height_fraction(),
      min_cross_distance = parameters.min_cross_distance(),
      max_clusters = parameters.max_clusters(),
      min_cubicle_edge = parameters.min_cubicle_edge())

class boxes_by_dimension(object):
  def __init__(self,
               n_real,
               abc,
               dim,
               log = None,
               prefix = ""):
    self.n_real = n_real
    #
    step_1 = abc[0]/n_real[0] # step size along edge
    step_2 = abc[1]/n_real[1] # step size along edge
    step_3 = abc[2]/n_real[2] # step size along edge
    i_step_1 = int(dim/step_1) # points per box edge
    i_step_2 = int(dim/step_2) # points per box edge
    i_step_3 = int(dim/step_3) # points per box edge
    #
    n_boxes = self._generate_boxes(i_step_1, i_step_2, i_step_3)
    assert n_boxes  ==  len(self.starts)

  def _generate_boxes(self, ba, bb, bc):
    def regroup(be):
      maxe = be[len(be)-1][1]
      step = int(maxe/len(be))
      result = []
      for i in range(len(be)):
        if(i == 0):
          l = 0
          r = step
        elif(i == len(be)-1):
          l = i*step
          r = maxe
        else:
          l = i*step
          r = (i+1)*step
        result.append([l, r])
      return result
    be = []
    for i, b in enumerate([ba, bb, bc]):
      be_ = self._box_edges(n_real_1d = self.n_real[i], step = b)
      be_ = regroup(be_)
      be.append(be_)
    self.starts = []
    self.ends = []
    for i in be[0]:
      for j in be[1]:
        for k in be[2]:
          self.starts.append([i[0], j[0], k[0]])
          self.ends.append([i[1], j[1], k[1]])
    return len(self.starts)

  def _box_edges(self, n_real_1d, step):
    limits = []
    for i in range(0, n_real_1d, step): limits.append(i)
    limits.append(n_real_1d)
    box_1d = []
    for i in range(len(limits)):
      if(i == 0):               box_1d.append([limits[0],  limits[1]])
      elif(i!= len(limits)-1): box_1d.append([limits[i], limits[i+1]])
    return box_1d

class boxes(object):
  """
  Split box defined by n_real into boxes where each box is a fraction of the
  whole box.
  """
  def __init__(self,
               n_real,
               fraction = None,
               log = None,
               max_boxes = 2000,
               prefix = ""):
    self.n_real = n_real
    i = 0
    n_boxes = 1.e+9
    n_boxes_ = []
    while n_boxes>max_boxes:
      ba, bb, bc = \
        min(10+i, max(3, int(n_real[0]*fraction))), \
        min(10+i, max(3, int(n_real[1]*fraction))), \
        min(10+i, max(3, int(n_real[2]*fraction)))
      n_boxes = self._generate_boxes(ba, bb, bc)
      if(n_boxes_.count(n_boxes)>3): break
      n_boxes_.append(n_boxes)
      i +=  1
    assert n_boxes  ==  len(self.starts)
    if(log):
      print(prefix, "n1, n2, n3 (n_real)  :", n_real, file = log)
      print(prefix, "points per box edge:", ba, bb, bc, file = log)
      print(prefix, "number of boxes    :", len(self.starts), file = log)

  def _generate_boxes(self, ba, bb, bc):
    def regroup(be):
      maxe = be[len(be)-1][1]
      step = int(maxe/len(be))
      result = []
      for i in range(len(be)):
        if(i == 0):
          l = 0
          r = step
        elif(i == len(be)-1):
          l = i*step
          r = maxe
        else:
          l = i*step
          r = (i+1)*step
        result.append([l, r])
      return result
    be = []
    for i, b in enumerate([ba, bb, bc]):
      be_ = self._box_edges(n_real_1d = self.n_real[i], step = b)
      be_ = regroup(be_)
      be.append(be_)
    self.starts = []
    self.ends = []
    for i in be[0]:
      for j in be[1]:
        for k in be[2]:
          self.starts.append([i[0], j[0], k[0]])
          self.ends.append([i[1], j[1], k[1]])
    return len(self.starts)

  def _box_edges(self, n_real_1d, step):
    limits = []
    for i in range(0, n_real_1d, step): limits.append(i)
    limits.append(n_real_1d)
    box_1d = []
    for i in range(len(limits)):
      if(i == 0):               box_1d.append([limits[0],  limits[1]])
      elif(i!= len(limits)-1): box_1d.append([limits[i], limits[i+1]])
    return box_1d

class peak_search_parameters(object):

  def __init__(self, peak_search_level = 1,
                     max_peaks = 0,
                     peak_cutoff = None,
                     interpolate = True,
                     min_distance_sym_equiv = None,
                     general_positions_only = False,
                     effective_resolution = None,
                     significant_height_fraction = None,
                     cluster_height_fraction = None,
                     min_cross_distance = None,
                     max_clusters = None,
                     min_cubicle_edge = 5):
    adopt_init_args(self, locals(), hide = True)

  def _copy_constructor(self, other):
    self._peak_search_level = other._peak_search_level
    self._max_peaks = other._max_peaks
    self._peak_cutoff = other._peak_cutoff
    self._interpolate = other._interpolate
    self._min_distance_sym_equiv = other._min_distance_sym_equiv
    self._general_positions_only = other._general_positions_only
    self._effective_resolution = other._effective_resolution
    self._significant_height_fraction = other._significant_height_fraction
    self._cluster_height_fraction = other._cluster_height_fraction
    self._min_cross_distance = other._min_cross_distance
    self._max_clusters = other._max_clusters
    self._min_cubicle_edge = other._min_cubicle_edge

  def peak_search_level(self):
    return self._peak_search_level

  def max_peaks(self):
    return self._max_peaks

  def peak_cutoff(self):
    return self._peak_cutoff

  def interpolate(self):
    return self._interpolate

  def min_distance_sym_equiv(self):
    return self._min_distance_sym_equiv

  def general_positions_only(self):
    return self._general_positions_only

  def effective_resolution(self):
    return self._effective_resolution

  def significant_height_fraction(self):
    return self._significant_height_fraction

  def cluster_height_fraction(self):
    return self._cluster_height_fraction

  def min_cross_distance(self):
    return self._min_cross_distance

  def max_clusters(self):
    return self._max_clusters

  def min_cubicle_edge(self):
    return self._min_cubicle_edge

class cluster_site_info(object):

  def __init__(self, peak_list_index, grid_index, grid_height, site, height):
    self.peak_list_index = peak_list_index
    self.grid_index = grid_index
    self.grid_height = grid_height
    self.site = site
    self.height = height

class peak_cluster_analysis(object):

  def __init__(self, peak_list,
                     special_position_settings,
                     general_positions_only = False,
                     effective_resolution = None,
                     significant_height_fraction = None,
                     cluster_height_fraction = None,
                     min_cross_distance = None,
                     max_clusters = None,
                     min_cubicle_edge = 5):
    if (effective_resolution is not None):
      if (significant_height_fraction is None):
          significant_height_fraction = 1/5
      if (cluster_height_fraction is None):
          cluster_height_fraction = 1/3
    if (min_cross_distance is None):
        min_cross_distance = special_position_settings.min_distance_sym_equiv()
    adopt_init_args(self, locals(), hide = True)
    assert self._min_cross_distance is not None
    self._gridding = peak_list.gridding()
    if (effective_resolution is not None):
      self._is_processed = flex.bool(peak_list.size(), False)
    else:
      self._is_processed = None
    if (   effective_resolution is not None
        or debug_peak_cluster_analysis  ==  "use_old"):
      self._site_cluster_analysis = None
    else:
      self._site_cluster_analysis = \
        self._special_position_settings.site_cluster_analysis(
          min_cross_distance = self._min_cross_distance,
          min_self_distance
             = self._special_position_settings.min_distance_sym_equiv(),
          general_positions_only = self._general_positions_only,
          min_cubicle_edge = self._min_cubicle_edge)
    self._peak_list_indices = flex.size_t()
    self._peak_list_index = 0
    self._sites = flex.vec3_double()
    self._heights = flex.double()
    self._fixed_site_indices = flex.size_t()

  def __next__(self):
    if (self._effective_resolution is not None):
      return self.next_with_effective_resolution()
    else:
      return self.next_site_cluster_analysis()

  next = __next__

  def all(self, max_clusters = None):
    if (self._effective_resolution is not None):
      return self.all_with_effective_resolution(max_clusters = max_clusters)
    else:
      return self.all_site_cluster_analysis(max_clusters = max_clusters)

  def __iter__(self):
    while 1:
      site_info = next(self)
      if site_info is None: break
      yield site_info

  def peak_list(self):
    return self._peak_list

  def special_position_settings(self):
    return self._special_position_settings

  def general_positions_only(self):
    return self._general_positions_only

  def effective_resolution(self):
    return self._effective_resolution

  def significant_height_fraction(self):
    return self._significant_height_fraction

  def cluster_height_fraction(self):
    return self._cluster_height_fraction

  def min_cross_distance(self):
    return self._min_cross_distance

  def max_clusters(self):
    return self._max_clusters

  def site_cluster_analysis(self):
    return self._site_cluster_analysis

  def peak_list_indices(self):
    return self._peak_list_indices

  def fixed_site_indices(self):
    return self._fixed_site_indices

  def sites(self):
    return self._sites

  def heights(self):
    return self._heights

  def max_grid_height(self):
    if (self._peak_list.size()  ==  0):
      return None
    return self._peak_list.heights()[0]

  def append_fixed_site(self, site, height = 0):
    if (self._site_cluster_analysis is not None):
      self._site_cluster_analysis.insert_fixed_site_frac(original_site = site)
    self._fixed_site_indices.append(self._sites.size())
    self._sites.append(site)
    self._heights.append(height)
    self._peak_list_indices.append(self._peak_list.size())

  def discard_last(self):
    assert self._peak_list_indices.size() > 0
    if (self._site_cluster_analysis is not None):
      self._site_cluster_analysis.discard_last()
    self._peak_list_indices.pop_back()
    self._sites.pop_back()
    self._heights.pop_back()

  def next_site_cluster_analysis(self):
    while 1:
      peak_list_index = self._peak_list_index
      if (peak_list_index >=  self._peak_list.size()): return None
      self._peak_list_index +=  1
      site_symmetry = self._special_position_settings.site_symmetry(
        site = self._peak_list.sites()[peak_list_index])
      site = site_symmetry.exact_site()
      if (not self._site_cluster_analysis.process_site_frac(
                original_site = site,
                site_symmetry_ops = site_symmetry)): continue
      height = self._peak_list.heights()[peak_list_index]
      self._peak_list_indices.append(peak_list_index)
      self._sites.append(site)
      self._heights.append(height)
      return cluster_site_info(
        peak_list_index = peak_list_index,
        grid_index = self._peak_list.grid_indices(peak_list_index),
        grid_height = self._peak_list.grid_heights()[peak_list_index],
        site = site,
        height = height)

  def all_site_cluster_analysis(self, max_clusters = None):
    if (max_clusters is None):
      max_clusters = self._max_clusters
    assert max_clusters is not None
    while 1:
      if (self._sites.size() >=  max_clusters): break
      if (self.next_site_cluster_analysis() is None): break
    return self

  def next_with_effective_resolution(self):
    while 1:
      peak_list_index = self._peak_list_index
      if (peak_list_index >=  self._peak_list.size()): return None
      self._peak_list_index +=  1
      if (self._is_processed is not None):
        if (self._is_processed[peak_list_index]): continue
        self._is_processed[peak_list_index] = True
      grid_index = self._peak_list.grid_indices(peak_list_index)
      grid_height = self._peak_list.grid_heights()[peak_list_index]
      site = self._peak_list.sites()[peak_list_index]
      height = self._peak_list.heights()[peak_list_index]
      site_symmetry = self._special_position_settings.site_symmetry(site)
      if (    self._general_positions_only
          and not site_symmetry.is_point_group_1()):
        continue
      site = site_symmetry.exact_site()
      equiv_sites = sgtbx.sym_equiv_sites(site_symmetry)
      keep = True
      if (self._sites.size() > 250):
        import warnings
        warnings.warn(
          message = "This function should not be used for"
                  " processing a large number of peaks.",
          category = RuntimeWarning)
      for s in self._sites:
        dist = sgtbx.min_sym_equiv_distance_info(equiv_sites, s).dist()
        if (dist < self._min_cross_distance):
          keep = False
          break
      if (keep  ==  True):
        if (    self._effective_resolution is not None
            and (   self._heights.size()  ==  0
                 or height <   self._heights[0]
                             * self._significant_height_fraction)):
            site, height = self._accumulate_significant(
              site, height, site_symmetry, equiv_sites)
        self._peak_list_indices.append(peak_list_index)
        self._sites.append(site)
        self._heights.append(height)
        return cluster_site_info(
          peak_list_index = peak_list_index,
          grid_index = grid_index,
          grid_height = grid_height,
          site = site,
          height = height)

  def _accumulate_significant(self, site, height, site_symmetry, equiv_sites):
    unit_cell = self.special_position_settings().unit_cell()
    orth = unit_cell.orthogonalize
    frac = unit_cell.fractionalize
    sum_w_sites = matrix.col(orth(site)) * height
    sum_w = height
    height_cutoff = height * self._cluster_height_fraction
    for i in range(self._peak_list_index, self._peak_list.size()):
      if (self._is_processed[i]): continue
      other_height = self._peak_list.heights()[i]
      if (other_height < height_cutoff): break
      other_site = self._peak_list.sites()[i]
      other_site_symmetry = self._special_position_settings.site_symmetry(
        other_site)
      if (    self._general_positions_only
          and not other_site_symmetry.is_point_group_1()):
        self._is_processed[i] = True
        continue
      other_site = other_site_symmetry.exact_site()
      dist_info = sgtbx.min_sym_equiv_distance_info(equiv_sites, other_site)
      dist = dist_info.dist()
      if (dist < self._min_cross_distance):
        self._is_processed[i] = True
        close_site = dist_info.apply(flex.vec3_double([other_site]))[0]
        close_site = site_symmetry.special_op() * close_site
        sum_w_sites +=  matrix.col(orth(close_site)) * other_height
        sum_w +=  other_height
    return frac(sum_w_sites / sum_w), height

  def all_with_effective_resolution(self, max_clusters = None):
    if (max_clusters is None):
      max_clusters = self._max_clusters
    assert max_clusters is not None
    while 1:
      if (self._sites.size() >=  max_clusters): break
      if (self.next_with_effective_resolution() is None): break
    return self

def region_density_correlation(
      large_unit_cell,
      large_d_min,
      large_density_map,
      sites_cart,
      site_radii,
      work_scatterers):
  sites_frac_large = large_unit_cell.fractionalize(sites_cart)
  large_frac_min = sites_frac_large.min()
  large_frac_max = sites_frac_large.max()
  large_n_real = large_density_map.focus()
  from scitbx import fftpack
  from libtbx.math_utils import ifloor, iceil
  large_ucp = large_unit_cell.parameters()
  small_n_real = [0, 0, 0]
  small_origin_in_large_grid = [0, 0, 0]
  small_abc = [0, 0, 0]
  sites_frac_shift = [0, 0, 0]
  for i in range(3):
    grid_step = large_ucp[i] / large_n_real[i]
    buffer = large_d_min / grid_step
    grid_min = ifloor(large_frac_min[i] * large_n_real[i] - buffer)
    grid_max = iceil(large_frac_max[i] * large_n_real[i] + buffer)
    min_grid = grid_max - grid_min + 1
    small_n_real[i] = fftpack.adjust_gridding(min_grid = min_grid, max_prime = 5)
    if (small_n_real[i] < large_n_real[i]):
      shift_min = (small_n_real[i] - min_grid) // 2
      small_origin_in_large_grid[i] = grid_min - shift_min
      small_abc[i] = small_n_real[i] * grid_step
      sites_frac_shift[i] = small_origin_in_large_grid[i] / large_n_real[i]
    else:
      small_n_real[i] = large_n_real[i]
      small_origin_in_large_grid[i] = 0
      small_abc[i] = large_ucp[i]
      sites_frac_shift[i] = 0
  sites_cart_shift = large_unit_cell.orthogonalize(sites_frac_shift)
  sites_cart_small = sites_cart - sites_cart_shift
  from cctbx import xray
  small_xray_structure = xray.structure(
    crystal_symmetry = crystal.symmetry(
      unit_cell = tuple(small_abc)+large_ucp[3:],
      space_group_symbol = "P1"),
    scatterers = work_scatterers)
  small_xray_structure.set_sites_cart(sites_cart = sites_cart_small)
  small_f_calc = small_xray_structure.structure_factors(
    d_min = large_d_min).f_calc()
  small_gridding = crystal_gridding(
    unit_cell = small_f_calc.unit_cell(),
    space_group_info = small_f_calc.space_group_info(),
    pre_determined_n_real = small_n_real)
  from cctbx import miller
  small_fft_map = miller.fft_map(
    crystal_gridding = small_gridding,
    fourier_coefficients = small_f_calc)
  small_fft_map.apply_sigma_scaling()
  small_map = small_fft_map.real_map_unpadded()
  grid_indices = grid_indices_around_sites(
    unit_cell = small_xray_structure.unit_cell(),
    fft_n_real = small_n_real,
    fft_m_real = small_n_real,
    sites_cart = sites_cart_small,
    site_radii = site_radii)
  small_copy_from_large_map = copy(
    map_unit_cell = large_density_map,
    first = small_origin_in_large_grid,
    last = matrix.col(small_origin_in_large_grid)
       + matrix.col(small_n_real)
       - matrix.col((1, 1, 1)))
  assert small_copy_from_large_map.all()  ==  small_map.all()
  corr = flex.linear_correlation(
    x = small_map.select(grid_indices),
    y = small_copy_from_large_map.select(grid_indices))
  if (not corr.is_well_defined()):
    return None
  return corr.coefficient()

def ccv(map_1, map_2, modified, centered, cutoff = None, n_bins = 10000):
  if(modified):
    map_1 = volume_scale(map = map_1, n_bins = n_bins).map_data()
    map_2 = volume_scale(map = map_2, n_bins = n_bins).map_data()
  if(cutoff is not None):
    map_1 = map_1 - cutoff
    map_2 = map_2 - cutoff
    s1 = map_1 < 0
    s2 = map_2 < 0
    map_1 = map_1.set_selected(s1, 0)
    map_2 = map_2.set_selected(s2, 0)
    def corr(x, y, centered):
      s1 = x > 0
      s2 = y > 0
      s = s1 | s2
      s = s.iselection()
      x_ = x.select(s)
      y_ = y.select(s)
      return flex.linear_correlation(x = x_, y = y_,
        subtract_mean = centered).coefficient()
    return corr(x = map_1, y = map_2, centered = centered)
  else:
    return flex.linear_correlation(x = map_1.as_1d(), y = map_2.as_1d(),
      subtract_mean = centered).coefficient()

class spherical_variance_around_point(object):
  def __init__(self,
      real_map,
      unit_cell,
      site_cart,
      radius,
      n_points = 40,
      spline_interpolation = True,
      write_sphere_points_to_pdb_file = None):
    self.site_cart = site_cart
    self.radius = radius
    assert n_points>0
    sphere_points = []
    x, y, z = site_cart
    # reference: "Distributing many points on a sphere" by E.B. Saff and
    #     A.B.J. Kuijlaars, Mathematical Intelligencer 19.1 (1997) 5--11.
    # derived from http://packinon.sourceforge.net/py_progs/pg_saff.html
    for k in range(1, n_points+1):
      h = -1 + 2 * (k - 1) / float(n_points - 1)
      theta = math.acos(h)
      if (k  ==  1) or (k  ==  n_points):
        phi = 0
      else:
        phi = (old_phi + 3.6/math.sqrt(n_points*(1-h*h))) % (2*math.pi)
      sphere_points.append((
        x + math.sin(phi)*math.sin(theta),
        y + math.cos(theta),
        z + math.cos(phi)*math.sin(theta) ))
      old_phi = phi
    map_values = flex.double()
    for point in sphere_points :
      site_frac = unit_cell.fractionalize(site_cart = point)
      value_at_point = real_map.tricubic_interpolation(site_frac)
      map_values.append(value_at_point)
    self.min = flex.min(map_values)
    self.max = flex.max(map_values)
    self.mean = flex.mean(map_values)
    self.standard_deviation = map_values.standard_deviation_of_the_sample()
    if (write_sphere_points_to_pdb_file is not None):
      f = open(write_sphere_points_to_pdb_file, "w")
      for i, point in enumerate(sphere_points):
        f.write(
          "HETATM    1  O   HOH A   1     %7.3f %7.3f %7.3f  1.00 20.00\n"%
          point)
      f.close()

  def show(self, out = None, prefix = ""):
    if (out is None) : out = sys.stdout
    print("%sMap values around point [%g, %g, %g], radius = %g:" % \
      (prefix, self.site_cart[0], self.site_cart[1], self.site_cart[2],
       self.radius), file = out)
    print("%s  min = %.2f  max = %.2f  mean = %.2f  stddev = %.2f" % \
      (prefix, self.min, self.max, self.mean, self.standard_deviation), file = out)

def principal_axes_of_inertia(
    real_map,
    site_cart,
    unit_cell,
    radius):
  st = sphericity_tensor(
    map_data  = real_map,
    unit_cell = unit_cell,
    radius    = radius,
    site_frac = unit_cell.fractionalize(site_cart))
  es = adptbx.eigensystem(st)
  def center_of_mass_():
    return center_of_mass(
    map_data = real_map, unit_cell = unit_cell, cutoff = 0.1)
  def inertia_tensor():
    return st
  def eigensystem():
    return es
  return group_args(
    center_of_mass = center_of_mass_,
    inertia_tensor = inertia_tensor,
    eigensystem    = eigensystem)

class local_scale(object):
  def __init__(
        self,
        crystal_gridding,
        crystal_symmetry,
        f_map = None,
        map_data = None,
        miller_array = None,
        d_min = None): #XXX  = 1: more features and noise
    # process inputs
    assert [f_map, map_data].count(None)  ==  1
    if(f_map is not None):
      import cctbx.miller
      fft_map = cctbx.miller.fft_map(
        crystal_gridding     = crystal_gridding,
        fourier_coefficients = f_map)
      fft_map.apply_sigma_scaling()
      map_data = fft_map.real_map_unpadded()
    #
    self.map_result = None
    self.map_coefficients = None
    b = boxes(
      n_real   = crystal_gridding.n_real(),
      fraction = 0.03)
    # Loop over boxes, fill map_result with one box at a time
    self.map_result = flex.double(flex.grid(b.n_real))
    for s, e in zip(b.starts, b.ends):
      box = copy(map_data, s, e)
      box.reshape(flex.grid(box.all()))
      mi, ma, me = box.as_1d().min_max_mean().as_tuple()
      if(mi < ma):
        box = volume_scale(map = box, n_bins = 1000).map_data()
      set_box(
        map_data_from = box,
        map_data_to   = self.map_result,
        start         = s,
        end           = e)
    sd = self.map_result.sample_standard_deviation()
    self.map_result = self.map_result/sd
    if(miller_array is not None):
      complete_set = miller_array
      if(d_min is not None):
        d_min = miller_array.d_min()
        complete_set = miller_array.complete_set(d_min = d_min)
      self.map_coefficients = complete_set.structure_factors_from_map(
        map            = self.map_result,
        use_scale      = True,
        anomalous_flag = False,
        use_sg         = False)

def sphericity_by_heuristics(
      map_data,
      unit_cell,
      center_cart,
      radius,
      s_angle_sampling_step = 20,
      t_angle_sampling_step = 20):
  points_on_sphere_cart = flex.vec3_double()
  for s in range(0, 360, s_angle_sampling_step):
    for t in range(0, 360, t_angle_sampling_step):
      xc, yc, zc = scitbx.math.point_on_sphere(r = radius, s_deg = s, t_deg = t,
        center = center_cart)
      points_on_sphere_cart.append([xc, yc, zc])
  o = sphericity2(
    map_data              = map_data,
    center_cart           = center_cart,
    points_on_sphere_cart = points_on_sphere_cart,
    unit_cell             = unit_cell)
  return group_args(rho = o.rho_min_max_mean(), ccs = o.ccs_min_max_mean())

def map_peak_3d_as_2d(
      map_data,
      unit_cell,
      center_cart,
      radius,
      step = 0.01,
      s_angle_sampling_step = 10,
      t_angle_sampling_step = 10):
  rho_1d = flex.double()
  dist = flex.double()
  radius = int(radius*100)+1
  step = int(step*100)
  for r in range(0, radius, step):
    r = r/100.
    dist.append(r)
    rho = flex.double()
    for s in range(0, 360, s_angle_sampling_step):
      for t in range(0, 360, t_angle_sampling_step):
        xc, yc, zc = scitbx.math.point_on_sphere(r = r, s_deg = s, t_deg = t,
          center = center_cart)
        xf, yf, zf = unit_cell.fractionalize([xc, yc, zc])
        rho.append(map_data.eight_point_interpolation([xf, yf, zf]))
        #rho.append(map_data.tricubic_interpolation([xf, yf, zf]))
    rho_1d.append(flex.mean(rho))
  return dist, rho_1d

class positivity_constrained_density_modification(object):
  def __init__(self, f, f_000, n_cycles = 100, resolution_factor = 0.25, d_min = None,
               crystal_gridding = None, complete_set = None):
    self.f = f
    self.d_min = d_min
    self.map = None
    self.crystal_gridding = crystal_gridding
    from cctbx import miller
    if(self.d_min is None): self.d_min = self.f.d_min()
    if(complete_set is None):
      complete_set = self.f.complete_set(d_min = self.d_min)
    if(self.crystal_gridding is None):
      self.crystal_gridding = self.f.crystal_gridding(
        d_min                   = d_min,
        resolution_factor       = resolution_factor,
        grid_step               = None,
        symmetry_flags          = None,
        mandatory_factors       = None,
        max_prime               = 5,
        assert_shannon_sampling = True)
    self.f_mod = self.f.deep_copy()
    for i in range(n_cycles):
      fft_map = miller.fft_map(
        crystal_gridding     = self.crystal_gridding,
        fourier_coefficients = self.f_mod,
        f_000                = f_000)
      if(f_000 is not None): fft_map.apply_volume_scaling()
      self.map = fft_map.real_map_unpadded()
      convert_to_non_negative(self.map, 0)
      self.f_mod = complete_set.structure_factors_from_map(
        map            = self.map,
        use_scale      = True,
        anomalous_flag = False,
        use_sg         = False)
      self.f_mod = self.f.complete_with(other = self.f_mod, scale = True,
        replace_phases = True)
      #self.assert_equal()

  def assert_equal(self):
    from libtbx.test_utils import approx_equal
    x, y = self.f, self.f_mod
    x, y = x.common_sets(y)
    x = abs(x).data()
    y = abs(y).data()
    assert approx_equal(x, y)

def d_min_corner(map_data, unit_cell):
  max_index = flex.miller_index( [[(i-1)//2 for i in map_data.all()]] )
  return uctbx.d_star_sq_as_d(unit_cell.max_d_star_sq( max_index ))

def d_min_from_map(map_data, unit_cell, resolution_factor = 1./2.):
  a, b, c = unit_cell.parameters()[:3]
  nx, ny, nz = map_data.all()
  d1, d2, d3 = \
    a/nx/resolution_factor, \
    b/ny/resolution_factor, \
    c/nz/resolution_factor
  return max(d1, d2, d3)

def map_coefficients_to_map(map_coeffs, crystal_symmetry, n_real):
  assert isinstance(map_coeffs.data(), flex.complex_double)
  cg = crystal_gridding(
    unit_cell             = crystal_symmetry.unit_cell(),
    space_group_info      = crystal_symmetry.space_group_info(),
    pre_determined_n_real = n_real)
  fft_map = map_coeffs.fft_map(
    crystal_gridding = cg,
    symmetry_flags   = use_space_group_symmetry)
  fft_map.apply_volume_scaling()
  return fft_map.real_map_unpadded()

def map_to_map_coefficients(m, cs, d_min):
  import cctbx.miller
  fft = fftpack.real_to_complex_3d([i for i in m.all()])
  map_box = copy(
    m, flex.grid(fft.m_real()).set_focus(m.focus()))
  map_box.reshape(flex.grid(fft.m_real()).set_focus(fft.n_real()))
  map_box = fft.forward(map_box)
  box_structure_factors = structure_factors.from_map(
    unit_cell = cs.unit_cell(),
    space_group_type = cs.space_group().type(),
    anomalous_flag = False,
    d_min = d_min,
    complex_map = map_box,
    conjugate_flag = True,
    discard_indices_affected_by_aliasing = True)
  n = map_box.all()[0] * map_box.all()[1] * map_box.all()[2]
  map_coeffs = cctbx.miller.set(
    crystal_symmetry = cs,
    anomalous_flag = False,
    indices = box_structure_factors.miller_indices(),
    ).array(data = box_structure_factors.data()/n)
  return map_coeffs

def atom_radius_as_central_peak_width(element, b_iso, d_min, scattering_table):
  """
  Estimate atom radius as half-width of the central peak of Fourier image.
  """
  from cctbx import xray, miller
  dim = 40.
  cs = crystal.symmetry((dim, dim, dim, 90, 90, 90), "P 1")
  sp = crystal.special_position_settings(cs)
  sc = xray.scatterer(
    scattering_type = element,
    site            = (0, 0, 0),
    u               = adptbx.b_as_u(b_iso))
  scatterers = flex.xray_scatterer([sc])
  xrs = xray.structure(sp, scatterers)
  xrs.scattering_type_registry(table = scattering_table)
  cg = crystal_gridding(
    unit_cell         = xrs.unit_cell(),
    space_group_info  = xrs.space_group_info(),
    step              = 0.1)
  fc = xrs.structure_factors(d_min = d_min, algorithm = "direct").f_calc()
  fft_map = miller.fft_map(
    crystal_gridding     = cg,
    fourier_coefficients = fc,
    f_000                = xrs.f_000())
  fft_map.apply_volume_scaling()
  map_data = fft_map.real_map_unpadded()
  def search_curve(map_data, dim):
    x = 0.
    step = 0.01
    mv_max = None
    mv_prev = None
    while x<= dim:
      mv = map_data.eight_point_interpolation([x/dim, 0, 0])
      if(mv_prev is not None and mv>mv_prev): return x-step
      if(mv_max is None): mv_max = mv
      if(mv_max/mv>100.): return x-step
      if(mv<0.):          return x-step
      x+= step
      mv_prev = mv
    return None
  radius = search_curve(map_data = map_data, dim = dim)
  assert radius is not None
  return radius

class atom_curves(object):
  """
Class-toolkit to compute various 1-atom 1D curves: exact electron density,
Fourier image of specified resolution, etc.
  """

  def __init__(self, scattering_type, scattering_table = "wk1995",
               scattering_dictionary=None):
    adopt_init_args(self, locals())
    assert [self.scattering_table, self.scattering_dictionary].count(None)==1
    self.scr = self.get_xray_structure(box = 1, b = 0).scattering_type_registry()
    self.uff = self.scr.unique_form_factors_at_d_star_sq

  def get_xray_structure(self, box, b):
    cs = crystal.symmetry((box, box, box, 90, 90, 90), "P 1")
    sp = crystal.special_position_settings(cs)
    from cctbx import xray
    sc = xray.scatterer(
      scattering_type = self.scattering_type,
      site            = (0, 0, 0),
      u               = adptbx.b_as_u(b))
    scatterers = flex.xray_scatterer([sc])
    xrs = xray.structure(sp, scatterers)
    if(self.scattering_table is not None):
      xrs.scattering_type_registry(table = self.scattering_table)
    else:
      xrs.scattering_type_registry(custom_dict = self.scattering_dictionary)
    return xrs

  def exact_density_at_r(self, r, b_iso):
    return self.scr.gaussian(self.scattering_type).electron_density(r, b_iso)

  def exact_gradient_at_r(self, r, t, t0, b_iso):
    return self.scr.gaussian(self.scattering_type).gradient(r = r, t = t, t0 = t0,
      b_iso = b_iso)

  def exact_density(self, b_iso, radius_max = 5., radius_step = 0.001):
    r = 0.0
    density = flex.double()
    radii   = flex.double()
    ed = self.scr.gaussian(self.scattering_type)
    while r < radius_max:
      density.append(ed.electron_density(r, b_iso))
      radii.append(r)
      r+= radius_step
    return group_args(radii = radii, density = density)

  def form_factor(self, ss, b_iso):
    dss = 4*ss
    return self.uff(dss)[0]*math.exp(-b_iso*ss)

  def integrand(self, r, b_iso):
    def compute(s):
      ss = (s/2)**2
      if(abs(r)>1.e-9):
        return 2/r * s * self.form_factor(ss, b_iso) * math.sin(2*math.pi*r*s)
      else:
        return 4*math.pi * s**2 * self.form_factor(ss, b_iso)
    return compute

  def bcr_approx(self,
                 d_min,
                 radius_max,
                 radius_step,
                 mxp=5, epsc=0.001, kpres=0 # BCR params
                 ):
    b_iso = 0 # Must always be 0! All image vals below are for b_iso=0 !!!
    from cctbx.maptbx.bcr import bcr
    im = self.image(
      d_min=d_min, b_iso=0, radius_max=radius_max, radius_step=radius_step)
    bpeak, cpeak, rpeak, _,_,_,_ = bcr.get_BCR(
      dens=im.image_values, dist=im.radii, mxp=mxp, epsc=epsc, kpres=kpres,
      dmax=radius_max)
    #
    bcr_approx_values = flex.double()
    # FILTER
    bpeak_, cpeak_, rpeak_ = [],[],[]
    for bi, ci, ri in zip(bpeak, cpeak, rpeak):
      if(abs(bi)<1.e-6 or abs(ci)<1.e-6): continue
      else:
        bpeak_.append(bi)
        cpeak_.append(ci)
        rpeak_.append(ri)
    bpeak, cpeak, rpeak = bpeak_, cpeak_, rpeak_
    #
    for r in im.radii:
      first = 0
      second = 0
      for B, C, R in zip(bpeak, cpeak, rpeak):
        if(abs(R)<1.e-6):
          first += bcr.gauss(B=B, C=C, r=r, b_iso=0)
        else:
          second += C*bcr.chi(B=B, R=R, r=r, b_iso=0)
      bcr_approx_values.append(first + second)
    return group_args(
      radii             = im.radii,
      image_values      = im.image_values,
      bcr_approx_values = bcr_approx_values,
      B=bpeak, C=cpeak, R=rpeak)

  def image(self,
            d_min,
            b_iso,
            d_max = None,
            radius_min = 0,
            radius_max = 5.,
            radius_step = 0.001,
            n_integration_steps = 2000):
    r = radius_min
    assert d_max !=  0.
    if(d_max is None): s_min = 0
    else:              s_min = 1./d_max
    assert d_min !=  0.
    s_max = 1./d_min
    image_values = flex.double()
    radii        = flex.double()
    while r < radius_max:
      s = scitbx.math.simpson(
        f = self.integrand(r, b_iso), a = s_min, b = s_max, n = n_integration_steps)
      image_values.append(s)
      radii.append(r)
      r+= radius_step
    # Fine first inflection point
    first_inflection_point = None
    i_first_inflection_point = None
    size = image_values.size()
    second_derivatives = flex.double()
    for i in range(size):
      if(i>0 and i<size-1):
        dxx = image_values[i-1]+image_values[i+1]-2*image_values[i]
      elif(i == 0):
        dxx = 2*image_values[i+1]-2*image_values[i]
      else:
        dxx = second_derivatives[i-1]*radius_step**2
      if(first_inflection_point is None and dxx>0):
        first_inflection_point = (radii[i-1]+radii[i])/2.
        i_first_inflection_point = i
      second_derivatives.append(dxx/radius_step**2)
    return group_args(
      radii                    = radii,
      image_values             = image_values,
      first_inflection_point   = first_inflection_point,
      i_first_inflection_point = i_first_inflection_point,
      radius                   = first_inflection_point*2,
      second_derivatives       = second_derivatives)

  def image_from_miller_indices(self, miller_indices, b_iso, uc,
                                radius_max, radius_step):
    p2 = flex.double()
    tmp = flex.double()
    for mi in miller_indices:
      p2.append(self.form_factor(ss = uc.d_star_sq(mi)/4, b_iso = b_iso))
      tmp.append( 2*math.pi*mi[2] )
    mv  = flex.double()
    rad = flex.double()
    z = 0.0
    while z < radius_max:
      result = 0
      for mi, p2i, tmpi in zip(miller_indices, p2, tmp):
        result +=  p2i*math.cos(tmpi*z)
      rad.append(z)
      mv.append(result*2)
      z+= radius_step
    return group_args(radii = rad, image_values = mv/uc.volume())

  def image_from_3d(self, box, b, step, unit_cell, space_group_info,
                          miller_array):
    from cctbx import miller
    xrs = self.get_xray_structure(box = box, b = b)
    fc = miller_array.structure_factors_from_scatterers(
      xray_structure = xrs, algorithm = "direct").f_calc()
    cg = crystal_gridding(
      unit_cell         = unit_cell,
      space_group_info  = space_group_info,
      step              = step,
      symmetry_flags    = use_space_group_symmetry)
    fft_map = miller.fft_map(
      crystal_gridding     = cg,
      fourier_coefficients = fc)
    fft_map.apply_volume_scaling()
    map_data = fft_map.real_map_unpadded()
    mv = flex.double()
    radii = flex.double()
    r = 0
    while r < box:
      mv_ = map_data.eight_point_interpolation([r/box, 0, 0])
      mv.append(mv_)
      radii.append(r)
      r+= step
    return group_args(radii = radii, image_values = mv)

  def one_gaussian_exact(self, r, A0, B0, b = 0):
    cmn = 4*math.pi/(B0+b)
    return A0*cmn**1.5 * math.exp(-math.pi*cmn*r**2)

  def one_gaussian_approximation(self, d_min, b, use_inflection_point = True):
    ib0 = self.image(
      d_min = d_min, b_iso = 0, radius_max = 5, radius_step = 0.01)
    if(use_inflection_point):
      i_cut = ib0.i_first_inflection_point
    else:
      i_cut = None
      for i in range(ib0.radii.size()):
        if(ib0.image_values[i]<= 0):
          rad_cut = ib0.radii[i-1]
          i_cut = i-1
          break
    assert i_cut is not None
    # this gives a*exp(-b*x**2)
    r = scitbx.math.gaussian_fit_1d_analytical(
      x = ib0.radii[:i_cut], y = ib0.image_values[:i_cut])
    B0 = 4*math.pi**2/r.b
    A0 = r.a/(r.b/math.pi)**1.5
    image_approx_values = flex.double()
    for rad in ib0.radii:
      v = self.one_gaussian_exact(r = rad, A0 = A0, B0 = B0, b = b)
      image_approx_values.append(v)
    return group_args(image_b0 = ib0, image_approx_at_b = image_approx_values,
      i_cut = i_cut, n_points = ib0.radii.size())

def sharpen2(map, xray_structure, resolution, file_name_prefix):
  from cctbx import miller
  fo = miller.structure_factor_box_from_map(
    crystal_symmetry = xray_structure.crystal_symmetry(), map = map)
  #
  fc = fo.structure_factors_from_scatterers(
    xray_structure = xray_structure).f_calc()
  d_fsc_model = fc.d_min_from_fsc(other = fo, fsc_cutoff = 0.).d_min
  print("d_fsc_model:", d_fsc_model)
  #resolution = min(resolution, d_fsc_model)
  #resolution = d_fsc_model
  print(resolution, d_fsc_model)
  #
  xray_structure = xray_structure.set_b_iso(value = 0)
  fc = fo.structure_factors_from_scatterers(
    xray_structure = xray_structure).f_calc()
  d_spacings = fo.d_spacings().data()
  #
  cc = -999
  d_best = None
  data = fc.data().deep_copy()
  for d in [i/10. for i in range(10, 100)]:
    sel = d_spacings<d
    data_ = data.set_selected(sel, 0)
    fc_ = fc.customized_copy(data = data_)
    cc_ = fo.map_correlation(other = fc_)
    if(cc_>cc):
      cc = cc_
      d_best = d
    #print "%8.1f %10.6f"%(d, cc_)
  print("Best d:", d_best)
  #
  fc1 = xray_structure.structure_factors(d_min = resolution).f_calc()
  fc2 = fc1.resolution_filter(d_min = d_best)
  cg = crystal_gridding(
    unit_cell        = xray_structure.crystal_symmetry().unit_cell(),
    space_group_info = xray_structure.crystal_symmetry().space_group_info(),
    d_min            = resolution)
  map2 = fc2.fft_map(crystal_gridding = cg).real_map_unpadded()
  cc = -999
  b = None
  ss = 1./flex.pow2(fc1.d_spacings().data()) / 4.
  data = fc1.data()
  for b_ in range(1, 500, 1):
    xray_structure = xray_structure.set_b_iso(value = b_)
    sc = flex.exp(-b_*ss)
    fc1 = fc1.customized_copy(data = data*sc)
    map1 = fc1.fft_map(crystal_gridding = cg).real_map_unpadded()
    cc_ = flex.linear_correlation(x = map1.as_1d(), y = map2.as_1d()).coefficient()
    if(cc_>cc):
      cc = cc_
      b = b_
    #print "%8.0f %10.6f"%(b_, cc_)
  print("Best B:", b)
  #
  fo_sharp = fo.resolution_filter(d_min = resolution)
  ss = 1./flex.pow2(fo_sharp.d_spacings().data()) / 4.
  #B_sharp = -35.
  B_sharp = -1*b
  sc = flex.exp(-B_sharp*ss)
  fo_sharp = fo_sharp.customized_copy(data = fo_sharp.data()*sc)
  # output
  mtz_dataset = fo_sharp.as_mtz_dataset(column_root_label = "F")
  mtz_object = mtz_dataset.mtz_object()
  mtz_object.write(file_name = "%s.mtz"%file_name_prefix)
  fft_map = fo_sharp.fft_map(crystal_gridding = cg)
  fft_map.apply_sigma_scaling()
  map_data = fft_map.real_map_unpadded()
  #
  import mmtbx.masks
  mask_object = mmtbx.masks.smooth_mask(
    xray_structure = xray_structure,
    n_real         = map_data.all(),
    rad_smooth     = 2.0)
  map_data = map_data * mask_object.mask_smooth
  #
  from iotbx import mrcfile
  mrcfile.write_ccp4_map(
    file_name = "%s.ccp4"%file_name_prefix,
    unit_cell = cg.unit_cell(),
    space_group = cg.space_group(),
    #gridding_first = (0, 0, 0), # This causes a bug (map gets shifted)
    #gridding_last = n_real,  # This causes a bug (map gets shifted)
    map_data = map_data,
    labels = flex.std_string([""]))
  return fo_sharp, map_data

def loc_res(map_model_manager,
            chunk_size = 10,
            method = "fsc",
            b_min = 0,
            b_max = 500,
            b_step = 5,
            res_min = 1.5,
            res_max = 10.0,
            res_step = 0.1,
            fsc_cutoff = 0.143):
  assert method in ["fsc", "rscc", "rscc_d_min_b", "d99"]
  from cctbx import miller
  mmm = map_model_manager
  mmm.map_manager().set_mean_zero_sd_one()
  mmm.model().setup_scattering_dictionaries(scattering_table = "electron")
  result = flex.double(mmm.model().size())
  chunk_selections = mmm.model().get_hierarchy().chunk_selections(
    residues_per_chunk = chunk_size)
  for chunk_sel in chunk_selections:
    box_mmm = mmm.extract_all_maps_around_model(
       selection = chunk_sel,  box_cushion=3)
    box_mmm.remove_origin_shift_and_unit_cell_crystal_symmetry()

    # <<<<<<<<<<<<<<<
    if 0: ######## WHY THIS:
      box_mmm.mask_all_maps_around_atoms(soft_mask = True,
        mask_atoms_atom_radius=3, soft_mask_radius = 3)
    else: ######## IS NOT THE SAME AS THIS:
      box_mmm.map_manager().create_mask_around_atoms(model = box_mmm.model(),
        mask_atoms_atom_radius = 3.)
      box_mmm.map_manager().soft_mask(soft_mask_radius = 3)
      box_mmm.map_manager().apply_mask()
    # <<<<<<<<<<<<<<<

    # <<<<<<<<<<<<<<<
    if 1: ######## WHY THIS:
      fo = miller.structure_factor_box_from_map(
        crystal_symmetry = box_mmm.model().get_xray_structure().crystal_symmetry(),
        map              = box_mmm.map_manager().map_data())
    else: ######## IS NOT THE SAME AS THIS:
      fo = box_mmm.map_as_fourier_coefficients()
    # <<<<<<<<<<<<<<<

    if method in ["rscc_d_min_b", "rscc"]:
      box_mmm.model().get_xray_structure().set_b_iso(value = 0.0)
      d_spacings = fo.d_spacings().data()
      ss = 1./flex.pow2(d_spacings) / 4.
      def rcast(x): return int(x*10)
      resolutions = flex.double(
        [i/10. for i in range(rcast(res_min), rcast(res_max), rcast(res_step))])
    if method != "d99":
      fc = fo.structure_factors_from_scatterers(
        xray_structure = box_mmm.model().get_xray_structure()).f_calc()
    if(method == "d99"):
      d_min = d99(f_map=fo).result.d99
    elif(method == "fsc"):
      d_min = fc.d_min_from_fsc(other = fo, fsc_cutoff = fsc_cutoff).d_min
    elif(method == "rscc"):
      d_min, cc = cc_complex_complex(
        f_1        = fo.data(),
        f_2        = fc.data(),
        d_spacings = d_spacings,
        ss         = ss,
        d_mins     = flex.double([i/10. for i in range(15, 100)]),
        b_iso      = 0)
    elif(method == "rscc_d_min_b"):
      d_min_best = None
      cc_best = -1
      for b_iso in  [ i for i in range(b_min, b_max, b_step)]:
        d_min, cc = cc_complex_complex(
          f_1        = fo.data(),
          f_2        = fc.data(),
          d_spacings = d_spacings,
          ss         = ss,
          d_mins     = flex.double([i/10. for i in range(15, 100)]),
          b_iso      = b_iso)
        if cc>cc_best:
          cc_best = cc
          d_min_best = d_min
      cc = cc_best
      d_min = d_min_best
    result.set_selected(chunk_sel, d_min)
  return group_args(result = result, selections = chunk_selections)

def is_bounded_by_constant(map_data,
     relative_sd_tol = 0.1):
    ''' Determine if this map is bounded on all sides by values that are
       zero or a constant, within relative tolerance of relative_sd_tol to
       the SD of the map as a whole

       Returns True if map boundary values are nearly constant,
         and False if they vary

       Requires that map is at origin (0,0,0)
    '''

    assert tuple(map_data.origin()) == (0,0,0)

    relative_sd = relative_sd_on_edges(map_data)

    # Determine whether values at boundaries are all about the same:
    if relative_sd  > relative_sd_tol:
      return False  # Not uniform on edges
    else:
      return True  # uniform on edges


def relative_sd_on_edges(map_data,
    skip_if_greater_than = None,
    use_maximum = None):

    '''
     Determine relative SD of values on edges to the map as a whole

     Requires that map is at origin (0,0,0)

    '''
    assert tuple(map_data.origin()) == (0,0,0)

    sd_overall = map_data.as_1d().standard_deviation_of_the_sample()

    all = list(map_data.all())
    boundary_data = flex.double()
    relative_sd_on_edges = 0

    from cctbx.maptbx import copy
    for i in (0, all[0]-1):
      new_map_data = copy(map_data,
         tuple((i, 0, 0)),
         tuple((i, all[1], all[2])))
      boundary_data.extend(new_map_data.as_1d())
      relative_sd_on_edges = max(relative_sd_on_edges,
        new_map_data.as_1d().standard_deviation_of_the_sample() / max(
          1.e-10,sd_overall))
      if (skip_if_greater_than is not None) and (
        relative_sd_on_edges > skip_if_greater_than):
          return relative_sd_on_edges

    for j in (0, all[1]-1):
      new_map_data = copy(map_data,
         tuple((0, j, 0)),
         tuple((all[0], j, all[2])))
      boundary_data.extend(new_map_data.as_1d())
      relative_sd_on_edges = max(relative_sd_on_edges,
        new_map_data.as_1d().standard_deviation_of_the_sample() / max(
          1.e-10,sd_overall))
      if (skip_if_greater_than is not None) and (
        relative_sd_on_edges > skip_if_greater_than):
          return relative_sd_on_edges

    for k in (0, all[2]-1):
      new_map_data = copy(map_data,
         tuple((0, 0, k)),
         tuple((all[0], all[1], k)))
      boundary_data.extend(new_map_data.as_1d())
      relative_sd_on_edges = max(relative_sd_on_edges,
        new_map_data.as_1d().standard_deviation_of_the_sample() / max(
          1.e-10,sd_overall))
      if (skip_if_greater_than is not None) and (
        relative_sd_on_edges > skip_if_greater_than):
          return relative_sd_on_edges

    if use_maximum: # Take maximum for any edge
      return relative_sd_on_edges
    else:  # use overall
      return boundary_data.standard_deviation_of_the_sample(
        ) / max(1.e-10,sd_overall)

def get_resolution_where_significant_data_present(ma,
   minimum_fraction_data_points=0.1):
    # Now filter ma at resolution where there are significant data
    sel = ( ma.amplitudes().data() > 1.e-10)
    ma_with_data = ma.select(sel)
    n_bins = int(0.5+10 * 1/minimum_fraction_data_points)
    ma_with_data.setup_binner(n_bins = n_bins, d_max = 10000.,
      d_min = ma_with_data.d_min())
    dsd = ma_with_data.d_spacings().data()
    ibin_list=list(ma_with_data.binner().range_used())
    ibin_list.reverse()
    total_data = ma_with_data.size()
    minimum_data_points = int(minimum_fraction_data_points * total_data)
    total_found = 0
    for i_bin in ibin_list:
      sel2      = ma_with_data.binner().selection(i_bin)
      dd        = dsd.select(sel2)
      d_max     = dd.min_max_mean().max
      n         = dd.size()
      total_found += n
      if total_found >= minimum_data_points and total_found < total_data//2:
        return d_max
    return None

def get_diff_score_towards_periodic(map_data,
      minimum_fraction_data_points = None):

    '''
      Evaluate consistency of high-pass filtered difference map analysis
      with that expected for a map that is periodic.

      The difference map is difference between the map and the map lacking high-
      resolution terms.  This difference map shows only high-frequency
      information

      A map that is periodic should give a difference map that is more or less
      uniform everywhere.  A non-periodic map should have a discontinuity at the
      borders and have high variation in the difference map at the edges.
    '''

    from cctbx import crystal
    dummy_uc_parameters=tuple(list(map_data.all())+[90.,90.,90.])
    cs= crystal.symmetry( dummy_uc_parameters, 1)

    # Normalize the map data
    sd=max(1.e-20,map_data.as_1d().standard_deviation_of_the_sample())
    mean=map_data.as_1d().min_max_mean().mean
    map_data=(map_data - mean)/sd

    # Test for difference map variation at edges of map

    # Get all structure factors, back transform to get map that can
    #  be represented by FT of all map coefficients in box (may not
    #  be the same as original because gridding may not allow it)

    from cctbx import miller
    ma = miller.structure_factor_box_from_map(
      crystal_symmetry = cs,
      map              = map_data,
      d_min            = None)

    map_data = map_coefficients_to_map(
      map_coeffs       = ma,
      crystal_symmetry = cs,
      n_real           = map_data.all())

    # Now we have map that can be represented by Fourier coefficients.
    # First get the map as Fourier coefficients

    ma = miller.structure_factor_box_from_map(
      crystal_symmetry = cs,
      map              = map_data,
      d_min            = None)

    # Ready with map as Fourier coefficients (FT of ma will give map_data again)

    # Find highest resolution where there are some non-zero data

    d_min_value = get_resolution_where_significant_data_present(ma,
      minimum_fraction_data_points = minimum_fraction_data_points)

    # High-frequency filter at this resolution
    filtered_ma = ma.resolution_filter(d_min = d_min_value)

    filtered_map       = map_coefficients_to_map(
      map_coeffs       = filtered_ma,
      crystal_symmetry = cs,
      n_real           = map_data.all())

    # Make a difference map to look at only high_frequency terms

    diff_map=map_data - filtered_map

    # Get the overall SD of the map and SD on edges:

    diff_sd = diff_map.as_1d().standard_deviation_of_the_sample()
    diff_relative_sd_on_edges = relative_sd_on_edges(diff_map,
       use_maximum = True)

    # Score based on expectation that a periodic map has a value of about 1
    #  and a non-periodic map has a value about 2

    diff_score_towards_aperiodic = max(0,min(1,(
         diff_relative_sd_on_edges - 1)/(2 - 1)))
    diff_score_towards_periodic = 1 - diff_score_towards_aperiodic

    return diff_score_towards_periodic

def get_edge_score_towards_periodic(map_data,
  use_minimum = True):
    '''
      Measure of whether facing edges have correlated data with correlation
     similar to that found for adjacent planes and different than randomly
     chosen points

     If use_minimum is set, take minimum of values on all pairs of faces

    '''

    all = list(map_data.all())
    one_data = flex.double()
    middle_plus_one_data = flex.double()
    middle_data = flex.double()
    boundary_zero_data = flex.double()
    boundary_zero_one_data = flex.double()
    boundary_one_data = flex.double()

    lowest_relative_cc = 1.0

    from cctbx.maptbx import copy
    unique_list=[]
    for i in (0,1, all[0]-1):
      if not i in unique_list: unique_list.append(i)
      new_map_data = copy(map_data,
         tuple((i, 0, 0)),
         tuple((i, all[1], all[2])))
      if i == 0:
        boundary_zero_data_local=new_map_data.as_1d()
        boundary_zero_data.extend(new_map_data.as_1d())
      elif i == 1:
        one_data_local=new_map_data.as_1d()
        one_data.extend(new_map_data.as_1d())
      else:
        boundary_one_data_local=new_map_data.as_1d()
        boundary_one_data.extend(new_map_data.as_1d())
    lowest_relative_cc = min(lowest_relative_cc,get_relative_cc(
      boundary_zero_data=boundary_zero_data_local,
      boundary_one_data=boundary_one_data_local,
      one_data=one_data_local,))

    assert len(unique_list) == 3

    unique_list=[]
    for j in (0,1, all[1]-1):
      if not j in unique_list: unique_list.append(j)
      new_map_data = copy(map_data,
         tuple((0, j, 0)),
         tuple((all[0], j, all[2])))
      if j == 0:
        boundary_zero_data_local=new_map_data.as_1d()
        boundary_zero_data.extend(new_map_data.as_1d())
      elif j == 1:
        one_data_local=new_map_data.as_1d()
        one_data.extend(new_map_data.as_1d())
      else:
        boundary_one_data_local=new_map_data.as_1d()
        boundary_one_data.extend(new_map_data.as_1d())
    assert len(unique_list) == 3
    lowest_relative_cc = min(lowest_relative_cc,get_relative_cc(
      boundary_zero_data=boundary_zero_data_local,
      boundary_one_data=boundary_one_data_local,
      one_data=one_data_local,))

    unique_list=[]
    for k in (0, 1, all[2]-1):
      if not k in unique_list: unique_list.append(k)
      new_map_data = copy(map_data,
         tuple((0, 0, k)),
         tuple((all[0], all[1], k)))
      if k == 0:
        boundary_zero_data_local=new_map_data.as_1d()
        boundary_zero_data.extend(new_map_data.as_1d())
      elif k == 1:
        one_data_local=new_map_data.as_1d()
        one_data.extend(new_map_data.as_1d())
      else:
        boundary_one_data_local=new_map_data.as_1d()
        boundary_one_data.extend(new_map_data.as_1d())
    assert len(unique_list) == 3
    lowest_relative_cc = min(lowest_relative_cc,get_relative_cc(
      boundary_zero_data=boundary_zero_data_local,
      boundary_one_data=boundary_one_data_local,
      one_data=one_data_local,))

    # use lowest value of relative_cc for any pair of faces so
    #  we can detect any faces that are trimmed

    if use_minimum:
      relative_cc=lowest_relative_cc
    else:
      relative_cc = get_relative_cc(
        boundary_zero_data=boundary_zero_data,
        boundary_one_data=boundary_one_data,
        one_data=one_data,)

    edge_score_towards_periodic = max(0,min(1,relative_cc ))

    return edge_score_towards_periodic

def get_relative_cc(
      boundary_zero_data = None,
      boundary_one_data = None,
      one_data = None):

    cc_boundary_zero_one= flex.linear_correlation(boundary_zero_data,
       boundary_one_data).coefficient()
    cc_positive_control= flex.linear_correlation(boundary_zero_data,
      one_data).coefficient()

    # Make negative control with randomized order of data
    one_data_random_perm= one_data.select(
         flex.random_permutation(len(one_data)))
    cc_negative_control = flex.linear_correlation(boundary_zero_data,
       one_data_random_perm).coefficient()


    # Expect that negative controls about zero, positive control high near 1,
    #  then cc_boundary_zero_one like negative_control means planes at
    #  boundaries differ, and cc_boundary_zero_one like positive means
    #  boundaries similar (as in wrapped)

    relative_cc = (cc_boundary_zero_one - cc_negative_control)/max(1.e-10,
         cc_positive_control - cc_negative_control)
    return relative_cc

def is_periodic(map_data,
     minimum_fraction_data_points = 0.1,
     high_confidence_delta = 0.2,
     medium_confidence_delta = 0.25):

    '''
       Determine if this map is periodic.  If values on opposite faces are
       about as similar as values on adjacent planes, it is probably periodic.

       Two tests are used: (1) correlation of facing edges of map and
        (2) test whether difference map between original and map without
        high resolution data shows most variation at edges (due to mismatch
        of edge data at facing edges of map).

       Map edge correlation score:
       Normally values on adjacent planes are very highly correlated (> 0.9)
       and random points in a map have very low correlation (< 0.1). This
       allows a test based on correlation of facing edges of a map and comparison
       to random pairs of points in map.

       Difference map score:
       If a map is boxed then if it is treated as a periodic map, there will
       be a discontinuity at the edges of the map.  This can be detected by
       calculating the Fourier transform of the high-resolution map coefficients
       for the map and detecting if this high-pass filtered map is dominated by
       features at the edge of the map.

       Returns True if periodic, False if not, and None if map gridding is
       too small (too few planes) or sampling is insufficiently fine to tell.

       Requires that map is at origin (0,0,0)
    '''

    assert tuple(map_data.origin()) == (0,0,0)


    # The difference map score is solid if > 0.8 or < 0.2. Otherwise best to
    #   combine it with edge score (correlation of edges) to get sum score

    diff_score_towards_periodic = get_diff_score_towards_periodic(map_data,
      minimum_fraction_data_points = minimum_fraction_data_points)

    if diff_score_towards_periodic >  (1 - high_confidence_delta):
      return True
    elif diff_score_towards_periodic < high_confidence_delta:
      return False

    # Get edge score and sum score now

    edge_score_towards_periodic = get_edge_score_towards_periodic(map_data)

    sum_score_towards_periodic = 0.5* (
         diff_score_towards_periodic + edge_score_towards_periodic)

    # We can be confident if sum_score is < .25 or > 0.75

    if sum_score_towards_periodic > (1 - medium_confidence_delta):
        return True
    elif sum_score_towards_periodic < medium_confidence_delta:
        return False
    else:
        return None # Really do not know

def map_values_along_line_connecting_two_points(map_data, points_cart,
      unit_cell, interpolation, step=None, n_steps=None):
  """
  Calculate interpolated map values along the line connecting two points in
  space.
  """
  assert interpolation in ["eight_point", "tricubic"]
  assert [step, n_steps].count(None)==1
  points_frac = unit_cell.fractionalize(points_cart)
  dist = unit_cell.distance(points_frac[0], points_frac[1])
  #
  def get_points(start, end, step=None, n_steps=None):
    assert [step, n_steps].count(None)==1
    dx = end[0] - start[0]
    dy = end[1] - start[1]
    dz = end[2] - start[2]
    direction = (dx, dy, dz)
    length = math.sqrt(direction[0]**2 + direction[1]**2 + direction[2]**2)
    direction_unit = (direction[0] / length, direction[1] / length, direction[2] / length)
    if n_steps is None:
      n_steps = int(max(abs(dx), abs(dy), abs(dz), length) / step)
    if step is None:
      step = length/n_steps
    points = []
    for i in range(n_steps + 1):
      point = (
        start[0] + i * step * direction_unit[0],
        start[1] + i * step * direction_unit[1],
        start[2] + i * step * direction_unit[2])
      points.append(point)
    # check end point
    end_ = points[-1]
    d = math.sqrt(
      (end_[0] - start[0])**2 +
      (end_[1] - start[1])**2 +
      (end_[2] - start[2])**2)
    if d<length: points.append(end)
    #
    return points
  #
  points = get_points(start=points_cart[0], end=points_cart[1], step=step,
    n_steps=n_steps)

  dist = flex.double()
  vals = flex.double()
  mv_max = None
  point_max = None
  for p in points:
    xp = p[0]
    yp = p[1]
    zp = p[2]
    rp = unit_cell.fractionalize([xp,yp,zp])
    d = unit_cell.distance(points_frac[0], rp)
    dist.append(d)
    pf = unit_cell.fractionalize([xp,yp,zp])
    if(interpolation=="eight_point"):
      mv = map_data.eight_point_interpolation(pf)
    else:
      mv = map_data.tricubic_interpolation(pf)
    if mv_max is None:
      mv_max = mv
      point_max = p[:]
    else:
      if mv > mv_max:
        mv_max = mv
        point_max = p[:]
    vals.append(mv)
  return group_args(dist = dist, vals = vals, point_max = point_max)


 *******************************************************************************


 *******************************************************************************
cctbx/maptbx/auto_sharpen.py
from __future__ import absolute_import, division, print_function
import sys, os
import iotbx.phil
from libtbx.utils import Sorry
import libtbx.phil

map_modification_phil_str = """

     b_iso = None
       .type = float
       .short_caption = Target b_iso
       .help = Target B-value for map (sharpening will be applied to yield \
          this value of b_iso). If sharpening method is not supplied, \
          default is to use b_iso_to_d_cut sharpening.

     b_sharpen = None
       .type = float
       .short_caption = B-sharpen to apply
       .help = Sharpen with this b-value. Contrast with b_iso that yields a \
           targeted value of b_iso

     b_blur_hires = 200
       .type = float
       .short_caption = high_resolution blurring
       .help = Blur high_resolution data (higher than d_cut) with \
             this b-value. Contrast with b_sharpen applied to data up to\
             d_cut. \
             Note on defaults: If None and b_sharpen is positive (sharpening) \
             then high-resolution data is left as is (not sharpened). \
             If None and b_sharpen is negative (blurring) high-resolution data\
             is also blurred.

     resolution_dependent_b = None
       .type = floats
       .short_caption = resolution_dependent b

       .help = If set, apply resolution_dependent_b (b0 b1 b2). \
             Log10(amplitudes) will start at 1, change to b0 at half \
             of resolution specified, changing linearly, \
             change to b1/2 at resolution specified, \
             and change to b1/2+b2 at d_min_ratio*resolution

     normalize_amplitudes_in_resdep = False
       .type = bool
       .short_caption = Normalize amplitudes in resdep
       .help = Normalize amplitudes in resolution-dependent sharpening

     d_min_ratio = 0.833
       .type = float
       .short_caption = Sharpen d_min ratio
       .help = Sharpening will be applied using d_min equal to \
             d_min_ratio times resolution. Default is 0.833

     scale_max = 100000
       .type = float
       .short_caption = Scale_max
       .help = Scale amplitudes from inverse FFT to yield maximum of this value

     input_d_cut = None
       .type = float
       .short_caption = d_cut
       .help = High-resolution limit for sharpening

     rmsd = None
       .type = float
       .short_caption = RMSD of model
       .help = RMSD of model to true model (if supplied).  Used to \
             estimate expected fall-of with resolution of correct part \
             of model-based map. If None, assumed to be resolution \
             times rmsd_resolution_factor.

     rmsd_resolution_factor = 0.25
       .type = float
       .short_caption = rmsd resolution factor
        .help = default RMSD is resolution times resolution factor


     fraction_complete = None
       .type = float
       .short_caption = Completeness model
       .help = Completness of model (if supplied).  Used to \
             estimate correct part \
             of model-based map. If None, estimated from max(FSC).

     auto_sharpen = True
       .type = bool
       .short_caption = Automatically determine sharpening
       .help = Automatically determine sharpening using kurtosis maximization\
                 or adjusted surface area. Default is True

     auto_sharpen_methods = no_sharpening b_iso *b_iso_to_d_cut \
                            resolution_dependent model_sharpening \
                            half_map_sharpening target_b_iso_to_d_cut \
                            external_map_sharpening None

       .type = choice(multi=True)
       .short_caption = Sharpening methods
       .help = Methods to use in sharpening. b_iso searches for b_iso to \
          maximize sharpening target (kurtosis or adjusted_sa). \
          b_iso_to_d_cut applies b_iso only up to resolution specified, with \
          fall-over of k_sharpen.  Resolution dependent adjusts 3 parameters \
          to sharpen variably over resolution range. Default is \
          b_iso_to_d_cut . target_b_iso_to_d_cut uses target_b_iso_ratio \
          to set b_iso.

     box_in_auto_sharpen = False
       .type = bool
       .short_caption = Use box for auto_sharpening
       .help = Use a representative box of density for initial \
                auto-sharpening instead of the entire map. Default is False.

     density_select_in_auto_sharpen = True
       .type = bool
       .short_caption = density_select to choose box
       .help = Choose representative box of density for initial \
                auto-sharpening with density_select method \
                (choose region where there is high density).  Normally use\
                False for X-ray data and True for cryo-EM.

     density_select_threshold_in_auto_sharpen = None
       .type = float
       .short_caption = density_select threshold to choose box
       .help = Threshold for density select choice of box. Default is 0.05. \
               If your map has low overall contrast you might need to make this\
               bigger such as 0.2.

     allow_box_if_b_iso_set = False
       .type = bool
       .short_caption = Allow box if b_iso set
       .help = Allow box_in_auto_sharpen (if set to True) even if \
               b_iso is set. Default is to set box_n_auto_sharpen=False \
               if b_iso is set.

    soft_mask = True
      .type = bool
      .help = Use soft mask (smooth change from inside to outside with radius\
             based on resolution of map).
      .short_caption = Soft mask

     use_weak_density = False
       .type = bool
       .short_caption = Use box with poor density
       .help = When choosing box of representative density, use poor \
               density (to get optimized map for weaker density)

     discard_if_worse = None
       .type = bool
       .short_caption = Discard sharpening if worse
       .help = Discard sharpening if worse

     local_sharpening = None
       .type = bool
       .short_caption = Local sharpening
       .help = Sharpen locally using overlapping regions. \
               NOTE: Best to turn off local_aniso_in_local_sharpening \
               if NCS is present.\
               If local_aniso_in_local_sharpening is True and NCS is \
               present this can distort the map for some NCS copies \
               because an anisotropy correction is applied\
               based on local density in one copy and is transferred without \
               rotation to other copies.

     local_aniso_in_local_sharpening = None
       .type = bool
       .short_caption = Local anisotropy
       .help = Use local anisotropy in local sharpening.  \
               Default is True unless NCS is present.

     overall_before_local = True
       .type = bool
       .short_caption = Overall before local
       .help = Apply overall scaling before local scaling

     select_sharpened_map = None
       .type = int
       .short_caption = Sharpened map to use
       .help = Select a single sharpened map to use

     read_sharpened_maps = None
       .type = bool
       .short_caption = Read sharpened maps
       .help = Read in previously-calculated sharpened maps

     write_sharpened_maps = None
       .type = bool
       .short_caption = Write sharpened maps
       .help = Write out local sharpened maps

     smoothing_radius = None
       .type = float
       .short_caption = Smoothing radius
       .help = Sharpen locally using smoothing_radius. Default is 2/3 of \
                 mean distance between centers for sharpening

     box_center = None
       .type = floats
       .short_caption = Center of box
       .help = You can specify the center of the box (A units)

     box_size = 30 30 30
       .type = ints
       .short_caption = Size of box
       .help = You can specify the size of the box (grid units)

     target_n_overlap = 10
       .type = int
       .short_caption = Target overlap of boxes
       .help = You can specify the targeted overlap of boxes in local \
           sharpening

     restrict_map_size = None
       .type = bool
       .short_caption = Restrict box map size
       .help = Restrict box map to be inside full map (required for cryo-EM data).\
               Default is True if use_sg_symmetry=False and False \
                if use_sg_symmetry=True

     remove_aniso = True
       .type = bool
       .short_caption = Remove anisotropy
       .help = You can remove anisotropy (overall and locally) during sharpening

     max_box_fraction = 0.5
       .type = float
       .short_caption = Max size of box for auto_sharpening
       .help = If box is greater than this fraction of entire map, use \
                entire map. Default is 0.5.

     density_select_max_box_fraction = 0.95
       .type = float
       .short_caption = Max size of box for density_select
       .help = If box is greater than this fraction of entire map, use \
                entire map for density_select. Default is 0.95
    cc_cut = 0.2
       .type = float
       .short_caption = Min reliable CC in half-maps
       .help = Estimate of minimum highly reliable CC in half-map FSC. Used\
               to decide at what CC value to smooth the remaining CC values.

     max_cc_for_rescale = 0.2
       .type = float
       .short_caption = Max CC for rescaleMin reliable CC in half-maps
       .help = Used along with cc_cut and scale_using_last to correct for \
               small errors in FSC estimation at high resolution.  If the \
               value of FSC near the high-resolution limit is above \
               max_cc_for_rescale, assume these values are correct and do not \
               correct them.

     scale_using_last = 3
       .type = int
       .short_caption = Last N bins in FSC assumed to be about zero
       .help = If set, assume that the last scale_using_last bins in the FSC \
          for half-map or model sharpening are about zero (corrects for  \
          errors int the half-map process).


     mask_atoms = True
       .type = bool
       .short_caption = Mask atoms
       .help = Mask atoms when using model sharpening

     mask_atoms_atom_radius = 3
       .type =float
       .short_caption = Mask radius
       .help = Mask for mask_atoms will have mask_atoms_atom_radius

     value_outside_atoms = None
       .type = str
       .short_caption = Value outside atoms
       .help = Value of map outside atoms (set to 'mean' to have mean \
                value inside and outside mask be equal)

     k_sharpen = 10
       .type = float
       .short_caption = sharpening transition
       .help = Steepness of transition between sharpening (up to resolution \
           ) and not sharpening (d < resolution).  Note: for blurring, \
           all data are blurred (regardless of resolution), while for \
           sharpening, only data with d about resolution or lower are \
           sharpened. This prevents making very high-resolution data too \
           strong.  Note 2: if k_sharpen is zero or None, then no \
           transition is applied and all data is sharpened or blurred. \

     iterate = False
       .type = bool
       .short_caption = Iterate auto-sharpening
       .help = You can iterate auto-sharpening. This is useful in cases where \
                 you do not specify the solvent content and it is not \
                 accurately estimated until sharpening is optimized.

     optimize_b_blur_hires = False
       .type = bool
       .short_caption = Optimize value of b_blur_hires
       .help = Optimize value of b_blur_hires. \
                Only applies for auto_sharpen_methods b_iso_to_d_cut and \
                b_iso. This is normally carried out and helps prevent \
                over-blurring at high resolution if the same map is \
                sharpened more than once.

     optimize_d_cut = None
       .type = bool
       .short_caption = Optimize value of d_cut
       .help = Optimize value of d_cut. \
                Only applies for auto_sharpen_methods b_iso_to_d_cut and \
                b_iso

     adjust_region_weight = True
       .type = bool
       .short_caption = Adjust region weight
       .help = Adjust region_weight to make overall change in surface area \
               equal to overall change in normalized regions over the range \
               of search_b_min to search_b_max using b_iso_to_d_cut.

     region_weight_method = initial_ratio *delta_ratio b_iso
       .type = choice
       .short_caption = Region weight method
       .help = Method for choosing region_weights. Initial_ratio uses \
               ratio of surface area to regions at low B value.  Delta \
               ratio uses change in this ratio from low to high B. B_iso \
               uses resolution-dependent b_iso (not weights) with the \
               formula b_iso=5.9*d_min**2

     region_weight_factor = 1.0
       .type = float
       .short_caption = Region weight factor
       .help = Multiplies region_weight after calculation with \
               region_weight_method above

     region_weight_buffer = 0.1
       .type = float
       .short_caption = Region weight factor buffer
       .help = Region_weight adjusted to be region_weight_buffer \
               away from minimum or maximum values

     target_b_iso_ratio = 5.9
       .type = float
       .short_caption = Target b_iso ratio
       .help = Target b_iso ratio : b_iso is estimated as \
               target_b_iso_ratio * resolution**2

     target_b_iso_model_scale = 0.
       .type = float
       .short_caption = scale on target b_iso ratio for model
       .help = For model sharpening, the target_biso is scaled \
                (normally zero).

     signal_min = 3.0
       .type = float
       .short_caption = Minimum signal
       .help = Minimum signal in estimation of optimal b_iso.  If\
                not achieved, use any other method chosen.

     search_b_min = None
       .type = float
       .short_caption = Low bound for b_iso search
       .help = Low bound for b_iso search. Default is -100.

     search_b_max = None
       .type = float
       .short_caption = High bound for b_iso search
       .help = High bound for b_iso search. Default is 300.

     search_b_n = None
       .type = int
       .short_caption = Number of b_iso values to search
       .help = Number of b_iso values to search. Default is 21.

     residual_target = None
       .type = str
       .short_caption = Residual target
       .help = Target for maximization steps in sharpening.  \
          Can be kurtosis or adjusted_sa (adjusted surface area).\
          Default is adjusted_sa.

     sharpening_target = None
       .type = str
       .short_caption = Overall sharpening target
       .help = Overall target for sharpening.  Can be kurtosis or adjusted_sa \
          (adjusted surface area).  Used to decide which sharpening approach \
          is used. Note that during optimization, residual_target is used \
          (they can be the same.) Default is adjusted_sa.

     require_improvement = None
       .type = bool
       .short_caption = Require improvement
       .help = Require improvement in score for sharpening to be applied.\
                Default is True.

     region_weight = None
       .type = float
       .short_caption = Region weighting
       .help = Region weighting in adjusted surface area calculation.\
            Score is surface area minus region_weight times number of regions.\
            Default is set automatically.  \
            A smaller value will give more sharpening.

     sa_percent = None
       .type = float
       .short_caption = Percent of target regions in adjusted_sa
       .help = Percent of target regions used in calulation of adjusted \
         surface area.  Default is 30.

     fraction_occupied = None
       .type = float
       .short_caption = Fraction of molecular volume inside contours
       .help = Fraction of molecular volume targeted to be inside contours. \
           Used to set contour level. Default is 0.20

      n_bins = None
        .type = int
        .short_caption = Resolution bins
        .help = Number of resolution bins for sharpening. Default is 20.
        .expert_level = 1

     regions_to_keep = None
       .type = int
       .short_caption = Regions to keep
       .help = You can specify a limit to the number of regions to keep\
                when generating the asymmetric unit of density.

      max_regions_to_test = None
        .type = int
        .short_caption = Max regions to test
        .help = Number of regions to test for surface area in adjusted_sa \
                scoring of sharpening. Default is 30

      eps = None
        .type = float
        .short_caption = Shift used in calculation of derivatives for \
           sharpening maximization.  Default is 0.01 for kurtosis and 0.5 for \
           adjusted_sa.

      k_sol = 0.35
        .type = float
        .help = k_sol value for model map calculation. IGNORED (Not applied)
        .short_caption = k_sol IGNORED
        .style = hidden

      b_sol = 50
        .type = float
        .help = b_sol value for model map calculation. IGNORED (Not applied)
        .short_caption = b_sol IGNORED
        .style = hidden
    """

output_files = """

    shifted_map_file = shifted_map.ccp4
      .type = str
      .help = Input map file shifted to new origin.
      .short_caption = Shifted map file
      .style = new_file

    sharpened_map_file = None
      .type = str
      .help = Sharpened input map file. In the same location as input map.
      .short_caption = Sharpened map file
      .input_size = 400
      .style = new_file
      .expert_level = 1

    shifted_sharpened_map_file = None
      .type = str
      .help = Input map file shifted to place origin at 0,0,0 and sharpened.
      .short_caption = Shifted sharpened map file
      .input_size = 400
      .style = new_file

    sharpened_map_coeffs_file = None
      .type = str
      .help = Sharpened input map \
              (shifted to new origin if original origin was not 0,0,0), \
              written out as map coefficients
      .short_caption = Sharpened map coeffs file
      .input_size = 400
      .style = new_file

    output_weight_map_pickle_file = weight_map_pickle_file.pkl
       .type = path
       .short_caption = Output weight map pickle file
       .help = Output weight map pickle file
       .style = new_file

    output_directory =  None
      .type = path
      .help = Directory where output files are to be written \
                applied.
      .short_caption = Output directory
      .style = new_file directory
"""

crystal_info = """
     is_crystal = None
       .type = bool
       .short_caption = Is a crystal
       .help = Defines whether this is a crystal (or cryo-EM).\
                Default is True if use_sg_symmetry=True and False otherwise.

     resolution = None
       .type = float
       .short_caption = Resolution
       .help = Optional nominal resolution of the map.
       .style = resolution
       .expert_level = 1


     solvent_content = None
       .type = float
       .help = Optional solvent fraction of the cell.
       .short_caption = Solvent content

     solvent_content_iterations = 3
       .type = int
       .help = Iterations of solvent fraction estimation. Used for ID of \
               solvent content in boxed maps.
       .short_caption = Solvent fraction iterations
       .style = hidden

     molecular_mass = None
       .type = float
       .help = Molecular mass of molecule in Da. Used as alternative method \
                 of specifying solvent content.
       .short_caption = Molecular mass in Da

      ncs_copies = None
        .type = int
        .help = You can specify ncs copies and seq file to define solvent \
            content
        .short_caption = NCS copies

     wang_radius = None
       .type = float
       .help = Wang radius for solvent identification. \
           Default is 1.5* resolution
       .short_caption = Wang radius

     buffer_radius = None
       .type = float
       .help = Buffer radius for mask smoothing. \
           Default is resolution
       .short_caption = Buffer radius

     pseudo_likelihood = None
       .type = bool
       .help = Use pseudo-likelihood method for half-map sharpening. \
               (In development)
       .short_caption = Pseudo-likelihood
       .style = hidden
"""

master_phil = iotbx.phil.parse("""

  input_files
    .style = menu_item auto_align
  {

    map_file = None
      .type = path
      .help = File with CCP4-style map
      .short_caption = Map file
      .style = file_type:ccp4_map bold input_file

    half_map_file = None
      .type = path
      .multiple = True
      .short_caption = Half map
      .style = file_type:ccp4_map bold input_file
      .help = Half map (two should be supplied) for FSC calculation. Must \
               have grid identical to map_file

    external_map_file = None
      .type = path
      .short_caption = External map
      .style = file_type:ccp4_map bold input_file
      .help = External map to be used to scale map_file (power vs resolution\
              will be matched)

    map_coeffs_file = None
      .type = path
      .help = Optional file with map coefficients
      .short_caption = Map coefficients
      .style = bold file_type:hkl input_file process_hkl \
        child:map_labels:map_coeffs_labels \
        child:space_group:space_group child:unit_cell:unit_cell

    map_coeffs_labels = None
      .type = str
      .input_size = 160
      .help = Optional label specifying which columns of of map coefficients \
          to use
      .short_caption = Map coeffs label
      .style = renderer:draw_map_arrays_widget

    pdb_file = None
      .type = path
      .help = If a model is supplied, the map will be adjusted to \
                maximize map-model correlation.  This can be used \
                to improve a map in regions where no model is yet \
                built.
      .style = file_type:pdb input_file
      .short_caption = Model file (optional)

    ncs_file = None
      .type = path
      .help = File with NCS information (typically point-group NCS with \
               the center specified). Typically in  PDB format. \
              Can also be a .ncs_spec file from phenix. \
              Created automatically if symmetry is specified.
      .short_caption = NCS info file

    seq_file = None
       .type = path
       .short_caption = Sequence file
       .style = file_type:seq input_file
       .help = Sequence file (unique chains only,  \
               1-letter code, chains separated by \
               blank line or greater-than sign.)  \
               Can have chains that are DNA/RNA/protein and\
               all can be present in one file.

    input_weight_map_pickle_file = None
      .type = path
      .short_caption = Input weight map pickle file
      .help = Weight map pickle file

  }

  output_files
    .style = menu_item auto_align
  {
   %s
  }

  crystal_info
    .style = menu_item auto_align
  {
   %s
  }

  map_modification {
    %s
  }


   control
     .style = menu_item auto_align
   {
     verbose = False
        .type = bool
        .help = '''Verbose output'''
        .short_caption = Verbose output

     resolve_size = None
        .type = int
        .help = "Size of resolve to use. "
        .style = hidden

     ignore_map_limitations = None
       .type = bool
       .short_caption = Ignore map limitations
       .help = Ignore limitations such as 'map cannot be sharpened'

      multiprocessing = *multiprocessing sge lsf pbs condor pbspro slurm
        .type = choice
        .short_caption = multiprocessing type
        .help = Choices are multiprocessing (single machine) or queuing systems

      queue_run_command = None
        .type = str
        .short_caption = Queue run command
        .help = run command for queue jobs. For example qsub.

      nproc = 1
        .type = int
        .short_caption = Number of processors
        .help = Number of processors to use
        .style = renderer:draw_nproc_widget bold

   }

  include scope libtbx.phil.interface.tracking_params

  gui
    .help = "GUI-specific parameter required for output directory"
  {
    output_dir = None
    .type = path
    .style = output_dir
  }

""" %(output_files, crystal_info, map_modification_phil_str),
  process_includes=True)
master_params = master_phil

def get_params(args,out=sys.stdout):
  """Get parameters from args"""

  command_line = iotbx.phil.process_command_line_with_files(
    reflection_file_def="input_files.map_coeffs_file",
    map_file_def="input_files.map_file",
    pdb_file_def="input_files.pdb_file",
    seq_file_def="input_files.seq_file",
    ncs_file_def="input_files.ncs_file",
    args=args,
    master_phil=master_phil)


  print("\nAuto-sharpen a map\n", file=out)
  params=command_line.work.extract()
  print("Command used: %s\n" %(
   " ".join(['phenix.auto_sharpen']+args)), file=out)
  master_params.format(python_object=params).show(out=out)

  if params.output_files.output_directory is None:
    params.output_files.output_directory=os.getcwd()
  elif not os.path.isdir(params.output_files.output_directory):
    os.mkdir(params.output_files.output_directory)

  params=set_sharpen_params(params,out)
  return params


def set_sharpen_params(params,out=sys.stdout):
  """Set and check sharpening parameters"""

  if params.map_modification.resolution_dependent_b==[0,0,0]:
    params.map_modification.resolution_dependent_b=[0,0,1.e-10]
    # just so that we know it was set

  if params.map_modification.b_iso:
    if params.map_modification.k_sharpen and \
        'b_iso_to_d_cut' in params.map_modification.auto_sharpen_methods:
      params.map_modification.auto_sharpen_methods=['b_iso_to_d_cut']
    elif 'b_iso_to_d_cut' in params.map_modification.auto_sharpen_methods and\
        len(params.map_modification.auto_sharpen_methods)==1:
      params.map_modification.auto_sharpen_methods=['b_iso_to_d_cut']
    else:
      params.map_modification.auto_sharpen_methods=['b_iso']

  if (params.map_modification.b_iso and \
       params.map_modification.auto_sharpen_methods in [
       ['b_iso_to_d_cut'],['b_iso']])   or  \
     (params.map_modification.resolution_dependent_b and \
       params.map_modification.auto_sharpen_methods in [
       ['resolution_dependent']]):
    if params.map_modification.box_in_auto_sharpen and (
      not getattr(params.map_modification,'allow_box_if_b_iso_set',None)):
      params.map_modification.box_in_auto_sharpen=False
      print("Set box_in_auto_sharpen=False as parameters are set "+\
        "\nand sharpening method is %s" %(
        params.map_modification.auto_sharpen_methods[0]), file=out)
    if params.map_modification.density_select_in_auto_sharpen and (
      not getattr(params.map_modification,'allow_box_if_b_iso_set',None)):
      params.map_modification.density_select_in_auto_sharpen=False
      print("Set density_select_in_auto_sharpen=False as parameters are set "+\
        "\nand sharpening method is %s" %(
        params.map_modification.auto_sharpen_methods[0]), file=out)

  if params.map_modification.optimize_b_blur_hires and \
    not 'b_iso_to_d_cut' in params.map_modification.auto_sharpen_methods and \
       not 'b_iso' in params.map_modification.auto_sharpen_methods:
     print("Set optimize_b_blur_hires=False as neither b_iso_to_d_cut nor"+\
         " b_iso are used", file=out)
     params.map_modification.optimize_b_blur_hires=False
  if params.map_modification.iterate and \
    not 'b_iso_to_d_cut' in params.map_modification.auto_sharpen_methods and \
       not 'b_iso' in params.map_modification.auto_sharpen_methods:
     print("Set iterate=False as neither b_iso_to_d_cut nor"+\
         " b_iso are used", file=out)
     params.map_modification.iterate=False

  if 'half_map_sharpening' in params.map_modification.auto_sharpen_methods and \
   ((not params.input_files.half_map_file) or
   (not len(params.input_files.half_map_file))==2):
    print("Skipping half-map sharpening as there are no half-maps supplied...",
      file = out)
    params.map_modification.auto_sharpen_methods.remove('half_map_sharpening')

  return params


def get_map_coeffs_from_file(
      map_coeffs_file=None,
      map_coeffs_labels=None):
    """Get map coeffs from a file with reflection_file_reader. Use
     data_manager instead."""
    from iotbx import reflection_file_reader
    reflection_file=reflection_file_reader.any_reflection_file(
        map_coeffs_file)
    mtz_content=reflection_file.file_content()
    for ma in reflection_file.as_miller_arrays(merge_equivalents=True):
      if not ma.is_complex_array(): continue
      labels=",".join(ma.info().labels)
      if not map_coeffs_labels or labels==map_coeffs_labels:  # take it
         return ma

def map_inside_cell(pdb_hierarchy,crystal_symmetry=None):
  """Map (move) coordinates in hierarchy to center them in the cell"""
  pa=pdb_hierarchy.atoms()
  sites_cart=pa.extract_xyz()
  from cctbx.maptbx.segment_and_split_map import move_xyz_inside_cell
  new_sites_cart=move_xyz_inside_cell(xyz_cart=sites_cart,
     crystal_symmetry=crystal_symmetry)
  pa.set_xyz(new_sites_cart)
  return pdb_hierarchy


def get_map_and_model(params=None,
    map_data=None,
    crystal_symmetry=None,
    pdb_hierarchy=None,
    ncs_obj=None,
    half_map_data_list=None,
    map_coords_inside_cell=True,
    get_map_labels=None,
    out=sys.stdout):

  """Get maps and model for auto_sharpen.
  Returns   pdb_hierarchy,
       map_data,half_map_data_list,ncs_obj,crystal_symmetry,acc,
       original_crystal_symmetry,original_unit_cell_grid.
  if get_map_labels is set, also return map_labels
  """


  acc=None # accessor used to shift map back to original location if desired
  origin_frac=(0,0,0)
  map_labels=None
  if map_data and crystal_symmetry:
    original_crystal_symmetry=crystal_symmetry
    original_unit_cell_grid=None
    acc=map_data.accessor()
    shift_needed = not \
       (map_data.focus_size_1d() > 0 and map_data.nd() == 3 and
        map_data.is_0_based())
    if(shift_needed):
      origin_shift=(
        map_data.origin()[0]/map_data.all()[0],
        map_data.origin()[1]/map_data.all()[1],
        map_data.origin()[2]/map_data.all()[2])
      origin_frac=origin_shift  # NOTE: fraction of NEW cell
      map_data = map_data.shift_origin()
    else:
      origin_frac=(0.,0.,0.)

  elif params.input_files.map_file:
    print("\nReading map from %s\n" %( params.input_files.map_file), file=out)
    from cctbx.maptbx.segment_and_split_map import get_map_object
    map_data,space_group,unit_cell,crystal_symmetry,origin_frac,acc,\
        original_crystal_symmetry,original_unit_cell_grid,map_labels=\
      get_map_object(file_name=params.input_files.map_file,
      must_allow_sharpening=(not params.control.ignore_map_limitations),
      get_map_labels=True,out=out)
    map_data=map_data.as_double()
    if origin_frac != (0,0,0) and acc is None:
      print("\nWARNING: Unable to place output map at position of "+\
        "input map though input map has non-zero origin at %s\n" %(
        str(origin_frac)), file=out)

  elif params.input_files.map_coeffs_file:
    map_coeffs=get_map_coeffs_from_file(
      map_coeffs_file=params.input_files.map_coeffs_file,
      map_coeffs_labels=params.input_files.map_coeffs_labels)

    if not map_coeffs:
      raise Sorry("Could not get map coeffs from %s with labels %s" %(
        params.input_files.map_coeffs_file,params.input_files.map_coeffs_labels))
    print("Map coefficients read from %s with labels %s" %(
         params.input_files.map_coeffs_file,
         str(params.input_files.map_coeffs_labels)), file=out)
    crystal_symmetry=map_coeffs.crystal_symmetry()
    from cctbx.development.create_models_or_maps import get_map_from_map_coeffs
    map_data=get_map_from_map_coeffs(
      map_coeffs=map_coeffs,crystal_symmetry=crystal_symmetry)
    acc=map_data.accessor()
    original_crystal_symmetry=crystal_symmetry
    original_unit_cell_grid=None
    if not params.crystal_info.resolution:
      params.crystal_info.resolution=map_coeffs.d_min()
      print("Resolution from map_coeffs is %7.2f A" %(
          params.crystal_info.resolution), file=out)
  else:
    raise Sorry("Need ccp4 map or map_coeffs")

  if params.input_files.external_map_file and not \
      params.map_modification.auto_sharpen_methods==['external_map_sharpening']:
    raise Sorry("For external map sharpening, please do not set any other "+
        "options in 'Sharpening methods' (options set: %s)" %(
      ", ".join(params.map_modification.auto_sharpen_methods)))


  if params.map_modification.auto_sharpen_methods==['external_map_sharpening']:
    if not params.input_files.external_map_file:
      raise Sorry("Need external_map_file for external_map")
    if params.input_files.half_map_file:
      raise Sorry("Cannot use half_map_file with external_map")
    half_map_data_list=[]
    file_name=params.input_files.external_map_file
    print("\nReading external map from %s\n" %(file_name), file=out)
    half_map_data,half_map_space_group,half_map_unit_cell,\
        half_map_crystal_symmetry,half_map_origin_frac,half_map_acc,\
         half_map_original_crystal_symmetry,half_map_original_unit_cell_grid=\
        get_map_object(file_name=file_name,out=out)
    half_map_data=half_map_data.as_double()
    assert half_map_crystal_symmetry.is_similar_symmetry(crystal_symmetry)
    half_map_data_list.append(half_map_data) # save it in half_map_data_list
    # and add another just so we have two..
    half_map_data_list.append(half_map_data.deep_copy())
    if map_data and half_map_data.size()!=map_data.size():
      raise Sorry("Map data and external_map_file data must be the same size")


  if params.input_files.half_map_file:
    if len(params.input_files.half_map_file) != 2:
      raise Sorry("Please supply zero or two half_map files")
    half_map_data_list=[]
    from cctbx.maptbx.segment_and_split_map import get_map_object
    for file_name in params.input_files.half_map_file:
      print("\nReading half-map from %s\n" %(file_name), file=out)
      half_map_data,half_map_space_group,half_map_unit_cell,\
        half_map_crystal_symmetry,half_map_origin_frac,half_map_acc,\
         half_map_original_crystal_symmetry,half_map_original_unit_cell_grid=\
        get_map_object(file_name=file_name,out=out)
      half_map_data=half_map_data.as_double()
      assert half_map_crystal_symmetry.is_similar_symmetry(crystal_symmetry)

      half_map_data_list.append(half_map_data)

  if params.crystal_info.resolution is None:
    raise Sorry("Need resolution for b-sharpening if "+
       "map is supplied and no model is supplied")

  if params.crystal_info.resolution >= 10:
    print("\n** WARNING: auto_sharpen is designed for maps at a "+\
      "resolution of about 4.5 A\nor better.  Sharpening may be"+\
      "poor at %7.0f A" %(params.crystal_info.resolution), file=out)


  if params.input_files.pdb_file and not pdb_hierarchy: # get model
    model_file=params.input_files.pdb_file
    if not os.path.isfile(model_file):
      raise Sorry("Missing the model file: %s" %(model_file))
    from iotbx.pdb.utils import get_pdb_hierarchy
    pdb_hierarchy= get_pdb_hierarchy(file_name = model_file)
  if pdb_hierarchy: # XXX added 2019-05-05
    if origin_frac != (0,0,0):
      print("Shifting model by %s" %(str(origin_frac)), file=out)
      from cctbx.maptbx.segment_and_split_map import \
         apply_shift_to_pdb_hierarchy
      origin_shift=crystal_symmetry.unit_cell().orthogonalize(
         (-origin_frac[0],-origin_frac[1],-origin_frac[2]))
      pdb_hierarchy=apply_shift_to_pdb_hierarchy(
       origin_shift=origin_shift,
       crystal_symmetry=crystal_symmetry,
       pdb_hierarchy=pdb_hierarchy,
       out=out)
    if map_coords_inside_cell:
      # put inside (0,1)
      pdb_hierarchy=map_inside_cell(pdb_hierarchy,crystal_symmetry=crystal_symmetry)

  if params.input_files.ncs_file and not ncs_obj: # NCS
    from cctbx.maptbx.segment_and_split_map import get_ncs
    ncs_obj,dummy_tracking_data=get_ncs(params,out=out)
    if origin_frac != (0,0,0):
      origin_shift=crystal_symmetry.unit_cell().orthogonalize(
         (-origin_frac[0],-origin_frac[1],-origin_frac[2]))
      print("Shifting NCS by (%7.2f,%7.2f,%7.2f) " %((origin_shift)), file=out)
      from scitbx.math import  matrix
      ncs_obj=ncs_obj.coordinate_offset(
       coordinate_offset=matrix.col(origin_shift))

  if get_map_labels:
    return pdb_hierarchy,\
       map_data,half_map_data_list,ncs_obj,crystal_symmetry,acc,\
       original_crystal_symmetry,original_unit_cell_grid,map_labels
  else:
    return pdb_hierarchy,\
      map_data,half_map_data_list,ncs_obj,crystal_symmetry,acc,\
       original_crystal_symmetry,original_unit_cell_grid


def run(args=None,params=None,
    map_data=None,crystal_symmetry=None,
    wrapping = None,
    write_output_files=True,
    pdb_hierarchy=None,
    ncs_obj=None,
    return_map_data_only=False,
    return_unshifted_map=False,
    half_map_data_list=None,
    ncs_copies=None,
    n_residues=None,
    out=sys.stdout):
  """Run auto-sharpening"""

  # Get the parameters
  if not params:
    params=get_params(args,out=out)

  if not ncs_copies:
    ncs_copies=params.crystal_info.ncs_copies

  # get map_data and crystal_symmetry

  pdb_hierarchy,map_data,half_map_data_list,ncs_obj,crystal_symmetry,acc,\
       original_crystal_symmetry,original_unit_cell_grid,map_labels=\
        get_map_and_model(
     map_data=map_data,
     half_map_data_list=half_map_data_list,
     pdb_hierarchy=pdb_hierarchy,
     ncs_obj=ncs_obj,
     map_coords_inside_cell=False,
     crystal_symmetry=crystal_symmetry,
     get_map_labels=True,
     params=params,out=out)
  # NOTE: map_data is now relative to origin at (0,0,0).
  # Use map_data.reshape(acc) to put it back where it was if acc is not None


  # auto-sharpen the map
  from cctbx.maptbx.segment_and_split_map import auto_sharpen_map_or_map_coeffs
  si=auto_sharpen_map_or_map_coeffs(
        resolution=params.crystal_info.resolution, # required
        crystal_symmetry=crystal_symmetry,
        is_crystal=params.crystal_info.is_crystal,
        verbose=params.control.verbose,
        resolve_size=params.control.resolve_size,
        multiprocessing=params.control.multiprocessing,
        nproc=params.control.nproc,
        queue_run_command=params.control.queue_run_command,
        map=map_data,
        wrapping=wrapping,
        half_map_data_list=half_map_data_list,
        solvent_content=params.crystal_info.solvent_content,
        molecular_mass=params.crystal_info.molecular_mass,
        input_weight_map_pickle_file=\
            params.input_files.input_weight_map_pickle_file,
        output_weight_map_pickle_file=\
            params.output_files.output_weight_map_pickle_file,
        read_sharpened_maps=params.map_modification.read_sharpened_maps,
        write_sharpened_maps=params.map_modification.write_sharpened_maps,
        select_sharpened_map=params.map_modification.select_sharpened_map,
        auto_sharpen=params.map_modification.auto_sharpen,
        local_sharpening=params.map_modification.local_sharpening,
        output_directory=params.output_files.output_directory,
        smoothing_radius=params.map_modification.smoothing_radius,
        local_aniso_in_local_sharpening=\
           params.map_modification.local_aniso_in_local_sharpening,
        overall_before_local=\
           params.map_modification.overall_before_local,
        box_in_auto_sharpen=params.map_modification.box_in_auto_sharpen,
        density_select_in_auto_sharpen=params.map_modification.density_select_in_auto_sharpen,
        density_select_threshold_in_auto_sharpen=params.map_modification.density_select_threshold_in_auto_sharpen,
        use_weak_density=params.map_modification.use_weak_density,
        discard_if_worse=params.map_modification.discard_if_worse,
        box_center=params.map_modification.box_center,
        box_size=params.map_modification.box_size,
        target_n_overlap=params.map_modification.target_n_overlap,
        restrict_map_size=params.map_modification.restrict_map_size,
        remove_aniso=params.map_modification.remove_aniso,
        auto_sharpen_methods=params.map_modification.auto_sharpen_methods,
        residual_target=params.map_modification.residual_target,
        region_weight=params.map_modification.region_weight,
        sa_percent=params.map_modification.sa_percent,
        eps=params.map_modification.eps,
        n_bins=params.map_modification.n_bins,
        max_regions_to_test=params.map_modification.max_regions_to_test,
        regions_to_keep=params.map_modification.regions_to_keep,
        fraction_occupied=params.map_modification.fraction_occupied,
        sharpening_target=params.map_modification.sharpening_target,
        d_min_ratio=params.map_modification.d_min_ratio,
        scale_max=params.map_modification.scale_max,
        input_d_cut=params.map_modification.input_d_cut,
        b_blur_hires=params.map_modification.b_blur_hires,
        max_box_fraction=params.map_modification.max_box_fraction,
        cc_cut=params.map_modification.cc_cut,
        max_cc_for_rescale=params.map_modification.max_cc_for_rescale,
        scale_using_last=params.map_modification.scale_using_last,
        density_select_max_box_fraction=params.map_modification.density_select_max_box_fraction,
        mask_atoms=params.map_modification.mask_atoms,
        mask_atoms_atom_radius=params.map_modification.mask_atoms_atom_radius,
        value_outside_atoms=params.map_modification.value_outside_atoms,
        k_sharpen=params.map_modification.k_sharpen,
        optimize_b_blur_hires=params.map_modification.optimize_b_blur_hires,
        iterate=params.map_modification.iterate,
        optimize_d_cut=params.map_modification.optimize_d_cut,
        soft_mask=params.map_modification.soft_mask,
        allow_box_if_b_iso_set=params.map_modification.allow_box_if_b_iso_set,
        search_b_min=params.map_modification.search_b_min,
        search_b_max=params.map_modification.search_b_max,
        search_b_n=params.map_modification.search_b_n,
        adjust_region_weight=params.map_modification.adjust_region_weight,
        region_weight_method=params.map_modification.region_weight_method,
        region_weight_factor=params.map_modification.region_weight_factor,
        region_weight_buffer=\
            params.map_modification.region_weight_buffer,
        target_b_iso_ratio=params.map_modification.target_b_iso_ratio,
        signal_min=params.map_modification.signal_min,
        buffer_radius=params.crystal_info.buffer_radius,
        wang_radius=params.crystal_info.wang_radius,
        pseudo_likelihood=params.crystal_info.pseudo_likelihood,
        target_b_iso_model_scale=params.map_modification.target_b_iso_model_scale,
        b_iso=params.map_modification.b_iso,
        b_sharpen=params.map_modification.b_sharpen,
        resolution_dependent_b=\
           params.map_modification.resolution_dependent_b,
        normalize_amplitudes_in_resdep=\
           params.map_modification.normalize_amplitudes_in_resdep,
        pdb_hierarchy=pdb_hierarchy,
        ncs_obj=ncs_obj,
        rmsd=params.map_modification.rmsd,
        rmsd_resolution_factor=params.map_modification.rmsd_resolution_factor,
        b_sol=params.map_modification.b_sol,
        k_sol=params.map_modification.k_sol,
        fraction_complete=params.map_modification.fraction_complete,
        seq_file=params.input_files.seq_file,
        ncs_copies=ncs_copies,
        n_residues=n_residues,
        out=out)

  # get map_data and map_coeffs of final map

  new_map_data=si.as_map_data()
  new_map_coeffs=si.as_map_coeffs()

  from cctbx.maptbx.segment_and_split_map import get_b_iso,map_coeffs_as_fp_phi
  f,phi=map_coeffs_as_fp_phi(new_map_coeffs)
  temp_b_iso=get_b_iso(f,d_min=params.crystal_info.resolution)

  if not si.is_model_sharpening():
    print(file=out)
    print(80*"=","\n",80*"=", file=out)
    print("\n           Summary of sharpening information\n ", file=out)
    si.show_summary(verbose=params.control.verbose,out=out)
    print(80*"=","\n",80*"=", file=out)

  # write out the new map_coeffs and map if requested:

  offset_map_data=new_map_data.deep_copy()
  if acc is not None:  # offset the map to match original if possible
    offset_map_data.reshape(acc)

  if write_output_files and (not params.output_files.sharpened_map_file):
    params.output_files.sharpened_map_file = 'sharpened_map.ccp4'
  if write_output_files and params.output_files.sharpened_map_file and \
      offset_map_data:
    output_map_file=os.path.join(params.output_files.output_directory,
        params.output_files.sharpened_map_file)
    from cctbx.maptbx.segment_and_split_map import write_ccp4_map
    if acc is not None:  # we offset the map to match original
      print("\nWrote sharpened map in original location with origin at %s\nto %s" %(
         str(offset_map_data.origin()),output_map_file), file=out)
      write_ccp4_map(original_crystal_symmetry, output_map_file,
        offset_map_data,
        output_unit_cell_grid=original_unit_cell_grid)
    else:
      print("\nWrote sharpened map with origin at 0,0,0 "+\
        "(NOTE: may be boxed map and may not be "+\
        "\nsame as original location) to %s\n" %(
         output_map_file), file=out)

    from iotbx.mrcfile import create_output_labels
    program_name='auto_sharpen'
    limitations=["map_is_sharpened"]
    labels=create_output_labels(program_name=program_name,
       input_file_name=params.input_files.map_file,
       input_labels=map_labels,
       limitations=limitations,
       output_labels=None)

    write_ccp4_map(crystal_symmetry, output_map_file, offset_map_data,
        labels=labels)

  if write_output_files and params.output_files.shifted_sharpened_map_file:
    output_map_file=os.path.join(params.output_files.output_directory,
        params.output_files.shifted_sharpened_map_file)
    from cctbx.maptbx.segment_and_split_map import write_ccp4_map
    write_ccp4_map(crystal_symmetry, output_map_file, new_map_data)
    print("\nWrote sharpened map (origin at %s)\nto %s" %(
     str(new_map_data.origin()),output_map_file), file=out)

  if write_output_files and (not params.output_files.sharpened_map_coeffs_file):
     params.output_files.sharpened_map_coeffs_file = 'sharpened_map_coeffs.mtz'
  if write_output_files and params.output_files.sharpened_map_coeffs_file and \
      new_map_coeffs:
    output_map_coeffs_file=os.path.join(params.output_files.output_directory,
        params.output_files.sharpened_map_coeffs_file)
    new_map_coeffs.as_mtz_dataset(column_root_label='FWT').mtz_object().write(
       file_name=output_map_coeffs_file)
    print("\nWrote sharpened map_coeffs (origin at 0,0,0)\n to %s\n" %(
       output_map_coeffs_file), file=out)

  if return_unshifted_map:
    map_to_return=offset_map_data
  else:
    map_to_return=new_map_data

  if return_map_data_only:
    return map_to_return
  else:  #usual
    return map_to_return,new_map_coeffs,crystal_symmetry,si

# =============================================================================
# GUI-specific bits for running command
from libtbx import runtime_utils
class launcher(runtime_utils.target_with_save_result):
  """Launch this method from GUI"""
  def run(self):
    import os
    from wxGUI2 import utils
    utils.safe_makedirs(self.output_dir)
    os.chdir(self.output_dir)
    map_to_return, new_map_coeffs, crystal_symmetry, si = \
      run(args=self.args, out=sys.stdout)
    si.map_data = None
    result = (None, None, crystal_symmetry, si)
    return result

def validate_params(params):
  """Check parameters for GUI"""
  if ( (params.input_files.map_coeffs_file is None) and
       (params.input_files.map_file is None) ):
    raise Sorry('Please provide a map file.')
  if ( (params.input_files.map_coeffs_file is not None) and
       (params.input_files.map_coeffs_labels is None) ):
    raise Sorry('Please select the label for the map coefficients.')
  if ( (params.input_files.map_file is not None) and
       (params.crystal_info.resolution is None) ):
    raise Sorry('Please provide a resolution limit.')
  return True

# =============================================================================

if __name__=="__main__":
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/maptbx/bcr/__init__.py


 *******************************************************************************


 *******************************************************************************
cctbx/maptbx/bcr/bcr.py
from __future__ import absolute_import, division, print_function
import math
from scipy.optimize import minimize
from libtbx import adopt_init_args

from cctbx.array_family import flex
import scitbx.minimizers

# Adapted by Pavel Afonine. This is a verbatim copy of the original code
# supplied by A. Urzhumtsev on September 12, 2024; dec3D, version 7.6

# the modification are :
#- removing data-iinput routines
#- including first line till 'PreciseData'
#- modification of the minimizer's call in 'RefineBCR'
#- inserted that all prints are under condition : 'nfmes is not None'

######################################################
#
#    decomposition of oscillating curves
#    (atomic images at a given resolution)
#                                by A.Urzhumtsev, L.Urzhumtseva, 2021
#
#    python remake of the respective fortran program
#
#    input curves are obtained by 'image-atom.py'
#
######################################################

def gauss(B, C, r, b_iso):
  assert B>0
  B = B + b_iso
  fpob = 4 * math.pi / B
  return C * fpob**1.5 * math.exp(-fpob*math.pi*r**2)

def chi(B, R, r, b_iso):
  assert B>0
  assert R>0
  assert r>=0
  B = B + b_iso
  mfpsob = (-4*math.pi**2)/B
  if(r==0):
    return ((4*math.pi/B)**1.5) * math.exp(mfpsob*R**2)
  else:
    e1 = math.exp(mfpsob*(r-R)**2)
    e2 = math.exp(mfpsob*(r+R)**2)
    return (4*math.pi*B)**(-0.5) * (1/(r*R)) * (e1-e2)

class calculator(object):

  def __init__(self, npeak,dens,yc,dist,nfmes, x, mdist,edist,
               bound_flags, lower_bound, upper_bound):
    adopt_init_args(self, locals())
    self.x = flex.double(x)

  def update(self, x):
    self.x = x

  def gradients(self):
    return flex.double(GradFit(self.x, self.npeak, self.dens, self.yc, self.dist,
      self.mdist,self.edist, self.nfmes))

  def target(self):
    return FuncFit(self.x, self.npeak, self.dens, self.yc, self.dist,
      self.mdist,self.edist, self.nfmes)

#============================
def get_BCR(dens,dist,dmax,mxp,epsc,epsp=0.000,edist=1.0E-13,kpres=1,kprot=3,nfmes=None):

#    dens   - array of the curve values,
#             in in creasing order of the argument starting from 0
#    dist   - array of the argument values ; normally this is a regular grid
#    dmax   - maximal distance value till which the curve will be approximated
#    mxp    - maximal number of terms ; except special cases, it is recommended
#             to choose a large value (e.g., 1000) and limit the number of terms
#             rather referring to the parameter epsc below
#    epsc   - precision with which the decomposition will be constructed;
#             A KEY PARAMETER ;
#             the value recommended is 0.001; at least for atomic images, this gives
#             an accurate approximation with a single term per a local peak for most of
#             atomic images at conventional resolution
#    epsp   - part of the value of the local peak defining the peak limits;
#             use values in the ragne 0.0 - 0.005
#    edist  - value at which the atomic contribution considered as negligibly small;
#             1.0E-13 ie recommended;
#    kpres  - defines if the precision is given in absolute values (=1) or as a part of
#             peak in the origin, dens[0]
#    kprot  - type of the peak analysis processing; kprot = 3 is recommended
#             1 - only one iteration; refinement at the end
#             2 - only one iteration; refinement of each term instantly
#             3 - several iterations allowed; refinement at the end of each iteration
#             4 - several iterations allowed; refinement at the end of each iteration
#                 except for the first peak (supposed to be that in the origin)
#             5 - several iterations allowed; refinement of each term instantly

    #if (nfmes is not None) :
    #   print('',file=nfmes)
    #   print(30*'=',' NEW CURVE IN PROCESS ',30*'=',file=nfmes)
    #
    #   print('')
    #   print(30*'=',' NEW CURVE IN PROCESS ',30*'=')

    bpeak  = [ 0 for i in range(2*mxp+2) ]
    cpeak  = [ 0 for i in range(2*mxp+2) ]
    rpeak  = [ 0 for i in range(2*mxp+2) ]

#   definition / estimations of the internal parameters

    ceps,bmin,cmin,rmin,edist,mdist = PreciseData(kpres,epsc,epsp,edist,
                                                  dmax,dens[0],dist,nfmes)
#--------------------------------------
#
#   starting point to search for the peaks;
#   number of terms found previously

    kpeak = 0
    npeak = -1
    curres,curve,epsres =  CurveDiff(dens,dist,mdist,edist,nfmes,bpeak,cpeak,rpeak,npeak,mxp)

#--------------------------------------

#   main cycle over peaks including the residual one in the origin

    while (epsres >= ceps) and (npeak < mxp) :

#       find next group of peaks

        kpeak,kneg,curres = NextPeak(curres,mdist,kpeak,nfmes,ceps)

        if kpeak >= 0 and kpeak <= mdist :

           bpeak,cpeak,rpeak,npeak,kdist,kpeak = PeakBCR(curres,dist,mdist,ceps,kneg,kpeak,
                                            bpeak,cpeak,rpeak,npeak,epsp,bmin,cmin,rmin,mxp,nfmes)

           if npeak == mxp or kprot == 2 or kprot == 5 or (kprot == 4 and npeak == 0):

#             if the last (mxp) peak found or
#             if the accurate accurate search protocol applied :
#             refine parameters in the extended interval
#                    and remove contribution

              bpeak,cpeak,rpeak =        \
                    RefineBCR(dens,dist,mdist,edist,bpeak,cpeak,rpeak,npeak,bmin,cmin,rmin,nfmes)

              curres,curve,epsres = \
                               CurveDiff(dens,dist,mdist,edist,nfmes,bpeak,cpeak,rpeak,npeak,mxp)
        else :

#          no more peaks ; the whole interval has been analysed
#          refine estimated parameters in the required interval
#          remove the contribution of the modeled peaks and update start search point

           if kprot == 1 or kprot == 3 or kprot == 4 :

              bpeak,cpeak,rpeak =        \
                    RefineBCR(dens,dist,mdist,edist,bpeak,cpeak,rpeak,npeak,bmin,cmin,rmin,nfmes)

              curres,curve,epsres = \
                               CurveDiff(dens,dist,mdist,edist,nfmes,bpeak,cpeak,rpeak,npeak,mxp)

           if kprot == 1 or kprot == 2 :
              break
           elif kprot == 5 :
              kprot = 3

           kpeak = 0
#
#   end of the main cycle ;
#
#   filter out weak terms if possible

    bpeak,cpeak,rpeak,mpeak,curve,curres,epsres = FilterWeak(dens,curve,curres,dist,mdist, \
                       edist,epsres,bpeak,cpeak,rpeak,npeak,mxp,bmin,cmin,rmin,nfmes,ceps)

    return bpeak,cpeak,rpeak,mpeak,curve,curres,epsres

#============================
def RefineBCR(dens,dist,mdist,edist,bpeak,cpeak,rpeak,npeak,bmin,cmin,rmin,nfmes):

    ndist = len(dist) - 1

    xc        = [ 0 for i in range(3*(npeak+1)) ]
    yc        = [ 0 for i in range(ndist+1) ]
    bcrbounds = [ (None,None) for i in range(3*(npeak+1)) ]

    sp = ' '

#   define bounds
#   cmin is the bound for |c| and not for c itself

#!!!!!!!!!!!!!! inserted by P.Afonine instead of the original call of "minimize"

    for i in range(npeak+1):
        i3 = i*3
        xc[i3]   = bpeak[i]
        xc[i3+1] = cpeak[i]
        xc[i3+2] = rpeak[i]
        bcrbounds[i3]   = (bmin,1000.)
        bcrbounds[i3+2] = (rmin,dist[ndist]*1.2)
        if cpeak[i] > 0.0 :
           bcrbounds[i3+1] = (cmin,1000.)
        else :
           bcrbounds[i3+1] = (-1000.,-cmin)

#   minimization

    for it in range(1,3):
      if it > 1:
        xc = res.x
      lbound = []
      ubound = []
      for b in bcrbounds:
        lbound.append(b[0])
        ubound.append(b[1])

      CALC = calculator(npeak,dens,yc,dist,nfmes, xc, mdist,edist,
        bound_flags = flex.int(len(xc), 2),
        lower_bound = lbound,
        upper_bound = ubound)

      res = scitbx.minimizers.lbfgs(
           mode='lbfgsb', max_iterations=500, calculator=CALC)

    res.x = list(res.x)

    if 0: # SciPy analogue. Works with Python 3 only.
      res = minimize(FuncFit,xc,args=(npeak,dens,yc,dist,ndist,nfmes),
                 method='L-BFGS-B',jac=GradFit, bounds = bcrbounds)

#!!!!!!!!!!! end of the insertion

#   recover refined values

    #if (nfmes is not None) :
    #   print('',file=nfmes)
    #   print(' parameters before and after their refinement:'     ,file=nfmes)
    #   print(' Nterm    R (M)   ',6*' ','B (N)   ',6*' ','C (K)   ',5*' ',
    #                  'R (M)   ',6*' ','B (N)   ',6*' ','C (K)   ',file=nfmes)
    #
    #   print('')
    #   print(' parameters before and after their refinement:')
    #   print(' Nterm    R (M)   ',6*' ','B (N)   ',6*' ','C (K)   ',5*' ',
    #                   'R (M)   ',6*' ','B (N)   ',6*' ','C (K)   ')

    for i in range(npeak+1):
        i3 = i*3
        b0 , c0, r0 = res.x[i3] , res.x[i3+1] , res.x[i3+2]

        #if (nfmes is not None) :
        #   print(f'{i+1:6}{rpeak[i]:16.10f}{bpeak[i]:16.10f}{cpeak[i]:11.5f}   ',
        #         f'{r0:16.10f}{b0:16.10f}{c0:11.5f}',file=nfmes)
        #
        #   print(f'{i+1:6}{rpeak[i]:16.10f}{bpeak[i]:16.10f}{cpeak[i]:11.5f}   ',
        #         f'{r0:16.10f}{b0:16.10f}{c0:11.5f}')

        bpeak[i] , cpeak[i] , rpeak[i] = b0 , c0 , r0

    return bpeak,cpeak,rpeak

#============================
def PreciseData(kpres,epsc,epsp,edist,dmax,peak,dist,nfmes):

#   ceps  - defines accuracy in absolute values
#   bmin  - defines sharpest drop < 10**(-ndrop) of the 3D-exponential
#            at a distance = grid step
#   cmin  - defines minimal peak height (64 majorates (4*pi)**1.5 )
#   epsp  - drop when approximating internal peaks
#   edist - limit of the term contribution

    ndist = len(dist) -1

#   precision constants

    if kpres > 0:
      ceps  = epsc
    else:
      ceps  = abs(peak) * epsc
      edist = abs(peak) * edist

#   find the point in 'dist' for the required distance limit

    mdist = ndist
    if dist[ndist] < dmax :
       print('*** warning : curve interval is defined for x <= ',dist[ndist])
       print('              shrter that the required distance  ',dmax)
    else :
       for ix in range(ndist+1) :
           if dist[ix] > dmax :
              mdist = ix - 1
              break

#   estimates for a regular grid with step = dist(1) - dist(0)

    dstep = dist[1]
    ndrop = 2.
    bmin  = 16.*dstep*dstep/ndrop
    cmin  = ceps*(bmin**1.5)/64.
    rmin  = 0.0

    #print ('',file=nfmes)
    #print (' INTERNAL DECOMPOSITION PARAMETERS ',file=nfmes)
    #print ('',file=nfmes)
    #print (' absolute max allowed error     ',f'{ceps:13.5e}' ,file=nfmes)
    #print (' drop to estimate the peak width',f'{epsp:13.5e}' ,file=nfmes)
    #if edist > 0.0 :
    #   print (' term extension limit           ',f'{edist:13.5e}',file=nfmes)
    #else :
    #   print (' term extension limit :            no limit applied',file=nfmes)
    #print (' estimated accuracy parameters :',file=nfmes)
    #print ('    bmin                        ',f'{bmin:13.5e}' ,file=nfmes)
    #print ('    cmin                        ',f'{cmin:13.5e}' ,file=nfmes)
    #print ('---------------------------',file=nfmes)

    return ceps,bmin,cmin,rmin,edist,mdist

#============================
def CurveInvert(dens,d0):

    ndist = len(dens) - 1

    for i in range(ndist+1):
      dens[i] = -dens[i]

    d0 = -d0

    return dens,d0

#============================
def GaussBC(curres,dist,epsp,bmin,cmin,nfmes):

    ndist = len(dist) -1

    cpi   = math.pi

#   inflection point and approximate curve till this point

    kpeak = 0
    r0    = dist[kpeak]

    minf = NumInflRight(curres,kpeak,epsp)
    if minf == 0:
       b0 = 2.0*bmin
       c0 = curres[kpeak] * (b0/(4.0*cpi))**1.5
    else:
       ug,vg = uvFitGaussR(curres,dist,r0,kpeak,minf)
       b0 = 4.0 * cpi**2 / vg
       c0 = ug  * (cpi/vg)**1.5
       if b0 < 2.0*bmin:
          b0 = 2.0*bmin

    if c0 < 2.0*cmin:
       c0 = 2.0*cmin

    return b0,c0,r0,minf

#============================
def RippleBCR(curres,dist,mdist,kpeak,epsp,bmin,cmin,rmin,nfmes):

#   inflection point and approximate curve till this point

    ndist = len(dist) -1
    cpi   = math.pi

    minfr = NumInflRight(curres,kpeak,epsp)
    minfl = NumInflLeft(curres,kpeak,epsp)

    if minfr-minfl <= 1:
       b0 = 2.0*bmin
       c0 = curres[kpeak] * math.sqrt(4.0*cpi*b0) * dist[kpeak]**2
    else:
       ug,vg = uvFitGaussR(curres,dist,dist[kpeak],minfl,minfr)
       b0    = 4.0 * cpi * cpi / vg
       if b0 < 2.0*bmin:
          b0 = 2.0*bmin
       c0    = ug * math.sqrt(b0)

    if c0 < 2.0*cmin:
       c0 = 2.0*cmin
    r0 = dist[kpeak]

    kdist = minfr

    return b0,c0,r0,kdist

#============================
def TailBCR(curres,dist,mdist,epsp,bmin,cmin,rmin,nfmes):

#   inflection point for the peak at the upper interval bound

    ndist = len(dist) -1

#   the peak at the upper bound of the required interval

    kpeak = mdist
    if mdist < ndist :
       kpeak = NumPeakRight(curres,mdist)

    if kpeak < ndist :

#      an internal peak in the extended interval

       b0, c0, r0, kdist = RippleBCR(curres,dist,mdist,kpeak,epsp,bmin,cmin,rmin,nfmes)

    else :

#      otherwise find the inflection point to the left
#      and approximate the curve till this point

       b0, c0, r0, kdist = border(dist,mdist,epsp,bmin,cmin,rmin,curres,nfmes)

    return b0, c0, r0, kdist

#============================
def border(dist,kpeak,epsp,bmin,cmin,rmin,curres,nfmes):

    ndist = len(dist) - 1

    kdist = ndist
    r0    = dist[ndist]
    kref = NumInflLeft(curres,ndist,epsp)

    if kref == ndist :
          b0 = 2.0*bmin
          c0 = curres[ndist] * math.sqrt(4*math.pi*b0) * r0**2
    elif kref == ndist-1 :
          b0 = 4.0*bmin
          c0 = curres[ndist] * math.sqrt(4*math.pi*b0) * r0**2
    else :
       ug,vg = uvFitGaussR(curres,dist,r0,kref,ndist)
       b0    = 4.0 * math.pi**2 / vg
       if b0 < 2.0*bmin:
          b0 = 2.0*bmin
       c0    = ug * math.sqrt(b0)

    if c0 < 2.0*cmin:
       c0 = 2.0*cmin

    return b0,c0,r0,kdist

#============================
def NumPeakRight(curres,npeak):

#   peak in the interval npeak <= ndist
#   (if nreak is on the upper bound of the search interval)

    ndist = len(curres) - 1

    npeakr = npeak
    if npeak < ndist :
       for i in range (npeak+1,ndist+1) :
           if curres[i] < curres[i-1] :
              npeakr = i - 1
              break

    return npeakr

#============================
def NumInflRight(curres,kpeak,epsp):

#   right inflection point ; always 0 <= kpeak < ndist

    ndist = len(curres) - 1

    clim = epsp * curres[kpeak]

    k = ndist
    if kpeak < ndist-1 :
       for i in range (kpeak,ndist-1) :
           if curres[i+1] <= clim or curres[i+2]+curres[i]-2.*curres[i+1] >= 0.0 :
              k = i
              break

    if k < ndist or curres[ndist] > clim :
       return k
    else :
       return ndist-1

#============================
def NumInflLeft(curres,kpeak,epsp):

#   left inflection point; always 0 < kpeak <= ndist ;
#   return 0 (r=0) is forbidden giving 0 in fitBCR

    ndist = len(curres) -1

    clim = epsp * curres[kpeak]

    k = 1
    if kpeak > 1:
       for i in range (kpeak,1,-1):
           if curres[i-1] <= clim or curres[i-2]+curres[i]-2.*curres[i-1] >= 0.0 :
              k = i
              break

    return k

#============================
def uvFitGaussR(curres,dist,d0,minx,maxx):

#   used below : w = ln(u)

    sumr2, sumr4, sumdl, sumrdl = 0.0 , 0.0 , 0.0 , 0.0
    sumx                        = maxx - minx + 1

    if d0 > 0.0 :
       scalf = d0 * d0 * math.sqrt(4.0 * math.pi)
    else :
       scalf = 1.0

    for i in range(minx,maxx+1):
      curvei = math.log(curres[i] * scalf)
      dr = dist[i] - d0
      ri2    = dr * dr
      ri4    = ri2    * ri2
      sumr2  = sumr2  + ri2
      sumr4  = sumr4  + ri4
      sumdl  = sumdl  + curvei
      sumrdl = sumrdl + curvei * ri2

    det  =  -sumx * sumr4  + sumr2 * sumr2
    detw = -sumdl * sumr4  + sumrdl*sumr2
    detv =   sumx * sumrdl - sumr2 * sumdl

    wg = detw / det
    vg = detv / det
    ug = math.exp(wg)

    return ug,vg

#============================
def CurveDiff(dens,dist,mdist,edist,nfmes,bpeak,cpeak,rpeak,npeak,mxp):

    ndist = len(dist) - 1

    curve  = [ [ 0 for j in range(mxp+1)] for i in range(ndist+1) ]
    curres = [ dens[i] for i in range(ndist+1) ]

#   cycle over components

    for ipeak in range(npeak+1):

#     select the  parameters

      b0, c0, r0 = bpeak[ipeak] , cpeak[ipeak] , rpeak[ipeak]

#     calculate the contribution
#         ripple in point r0 or Gaussian in the origin

      if r0 > 0.0 :
        tcurve = CurveRipple(dist,edist,b0,c0,r0)
      else:
        tcurve = CurveGauss(dist,edist,b0,c0)

#     remove contribution

      for ix in range(ndist+1):
        curve [ix][ipeak] = tcurve[ix]
        curres[ix]        = curres[ix] - tcurve[ix]

#   end of cycle over components; residual errors

    epsres = 0.0
    for ix in range (mdist+1):
      curabs = abs(curres[ix])
      if curabs > epsres:
         epsres = curabs

    totres = epsres
    if ndist > mdist :
       for ix in range (mdist+1,ndist+1):
         curabs = abs(curres[ix])
         if curabs > totres:
            totres = curabs

    #if (nfmes is not None) :
    #   space = 23*' '
    #   print('',file=nfmes)
    #   print(f' with {npeak+1:4} terms max residual peaks are',file=nfmes)
    #   print(space,' inside the interval of modeling',f'{epsres:12.7f}',file=nfmes)
    #   print(space,' in the whole range of distances',f'{totres:12.7f}',file=nfmes)
    #
    #   print('')
    #   print(f' with {npeak+1:4} terms max residual peaks are')
    #   print(space,' inside the interval of modeling',f'{epsres:12.7f}')
    #   print(space,' in the whole range of distances',f'{totres:12.7f}')

    return curres,curve,epsres

#============================
def CurveGauss(dist,edist,b0,c0):

    ndist = len(dist) -1

#   curve for a Gaussian in the origin

    curve = [ 0.0 for i in range(ndist+1) ]

    cpi  = math.pi
    pi4b = 4. * cpi / b0
    vg   = pi4b * cpi
    ug   = c0 * pi4b**1.5

    if edist > 0.0 :
       distmx = math.sqrt(-math.log(edist/abs(ug)) / vg)
    else :
       distmx = dist[ndist]

    for ix in range(ndist+1):
      distx = dist[ix]
      if distx <= distmx :
         arg = vg * distx**2
         curve[ix] = ug * math.exp(-arg)
      else :
         break

    return curve

#============================
def CurveRipple(dist,edist,b0,c0,r0):

    ndist = len(dist) -1

#   curve for a rippe in point r0

    curve = [ 0.0 for i in range(ndist+1) ]

    cpi   = math.pi
    pi4   = 4.0 * cpi
    pisq4 = pi4 * cpi
    ur    = c0  * (pi4/b0)**1.5
    vr    = pisq4 / b0
    vr2   = 2.0 * vr

    scaler = c0 / (r0*math.sqrt(pi4*b0))
    if edist > 0.0 :
       arg0mx = -math.log(edist/abs(ur))
    else :
       arg0mx = vr * dist[ndist]**2

    arg0 = vr * r0**2
    if arg0 < arg0mx :
       curve[0] = c0 * math.exp(-arg0) * (pi4/b0)**1.5

#   find the distance point for r0

    ir = 0
    for ix in range(1,ndist+1) :
        if dist[ix] > r0 :
           ir = ix
           break
    if ir == 0 :
       ir = ndist
    else :
       ir = ir - 1

#   left part of the curve

    if ir > 0 :
       for ix in range(ir,0,-1) :
           rx         = dist[ix]
           argm, argp = vr * (rx-r0)**2 , vr * (rx+r0)**2
           curvex     = scaler * (math.exp(-argm) - math.exp(-argp)) / rx
           if abs(curvex) >= edist :
              curve[ix]   = curvex
           else :
              break

#   right part of the curve

    if ir < ndist :
       for ix in range(ir+1,ndist+1) :
           rx         = dist[ix]
           argm, argp = vr * (rx-r0)**2 , vr * (rx+r0)**2
           curvex     = scaler * (math.exp(-argm) - math.exp(-argp)) / rx
           if abs(curvex) >= edist :
              curve[ix]   = curvex
           else :
              break

    return curve

#============================
def OutCurves(dens,dist,curres,curve,filecurve):

    if filecurve == 'none' :
       return

    nfcurv = open(filecurve, 'w')

    ndist = len(dist) - 1

#    print(f'   dist   curve   modeled   resid    cmp=  0',
#          ''.join(f'{ip:9}' for ip in range(1,npeak+1)),file=nfcurv)
#    for i in range(ndist+1):
#        densum = dens[i]-curres[i]
#        print(f'{dist[i]:7.3f}{dens[i]:9.5f}{densum:9.5f}{curres[i]:9.5f}',
#              ''.join(f'{curve[i][ip]:9.5f}' for ip in range(npeak+1)),file=nfcurv)

    #print(f'    dist       curve         modeled         resid        max.error',file=nfcurv)

    resmax = 0.0
    for i in range(ndist+1):
        curabs = abs(curres[i])
        if curabs > resmax:
           resmax = curabs
        densum = dens[i]-curres[i]
        #print(f'{dist[i]:8.3f}{dens[i]:15.8f}{densum:15.8f}{curres[i]:15.8f}{resmax:15.8f}',
        #                                                                         file=nfcurv)
    return

#============================
def PeakBCR(curres,dist,mdist,ceps,kneg,kpeak,bpeak,cpeak,rpeak,npeak,       \
              epsp,bmin,cmin,rmin,mxp,nfmes):

    ndist = len(dist) - 1
    kdist = mdist

    if kpeak == 0:

#      peak in the origin - model it by a Gaussian

       b0, c0, r0, minf = GaussBC(curres,dist,epsp,bmin,cmin,nfmes)
       kpeak = minf

    elif kpeak < mdist:

#      internal peak

       b0, c0, r0, kdist = \
                   RippleBCR(curres,dist,mdist,kpeak,epsp,bmin,cmin,rmin,nfmes)
       kpeak = kdist

#      peak at the right border of the interval

    else:
       b0, c0, r0, kdist = TailBCR(curres,dist,mdist,epsp,bmin,cmin,rmin,nfmes)
       kpeak = mdist

    if kneg > 0:
       curres, c0 = CurveInvert(curres,c0)

    kpeak = kpeak+1
    npeak = npeak+1
    bpeak[npeak] , cpeak[npeak] , rpeak[npeak] = b0 , c0, r0

    return bpeak,cpeak,rpeak,npeak,kdist,kpeak

#============================
def NextPeak(curres,mdist,kpeak,nfmes,ceps):

    kfound = 0
    kneg   = 0

#   check the peak in the origin

    if kpeak == 0:

#     check if the peak in the origin if flat

      cx = curres[0]
      i  = 1
      while curres[i]-cx == 0.0:
         i = i+1

      if cx*(curres[i]-cx) < 0.0 and abs(cx) > ceps:
         ix     = 0
         kfound = 1

#     there is no peak in the origin; check next points

      else:
         kpeak = 1

#   (we cannot use 'else' below since kpeak may change after its previous check)

    if kfound == 0 and kpeak < mdist:

#        search for an internal peak

         for ix in range(kpeak,mdist):
             cx   = curres[ix]
             delm = cx-curres[ix-1]
             delp = curres[ix+1]-cx
             if delm*delp <= 0. and delp*cx < 0. and abs(cx) > ceps:
                kfound = 2
                break

#        no internal peak found ; check the upper interval bound

         if kfound == 0 :
            cx = curres[mdist]
            if (cx-curres[mdist-1])*cx > 0 and abs(cx) > ceps :
               ix = mdist
               kfound = 3

#   flip the curve temporarily if the peak is negative

    if kfound == 0 :
       kpeak = -1
    else :
       kpeak = ix
       if cx < 0.0 :
          kneg = 1
          curres,cx = CurveInvert(curres,cx)

    return kpeak,kneg,curres

#============================
def FuncFit(xc,npeak,y0,yc,dist,mdist,edist,nfmes):

#   calculate model curve

    yc = CurveCalc(xc,npeak,yc,dist,mdist,edist,nfmes)

#   comparer model and control curves

    fvalue = LSFunc(yc,y0,mdist)

    return fvalue

#============================
def GradFit(xc,npeak,y0,yc,dist,mdist,edist,nfmes):

#   calculate the gradient with respect to the curve yc

    gy = GradCurve(yc,y0,mdist)

#   calculate the gradient with respect to the parameters

    gx = GradX(xc,npeak,yc,gy,dist,mdist,edist,nfmes)

    return gx

#============================
def CurveCalc(xc,npeak,yc,dist,mdist,edist,nfmes):

    ndist = mdist

    for ix in range(ndist+1):
        yc[ix] = 0.0

    for i in range(npeak+1):
        i3 = i*3
        b0 , c0 , r0 = xc[i3] , xc[i3+1] , xc[i3+2]

#       contribution from a ripple or from a Gaussian in the origin

        if r0 > 0.0 :
           tcurve = CurveRipple(dist,edist,b0,c0,r0)
        else:
           tcurve = CurveGauss(dist,edist,b0,c0)

        for ix in range(ndist+1):
            yc[ix] = yc[ix] + tcurve[ix]

    return yc

#============================
def LSFunc(yc,y0,mdist):

    fvalue = 0.0
    ndist = mdist

    for i in range(ndist+1):
        fvalue = fvalue + (yc[i]-y0[i])**2

    fvalue = fvalue * 0.5

    return fvalue

#============================
def GradCurve(yc,y0,mdist):

    ndist = mdist

    gy = [ yc[i]-y0[i] for i in range(ndist+1) ]

    return gy

#============================
def GradX(xc,npeak,yc,gy,dist,mdist,edist,nfmes):

    gx = [ 0 for i in range(3*(npeak+1)) ]

    for i in range(npeak+1):
       i3 = i * 3
       b0 , c0, r0 = xc[i3] , xc[i3+1] , xc[i3+2]

       if r0 > 0.0:
          gb, gc, gr = GradRipple(yc,gy,dist,mdist,edist,b0,c0,r0)
       else:
          gb, gc = GradGauss(yc,gy,dist,mdist,edist,b0,c0)
          gr    = 0.0

       gx[i3] , gx[i3+1] , gx[i3+2]  = gb , gc , gr

#    exit()

    return gx

#============================
def GradRipple(yc,gy,dist,mdist,edist,b0,c0,r0):

    ndist = mdist

    cpi    = math.pi
    pi4    = 4.0 * cpi
    pisq4  = pi4 * cpi
    vr     = pisq4 / b0
    vr2    = 2.0 * vr
    pisq8r = vr2 * r0

    scaler = c0 / (r0 * math.sqrt(pi4*b0))
    ur     = c0 * (pi4/b0)**1.5

    if edist > 0.0 :
       arg0mx = -math.log(edist/abs(ur))
    else :
       arg0mx = vr * dist[ndist]**2

    scc   = 1. / (2.0*r0*math.sqrt(b0*cpi))
    c0r0 , c0b0 = c0/r0 , c0/b0
    c0b02       = c0b0 / 2.0

#   gradient in the origin, x = 0

    arg0 = vr * r0**2
    if arg0 < arg0mx :
       gadd          = 8.0 * math.exp(-arg0) * gy[0] * (cpi/b0)**1.5
       gb , gc , gr  =  gadd * c0b0 * (arg0 - 1.5) , gadd , -gadd * c0 * pisq8r
    else:
       gb , gc , gr  = 0.0 , 0.0 , 0.0

#   find the distance point for r0

    ir = 0
    for ix in range(1,ndist+1) :
        if dist[ix] > r0 :
           ir = ix
           break
    if ir == 0 :
       ir = ndist
    else :
       ir = ir - 1

#   left part of the curve

    if ir > 0 :
       for ix in range(ir,0,-1) :
           rx           = dist[ix]
           xm   , xp    = rx - r0         , rx + r0
           argm , argp  = vr * xm*xm      , vr * xp*xp
           gaddm, gaddp = math.exp(-argm) , math.exp(-argp)
           delmp        = gaddm-gaddp
           curvex       = scaler * (math.exp(-argm) - math.exp(-argp)) / rx
           if abs(curvex) >= edist :
              sccx = scc * gy[ix] / rx
              gc   = gc + sccx * delmp
              gb   = gb + sccx * c0b02 * ((gaddm*(2.0*argm - 1.0) - gaddp*(2.0*argp - 1.0)))
##              gb   = gb + sccx * c0b02 * (2.0 * (gaddm*argm - gaddp*argp) - delmp)
              gr   = gr + sccx * c0r0 * (gaddm*(pisq8r*xm-1.0) + gaddp*(pisq8r*xp+1.0))
##              gr   = gr + sccx * c0r0 * (pisq8r * (gaddm*xm + gaddp*xp) - delmp)
           else :
              break

#   right part of the curve

    if ir < ndist :
       for ix in range(ir+1,ndist+1) :
           rx           = dist[ix]
           xm   , xp    = rx - r0         , rx + r0
           argm , argp  = vr * xm*xm      , vr * xp*xp
           gaddm, gaddp = math.exp(-argm) , math.exp(-argp)
           delmp        = gaddm - gaddp
           curvex       = scaler * delmp / rx
           if abs(curvex) >= edist :
              sccx = scc * gy[ix] / rx
              gc   = gc + sccx * delmp
              gb   = gb + sccx * c0b02 * ((gaddm*(2.0*argm - 1.0) - gaddp*(2.0*argp - 1.0)))
##              gb   = gb + sccx * c0b02 * (2.0 * (gaddm*argm - gaddp*argp) - delmp)
              gr   = gr + sccx * c0r0 * (gaddm*(pisq8r*xm-1.0) + gaddp*(pisq8r*xp+1.0))
##              gr   = gr + sccx * c0r0 * (pisq8r * (gaddm*xm + gaddp*xp) - delmp)
           else :
              break

    return gb,gc,gr

#============================
def GradGauss(yc,gy,dist,mdist,edist,b0,c0):

    ndist = mdist

    cpi  = math.pi
    pi4b = 4.0  * cpi / b0
    vg   = pi4b * cpi
    ugc  = pi4b**1.5
    ug   = ugc * c0
    ugb  = ug  / b0

    gb , gc = 0.0 , 0.0

    if edist > 0.0 :
       distmx = math.sqrt(-math.log(edist/abs(ug)) / vg)
    else :
       distmx = dist[ndist]

    for ix in range(ndist+1):
        distx = dist[ix]
        if distx <= distmx :
           arg = vg * distx**2
           gadd = math.exp(-arg) * gy[ix]
           gb   = gb + ugb*gadd*(arg-1.5)
           gc   = gc + ugc*gadd
        else :
           break

    return gb,gc

#================================
def CheckLow(bpeak,cpeak,rpeak,npeak,ceps,nfmes):

    pi4    = 4.0 * math.pi
    pisq16 = pi4 * pi4

    bpeakc, cpeakc, rpeakc = [], [], []

    #if (nfmes is not None) :
    #
    #   print('',file=nfmes)
    #   print(' Check term values in the points r = r0 :',file=nfmes)
    #   print(' Nterm    R (M)   ',6*' ','B (N)   ',6*' ','C (K)   ',7*' ','value',file=nfmes)
    #
    #   print('')
    #   print(' Check term values in the points r = r0 :')
    #   print(' Nterm    R (M)   ',6*' ','B (N)   ',6*' ','C (K)   ',7*' ','value')

    for ip in range (npeak+1):
        b0 = bpeak[ip]
        c0 = cpeak[ip]
        r0 = rpeak[ip]
        if r0 == 0.0 :
           fval = c0 * (pi4/b0)**1.5
        else :
           fval = c0 * (1.0 - math.exp(-pisq16*r0**2/b0)) / (math.sqrt(pi4*b0) * r0**2)

        #if (nfmes is not None) :
        #   print(f'{ip+1:6}{r0:16.10f}{b0:16.10f}{c0:11.5f}   {fval:12.7f}',file=nfmes)
        #   print(f'{ip+1:6}{r0:16.10f}{b0:16.10f}{c0:11.5f}   {fval:12.7f}')

        if abs(fval) >= ceps :
           bpeakc.append(b0)
           cpeakc.append(c0)
           rpeakc.append(r0)

    return bpeakc, cpeakc, rpeakc

#============================
def FilterWeak(dens,curve,curres,dist,mdist,edist,epsres,bpeak,cpeak,rpeak,npeak,mxp,  \
                                 bmin,cmin,rmin,nfmes,ceps):

    bpeakc,cpeakc,rpeakc = CheckLow(bpeak,cpeak,rpeak,npeak,ceps,nfmes)

    mpeak = len(bpeakc) - 1

    if mpeak < npeak :

#      small contributions found; check the result after removing these terms

       bpeakc,cpeakc,rpeakc =        \
                    RefineBCR(dens,dist,mdist,edist,bpeakc,cpeakc,rpeakc,mpeak,bmin,cmin,rmin,nfmes)

       curres,curve,epsres = \
                               CurveDiff(dens,dist,mdist,edist,nfmes,bpeakc,cpeakc,rpeakc,mpeak,mxp)

#      removing small contributions makes the residual error above the limit;
#      include these terms back

       if epsres > ceps :

          mpeak  = npeak
          bpeakc = [ bpeak[ip] for ip in range(npeak+1)]
          cpeakc = [ cpeak[ip] for ip in range(npeak+1)]
          rpeakc = [ rpeak[ip] for ip in range(npeak+1)]

          curres,curve,epsres = \
                               CurveDiff(dens,dist,mdist,edist,nfmes,bpeakc,cpeakc,rpeakc,mpeak,mxp)

    return bpeakc,cpeakc,rpeakc,mpeak,curve,curres,epsres


 *******************************************************************************


 *******************************************************************************
cctbx/maptbx/boost_python/time_grid_indices_around_sites.py
from __future__ import absolute_import, division, print_function
import iotbx.pdb
from cctbx import maptbx
from cctbx.array_family import flex
from scitbx import fftpack
from scitbx import matrix
from libtbx.utils import time_log
import sys

def run(args):
  assert len(args) == 1
  timer = time_log("pdb.input").start()
  pdb_inp = iotbx.pdb.input(file_name=args[0])
  print("number of pdb atoms:", pdb_inp.atoms().size())
  print(timer.log())
  crystal_symmetry = pdb_inp.crystal_symmetry()
  assert crystal_symmetry is not None
  crystal_symmetry.show_summary()
  assert crystal_symmetry.unit_cell() is not None
  assert crystal_symmetry.space_group_info() is not None
  sites_cart = pdb_inp.atoms().extract_xyz()
  site_radii = flex.double(sites_cart.size(), 2.5)
  crystal_gridding = maptbx.crystal_gridding(
    unit_cell=crystal_symmetry.unit_cell(),
    d_min=2,
    resolution_factor=1/3)
  fft = fftpack.real_to_complex_3d(crystal_gridding.n_real())
  print("n_real:", fft.n_real())
  print("m_real:", fft.m_real())
  timer = time_log("grid_indices_around_sites").start()
  grid_indices = maptbx.grid_indices_around_sites(
    unit_cell=crystal_symmetry.unit_cell(),
    fft_n_real=fft.n_real(),
    fft_m_real=fft.m_real(),
    sites_cart=sites_cart,
    site_radii=site_radii)
  print("grid_indices.size():", grid_indices.size())
  print(timer.log())
  print("grid fraction:", \
    grid_indices.size() / matrix.col(fft.n_real()).product())

if (__name__ == "__main__"):
  run(sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/maptbx/boost_python/tst_maptbx.py
from __future__ import absolute_import, division, print_function
from cctbx import maptbx
from cctbx import uctbx
from cctbx import sgtbx
from cctbx.array_family import flex
from cctbx import crystal
from scitbx import matrix
from libtbx.test_utils import Exception_expected, approx_equal, \
  not_approx_equal
from libtbx.utils import n_dim_index_from_one_dim
import itertools
import time
import sys
import random
import math
from six.moves import range
from six.moves import zip

def flex_types():
  return (flex.float, flex.double)

def exercise_copy():
  for flex_type in flex_types():
    m = flex_type((1,2,3,4))
    m.resize(flex.grid(2,2))
    c = maptbx.copy(map=m, result_grid=m.accessor())
    assert tuple(m) == tuple(c)
    c = maptbx.copy(map=m, result_grid=flex.grid(2,3).set_focus(2,2))
    assert approx_equal(tuple(c), (1,2,0,3,4,0))
    n = maptbx.copy(c, result_grid=m.accessor())
    assert approx_equal(tuple(m), tuple(n))
    c = maptbx.copy(m, flex.grid(3,2).set_focus(2,2))
    assert approx_equal(tuple(c), (1,2,3,4,0,0))
    n = maptbx.copy(c, m.accessor())
    assert approx_equal(tuple(m), tuple(n))
    m = flex_type((1,2,3,4,5,6))
    m.resize(flex.grid((1,2),(3,5)))
    c = maptbx.copy(m, m.accessor())
    assert approx_equal(tuple(m), tuple(c))
    c = maptbx.copy(m, flex.grid((1,2),(3,6)).set_focus(3,5))
    assert approx_equal(tuple(c), (1,2,3,0,4,5,6,0))
    n = maptbx.copy(c, m.accessor())
    assert approx_equal(tuple(m), tuple(n))
    c = maptbx.copy(m, flex.grid((1,2),(4,5)).set_focus(3,5))
    assert approx_equal(tuple(c), (1,2,3,4,5,6,0,0,0))
    n = maptbx.copy(c, m.accessor())
    assert approx_equal(tuple(m), tuple(n))
    #
    m = flex_type()
    for i in range(2):
      for j in range(3):
        for k in range(5):
          m.append(i*100+j*10+k)
    m.resize(flex.grid(2,3,5).set_focus((2,3,4)))
    for i in range(-5,5):
      for j in range(-5,5):
        for k in range(-5,5):
          c = maptbx.copy(map_unit_cell=m, first=(i,j,k), last=(i,j,k))
          assert c.size() == 1
          assert c[(i,j,k)] == m[(i%2,j%3,k%4)]
    c = maptbx.copy(map_unit_cell=m, first=(-1,1,-2), last=(1,2,0))
    assert list(c) == [112, 113, 110, 122, 123, 120,  12,  13,  10,
                        22,  23,  20, 112, 113, 110, 122, 123, 120]
    #
    m2 = m.deep_copy()
    grid = flex.grid( (-1,-1,-1), (1,2,4) ).set_focus( (1,2,3) )
    m2.resize(grid)
    for i in range(-1,1):
      for j in range(-1,2):
        for k in range(-1,3):
          # aperiodic copy
          c = maptbx.copy_box(map=m2, first=(i,j,k), last=(i,j,k))
          assert c.size() == 1
          ind = ((i+1)%2-1,(j+1)%3-1,(k+1)%4-1)
          assert c[(i,j,k)] == m2[ind]
    c = maptbx.copy_box(map=m2, first=(-1,0,-1), last=(0,1,2))
    assert list(c) == [10, 11, 12, 13, 20, 21,  22,  23,  110,
                       111, 112, 113, 120, 121, 122, 123]
    #
    for n0 in range(4):
      for n1 in range(4):
        for n2 in range(4):
          for d2 in range(3):
            g = flex.grid((n0,n1,n2+d2)).set_focus((n0,n1,n2))
            map1 = flex_type(range(1,1+g.size_1d()))
            map1.resize(g)
            map2 = map1.deep_copy()
            maptbx.unpad_in_place(map=map2)
            assert map2.all() == (n0,n1,n2)
            assert not map2.is_padded()
            if (n0*n1*n2 != 0):
              for i in flex.nested_loop((n0,n1,n2)):
                assert map2[i] == map1[i]
    n0,n1,n2,d2 = 2,3,4,1
    g = flex.grid((n0,n1,n2+d2)).set_focus((n0,n1,n2))
    map1 = flex_type(range(1,1+g.size_1d()))
    map1.resize(g)
    map2 = map1.deep_copy()
    maptbx.unpad_in_place(map=map2)
    assert map2.all() == (n0,n1,n2)
    assert not map2.is_padded()
    assert list(map2) == [
       1, 2, 3, 4,
       6, 7, 8, 9,
      11,12,13,14,
      16,17,18,19,
      21,22,23,24,
      26,27,28,29]

def exercise_statistics():
  import scitbx.math
  for flex_type in flex_types():
    a = flex_type(flex.grid((3,5)))
    s = maptbx.statistics(a)
    assert s.min() == 0
    assert s.max() == 0
    assert s.mean() == 0
    assert s.mean_sq() == 0
    assert s.sigma() == 0
    a = flex_type([random.random() for i in range(3*5)])
    a.resize(flex.grid((3,5)))
    s = maptbx.statistics(a)
    assert approx_equal(flex.min(a), s.min())
    assert approx_equal(flex.max(a), s.max())
    assert approx_equal(flex.mean(a), s.mean())
    assert approx_equal(flex.mean_sq(a), s.mean_sq())
    assert approx_equal(flex.mean_sq(a)-flex.mean(a)**2, s.sigma()**2)
    b = flex_type(flex.grid((4,6)).set_focus((3,5)))
    for i in range(3):
      for j in range(5):
        b[(i,j)] = a[(i,j)]
    b[(3,5)] = -1
    b[(2,5)] = 2
    b.resize(flex.grid((-2,3), (2,9)).set_focus((1,8)))
    t = maptbx.statistics(b)
    assert not_approx_equal(flex.min(b), t.min())
    assert not_approx_equal(flex.max(b), t.max())
    assert not_approx_equal(flex.mean(b), t.mean())
    assert not_approx_equal(flex.mean_sq(b), t.mean_sq())
    assert not_approx_equal(flex.mean_sq(b)-flex.mean(b)**2, t.sigma()**2)
    assert approx_equal(s.min(), t.min())
    assert approx_equal(s.max(), t.max())
    assert approx_equal(s.mean(), t.mean())
    assert approx_equal(s.mean_sq(), t.mean_sq())
    assert approx_equal(s.sigma(), t.sigma())
  a = flex.double(flex.grid(5,3))
  s = maptbx.more_statistics(a)
  assert s.min() == 0
  assert s.max() == 0
  assert s.mean() == 0
  assert s.mean_sq() == 0
  assert s.sigma() == 0
  assert s.skewness() == 0
  assert s.kurtosis() == 0
  a = flex.random_double(5*3)
  reference = scitbx.math.basic_statistics(a)
  a.resize(flex.grid(5,3))
  s = maptbx.more_statistics(a)
  assert approx_equal(s.min(), reference.min)
  assert approx_equal(s.max(), reference.max)
  assert approx_equal(s.mean(), reference.mean)
  assert approx_equal(s.sigma(), reference.biased_standard_deviation)
  assert approx_equal(s.skewness(), reference.skew)
  assert approx_equal(s.kurtosis(), reference.kurtosis)
  b = flex.double(flex.grid((6,4)).set_focus((5,3)))
  for i in range(5):
    for j in range(3):
      b[(i,j)] = a[(i,j)]
  b[(5,3)] = -1
  b[(5,2)] = 2
  b.resize(flex.grid((3,-2), (9,2)).set_focus((8,1)))
  t = maptbx.statistics(b)
  assert approx_equal(s.min(), reference.min)
  assert approx_equal(s.max(), reference.max)
  assert approx_equal(s.mean(), reference.mean)
  assert approx_equal(s.sigma(), reference.biased_standard_deviation)
  assert approx_equal(s.skewness(), reference.skew)
  assert approx_equal(s.kurtosis(), reference.kurtosis)
  m = flex.double(flex.grid((6,4,8)).set_focus((5,3,7)))

def exercise_grid_tags():
  t = maptbx.grid_tags((8,10,12))
  assert not t.is_valid()
  assert t.tag_array().all() == (8,10,12)
  s = sgtbx.space_group_info("P 21")
  for i_flags in range(8):
    f = sgtbx.search_symmetry_flags(
      use_space_group_symmetry=i_flags % 2 != 0,
      use_space_group_ltr=0,
      use_seminvariants=(i_flags//4) % 2 != 0,
      use_normalizer_k2l=(i_flags//2) % 2 != 0,
      use_normalizer_l2n=False)
    t.build(s.type(), f)
    assert t.is_valid()
    assert t.space_group_type().group() == s.group()
    assert t.symmetry_flags() == f
    if (f.use_seminvariants()):
      assert [(vm.v, vm.m) for vm in t.grid_ss_continuous()] \
          == [((0, 1, 0), 10)]
    assert t.n_grid_misses() == 0
    assert t.n_independent() == (960, 480, 484, 242, 24, 14, 14, 14)[i_flags]
    assert t.n_independent() + t.n_dependent() == t.tag_array().size()
    for flex_type in flex_types():
      d = flex_type(t.tag_array().accessor())
      assert t.n_dependent() == 0 \
          or approx_equal(t.dependent_correlation(d, 1.e-10).coefficient(),0)
      assert t.verify(d, 0)
      t.sum_sym_equiv_points(d)
    if (i_flags == 0):
      assert t.n_independent() == t.tag_array().size()
    else:
      assert t.n_independent() < t.tag_array().size()
      for flex_type in flex_types():
        d = flex_type([random.random() for x in range(t.tag_array().size())])
        d.resize(t.tag_array().accessor())
        assert not t.verify(d)
        t.sum_sym_equiv_points(d)
        assert t.verify(d)

def exercise_peak_search():
  t = flex.long(flex.grid((3,4,5)))
  for flex_type in flex_types():
    d = flex_type(flex.grid((3,4,5)))
    l = maptbx.peak_list(d, t, peak_search_level=0, interpolate=False)
    assert l.gridding() == d.focus()
    assert l.grid_indices(0) == (0,0,0)
    assert list(l.grid_heights()) == [0]
    assert list(l.sites()) == [(0,0,0)]
    assert list(l.heights()) == [0]
    l = maptbx.peak_list(
      d, t, peak_search_level=0,peak_cutoff=-1, interpolate=False)
    assert l.gridding() == d.focus()
    assert l.grid_indices(0) == (0,0,0)
    assert list(l.grid_heights()) == [0]
    assert list(l.sites()) == [(0,0,0)]
    assert list(l.heights()) == [0]

def exercise_pymol_interface():
  for flex_type in flex_types():
    m = flex_type(flex.grid(3,4,6).set_focus(3,4,5))
    o = maptbx.as_CObjectZYX(m, first=(0,0,0), last=(4,5,6))

def exercise_structure_factors():
  uc = uctbx.unit_cell((11,13,17))
  sg = sgtbx.space_group_info("P 31")
  mi = flex.miller_index(((1,2,3),(2,3,4)))
  d = flex.complex_double((1+2j, 2+3j))
  for anomalous_flag in (False, True):
    for conjugate_flag in (False, True):
      t = maptbx.structure_factors.to_map(
        space_group=sg.group(),
        anomalous_flag=anomalous_flag,
        miller_indices=mi,
        structure_factors=d,
        n_real=(11,11,9),
        map_grid=flex.grid(11,11,9),
        conjugate_flag=conjugate_flag)
      assert t.complex_map().focus() == (11,11,9)
      t = maptbx.structure_factors.to_map(
        space_group=sg.group(),
        anomalous_flag=anomalous_flag,
        miller_indices=mi,
        structure_factors=d,
        n_real=(11,11,9),
        map_grid=flex.grid(11,11,9),
        conjugate_flag=conjugate_flag,
        treat_restricted=False)
      assert t.complex_map().focus() == (11,11,9)
      f = maptbx.structure_factors.from_map(
        unit_cell=uc,
        space_group_type=sg.type(),
        anomalous_flag=anomalous_flag,
        d_min=5.,
        complex_map=t.complex_map(),
        conjugate_flag=conjugate_flag)
      assert f.miller_indices().size() > 0
      assert f.miller_indices().size() == f.data().size()
      f = maptbx.structure_factors.from_map(
        anomalous_flag=anomalous_flag,
        miller_indices=mi,
        complex_map=t.complex_map(),
        conjugate_flag=conjugate_flag)
      assert f.miller_indices().size() == 0
      assert f.data().size() == mi.size()
      f = maptbx.structure_factors.from_map(
        anomalous_flag=anomalous_flag,
        miller_indices=mi,
        complex_map=t.complex_map(),
        conjugate_flag=conjugate_flag,
        allow_miller_indices_outside_map=True)
      assert f.miller_indices().size() == 0
      assert f.data().size() == mi.size()
      assert f.n_indices_affected_by_aliasing() == 0
      assert f.outside_map().size() == 0
      f = maptbx.structure_factors.from_map(
        space_group=sg.group(),
        anomalous_flag=anomalous_flag,
        miller_indices=mi,
        complex_map=t.complex_map(),
        conjugate_flag=conjugate_flag)
      assert f.miller_indices().size() == 0
      assert f.data().size() == mi.size()
      assert f.n_indices_affected_by_aliasing() == 0
      assert f.outside_map().size() == 0

def exercise_fft():
  sg = sgtbx.space_group_info("P 31").group()
  mi = flex.miller_index(((1,2,3),(2,3,4)))
  d = flex.complex_double((1+2j, 2+3j))
  map = maptbx.fft_to_real_map_unpadded(
    space_group=sg,
    n_real=(10,13,17),
    miller_indices=mi,
    data=d)
  assert map.is_0_based()
  assert not map.is_padded()
  assert map.focus() == (10,13,17)
  assert approx_equal(
    map[:5], [6,13.4163896,5.9603989,-8.1028328,-13.1838857])
  assert approx_equal(
    map[1000:1005], [-17.5217557,-1.4971115,20.1455825,-4.0350021,-2.7312275])
  assert approx_equal(
    map[-5:], [8.7337234,-0.7930404,-6.6343761,-1.9521735,2.6725642])

def exercise_gridding():
  u = uctbx.unit_cell((4,6,7))
  assert maptbx.ext.determine_gridding(u, 2, 1/3., (1,1,1), 5, True) \
      == (8,9,12)
  f = sgtbx.search_symmetry_flags(
    use_space_group_symmetry=True,
    use_space_group_ltr=0,
    use_seminvariants=False,
    use_normalizer_k2l=True,
    use_normalizer_l2n=False)
  t = sgtbx.space_group_info("F 2 2 2").primitive_setting().type()
  assert maptbx.ext.determine_gridding(u, 2, 1/3., f, t, (1,1,1), 5, True) \
      == (12, 12, 12)

def exercise_misc():
  for flex_type in flex_types():
    m = flex_type([1,2,-3,4,-5,6])
    maptbx.set_if_less_than(m, 0, 0)
    assert approx_equal(tuple(m), (1,2,0,4,0,6))
    maptbx.set_if_less_than(m, 2, 9)
    assert approx_equal(tuple(m), (9,2,9,4,9,6))
  from cctbx import xray
  structure = xray.structure(
    special_position_settings=crystal.special_position_settings(
      crystal_symmetry=crystal.symmetry(
        unit_cell=(10.0,10.0,10.0,90,90,90),
        space_group_symbol="P1")),
    scatterers=flex.xray_scatterer([
      xray.scatterer(
        label="O",
        site=(0.5,0.5,0.5),
        u=0.2)]))
  fc = structure.structure_factors(d_min=2).f_calc()
  fc_map = fc.fft_map(resolution_factor=1/4.)
  fc_map.apply_sigma_scaling()
  real_map = fc_map.real_map_unpadded()
  stats = maptbx.spherical_variance_around_point(
    real_map=real_map,
    unit_cell=structure.unit_cell(),
    site_cart=(5.,5.,5.),
    radius=1.)
  # XXX exact numbers are *not* consistent across platforms!
  assert (approx_equal(stats.min, 8.3, eps=0.2))
  assert (approx_equal(stats.mean, 8.5, eps=0.1))
  assert (stats.standard_deviation < 0.15)
  stats = maptbx.spherical_variance_around_point(
    real_map=real_map,
    unit_cell=structure.unit_cell(),
    site_cart=(6.,6.,6.),
    radius=1.)
  assert (approx_equal(stats.min, -0.75, eps=0.15))
  assert (approx_equal(stats.mean, 1.35, eps=0.1))
  assert (approx_equal(stats.standard_deviation, 3.25, eps=0.1))
  # test principal_axes_of_inertia
  # XXX d_min=2.01 to get consistent behavior across platforms
  fc = structure.structure_factors(d_min=2.01).f_calc()
  assert (fc.indices().size() == 242)
  fc_map = fc.fft_map(resolution_factor=1/4.)
  fc_map.apply_sigma_scaling()
  real_map = fc_map.real_map_unpadded()
  pai = maptbx.principal_axes_of_inertia(
    real_map=real_map,
    unit_cell=structure.unit_cell(),
    site_cart=(5.,5.,5.),
    radius=2.0)
  assert approx_equal(pai.center_of_mass(), (5.0,5.0,5.0), 0.1)
  assert (approx_equal(pai.inertia_tensor(), (44.89,44.89,44.89,1.87,1.87,1.87),
    eps=0.5))
  assert (approx_equal(list(pai.eigensystem().values()), (48,43,43),
    eps=1))
  # and now with anisotropy
  structure = xray.structure(
    special_position_settings=crystal.special_position_settings(
      crystal_symmetry=crystal.symmetry(
        unit_cell=(10.0,10.0,10.0,90,90,90),
        space_group_symbol="P1")),
    scatterers=flex.xray_scatterer([
      xray.scatterer(
        label="O",
        site=(0.5,0.5,0.5),
        u=(0.2,0.2,0.2,0.1,0.0,0.0))]))
  fc = structure.structure_factors(d_min=2.01).f_calc()
  assert (fc.indices().size() == 242)
  fc_map = fc.fft_map(resolution_factor=1/4.)
  fc_map.apply_sigma_scaling()
  fc_map.as_ccp4_map("aniso.ccp4")
  real_map = fc_map.real_map_unpadded()
  pai = maptbx.principal_axes_of_inertia(
    real_map=real_map,
    unit_cell=structure.unit_cell(),
    site_cart=(5.,5.,5.),
    radius=2.0)
  assert (approx_equal(pai.center_of_mass(), (5.0,5.0,5.0), eps=0.2))

def exercise_eight_point_interpolation():
  map = flex.double(flex.grid(2,3,5), 10)
  for shift in [0,1,-1]:
    for index in flex.nested_loop(map.focus()):
      x_frac = [float(i)/n+shift for i,n in zip(index, map.focus())]
      assert approx_equal(maptbx.eight_point_interpolation(map, x_frac), 10)
      assert approx_equal(
        maptbx.eight_point_interpolation_with_gradients(map, x_frac,[1,1,1])[0], 10)
      assert maptbx.closest_grid_point(map.accessor(), x_frac) == index
  for i in range(100):
    x_frac = [3*random.random()-1 for i in range(3)]
    assert approx_equal(map.eight_point_interpolation(x_frac), 10)
    assert approx_equal(
      map.eight_point_interpolation_with_gradients(x_frac,[1,1,1])[0], 10)
  map = flex.double(range(30))
  map.resize(flex.grid(2,3,5))
  for shift in [0,1,-1]:
    v = 0
    for index in flex.nested_loop(map.focus()):
      x_frac = [float(i)/n+shift for i,n in zip(index, map.focus())]
      assert approx_equal(map.eight_point_interpolation(x_frac), v)
      assert approx_equal(
        map[maptbx.closest_grid_point(map.accessor(), x_frac)], v)
      assert approx_equal(map.value_at_closest_grid_point(x_frac), v)
      v += 1
  map = flex.double()
  for i in range(48): map.append(i%2)
  map.resize(flex.grid(2,4,6))
  for shift in [0,1,-1]:
    for offs in [.0,.5,.25,.75]:
      v = offs
      for index in flex.nested_loop(map.focus()):
        x_frac = [(i+offs)/n+shift for i,n in zip(index, map.focus())]
        assert approx_equal(map.eight_point_interpolation(x_frac), v)
        if (offs != .5):
          assert maptbx.closest_grid_point(map.accessor(), x_frac) == tuple(
            [int(i+offs+.5)%n for i,n in zip(index,map.focus())])
        v = 1-v

def exercise_real_space_gradients_simple(timing):
  uc = uctbx.unit_cell((11,13,17))
  def check():
    map = flex.double(flex.grid(22,26,36).set_focus(22,26,34))
    site_frac = [i/n for i,n in zip(grid_point, map.focus())]
    sites_cart = flex.vec3_double([uc.orthogonalize(site_frac)])
    target = maptbx.real_space_target_simple(
      unit_cell=uc, density_map=map, sites_cart=sites_cart,
      selection=flex.bool(sites_cart.size(), True))
    assert approx_equal(target, 0)
    terms = maptbx.real_space_target_simple_per_site(
      unit_cell=uc, density_map=map, sites_cart=sites_cart)
    assert approx_equal(terms, [0])
    grads = maptbx.real_space_gradients_simple(
      unit_cell=uc, density_map=map, sites_cart=sites_cart, delta=0.1,
      selection=flex.bool(sites_cart.size(), True))
    assert approx_equal(grads, [(0,0,0)])
    grid_point_mod = [i%n for i,n in zip(grid_point, map.focus())]
    map[grid_point_mod] = 1
    target = maptbx.real_space_target_simple(
      unit_cell=uc, density_map=map, sites_cart=sites_cart,
      selection=flex.bool(sites_cart.size(), True))
    assert approx_equal(target, 1)
    terms = maptbx.real_space_target_simple_per_site(
      unit_cell=uc, density_map=map, sites_cart=sites_cart)
    assert approx_equal(terms, [1])
    grads = maptbx.real_space_gradients_simple(
      unit_cell=uc, density_map=map, sites_cart=sites_cart, delta=0.1,
      selection=flex.bool(sites_cart.size(), True))
    assert approx_equal(grads, [(0,0,0)])
    i,j,k = grid_point_mod
    u,v,w = map.focus()
    map[((i+1)%u,j,k)] = 0.3
    map[(i,(j+1)%v,k)] = 0.5
    map[(i,j,(k+1)%w)] = 0.7
    target = maptbx.real_space_target_simple(
      unit_cell=uc, density_map=map, sites_cart=sites_cart,
      selection=flex.bool(sites_cart.size(), True))
    assert approx_equal(target, 1)
    for delta in [0.1, 0.2]:
      grads = maptbx.real_space_gradients_simple(
        unit_cell=uc, density_map=map, sites_cart=sites_cart, delta=delta,
        selection=flex.bool(sites_cart.size(), True))
      assert approx_equal(grads, [(0.3,0.5,0.7)])
  for grid_point in [(0,0,0), (3,4,5), (-3,15,20)]:
    check()
  for i_trial in range(10):
    grid_point = [random.randrange(-100,100) for i in [0,1,2]]
    check()
  if (timing): n = 1000000
  else:        n = 10
  sites_cart = flex.vec3_double(flex.random_double(size=n*3)*40-20)
  map = flex.double(flex.grid(22,26,36).set_focus(22,26,34), 1)
  target = maptbx.real_space_target_simple(
    unit_cell=uc, density_map=map, sites_cart=sites_cart,
    selection=flex.bool(sites_cart.size(), True))
  assert approx_equal(target, n)
  t0 = time.time()
  maptbx.real_space_gradients_simple(
    unit_cell=uc, density_map=map, sites_cart=sites_cart, delta=0.1,
    selection=flex.bool(sites_cart.size(), True))
  tm = time.time() - t0
  msg = "real_space_gradients_simple: %.2f s / %d sites" % (tm, n)
  if (tm >= 0.01): msg += ", %.0f sites / s" % (n / tm)
  if (timing): print(msg)

test_map  = flex.double([
  -0.069785, -0.109740, -0.172220, -0.209010, -0.255220, -0.285670,
  -0.303130, -0.221400, -0.136640, -0.121530, -0.215260, -0.292640,
  -0.498500, -0.371540, -0.180660, -0.093766, -0.200360, -0.334720,
  -0.356690, -0.330580, -0.249670, -0.204200, -0.264490, -0.320590,
  -0.190610, -0.302730, -0.375040, -0.377540, -0.327030, -0.219010,
  0.060113, -0.023043, -0.185520, -0.311580, -0.395500, -0.435890,
  -0.181560, -0.157460, -0.223360, -0.318560, -0.405230, -0.414470,
  -0.479920, -0.355250, -0.260400, -0.264970, -0.357940, -0.414640,
  -0.362330, -0.292680, -0.244540, -0.294960, -0.416090, -0.486070,
  -0.111790, -0.173040, -0.295180, -0.440520, -0.506410, -0.444720,
  0.077020, 0.038778, -0.054072, -0.178180, -0.323440, -0.434550,
  -0.015310, -0.030401, -0.141110, -0.275890, -0.399010, -0.461390,
  -0.241520, -0.209370, -0.248690, -0.322660, -0.384480, -0.383160,
  -0.209260, -0.185350, -0.221370, -0.317920, -0.396670, -0.400010,
  -0.001700, -0.066179, -0.224020, -0.427730, -0.515120, -0.456980,
  0.015884, 0.042340, 0.061897, -0.020660, -0.193310, -0.338580,
  0.034724, 0.063173, 0.054727, -0.019280, -0.169690, -0.341410,
  0.026087, -0.022744, -0.092896, -0.141160, -0.186520, -0.249360,
  0.052272, -0.015214, -0.111030, -0.175570, -0.180900, -0.163140,
  0.093106, 0.010392, -0.141450, -0.299110, -0.328730, -0.249500])

def exercise_asu_eight_point_interpolation():
  map = flex.double(flex.grid(2,3,5), 10)
  cs = crystal.symmetry(
    unit_cell=(1,1,1,90,90,90),
    space_group="P1")
  asu_mappings=cs.asu_mappings(buffer_thickness=0)
  for shift in [0,1,-1]:
    for index in flex.nested_loop(map.focus()):
      x_frac = [float(i)/n+shift for i,n in zip(index, map.focus())]
      assert approx_equal(
        maptbx.asu_eight_point_interpolation(map, asu_mappings, x_frac), 10)
  assert approx_equal(
    maptbx.asu_eight_point_interpolation(map, asu_mappings, (10,11,12)), 10)

def exercise_transformers():
  unit_cell=uctbx.unit_cell((10,10,10,90,90,90))
  sites_cart = ((9.5,10.7,3.2),(-.5,1.7,13.2))
  sites_frac = ((1.0,1.9,-.21),(3.6,0.7,-100.7))
  sites_grid = ((5,8,51),(-12,6,105))
  extents = (100,100,100)
  c2f = maptbx.cart2frac(unit_cell.fractionalization_matrix())
  c2g = maptbx.cart2grid(unit_cell.fractionalization_matrix(),extents)
  c2c = maptbx.cart2cart()
  f2f = maptbx.frac2frac()
  f2c = maptbx.frac2cart(unit_cell.orthogonalization_matrix())
  f2g = maptbx.frac2grid(extents)
  g2f = maptbx.grid2frac(extents)
  g2g = maptbx.grid2grid()
  g2c = maptbx.grid2cart(extents,unit_cell.orthogonalization_matrix())
  for site_cart in sites_cart:
    assert approx_equal( c2f(site_cart), unit_cell.fractionalize(site_cart) )
    frac_pt = unit_cell.fractionalize(site_cart)
    grid_pt = (frac_pt[0]*extents[0],frac_pt[1]*extents[1],frac_pt[2]*extents[2])
    assert approx_equal( c2g(site_cart), grid_pt )
    assert approx_equal( c2c(site_cart), site_cart )
  for site_frac in sites_frac:
    assert approx_equal( f2f(site_frac), site_frac )
    assert approx_equal( f2c(site_frac), unit_cell.orthogonalize(site_frac) )
    grid_pt = (site_frac[0]*extents[0],site_frac[1]*extents[1],site_frac[2]*extents[2])
    assert approx_equal( f2g(site_frac), grid_pt )
  for site_grid in sites_grid:
    frac_pt = (site_grid[0]/float(extents[0]),site_grid[1]/float(extents[1]),site_grid[2]/float(extents[2]))
    assert approx_equal( g2f(site_grid), frac_pt )
    assert approx_equal( g2g(site_grid), site_grid )
    assert approx_equal( g2c(site_grid), unit_cell.orthogonalize(frac_pt) )

def exercise_non_crystallographic_eight_point_interpolation():
  unit_cell=130.45,130.245,288.405,90,90,120
  unit_cell_gridding_n=144,144,360
  grid_cell=uctbx.unit_cell((130.45/144,130.245/144,388.405/360,90,90,120))
  grid_mat = grid_cell.fractionalization_matrix()
  map = test_map.deep_copy()
  map.resize(flex.grid((-1,-2,-1),(3,3,5)))
  for site_cart,expected_result in ([(0.468661,-1.549268,3.352108),-0.333095],
                                    [(0.624992,1.553980,1.205578),-0.187556],
                                    [(0.278175,0.968454,2.578265),-0.375068],
                                    [(0.265198,-1.476055,0.704381),-0.147061],
                                    [(1.296042,0.002101,3.459270),-0.304401],
                                    [(0.296189,-1.346603,2.935777),-0.296395],
                                    [(0.551586,-1.284371,3.202145),-0.363263],
                                    [(0.856542,-0.782700,-0.985020),-0.106925],
                                    [(0.154407,1.078936,-0.917551),-0.151128]):
    assert approx_equal(maptbx.non_crystallographic_eight_point_interpolation(
      map=map,
      gridding_matrix=grid_mat,
      site_cart=site_cart,
      allow_out_of_bounds=False,
      out_of_bounds_substitute_value=0), expected_result)
  for x in range(0,2):
    for y in range(-1,2):
      for z in range(0,4):
        assert approx_equal(
          maptbx.non_crystallographic_eight_point_interpolation(
            map,
            grid_mat,
            grid_cell.orthogonalize((x,y,z))), map[x,y,z])
  try:
    val = maptbx.non_crystallographic_eight_point_interpolation(
      map, grid_mat, (5,5,5))
  except RuntimeError as e:
    assert str(e) == \
      "cctbx Error: non_crystallographic_eight_point_interpolation:" \
      " point required for interpolation is out of bounds."
  else: raise Exception_expected
  assert approx_equal(maptbx.non_crystallographic_eight_point_interpolation(
    map, grid_mat, (5,5,5), True, -123), -123)

def exercise_average_density():
  map = test_map.deep_copy()
  map.resize(flex.grid(4,5,6))
  sites_frac = flex.vec3_double([
    (-0.8492400683111605, 0.49159543530354166, 0.55624239788303198),
    (0.10631567870879444, -0.38726326483005269, -0.13581656178827783),
    (0.1895918946688977, -0.25027164520003642, -0.61981792226895172),
    (-0.88980846616667897, -0.79492758628794169, 0.015347308715653485)])
  unit_cell = uctbx.unit_cell((130,130,288,90,90,120))
  densities = maptbx.average_densities(
    unit_cell=unit_cell,
    data=map,
    sites_frac=sites_frac,
    radius=5)
  assert approx_equal(densities, [0,0,0,0])
  densities = maptbx.average_densities(
    unit_cell=unit_cell,
    data=map,
    sites_frac=sites_frac,
    radius=50)
  assert approx_equal(densities, [
    -0.27089094117647061,
    -0.34313799999999994,
    -0.2644232307692308,
    -0.20403226666666666])

def exercise_grid_indices_around_sites():
  unit_cell = uctbx.unit_cell((5,5,5))
  fft_n_real = (5,5,5)
  fft_m_real = (5,5,5)
  site_radii = flex.double([0.5*3**0.5+1e-6])
  def get():
    grid_indices = maptbx.grid_indices_around_sites(
      unit_cell=unit_cell, fft_n_real=fft_n_real, fft_m_real=fft_m_real,
      sites_cart=sites_cart, site_radii=site_radii)
    return list(grid_indices)
  sites_cart = flex.vec3_double([(0.5,0.5,0.5)])
  assert get() == [0, 1, 5, 6, 25, 26, 30, 31]
  sites_cart = flex.vec3_double([(1.5,1.5,1.5)])
  assert get() == [31, 32, 36, 37, 56, 57, 61, 62]
  def sample():
    for i in range(-2,7):
      for j in range(-2,7):
        for k in range(-2,7):
          sites_cart = flex.vec3_double([(i+.5,j+.5,k+.5)])
          assert len(get()) == 8
  sample()
  #
  unit_cell = uctbx.unit_cell((5,6,7))
  fft_n_real = (5,6,7)
  fft_m_real = (5,6,7)
  sites_cart = flex.vec3_double([(0.5,0.5,0.5)])
  assert get() == [0, 1, 7, 8, 42, 43, 49, 50]
  fft_m_real = (5,6,8)
  assert get() == [0, 1, 8, 9, 48, 49, 56, 57]
  fft_m_real = (5,7,8)
  assert get() == [0, 1, 8, 9, 56, 57, 64, 65]
  sample()
  #
  site_radii = flex.double([2])
  assert len(get()) == 8 + 6*4
  site_radii = flex.double([1000])
  assert len(get()) == 5*6*7
  #
  unit_cell = uctbx.unit_cell((18,26,27))
  fft_n_real = (18,26,27)
  fft_m_real = (18,27,28)
  for ish in range(5):
    x = 2*ish+.5
    sites_cart = flex.vec3_double([[x]*3])
    sh = 3**0.5*(ish+0.5)
    site_radii = flex.double([sh-1e-6])
    s1 = set(get())
    site_radii = flex.double([sh+1e-6])
    s2 = set(get())
    for gi in sorted(s2-s1):
      i,j,k = n_dim_index_from_one_dim(gi, fft_m_real)
      assert approx_equal(abs(matrix.col((i-x,j-x,k-x))), sh)
    assert len(s1) == [0, 56, 304, 912, 1904][ish]
    assert len(s2) == [8, 88, 360, 968, 2008][ish]
  #
  unit_cell = uctbx.unit_cell((8,9,7,80,100,110))
  fft_n_real = (11,13,15)
  fft_m_real = (18,26,19)
  sites_cart = flex.vec3_double([(3,11,5)])
  ls = []
  prev = 0
  for r in itertools.count(1):
    site_radii = flex.double([r])
    l = len(get())
    assert l > prev
    ls.append(l)
    if (l == 11*13*15):
      break
    assert r < 7
    prev = l
  assert ls == [18, 155, 524, 1225, 1940, 2139, 2145]
  #
  fft_m_real = (1073741824, 1073741824, 1073741824)
  try:
    maptbx.grid_indices_around_sites(
      unit_cell=unit_cell, fft_n_real=fft_n_real, fft_m_real=fft_m_real,
      sites_cart=sites_cart, site_radii=site_radii)
  except RuntimeError as e:
    assert str(e).startswith("product of fft_m_real")
  else: raise Exception_expected

def exercise_standard_devations_around_sites():
  unit_cell = uctbx.unit_cell((5,5,5))
  fft_n_real = (5,5,5)
  fft_m_real = (5,5,6)
  density_map = flex.double(flex.grid(fft_m_real).set_focus(fft_n_real), 0)
  sites_cart = flex.vec3_double([(2.5,2.5,2.5)])
  site_radii = flex.double([1.2])
  def get():
    return maptbx.standard_deviations_around_sites(
      unit_cell=unit_cell, density_map=density_map,
      sites_cart=sites_cart, site_radii=site_radii)
  assert approx_equal(get(), [0])
  density_map[(2,2,2)] = 1
  assert approx_equal(get(), [0.35355339059327379])

def exercise_region_density_correlation():
  sites_frac = flex.vec3_double([
    (0.02,0.10,0.02),
    (0.10,0.02,0.40),
    (0.98,0.10,0.60),
    (0.10,0.98,0.80),
    (0.20,0.50,0.98)])
  from cctbx import xray
  xray_structure = xray.structure(
    crystal_symmetry=crystal.symmetry(
      unit_cell=(30,30,50,90,90,120),
      space_group_symbol="P1"),
    scatterers=flex.xray_scatterer([
      xray.scatterer(label=str(i), scattering_type="Si", site=site_frac)
        for i,site_frac in enumerate(sites_frac)]))
  d_min = 2
  f_calc = xray_structure.structure_factors(d_min=d_min).f_calc()
  density_map = f_calc.fft_map().real_map_unpadded()
  def get(region_sel):
    return maptbx.region_density_correlation(
      large_unit_cell=xray_structure.unit_cell(),
      large_d_min=d_min,
      large_density_map=density_map,
      sites_cart=xray_structure.sites_cart().select(region_sel),
      site_radii=flex.double(sites_frac.size(), 1).select(region_sel),
      work_scatterers=xray_structure.scatterers().select(region_sel))
  cc = get(region_sel=flex.bool(5, False))
  assert cc is None
  cc = get(region_sel=flex.bool(5, True))
  assert approx_equal(cc, 1)
  cc = get(region_sel=flex.size_t([4]))
  assert approx_equal(cc, 0.999923364584, eps=1.e-4)
  cc = get(region_sel=flex.size_t([0,2]))
  assert approx_equal(cc, 0.998640554144, eps=1.e-4)
  cc = get(region_sel=flex.size_t([1,3]))
  assert approx_equal(cc, 0.999324555256, eps=1.e-4)
  cc = get(region_sel=flex.size_t([0,4]))
  assert approx_equal(cc, 0.999570252441, eps=1.e-4)
  xray_structure.scatterers()[4].site = (0.205,0.503,0.974)
  cc = get(region_sel=flex.size_t([4]))
  assert approx_equal(cc, 0.6756590336, eps=1.e-3)

def exercise_boxing():
  n_real = (60, 100, 160)
  cs=crystal.symmetry(
    unit_cell=(21,37,58,80,111,117),
    space_group_symbol="P1")
  maptbx.boxes(n_real = n_real, fraction=0.1)

def exercise_hoppe_gassman_modification__and__convert_to_non_negative():
  values = [-2,-1,-0.3,-0.2,-0.1,0,0.1,0.2,0.3,0.4,3,4]
  random.choice([0,1,2,3,4,5,6,7,8,9,10,11])
  av = [values[random.choice([0,1,2,3,4,5,6,7])] for i in range(10*20*30)]
  a = flex.double(av)
  a.resize(flex.grid((10,20,30)))
  # inefficient, but transparent way
  a1 = a.deep_copy()
  maptbx.convert_to_non_negative(data=a1, substitute_value=0)
  assert flex.min(a1)>=0
  ave = flex.mean(a1.as_1d().select(a1.as_1d()>0))
  a1.set_selected(a1>ave*2, ave*2)
  a1 = a1/flex.max(a1)
  a1 = 3*a1*a1-2*a1*a1*a1
  assert flex.min(a1)>=0
  assert flex.max(a1)<=1
  # unobvious but efficient way
  a2 = a.deep_copy()
  maptbx.hoppe_gassman_modification(data=a2, mean_scale=2, n_iterations=1)
  assert flex.min(a2)>=0
  assert flex.max(a2)<=1
  #
  assert approx_equal(flex.mean(a1), flex.mean(a2))

def exercise_set_box():
  n_real = (60, 100, 160)
  n = n_real[0]*n_real[1]*n_real[2]
  cs=crystal.symmetry(
    unit_cell=(21,37,58,80,111,117),
    space_group_symbol="P1")
  be = maptbx.boxes(n_real = n_real, fraction=0.1)
  #
  m1 = flex.double([-1 for i in range(n)])
  m1.resize(flex.grid(n_real))
  m2 = flex.double([1 for i in range(n)])
  m2.resize(flex.grid(n_real))
  #
  for s,e in zip(be.starts, be.ends):
    box = maptbx.copy(m2, s, e)
    box.reshape(flex.grid(box.all()))
    maptbx.set_box(
      map_data_from = box,
      map_data_to   = m1,
      start         = s,
      end           = e)
  assert m2.as_1d().min_max_mean().as_tuple() == (1.,1.,1.)


def exercise_set_box_0():
  # Create a grid of size 10x10x10 having value 0 everywhere
  box = flex.double(flex.grid(10,10,10), 0)
  # test 0: same start and end
  b1 = box.deep_copy()
  try:
    maptbx.set_box(
      value       = -1,
      map_data_to = b1,
      start       = b1.all(),
      end         = b1.all())
  except RuntimeError as e:
    assert str(e).endswith("CCTBX_ASSERT(end[i] > start[i]) failure.")
  else: raise Exception_expected
  # test 1: transform entire unit cell
  b1 = box.deep_copy()
  maptbx.set_box(
    value       = -1,
    map_data_to = b1,
    start       = [0,0,0],
    end         = b1.all())
  assert approx_equal(b1.as_1d().min_max_mean().as_tuple(), [-1.0, -1.0, -1.0])
  # test 2: transform entire unit cell, this time translated
  b1 = box.deep_copy()
  maptbx.set_box(
    value       = 1,
    map_data_to = b1,
    start       = [-30,-30,-30],
    end         = [-20,-20,-20])
  assert approx_equal(b1.as_1d().min_max_mean().as_tuple(), [1.0, 1.0, 1.0])
  # test 3: start in neighboring cell and end at 0,0,0
  b1 = box.deep_copy()
  maptbx.set_box(
    value       = 1,
    map_data_to = b1,
    start       = [-5,-5,-5],
    end         = [0,0,0])
  assert approx_equal(b1.as_1d().min_max_mean().as_tuple(), [0.0, 1.0, 0.125])
  # test 4: slice instead of a box
  b1 = box.deep_copy()
  try:
    maptbx.set_box(
      value       = -1,
      map_data_to = b1,
      start       = [1,2,3],
      end         = [2,2,3])
  except RuntimeError as e:
    assert str(e).endswith("CCTBX_ASSERT(end[i] > start[i]) failure.")
  else: raise Exception_expected
  # test 5: another slice
  b1 = box.deep_copy()
  try:
    maptbx.set_box(
      value       = -1,
      map_data_to = b1,
      start       = [-1,0,2],
      end         = [0,0,3])
  except RuntimeError as e:
    assert str(e).endswith("CCTBX_ASSERT(end[i] > start[i]) failure.")
  else: raise Exception_expected
  # test 6: one point changed
  b1 = box.deep_copy()
  maptbx.set_box(
    value       = 1,
    map_data_to = b1,
    start       = [0,0,0],
    end         = [1,1,1])
  assert (b1==0).count(True)==999
  assert (b1==1).count(True)==1
  # test 7: change 1/8 of the unit cell
  b1 = box.deep_copy()
  maptbx.set_box(
    value       = 1,
    map_data_to = b1,
    start       = [0,0,0],
    end         = [5,5,5])
  assert approx_equal(b1.as_1d().min_max_mean().as_tuple(), [0.0, 1.0, 0.125])
  # test 8: change one point
  b1 = box.deep_copy()
  maptbx.set_box(
    value       = 1,
    map_data_to = b1,
    start       = [-1,-1,-1],
    end         = [0,0,0])
  assert (b1==0).count(True)==999
  assert (b1==1).count(True)==1
  # test 9: entire cell, end point is 0,0,0
  b1 = box.deep_copy()
  maptbx.set_box(
    value       = 1,
    map_data_to = b1,
    start       = [-10,-10,-10],
    end         = [0,0,0])
  assert approx_equal(b1.as_1d().min_max_mean().as_tuple(), [1.0, 1.0, 1.0])
  # test 10: slice of a box
  b1 = box.deep_copy()
  try:
    maptbx.set_box(
      value       = 1,
      map_data_to = b1,
      start       = [0,0,0],
      end         = [9,0,0])
  except RuntimeError as e:
    assert str(e).endswith("CCTBX_ASSERT(end[i] > start[i]) failure.")
  else: raise Exception_expected
  # test 11: box within unit cell one period apart
  b1 = box.deep_copy()
  maptbx.set_box(
    value       = 1,
    map_data_to = b1,
    start       = [14,14,14],
    end         = [19,19,19])
  assert approx_equal(b1.as_1d().min_max_mean().as_tuple(), [0.0, 1.0, 0.125])
  # test 12 box between cells, translated by a period
  b1 = box.deep_copy()
  maptbx.set_box(
    value       = 1,
    map_data_to = b1,
    start       = [-14,-14,-14],
    end         = [-9,-9,-9])
  assert approx_equal(b1.as_1d().min_max_mean().as_tuple(), [0.0, 1.0, 0.125])
  # TEST 13: Reset map values in a box within a unit cell
  n_real = (100, 60, 80)
  n = n_real[0]*n_real[1]*n_real[2]
  m1 = flex.double([1 for i in range(n)])
  m1.resize(flex.grid(n_real))
  maptbx.set_box(
    value       = -1,
    map_data_to = m1,
    start       = [20,30,40],
    end         = [80,40,60])
  assert m1.as_1d().min_max_mean().as_tuple() == (-1.,1.,0.95)
  # TEST 14: reset map values in a box crossing the border of the unit cell
  n_real = (60, 100, 80)
  n = n_real[0]*n_real[1]*n_real[2]
  m2 = flex.double([1 for i in range(n)])
  m2.resize(flex.grid(n_real))
  maptbx.set_box(
    value       = -1,
    map_data_to = m2,
    start       = [-10,-20,20],
    end         = [30,40,50])
  assert m2.as_1d().min_max_mean().as_tuple() == (-1.,1.,0.7)

def exercise_median_filter():
  values = [-2,-1,-0.3,-0.2,-0.1,0,0.1,0.2,0.3,0.4,3,4]
  av = [values[random.choice([0,1,2,3,4,5,6,7])] for i in range(10*20*30)]
  a = flex.double(av)
  a.resize(flex.grid((10,20,30)))
  maptbx.median_filter(map_data=a, index_span=1)

def exercise_kuwahara_filter():
  values = [-2,-1,-0.3,-0.2,-0.1,0,0.1,0.2,0.3,0.4,3,4]
  av = [values[random.choice([0,1,2,3,4,5,6,7])] for i in range(10*20*30)]
  a = flex.double(av)
  a.resize(flex.grid((10,20,30)))
  maptbx.kuwahara_filter(map_data=a, index_span=2)

def exercise_intersection():
  thresholds = flex.double([0,0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.8, 1.0])
  def get_map():
    av = [random.random() for i in range(10*20*30)]
    m = flex.double(av)
    m.resize(flex.grid((10,20,30)))
    return m
  m1 = get_map()
  m2 = get_map()
  for average in [True, False]:
    maptbx.intersection(
      map_data_1 = m1,
      map_data_2 = m2,
      thresholds = thresholds,
      average    = average)

def exercise_binarize():
  thresholds = flex.double([0,0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.8, 1.0])
  def get_map():
    av = [random.random() for i in range(10*20*30)]
    m = flex.double(av)
    m.resize(flex.grid((10,20,30)))
    return m
  m = get_map()
  maptbx.binarize(map_data=m, threshold=0.5, substitute_value_below=0,
    substitute_value_above=1)
  assert m.as_1d().min_max_mean().as_tuple()[:2] == (0,1)

def exercise_intersection():
  sites_frac = flex.vec3_double([
    (0.02,0.10,0.02),
    (0.10,0.02,0.40),
    (0.98,0.10,0.60),
    (0.10,0.98,0.80),
    (0.20,0.50,0.98)])
  from cctbx import xray
  xray_structure = xray.structure(
    crystal_symmetry=crystal.symmetry(
      unit_cell=(30,30,50,90,90,120),
      space_group_symbol="P1"),
    scatterers=flex.xray_scatterer([
      xray.scatterer(label=str(i), scattering_type="Si", site=site_frac)
        for i,site_frac in enumerate(sites_frac)]))
  d_min = 0.7
  f_calc = xray_structure.structure_factors(d_min=d_min).f_calc()
  fft_map = f_calc.fft_map(resolution_factor=1/6.)
  fft_map.apply_sigma_scaling()
  density_map = fft_map.real_map_unpadded()
  #
  cm1 = xray_structure.center_of_mass()
  cm2 = maptbx.center_of_mass(map_data=density_map, unit_cell=xray_structure.unit_cell(),
    cutoff=20) #large cutoff to make map look like point scattereres
  assert approx_equal(cm1, cm2, 0.1)

def exercise_map_accumulator(n1=2, n2=2, n3=2):
  ### Python prototype START
  def py_exercise(points, show=False, b=1):
    def smear(x, a, b):
      return math.exp(-(x-a)**2 / (2*b**2))
    def to_int(f):
      p0 = 0
      if(f<=p0): return 0
      return min(int(256*(f-p0)/(1.-p0))+1, 255)
    As = flex.int()
    for i, t_ in enumerate(points):
      a = to_int(t_)
      As.append(a)
      if(show): print("%2d: %8.4f %3d"%(i, t_, a))
    if(show): print(list(As))
    #
    R  = flex.double([0,]*256)
    Rx = flex.int(range(256))
    assert R.size()==Rx.size()
    #
    hit_l = False
    hit_r = False
    for a in As:
      for i in range(-10,11):
        x = a+i
        if(x>=0 and x<=255):
          R[x] += smear(x=x, a=a, b=b)
    #
    if(show):
      for i, rx in enumerate(R):
        print("%4d %10.7f"%(i, rx))
    #
    return R
  ### Python prototype END
  def get_ma(n1,n2,n3, points):
    ma = maptbx.map_accumulator(n_real = (n1,n2,n3), use_max_map=False)
    for value in points:
      m = [value for i in range(n1*n2*n3)]
      m = flex.double(m)
      m.resize(flex.grid((n1,n2,n3)))
      ma.add(map_data=m)
    return ma
  def mmm(m): return m.as_1d().min_max_mean().as_tuple()
  #
  # case 1
  points = flex.double([0,]*16)
  ma = get_ma(n1,n2,n3, points)
  assert approx_equal(mmm(ma.as_median_map()),(0,0,0))
  # case 2
  points = flex.double([1,]*16)
  ma = get_ma(n1,n2,n3, points)
  assert approx_equal(mmm(ma.as_median_map()),(255,255,255))
  # case 3
  points = flex.double([0.5,]*16)
  ma = get_ma(n1,n2,n3, points)
  assert approx_equal(mmm(ma.as_median_map()),(129,129,129))
  # case 4
  points = flex.double([i/16. for i in range(16)])
  ma = get_ma(n1,n2,n3, points)
  assert approx_equal(mmm(ma.as_median_map()),(0,0,0))
  # case 5
  points = flex.double([
    0,
    0.49375, 0.4875, 0.48125, 0.475, 0.46875, 0.4625, 0.45625,
    0.5,
    0.50625, 0.5125, 0.51875, 0.525, 0.53125, 0.5375, 0.54375,
    1])
  ma = get_ma(n1,n2,n3, points)
  assert approx_equal(mmm(ma.as_median_map()),(128.7,128.7,128.7), 0.01)
  # case 6
  points = flex.double([0,]*8+[1,]*8)
  ma = get_ma(n1,n2,n3, points)
  assert approx_equal(mmm(ma.as_median_map()),(0,0,0))
  # case 7
  points = flex.double([0,]*5+[0.5,]*6+[1,]*5)
  ma = get_ma(n1,n2,n3, points)
  assert approx_equal(mmm(ma.as_median_map()),(0,0,0))
  # case 8
  points = flex.double([0,]*4+[0.5,]*8+[1,]*4)
  ma = get_ma(n1,n2,n3, points)
  assert approx_equal(mmm(ma.as_median_map()),(0,0,0))
  # case 9
  points = flex.double([0,]*3+[0.5,]*10+[1,]*3)
  ma = get_ma(n1,n2,n3, points)
  assert approx_equal(mmm(ma.as_median_map()),(129,129,129))
  # case 10
  points = flex.double([
    0,0,
    0.36,0.37,0.38,0.39,0.4,0.41,0.42,
    0.67,0.68,0.69,0.7,0.71,
    1,1])
  ma = get_ma(n1,n2,n3, points)
  assert approx_equal(mmm(ma.as_median_map()),(100.17,100.17,100.17), 0.01)
  # case 11
  points = flex.double([0, 0.1,0.11, 0.44, 0.51,0.5101,0.515,0.534,0.54,0.55,
    0.577, 0.78,0.789, 0.77,0.79,0.8, 1])
  ma = get_ma(n1,n2,n3, points)
  # should be 27 or 28 if handles plateaus correctlu (see c++ code for a comment)
  assert approx_equal(mmm(ma.as_median_map()),(134.67,134.67,134.67), 0.01)
  # case 12
  points = flex.double([0.6423, 0.0000, 0.6346, 0.0000, 0.7042, 0.7037, 0.7092,
    0.0067, 0.0000, 0.6796, 0.7073, 0.7900, 0.8083, 0.7582, 0.6609, 0.6851])
  ma = get_ma(n1,n2,n3, points)
  assert approx_equal(mmm(ma.as_median_map()),(0,0,0))
  ###
  # useful for debugging
  #py_exercise(points=points, show=True, b=2)
  #print mmm(ma.as_median_map())
  ###
  # case xxx
  table = """
 0 0.8425 0.5849 0.7631 0.7929 0.7979 0.8319 0.6423 0.8151 0.6436 0.8064
 1 0.7954 0.0000 0.8245 0.8124 0.8245 0.8356 0.0000 0.7857 0.7891 0.8261
 2 0.7798 0.5470 0.8324 0.8453 0.8334 0.8256 0.6346 0.8167 0.5750 0.8150
 3 0.6782 0.7564 0.8275 0.7687 0.8300 0.8496 0.0000 0.6892 0.7873 0.8129
 4 0.7508 0.7976 0.8347 0.8284 0.8325 0.8334 0.7042 0.8344 0.6594 0.8312
 5 0.7192 0.5254 0.8341 0.8376 0.8336 0.8283 0.7037 0.8147 0.0693 0.7969
 6 0.7715 0.5572 0.8238 0.7971 0.8219 0.8312 0.7092 0.8138 0.7656 0.8116
 7 0.7813 0.5117 0.8071 0.8205 0.7839 0.7857 0.0067 0.8208 0.8069 0.7658
 8 0.8228 0.7991 0.8310 0.8057 0.8289 0.8343 0.0000 0.8295 0.7911 0.8072
 9 0.7975 0.6647 0.8411 0.8421 0.8437 0.8383 0.6796 0.8463 0.4164 0.8147
10 0.7570 0.4042 0.8310 0.8263 0.8357 0.8306 0.7073 0.8263 0.7749 0.8061
11 0.7565 0.7787 0.8140 0.8176 0.8302 0.8381 0.7900 0.8109 0.5895 0.8068
12 0.8105 0.3355 0.8273 0.8390 0.7878 0.8159 0.8083 0.8421 0.5090 0.8254
13 0.7748 0.5478 0.8075 0.8365 0.8278 0.8230 0.7582 0.8336 0.4904 0.8077
14 0.8250 0.7528 0.8053 0.8416 0.8251 0.8518 0.6609 0.8097 0.7752 0.7933
15 0.7847 0.4245 0.8193 0.8146 0.8283 0.8435 0.6851 0.8297 0.8027 0.8125
"""
  d = {}
  for l in table.splitlines():
    for i, v in enumerate(l.split()):
      if(i>0): d.setdefault(i, []).append(float(v))
  #
  Rs = []
  results = []
  for points in d.values():
    ma = get_ma(n1,n2,n3, points)
    r = mmm(ma.as_median_map())
    #print r
    results.append(r[0])
    Rs.append(py_exercise(points=points, show=False, b=5))
  assert approx_equal(results,
    (200.70, 140.54, 211.58, 212.27, 212.71, 213.86, 0.0, 211.27, 201.98, 208.10),
    0.1)
  # good to plot frequency distribution
  #for i in range(Rs[0].size()):
  #  print " ".join(["%10.7f"%r[i] for r in Rs])

def exercise_cc_peak():
  def get_map():
    av = [random.random() for i in range(10*20*30)]
    m = flex.double(av)
    m = m-flex.min(m)
    m = m/flex.max(m)
    m.resize(flex.grid((10,20,30)))
    return m
  m1 = get_map()
  m2 = get_map()
  for t in range(0,11):
    t=t/10.
    ccp=maptbx.cc_peak(map_1=m1, map_2=m2, cutoff=t)
  #
  sites_frac = flex.vec3_double([
    (0.50,0.50,0.50)])
  from cctbx import xray
  xray_structure = xray.structure(
    crystal_symmetry=crystal.symmetry(
      unit_cell=(5,5,5,90,90,90),
      space_group_symbol="P1"),
    scatterers=flex.xray_scatterer([
      xray.scatterer(label=str(i), scattering_type="C", site=site_frac)
        for i,site_frac in enumerate(sites_frac)]))
  fc1 = xray_structure.structure_factors(d_min=1.6).f_calc()
  fc2 = xray_structure.structure_factors(d_min=1.7).f_calc()
  for t in range(0,11):
    t=t/10.
    ccp=maptbx.cc_peak(map_coeffs_1=fc1, map_coeffs_2=fc2, cutoff=t)
  #
  m1_he = maptbx.volume_scale(map = m1,  n_bins = 10000).map_data()
  m2_he = maptbx.volume_scale(map = m2,  n_bins = 10000).map_data()
  cutoffs = flex.double([i/20. for i in range(1,20)])
  df = maptbx.discrepancy_function(map_1=m1_he, map_2=m2_he, cutoffs=cutoffs)
  #
  fc1 = xray_structure.structure_factors(d_min=2.2).f_calc()
  fc2 = xray_structure.structure_factors(d_min=2.2).f_calc()
  for t in range(0,10):
    t=t/10.
    ccp=maptbx.cc_peak(map_coeffs_1=fc1, map_coeffs_2=fc2, cutoff=t)
    assert approx_equal(ccp, 1)
  # 1D case
  m1_he_1d = maptbx.volume_scale_1d(map = m1.as_1d(),  n_bins = 10000).map_data()
  m2_he_1d = maptbx.volume_scale_1d(map = m2.as_1d(),  n_bins = 10000).map_data()
  df_1d = maptbx.discrepancy_function(
    map_1=m1_he_1d, map_2=m2_he_1d, cutoffs=cutoffs)
  assert approx_equal(df, df_1d)

def exercise_gamma_compression():
  def get_map():
    av = [random.random() for i in range(10*20*30)]
    m = flex.double(av)
    m = (m-flex.min(m))*10
    m.resize(flex.grid((10,20,30)))
    return m
  m = get_map()
  maptbx.gamma_compression(map_data=m, gamma=0.5)


def exercise_sample_all_mask_regions():
  cmap = flex.double(flex.grid(30,30,30))
  cmap.fill(1)
  for i in range(0,10):
    for j in range(0,10):
      for k in range(0,10):
        cmap[i,j,k] = 10
  for i in range(15,25):
    for j in range(15,25):
      for k in range(15,25):
        cmap[i,j,k] = 20
  co = maptbx.connectivity(map_data=cmap, threshold=5, wrapping=False)
  uc = uctbx.unit_cell((10,10,10))
  mask_result = co.result()

  sample_regs_obj = maptbx.sample_all_mask_regions(
      mask=mask_result,
      volumes=flex.int([0, 1000,1000]),
      sampling_rates=flex.int([0, 10,10]),
      unit_cell=uc)
  a = sample_regs_obj.get_array(1)
  b = sample_regs_obj.get_array(2)

  assert a.size() == b.size() == 101
  assert approx_equal(a[0], (0,0,0))
  assert approx_equal(b[0], (5,5,5))

def exercise_map_values_along_line_connecting_two_points():
  pdb_str= """
CRYST1   10.000   10.000   10.000  90.00  90.00  90.00 P 1
HETATM    1  O   HOH A   1       1.000   2.000   3.000  1.00 10.00           O
HETATM    2  O   HOH A   2       4.000   5.000   6.000  1.00 20.00           O
END
"""
  import iotbx.pdb
  xrs = iotbx.pdb.input(lines = pdb_str, source_info=None).xray_structure_simple()
  fc = xrs.structure_factors(d_min=1).f_calc()
  fft_map = fc.fft_map(resolution_factor=1/4.)
  fft_map.apply_sigma_scaling()
  map_data = fft_map.real_map_unpadded()
  r = maptbx.map_values_along_line_connecting_two_points(
    map_data=map_data, points_cart=xrs.sites_cart(), step=0.001,
    unit_cell=xrs.unit_cell(), interpolation="tricubic")
  #
  sites_frac = xrs.sites_frac()
  m1 = map_data.tricubic_interpolation(sites_frac[0])
  m2 = map_data.tricubic_interpolation(sites_frac[1])
  #
  assert approx_equal(m1, r.vals[0])
  assert approx_equal(m2, r.vals[-1])

def run(args):
  assert args in [[], ["--timing"]]
  timing = len(args) != 0
  exercise_map_accumulator()
  exercise_gamma_compression()
  exercise_cc_peak()
  exercise_binarize()
  exercise_intersection()
  exercise_boxing()
  exercise_kuwahara_filter()
  exercise_median_filter()
  exercise_set_box()
  exercise_set_box_0()
  exercise_copy()
  exercise_statistics()
  exercise_grid_tags()
  exercise_gridding()
  exercise_misc()
  exercise_peak_search()
  exercise_pymol_interface()
  exercise_structure_factors()
  exercise_fft()
  exercise_transformers()
  exercise_eight_point_interpolation()
  exercise_real_space_gradients_simple(timing=timing)
  exercise_non_crystallographic_eight_point_interpolation()
  exercise_asu_eight_point_interpolation()
  exercise_average_density()
  exercise_grid_indices_around_sites()
  exercise_standard_devations_around_sites()
  exercise_region_density_correlation()
  exercise_hoppe_gassman_modification__and__convert_to_non_negative()
  exercise_sample_all_mask_regions()
  exercise_map_values_along_line_connecting_two_points()
  print("OK")

if (__name__ == "__main__"):
  run(args=sys.argv[1:])


 *******************************************************************************


 *******************************************************************************
cctbx/maptbx/box.py
from __future__ import absolute_import, division, print_function
from libtbx.math_utils import ifloor, iceil
from libtbx.utils import Sorry, null_out
from cctbx import crystal, maptbx, uctbx
from scitbx.array_family import flex
from libtbx import group_args
import iotbx.map_manager
import mmtbx.model
import sys

class with_bounds(object):
  """
  Extract map box using specified lower_bounds and upper_bounds

  Creates new map_manager and modifies model in place

  Input map_manager must have origin (working position) at (0, 0, 0)
  Input model coordinates must correspond to working position of map_manager

  On initialization new bounds and crystal_symmetry are identified.
  Then map_manager is replaced with boxed version and shifted model is created

  Output versions of map_manager and model are in P1 and have origin at (0, 0, 0).
  Bounds refer to grid position in this box with origin at (0, 0, 0)

  Wrapping:
    wrapping = True means that grid points outside of the unit cell can be
    mapped inside with unit translations and box can effectively come
    from anywhere in space.
    If wrapping = True, the supplied box must be a complete unit cell so that
    map_data.all() must be the same as unit_cell_grid.

   wrapping = False means that grid points outside of the unit cell are
    undefined.  If a box is specified that uses points outside the defined
    region, those points are set to zero.

  if use_cubic_boxing, adjust bounds to make a cubic box by making box bigger.
      if this conflicts with stay_inside_current_map, make box smaller. Normally
      this option should not be used with with_bounds because the bounds should
      be directly specified.
  Note: stay_inside_current_map applies only when using cubic boxing
  If require_match_unit_cell_crystal_symmetry:  require that unit_cell
    crystal symmetry of map and model match

  """
  def __init__(self,
     map_manager,
     lower_bounds,
     upper_bounds,
     model = None,
     wrapping = None,
     model_can_be_outside_bounds = False,
     stay_inside_current_map = True,
     use_cubic_boxing = False,
     require_match_unit_cell_crystal_symmetry = False,
     log = sys.stdout):

    self.require_match_unit_cell_crystal_symmetry = \
       require_match_unit_cell_crystal_symmetry
    self.lower_bounds = lower_bounds
    self.upper_bounds = upper_bounds
    self._map_manager = map_manager
    self._model = model
    self.model_can_be_outside_bounds = model_can_be_outside_bounds
    self.use_cubic_boxing = use_cubic_boxing
    self._info = None


    # safeguards
    assert lower_bounds is not None
    assert upper_bounds is not None
    assert len(tuple(lower_bounds))==3
    assert len(tuple(upper_bounds))==3
    for i in range(3):
      assert list(upper_bounds)[i] > list(lower_bounds)[i]

    assert isinstance(map_manager, iotbx.map_manager.map_manager)

    assert self._map_manager.map_data().accessor().origin()  ==  (0, 0, 0)
    if model is not None:
      assert isinstance(model, mmtbx.model.manager)
      assert map_manager.is_compatible_model(model,
        require_match_unit_cell_crystal_symmetry=True)

    self._force_wrapping = wrapping
    if wrapping is None:
      wrapping = self.map_manager().wrapping()
    self.basis_for_boxing_string = 'supplied bounds, wrapping = %s' %(
      wrapping)

    # These are lower and upper bounds of map with origin at (0, 0, 0)
    #   (not the original map)

    self.gridding_first = lower_bounds
    self.gridding_last  = upper_bounds

    # Adjust gridding to make a cubic box if desired
    if self.use_cubic_boxing:
      self.set_cubic_boxing(stay_inside_current_map = stay_inside_current_map)

    # Ready with gridding...set up shifts and box crystal_symmetry
    self.set_shifts_and_crystal_symmetry()

    # Apply boxing to model, ncs, and map (if available)
    self.apply_to_model_ncs_and_map()

  def as_map_model_manager(self):
    '''
      Return map_model_manager object with contents of this class (not a deepcopy)

    '''
    from iotbx.map_model_manager import map_model_manager
    mmm = map_model_manager(
        map_manager = self.map_manager(),
        model = self.model(),
        )
    # Keep track of the gridding in this boxing.
    mmm.set_gridding_first(self.gridding_first)
    mmm.set_gridding_last(self.gridding_last)
    return mmm

  def model(self):
    return self._model

  def map_manager(self):
    return self._map_manager

  def info(self):
    return self._info

  def set_info(self, info):
    ''' Holder for anything you want.
      Usually set it to a group_args object:
         self.set_info(group_args(group_args_type='my_group_args', value = value))
    '''

    self._info = info

  def ncs_object(self):
    if self.map_manager():
      return self.map_manager().ncs_object()
    else:
      return None

  def set_cubic_boxing(self, stay_inside_current_map = None,
    require_even_gridding = True,
    log = sys.stdout):
    ''' Adjust bounds to make a cubic box.
      Adjust bounds to make a cubic box by making box bigger.
      if this conflicts with stay_inside_current_map, make box smaller. Normally
      this option should not be used with with_bounds because the bounds should
      be directly specified.
      Normally creates a box with an even number of grid points '''

    if not self.use_cubic_boxing:
      return  # nothing to do

    print("\nSetting up cubic box", file = log)
    map_all = self._map_manager.map_data().all()
    lmn = [1 + b - a for a,b in zip(self.gridding_first, self.gridding_last)]
    if lmn[0] == lmn[1] and lmn[0] == lmn[2] and (
       is_even(lmn[0]) or (not require_even_gridding)):
      print("Box is already cubic with dimensions ",lmn, file = log)
      return # all set already
    # Maximum dimension of box
    max_dim = max(lmn)
    if not is_even(max_dim):
      max_dim += 1

    # How many grid points to add in each direction
    dlmn = [max_dim - a for a in lmn]
    # How many to add before
    dlmn1= [a//2 for a in dlmn]
    # How many to add after
    dlmn2 = [a - b for a,b in zip( dlmn, dlmn1)]
    # New start, end
    new_first = [b - a for a, b in zip(dlmn1,self.gridding_first)]
    new_last = [b + a for a, b in zip(dlmn2,self.gridding_last)]
    new_lmn = [1 +b - a for a,b in zip(new_first, new_last)]

    print("Original map size: ",map_all, file = log)
    print("Original box: ",lmn, "cubic:", max_dim, file = log)
    print("Original start: ",self.gridding_first, file = log)
    print("Original end: ",self.gridding_last, file = log)
    print("New box: ",new_lmn, file = log)
    print("New start: ",new_first, file = log)
    print("New end: ",new_last, file = log)

    # Now make sure we are inside map if requested
    lowest_value,highest_value = cube_relative_to_box( # 0 or neg, 0 or pos
      new_first, new_last, map_all,
       require_even_gridding = require_even_gridding)
    if stay_inside_current_map and (lowest_value != 0 or highest_value != 0):
      print("Reboxing cubic map to stay inside current map", file = log)
      new_first = [a - lowest_value for a in new_first]
      new_last = [a - highest_value for a in new_last]
      lowest_value,highest_value = cube_relative_to_box(
        new_first, new_last, map_all,
        require_even_gridding = require_even_gridding)
      assert [lowest_value,highest_value] == [0,0]
    print("Final start: ",new_first, file = log)
    print("Final end: ",new_last, file = log)
    print("Final box: ",[1 + b - a for a,b in zip(new_first, new_last)],
       file = log)
    self.gridding_first = new_first
    self.gridding_last = new_last

  def set_shifts_and_crystal_symmetry(self):
    '''
      Set items needed to do the shift

      Here self.gridding_first and self.gridding_last are the grid points
      marking the start and end, in the map with origin at (0, 0, 0), of the
      region to be kept.

      Also save the input crystal_symmetry for comparison later
    '''

    # Save to check later if another map_manager is used as input
    self.accessor_at_initialization = self._map_manager.map_data().accessor()
    self.map_crystal_symmetry_at_initialization = self._map_manager.crystal_symmetry()

    full_cs = self._map_manager.unit_cell_crystal_symmetry()
    full_uc = full_cs.unit_cell()
    self.box_all = [j-i+1 for i, j in zip(self.gridding_first, self.gridding_last)]
    assert min(self.box_all) >= 1 # box size must be greater than zero. Check stay_inside_current_map and bounds
    # get shift vector as result of boxing
    full_all_orig = self._map_manager.unit_cell_grid
    self.shift_frac = \
        [-self.gridding_first[i]/full_all_orig[i] for i in range(3)]
    self.shift_cart = full_cs.unit_cell().orthogonalize(self.shift_frac)
    # get crystal symmetry of the box
    p = full_uc.parameters()
    abc = [p[i] * self.box_all[i]/full_all_orig[i] for i in range(3)]
    box_uc = uctbx.unit_cell(parameters = (abc[0], abc[1], abc[2], p[3], p[4], p[5]))
    self.crystal_symmetry = crystal.symmetry(
      unit_cell = box_uc, space_group = "P1")

    self._warning_message = ""

  def warning_message(self):
    return self._warning_message

  def apply_to_model_ncs_and_map(self):
    '''
    Apply boxing to to self._model,  self._map_manager
    so all are boxed

    '''

    if self._model:
      self._model = self.apply_to_model(self._model)

    self._map_manager = self.apply_to_map(self._map_manager)


  def apply_to_map(self, map_manager):
    '''
     Apply boxing to a map_manager that is similar to the one used to generate
       this around_model object

     Also apply to its ncs_object, if any

    '''
    assert isinstance(map_manager, iotbx.map_manager.map_manager)

    # This one should just have similar unit_cell_crystal_symmetry
    # crystal_symmetry should match self.map_crystal_symmetry_at_initialization

    assert map_manager.unit_cell_crystal_symmetry().is_similar_symmetry(
      self._map_manager.unit_cell_crystal_symmetry())
    assert map_manager.crystal_symmetry().is_similar_symmetry(
      self.map_crystal_symmetry_at_initialization)

    ma1 = map_manager.map_data().accessor()
    ma2 = self.accessor_at_initialization
    assert ma1.all()     ==  ma2.all()
    assert ma1.origin()  ==  ma2.origin()
    assert ma1.focus()   ==  ma2.focus()
    map_data = map_manager.map_data()
    # Check if map is all valid
    bounds_info = get_bounds_of_valid_region(map_data,
      self.gridding_first,
      self.gridding_last)
    # Allow override of wrapping
    if isinstance(self._force_wrapping, bool):
      wrapping = self._force_wrapping
    else:
      # Get wrapping from map_manager. If it is not defined and
      #  bounds are outside allowed, try to get the wrapping
      wrapping = map_manager.wrapping()

    if wrapping or bounds_info.inside_allowed_bounds:
      # Just copy everything
      map_box = maptbx.copy(map_data, self.gridding_first, self.gridding_last)
      # Note: map_box gridding is self.gridding_first to self.gridding_last
    elif not bounds_info.some_valid_points:
      # No valid points, Just copy everything and zero
      map_box = maptbx.copy(map_data, self.gridding_first, self.gridding_last)
      map_box = map_box * 0.
      self._warning_message += "\nWARNING: boxed map is entirely outside map"+\
         " and wrapping=%s\n...setting all values to zero" %(wrapping)

    else: # Need to copy and then zero outside of defined region
      map_box = copy_and_zero_map_outside_bounds(map_data, bounds_info)
      self._warning_message += \
            "\nWARNING: boxed map goes outside original map"+\
         " and wrapping=%s\n...setting unknown values to zero" %(wrapping)
    #  Now reshape map_box to put origin at (0, 0, 0)
    map_box.reshape(flex.grid(self.box_all))

    # Create new map_manager object:
    #   Use original values for:
    #     unit_cell_grid    (gridding of original full unit cell)
    #     unit_cell_crystal_symmetry  (symmetry of original full unit cell)
    #     input_file_name
    #   Use new (boxed) values for:
    #     map_data
    #     crystal_symmetry   (symmetry of the part of the map that is present)
    #   Update:
    #     origin_shift_grid_units  (position in the original map of the
    #                                 (0, 0, 0) grid point in map_box)
    #     labels  (add label specifying boxing operation)
    #
    # New origin_shift_grid_units:
    origin_shift_grid_units = [
      self.gridding_first[i]+map_manager.origin_shift_grid_units[i]
        for i in range(3)]
    # New labels:
    new_label = "Boxed %s to %s %s" %(
      str(tuple(self.gridding_first)), str(tuple(self.gridding_last)),
      self.basis_for_boxing_string)
    #  Set up new map_manager. This will contain new data and not overwrite
    #   original
    #  NOTE: origin_shift_grid_units is required as bounds have changed

    # Crystal symmetry is now always P1 and wrapping is False
    new_map_manager = map_manager.customized_copy(map_data = map_box,
      origin_shift_grid_units = origin_shift_grid_units,
      crystal_symmetry_space_group_number = 1,
      wrapping = False)
    if self._force_wrapping:
      # Set the wrapping of the new map if it is possible
      if (self._force_wrapping and (new_map_manager.is_full_size())) or \
       ( (not self._force_wrapping) and (not new_map_manager.is_full_size())):
        new_map_manager.set_wrapping(self._force_wrapping)

    # Add the label
    new_map_manager.add_label(new_label)
    return new_map_manager

  def apply_to_model(self, model):
    '''
       Apply boxing to a model that is similar to the one used to generate
       this around_model object

       Changes the model in place

       Allow relaxed check if require_match_unit_cell_crystal_symmetry=False
    '''

    assert isinstance(model, mmtbx.model.manager)

    # This one should have similar unit_cell_crystal_symmetry for map and
    #  model and model original_crystal_symmetry should match
    #   self.map_crystal_symmetry_at_initialization

    # Allow relaxed check if require_match_unit_cell_crystal_symmetry=False

    s = getattr(self,'require_match_unit_cell_crystal_symmetry', None)
    require_uc_crystal_symmetry = (s in (None, True))
    if require_uc_crystal_symmetry:
      if model.shift_cart() is None:
        # model not yet initialized for shifts
        assert self.map_manager().unit_cell_crystal_symmetry(
          ).is_similar_symmetry( model.crystal_symmetry())
      else:  # model is initialized: should match unless not requiring it
        assert model.unit_cell_crystal_symmetry()
        assert self.map_manager().unit_cell_crystal_symmetry(
           ).is_similar_symmetry( model.unit_cell_crystal_symmetry())

    # Shift the model and add self.shift_cart on to whatever shift was there
    model.shift_model_and_set_crystal_symmetry(
       shift_cart = self.shift_cart, # shift to apply
       crystal_symmetry = self.crystal_symmetry, # new crystal_symmetry
       )

    # if wrapping is False, check to see if model is outside the box
    if (not self.map_manager().wrapping()) and (
        not self.model_can_be_outside_bounds):
      if not model.is_inside_working_cell():
        self._warning_message += "\nWARNING: Model is not entirely "+\
          "inside working cell and wrapping is False"
    return model

  def apply_to_ncs_object(self, ncs_object):
    '''
      Apply shifts from this boxing to an ncs_object
       ncs does keep track of shifts
    '''

    return ncs_object.coordinate_offset(coordinate_offset = self.shift_cart)


class around_model(with_bounds):
  """
  Extract map box around atomic model. Box is in P1 and has origin at (0, 0, 0).

  Creates new map_manager and modifies model in place

  Input map_manager must have origin (working position) at (0, 0, 0)
  Input model coordinates must correspond to working position of map_manager

  On initialization new bounds and crystal_symmetry are identified.
  Then map_manager is replaced with boxed version and shifted model is created

  Output versions of map_manager and model are in P1 and have origin
    at (0, 0, 0).
  Bounds refer to grid position in this box with origin at (0, 0, 0)

  Wrapping:
    wrapping = True means that grid points outside of the unit cell can be
    mapped inside with unit translations and box can effectively come
    from anywhere in space.
    If wrapping = True, the supplied box must be a complete unit cell so that
    map_data.all() must be the same as unit_cell_grid.

   wrapping = False means that grid points outside of the unit cell are
    undefined.  If a box is specified that uses points outside the defined
    region, those points are set to zero.

  Bounds:
    if model_can_be_outside_bounds, allow model to be outside the bounds
    if stay_inside_current_map, adjust bounds to not go outside current map
      in the case that bounds are entirely outside current map, use current map
    Note: stay_inside_current_map applies to all boxing in this method
      because it is a normal part of the boxing process (in other boxing it
        only applies to cubic boxing which can cause a box to go outside the
        current map)
    if use_cubic_boxing, adjust bounds to make a cubic box by making box bigger.
      if this conflicts with stay_inside_current_map, make box smaller
  If require_match_unit_cell_crystal_symmetry:  require that unit_cell
    crystal symmetry of map and model match
  """
  def __init__(self, map_manager, model, box_cushion,
      wrapping = None,
      model_can_be_outside_bounds = False,
      stay_inside_current_map = None, # Note that this default is different
      use_cubic_boxing = False,
      require_match_unit_cell_crystal_symmetry = False,
      log = sys.stdout):

    self._map_manager = map_manager
    self._model = model
    self.model_can_be_outside_bounds = model_can_be_outside_bounds
    self.use_cubic_boxing = use_cubic_boxing
    self.require_match_unit_cell_crystal_symmetry = \
       require_match_unit_cell_crystal_symmetry

    s = getattr(self,'require_match_unit_cell_crystal_symmetry', None)
    self._force_wrapping = wrapping
    if wrapping is None:
      wrapping = self.map_manager().wrapping()
    self.basis_for_boxing_string = 'using_model, wrapping = %s' %(
      wrapping)

    # safeguards
    assert isinstance(map_manager, iotbx.map_manager.map_manager)
    assert isinstance(model, mmtbx.model.manager)
    assert self._map_manager.map_data().accessor().origin()  ==  (0, 0, 0)

    # Do not work with dummy map_manager
    assert not map_manager.is_dummy_map_manager()

    # Make sure working model and map_manager crystal_symmetry match
    assert map_manager.is_compatible_model(model,
      require_match_unit_cell_crystal_symmetry =
         self.require_match_unit_cell_crystal_symmetry)

    assert box_cushion >=  0

    if self.map_manager().wrapping():  # map must be entire unit cell
      assert map_manager.unit_cell_grid == map_manager.map_data().all()

    # NOTE: We are going to use crystal_symmetry and sites_frac based on
    #   the map_manager (the model could still have different crystal_symmetry)

    info = get_bounds_around_model(
      map_manager = map_manager,
      model = model,
      box_cushion = box_cushion,
      stay_inside_current_map = stay_inside_current_map)
    from scitbx.matrix import col
    if flex.double(col(info.upper_bounds) - col(info.lower_bounds)
        ).min_max_mean().min < -0.5:  # nothing there
      raise AssertionError("Sorry, model is entirely outside box,"+
        " so boxing around model staying inside current map is not possible")
      self.gridding_first = map_manager.data().origin()
      self.gridding_last = map_manager.data().all()
    else: # usual
      self.gridding_first = info.lower_bounds
      self.gridding_last = info.upper_bounds

    # Adjust gridding to make a cubic box if desired
    if self.use_cubic_boxing:
      self.set_cubic_boxing(stay_inside_current_map = stay_inside_current_map)

    # Ready with gridding...set up shifts and box crystal_symmetry
    self.set_shifts_and_crystal_symmetry()

    # Apply boxing to model, ncs, and map (if available)
    self.apply_to_model_ncs_and_map()

class around_unique(with_bounds):

  '''
  Identify unique part of density in a map (using ncs object if present)
  and create a new map_manager containing this box of density, masked
  around regions containing density.  Note: the map may be masked between
  nearby density regions so this map could have many discontinuities.

  NOTE: This method carries out both boxing and masking. Its effect is
  similar to create_box_with_bounds, where the bounds are defined by the
  asymmetric part of the map, followed by masking around that asymmetric part
  of the map.

  NOTE: ncs_object from map_manager will be used to identify the unique
  part of the map.

  Creates new map_manager and modifies model in place

  Input map_manager must have origin (working position) at (0, 0, 0)
  Input model coordinates must correspond to working position of map_manager

  On initialization new bounds and crystal_symmetry are identified.
  Then map_manager is replaced with boxed version and shifted model is created

  Output versions of map_manager and model are in P1 and have origin at (0, 0, 0).
  Bounds refer to grid position in this box with origin at (0, 0, 0)

  Wrapping:
    wrapping = True means that grid points outside of the unit cell can be
    mapped inside with unit translations and box can effectively come
    from anywhere in space.
    If wrapping = True, the supplied box must be a complete unit cell so that
    map_data.all() must be the same as unit_cell_grid.

   wrapping = False means that grid points outside of the unit cell are
    undefined.  If a box is specified that uses points outside the defined
    region, those points are set to zero.

    if use_cubic_boxing, adjust bounds to make a cubic box by making box bigger.
      if this conflicts with stay_inside_current_map, make box smaller
    Note: stay_inside_current_map applies only when using cubic boxing

      Additional parameters:
         mask_expand_ratio:   allows increasing masking radius beyond default at
                              final stage of masking
         solvent_content:  fraction of cell not occupied by macromolecule. May
                           be None in which case it is estimated from the map
         sequence:        one-letter code of sequence of unique part of molecule
         chain_type:       PROTEIN or RNA or DNA. Used with sequence to estimate
                            molecular_mass
         molecular_mass:    Molecular mass (Da) of entire molecule used to
                            estimate solvent_content
         symmetry:         Alternative way to specify symmetry (as a character
                            string like D2, T, C3)
         use_symmetry_in_extract_unique:   Use symmetry in identification
                            of unique part of map
         target_ncs_au_model: model marking center of location to choose as
                              unique
         box_cushion:        buffer around unique region to be boxed
         soft_mask:  use soft mask
         keep_low_density:  keep low density regions
         regions_to_keep:   Allows choosing just highest-density contiguous
                            region (regions_to_keep=1) or a few
         keep_this_region_only: Allows choosing any specific region (first region is 0 not 1)
         residues_per_region: Allows setting threshold to try and get about this many
                              residues in each region. Default is 50.
        If require_match_unit_cell_crystal_symmetry:  require that unit_cell
           crystal symmetry of map and model match

  '''

  def __init__(self, map_manager,
    model = None,
    target_ncs_au_model = None,
    regions_to_keep = None,
    residues_per_region = None,
    keep_this_region_only = None,
    solvent_content = None,
    resolution = None,
    sequence = None,
    molecular_mass = None,
    symmetry = None,
    use_symmetry_in_extract_unique = True,
    chain_type = 'PROTEIN',
    keep_low_density = True,  # default from map_box
    box_cushion= 5,
    soft_mask = True,
    mask_expand_ratio = 1,
    wrapping = None,
    use_cubic_boxing = False,
    stay_inside_current_map = True,
    require_match_unit_cell_crystal_symmetry = False,
    log = None):


    self.require_match_unit_cell_crystal_symmetry = \
       require_match_unit_cell_crystal_symmetry

    self.model_can_be_outside_bounds = None  # not used but required to be set
    self.use_cubic_boxing = use_cubic_boxing
    self._map_manager = map_manager
    self._model = model

    self._mask_data = None

    self._force_wrapping = wrapping
    if wrapping is None:
      wrapping = self.map_manager().wrapping()
    self.basis_for_boxing_string = 'around_unique, wrapping = %s' %(
      wrapping)

    if log is None:
      log = null_out() # Print only if a log is supplied

    assert isinstance(map_manager, iotbx.map_manager.map_manager)
    assert self._map_manager.map_data().accessor().origin()  ==  (0, 0, 0)
    assert resolution is not None
    if model is not None:
      assert isinstance(model, mmtbx.model.manager)
      assert map_manager.is_compatible_model(model,
        require_match_unit_cell_crystal_symmetry=True)
    if self.map_manager().wrapping():  # map must be entire unit cell
      assert map_manager.unit_cell_grid == map_manager.map_data().all()

    # Get crystal_symmetry
    crystal_symmetry = map_manager.crystal_symmetry()
    # Convert to map_data

    from cctbx.maptbx.segment_and_split_map import run as segment_and_split_map
    assert self._map_manager.map_data().origin() == (0, 0, 0)

    args = []
    if residues_per_region:
      args.append("residues_per_region=%s" %(residues_per_region))

    if keep_this_region_only is not None:
      regions_to_keep = -1 * keep_this_region_only


    if solvent_content is None and sequence is None and molecular_mass is None:
      from cctbx.maptbx.segment_and_split_map \
          import get_iterated_solvent_fraction
      solvent_content = get_iterated_solvent_fraction(
          crystal_symmetry = crystal_symmetry,
          mask_resolution = resolution,
          map = self._map_manager.map_data(),
          out = log)


    ncs_group_obj, remainder_ncs_group_obj, tracking_data  = \
      segment_and_split_map(args,
        map_data = self._map_manager.map_data(),
        crystal_symmetry = crystal_symmetry,
        ncs_obj = self._map_manager.ncs_object() if \
          use_symmetry_in_extract_unique else None,
        target_model = target_ncs_au_model,
        write_files = False,
        auto_sharpen = False,
        add_neighbors = False,
        density_select = False,
        save_box_map_ncs_au = True,
        resolution = resolution,
        solvent_content = solvent_content,
        chain_type = chain_type,
        sequence = sequence,
        molecular_mass = molecular_mass,
        symmetry = symmetry if use_symmetry_in_extract_unique else None,
        keep_low_density = keep_low_density,
        regions_to_keep = regions_to_keep,
        box_buffer = box_cushion,
        soft_mask_extract_unique = soft_mask,
        mask_expand_ratio = mask_expand_ratio,
        out = log)

    from scitbx.matrix import col

    # Note number of selected regions used.
    if hasattr(tracking_data, 'available_selected_regions'):
      self.set_info(group_args(
        group_args_type = 'available selected regions from around_unique',
        available_selected_regions = tracking_data.available_selected_regions,
        ))

    if not hasattr(tracking_data, 'box_mask_ncs_au_map_data'):
      raise Sorry(" Extraction of unique part of map failed...")

    ncs_au_mask_data = tracking_data.box_mask_ncs_au_map_data

    lower_bounds = ncs_au_mask_data.origin()
    upper_bounds = tuple(
      col(ncs_au_mask_data.focus())-col((1, 1, 1)))

    print("\nBounds for unique part of map: %s to %s " %(
     str(lower_bounds), str(upper_bounds)), file = log)

    # shift the map so it is in the same position as the box map will be in
    ncs_au_mask_data.reshape(flex.grid(ncs_au_mask_data.all()))
    assert col(ncs_au_mask_data.all()) == \
        col(upper_bounds)-col(lower_bounds)+col((1, 1, 1))

    self.gridding_first = lower_bounds
    self.gridding_last  = upper_bounds

    # Adjust gridding to make a cubic box if desired
    if self.use_cubic_boxing:
      self.set_cubic_boxing(stay_inside_current_map = stay_inside_current_map)

    # Ready with gridding...set up shifts and box crystal_symmetry
    self.set_shifts_and_crystal_symmetry()

    # Apply boxing to model, ncs, and map (if available)
    self.apply_to_model_ncs_and_map()

    # Note that at this point, self._map_manager has been boxed
    assert ncs_au_mask_data.all() == self._map_manager.map_data().all()
    self._mask_data = ncs_au_mask_data

    # Now separately apply the mask to the boxed map
    self.apply_around_unique_mask(
       self._map_manager,
       resolution = resolution,
       soft_mask = soft_mask)

  def apply_around_unique_mask(self,
      map_manager,
      resolution,
      soft_mask):
    '''
      This procedure matches what is done in segment_and_split_map
      It comes at the end of around_unique and can be applied to additional
      map_manager objects if desired.
    '''
    assert self._mask_data is not None

    map_manager.create_mask_with_map_data(map_data = self._mask_data)

    if soft_mask: # Make the mask a soft mask if requested
      map_manager.soft_mask(soft_mask_radius = resolution)
      map_manager.apply_mask()
      # Now mask around edges
      map_manager.create_mask_around_edges(boundary_radius = resolution)
      map_manager.soft_mask(soft_mask_radius = resolution)
      map_manager.apply_mask()

    else:  # just apply the mask
      map_manager.apply_mask()

    # And add limitation to map
    map_manager.add_limitation("extract_unique")

class around_mask(with_bounds):
  """
  Extract map box around masked region of a map that represents a mask
  You need to supply the mask as a map_manager object

  Box is in P1 and has origin at (0, 0, 0).

  Input map_manager must have origin (working position) at (0, 0, 0)

  Returns boxed version of map_manager supplied.  Object will contain
  the boxed version of mask as self.mask_as_map_manager.

  Wrapping:
    wrapping = True means that grid points outside of the unit cell can be
    mapped inside with unit translations and box can effectively come
    from anywhere in space.
    If wrapping = True, the supplied box must be a complete unit cell so that
    map_data.all() must be the same as unit_cell_grid.

   wrapping = False means that grid points outside of the unit cell are
    undefined.  If a box is specified that uses points outside the defined
    region, those points are set to zero.

  Note: stay_inside_current_map applies only when using cubic boxing
  if use_cubic_boxing, adjust bounds to make a cubic box by making box bigger.
      if this conflicts with stay_inside_current_map, make box smaller
  If require_match_unit_cell_crystal_symmetry:  require that unit_cell
    crystal symmetry of map and model match

  """
  def __init__(self, map_manager,
     mask_as_map_manager,
     model = None,
     box_cushion = 3,
     wrapping = None,
     use_cubic_boxing = False,
     model_can_be_outside_bounds = False,
     stay_inside_current_map = True,
     require_match_unit_cell_crystal_symmetry = False,
     log = sys.stdout):

    self.require_match_unit_cell_crystal_symmetry = \
       require_match_unit_cell_crystal_symmetry
    self._map_manager = map_manager
    self._model = model
    self.model_can_be_outside_bounds = model_can_be_outside_bounds
    self.use_cubic_boxing = use_cubic_boxing
    assert map_manager.shift_cart()==mask_as_map_manager.shift_cart()

    # safeguards
    assert isinstance(map_manager, iotbx.map_manager.map_manager)
    assert isinstance(mask_as_map_manager, iotbx.map_manager.map_manager)
    assert self._map_manager.map_data().accessor().origin()  ==  (0, 0, 0)
    assert map_manager.is_similar(mask_as_map_manager)
    if self.map_manager().wrapping():
      assert map_manager.unit_cell_grid == map_manager.map_data().all()

    self._force_wrapping = wrapping
    if wrapping is None:
      wrapping = self.map_manager().wrapping()
    self.basis_for_boxing_string = 'around_mask bounds, wrapping = %s' %(
      wrapping)

    # Make sure the map goes from 0 to 1
    map_data = mask_as_map_manager.map_data()
    mmm = map_data.as_1d().min_max_mean()
    minimum = mmm.min
    range_of_values = mmm.max - mmm.min
    map_data = (map_data - minimum ) / max(1.e-10,range_of_values)


    # Get a connectivity object that marks all the connected regions in map

    from cctbx.maptbx.segment_and_split_map import get_co
    co, sorted_by_volume, min_b, max_b = get_co(
       map_data = map_data,
       threshold = 0.5,
       wrapping = False)


    if len(sorted_by_volume)<2:  # didn't work
      raise Sorry("No mask obtained...")

    # Get the biggest connected region in the map

    original_id_from_id = {}
    for i in range(1, len(sorted_by_volume)):
      v, id = sorted_by_volume[i]
      original_id_from_id[i] = id
    id = 1
    orig_id = original_id_from_id[id]

    # Get lower and upper bounds of this region in grid units

    self.gridding_first = min_b[orig_id]
    self.gridding_last  = max_b[orig_id]

    # Increase range of bounds by box_cushion
    cs = map_manager.crystal_symmetry()
    cushion = flex.double(cs.unit_cell().fractionalize((box_cushion, )*3))
    all_orig = map_manager.map_data().all()
    self.gridding_first = [max(0, ifloor(gf-c*n)) for c, gf, n in zip(
       cushion, self.gridding_first, all_orig)]
    self.gridding_last  = [min(n-1, iceil(gl+c*n)) for c, gl, n in zip(
       cushion, self.gridding_last, all_orig)]

    # Adjust gridding to make a cubic box if desired
    if self.use_cubic_boxing:
      self.set_cubic_boxing(stay_inside_current_map = stay_inside_current_map)

    # Ready with gridding...set up shifts and box crystal_symmetry
    self.set_shifts_and_crystal_symmetry()

    self.apply_to_model_ncs_and_map()

    # Also apply to mask_as_map_manager so that mask_as_map_manager is boxed
    mask_as_map_manager = self.apply_to_map(mask_as_map_manager)
    self.mask_as_map_manager = mask_as_map_manager # save it


class around_density(with_bounds):
  """
  Extract map box around region of a map containing density

  Box is in P1 and has origin at (0, 0, 0).

  Input map_manager must have origin (working position) at (0, 0, 0)

  Wrapping:
    wrapping = True means that grid points outside of the unit cell can be
    mapped inside with unit translations and box can effectively come
    from anywhere in space.
    If wrapping = True, the supplied box must be a complete unit cell so that
    map_data.all() must be the same as unit_cell_grid.

   wrapping = False means that grid points outside of the unit cell are
    undefined.  If a box is specified that uses points outside the defined
    region, those points are set to zero.

   if use_cubic_boxing, adjust bounds to make a cubic box by making box bigger.
   Note: stay_inside_current_map applies only when using cubic boxing
   if this conflicts with stay_inside_current_map, make box smaller
  If require_match_unit_cell_crystal_symmetry:  require that unit_cell
    crystal symmetry of map and model match

  """
  def __init__(self, map_manager,
     threshold = 0.05,
     box_cushion = 3.,
     get_half_height_width = True,
     model = None,
     wrapping = None,
     model_can_be_outside_bounds = False,
     use_cubic_boxing = False,
     stay_inside_current_map = True,
     require_match_unit_cell_crystal_symmetry = False,
     log = sys.stdout):

    self.require_match_unit_cell_crystal_symmetry = \
       require_match_unit_cell_crystal_symmetry
    self._map_manager = map_manager
    self._model = model
    self.model_can_be_outside_bounds = model_can_be_outside_bounds
    self.use_cubic_boxing = use_cubic_boxing

    # safeguards
    assert threshold is not None
    assert box_cushion is not None
    assert isinstance(map_manager, iotbx.map_manager.map_manager)
    assert self._map_manager.map_data().accessor().origin()  ==  (0, 0, 0)
    if self.map_manager().wrapping():
      assert map_manager.unit_cell_grid == map_manager.map_data().all()

    self._force_wrapping = wrapping
    if wrapping is None:
      wrapping = self.map_manager().wrapping()
    self.basis_for_boxing_string = 'around_density, wrapping = %s' %(
      wrapping)

    # Select box where data are positive (> threshold*max)
    map_data = map_manager.map_data()
    origin = list(map_data.origin())
    assert origin == [0, 0, 0]
    all = list(map_data.all())

    edge_values = flex.double()
    ux = all[0]-1
    uy = all[1]-1
    uz = all[2]-1
    for lb, ub in (
      [(0,0,0), (0,uy,uz)],
      [(ux,0,0), (ux,uy,uz)],
      [(0,0,0), (ux,0,uz)],
      [(0,uy,0), (ux,uy,uz)],
      [(0,0,0), (ux,uy,0)],
      [(0,0,uz), (ux,uy,uz)],
      ):
      new_map_data = maptbx.copy(map_data,lb,ub)
      edge_values.append(new_map_data.as_1d().as_double().min_max_mean().max)
    edge_value = edge_values.min_max_mean().mean

    # Get max value vs x, y, z
    value_list = flex.double()
    for i in range(0, all[0]):
      new_map_data = maptbx.copy(map_data,
         tuple((i, 0, 0)),
         tuple((i, all[1], all[2]))
       )
      value_list.append(
        new_map_data.as_1d().as_double().min_max_mean().max - edge_value)
    ii = 0
    for z in value_list:
      ii+= 1
    x_min, x_max = get_range(value_list, threshold = threshold,
      get_half_height_width = get_half_height_width)

    value_list = flex.double()
    for j in range(0, all[1]):
      new_map_data = maptbx.copy(map_data,
         tuple((0, j, 0)),
         tuple((all[0], j, all[2]))
       )
      value_list.append(
        new_map_data.as_1d().as_double().min_max_mean().max - edge_value)
    y_min, y_max = get_range(value_list, threshold = threshold,
      get_half_height_width = get_half_height_width)

    value_list = flex.double()
    for k in range(0, all[2]):
      new_map_data = maptbx.copy(map_data,
         tuple((0, 0, k)),
         tuple((all[0], all[1], k))
       )
      value_list.append(
        new_map_data.as_1d().as_double().min_max_mean().max - edge_value)
    z_min, z_max = get_range(value_list, threshold = threshold,
      get_half_height_width = get_half_height_width)

    # Get lower and upper bounds of this region in grid units
    frac_min = (x_min, y_min, z_min)
    frac_max = (x_max, y_max, z_max)
    cs = map_manager.crystal_symmetry()
    cushion = flex.double(cs.unit_cell().fractionalize((box_cushion, )*3))
    all_orig = map_data.all()
    self.gridding_first = [max(0, ifloor((f-c)*n)) for c, f, n in zip(
       cushion, frac_min, all_orig)]
    self.gridding_last  = [ min(n-1, iceil((f+c)*n)) for c, f, n in zip(
       cushion, frac_max, all_orig)]
    # Adjust gridding to make a cubic box if desired
    if self.use_cubic_boxing:
      self.set_cubic_boxing(stay_inside_current_map = stay_inside_current_map)

    # Ready with gridding...set up shifts and box crystal_symmetry
    self.set_shifts_and_crystal_symmetry()

    # Apply boxing to model, ncs, and map (if available)
    self.apply_to_model_ncs_and_map()

def is_even(n):
  if n < 0:
    n = -n
  if 2 * (n//2) == n:
    return True
  else:
    return False

def cube_relative_to_box(new_first, new_last, map_all,
       require_even_gridding = None):
    ''' returns zero or negative number for lowest_value of new_first and
       zero or positive number for highest value of new_last - map_all
      If require_even_gridding, make the lowest and highest even by making
       them further from zero'''

    lowest_value = min(0, min([a for a in new_first]))
    if require_even_gridding and (not is_even(lowest_value)):
      lowest_value -= 1
    highest_value = max(0, max([a - b for a, b in zip(new_last,map_all)]))
    if require_even_gridding and (not is_even(highest_value)):
      highest_value += 1
    print("lowest, highest out of box:",lowest_value, highest_value)
    return lowest_value,highest_value

def get_range(value_list, threshold = None, ignore_ends = True,
   keep_near_ends_frac = 0.02, half_height_width = 2.,
   get_half_height_width = None,
   cutoff_ratio = 4, ratio_max = 0.5,
   smooth_list_first = True,
   smooth_units = 20,
   max_allowed_outside_of_box = 0.33 ): # XXX May need to set cutoff_ratio and
  #  ratio_max lower.
  # ignore ends allows ignoring the first and last points which may be off
  # if get_half_height_width, find width at half max hieght, go
  #  half_height_width times this width out in either direction, use that as
  #  baseline instead of full cell. Don't do it if the height at this point
  #  is over cutoff_ratio times threshold above original baseline.
  #  If value outside range is more than max_allowed_outside_of_box of max,
  #    make it bigger.
  n_tot = value_list.size()
  assert n_tot>0
  if smooth_list_first:
   value_list = flex.double(smooth_list(value_list,
     smooth_range = max(1, value_list.size()//smooth_units)))

  if get_half_height_width:
    z_min, z_max = get_range(value_list, threshold = 0.5,
      ignore_ends = ignore_ends, keep_near_ends_frac = keep_near_ends_frac,
      get_half_height_width = False, smooth_list_first = False)
    z_mid = 0.5*(z_min+z_max)
    z_width = 0.5*(z_max-z_min)
    z_low = z_mid-2*z_width
    z_high = z_mid+2*z_width
    if ignore_ends:
      i_max = value_list.size()-2
      i_min = 1
    else:
      i_max = value_list.size()-1
      i_min = 0

    i_low =  max(i_min, min(i_max, int(0.5+z_low* value_list.size())))
    i_high = max(i_min, min(i_max, int(0.5+z_high*value_list.size())))
    min_value = value_list.min_max_mean().min
    max_value = value_list.min_max_mean().max
    ratio_low = (value_list[i_low]-min_value)/max(
       1.e-10, (max_value-min_value))
    ratio_high = (value_list[i_high]-min_value)/max(
       1.e-10, (max_value-min_value))
    if ratio_low <=  cutoff_ratio*threshold and ratio_low >0 \
         and ratio_low<ratio_max\
         and ratio_high <=  cutoff_ratio*threshold and ratio_high > 0 \
         and ratio_high < ratio_max:
      ratio = min(ratio_low, ratio_high)
      z_min, z_max = get_range(
        value_list, threshold = threshold+ratio,
        ignore_ends = ignore_ends, keep_near_ends_frac = keep_near_ends_frac,
        get_half_height_width = False, smooth_list_first = False)
    else:
      z_min, z_max = get_range(value_list, threshold = threshold,
        ignore_ends = ignore_ends, keep_near_ends_frac = keep_near_ends_frac,
        get_half_height_width = False, smooth_list_first = False)
    if not too_high_outside_range(value_list, int(0.5+ n_tot * z_min),
         int(0.5+ n_tot *z_max),
        max_allowed_outside_of_box): # ok
      return z_min, z_max

  if threshold is None: threshold = 0
  min_value = value_list.min_max_mean().min
  max_value = value_list.min_max_mean().max
  cutoff = min_value+(max_value-min_value)*threshold

  # Find lowest point to left and right of highest point
  vl = list(value_list)
  max_i = vl.index(max_value)
  if max_i == 0:
    min_i_to_left = 0
  else: # usual
    min_to_left = value_list[:max_i].min_max_mean().min
    min_i_to_left = vl.index(min_to_left,0,max_i)
  if max_i == n_tot - 1:
    min_i_to_right = n_tot - 1
  else: # usual
    min_to_right = value_list[max_i:].min_max_mean().min
    min_i_to_right = vl.index(min_to_right,min(n_tot-1,max_i+1),n_tot)
  if ignore_ends:
    i_off = 1
  else:
    i_off = 0
  i_low = None
  for i in range(max(min_i_to_left,i_off), min(min_i_to_right,n_tot-i_off)):
    if value_list[i]>cutoff:
      i_low = max(i_off, i-1)
      break
  i_high = None
  for ii in range(
       min(min_i_to_right,n_tot-i_off),
       max(min_i_to_left,i_off),
        -1):
    if value_list[ii]>cutoff:
      i_high = min(n_tot-1-i_off, ii+1)
      break
  if i_low is None or i_high is None:
    raise Sorry("Cannot auto-select region...")
  if i_low/n_tot<keep_near_ends_frac: i_low = 0
  if (n_tot-1-i_high)/n_tot<keep_near_ends_frac: i_high = n_tot-1
  if not too_high_outside_range(value_list, i_low, i_high,
        max_allowed_outside_of_box): # ok
    return i_low/n_tot, i_high/n_tot

  # Failed to include high density...try again not using low point
  if threshold is None: threshold = 0
  min_value = value_list.min_max_mean().min
  max_value = value_list.min_max_mean().max
  cutoff = min_value+(max_value-min_value)*threshold
  if ignore_ends:
    i_off = 1
  else:
    i_off = 0
  i_low = None
  for i in range(i_off, n_tot-i_off):
    if value_list[i]>cutoff:
      i_low = max(i_off, i-1)
      break
  i_high = None
  for i in range(i_off, n_tot-i_off):
    ii = n_tot-1-i
    if value_list[ii]>cutoff:
      i_high = min(n_tot-1-i_off, ii+1)
      break
  if i_low is None or i_high is None:
    raise Sorry("Cannot auto-select region...")
  if i_low/n_tot<keep_near_ends_frac: i_low = 0
  if (n_tot-1-i_high)/n_tot<keep_near_ends_frac: i_high = n_tot-1
  if not too_high_outside_range(value_list, i_low, i_high,
        max_allowed_outside_of_box): # ok
    return i_low/n_tot, i_high/n_tot
  else:  # give up and take the whole thing
    return i_off/n_tot, (n_tot - i_off - 1)/n_tot



def too_high_outside_range(value_list, i_start, i_end,
       max_allowed_outside_of_box):
  inside_values = flex.double(value_list[i_start:i_end])
  outside_values = flex.double(value_list[:i_start])
  outside_values.extend(flex.double(value_list[i_end:]))
  if outside_values.min_max_mean().max > \
      max_allowed_outside_of_box * inside_values.min_max_mean().max:
    return True
  else:
    return False

def smooth_list(working_list,smooth_range = None): # smooth this list of numbers
    assert smooth_range is not None
    new_list=[]
    delta=smooth_range//2
    for i in range(len(working_list)):
      sum=0.
      sumn=0.
      for j in range(-delta,delta+1):
        jj=j+i
        if jj >=0 and jj < len(working_list):
          sum+=working_list[jj]
          sumn+=1.
      if sumn>0.:
        sum=sum/sumn
      new_list.append(sum)
    return new_list

def get_bounds_of_valid_region(map_data,
    gridding_first,
    gridding_last):

  '''
    If map_data is sampled from gridding_first to gridding_last with
    maptbx.copy, (1) does the sampling go outside of map_data?
    (2) What are the lower and upper bounds of the valid region of the resulting
    map?
  '''

  lower_allowed_bounds = []
  upper_allowed_bounds = []
  inside_allowed_bounds = True
  some_valid_points = True
  for o, a, f, l in zip(map_data.origin(), map_data.all(),
     gridding_first, gridding_last):
    # Available map goes from o to o+a-1
    # Requested map goes from f to l

    # If f is less than o, first valid grid point is o.
    # Otherwise, first valid grid point is f
    # so first valid grid point is max(f, o)

    # If f is less than o
    #   After shifting origin to (0, 0, 0) first valid grid point is o-f
    # Otherwise, after shifting origin, first valid grid point is 0.

    #  If l is >=  a+o, last valid grid point is a+o-1
    #  Otherwise last valid grid point is l
    # So last valid grid point is min(l, a+o-1)

    #  If l is >=  a+o
    #    After shifting origin to (0, 0, 0), last valid grid point is a+o-1-f
    #  Otherwise, after shifting origin, last valid grid point is l-f


    first_valid = max(o, f) # first valid grid point
    last_valid = min(l, o+a-1) # last valid grid point
    lower_allowed_bounds.append(first_valid)
    upper_allowed_bounds.append(last_valid)
    if f < o or l >=  a+o:
      inside_allowed_bounds = False
    if last_valid <=  first_valid:
      some_valid_points = False

  return group_args(
     lower_allowed_bounds = lower_allowed_bounds,
     upper_allowed_bounds = upper_allowed_bounds,
     gridding_first = gridding_first,
     gridding_last = gridding_last,
     inside_allowed_bounds = inside_allowed_bounds,
     some_valid_points = some_valid_points)

def copy_and_zero_map_outside_bounds(map_data, bounds_info):
  '''
     Copy part of a map and zero outside valid region

     Goes with get_bounds_of_valid_region

     First copy requested part of map, wrapping if request goes outside
     of supplied map.

     Then zero out everything that was from outside the available region.

     Returns map with bounds from bounds_info.gridding_first to
     bounds_info.gridding_last, but everything outside of
     lower_allowed_bounds to upper_allowed_bounds is zeroed out.
  '''

  # First copy the entire requested region:

  map_copy = maptbx.copy(map_data,
      bounds_info.gridding_first, bounds_info.gridding_last)
  # Note: the origin of map_copy is at gridding_first and goes to last

  # Make sure we are working with a flex.double array
  if type(map_copy) !=  type(flex.double()): # must be double
    map_copy = map_copy.as_double()

  # Make sure this map matches the bounds_info
  assert tuple(map_copy.origin()) == tuple(bounds_info.gridding_first)

  # We are going to shift the origin in this copy, so shift the bounds to match

  lower_bounds_after_shift = []
  upper_bounds_after_shift = []
  for l, u, f in zip(bounds_info.lower_allowed_bounds,
      bounds_info.upper_allowed_bounds,
      bounds_info.gridding_first):
    lower_bounds_after_shift.append(l-f)
    upper_bounds_after_shift.append(u-f)

  acc = map_copy.accessor() # save where the origin is

  map_copy = map_copy.shift_origin()  # put origin at (0, 0, 0)
  map_copy_all = map_copy.all() # save size of map
  # XXX work-around for set_box does not allow offset origin
  map_copy.resize(flex.grid(map_copy_all))
  new_map = maptbx.set_box_copy_inside(0,  # copies inside, zero outside bounds
    map_data_to   = map_copy,
    start         = tuple(lower_bounds_after_shift),
    end           = tuple(upper_bounds_after_shift))
  # XXX and shift map back
  new_map = new_map.as_1d()
  new_map.reshape(acc)
  return new_map

def shift_and_box_model(model = None,
    box_cushion = 5, shift_model = True,
    crystal_symmetry = None):
  '''
    Shift a model near the origin and box around it
    Use crystal_symmetry if supplied
    Keeps input model unchanged.
  '''
  from mmtbx.model import manager as model_manager
  from scitbx.matrix import col
  from cctbx import crystal

  ph=model.get_hierarchy()
  sites_cart=ph.atoms().extract_xyz()
  if shift_model:
    sites_cart=sites_cart-col(sites_cart.min())+col(
      (box_cushion,box_cushion,box_cushion))

  box_start=col(sites_cart.min())-col((box_cushion,box_cushion,box_cushion))
  box_end=col(sites_cart.max())+col((box_cushion,box_cushion,box_cushion))
  if not crystal_symmetry:
    a,b,c = box_end - box_start
    crystal_symmetry=crystal.symmetry((a,b,c, 90,90,90),1)
  phc = ph.deep_copy()
  phc.atoms().set_xyz(sites_cart)
  phc.atoms().reset_serial()
  mm = model_manager(
     model_input = None,
     pdb_hierarchy = phc,
     crystal_symmetry = crystal_symmetry,
     restraint_objects = model.get_restraint_objects(),
     monomer_parameters = model.get_monomer_parameters(),
     log = null_out())
  return mm

def get_boxes_to_tile_map(target_for_boxes = 24,
      n_real = None,
      crystal_symmetry = None,
      cushion_nx_ny_nz = None,
      wrapping = False,
      do_not_go_over_target = None,
      target_xyz_center_list = None,
     ):

    '''
      Get a set of boxes that tile the map
      If cushion_nx_ny_nz is set ... create a second set of boxes that are
        expanded by cushion_nx_ny_nz in each direction
      Try to make boxes symmetrical in full map
      If target_xyz_center_list is set, try to use them as centers but keep
       size the same as would otherwise be used
    '''
    nx,ny,nz = n_real
    smallest = min(nx,ny,nz)
    largest = max(nx,ny,nz)
    target_volume_per_box = (nx*ny*nz)/target_for_boxes
    target_length = target_volume_per_box**0.33
    if target_xyz_center_list:
      lower_bounds_list = []
      upper_bounds_list = []
      uc = crystal_symmetry.unit_cell()
      for site_frac in uc.fractionalize(target_xyz_center_list):
        center_ijk = tuple([ int(0.5+x * n) for x,n in zip(site_frac, n_real)])
        lower_bounds_list.append(
          tuple( [
             int(max(1,min(n-2,(i - (1+target_length)//2)))) for i,n in
            zip(center_ijk,n_real)
             ]
          ))
        upper_bounds_list.append(
          tuple( [
             int(max(1,min(n-2,(i + (1+target_length)//2)))) for i,n in
            zip(center_ijk,n_real)
             ]
          ))
    elif target_for_boxes == 1:
      lower_bounds_list = [(0,0,0)]
      upper_bounds_list = [tuple([i - 1 for i in n_real])]
    else:
      lower_bounds_list = []
      upper_bounds_list = []
      for x_info in get_bounds_list(nx, target_length,
        do_not_go_over_target = do_not_go_over_target):
        for y_info in get_bounds_list(ny, target_length,
           do_not_go_over_target = do_not_go_over_target):
          for z_info in get_bounds_list(nz, target_length,
             do_not_go_over_target = do_not_go_over_target):
            lower_bounds_list.append(
               [x_info.lower_bound,
                y_info.lower_bound,
                z_info.lower_bound])
            upper_bounds_list.append(
               [x_info.upper_bound,
                y_info.upper_bound,
                z_info.upper_bound])

    # Now make a set of boxes with a cushion if requested
    lower_bounds_with_cushion_list = []
    upper_bounds_with_cushion_list = []
    if cushion_nx_ny_nz:

      for lb,ub in zip (lower_bounds_list,upper_bounds_list):
        if (wrapping):
          new_lb = tuple([b - c for b,c in zip(lb, cushion_nx_ny_nz)])
          new_ub = tuple([u + c for u,c in zip(ub, cushion_nx_ny_nz)])
        else:
          new_lb = tuple([max(0,b - c) for b,c in zip(lb, cushion_nx_ny_nz)])
          new_ub = tuple([min(n-1,u + c) for u,c,n in zip(ub, cushion_nx_ny_nz,
            n_real)])
        lower_bounds_with_cushion_list.append(new_lb)
        upper_bounds_with_cushion_list.append(new_ub)
    else:
      lower_bounds_with_cushion_list = lower_bounds_list
      upper_bounds_with_cushion_list = upper_bounds_list

    # Now remove any duplicates
    lb_ub_list = []
    new_lb_list = []
    new_ub_list = []
    for lb,ub in zip (
         lower_bounds_with_cushion_list,upper_bounds_with_cushion_list):
       if [lb,ub] in lb_ub_list: continue
       lb_ub_list.append([lb,ub])
       new_lb_list.append(lb)
       new_ub_list.append(ub)
    lower_bounds_with_cushion_list = new_lb_list
    upper_bounds_with_cushion_list = new_ub_list

    return group_args(
      lower_bounds_list = lower_bounds_list,
      upper_bounds_list = upper_bounds_list,
      lower_bounds_with_cushion_list = lower_bounds_with_cushion_list,
      upper_bounds_with_cushion_list = upper_bounds_with_cushion_list,
      n_real = n_real,
      crystal_symmetry = crystal_symmetry,
     )

def get_bounds_list(nx, target_length,
     do_not_go_over_target = None,):
  '''
    Return start, end that are about the length target_length and that
    collectively cover exactly nx grid units.
    Try to make bounds on the ends match target_length
    Try to make bounds symmetrical
  '''

  bounds_list = []
  if nx < (3 * target_length)/2:  # take one only
    bounds_list.append(
      group_args(
       lower_bound = 0,
       upper_bound = nx - 1,)
      )
  else:  # take as many as fit
    n_target = nx/target_length  # how many we want (float)
    if do_not_go_over_target:
      n = max(1,int(n_target)) # int ... how many can fit
    else: # usual
      n = max(1,int(0.5 + n_target)) # int ... how many can fit
    exact_target_length =  nx/n  # float length of each group

    last_end_point = -1
    length_list = []
    for i in range(n):
      target_end_point = exact_target_length * (i+1)
      actual_end_point = min (nx -1, max(0, int(0.5 + target_end_point)))
      length_list.append(actual_end_point - last_end_point)
      last_end_point = actual_end_point

    # Now try and make length_list symmetric
    length_list = make_list_symmetric(length_list)
    last_end_point = -1
    for i in range(n):
      actual_end_point = last_end_point + length_list[i]
      bounds_list.append(
          group_args(
       lower_bound = last_end_point + 1,
       upper_bound = actual_end_point,)
      )
      last_end_point = actual_end_point

  return bounds_list

def make_list_symmetric(length_list):
  '''
   adjust entries in length_list to make it symmetric but same total
  '''
  from copy import deepcopy
  length_list = deepcopy(length_list)
  unused_length = 0
  n=len(length_list)

  from scitbx.array_family import flex
  total = flex.double(tuple(length_list)).min_max_mean().mean*len(length_list)
  for i_from_end in range (n//2): # may leave out middle one if present
    i = i_from_end
    n_bigger = length_list[i] - length_list[n-i-1]
    n_bigger_abs = abs(n_bigger)
    n_shift = n_bigger_abs//2
    n_bigger_even = 2*n_shift
    if n_bigger > 0:
      # move n_shift to n-i-1 and save remainder
      length_list[n-i-1] += n_shift
      length_list[i] -= n_shift
      delta = length_list[i] - length_list[n-i-1]
      assert delta >= 0
      length_list[i] -= delta
      unused_length += delta
    elif n_bigger < 0:
      # move n_shift to i and save remainder
      length_list[i] += n_shift
      length_list[n-i-1] -= n_shift
      delta = length_list[n-i-1] - length_list[i]
      assert delta >= 0
      length_list[n-i-1] -= delta
      unused_length += delta
    if unused_length//2 > 0:
      length_list[i] += unused_length//2
      length_list[n-i-1] += unused_length//2
      unused_length -= 2* (unused_length//2)
  if unused_length:
    length_list[(n+1)//2] += unused_length
  return length_list


def get_bounds_around_model(
      map_manager = None,
      model = None,
      box_cushion = None,
      stay_inside_current_map = None,
     ):
    '''
      Calculate the lower and upper bounds to box around a model
      Allow bounds to go outside the available box unless
        stay_inside_current_map (this has to be dealt with at the boxing stage)
    '''

    # get items needed to do the shift
    cs = map_manager.crystal_symmetry()
    uc = cs.unit_cell()
    sites_cart = model.get_sites_cart()
    sites_frac = uc.fractionalize(sites_cart)
    map_data = map_manager.map_data()
    # convert box_cushion into fractional vector
    cushion_frac = flex.double(uc.fractionalize((box_cushion, )*3))
    # find fractional corners
    frac_min = sites_frac.min()
    frac_max = sites_frac.max()
    frac_max = list(flex.double(frac_max)+cushion_frac)
    frac_min = list(flex.double(frac_min)-cushion_frac)
    # find corner grid nodes
    all_orig = map_data.all()

    lower_bounds = [ifloor(f*n) for f, n in zip(frac_min, all_orig)]
    upper_bounds = [ iceil(f*n) for f, n in zip(frac_max, all_orig)]
    n = all_orig[-1]
    if stay_inside_current_map:
      lower_bounds = [ min(n-1,max (0,lb)) for lb in lower_bounds]
      upper_bounds = [ min (ub, n-1) for ub,n in zip(upper_bounds,all_orig)]
    return group_args(
      lower_bounds = lower_bounds,
      upper_bounds = upper_bounds,
    )


 *******************************************************************************
